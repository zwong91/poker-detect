{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8用于检测牌的位置，而LSTM则学习这些位置的时间序列模式，从而预测未来的行为。\n",
    "- You Only Look Once YOLO 接受整张图片作为输入划分为网格，每个网格预测一组边界框和对应的物体类别，这让 YOLO 很快\n",
    "- YOLO 将物体检测视为回归问题来解决，直接从图片生成边界框坐标和类别概率\n",
    "- LSTM Long Short-Term Memory 长短期记忆网络，适合时间序列预测的行为模式\n",
    "\n",
    "**这是一个相对复杂的深度学习应用，适用于人和动物行为研究中需要分析大量序列数据的场景。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "样本数num_samples: 54 poker, 每个样本time_steps: 20个时间序列, 每个时间序列num_features: 10个特征(待加入更多)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.15 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: filterpy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.4.5)\n",
      "Requirement already satisfied: opencv-python in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: pillow in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (10.4.0)\n",
      "Requirement already satisfied: numpy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: tensorboard in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (2.15.2)\n",
      "Requirement already satisfied: pandas in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tf2onnx in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.16.1)\n",
      "Requirement already satisfied: onnx in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.16.2)\n",
      "Requirement already satisfied: onnxruntime in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.19.2)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.66.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: scipy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from filterpy) (1.14.1)\n",
      "Requirement already satisfied: matplotlib in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from filterpy) (3.9.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from onnxruntime) (1.13.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow==2.15) (0.43.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.15 filterpy opencv-python pillow numpy scikit-learn tensorboard pandas tf2onnx onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras\n",
    "# print(tensorflow.keras.__version__)\n",
    "\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ultralytics/ultralytics.git@main\n",
      "  Cloning https://github.com/ultralytics/ultralytics.git (to revision main) to /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-req-build-hrugaz0j\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics.git /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-req-build-hrugaz0j\n",
      "  Resolved https://github.com/ultralytics/ultralytics.git to commit 1e604e0d1c74863001debdb1992471af4b030868\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (2.4.1)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics==8.2.87)\n",
      "  Using cached torchvision-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (4.66.5)\n",
      "Requirement already satisfied: psutil in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (6.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics==8.2.87)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from ultralytics==8.2.87) (2.2.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics==8.2.87)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics==8.2.87)\n",
      "  Using cached ultralytics_thop-2.0.6-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.87) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.87) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.87) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.87) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.87) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.87) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.87) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.2.87) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.2.87) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.87) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.87) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.87) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.87) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.87) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.87) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.87) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.87) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.87) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.87) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.2.87) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.2.87) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics==8.2.87) (1.3.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached torchvision-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (1.7 MB)\n",
      "Using cached ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: ultralytics\n",
      "  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ultralytics: filename=ultralytics-8.2.87-py3-none-any.whl size=872130 sha256=002c5d5b9b850a36a2f66a4777d2e5ca66dfa0c8a98c197af06dfcf0b64e4e9f\n",
      "  Stored in directory: /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-ephem-wheel-cache-yvun7lp5/wheels/60/db/e5/6abbdd13b4e3d5e2fdcd87690cd8738f842eeb37142fdccb5b\n",
      "Successfully built ultralytics\n",
      "Installing collected packages: py-cpuinfo, ultralytics-thop, torchvision, seaborn, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 seaborn-0.13.2 torchvision-0.19.1 ultralytics-8.2.87 ultralytics-thop-2.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the ultralytics package from GitHub\n",
    "%pip install git+https://github.com/ultralytics/ultralytics.git@main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. YOLOv8 模型检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#from sort import Sort\n",
    "#https://github.com/RizwanMunawar/yolov7-object-tracking/blob/main/sort.py\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, Layer, Masking, BatchNormalization, GRU, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='poker_analysis.log', level=logging.INFO, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "# 加载YOLOv8 模型\n",
    "#yolo_model = YOLO('poker/n_pretrain/weights/best.pt')\n",
    "yolo_model = YOLO(\"poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel\") #load a custom nano trained model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. 多目标的位置\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model(frame)  # 进行目标检测\n",
    "    detections = {\n",
    "        'Tc': [], 'Td': [], 'Th': [], 'Ts': [],\n",
    "        '2c': [], '2d': [], '2h': [], '2s': [],\n",
    "        '3c': [], '3d': [], '3h': [], '3s': [],\n",
    "        '4c': [], '4d': [], '4h': [], '4s': [],\n",
    "        '5c': [], '5d': [], '5h': [], '5s': [],\n",
    "        '6c': [], '6d': [], '6h': [], '6s': [],\n",
    "        '7c': [], '7d': [], '7h': [], '7s': [],\n",
    "        '8c': [], '8d': [], '8h': [], '8s': [],\n",
    "        '9c': [], '9d': [], '9h': [], '9s': [],\n",
    "        'Ac': [], 'Ad': [], 'Ah': [], 'As': [],\n",
    "        'Jc': [], 'Jd': [], 'Jh': [], 'Js': [],\n",
    "        'Kc': [], 'Kd': [], 'Kh': [], 'Ks': [],\n",
    "        'Qc': [], 'Qd': [], 'Qh': [], 'Qs': [],\n",
    "        'SJoker': [], 'BJoker': []\n",
    "    }\n",
    "    for result in results:\n",
    "        for obj in result.boxes: # 提取检测结果\n",
    "            if obj.conf.item() > 0.5:\n",
    "                # tensor to numpy\n",
    "                #bbox = obj.xyxy[0].cpu().numpy()\n",
    "                #x_min, y_min, x_max, y_max = obj.xyxy[0]\n",
    "                bbox = obj.xyxy[0].cpu().numpy().astype(int)\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                \n",
    "                # roi = frame[y_min:y_max, x_min:x_max]\n",
    "                # roi_resized = cv2.resize(roi, (64, 64))\n",
    "                \n",
    "                # 数据增强: 随机翻转和旋转\n",
    "                # if np.random.rand() > 0.5:\n",
    "                #     roi_resized = cv2.flip(roi_resized, 1)\n",
    "                # angle = np.random.uniform(-10, 10)\n",
    "                # M = cv2.getRotationMatrix2D((32, 32), angle, 1.0)\n",
    "                # roi_resized = cv2.warpAffine(roi_resized, M, (64, 64))\n",
    "                # roi_tensor = torch.tensor(roi_resized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "                #张量的形状变为 (1, 通道, 高度, 宽度)\n",
    "                #print(\"ROI Tensor:\", roi_tensor)\n",
    "                \n",
    "                #x_center = (x_min + x_max) / 2\n",
    "                #y_center = (y_min + y_max) / 2\n",
    "                # Get the boxes center coordinates (x, y), width (w), and height (h) size\n",
    "                x, y, w, h = obj.xywh[0].cpu()\n",
    "                speed = np.sqrt((w ** 2 + h ** 2))\n",
    "                conf = obj.conf.item()\n",
    "                # labels names\n",
    "                class_id = int(obj.cls.item())\n",
    "                class_name = yolo_model.names[class_id]\n",
    "                if class_name in detections:\n",
    "                    detections[class_name].append([x_min, y_min, x_max, y_max, conf])\n",
    "\n",
    "    return detections\n",
    "\n",
    "# 2. 多模态输入包括上面的视频数据和其他传感器数据\n",
    "#TODO: 假设我们有来自不同传感器的数据，Raspberry Pi 控制挂件装置，读取和处理传感器数据\n",
    "sensor_data = np.random.rand(1000, 5)  # 例如溫度、光強度等\n",
    "\n",
    "# 3. 同步处理多模态数据\n",
    "def synchronize_data(detections, sensor_data):\n",
    "    # hstack 将目标的检测数据与传感器数据在特征层面上拼接在一起，形成一个多模态输入矩阵\n",
    "    return np.hstack([detections, sensor_data[:len(detections), :]])\n",
    "\n",
    "# 获取同步后的数据\n",
    "#sync_data = synchronize_data(all_detections, sensor_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 卡尔曼滤波器精确追踪进行位置更新和噪声过滤\n",
    "\n",
    "https://medium.com/@mosesdaudu001/object-detection-tracking-with-yolov8-and-sort-algorithm-363be8bc0806\n",
    "\n",
    "\n",
    "Predicting future positions of moving objects is indeed a complex task that typically involves motion prediction algorithms such as Kalman filters \n",
    "or more advanced techniques like deep learning-based trajectory prediction.\n",
    "预测移动物体的未来位置确实是一项复杂的任务，通常涉及运动预测算法（例如卡尔曼滤波器）或更先进的技术（例如基于深度学习的轨迹预测）。\n",
    "\n",
    "YOLO's tracking algorithm already incorporates Kalman filtering\n",
    "YOLO 的跟踪算法已经包含卡尔曼滤波器， 提取每个跟踪对象的当前状态（位置和速度），然后多次使用卡尔曼滤波器来预测其未来状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 追踪所有目标对象\\ntracked_positions = []\\nfor det_list in all_detections.values():\\n    tracked_position = [track_objects(d) for d in det_list]\\n    tracked_positions.append(tracked_position)\\n    \\ntracked_positions\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from filterpy.kalman import KalmanFilter\n",
    "# DeepSORT\n",
    "\n",
    "def initialize_kalman_filter():\n",
    "    kf = KalmanFilter(dim_x=7, dim_z=4)  # 7 个状态变量，4 个观测变量\n",
    "    kf.F = np.array([[1,0,0,0,1,0,0],\n",
    "                     [0,1,0,0,0,1,0],\n",
    "                     [0,0,1,0,0,0,1],\n",
    "                     [0,0,0,1,0,0,0],\n",
    "                     [0,0,0,0,1,0,0],\n",
    "                     [0,0,0,0,0,1,0],\n",
    "                     [0,0,0,0,0,0,1]])  # 状态转移矩阵\n",
    "    kf.H = np.array([[1,0,0,0,0,0,0],\n",
    "                     [0,1,0,0,0,0,0],\n",
    "                     [0,0,1,0,0,0,0],\n",
    "                     [0,0,0,1,0,0,0]])  # 观测矩阵\n",
    "    return kf\n",
    "\n",
    "# 初始化卡尔曼滤波器\n",
    "kf = initialize_kalman_filter()\n",
    "\n",
    "def track_objects(detection):\n",
    "    z = np.array([detection[0], detection[1], detection[2], detection[3]])  # 观测变量\n",
    "    kf.predict()  # 预测下一步\n",
    "    kf.update(z)  # 更新滤波\n",
    "    return kf.x[:4]  # 返回更新后的位置信息\n",
    "\"\"\"\n",
    "# 追踪所有目标对象\n",
    "tracked_positions = []\n",
    "for det_list in all_detections.values():\n",
    "    tracked_position = [track_objects(d) for d in det_list]\n",
    "    tracked_positions.append(tracked_position)\n",
    "    \n",
    "tracked_positions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 将视频帧或图像序列转换为LSTM模型的输入格式\n",
    "** 每一个时间点的数据都包括前n个时间步长的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 计算欧几里得距离\n",
    "def calculate_distance(box1, box2):\n",
    "    x1_center = (box1[0] + box1[2]) / 2\n",
    "    y1_center = (box1[1] + box1[3]) / 2\n",
    "    x2_center = (box2[0] + box2[2]) / 2\n",
    "    y2_center = (box2[1] + box2[3]) / 2\n",
    "    return np.sqrt((x1_center - x2_center)**2 + (y1_center - y2_center)**2)\n",
    "\n",
    "# 计算检测框的面积\n",
    "def calculate_area(box):\n",
    "    return (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "# 计算两个检测框之间的速度和角度\n",
    "def calculate_velocity_and_angle(previous_box, current_box, time_interval):\n",
    "    # 计算中心点\n",
    "    previous_center = [(previous_box[0] + previous_box[2]) / 2, (previous_box[1] + previous_box[3]) / 2]\n",
    "    current_center = [(current_box[0] + current_box[2]) / 2, (current_box[1] + current_box[3]) / 2]\n",
    "    \n",
    "    # 计算距离\n",
    "    distance = np.sqrt((current_center[0] - previous_center[0])**2 + (current_center[1] - previous_center[1])**2)\n",
    "    \n",
    "    # 计算速度\n",
    "    velocity = distance / time_interval\n",
    "    \n",
    "    # 计算角度(弧度), 表示检测框的运动方向\n",
    "    direction = np.arctan2(current_center[1] - previous_center[1], current_center[0] - previous_center[0])\n",
    "    \n",
    "    return velocity, direction\n",
    "\n",
    "                        \n",
    "def prepare_complex_sequence_data(detected_objects_list, sequence_length=3, time_interval=1.0):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # TODO: 目前是追踪54个样本的轨迹, 计算同一帧的两个目标的关联关系?\n",
    "    for key in detected_objects_list:\n",
    "        card_detections = detected_objects_list[key]\n",
    "        print(f\"Key: {key}, vector len: {len(card_detections)}, Card Detections: {card_detections}\")\n",
    "        for i in range(len(card_detections) - sequence_length):\n",
    "            input_seq = []\n",
    "            for j in range(sequence_length):\n",
    "                card_boxes = card_detections[i + j] \n",
    "                # 距離、面積、速度和置信度特徵\n",
    "                if card_boxes:\n",
    "                    cx = (card_boxes[0] + card_boxes[2]) / 2\n",
    "                    cy = (card_boxes[1] + card_boxes[3]) / 2\n",
    "                \n",
    "                    card_area = calculate_area(card_boxes)\n",
    "                    card_conf = card_boxes[4]  # 假设置信度在检测框的第五个元素\n",
    "                    \n",
    "                    if i > 0:  # 速度計算需要前一個時間點的數據\n",
    "                        prev_card_box = card_detections[i + j - 1]\n",
    "                        card_velocity, direction = calculate_velocity_and_angle(prev_card_box, card_boxes, time_interval)\n",
    "                    else:\n",
    "                        card_velocity = 0\n",
    "                        direction = 0\n",
    "                    \n",
    "                    # 特征序列\n",
    "                    input_seq.append([cx, cy, card_velocity, direction, card_conf])\n",
    "                else:\n",
    "                    input_seq.append([0, 0, 0, 0, 0])\n",
    "            \n",
    "            # X 作为LSTM 的输入向量\n",
    "            #seq = np.array(input_seq).flatten()\n",
    "            X.append(input_seq)\n",
    "            # y 作为LSTM 目标值, 构建 y 的 7 个特征, 下一frame的真实位置作为训练时的目标值\n",
    "            next_card_boxes = card_detections[i + sequence_length]\n",
    "            if next_card_boxes:\n",
    "                next_card_area = calculate_area(next_card_boxes)\n",
    "                cx = (next_card_boxes[0] + next_card_boxes[2]) / 2\n",
    "                cy = (next_card_boxes[1] + next_card_boxes[3]) / 2\n",
    "                next_card_conf = next_card_boxes[4]\n",
    "                if i + sequence_length > 0:\n",
    "                    prev_next_card_box = card_detections[i + sequence_length - 1]\n",
    "                    next_card_velocity, direction = calculate_velocity_and_angle(prev_next_card_box, next_card_boxes, time_interval)\n",
    "                else:\n",
    "                    next_card_velocity = 0\n",
    "                    direction = 0\n",
    "                y.append([cx, cy, next_card_velocity, direction, next_card_conf])\n",
    "            else:\n",
    "                y.append([0, 0, 0, 0, 0])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, frame_index):\n",
    "    res = detect_objects(frame)\n",
    "    height, width = frame.shape[:2]\n",
    "    if width == 0 or height == 0:\n",
    "        return frame_index, {}  # 返回空结果，避免除以零\n",
    "\n",
    "    return frame_index, res\n",
    "\n",
    "def load_video_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_detections = {\n",
    "        'Tc': [], 'Td': [], 'Th': [], 'Ts': [],\n",
    "        '2c': [], '2d': [], '2h': [], '2s': [],\n",
    "        '3c': [], '3d': [], '3h': [], '3s': [],\n",
    "        '4c': [], '4d': [], '4h': [], '4s': [],\n",
    "        '5c': [], '5d': [], '5h': [], '5s': [],\n",
    "        '6c': [], '6d': [], '6h': [], '6s': [],\n",
    "        '7c': [], '7d': [], '7h': [], '7s': [],\n",
    "        '8c': [], '8d': [], '8h': [], '8s': [],\n",
    "        '9c': [], '9d': [], '9h': [], '9s': [],\n",
    "        'Ac': [], 'Ad': [], 'Ah': [], 'As': [],\n",
    "        'Jc': [], 'Jd': [], 'Jh': [], 'Js': [],\n",
    "        'Kc': [], 'Kd': [], 'Kh': [], 'Ks': [],\n",
    "        'Qc': [], 'Qd': [], 'Qh': [], 'Qs': [],\n",
    "        'SJoker': [], 'BJoker': []\n",
    "    }\n",
    "    frames = []\n",
    "    frame_index = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append((frame_index, frame))\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    results = [None] * len(frames)  # 用于存储结果的列表，保持顺序\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future_to_frame = {executor.submit(process_frame, frame, idx): idx for idx, frame in frames}\n",
    "        for future in as_completed(future_to_frame):\n",
    "            idx, res = future.result()\n",
    "            results[idx] = res  # 按照索引存储结果\n",
    "\n",
    "    #FIXME: 合并结果前过滤掉异常值的结果\n",
    "    for idx, res in enumerate(results):\n",
    "        logging.info(f'#: {idx}, result: {res}')\n",
    "        for key in res.keys():\n",
    "            all_detections[key].extend(res[key])\n",
    "    return all_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用 Keras库來构建LSTM 模型与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# Custom Attention Layer\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = tf.nn.tanh(tf.matmul(x, self.W) + self.b)  # Energy\n",
    "        a = tf.nn.softmax(e, axis=1)  # Attention weights\n",
    "        output = tf.reduce_sum(x * a, axis=1)  # Weighted sum of input features\n",
    "        return output\n",
    "\n",
    "# 构建一个更复杂的双向LSTM模型，同时引入注意力机制, 使用检测到的数据进行训练。模型包括多层LSTM、Dropout、BatchNormalization等层\n",
    "# input_shape=(time_steps, num_features)\n",
    "def create_bilstm_attention_model(input_shape, dropout_rate=0.3):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    masked_inputs = Masking(mask_value=0.0)(inputs)  # Add a Masking layer\n",
    "    lstm_out = Bidirectional(LSTM(256, return_sequences=True))(masked_inputs)\n",
    "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "\n",
    "    lstm_out = Bidirectional(LSTM(128, return_sequences=True))(lstm_out)\n",
    "    # 添加 Dropout 和 BatchNormalization 层\n",
    "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "\n",
    "    lstm_out = Bidirectional(LSTM(64, return_sequences=True))(lstm_out)\n",
    "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "    \n",
    "    # 添加 GRU 层，units=64\n",
    "    gru_out = GRU(units=64, return_sequences=True)(lstm_out)\n",
    "    gru_out = Dropout(dropout_rate)(gru_out)\n",
    "    gru_out = BatchNormalization()(gru_out)\n",
    "\n",
    "    # Correct usage of Attention layer\n",
    "    attention = Attention()(gru_out)\n",
    "\n",
    "    # 全连接层，将 LSTM 的输出映射到32个神经元，并应用 ReLU 激活函数来引入非线性\n",
    "    dense_out = Dense(32, activation='relu')(attention)\n",
    "    \n",
    "    feature_len = input_shape[1]\n",
    "    # RepeatVector 和 TimeDistributed 层\n",
    "    # \"one-to-many\" 的序列预测。RepeatVector 层将输入重复 5 次，TimeDistributed 层将 Dense 层的计算分布到每个时间步上。\n",
    "    # 最终输出的形状将是 (batch_size, 5, feature_len)\n",
    "    #repeat_out = RepeatVector(5)(dense_out)\n",
    "    #outputs = TimeDistributed(Dense(units=feature_len, activation='relu'))(repeat_out)\n",
    "    \n",
    "    outputs = Dense(feature_len)(dense_out)  # The final Dense layer outputs 5 values 最后的全连接层，输出5个值\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # 使用Adam优化器(梯度下降优化)和均方误差（MSE）作为损失函数，衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    # 显示模型摘要\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # 均方根误差（RMSE）是一种用于衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好。 \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    # 平均绝对误差（MAE）\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # R^2 分数\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, mse, mae, r2\n",
    "\n",
    "def evaluate_inverse_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 反归一化预测结果和真实值\n",
    "    y_pred_inverse = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_inverse = scaler_y.inverse_transform(y_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "    # 均方根误差（RMSE）是一种用于衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好。 \n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inverse, y_pred_inverse))\n",
    "    # 平均绝对误差（MAE）\n",
    "    mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "    # R^2 分数\n",
    "    r2 = r2_score(y_test_inverse, y_pred_inverse)\n",
    "    \n",
    "    return rmse, mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting coremltools==7.2\n",
      "  Using cached coremltools-7.2-cp310-none-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools==7.2) (1.26.4)\n",
      "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools==7.2) (3.20.3)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools==7.2) (1.13.2)\n",
      "Requirement already satisfied: tqdm in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools==7.2) (4.66.5)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools==7.2) (24.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools==7.2) (24.2.0)\n",
      "Collecting cattrs (from coremltools==7.2)\n",
      "  Using cached cattrs-24.1.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyaml (from coremltools==7.2)\n",
      "  Using cached pyaml-24.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from cattrs->coremltools==7.2) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from cattrs->coremltools==7.2) (4.12.2)\n",
      "Requirement already satisfied: PyYAML in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pyaml->coremltools==7.2) (6.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from sympy->coremltools==7.2) (1.3.0)\n",
      "Using cached coremltools-7.2-cp310-none-macosx_11_0_arm64.whl (2.3 MB)\n",
      "Using cached cattrs-24.1.0-py3-none-any.whl (66 kB)\n",
      "Using cached pyaml-24.7.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pyaml, cattrs, coremltools\n",
      "Successfully installed cattrs-24.1.0 coremltools-7.2 pyaml-24.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# coremltools 7 以上版本不需要安装 onnx-coreml\n",
    "%pip install coremltools==7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coremltools in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (7.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (1.26.4)\n",
      "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (3.20.3)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (1.13.2)\n",
      "Requirement already satisfied: tqdm in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (4.66.5)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (24.1)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (24.2.0)\n",
      "Requirement already satisfied: cattrs in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (24.1.0)\n",
      "Requirement already satisfied: pyaml in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (24.7.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from cattrs->coremltools) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from cattrs->coremltools) (4.12.2)\n",
      "Requirement already satisfied: PyYAML in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pyaml->coremltools) (6.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from sympy->coremltools) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U coremltools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 将数据集拆分为训练集和测试集，训练LSTM模型并选择最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = 'videos/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = 'videos/debug/quick'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频文件路径列表: ['videos/debug/quick/IMG_0036.MOV']\n",
      "\n",
      "0: 640x640 (no detections), 32.0ms\n",
      "Speed: 4.1ms preprocess, 32.0ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 38.9ms\n",
      "Speed: 2.1ms preprocess, 38.9ms inference, 34.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.3ms\n",
      "Speed: 10.6ms preprocess, 20.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.6ms\n",
      "Speed: 1.4ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.3ms\n",
      "Speed: 5.6ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 24.7ms\n",
      "Speed: 22.8ms preprocess, 24.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 14.5ms\n",
      "Speed: 1.5ms preprocess, 14.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.3ms\n",
      "Speed: 3.5ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.4ms\n",
      "Speed: 1.5ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 43.6ms\n",
      "Speed: 25.9ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 9.7ms\n",
      "Speed: 3.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 13.2ms\n",
      "Speed: 11.6ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 As, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 As, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 9s, 54.2ms\n",
      "Speed: 2.3ms preprocess, 54.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.0ms\n",
      "Speed: 7.8ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 10.0ms\n",
      "Speed: 3.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 9.7ms\n",
      "Speed: 3.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 24.8ms\n",
      "Speed: 3.3ms preprocess, 24.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 58.7ms\n",
      "Speed: 2.6ms preprocess, 58.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 13.0ms\n",
      "Speed: 3.4ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 11.1ms\n",
      "Speed: 14.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 29.7ms\n",
      "Speed: 3.6ms preprocess, 29.7ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 4d, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Ad, 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 35.4ms\n",
      "Speed: 3.7ms preprocess, 35.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 21.9ms\n",
      "Speed: 20.9ms preprocess, 21.9ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 13.8ms\n",
      "Speed: 5.3ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 36.2ms\n",
      "Speed: 3.7ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 12.4ms\n",
      "Speed: 4.5ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 12.3ms\n",
      "Speed: 5.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 11.3ms\n",
      "Speed: 4.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 10.2ms\n",
      "Speed: 5.8ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9s, 1 As, 13.3ms\n",
      "Speed: 3.5ms preprocess, 13.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 10.3ms\n",
      "Speed: 10.7ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 12.2ms\n",
      "Speed: 4.8ms preprocess, 12.2ms inference, 23.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 20.1ms\n",
      "Speed: 3.1ms preprocess, 20.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 20.0ms\n",
      "Speed: 2.7ms preprocess, 20.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 13.3ms\n",
      "Speed: 7.5ms preprocess, 13.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 14.0ms\n",
      "Speed: 3.1ms preprocess, 14.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 13.0ms\n",
      "Speed: 5.2ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 36.3ms\n",
      "Speed: 5.3ms preprocess, 36.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 13.5ms\n",
      "Speed: 7.7ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 34.8ms\n",
      "Speed: 4.6ms preprocess, 34.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 24.0ms\n",
      "Speed: 16.1ms preprocess, 24.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 12.7ms\n",
      "Speed: 4.9ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 12.3ms\n",
      "Speed: 3.8ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 10.6ms\n",
      "Speed: 3.9ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 33.5ms\n",
      "Speed: 2.7ms preprocess, 33.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 12.7ms\n",
      "Speed: 3.1ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 8d, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5d, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 47.1ms\n",
      "Speed: 9.6ms preprocess, 47.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 10.2ms\n",
      "Speed: 4.2ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 5d, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 5d, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8d, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.7ms\n",
      "Speed: 1.7ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8s, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 34.4ms\n",
      "Speed: 94.2ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.1ms\n",
      "Speed: 4.0ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 15.7ms\n",
      "Speed: 3.0ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 12.4ms\n",
      "Speed: 5.1ms preprocess, 12.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.8ms\n",
      "Speed: 3.7ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 11.2ms\n",
      "Speed: 4.7ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 32.7ms\n",
      "Speed: 7.1ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 11.3ms\n",
      "Speed: 4.6ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.1ms\n",
      "Speed: 3.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.9ms\n",
      "Speed: 4.1ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 18.9ms\n",
      "Speed: 2.9ms preprocess, 18.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 12.7ms\n",
      "Speed: 4.7ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 13.8ms\n",
      "Speed: 2.5ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.8ms\n",
      "Speed: 3.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 13.0ms\n",
      "Speed: 4.7ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.9ms\n",
      "Speed: 6.6ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 10.1ms\n",
      "Speed: 4.0ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.8ms\n",
      "Speed: 3.5ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 79.7ms\n",
      "Speed: 14.2ms preprocess, 79.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 12.5ms\n",
      "Speed: 4.8ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 17.8ms\n",
      "Speed: 2.8ms preprocess, 17.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.2ms\n",
      "Speed: 12.9ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.9ms\n",
      "Speed: 4.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 17.3ms\n",
      "Speed: 4.2ms preprocess, 17.3ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 14.2ms\n",
      "Speed: 4.7ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.5ms\n",
      "Speed: 5.4ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 14.3ms\n",
      "Speed: 12.8ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.6ms\n",
      "Speed: 5.1ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.6ms\n",
      "Speed: 3.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 5.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 15.1ms\n",
      "Speed: 39.9ms preprocess, 15.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 14.0ms\n",
      "Speed: 8.0ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 14.6ms\n",
      "Speed: 21.2ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 13.6ms\n",
      "Speed: 3.8ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 14.8ms\n",
      "Speed: 5.9ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.4ms\n",
      "Speed: 6.2ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.9ms\n",
      "Speed: 5.4ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.5ms\n",
      "Speed: 8.4ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 31.1ms\n",
      "Speed: 2.7ms preprocess, 31.1ms inference, 27.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 17.9ms\n",
      "Speed: 2.8ms preprocess, 17.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.5ms\n",
      "Speed: 11.6ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.4ms\n",
      "Speed: 9.3ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.9ms\n",
      "Speed: 3.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.0ms\n",
      "Speed: 3.5ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.6ms\n",
      "Speed: 4.2ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.8ms\n",
      "Speed: 43.4ms preprocess, 24.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 4.6ms preprocess, 12.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 3.2ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 13.5ms preprocess, 13.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 51.7ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 15.7ms preprocess, 11.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 3.5ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.6ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.0ms\n",
      "Speed: 3.7ms preprocess, 18.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.9ms\n",
      "Speed: 2.9ms preprocess, 18.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.8ms preprocess, 14.1ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 5.6ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 12.5ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.9ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.8ms\n",
      "Speed: 2.5ms preprocess, 17.8ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.9ms\n",
      "Speed: 3.0ms preprocess, 19.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.7ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 12.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 5.7ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 4.9ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 8.1ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 9.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 35.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.3ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 6.5ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 5.9ms preprocess, 11.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 6.4ms preprocess, 10.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 39.6ms\n",
      "Speed: 22.0ms preprocess, 39.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 6.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 20.2ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.0ms\n",
      "Speed: 2.5ms preprocess, 21.0ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 8.5ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 3.1ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 8.7ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 9.2ms preprocess, 14.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.8ms preprocess, 14.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 16.3ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 3.8ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 8.5ms preprocess, 11.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.9ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 15.4ms preprocess, 12.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.9ms\n",
      "Speed: 2.8ms preprocess, 18.9ms inference, 38.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.9ms\n",
      "Speed: 2.6ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 7.6ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 10.0ms preprocess, 11.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Key: Tc, vector len: 12, Card Detections: [[100, 1116, 157, 1242, 0.64794921875], [100, 1115, 157, 1240, 0.64892578125], [101, 1115, 157, 1241, 0.6484375], [101, 1115, 157, 1241, 0.6484375], [102, 1113, 157, 1241, 0.646484375], [102, 1114, 157, 1242, 0.6455078125], [102, 1114, 157, 1242, 0.6416015625], [102, 1114, 157, 1242, 0.6376953125], [102, 1114, 157, 1241, 0.640625], [103, 1114, 157, 1242, 0.6416015625], [103, 1114, 157, 1241, 0.6396484375], [104, 1114, 159, 1242, 0.6435546875]]\n",
      "Key: Td, vector len: 13, Card Detections: [[97, 1119, 161, 1248, 0.658203125], [100, 1119, 159, 1241, 0.66650390625], [100, 1119, 159, 1241, 0.6650390625], [100, 1119, 159, 1241, 0.66455078125], [101, 1119, 159, 1241, 0.66259765625], [101, 1119, 159, 1241, 0.66015625], [101, 1119, 159, 1240, 0.6611328125], [101, 1119, 159, 1240, 0.662109375], [101, 1119, 159, 1241, 0.65966796875], [101, 1119, 159, 1241, 0.65966796875], [102, 1119, 159, 1241, 0.6591796875], [102, 1119, 159, 1241, 0.6591796875], [102, 1120, 160, 1242, 0.65576171875]]\n",
      "Key: Th, vector len: 19, Card Detections: [[476, 1106, 534, 1226, 0.60302734375], [475, 1106, 534, 1217, 0.61669921875], [477, 1107, 532, 1216, 0.6298828125], [477, 1107, 532, 1216, 0.6328125], [477, 1107, 532, 1215, 0.634765625], [477, 1107, 531, 1215, 0.63427734375], [477, 1108, 531, 1216, 0.63134765625], [477, 1108, 532, 1216, 0.63134765625], [477, 1108, 532, 1216, 0.63232421875], [477, 1107, 532, 1217, 0.6318359375], [477, 1107, 532, 1217, 0.6318359375], [477, 1107, 532, 1217, 0.630859375], [477, 1107, 532, 1217, 0.630859375], [477, 1107, 532, 1217, 0.63037109375], [477, 1108, 532, 1218, 0.62939453125], [477, 1108, 532, 1218, 0.62890625], [477, 1110, 531, 1218, 0.62890625], [477, 1110, 530, 1218, 0.62548828125], [475, 1112, 531, 1221, 0.6142578125]]\n",
      "Key: Ts, vector len: 9, Card Detections: [[96, 1054, 158, 1193, 0.56787109375], [96, 1056, 157, 1187, 0.61669921875], [96, 1055, 156, 1187, 0.6181640625], [96, 1055, 157, 1187, 0.6201171875], [96, 1054, 157, 1187, 0.62158203125], [96, 1055, 156, 1187, 0.6181640625], [96, 1055, 156, 1187, 0.615234375], [96, 1056, 156, 1188, 0.615234375], [97, 1057, 157, 1189, 0.60986328125]]\n",
      "Key: 2c, vector len: 12, Card Detections: [[99, 1101, 161, 1229, 0.646484375], [100, 1102, 162, 1230, 0.65185546875], [101, 1101, 162, 1230, 0.63623046875], [101, 1101, 162, 1230, 0.642578125], [102, 1100, 163, 1227, 0.6396484375], [102, 1100, 162, 1228, 0.64501953125], [102, 1100, 163, 1228, 0.64453125], [102, 1100, 163, 1227, 0.64599609375], [102, 1100, 164, 1228, 0.6474609375], [102, 1101, 163, 1228, 0.64306640625], [102, 1100, 163, 1228, 0.6435546875], [103, 1102, 164, 1228, 0.64111328125]]\n",
      "Key: 2d, vector len: 9, Card Detections: [[102, 1089, 164, 1223, 0.630859375], [103, 1090, 163, 1221, 0.63720703125], [104, 1089, 163, 1220, 0.62890625], [105, 1089, 162, 1220, 0.6328125], [105, 1090, 162, 1219, 0.62744140625], [106, 1090, 162, 1219, 0.6171875], [106, 1090, 162, 1219, 0.634765625], [106, 1090, 162, 1220, 0.62548828125], [106, 1091, 163, 1220, 0.62255859375]]\n",
      "Key: 2h, vector len: 7, Card Detections: [[87, 1056, 144, 1186, 0.615234375], [86, 1056, 144, 1186, 0.61376953125], [87, 1055, 144, 1187, 0.61328125], [87, 1055, 143, 1187, 0.61767578125], [87, 1054, 144, 1186, 0.6171875], [87, 1057, 143, 1188, 0.61767578125], [89, 1056, 146, 1190, 0.57470703125]]\n",
      "Key: 2s, vector len: 24, Card Detections: [[102, 1127, 162, 1249, 0.68408203125], [103, 1126, 162, 1248, 0.68359375], [102, 1126, 162, 1249, 0.68115234375], [102, 1126, 162, 1248, 0.6787109375], [101, 1125, 163, 1248, 0.67724609375], [101, 1125, 164, 1249, 0.6640625], [101, 1125, 164, 1249, 0.66845703125], [101, 1125, 163, 1249, 0.67626953125], [101, 1125, 163, 1249, 0.67578125], [101, 1125, 162, 1248, 0.6640625], [101, 1125, 162, 1248, 0.66552734375], [101, 1125, 162, 1248, 0.66064453125], [101, 1125, 162, 1248, 0.65869140625], [101, 1125, 162, 1248, 0.66162109375], [101, 1126, 162, 1248, 0.66162109375], [101, 1125, 162, 1248, 0.66455078125], [101, 1126, 162, 1248, 0.66259765625], [101, 1126, 162, 1248, 0.666015625], [101, 1126, 162, 1248, 0.66357421875], [101, 1125, 162, 1248, 0.6630859375], [101, 1125, 162, 1248, 0.6650390625], [101, 1125, 162, 1248, 0.6611328125], [101, 1125, 162, 1247, 0.6572265625], [100, 1126, 163, 1247, 0.64306640625]]\n",
      "Key: 3c, vector len: 24, Card Detections: [[79, 1054, 141, 1191, 0.6416015625], [81, 1055, 141, 1191, 0.61962890625], [80, 1056, 140, 1191, 0.61572265625], [81, 1056, 140, 1191, 0.61083984375], [81, 1056, 141, 1191, 0.61279296875], [81, 1057, 141, 1192, 0.6142578125], [81, 1059, 141, 1194, 0.61572265625], [82, 1060, 140, 1194, 0.62255859375], [81, 1060, 141, 1194, 0.6162109375], [82, 1060, 140, 1195, 0.61865234375], [81, 1060, 141, 1195, 0.619140625], [81, 1060, 141, 1195, 0.6240234375], [81, 1061, 141, 1195, 0.62646484375], [79, 1060, 142, 1195, 0.634765625], [79, 1060, 142, 1195, 0.625], [79, 1060, 143, 1195, 0.6279296875], [79, 1060, 143, 1194, 0.62548828125], [79, 1060, 143, 1194, 0.625], [79, 1060, 142, 1194, 0.62109375], [79, 1060, 142, 1194, 0.62548828125], [79, 1060, 143, 1194, 0.63037109375], [80, 1060, 143, 1194, 0.62646484375], [80, 1061, 143, 1194, 0.626953125], [80, 1063, 145, 1195, 0.65576171875]]\n",
      "Key: 3d, vector len: 15, Card Detections: [[81, 1050, 143, 1187, 0.6240234375], [81, 1050, 143, 1186, 0.61767578125], [81, 1051, 142, 1188, 0.619140625], [82, 1051, 142, 1188, 0.61279296875], [81, 1050, 143, 1187, 0.62060546875], [81, 1052, 142, 1188, 0.62060546875], [81, 1051, 142, 1188, 0.6220703125], [81, 1052, 142, 1188, 0.623046875], [81, 1052, 142, 1188, 0.62353515625], [81, 1053, 143, 1189, 0.62255859375], [81, 1053, 143, 1189, 0.6259765625], [82, 1054, 143, 1189, 0.623046875], [82, 1054, 143, 1190, 0.626953125], [83, 1055, 143, 1191, 0.6279296875], [83, 1056, 145, 1194, 0.63671875]]\n",
      "Key: 3h, vector len: 7, Card Detections: [[486, 1093, 542, 1213, 0.56005859375], [485, 1092, 542, 1212, 0.55908203125], [486, 1094, 541, 1213, 0.568359375], [485, 1093, 541, 1212, 0.568359375], [485, 1094, 540, 1213, 0.56982421875], [484, 1094, 541, 1212, 0.57373046875], [483, 1095, 540, 1214, 0.611328125]]\n",
      "Key: 3s, vector len: 18, Card Detections: [[478, 1114, 538, 1228, 0.59521484375], [478, 1114, 537, 1228, 0.59765625], [478, 1114, 537, 1228, 0.60986328125], [478, 1114, 536, 1228, 0.6064453125], [478, 1114, 537, 1228, 0.6142578125], [478, 1114, 536, 1229, 0.6142578125], [478, 1114, 536, 1229, 0.6201171875], [478, 1114, 536, 1229, 0.61962890625], [478, 1114, 536, 1229, 0.62451171875], [478, 1114, 537, 1229, 0.6240234375], [478, 1114, 537, 1229, 0.623046875], [478, 1114, 537, 1229, 0.62255859375], [478, 1114, 537, 1229, 0.6259765625], [478, 1114, 537, 1230, 0.625], [478, 1115, 537, 1230, 0.62548828125], [478, 1115, 537, 1230, 0.62158203125], [477, 1116, 536, 1231, 0.62353515625], [475, 1116, 536, 1231, 0.6240234375]]\n",
      "Key: 4c, vector len: 51, Card Detections: [[489, 1096, 609, 1226, 0.64599609375], [488, 1096, 609, 1224, 0.650390625], [488, 1096, 609, 1227, 0.65380859375], [489, 1096, 609, 1227, 0.65185546875], [489, 1097, 610, 1227, 0.65380859375], [489, 1097, 610, 1227, 0.6552734375], [489, 1097, 610, 1227, 0.65771484375], [489, 1097, 609, 1227, 0.65869140625], [489, 1097, 609, 1227, 0.65576171875], [489, 1098, 609, 1228, 0.65576171875], [489, 1097, 609, 1228, 0.65478515625], [489, 1098, 610, 1228, 0.65576171875], [488, 1098, 609, 1228, 0.65478515625], [488, 1098, 609, 1229, 0.654296875], [488, 1098, 609, 1229, 0.65625], [488, 1099, 609, 1230, 0.65576171875], [489, 1098, 609, 1230, 0.65966796875], [488, 1099, 609, 1230, 0.6572265625], [488, 1098, 609, 1230, 0.65478515625], [488, 1098, 609, 1230, 0.6572265625], [488, 1098, 609, 1230, 0.65673828125], [488, 1099, 609, 1231, 0.6591796875], [488, 1099, 609, 1231, 0.66064453125], [488, 1099, 609, 1231, 0.6611328125], [487, 1099, 609, 1231, 0.66064453125], [487, 1100, 609, 1231, 0.6611328125], [487, 1100, 609, 1231, 0.6611328125], [487, 1100, 609, 1232, 0.65673828125], [487, 1100, 609, 1232, 0.6591796875], [487, 1100, 609, 1232, 0.658203125], [487, 1100, 609, 1232, 0.65771484375], [487, 1100, 609, 1232, 0.6572265625], [487, 1101, 609, 1232, 0.6611328125], [487, 1102, 609, 1233, 0.66162109375], [487, 1102, 609, 1233, 0.6630859375], [487, 1101, 609, 1233, 0.66357421875], [487, 1102, 609, 1234, 0.66455078125], [487, 1102, 609, 1234, 0.66455078125], [486, 1103, 609, 1233, 0.66015625], [485, 1103, 609, 1234, 0.66162109375], [485, 1103, 609, 1235, 0.6611328125], [485, 1103, 609, 1235, 0.66259765625], [484, 1104, 610, 1235, 0.662109375], [484, 1104, 610, 1235, 0.66162109375], [484, 1104, 610, 1235, 0.66015625], [484, 1105, 609, 1235, 0.65966796875], [484, 1105, 610, 1235, 0.6572265625], [484, 1106, 609, 1235, 0.6552734375], [484, 1106, 609, 1235, 0.654296875], [483, 1107, 609, 1236, 0.6494140625], [480, 1110, 608, 1237, 0.64599609375]]\n",
      "Key: 4d, vector len: 10, Card Detections: [[102, 1074, 229, 1204, 0.603515625], [101, 1074, 229, 1204, 0.60595703125], [102, 1074, 229, 1204, 0.5986328125], [102, 1074, 229, 1205, 0.5966796875], [102, 1073, 230, 1204, 0.595703125], [102, 1073, 230, 1205, 0.595703125], [102, 1073, 230, 1204, 0.5986328125], [103, 1074, 230, 1204, 0.5966796875], [103, 1074, 230, 1205, 0.60009765625], [103, 1075, 230, 1205, 0.60107421875]]\n",
      "Key: 4h, vector len: 18, Card Detections: [[489, 1089, 605, 1215, 0.591796875], [491, 1090, 600, 1214, 0.626953125], [491, 1090, 600, 1213, 0.62646484375], [491, 1090, 600, 1213, 0.62646484375], [491, 1091, 600, 1213, 0.6279296875], [491, 1090, 600, 1214, 0.626953125], [491, 1091, 600, 1213, 0.6259765625], [491, 1090, 600, 1213, 0.626953125], [491, 1091, 600, 1214, 0.62890625], [491, 1091, 599, 1214, 0.62939453125], [491, 1091, 599, 1214, 0.6298828125], [490, 1091, 599, 1214, 0.62744140625], [490, 1092, 599, 1215, 0.630859375], [490, 1092, 599, 1215, 0.6318359375], [490, 1092, 598, 1215, 0.63330078125], [490, 1092, 598, 1215, 0.63330078125], [489, 1093, 598, 1215, 0.6318359375], [487, 1094, 597, 1216, 0.6201171875]]\n",
      "Key: 4s, vector len: 21, Card Detections: [[489, 1093, 583, 1209, 0.55322265625], [491, 1093, 599, 1222, 0.63623046875], [491, 1092, 598, 1214, 0.64501953125], [491, 1093, 600, 1219, 0.63671875], [491, 1093, 600, 1219, 0.63720703125], [491, 1093, 600, 1220, 0.63916015625], [491, 1093, 600, 1220, 0.6396484375], [491, 1093, 600, 1220, 0.63916015625], [491, 1093, 600, 1221, 0.6376953125], [491, 1093, 600, 1220, 0.63916015625], [491, 1095, 600, 1221, 0.6396484375], [491, 1095, 600, 1221, 0.6396484375], [491, 1095, 600, 1221, 0.638671875], [491, 1095, 599, 1222, 0.64208984375], [491, 1095, 599, 1221, 0.63818359375], [490, 1096, 599, 1222, 0.64013671875], [490, 1096, 599, 1222, 0.64111328125], [489, 1097, 599, 1222, 0.63916015625], [489, 1098, 599, 1224, 0.6396484375], [488, 1099, 598, 1225, 0.63916015625], [486, 1099, 598, 1226, 0.6318359375]]\n",
      "Key: 5c, vector len: 8, Card Detections: [[484, 1094, 544, 1213, 0.60205078125], [486, 1094, 543, 1215, 0.6279296875], [486, 1094, 543, 1215, 0.642578125], [486, 1096, 543, 1216, 0.64453125], [486, 1095, 542, 1216, 0.63525390625], [486, 1097, 542, 1216, 0.640625], [484, 1097, 542, 1217, 0.65087890625], [484, 1095, 543, 1216, 0.5166015625]]\n",
      "Key: 5d, vector len: 14, Card Detections: [[491, 1089, 548, 1217, 0.607421875], [493, 1089, 548, 1212, 0.6376953125], [495, 1089, 547, 1212, 0.6376953125], [495, 1090, 547, 1212, 0.6220703125], [495, 1090, 547, 1212, 0.607421875], [495, 1089, 547, 1211, 0.61669921875], [495, 1089, 547, 1211, 0.60888671875], [495, 1090, 546, 1212, 0.611328125], [495, 1089, 546, 1211, 0.607421875], [495, 1090, 546, 1212, 0.611328125], [494, 1090, 546, 1211, 0.60302734375], [494, 1090, 546, 1212, 0.60595703125], [493, 1091, 546, 1211, 0.64111328125], [491, 1092, 545, 1212, 0.65234375]]\n",
      "Key: 5h, vector len: 6, Card Detections: [[484, 1103, 540, 1218, 0.62890625], [483, 1101, 540, 1218, 0.63525390625], [484, 1102, 540, 1219, 0.63134765625], [484, 1102, 540, 1218, 0.634765625], [484, 1102, 540, 1218, 0.63525390625], [483, 1103, 539, 1218, 0.63134765625]]\n",
      "Key: 5s, vector len: 15, Card Detections: [[492, 1086, 546, 1209, 0.6435546875], [494, 1087, 546, 1210, 0.62548828125], [494, 1086, 546, 1208, 0.62646484375], [494, 1087, 546, 1210, 0.6259765625], [494, 1087, 546, 1210, 0.62353515625], [493, 1087, 547, 1210, 0.61962890625], [493, 1087, 546, 1210, 0.62060546875], [493, 1087, 546, 1210, 0.6181640625], [493, 1088, 546, 1210, 0.62060546875], [493, 1088, 546, 1210, 0.61962890625], [492, 1088, 545, 1211, 0.61474609375], [492, 1088, 545, 1211, 0.62109375], [491, 1090, 544, 1212, 0.61376953125], [491, 1090, 544, 1212, 0.61279296875], [489, 1091, 543, 1212, 0.63427734375]]\n",
      "Key: 6c, vector len: 23, Card Detections: [[493, 1090, 550, 1211, 0.67919921875], [495, 1090, 550, 1214, 0.69091796875], [495, 1089, 549, 1214, 0.681640625], [495, 1091, 549, 1214, 0.6826171875], [495, 1091, 549, 1214, 0.68505859375], [495, 1090, 549, 1214, 0.6875], [495, 1091, 549, 1214, 0.6865234375], [496, 1090, 549, 1214, 0.6865234375], [496, 1091, 549, 1214, 0.685546875], [496, 1091, 549, 1214, 0.68408203125], [494, 1091, 549, 1214, 0.68896484375], [494, 1092, 549, 1215, 0.68701171875], [494, 1092, 549, 1214, 0.69189453125], [493, 1092, 548, 1215, 0.68408203125], [493, 1092, 547, 1214, 0.677734375], [493, 1093, 547, 1215, 0.68017578125], [493, 1092, 547, 1215, 0.68408203125], [493, 1092, 546, 1215, 0.68359375], [493, 1093, 546, 1216, 0.685546875], [493, 1093, 546, 1216, 0.6845703125], [492, 1094, 545, 1216, 0.6806640625], [491, 1095, 545, 1216, 0.68017578125], [490, 1095, 544, 1217, 0.67236328125]]\n",
      "Key: 6d, vector len: 7, Card Detections: [[105, 1094, 162, 1224, 0.63916015625], [105, 1092, 162, 1223, 0.63818359375], [106, 1092, 163, 1223, 0.6416015625], [106, 1093, 163, 1222, 0.64794921875], [107, 1092, 163, 1222, 0.63818359375], [107, 1093, 164, 1222, 0.63623046875], [108, 1093, 165, 1224, 0.64013671875]]\n",
      "Key: 6h, vector len: 8, Card Detections: [[99, 1063, 158, 1202, 0.58154296875], [100, 1062, 158, 1192, 0.67626953125], [100, 1060, 158, 1190, 0.6796875], [100, 1061, 157, 1190, 0.67626953125], [101, 1060, 158, 1189, 0.6787109375], [101, 1060, 158, 1189, 0.6796875], [101, 1060, 158, 1189, 0.6806640625], [102, 1060, 158, 1189, 0.68115234375]]\n",
      "Key: 6s, vector len: 11, Card Detections: [[92, 1054, 152, 1186, 0.666015625], [93, 1054, 150, 1187, 0.712890625], [93, 1055, 150, 1187, 0.7099609375], [93, 1055, 150, 1187, 0.70703125], [93, 1054, 150, 1187, 0.70458984375], [93, 1055, 150, 1187, 0.708984375], [93, 1056, 149, 1188, 0.70849609375], [93, 1056, 149, 1188, 0.7099609375], [93, 1057, 149, 1189, 0.708984375], [93, 1058, 149, 1190, 0.71044921875], [91, 1057, 150, 1194, 0.6845703125]]\n",
      "Key: 7c, vector len: 67, Card Detections: [[66, 1058, 130, 1192, 0.6396484375], [67, 1060, 129, 1193, 0.66259765625], [67, 1062, 129, 1194, 0.66259765625], [66, 1063, 129, 1195, 0.658203125], [67, 1063, 130, 1195, 0.65966796875], [67, 1063, 130, 1195, 0.6630859375], [67, 1064, 130, 1196, 0.65966796875], [67, 1064, 130, 1196, 0.658203125], [67, 1064, 130, 1196, 0.66064453125], [67, 1064, 130, 1195, 0.66259765625], [67, 1064, 130, 1196, 0.65869140625], [67, 1064, 130, 1196, 0.65625], [67, 1064, 130, 1196, 0.6572265625], [67, 1065, 130, 1196, 0.64892578125], [68, 1065, 130, 1196, 0.64697265625], [68, 1066, 130, 1197, 0.6474609375], [68, 1066, 131, 1197, 0.6533203125], [68, 1066, 131, 1197, 0.6552734375], [68, 1066, 131, 1197, 0.6552734375], [68, 1066, 131, 1197, 0.650390625], [68, 1067, 131, 1197, 0.646484375], [69, 1067, 131, 1197, 0.6455078125], [69, 1067, 131, 1197, 0.6435546875], [69, 1067, 131, 1197, 0.642578125], [69, 1067, 131, 1197, 0.64697265625], [69, 1067, 131, 1197, 0.6455078125], [69, 1067, 131, 1196, 0.64453125], [70, 1068, 132, 1196, 0.64697265625], [70, 1068, 132, 1197, 0.64404296875], [70, 1068, 132, 1196, 0.65234375], [71, 1068, 132, 1195, 0.64990234375], [71, 1068, 132, 1195, 0.658203125], [71, 1067, 132, 1194, 0.66259765625], [71, 1067, 132, 1194, 0.658203125], [71, 1067, 132, 1194, 0.65771484375], [71, 1066, 132, 1195, 0.66015625], [71, 1067, 132, 1194, 0.65673828125], [71, 1066, 132, 1194, 0.6611328125], [71, 1066, 132, 1194, 0.66015625], [71, 1066, 132, 1193, 0.65966796875], [71, 1066, 132, 1193, 0.6591796875], [71, 1066, 132, 1193, 0.66015625], [71, 1066, 133, 1193, 0.6572265625], [72, 1066, 132, 1193, 0.66015625], [72, 1066, 132, 1193, 0.6630859375], [72, 1066, 133, 1193, 0.662109375], [72, 1066, 133, 1193, 0.66455078125], [72, 1066, 133, 1192, 0.66259765625], [72, 1066, 133, 1192, 0.66357421875], [72, 1066, 133, 1192, 0.66455078125], [72, 1066, 133, 1192, 0.6630859375], [72, 1066, 133, 1192, 0.66455078125], [72, 1066, 134, 1192, 0.66552734375], [73, 1066, 133, 1192, 0.66357421875], [73, 1065, 133, 1191, 0.6640625], [73, 1065, 134, 1191, 0.66357421875], [72, 1065, 134, 1192, 0.66015625], [73, 1066, 134, 1192, 0.6630859375], [73, 1066, 134, 1192, 0.6669921875], [73, 1066, 134, 1192, 0.66552734375], [73, 1066, 134, 1192, 0.66259765625], [74, 1066, 135, 1192, 0.66357421875], [73, 1066, 135, 1192, 0.6630859375], [74, 1066, 135, 1192, 0.6650390625], [74, 1066, 135, 1192, 0.66162109375], [74, 1066, 136, 1192, 0.66455078125], [78, 1066, 141, 1190, 0.6591796875]]\n",
      "Key: 7d, vector len: 9, Card Detections: [[102, 1105, 160, 1233, 0.64306640625], [102, 1105, 160, 1233, 0.6240234375], [103, 1103, 160, 1233, 0.6279296875], [103, 1104, 161, 1233, 0.6259765625], [103, 1104, 161, 1232, 0.63330078125], [104, 1104, 161, 1232, 0.6279296875], [104, 1104, 161, 1232, 0.6259765625], [105, 1104, 161, 1231, 0.62548828125], [105, 1105, 162, 1233, 0.61328125]]\n",
      "Key: 7h, vector len: 8, Card Detections: [[98, 1075, 162, 1215, 0.63134765625], [102, 1074, 159, 1208, 0.68310546875], [102, 1075, 159, 1207, 0.68017578125], [102, 1075, 159, 1207, 0.68115234375], [102, 1075, 159, 1207, 0.67529296875], [103, 1075, 159, 1207, 0.6787109375], [103, 1077, 159, 1208, 0.673828125], [104, 1077, 161, 1210, 0.68017578125]]\n",
      "Key: 7s, vector len: 10, Card Detections: [[80, 1058, 138, 1188, 0.61376953125], [81, 1058, 138, 1188, 0.6064453125], [82, 1057, 137, 1189, 0.59326171875], [83, 1058, 137, 1190, 0.59228515625], [83, 1059, 137, 1189, 0.599609375], [82, 1059, 137, 1189, 0.60595703125], [82, 1059, 137, 1190, 0.59814453125], [83, 1060, 138, 1191, 0.5966796875], [83, 1060, 138, 1192, 0.599609375], [83, 1060, 139, 1194, 0.60595703125]]\n",
      "Key: 8c, vector len: 49, Card Detections: [[463, 1181, 541, 1269, 0.54833984375], [464, 1161, 538, 1257, 0.59326171875], [468, 1146, 539, 1250, 0.58740234375], [472, 1137, 540, 1243, 0.5908203125], [475, 1131, 538, 1240, 0.59716796875], [477, 1125, 539, 1237, 0.619140625], [478, 1122, 539, 1233, 0.61279296875], [479, 1121, 540, 1232, 0.61669921875], [480, 1120, 541, 1231, 0.6181640625], [480, 1119, 541, 1230, 0.6279296875], [480, 1119, 540, 1231, 0.6279296875], [480, 1119, 540, 1231, 0.6279296875], [480, 1119, 540, 1230, 0.62548828125], [480, 1119, 540, 1230, 0.6240234375], [480, 1119, 539, 1230, 0.6240234375], [479, 1118, 539, 1230, 0.62451171875], [479, 1118, 538, 1230, 0.63037109375], [479, 1118, 538, 1229, 0.62890625], [479, 1118, 538, 1229, 0.6318359375], [479, 1118, 538, 1229, 0.6298828125], [479, 1118, 538, 1229, 0.63037109375], [479, 1118, 538, 1229, 0.62890625], [479, 1118, 538, 1229, 0.6279296875], [479, 1118, 538, 1229, 0.626953125], [479, 1118, 537, 1229, 0.626953125], [479, 1118, 537, 1229, 0.6259765625], [479, 1118, 537, 1229, 0.62353515625], [479, 1119, 537, 1229, 0.62353515625], [479, 1118, 537, 1229, 0.625], [479, 1118, 537, 1229, 0.6259765625], [479, 1118, 537, 1229, 0.6240234375], [479, 1118, 537, 1229, 0.62109375], [479, 1118, 537, 1229, 0.62744140625], [479, 1118, 537, 1229, 0.63037109375], [479, 1119, 537, 1229, 0.6328125], [479, 1119, 537, 1229, 0.63134765625], [479, 1119, 537, 1229, 0.630859375], [478, 1119, 538, 1229, 0.63037109375], [478, 1119, 538, 1230, 0.6337890625], [478, 1119, 538, 1230, 0.6318359375], [478, 1119, 537, 1230, 0.63037109375], [478, 1120, 537, 1230, 0.6298828125], [478, 1120, 537, 1230, 0.62646484375], [478, 1120, 537, 1230, 0.62890625], [478, 1120, 537, 1230, 0.6328125], [477, 1119, 536, 1230, 0.6376953125], [477, 1120, 536, 1230, 0.6337890625], [477, 1120, 535, 1231, 0.626953125], [474, 1117, 535, 1231, 0.64697265625]]\n",
      "Key: 8d, vector len: 13, Card Detections: [[492, 1093, 547, 1211, 0.66162109375], [492, 1094, 545, 1209, 0.6728515625], [493, 1094, 544, 1208, 0.6845703125], [492, 1093, 545, 1209, 0.68994140625], [493, 1093, 544, 1210, 0.69384765625], [493, 1093, 544, 1210, 0.6923828125], [493, 1094, 544, 1210, 0.6904296875], [493, 1093, 544, 1210, 0.69189453125], [492, 1095, 543, 1210, 0.6904296875], [492, 1094, 543, 1209, 0.689453125], [492, 1095, 543, 1211, 0.69140625], [490, 1095, 543, 1211, 0.6748046875], [493, 1092, 546, 1214, 0.59619140625]]\n",
      "Key: 8h, vector len: 9, Card Detections: [[479, 1111, 535, 1224, 0.64794921875], [481, 1112, 534, 1222, 0.66455078125], [480, 1112, 534, 1222, 0.6708984375], [481, 1113, 534, 1224, 0.6669921875], [481, 1113, 534, 1223, 0.6708984375], [481, 1113, 534, 1222, 0.66650390625], [480, 1113, 533, 1223, 0.6689453125], [480, 1113, 533, 1223, 0.68017578125], [478, 1113, 533, 1225, 0.662109375]]\n",
      "Key: 8s, vector len: 14, Card Detections: [[494, 1093, 547, 1213, 0.63720703125], [495, 1092, 547, 1212, 0.6376953125], [495, 1093, 547, 1213, 0.63623046875], [494, 1092, 547, 1212, 0.63671875], [494, 1092, 547, 1212, 0.64208984375], [493, 1093, 547, 1213, 0.64892578125], [494, 1092, 546, 1212, 0.6513671875], [494, 1095, 546, 1214, 0.6552734375], [493, 1093, 546, 1212, 0.650390625], [493, 1094, 546, 1213, 0.65869140625], [493, 1094, 545, 1213, 0.65673828125], [493, 1094, 545, 1213, 0.64990234375], [492, 1095, 545, 1214, 0.654296875], [490, 1096, 544, 1215, 0.63525390625]]\n",
      "Key: 9c, vector len: 8, Card Detections: [[101, 1073, 160, 1203, 0.646484375], [101, 1072, 159, 1202, 0.63818359375], [101, 1073, 159, 1203, 0.63671875], [102, 1072, 160, 1201, 0.64111328125], [103, 1072, 160, 1201, 0.63525390625], [102, 1072, 160, 1202, 0.64111328125], [103, 1072, 160, 1201, 0.6298828125], [104, 1074, 161, 1203, 0.62841796875]]\n",
      "Key: 9d, vector len: 8, Card Detections: [[97, 1066, 157, 1195, 0.65576171875], [99, 1066, 155, 1192, 0.65234375], [99, 1065, 155, 1193, 0.658203125], [99, 1066, 155, 1194, 0.658203125], [100, 1066, 155, 1194, 0.65283203125], [99, 1066, 155, 1194, 0.65869140625], [100, 1066, 155, 1194, 0.65673828125], [100, 1067, 155, 1193, 0.66162109375]]\n",
      "Key: 9h, vector len: 15, Card Detections: [[495, 1095, 547, 1210, 0.58251953125], [495, 1094, 547, 1209, 0.5908203125], [495, 1095, 547, 1209, 0.58935546875], [495, 1096, 546, 1210, 0.5986328125], [495, 1096, 547, 1210, 0.60009765625], [495, 1095, 547, 1211, 0.6015625], [495, 1095, 547, 1210, 0.60546875], [494, 1095, 546, 1211, 0.60791015625], [494, 1096, 546, 1211, 0.60498046875], [494, 1096, 546, 1210, 0.607421875], [494, 1096, 546, 1211, 0.611328125], [494, 1096, 546, 1211, 0.611328125], [493, 1096, 547, 1211, 0.611328125], [493, 1097, 546, 1212, 0.61083984375], [492, 1098, 545, 1212, 0.576171875]]\n",
      "Key: 9s, vector len: 14, Card Detections: [[479, 1112, 535, 1227, 0.61767578125], [481, 1113, 536, 1224, 0.63330078125], [481, 1112, 536, 1224, 0.6357421875], [481, 1112, 536, 1224, 0.6318359375], [481, 1112, 536, 1224, 0.6376953125], [482, 1111, 536, 1225, 0.64501953125], [482, 1112, 534, 1224, 0.63623046875], [482, 1112, 535, 1224, 0.6357421875], [482, 1113, 534, 1225, 0.6337890625], [481, 1113, 535, 1224, 0.63427734375], [481, 1113, 535, 1224, 0.63232421875], [480, 1114, 534, 1225, 0.62939453125], [480, 1116, 534, 1225, 0.61767578125], [99, 1070, 162, 1210, 0.5654296875]]\n",
      "Key: Ac, vector len: 10, Card Detections: [[481, 1116, 538, 1227, 0.51708984375], [481, 1116, 538, 1227, 0.5185546875], [481, 1116, 538, 1227, 0.56591796875], [481, 1116, 539, 1226, 0.54638671875], [481, 1116, 538, 1227, 0.5888671875], [481, 1116, 539, 1227, 0.58642578125], [481, 1116, 538, 1227, 0.57861328125], [481, 1116, 539, 1228, 0.5908203125], [481, 1116, 538, 1227, 0.6044921875], [480, 1117, 538, 1228, 0.501953125]]\n",
      "Key: Ad, vector len: 11, Card Detections: [[105, 1090, 164, 1225, 0.58056640625], [105, 1087, 159, 1217, 0.66259765625], [106, 1087, 159, 1217, 0.64599609375], [106, 1086, 159, 1215, 0.65283203125], [105, 1086, 159, 1215, 0.65576171875], [106, 1086, 159, 1215, 0.6533203125], [106, 1086, 159, 1216, 0.6494140625], [107, 1086, 159, 1216, 0.65234375], [106, 1085, 159, 1215, 0.650390625], [106, 1086, 159, 1215, 0.64599609375], [107, 1083, 161, 1216, 0.64404296875]]\n",
      "Key: Ah, vector len: 32, Card Detections: [[75, 1059, 135, 1188, 0.6484375], [76, 1059, 134, 1188, 0.64208984375], [76, 1059, 134, 1188, 0.63916015625], [76, 1060, 133, 1189, 0.63818359375], [76, 1060, 134, 1189, 0.63916015625], [75, 1060, 134, 1189, 0.6416015625], [76, 1060, 134, 1189, 0.6416015625], [77, 1060, 133, 1190, 0.6337890625], [77, 1060, 133, 1190, 0.6328125], [77, 1060, 133, 1190, 0.63037109375], [77, 1060, 133, 1189, 0.6298828125], [77, 1060, 132, 1189, 0.62939453125], [77, 1060, 132, 1189, 0.6279296875], [76, 1059, 133, 1188, 0.63037109375], [77, 1059, 133, 1188, 0.63134765625], [77, 1059, 133, 1188, 0.62744140625], [76, 1059, 133, 1189, 0.62939453125], [77, 1059, 132, 1189, 0.62939453125], [77, 1059, 132, 1189, 0.62890625], [76, 1059, 132, 1188, 0.6318359375], [76, 1059, 133, 1188, 0.6328125], [76, 1059, 133, 1189, 0.63330078125], [76, 1059, 133, 1189, 0.6328125], [75, 1059, 133, 1188, 0.6328125], [75, 1059, 133, 1188, 0.630859375], [75, 1059, 133, 1188, 0.6337890625], [75, 1059, 133, 1187, 0.630859375], [75, 1058, 133, 1186, 0.62939453125], [75, 1058, 133, 1186, 0.6318359375], [75, 1058, 133, 1186, 0.63134765625], [75, 1060, 133, 1186, 0.6318359375], [75, 1054, 135, 1188, 0.60400390625]]\n",
      "Key: As, vector len: 11, Card Detections: [[481, 1117, 538, 1227, 0.58642578125], [481, 1116, 539, 1228, 0.51220703125], [490, 1093, 546, 1213, 0.60009765625], [491, 1093, 545, 1214, 0.5859375], [491, 1093, 545, 1213, 0.5966796875], [491, 1094, 545, 1214, 0.591796875], [491, 1094, 545, 1213, 0.59765625], [491, 1094, 544, 1213, 0.60009765625], [491, 1095, 544, 1213, 0.6005859375], [491, 1096, 544, 1213, 0.603515625], [488, 1098, 543, 1214, 0.62841796875]]\n",
      "Key: Jc, vector len: 28, Card Detections: [[72, 1054, 133, 1186, 0.66748046875], [72, 1056, 132, 1188, 0.6796875], [72, 1056, 132, 1188, 0.681640625], [72, 1058, 131, 1190, 0.67333984375], [72, 1058, 132, 1189, 0.67236328125], [72, 1060, 131, 1189, 0.6689453125], [72, 1061, 132, 1192, 0.67529296875], [72, 1062, 131, 1193, 0.67578125], [72, 1062, 131, 1192, 0.67724609375], [72, 1063, 130, 1193, 0.67529296875], [72, 1063, 131, 1193, 0.6796875], [72, 1063, 131, 1193, 0.677734375], [72, 1064, 130, 1193, 0.68115234375], [72, 1064, 130, 1194, 0.68017578125], [72, 1064, 130, 1194, 0.6806640625], [72, 1064, 130, 1194, 0.68310546875], [72, 1064, 130, 1194, 0.68017578125], [72, 1064, 130, 1194, 0.68017578125], [72, 1064, 130, 1194, 0.6806640625], [72, 1064, 131, 1194, 0.68310546875], [72, 1065, 130, 1194, 0.68212890625], [72, 1065, 131, 1195, 0.68212890625], [72, 1065, 131, 1194, 0.68115234375], [72, 1066, 131, 1194, 0.6787109375], [72, 1066, 131, 1194, 0.6787109375], [72, 1066, 131, 1194, 0.6787109375], [73, 1068, 132, 1194, 0.6728515625], [72, 1063, 134, 1198, 0.67138671875]]\n",
      "Key: Jd, vector len: 8, Card Detections: [[483, 1107, 534, 1221, 0.6337890625], [484, 1108, 533, 1218, 0.63818359375], [484, 1108, 533, 1218, 0.64013671875], [484, 1107, 533, 1218, 0.638671875], [484, 1107, 533, 1218, 0.6181640625], [484, 1107, 533, 1218, 0.607421875], [484, 1108, 533, 1221, 0.60205078125], [484, 1108, 532, 1219, 0.587890625]]\n",
      "Key: Jh, vector len: 9, Card Detections: [[486, 1099, 538, 1216, 0.62939453125], [486, 1098, 538, 1214, 0.63330078125], [486, 1099, 537, 1214, 0.62548828125], [486, 1099, 537, 1213, 0.6318359375], [486, 1098, 538, 1214, 0.626953125], [486, 1099, 537, 1215, 0.62353515625], [486, 1099, 537, 1214, 0.6279296875], [486, 1101, 536, 1215, 0.62353515625], [485, 1102, 535, 1215, 0.62451171875]]\n",
      "Key: Js, vector len: 14, Card Detections: [[492, 1091, 545, 1211, 0.673828125], [492, 1091, 547, 1212, 0.6806640625], [493, 1092, 546, 1210, 0.67919921875], [493, 1092, 546, 1212, 0.6796875], [493, 1092, 546, 1212, 0.6787109375], [492, 1092, 545, 1212, 0.6806640625], [492, 1093, 545, 1213, 0.6787109375], [492, 1092, 545, 1212, 0.677734375], [492, 1093, 544, 1213, 0.67333984375], [492, 1093, 544, 1213, 0.67236328125], [491, 1093, 543, 1214, 0.67138671875], [491, 1094, 543, 1214, 0.666015625], [490, 1096, 544, 1215, 0.66015625], [488, 1097, 542, 1215, 0.6630859375]]\n",
      "Key: Kc, vector len: 43, Card Detections: [[84, 1170, 147, 1275, 0.6826171875], [87, 1158, 151, 1270, 0.5732421875], [91, 1149, 152, 1264, 0.69091796875], [94, 1141, 155, 1261, 0.67041015625], [95, 1139, 155, 1258, 0.66943359375], [96, 1137, 155, 1256, 0.669921875], [95, 1134, 155, 1254, 0.67626953125], [96, 1134, 155, 1255, 0.67919921875], [97, 1134, 156, 1254, 0.68408203125], [97, 1134, 156, 1253, 0.6865234375], [98, 1133, 157, 1253, 0.689453125], [98, 1133, 156, 1252, 0.693359375], [98, 1132, 156, 1252, 0.69140625], [99, 1132, 158, 1252, 0.68994140625], [99, 1132, 159, 1252, 0.685546875], [100, 1131, 160, 1251, 0.68310546875], [101, 1131, 161, 1252, 0.68603515625], [102, 1130, 162, 1251, 0.68896484375], [103, 1129, 162, 1251, 0.69140625], [103, 1129, 162, 1251, 0.69482421875], [103, 1129, 162, 1251, 0.693359375], [103, 1129, 162, 1251, 0.6923828125], [103, 1129, 162, 1250, 0.689453125], [103, 1129, 162, 1250, 0.68798828125], [103, 1129, 162, 1251, 0.6884765625], [103, 1129, 162, 1251, 0.6865234375], [103, 1129, 162, 1251, 0.6884765625], [103, 1129, 162, 1251, 0.68994140625], [103, 1129, 162, 1251, 0.693359375], [103, 1129, 162, 1251, 0.6904296875], [103, 1128, 162, 1250, 0.69189453125], [103, 1128, 162, 1250, 0.69140625], [103, 1129, 162, 1251, 0.693359375], [103, 1129, 162, 1251, 0.6923828125], [103, 1129, 162, 1251, 0.69091796875], [103, 1129, 162, 1251, 0.6904296875], [103, 1129, 162, 1251, 0.6875], [103, 1129, 162, 1251, 0.68603515625], [103, 1129, 163, 1251, 0.6865234375], [103, 1129, 164, 1251, 0.68505859375], [104, 1130, 164, 1251, 0.693359375], [103, 1130, 164, 1251, 0.6953125], [106, 1130, 163, 1252, 0.646484375]]\n",
      "Key: Kd, vector len: 8, Card Detections: [[484, 1105, 537, 1221, 0.642578125], [484, 1105, 538, 1219, 0.65283203125], [484, 1104, 537, 1220, 0.65087890625], [484, 1104, 537, 1220, 0.654296875], [484, 1104, 537, 1219, 0.6533203125], [484, 1104, 537, 1220, 0.65576171875], [483, 1104, 537, 1221, 0.66064453125], [481, 1104, 535, 1224, 0.591796875]]\n",
      "Key: Kh, vector len: 8, Card Detections: [[102, 1066, 162, 1198, 0.6328125], [103, 1067, 162, 1197, 0.63671875], [104, 1066, 162, 1196, 0.6328125], [105, 1066, 161, 1197, 0.63525390625], [105, 1066, 162, 1195, 0.63037109375], [105, 1066, 162, 1195, 0.630859375], [105, 1066, 162, 1197, 0.6318359375], [106, 1067, 163, 1197, 0.64111328125]]\n",
      "Key: Ks, vector len: 6, Card Detections: [[101, 1081, 163, 1210, 0.66357421875], [102, 1080, 163, 1210, 0.69677734375], [103, 1080, 164, 1210, 0.693359375], [103, 1081, 164, 1210, 0.69287109375], [105, 1079, 165, 1209, 0.6962890625], [105, 1081, 166, 1210, 0.7021484375]]\n",
      "Key: Qc, vector len: 9, Card Detections: [[88, 1055, 146, 1188, 0.66552734375], [89, 1056, 146, 1188, 0.65380859375], [89, 1057, 145, 1188, 0.64892578125], [90, 1058, 144, 1188, 0.6376953125], [90, 1057, 144, 1188, 0.638671875], [90, 1059, 144, 1190, 0.63818359375], [90, 1059, 144, 1191, 0.63525390625], [91, 1059, 144, 1191, 0.640625], [91, 1062, 144, 1193, 0.62744140625]]\n",
      "Key: Qd, vector len: 13, Card Detections: [[494, 1095, 545, 1211, 0.62744140625], [495, 1095, 546, 1211, 0.63427734375], [495, 1096, 546, 1211, 0.63037109375], [495, 1096, 546, 1211, 0.6328125], [495, 1095, 545, 1211, 0.63427734375], [495, 1096, 546, 1212, 0.63330078125], [495, 1095, 545, 1211, 0.6318359375], [495, 1095, 545, 1211, 0.6328125], [495, 1096, 546, 1212, 0.63427734375], [494, 1096, 546, 1212, 0.638671875], [494, 1096, 546, 1213, 0.64111328125], [493, 1098, 544, 1213, 0.64404296875], [492, 1100, 543, 1212, 0.64111328125]]\n",
      "Key: Qh, vector len: 8, Card Detections: [[482, 1111, 535, 1224, 0.6337890625], [482, 1111, 535, 1224, 0.638671875], [482, 1110, 535, 1225, 0.63232421875], [482, 1111, 535, 1225, 0.6318359375], [482, 1110, 534, 1225, 0.63232421875], [482, 1110, 534, 1224, 0.634765625], [481, 1110, 534, 1224, 0.63232421875], [481, 1111, 534, 1224, 0.6240234375]]\n",
      "Key: Qs, vector len: 17, Card Detections: [[493, 1090, 549, 1210, 0.67724609375], [497, 1090, 551, 1213, 0.67333984375], [497, 1090, 550, 1213, 0.669921875], [497, 1090, 550, 1213, 0.67041015625], [497, 1090, 550, 1213, 0.66943359375], [497, 1090, 550, 1214, 0.66748046875], [497, 1090, 550, 1213, 0.66796875], [497, 1090, 550, 1213, 0.669921875], [497, 1090, 550, 1213, 0.66943359375], [496, 1090, 550, 1213, 0.66943359375], [495, 1091, 549, 1213, 0.66748046875], [495, 1091, 549, 1214, 0.671875], [495, 1092, 549, 1213, 0.66796875], [496, 1092, 549, 1213, 0.66455078125], [495, 1093, 548, 1213, 0.66650390625], [494, 1094, 547, 1214, 0.66650390625], [493, 1096, 546, 1215, 0.6806640625]]\n",
      "Key: SJoker, vector len: 15, Card Detections: [[486, 1089, 548, 1216, 0.50927734375], [486, 1090, 552, 1231, 0.59814453125], [488, 1090, 548, 1218, 0.55224609375], [487, 1090, 550, 1228, 0.599609375], [487, 1090, 550, 1228, 0.59521484375], [487, 1090, 550, 1229, 0.572265625], [486, 1091, 549, 1229, 0.57861328125], [486, 1090, 549, 1228, 0.63134765625], [486, 1091, 549, 1233, 0.623046875], [487, 1090, 550, 1232, 0.623046875], [487, 1090, 549, 1229, 0.62939453125], [486, 1090, 549, 1229, 0.63037109375], [486, 1092, 550, 1231, 0.630859375], [486, 1093, 549, 1231, 0.5869140625], [487, 1095, 549, 1231, 0.6044921875]]\n",
      "Key: BJoker, vector len: 15, Card Detections: [[486, 1091, 551, 1233, 0.60107421875], [485, 1090, 555, 1240, 0.60693359375], [487, 1091, 551, 1227, 0.609375], [486, 1092, 552, 1236, 0.61669921875], [487, 1091, 553, 1237, 0.61474609375], [486, 1091, 552, 1238, 0.6201171875], [487, 1091, 553, 1239, 0.62353515625], [487, 1091, 553, 1239, 0.62646484375], [486, 1092, 554, 1240, 0.62744140625], [486, 1091, 554, 1240, 0.626953125], [486, 1091, 554, 1240, 0.6279296875], [487, 1091, 553, 1240, 0.62646484375], [487, 1091, 553, 1241, 0.62890625], [487, 1092, 554, 1242, 0.6318359375], [486, 1096, 551, 1240, 0.63720703125]]\n",
      "X shape: (5, 5, 5)\n",
      "y shape: (5, 5)\n",
      "X_test : [[[          0        0.25           1           0           1]\n",
      "  [        0.5         0.5      0.4714        0.75     0.95652]\n",
      "  [        0.5         0.5           0         0.5     0.95652]\n",
      "  [          1           0     0.74536     0.14758     0.78261]\n",
      "  [          1         0.5     0.66667           1     0.69565]]], y_test: [[          0           1           0         0.5         0.5]]\n",
      "X_train shape: (4, 5, 5), num_samples: 4, sequence_length: 5, feature_len: 5\n",
      "y_train shape: (4, 5)\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 5, 5)]            0         \n",
      "                                                                 \n",
      " masking_6 (Masking)         (None, 5, 5)              0         \n",
      "                                                                 \n",
      " bidirectional_18 (Bidirect  (None, 5, 512)            536576    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 5, 512)            0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 5, 512)            2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " bidirectional_19 (Bidirect  (None, 5, 256)            656384    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 5, 256)            0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 5, 256)            1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " bidirectional_20 (Bidirect  (None, 5, 128)            164352    \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 5, 128)            0         \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 5, 64)             37248     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 5, 64)             0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 5, 64)             256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " attention_6 (Attention)     (None, 64)                69        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1400202 (5.34 MB)\n",
      "Trainable params: 1398538 (5.33 MB)\n",
      "Non-trainable params: 1664 (6.50 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 0.29624, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.7026 - accuracy: 0.0000e+00 - val_loss: 0.2962 - val_accuracy: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8333 - accuracy: 0.2500\n",
      "Epoch 2: val_loss improved from 0.29624 to 0.29480, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8333 - accuracy: 0.2500 - val_loss: 0.2948 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 0.29480 to 0.29316, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7216 - accuracy: 0.0000e+00 - val_loss: 0.2932 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.2500\n",
      "Epoch 4: val_loss improved from 0.29316 to 0.29223, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5432 - accuracy: 0.2500 - val_loss: 0.2922 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.2500\n",
      "Epoch 5: val_loss improved from 0.29223 to 0.29107, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5665 - accuracy: 0.2500 - val_loss: 0.2911 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7048 - accuracy: 0.2500\n",
      "Epoch 6: val_loss improved from 0.29107 to 0.29026, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7048 - accuracy: 0.2500 - val_loss: 0.2903 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6735 - accuracy: 0.0000e+00\n",
      "Epoch 7: val_loss improved from 0.29026 to 0.28977, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.6735 - accuracy: 0.0000e+00 - val_loss: 0.2898 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8311 - accuracy: 0.0000e+00\n",
      "Epoch 8: val_loss improved from 0.28977 to 0.28929, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8311 - accuracy: 0.0000e+00 - val_loss: 0.2893 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7835 - accuracy: 0.0000e+00\n",
      "Epoch 9: val_loss improved from 0.28929 to 0.28781, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7835 - accuracy: 0.0000e+00 - val_loss: 0.2878 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.0000e+00\n",
      "Epoch 10: val_loss improved from 0.28781 to 0.28622, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4025 - accuracy: 0.0000e+00 - val_loss: 0.2862 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.0000e+00\n",
      "Epoch 11: val_loss improved from 0.28622 to 0.28531, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5315 - accuracy: 0.0000e+00 - val_loss: 0.2853 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.2500\n",
      "Epoch 12: val_loss improved from 0.28531 to 0.28457, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4659 - accuracy: 0.2500 - val_loss: 0.2846 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.2500\n",
      "Epoch 13: val_loss improved from 0.28457 to 0.28349, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3644 - accuracy: 0.2500 - val_loss: 0.2835 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.0000e+00\n",
      "Epoch 14: val_loss improved from 0.28349 to 0.28230, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4977 - accuracy: 0.0000e+00 - val_loss: 0.2823 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4429 - accuracy: 0.5000\n",
      "Epoch 15: val_loss improved from 0.28230 to 0.28090, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4429 - accuracy: 0.5000 - val_loss: 0.2809 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.2500\n",
      "Epoch 16: val_loss improved from 0.28090 to 0.27938, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3452 - accuracy: 0.2500 - val_loss: 0.2794 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6272 - accuracy: 0.5000\n",
      "Epoch 17: val_loss improved from 0.27938 to 0.27755, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.6272 - accuracy: 0.5000 - val_loss: 0.2775 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5820 - accuracy: 0.2500\n",
      "Epoch 18: val_loss improved from 0.27755 to 0.27622, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5820 - accuracy: 0.2500 - val_loss: 0.2762 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.2500\n",
      "Epoch 19: val_loss improved from 0.27622 to 0.27449, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5141 - accuracy: 0.2500 - val_loss: 0.2745 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.2500\n",
      "Epoch 20: val_loss improved from 0.27449 to 0.27365, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4747 - accuracy: 0.2500 - val_loss: 0.2737 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.7500\n",
      "Epoch 21: val_loss improved from 0.27365 to 0.27183, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3241 - accuracy: 0.7500 - val_loss: 0.2718 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.5000\n",
      "Epoch 22: val_loss improved from 0.27183 to 0.26973, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3885 - accuracy: 0.5000 - val_loss: 0.2697 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.5000\n",
      "Epoch 23: val_loss improved from 0.26973 to 0.26811, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3913 - accuracy: 0.5000 - val_loss: 0.2681 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.2500\n",
      "Epoch 24: val_loss improved from 0.26811 to 0.26647, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6763 - accuracy: 0.2500 - val_loss: 0.2665 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.5000\n",
      "Epoch 25: val_loss improved from 0.26647 to 0.26511, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3199 - accuracy: 0.5000 - val_loss: 0.2651 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.2500\n",
      "Epoch 26: val_loss improved from 0.26511 to 0.26388, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3827 - accuracy: 0.2500 - val_loss: 0.2639 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4654 - accuracy: 0.5000\n",
      "Epoch 27: val_loss improved from 0.26388 to 0.26305, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4654 - accuracy: 0.5000 - val_loss: 0.2631 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.0000e+00\n",
      "Epoch 28: val_loss improved from 0.26305 to 0.26170, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6138 - accuracy: 0.0000e+00 - val_loss: 0.2617 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3140 - accuracy: 0.2500\n",
      "Epoch 29: val_loss improved from 0.26170 to 0.26072, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3140 - accuracy: 0.2500 - val_loss: 0.2607 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.0000e+00\n",
      "Epoch 30: val_loss improved from 0.26072 to 0.25979, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4819 - accuracy: 0.0000e+00 - val_loss: 0.2598 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.2500\n",
      "Epoch 31: val_loss improved from 0.25979 to 0.25892, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1956 - accuracy: 0.2500 - val_loss: 0.2589 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.7500\n",
      "Epoch 32: val_loss improved from 0.25892 to 0.25789, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6917 - accuracy: 0.7500 - val_loss: 0.2579 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5496 - accuracy: 0.0000e+00\n",
      "Epoch 33: val_loss improved from 0.25789 to 0.25720, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5496 - accuracy: 0.0000e+00 - val_loss: 0.2572 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.2500\n",
      "Epoch 34: val_loss improved from 0.25720 to 0.25609, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5054 - accuracy: 0.2500 - val_loss: 0.2561 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.2500\n",
      "Epoch 35: val_loss improved from 0.25609 to 0.25524, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4482 - accuracy: 0.2500 - val_loss: 0.2552 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.0000e+00\n",
      "Epoch 36: val_loss improved from 0.25524 to 0.25451, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4174 - accuracy: 0.0000e+00 - val_loss: 0.2545 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.2500\n",
      "Epoch 37: val_loss improved from 0.25451 to 0.25351, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3435 - accuracy: 0.2500 - val_loss: 0.2535 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3509 - accuracy: 0.2500\n",
      "Epoch 38: val_loss improved from 0.25351 to 0.25274, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3509 - accuracy: 0.2500 - val_loss: 0.2527 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.5000\n",
      "Epoch 39: val_loss improved from 0.25274 to 0.25174, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2504 - accuracy: 0.5000 - val_loss: 0.2517 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.5000\n",
      "Epoch 40: val_loss improved from 0.25174 to 0.25091, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4059 - accuracy: 0.5000 - val_loss: 0.2509 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.2500\n",
      "Epoch 41: val_loss improved from 0.25091 to 0.24998, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.4577 - accuracy: 0.2500 - val_loss: 0.2500 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.0000e+00\n",
      "Epoch 42: val_loss improved from 0.24998 to 0.24870, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4667 - accuracy: 0.0000e+00 - val_loss: 0.2487 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.7500\n",
      "Epoch 43: val_loss improved from 0.24870 to 0.24794, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3518 - accuracy: 0.7500 - val_loss: 0.2479 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.5000\n",
      "Epoch 44: val_loss improved from 0.24794 to 0.24743, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.3903 - accuracy: 0.5000 - val_loss: 0.2474 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.5000\n",
      "Epoch 45: val_loss improved from 0.24743 to 0.24596, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2302 - accuracy: 0.5000 - val_loss: 0.2460 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.2500\n",
      "Epoch 46: val_loss improved from 0.24596 to 0.24522, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3841 - accuracy: 0.2500 - val_loss: 0.2452 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.0000e+00\n",
      "Epoch 47: val_loss improved from 0.24522 to 0.24391, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4747 - accuracy: 0.0000e+00 - val_loss: 0.2439 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.0000e+00\n",
      "Epoch 48: val_loss improved from 0.24391 to 0.24367, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4584 - accuracy: 0.0000e+00 - val_loss: 0.2437 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.0000e+00\n",
      "Epoch 49: val_loss improved from 0.24367 to 0.24309, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4700 - accuracy: 0.0000e+00 - val_loss: 0.2431 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.2500\n",
      "Epoch 50: val_loss improved from 0.24309 to 0.24272, saving model to best_lstm_yolo_model_20240906_1302.tensorflow.keras\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2993 - accuracy: 0.2500 - val_loss: 0.2427 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "训练损失: 0.3883, 训练Accuracy: 50.00%, 测试损失: 0.2427, 测试Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型成功保存为 ONNX 格式，路径为: best_lstm_yolo_model_20240906_1302.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 107, Total Ops 510, % non-converted = 20.98 %\n",
      " * 89 ARITH ops, 18 TF ops\n",
      "\n",
      "- arith.constant:   89 occurrences  (f32: 59, i32: 30)\n",
      "\n",
      "  (i1: 7, i32: 7)\n",
      "\n",
      "\n",
      "- tf.TensorListReserve:    4 occurrences  (: 4)\n",
      "- tf.TensorListSetItem:    7 occurrences  (: 7)\n",
      "- tf.TensorListStack:    7 occurrences  (f32: 7)\n",
      "  (f32: 48, i32: 14)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (i1: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 31)\n",
      "  (f32: 7, i1: 7)\n",
      "  (i1: 7)\n",
      "  (f32: 40)\n",
      "  (f32: 47)\n",
      "\n",
      "  (i1: 1)\n",
      "  (i32: 4)\n",
      "  (i1: 1)\n",
      "  (i1: 1)\n",
      "  (f32: 6, i1: 1)\n",
      "  (f32: 20)\n",
      "  (i32: 7)\n",
      "  (f32: 1)\n",
      "  (f32: 16)\n",
      "  (f32: 4, i32: 7)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 27)\n",
      "  (f32: 13, i1: 1)\n",
      "  (i32: 7)\n",
      "\n",
      "  (f32: 7)\n",
      "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [01:05<00:00, 10.95s/ passes]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 16880.48 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 13641.22 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 15261.81 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 9142.63 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 21014.79 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 10367.01 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 11814.94 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 9720.90 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 18217.47 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 15227.85 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 14951.39 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 9218.99 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 21515.74 ops/s]]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 12401.85 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 7902.38 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 8787.40 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 764.70 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 4345.45 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 14155.88 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 10282.45 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 34329.88 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 2319.42 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 12548.96 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 10395.04 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 16/16 [00:00<00:00, 18246.02 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 57/57 [00:00<00:00, 14024.48 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 16/16 [00:00<00:00, 13400.33 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 57/57 [00:00<00:00, 9487.49 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 540/540 [00:00<00:00, 1943.63 ops/s]\n",
      "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 106.12 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 76/76 [00:00<00:00, 165.70 passes/s]\n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 9/9 [00:00<00:00, 294.43 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 7002.18 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 28/28 [00:00<00:00, 225.54 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 9731.56 ops/s]s/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 28/28 [00:00<00:00, 228.68 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 13486.51 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 28/28 [00:00<00:00, 187.18 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 13148.29 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 28/28 [00:00<00:00, 187.28 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 3542.49 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 28/28 [00:00<00:00, 646.71 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 11915.64 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 28/28 [00:00<00:00, 698.83 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 1/1 [00:00<00:00, 12787.51 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 32/32 [00:00<00:00, 1730.19 ops/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 311/311 [00:00<00:00, 450.20 ops/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型成功保存为 CoreML 格式，路径为: best_lstm_yolo_model_20240906_1302.mlmodel\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "RMSE: 0.6561200618743896, MSE: 0.4304935336112976, MAE: 0.37690091133117676, R2 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages/sklearn/metrics/_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "预测结果：[[      129.5      1177.6    0.036088     -1.3986     0.63782]]\n",
      "真实数据：[[      129.5        1178           0           0      0.6416]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "import onnx\n",
    "import tf2onnx\n",
    "import joblib\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# 获取 videos 文件夹中的所有视频文件路径\n",
    "video_extensions = ['.mov', '.mp4', '.avi', '.mkv', '.flv', '.wmv']  # 支持的所有视频格式（小写）\n",
    "video_paths = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if os.path.splitext(f)[1].lower() in video_extensions]\n",
    "\n",
    "print(\"视频文件路径列表:\", video_paths)\n",
    "\n",
    "all_detected_objects_list = []\n",
    "for video_path in video_paths:\n",
    "    detected_objects_list = load_video_frames(video_path)\n",
    "    all_detected_objects_list.append(detected_objects_list)\n",
    "\n",
    "# 时序数据的一般格式 time、x 和 y 列\n",
    "# 使用检测到的数据来训练,  X 是输入序列，y 是对应的目标输出\n",
    "# 定义不同的时间步长度, 每次用前3个时间步的数据来预测下一个时间步的行为\n",
    "time_steps = 5\n",
    "feature_len = 5  # 每个时间步的5 values，输出5个值，对应类目标的未来位置cx, cy, card_velocity, direction, card_conf)\n",
    "predict_times = 1  # 预测的时间步数\n",
    "dropout_rate = 0.6  # dropout比例\n",
    "\n",
    "X_all, y_all = [], []\n",
    "for detected_objects_list in all_detected_objects_list:\n",
    "    X, y = prepare_complex_sequence_data(detected_objects_list, time_steps)\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "\n",
    "# 填充序列，使所有样本具有相同的时间步长\n",
    "X_all = pad_sequences(X_all, maxlen=time_steps, dtype='float32', padding='post', truncating='post')\n",
    "y_all = pad_sequences(y_all, maxlen=time_steps, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# 合并所有视频样本的数据\n",
    "X_all = np.concatenate(X_all, axis=0)\n",
    "y_all = np.concatenate(y_all, axis=0)\n",
    "\n",
    "# 归一化处理特征数据\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_all = scaler_X.fit_transform(X_all.reshape(-1, X_all.shape[-1])).reshape(X_all.shape)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_all = scaler_y.fit_transform(y_all)\n",
    "\n",
    "\n",
    "print(\"X shape:\", X_all.shape)  # 输出 (num_samples 54, sequence_length 5, feature_len 5)\n",
    "print(\"y shape:\", y_all.shape)  # 输出 (num_samples, feature_len)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"X_test : {X_test}, y_test: {y_test}\")\n",
    "\n",
    "# 检查 X_train 的形状\n",
    "print(f\"X_train shape: {X_train.shape}, num_samples: {X_train.shape[0]}, sequence_length: {X_train.shape[1]}, feature_len: {X_train.shape[2]}\")\n",
    "\n",
    "# 确保目标数据的形状与模型的输出形状一致\n",
    "# 目标数据的形状应该是 (batch_size, x, feature_len)\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "#y_train = np.reshape(y_train, (y_train.shape[0], predict_times, feature_len))\n",
    "#print(f\"y_train shape: {y_train.shape}, num_samples: {y_train.shape[0]}, sequence_length: {y_train.shape[1]}, feature_len: {y_train.shape[2]}\")\n",
    "\n",
    "# 模型训练\n",
    "# LSTM模型的輸入形狀: X_train.shape[1] 是sequence_length，X_train.shape[2] num_features是指定目标的7个特征值(x1, y1, x2, y2, card_area, card_velocity, card_conf)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "lstm_model = create_bilstm_attention_model(input_shape, dropout_rate)\n",
    "\n",
    "# 定义回调函数\n",
    "# Add Tensorboard\n",
    "tb_callback = TensorBoard(log_dir='./tb_results', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# EarlyStopping：监控val_loss，如果50个epoch内没有改善，则停止训练，并恢复至最佳模型权重。\n",
    "# ReduceLROnPlateau：当val_loss停止改善时，将学习率降低一半。\n",
    "# ModelCheckpoint：在每个epoch后保存最佳模型\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'best_lstm_yolo_model_{current_time}.tensorflow.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "#model_checkpoint = ModelCheckpoint(f'best_lstm_yolo_model_{current_time}.tensorflow.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# 拟合nn训练模型: 整个数据集上训练12000次，每次训练32个样本，validation_data 在每个 epoch结束后计算验证集的损失\n",
    "history = lstm_model.fit(X_train, y_train, \n",
    "                epochs=12000,\n",
    "                batch_size=32,\n",
    "                validation_data=(X_test, y_test), \n",
    "                callbacks=[tb_callback, reduce_lr, model_checkpoint])\n",
    "\n",
    "# # 保存 scaler\n",
    "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
    "\n",
    "# 评估模型\n",
    "train_loss, train_accuracy = lstm_model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_accuracy = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"训练损失: {train_loss:.4f}, 训练Accuracy: {train_accuracy * 100:.2f}%, 测试损失: {test_loss:.4f}, 测试Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "# 选择最佳模型\n",
    "# 训练过程中每个 epoch 的验证损失值\n",
    "val_loss = history.history['val_loss']\n",
    "# 验证损失最小的 epoch 对应就是最佳模型, 保存为lstm_weights_xx.h5文件\n",
    "best_epoch = np.argmin(val_loss)\n",
    "best_model = load_model(f'best_lstm_yolo_model_{current_time}.tensorflow.keras', custom_objects={'Attention': Attention})\n",
    "best_model.save(f'best_lstm_yolo_model_{current_time}.h5')  # 保存整个模型\n",
    "\n",
    "# 将 Keras 模型转换为 ONNX 格式\n",
    "spec = (tf.TensorSpec((None, X_train.shape[1], X_train.shape[2]), tf.float32, name=\"input\"),)\n",
    "output_path = f'best_lstm_yolo_model_{current_time}.onnx'\n",
    "model_proto, _ = tf2onnx.convert.from_keras(best_model, input_signature=spec, opset=13)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "print(f\"模型成功保存为 ONNX 格式，路径为: {output_path}\")\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'best_lstm_yolo_model_{current_time}.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "## 转换Core ML 模型\n",
    "# 定义输入\n",
    "sequence_input = ct.TensorType(shape=(1, X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# 进行模型转换\n",
    "coreml_model = ct.convert(\n",
    "    best_model,\n",
    "    convert_to=\"neuralnetwork\",\n",
    "    inputs=[sequence_input]\n",
    ")\n",
    "\n",
    "# 写入元数据\n",
    "#coreml_model.input_description[\"input_1\"] = \"输入序列数据\"\n",
    "#coreml_model.output_description[\"output_1\"] = \"模型输出\"\n",
    "\n",
    "# 模型作者\n",
    "coreml_model.author = \"hello\"\n",
    "\n",
    "# 许可\n",
    "coreml_model.license = \"许可信息\"\n",
    "\n",
    "# 描述\n",
    "coreml_model.short_description = \"双向LSTM模型, 带有注意力机制\"\n",
    "\n",
    "# 版本号\n",
    "coreml_model.version = \"1.0\"\n",
    "\n",
    "# 存储模型\n",
    "coreml_output_path = f'best_lstm_yolo_model_{current_time}.mlmodel'\n",
    "coreml_model.save(coreml_output_path)\n",
    "print(f\"模型成功保存为 CoreML 格式，路径为: {coreml_output_path}\")\n",
    "\n",
    "# 评估模型性能\n",
    "rmse, mse, mae, r2 = evaluate_inverse_performance(lstm_model, X_test, y_test)\n",
    "print(f\"RMSE: {rmse}, MSE: {mse}, MAE: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# 预测未来行为 如根据最近 3 frame序列, LSTM 模型进行预测下一个时间步的目标位置\n",
    "predictions = best_model.predict(X_test)\n",
    "# inverse 转回去原来的coordinate system\n",
    "predictions = scaler_y.inverse_transform(predictions)\n",
    "print(f\"预测结果：{predictions}\")\n",
    "\n",
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "# 真实数据\n",
    "print(f\"真实数据：{y_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看TensorBoard 实验结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'tb'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML 打包环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.15 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: coremltools in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (7.2)\n",
      "Requirement already satisfied: h5py in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (3.11.0)\n",
      "Requirement already satisfied: pillow in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (10.4.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (1.13.2)\n",
      "Requirement already satisfied: tqdm in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (4.66.5)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (24.2.0)\n",
      "Requirement already satisfied: cattrs in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (24.1.0)\n",
      "Requirement already satisfied: pyaml in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coremltools) (24.7.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from cattrs->coremltools) (1.2.2)\n",
      "Requirement already satisfied: PyYAML in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pyaml->coremltools) (6.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from sympy->coremltools) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow==2.15) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow==2.15) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "scikit-learn version 1.5.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "Torch version 2.4.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n",
      "7.2\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.15 coremltools h5py pillow\n",
    "!python -c \"import coremltools; print(coremltools.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlpackage 新格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:36<00:00,  6.04s/ passes]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 16601.44 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 11716.53 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 6792.07 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 1242.91 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 7989.15 ops/s]s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 11574.27 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 13352.65 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 8596.49 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 8611.49 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 11603.38 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 6441.70 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 6126.81 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 14641.31 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 11039.75 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 14212.31 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 8469.30 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 22904.97 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 9915.19 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 10753.00 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 7690.07 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 7230.83 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 7460.76 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 17/17 [00:00<00:00, 11266.10 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 55/55 [00:00<00:00, 5951.82 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 16/16 [00:00<00:00, 10341.94 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 57/57 [00:00<00:00, 9768.94 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 16/16 [00:00<00:00, 7964.50 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 57/57 [00:00<00:00, 1261.74 ops/s]\n",
      "Converting TF Frontend ==> MIL Ops: 100%|██████████| 540/540 [00:00<00:00, 1527.51 ops/s]\n",
      "Running MIL frontend_tensorflow2 pipeline: 100%|██████████| 7/7 [00:00<00:00, 99.79 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 78/78 [00:00<00:00, 106.95 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 189.87 passes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的输入特征名称: Features(input_1)\n",
      "模型的输出特征名称: Features(Identity)\n",
      "模型成功保存为 Core ML 格式，路径为: best_lstm_yolo_model.mlpackage\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 选择最佳模型\n",
    "best_model = load_model(f'best_lstm_yolo_model_20240905_2024.h5', custom_objects={'Attention': Attention})\n",
    "\n",
    "# 转换Core ML 模型\n",
    "# 定义输入\n",
    "sequence_input = ct.TensorType(shape=(1, 3, 9))\n",
    "\n",
    "# 进行模型转换\n",
    "coreml_model = ct.convert(\n",
    "    best_model,\n",
    "    inputs=[sequence_input]\n",
    ")\n",
    "\n",
    "# 打印模型的输入和输出特征名称\n",
    "print(\"模型的输入特征名称:\", coreml_model.input_description)\n",
    "print(\"模型的输出特征名称:\", coreml_model.output_description)\n",
    "\n",
    "# 写入元数据\n",
    "#input_feature_name = list(coreml_model.input_description.keys())[0]\n",
    "#output_feature_name = list(coreml_model.output_description.keys())[0]\n",
    "\n",
    "#coreml_model.input_description[input_feature_name] = \"输入序列数据\"\n",
    "#coreml_model.output_description[output_feature_name] = \"模型输出\"\n",
    "\n",
    "# 模型作者\n",
    "coreml_model.author = \"hello\"\n",
    "\n",
    "# 许可\n",
    "coreml_model.license = \"你的许可信息\"\n",
    "\n",
    "# 描述\n",
    "coreml_model.short_description = \"双向LSTM模型，带有注意力机制\"\n",
    "\n",
    "# 版本号\n",
    "coreml_model.version = \"1.0\"\n",
    "\n",
    "# 存储模型\n",
    "coreml_output_path = f'best_lstm_yolo_model.mlpackage'\n",
    "coreml_model.save(coreml_output_path)\n",
    "print(f\"模型成功保存为 Core ML 格式，路径为: {coreml_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlmodel 老格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 选择最佳模型\n",
    "best_model = load_model(f'best_lstm_yolo_model_20240905_2024.h5', custom_objects={'Attention': Attention})\n",
    "\n",
    "# 转换Core ML 模型\n",
    "# 定义输入\n",
    "sequence_input = ct.TensorType(shape=(1, 3, 9))\n",
    "\n",
    "# 进行模型转换\n",
    "coreml_model = ct.convert(\n",
    "    best_model, \n",
    "    convert_to=\"neuralnetwork\",\n",
    "    inputs=[sequence_input]\n",
    ")\n",
    "\n",
    "# 打印模型的输入和输出特征名称\n",
    "print(\"模型的输入特征名称:\", coreml_model.input_description)\n",
    "print(\"模型的输出特征名称:\", coreml_model.output_description)\n",
    "\n",
    "# 写入元数据\n",
    "#input_feature_name = list(coreml_model.input_description.keys())[0]\n",
    "#output_feature_name = list(coreml_model.output_description.keys())[0]\n",
    "\n",
    "#coreml_model.input_description[input_feature_name] = \"输入序列数据\"\n",
    "#coreml_model.output_description[output_feature_name] = \"模型输出\"\n",
    "\n",
    "# 模型作者\n",
    "coreml_model.author = \"hello\"\n",
    "\n",
    "# 许可\n",
    "coreml_model.license = \"你的许可信息\"\n",
    "\n",
    "# 描述\n",
    "coreml_model.short_description = \"双向LSTM模型，带有注意力机制\"\n",
    "\n",
    "# 版本号\n",
    "coreml_model.version = \"1.0\"\n",
    "\n",
    "# 存储模型\n",
    "coreml_output_path = f'best_lstm_yolo_model.mlmodel'\n",
    "coreml_model.save(coreml_output_path)\n",
    "print(f\"模型成功保存为 Core ML 格式，路径为: {coreml_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果（反归一化）：[[     101.07      1113.3      156.91      1241.1      129.06        1177     0.26257    -0.92349     0.64559]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import coremltools as ct\n",
    "\n",
    "# 加载 CoreML 模型\n",
    "coreml_model = ct.models.MLModel('best_lstm_yolo_model_20240905_2034.mlmodel')\n",
    "\n",
    "# 加载保存的 MinMaxScaler\n",
    "scaler_X = joblib.load('scaler_X.pkl')\n",
    "scaler_y = joblib.load('scaler_y.pkl')\n",
    "\n",
    "# 假设 X_test 是你的测试数据\n",
    "X_test = np.random.rand(1, 3, 9)  # 示例数据\n",
    "\n",
    "# 数据归一化\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "\n",
    "# 准备输入数据\n",
    "input_data = {'input_2': X_test_scaled}\n",
    "\n",
    "# 执行预测\n",
    "outputs = coreml_model.predict(input_data)\n",
    "y_pred_scaled = outputs['Identity']\n",
    "\n",
    "# 反归一化预测结果\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "print(f\"预测结果（反归一化）：{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测转换后的ONNX模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_model = onnx.load(f'best_lstm_yolo_model_20240905_1636.onnx')\n",
    "\n",
    "# 检查模型是否有效\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# 创建 ONNX Runtime 会话\n",
    "ort_session = ort.InferenceSession(f'best_lstm_yolo_model_20240905_1636.onnx')\n",
    "\n",
    "# 准备输入数据（根据实际情况调整）\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "input_data = np.random.random((1, 3, 9)).astype(np.float32)\n",
    "\n",
    "# 执行预测\n",
    "outputs = ort_session.run(None, {input_name: input_data})\n",
    "print(\"onnx预测结果:\", outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果和真实结果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "# 时间步（样本）索引\n",
    "samples = np.arange(y_test.shape[0])\n",
    "\n",
    "# 特征标签\n",
    "features = ['x_min', 'y_min', 'x_max', 'y_max', 'cx', 'cy', 'card_velocity', 'direction', 'card_conf']\n",
    "\n",
    "# 创建图形和子图\n",
    "fig, axes = plt.subplots(len(features), 1, figsize=(14, 3 * len(features)), tight_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 绘制每个特征的真实值和预测值\n",
    "for i in range(len(features)):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples, y_test[:, i], marker='o', linestyle='-', label='True', color='blue', markersize=4, linewidth=1.5)\n",
    "    ax.plot(samples, predictions[:, i], marker='x', linestyle='--', label='Predicted', color='red', markersize=6, linewidth=1.5)\n",
    "    ax.set_title(f'{features[i]}: True vs Predicted', fontsize=14)\n",
    "    ax.set_xlabel('Sample Index', fontsize=12)\n",
    "    ax.set_ylabel('Value', fontsize=12)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.7)\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 评估指标可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制训练与验证损失曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练与验证准确度曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型评估与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设有新的测试数据集\n",
    "test_samples = 10  # 测试样本数\n",
    "time_steps = 3\n",
    "num_features = 9\n",
    "test_data = np.random.rand(test_samples, time_steps, num_features)\n",
    "\n",
    "# 对测试数据进行标准化：我们使用标准化来将数据缩放到均值为0，标准差为1的范围内\n",
    "# (num_samples, time_steps, num_features) -> (num_samples * time_steps, num_features)\n",
    "scaler = StandardScaler()\n",
    "test_data_reshaped = test_data.reshape(-1, num_features)\n",
    "test_data_reshaped = scaler.fit_transform(test_data_reshaped)\n",
    "\n",
    "test_data_reshaped = scaler.transform(test_data_reshaped)\n",
    "# (num_samples * time_steps, num_features) -> (num_samples, time_steps, num_features)\n",
    "test_data = test_data_reshaped.reshape(test_samples, time_steps, num_features)\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = lstm_model.predict(test_data)\n",
    "\n",
    "# 将预测结果转换为类别标签\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# 显示每个测试样本的预测结果\n",
    "for i in range(test_samples):\n",
    "    print(f\"Sample {i+1} predictions: {predicted_classes[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
