{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8用于检测牌的位置，而LSTM则学习这些位置的时间序列模式，从而预测未来的行为。\n",
    "- You Only Look Once YOLO 接受整张图片作为输入划分为网格，每个网格预测一组边界框和对应的物体类别，这让 YOLO 很快\n",
    "- YOLO 将物体检测视为回归问题来解决，直接从图片生成边界框坐标和类别概率\n",
    "- LSTM Long Short-Term Memory 长短期记忆网络，适合时间序列预测的行为模式\n",
    "\n",
    "**这是一个相对复杂的深度学习应用，适用于人和动物行为研究中需要分析大量序列数据的场景。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "样本数num_samples: 54 poker, 每个样本time_steps: 20个时间序列, 每个时间序列num_features: 10个特征(待加入更多)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: filterpy in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.4.5)\n",
      "Requirement already satisfied: opencv-python in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tf2onnx in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.16.1)\n",
      "Requirement already satisfied: onnx in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.16.2)\n",
      "Requirement already satisfied: onnxruntime in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.19.0)\n",
      "Requirement already satisfied: onnx-coreml in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.3)\n",
      "Requirement already satisfied: absl-py in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: scipy in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from filterpy) (1.14.1)\n",
      "Requirement already satisfied: matplotlib in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from filterpy) (3.9.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: requests in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tf2onnx) (2.32.3)\n",
      "Requirement already satisfied: six in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tf2onnx) (24.3.25)\n",
      "Requirement already satisfied: protobuf~=3.20 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tf2onnx) (3.20.3)\n",
      "Requirement already satisfied: coloredlogs in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnxruntime) (1.13.2)\n",
      "Requirement already satisfied: click in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (8.1.7)\n",
      "Requirement already satisfied: typing>=3.6.4 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (3.7.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (4.12.2)\n",
      "Requirement already satisfied: coremltools>=3.2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (6.2)\n",
      "Requirement already satisfied: tqdm in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from coremltools>=3.2->onnx-coreml) (4.66.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib->filterpy) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib->filterpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib->filterpy) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib->filterpy) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib->filterpy) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib->filterpy) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests->tf2onnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests->tf2onnx) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests->tf2onnx) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests->tf2onnx) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras filterpy opencv-python numpy scikit-learn pandas tf2onnx onnx onnxruntime onnx-coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ultralytics/ultralytics.git@main\n",
      "  Cloning https://github.com/ultralytics/ultralytics.git (to revision main) to /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-req-build-0qi14jqu\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics.git /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-req-build-0qi14jqu\n",
      "  Resolved https://github.com/ultralytics/ultralytics.git to commit 1a497f174c21993e2464725d96482e2a4a52758b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (4.66.5)\n",
      "Requirement already satisfied: psutil in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from ultralytics==8.2.86) (2.0.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.86) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.86) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.86) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.86) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.86) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.86) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.2.86) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.2.86) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.2.86) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.86) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.86) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.86) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.2.86) (2024.7.4)\n",
      "Requirement already satisfied: filelock in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.86) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.86) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.86) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.86) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.86) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.2.86) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.2.86) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.2.86) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics==8.2.86) (1.3.0)\n",
      "Building wheels for collected packages: ultralytics\n",
      "  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ultralytics: filename=ultralytics-8.2.86-py3-none-any.whl size=872031 sha256=1e72beb6b6206e75f9557d401bad09ea5ebb325406b22618f5075748b037cb0b\n",
      "  Stored in directory: /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-ephem-wheel-cache-8fgp62ji/wheels/60/db/e5/6abbdd13b4e3d5e2fdcd87690cd8738f842eeb37142fdccb5b\n",
      "Successfully built ultralytics\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.2.83\n",
      "    Uninstalling ultralytics-8.2.83:\n",
      "      Successfully uninstalled ultralytics-8.2.83\n",
      "Successfully installed ultralytics-8.2.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the ultralytics package from GitHub\n",
    "%pip install git+https://github.com/ultralytics/ultralytics.git@main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. YOLOv8 模型检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#from sort import Sort\n",
    "#https://github.com/RizwanMunawar/yolov7-object-tracking/blob/main/sort.py\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, Layer, Masking, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.saving import serialize_keras_object\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='poker_analysis.log', level=logging.INFO, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "# 加载YOLOv8 模型\n",
    "#yolo_model = YOLO('poker/n_pretrain/weights/best.pt')\n",
    "yolo_model = YOLO(\"poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel\") #load a custom nano trained model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1. 多目标的位置\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model(frame)  # 进行目标检测\n",
    "    detections = {\n",
    "        'Tc': [], 'Td': [], 'Th': [], 'Ts': [],\n",
    "        '2c': [], '2d': [], '2h': [], '2s': [],\n",
    "        '3c': [], '3d': [], '3h': [], '3s': [],\n",
    "        '4c': [], '4d': [], '4h': [], '4s': [],\n",
    "        '5c': [], '5d': [], '5h': [], '5s': [],\n",
    "        '6c': [], '6d': [], '6h': [], '6s': [],\n",
    "        '7c': [], '7d': [], '7h': [], '7s': [],\n",
    "        '8c': [], '8d': [], '8h': [], '8s': [],\n",
    "        '9c': [], '9d': [], '9h': [], '9s': [],\n",
    "        'Ac': [], 'Ad': [], 'Ah': [], 'As': [],\n",
    "        'Jc': [], 'Jd': [], 'Jh': [], 'Js': [],\n",
    "        'Kc': [], 'Kd': [], 'Kh': [], 'Ks': [],\n",
    "        'Qc': [], 'Qd': [], 'Qh': [], 'Qs': [],\n",
    "        'SJoker': [], 'BJoker': []\n",
    "    }\n",
    "    for result in results:\n",
    "        for obj in result.boxes: # 提取检测结果\n",
    "            if obj.conf.item() > 0.5:\n",
    "                # tensor to numpy\n",
    "                #bbox = obj.xyxy[0].cpu().numpy()\n",
    "                #x_min, y_min, x_max, y_max = obj.xyxy[0]\n",
    "                bbox = obj.xyxy[0].cpu().numpy().astype(int)\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                \n",
    "                # roi = frame[y_min:y_max, x_min:x_max]\n",
    "                # roi_resized = cv2.resize(roi, (64, 64))\n",
    "                \n",
    "                # 数据增强: 随机翻转和旋转\n",
    "                # if np.random.rand() > 0.5:\n",
    "                #     roi_resized = cv2.flip(roi_resized, 1)\n",
    "                # angle = np.random.uniform(-10, 10)\n",
    "                # M = cv2.getRotationMatrix2D((32, 32), angle, 1.0)\n",
    "                # roi_resized = cv2.warpAffine(roi_resized, M, (64, 64))\n",
    "                # roi_tensor = torch.tensor(roi_resized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "                #张量的形状变为 (1, 通道, 高度, 宽度)\n",
    "                #print(\"ROI Tensor:\", roi_tensor)\n",
    "                \n",
    "                #x_center = (x_min + x_max) / 2\n",
    "                #y_center = (y_min + y_max) / 2\n",
    "                # Get the boxes center coordinates (x, y), width (w), and height (h) size\n",
    "                x, y, w, h = obj.xywh[0].cpu()\n",
    "                speed = np.sqrt((w ** 2 + h ** 2))\n",
    "                conf = obj.conf.item()\n",
    "                # labels names\n",
    "                class_id = int(obj.cls.item())\n",
    "                class_name = yolo_model.names[class_id]\n",
    "                if class_name in detections:\n",
    "                    detections[class_name].append([x_min, y_min, x_max, y_max, conf])\n",
    "\n",
    "    return detections\n",
    "\n",
    "# 2. 多模态输入包括上面的视频数据和其他传感器数据\n",
    "# 假设我们有来自不同传感器的数据\n",
    "sensor_data = np.random.rand(1000, 5)  # 例如溫度、光強度等\n",
    "\n",
    "# 3. 同步处理多模态数据\n",
    "def synchronize_data(detections, sensor_data):\n",
    "    # hstack 将目标的检测数据与传感器数据在特征层面上拼接在一起，形成一个多模态输入矩阵\n",
    "    return np.hstack([detections, sensor_data[:len(detections), :]])\n",
    "\n",
    "# 获取同步后的数据\n",
    "#sync_data = synchronize_data(all_detections, sensor_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 卡尔曼滤波器精确追踪进行位置更新和噪声过滤\n",
    "\n",
    "https://medium.com/@mosesdaudu001/object-detection-tracking-with-yolov8-and-sort-algorithm-363be8bc0806\n",
    "\n",
    "\n",
    "Predicting future positions of moving objects is indeed a complex task that typically involves motion prediction algorithms such as Kalman filters \n",
    "or more advanced techniques like deep learning-based trajectory prediction.\n",
    "预测移动物体的未来位置确实是一项复杂的任务，通常涉及运动预测算法（例如卡尔曼滤波器）或更先进的技术（例如基于深度学习的轨迹预测）。\n",
    "\n",
    "YOLO's tracking algorithm already incorporates Kalman filtering\n",
    "YOLO 的跟踪算法已经包含卡尔曼滤波器， 提取每个跟踪对象的当前状态（位置和速度），然后多次使用卡尔曼滤波器来预测其未来状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from filterpy.kalman import KalmanFilter\n",
    "# DeepSORT\n",
    "\n",
    "def initialize_kalman_filter():\n",
    "    kf = KalmanFilter(dim_x=7, dim_z=4)  # 7 个状态变量，4 个观测变量\n",
    "    kf.F = np.array([[1,0,0,0,1,0,0],\n",
    "                     [0,1,0,0,0,1,0],\n",
    "                     [0,0,1,0,0,0,1],\n",
    "                     [0,0,0,1,0,0,0],\n",
    "                     [0,0,0,0,1,0,0],\n",
    "                     [0,0,0,0,0,1,0],\n",
    "                     [0,0,0,0,0,0,1]])  # 状态转移矩阵\n",
    "    kf.H = np.array([[1,0,0,0,0,0,0],\n",
    "                     [0,1,0,0,0,0,0],\n",
    "                     [0,0,1,0,0,0,0],\n",
    "                     [0,0,0,1,0,0,0]])  # 观测矩阵\n",
    "    return kf\n",
    "\n",
    "# 初始化卡尔曼滤波器\n",
    "kf = initialize_kalman_filter()\n",
    "\n",
    "def track_objects(detection):\n",
    "    z = np.array([detection[0], detection[1], detection[2], detection[3]])  # 观测变量\n",
    "    kf.predict()  # 预测下一步\n",
    "    kf.update(z)  # 更新滤波\n",
    "    return kf.x[:4]  # 返回更新后的位置信息\n",
    "\n",
    "# 追踪所有目标对象\n",
    "tracked_positions = []\n",
    "# for det_list in all_detections.values():\n",
    "#     tracked_position = [track_objects(d) for d in det_list]\n",
    "#     tracked_positions.append(tracked_position)\n",
    "    \n",
    "tracked_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 将视频帧或图像序列转换为LSTM模型的输入格式\n",
    "** 每一个时间点的数据都包括前n个时间步长的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 计算欧几里得距离\n",
    "def calculate_distance(box1, box2):\n",
    "    x1_center = (box1[0] + box1[2]) / 2\n",
    "    y1_center = (box1[1] + box1[3]) / 2\n",
    "    x2_center = (box2[0] + box2[2]) / 2\n",
    "    y2_center = (box2[1] + box2[3]) / 2\n",
    "    return np.sqrt((x1_center - x2_center)**2 + (y1_center - y2_center)**2)\n",
    "\n",
    "# 计算检测框的面积\n",
    "def calculate_area(box):\n",
    "    return (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "# 计算两个检测框之间的速度和角度\n",
    "def calculate_velocity_and_angle(previous_box, current_box, time_interval):\n",
    "    # 计算中心点\n",
    "    previous_center = [(previous_box[0] + previous_box[2]) / 2, (previous_box[1] + previous_box[3]) / 2]\n",
    "    current_center = [(current_box[0] + current_box[2]) / 2, (current_box[1] + current_box[3]) / 2]\n",
    "    \n",
    "    # 计算距离\n",
    "    distance = np.sqrt((current_center[0] - previous_center[0])**2 + (current_center[1] - previous_center[1])**2)\n",
    "    \n",
    "    # 计算速度\n",
    "    velocity = distance / time_interval\n",
    "    \n",
    "    # 计算角度(弧度), 表示检测框的运动方向\n",
    "    direction = np.arctan2(current_center[1] - previous_center[1], current_center[0] - previous_center[0])\n",
    "    \n",
    "    return velocity, direction\n",
    "\n",
    "                        \n",
    "def prepare_complex_sequence_data(detected_objects_list, sequence_length=3, time_interval=1.0):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # TODO: 目前是追踪54个样本的轨迹, 计算同一帧的两个目标的关联关系?\n",
    "    for key in detected_objects_list:\n",
    "        card_detections = detected_objects_list[key]\n",
    "        print(f\"Key: {key}, vector len: {len(card_detections)}, Card Detections: {card_detections}\")\n",
    "        for i in range(len(card_detections) - sequence_length):\n",
    "            input_seq = []\n",
    "            for j in range(sequence_length):\n",
    "                card_boxes = card_detections[i + j]    \n",
    "                # 距離、面積、速度和置信度特徵\n",
    "                if card_boxes:\n",
    "                    cx = (card_boxes[0] + card_boxes[2]) / 2\n",
    "                    cy = (card_boxes[1] + card_boxes[3]) / 2\n",
    "                \n",
    "                    card_area = calculate_area(card_boxes)\n",
    "                    card_conf = card_boxes[4]  # 假设置信度在检测框的第五个元素\n",
    "                    \n",
    "                    if i > 0:  # 速度計算需要前一個時間點的數據\n",
    "                        prev_card_box = card_detections[i + j - 1]\n",
    "                        card_velocity, direction = calculate_velocity_and_angle(prev_card_box, card_boxes, time_interval)\n",
    "                    else:\n",
    "                        card_velocity = 0\n",
    "                        direction = 0\n",
    "                    \n",
    "                    # 特征序列\n",
    "                    input_seq.append([card_boxes[0], card_boxes[1], card_boxes[2], card_boxes[3], cx, cy, card_area, card_velocity, direction, card_conf])\n",
    "                else:\n",
    "                    input_seq.append([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            \n",
    "            # X 作为LSTM 的输入向量\n",
    "            #seq = np.array(input_seq).flatten()\n",
    "            X.append(input_seq)\n",
    "            # y 作为LSTM 目标值, 构建 y 的 7 个特征, 下一frame的真实位置作为训练时的目标值\n",
    "            next_card_boxes = card_detections[i + sequence_length]\n",
    "            if next_card_boxes:\n",
    "                next_card_area = calculate_area(next_card_boxes)\n",
    "                cx = (next_card_boxes[0] + next_card_boxes[2]) / 2\n",
    "                cy = (next_card_boxes[1] + next_card_boxes[3]) / 2\n",
    "                next_card_conf = next_card_boxes[4]\n",
    "                if i + sequence_length > 0:\n",
    "                    prev_next_card_box = card_detections[i + sequence_length - 1]\n",
    "                    next_card_velocity, direction = calculate_velocity_and_angle(prev_next_card_box, next_card_boxes, time_interval)\n",
    "                else:\n",
    "                    next_card_velocity = 0\n",
    "                    direction = 0\n",
    "                y.append([next_card_boxes[0], next_card_boxes[1], next_card_boxes[2], next_card_boxes[3], cx, cy, next_card_area, next_card_velocity, direction, next_card_conf])\n",
    "            else:\n",
    "                y.append([0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, frame_index):\n",
    "    res = detect_objects(frame)\n",
    "    height, width = frame.shape[:2]\n",
    "    if width == 0 or height == 0:\n",
    "        return frame_index, {}  # 返回空结果，避免除以零\n",
    "\n",
    "    return frame_index, res\n",
    "\n",
    "def load_video_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_detections = {\n",
    "        'Tc': [], 'Td': [], 'Th': [], 'Ts': [],\n",
    "        '2c': [], '2d': [], '2h': [], '2s': [],\n",
    "        '3c': [], '3d': [], '3h': [], '3s': [],\n",
    "        '4c': [], '4d': [], '4h': [], '4s': [],\n",
    "        '5c': [], '5d': [], '5h': [], '5s': [],\n",
    "        '6c': [], '6d': [], '6h': [], '6s': [],\n",
    "        '7c': [], '7d': [], '7h': [], '7s': [],\n",
    "        '8c': [], '8d': [], '8h': [], '8s': [],\n",
    "        '9c': [], '9d': [], '9h': [], '9s': [],\n",
    "        'Ac': [], 'Ad': [], 'Ah': [], 'As': [],\n",
    "        'Jc': [], 'Jd': [], 'Jh': [], 'Js': [],\n",
    "        'Kc': [], 'Kd': [], 'Kh': [], 'Ks': [],\n",
    "        'Qc': [], 'Qd': [], 'Qh': [], 'Qs': [],\n",
    "        'SJoker': [], 'BJoker': []\n",
    "    }\n",
    "    frames = []\n",
    "    frame_index = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append((frame_index, frame))\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    results = [None] * len(frames)  # 用于存储结果的列表，保持顺序\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        future_to_frame = {executor.submit(process_frame, frame, idx): idx for idx, frame in frames}\n",
    "        for future in as_completed(future_to_frame):\n",
    "            idx, res = future.result()\n",
    "            results[idx] = res  # 按照索引存储结果\n",
    "\n",
    "    #FIXME: 合并结果前过滤掉异常值的结果\n",
    "    for idx, res in enumerate(results):\n",
    "        logging.info(f'#: {idx}, result: {res}')\n",
    "        for key in res.keys():\n",
    "            all_detections[key].extend(res[key])\n",
    "    return all_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用 Keras库來构建LSTM 模型与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (1.65.5)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Custom Attention Layer\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = tf.nn.tanh(tf.matmul(x, self.W) + self.b)  # Energy\n",
    "        a = tf.nn.softmax(e, axis=1)  # Attention weights\n",
    "        output = tf.reduce_sum(x * a, axis=1)  # Weighted sum of input features\n",
    "        return output\n",
    "\n",
    "# 构建一个更复杂的双向LSTM模型，同时引入注意力机制, 使用检测到的数据进行训练。模型包括多层LSTM、Dropout、BatchNormalization等层\n",
    "# input_shape=(time_steps, num_features)\n",
    "def create_bilstm_attention_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    masked_inputs = Masking(mask_value=0.0)(inputs)  # Add a Masking layer\n",
    "    lstm_out = Bidirectional(LSTM(256, return_sequences=True))(masked_inputs)\n",
    "    lstm_out = Dropout(0.3)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "\n",
    "    lstm_out = Bidirectional(LSTM(128, return_sequences=True))(lstm_out)\n",
    "    # 添加 Dropout 和 BatchNormalization 层\n",
    "    lstm_out = Dropout(0.3)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "\n",
    "    lstm_out = Bidirectional(LSTM(64, return_sequences=True))(lstm_out)\n",
    "    lstm_out = Dropout(0.3)(lstm_out)\n",
    "    \n",
    "    # Correct usage of Attention layer\n",
    "    attention = Attention()(lstm_out)\n",
    "\n",
    "    # 全连接层，将 LSTM 的输出映射到32个神经元，并应用 ReLU 激活函数来引入非线性\n",
    "    dense_out = Dense(32, activation='relu')(attention)\n",
    "    outputs = Dense(10)(dense_out)  # The final Dense layer outputs 10 values 最后的全连接层，输出10个值\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # 使用Adam优化器(梯度下降优化)和均方误差（MSE）作为损失函数，衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    # 显示模型摘要\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 反归一化预测结果和真实值\n",
    "    y_pred_inverse = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_inverse = scaler_y.inverse_transform(y_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "    # 均方根误差（RMSE）是一种用于衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好。 \n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inverse, y_pred_inverse))\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "    r2 = r2_score(y_test_inverse, y_pred_inverse)\n",
    "    \n",
    "    return rmse, mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coremltools in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (6.2)\n",
      "Requirement already satisfied: onnx-coreml in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (1.3)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from coremltools) (1.26.4)\n",
      "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from coremltools) (3.20.3)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from coremltools) (1.13.2)\n",
      "Requirement already satisfied: tqdm in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from coremltools) (4.66.5)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from coremltools) (24.1)\n",
      "Requirement already satisfied: click in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (8.1.7)\n",
      "Requirement already satisfied: onnx>=1.5.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (1.16.2)\n",
      "Requirement already satisfied: typing>=3.6.4 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (3.7.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from onnx-coreml) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages (from sympy->coremltools) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install coremltools onnx-coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coremltools 6 以上版本不需要安装 onnx-coreml\n",
    "#%pip install --upgrade onnx-coreml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 将数据集拆分为训练集和测试集，训练LSTM模型并选择最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频文件路径列表: ['videos/980_raw.MP4', 'videos/1_1724912500.mp4', 'videos/5_1725263689.mp4', 'videos/11_1725263718.mp4', 'videos/9_1725263704.mp4', 'videos/10_1725263709.mp4', 'videos/3_1724913435.mp4', 'videos/8_1725263700.mp4', 'videos/video02.MOV', 'videos/IMG_0024.MOV', 'videos/7_1725263694.mp4', 'videos/2_1724912569.mp4', 'videos/4_1725263685.mp4']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ultralytics YOLOv8.2.86 🚀 Python-3.10.14 torch-2.4.0 CPU (Apple M2)\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "Ultralytics YOLOv8.2.86 🚀 Python-3.10.14 torch-2.4.0 CPU (Apple M2)\n",
      "Ultralytics YOLOv8.2.86 🚀 Python-3.10.14 torch-2.4.0 CPU (Apple M2)\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "Ultralytics YOLOv8.2.86 🚀 Python-3.10.14 torch-2.4.0 CPU (Apple M2)\n",
      "\n",
      "\n",
      "\n",
      "Ultralytics YOLOv8.2.86 🚀 Python-3.10.14 torch-2.4.0 CPU (Apple M2)\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "Loading poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel for CoreML inference...\n",
      "0: 640x640 (no detections), 25.1ms\n",
      "0: 640x640 (no detections), 65.8ms\n",
      "Speed: 5.9ms preprocess, 25.1ms inference, 3266.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Speed: 7.0ms preprocess, 65.8ms inference, 3224.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 4.2ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.6ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 2.7ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.7ms preprocess, 13.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 4.1ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 45.1ms preprocess, 16.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.5ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 2.6ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 3.4ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 2.6ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 3.0ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.8ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.2ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.4ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 3.3ms preprocess, 15.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 3.2ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 48.7ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 5.9ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 7.8ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 11.8ms\n",
      "Speed: 3.3ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 14.2ms\n",
      "Speed: 3.6ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 14.7ms\n",
      "Speed: 2.9ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 1 Ad, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 1 Ad, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 1 Ad, 12.8ms\n",
      "Speed: 4.0ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 2.4ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 12.7ms\n",
      "Speed: 3.6ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 32.7ms\n",
      "Speed: 2.5ms preprocess, 32.7ms inference, 29.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 17.0ms\n",
      "Speed: 2.3ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 13.9ms\n",
      "Speed: 2.8ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 14.2ms\n",
      "Speed: 2.9ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 12.9ms\n",
      "Speed: 3.1ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 10.1ms\n",
      "Speed: 4.2ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 12.9ms\n",
      "Speed: 3.1ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.8ms\n",
      "Speed: 3.8ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 11.5ms\n",
      "Speed: 3.7ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 13.8ms\n",
      "Speed: 2.8ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 11.5ms\n",
      "Speed: 3.3ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 13.7ms\n",
      "Speed: 2.9ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.4ms\n",
      "Speed: 3.4ms preprocess, 14.4ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 5.0ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.6ms\n",
      "Speed: 3.4ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.7ms\n",
      "Speed: 3.2ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 58.2ms\n",
      "Speed: 3.2ms preprocess, 58.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.1ms\n",
      "Speed: 2.6ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.6ms\n",
      "Speed: 3.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.6ms\n",
      "Speed: 2.6ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 3.5ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.2ms\n",
      "Speed: 2.5ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 3.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 4.5ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 8.8ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.6ms\n",
      "Speed: 3.2ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 4.1ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 4.2ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 6.2ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.5ms\n",
      "Speed: 3.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 14.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.6ms\n",
      "Speed: 2.7ms preprocess, 14.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.2ms\n",
      "Speed: 2.7ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.0ms\n",
      "Speed: 11.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 4.4ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 4.6ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 2.9ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.9ms\n",
      "Speed: 3.1ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.1ms\n",
      "Speed: 3.5ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 4.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.3ms\n",
      "Speed: 2.7ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.8ms\n",
      "Speed: 3.4ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 4.1ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.2ms\n",
      "Speed: 5.8ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.7ms\n",
      "Speed: 2.8ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.4ms\n",
      "Speed: 3.1ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.1ms\n",
      "Speed: 1.8ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 5.3ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 3.1ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.7ms\n",
      "Speed: 3.0ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.7ms\n",
      "Speed: 2.7ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.3ms\n",
      "Speed: 3.2ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 42.4ms\n",
      "Speed: 12.1ms preprocess, 42.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.0ms\n",
      "Speed: 4.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 3.1ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.7ms\n",
      "Speed: 3.4ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.1ms\n",
      "Speed: 3.2ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.4ms\n",
      "Speed: 3.1ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.7ms\n",
      "Speed: 3.2ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.2ms\n",
      "Speed: 4.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.1ms\n",
      "Speed: 4.6ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.8ms\n",
      "Speed: 3.1ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.8ms\n",
      "Speed: 2.5ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.8ms\n",
      "Speed: 2.6ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.0ms\n",
      "Speed: 2.5ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.7ms\n",
      "Speed: 3.3ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 57.8ms\n",
      "Speed: 3.3ms preprocess, 57.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 5.8ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 3.2ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.9ms\n",
      "Speed: 3.4ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 2.6ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.3ms\n",
      "Speed: 3.5ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.8ms\n",
      "Speed: 3.2ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.5ms\n",
      "Speed: 3.6ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.4ms\n",
      "Speed: 3.0ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 3.7ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 23.6ms\n",
      "Speed: 11.0ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 16.1ms\n",
      "Speed: 16.6ms preprocess, 16.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 3.8ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 13.9ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.5ms\n",
      "Speed: 3.5ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 3.7ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 3.6ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 4.3ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.8ms\n",
      "Speed: 3.1ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 4.7ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 5.6ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 3.4ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.2ms\n",
      "Speed: 2.8ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 3.9ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 2.9ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.4ms\n",
      "Speed: 2.7ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 46.4ms\n",
      "Speed: 3.1ms preprocess, 46.4ms inference, 10.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.7ms\n",
      "Speed: 9.5ms preprocess, 20.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 3.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.1ms\n",
      "Speed: 2.8ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 3.3ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 3.7ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.2ms\n",
      "Speed: 2.6ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 9.2ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 3.9ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 62.1ms\n",
      "Speed: 2.4ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.0ms\n",
      "Speed: 5.3ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6d, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9d, 12.8ms\n",
      "Speed: 3.2ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 13.1ms\n",
      "Speed: 3.6ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 12.4ms\n",
      "Speed: 4.1ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.6ms\n",
      "Speed: 3.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 13.5ms\n",
      "Speed: 5.3ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 9s, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 9s, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 9s, 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 12.1ms\n",
      "Speed: 3.2ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 14.2ms\n",
      "Speed: 2.9ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 67.4ms\n",
      "Speed: 2.3ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 18.6ms\n",
      "Speed: 2.3ms preprocess, 18.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 19.1ms\n",
      "Speed: 3.4ms preprocess, 19.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 12.9ms\n",
      "Speed: 6.7ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 16.5ms\n",
      "Speed: 3.6ms preprocess, 16.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 13.1ms\n",
      "Speed: 4.0ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 19.6ms\n",
      "Speed: 3.5ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 10.4ms\n",
      "Speed: 4.7ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 1 Kc, 12.2ms\n",
      "Speed: 3.4ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 24.5ms\n",
      "Speed: 30.0ms preprocess, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 14.6ms\n",
      "Speed: 9.2ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 14.3ms\n",
      "Speed: 2.8ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 13.1ms\n",
      "Speed: 3.0ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ac, 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 11.2ms\n",
      "Speed: 12.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 As, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 12.7ms\n",
      "Speed: 2.8ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 9h, 1 Ac, 13.9ms\n",
      "Speed: 2.4ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 21.9ms\n",
      "Speed: 2.7ms preprocess, 21.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 11.9ms\n",
      "Speed: 4.5ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 10.6ms\n",
      "Speed: 3.6ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 13.3ms\n",
      "Speed: 3.2ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.0ms\n",
      "Speed: 4.4ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 7c, 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 13.4ms\n",
      "Speed: 3.1ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 16.8ms\n",
      "Speed: 9.1ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 14.0ms\n",
      "Speed: 2.7ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 15.3ms\n",
      "Speed: 2.5ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 11.1ms\n",
      "Speed: 4.5ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 13.0ms\n",
      "Speed: 3.8ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 14.6ms\n",
      "Speed: 2.9ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 10.8ms\n",
      "Speed: 4.7ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 14.1ms\n",
      "Speed: 2.4ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 19.4ms\n",
      "Speed: 2.6ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 13.1ms\n",
      "Speed: 3.6ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 14.4ms\n",
      "Speed: 2.6ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 14.7ms\n",
      "Speed: 2.9ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 14.6ms\n",
      "Speed: 2.7ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 14.8ms\n",
      "Speed: 2.5ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 13.4ms\n",
      "Speed: 2.7ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 13.2ms\n",
      "Speed: 2.7ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Qs, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Qs, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 14.2ms\n",
      "Speed: 2.9ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 10.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 11.6ms\n",
      "Speed: 3.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 13.9ms\n",
      "Speed: 2.5ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 12.9ms\n",
      "Speed: 3.2ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 14.6ms\n",
      "Speed: 2.8ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 15.2ms\n",
      "Speed: 2.6ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 13.9ms\n",
      "Speed: 2.6ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 13.7ms\n",
      "Speed: 2.5ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 16.1ms\n",
      "Speed: 9.4ms preprocess, 16.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.0ms\n",
      "Speed: 3.5ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 13.8ms\n",
      "Speed: 2.5ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 14.3ms\n",
      "Speed: 3.3ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 14.5ms\n",
      "Speed: 2.9ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 14.6ms\n",
      "Speed: 3.3ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 15.1ms\n",
      "Speed: 2.6ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 20.5ms\n",
      "Speed: 3.0ms preprocess, 20.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 14.1ms\n",
      "Speed: 2.5ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 13.6ms\n",
      "Speed: 2.7ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 15.9ms\n",
      "Speed: 2.8ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 9.9ms\n",
      "Speed: 3.8ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ts, 1 9h, 13.8ms\n",
      "Speed: 7.4ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 13.4ms\n",
      "Speed: 2.5ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 13.3ms\n",
      "Speed: 3.9ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kd, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kd, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kd, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kd, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 11.2ms\n",
      "Speed: 3.4ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 15.7ms\n",
      "Speed: 2.4ms preprocess, 15.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 10.2ms\n",
      "Speed: 4.1ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 11.9ms\n",
      "Speed: 10.1ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 14.9ms\n",
      "Speed: 2.6ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 10.3ms\n",
      "Speed: 5.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.2ms\n",
      "Speed: 3.1ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 14.9ms\n",
      "Speed: 2.9ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 13.4ms\n",
      "Speed: 2.9ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 21.5ms\n",
      "Speed: 2.8ms preprocess, 21.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 14.6ms\n",
      "Speed: 3.4ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 19.1ms\n",
      "Speed: 47.1ms preprocess, 19.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 11.5ms\n",
      "Speed: 6.9ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 14.5ms\n",
      "Speed: 2.8ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 14.8ms\n",
      "Speed: 2.4ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 14.4ms\n",
      "Speed: 2.8ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Qh, 14.8ms\n",
      "Speed: 2.7ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Qh, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Qh, 14.6ms\n",
      "Speed: 2.8ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Qh, 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 14.4ms\n",
      "Speed: 2.9ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 16.0ms\n",
      "Speed: 2.7ms preprocess, 16.0ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 9.8ms\n",
      "Speed: 4.8ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 10.0ms\n",
      "Speed: 8.0ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 12.3ms\n",
      "Speed: 3.7ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 13.0ms\n",
      "Speed: 3.3ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 11.8ms\n",
      "Speed: 3.9ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 14.0ms\n",
      "Speed: 3.4ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 17.6ms\n",
      "Speed: 3.3ms preprocess, 17.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 12.6ms\n",
      "Speed: 8.0ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 40.8ms\n",
      "Speed: 47.5ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 10.7ms\n",
      "Speed: 11.1ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 12.9ms\n",
      "Speed: 3.2ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 10.9ms\n",
      "Speed: 3.7ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 10.6ms\n",
      "Speed: 7.2ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 13.6ms\n",
      "Speed: 2.6ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 11.1ms\n",
      "Speed: 4.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 11.1ms\n",
      "Speed: 3.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8d, 11.4ms\n",
      "Speed: 6.6ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 10.6ms\n",
      "Speed: 4.2ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 15.1ms\n",
      "Speed: 6.0ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 14.0ms\n",
      "Speed: 3.8ms preprocess, 14.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 23.2ms\n",
      "Speed: 3.1ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 24.0ms\n",
      "Speed: 2.7ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 12.5ms\n",
      "Speed: 3.6ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 12.6ms\n",
      "Speed: 3.2ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 13.6ms\n",
      "Speed: 3.0ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7c, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7c, 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7c, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.8ms\n",
      "Speed: 6.1ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.6ms\n",
      "Speed: 2.1ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 15.2ms\n",
      "Speed: 11.0ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 9.9ms\n",
      "Speed: 3.6ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 20.7ms\n",
      "Speed: 3.6ms preprocess, 20.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 12.7ms\n",
      "Speed: 7.2ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 11.1ms\n",
      "Speed: 3.3ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6s, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 12.9ms\n",
      "Speed: 2.2ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 12.9ms\n",
      "Speed: 3.4ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 13.1ms\n",
      "Speed: 2.6ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.5ms\n",
      "Speed: 4.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.7ms\n",
      "Speed: 4.5ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 14.7ms\n",
      "Speed: 3.8ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.9ms\n",
      "Speed: 4.1ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.0ms\n",
      "Speed: 3.9ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 10.4ms\n",
      "Speed: 3.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 15.2ms\n",
      "Speed: 12.3ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 10.4ms\n",
      "Speed: 4.7ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.2ms\n",
      "Speed: 2.6ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 13.6ms\n",
      "Speed: 5.7ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 14.0ms\n",
      "Speed: 5.1ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.2ms\n",
      "Speed: 4.0ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 11.6ms\n",
      "Speed: 6.4ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 26.8ms\n",
      "Speed: 2.5ms preprocess, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 13.1ms\n",
      "Speed: 2.8ms preprocess, 13.1ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 12.1ms\n",
      "Speed: 4.4ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 15.0ms\n",
      "Speed: 3.4ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 11.5ms\n",
      "Speed: 3.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 12.7ms\n",
      "Speed: 3.4ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 12.5ms\n",
      "Speed: 4.5ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 12.5ms\n",
      "Speed: 4.5ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 12.9ms\n",
      "Speed: 3.4ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 13.3ms\n",
      "Speed: 2.4ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 14.0ms\n",
      "Speed: 3.2ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 18.1ms\n",
      "Speed: 8.5ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.2ms\n",
      "Speed: 3.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.7ms\n",
      "Speed: 2.2ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 15.8ms\n",
      "Speed: 3.3ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 14.6ms\n",
      "Speed: 6.1ms preprocess, 14.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 14.6ms\n",
      "Speed: 4.6ms preprocess, 14.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.7ms\n",
      "Speed: 3.6ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.6ms\n",
      "Speed: 4.0ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.5ms\n",
      "Speed: 2.8ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 12.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.2ms\n",
      "Speed: 4.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.6ms\n",
      "Speed: 3.0ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 15.7ms\n",
      "Speed: 2.5ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.4ms\n",
      "Speed: 6.5ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 14.2ms\n",
      "Speed: 2.9ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 21.7ms\n",
      "Speed: 3.0ms preprocess, 21.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.2ms\n",
      "Speed: 4.2ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.3ms\n",
      "Speed: 2.8ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.3ms\n",
      "Speed: 3.3ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.2ms\n",
      "Speed: 3.3ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 5h, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 55.1ms\n",
      "Speed: 2.8ms preprocess, 55.1ms inference, 11.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 20.2ms\n",
      "Speed: 3.0ms preprocess, 20.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 16.5ms\n",
      "Speed: 3.1ms preprocess, 16.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.5ms\n",
      "Speed: 3.2ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 14.8ms\n",
      "Speed: 2.7ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 14.7ms\n",
      "Speed: 2.8ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 13.3ms\n",
      "Speed: 4.4ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 13.4ms\n",
      "Speed: 3.8ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 17.2ms\n",
      "Speed: 2.4ms preprocess, 17.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 14.2ms\n",
      "Speed: 3.2ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 20.1ms\n",
      "Speed: 2.7ms preprocess, 20.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 15.3ms\n",
      "Speed: 2.8ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 14.9ms\n",
      "Speed: 2.8ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 13.2ms\n",
      "Speed: 3.5ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.4ms\n",
      "Speed: 3.6ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 14.8ms\n",
      "Speed: 2.4ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5c, 13.7ms\n",
      "Speed: 2.6ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 14.5ms\n",
      "Speed: 2.9ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 17.2ms\n",
      "Speed: 2.7ms preprocess, 17.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.0ms\n",
      "Speed: 5.6ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 14.6ms\n",
      "Speed: 2.7ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 14.7ms\n",
      "Speed: 2.6ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 14.3ms\n",
      "Speed: 2.7ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 14.5ms\n",
      "Speed: 2.7ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 9.8ms\n",
      "Speed: 3.7ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 21.9ms\n",
      "Speed: 2.6ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.6ms\n",
      "Speed: 4.8ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 12.6ms\n",
      "Speed: 4.1ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 13.0ms\n",
      "Speed: 24.8ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 13.7ms\n",
      "Speed: 2.2ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 14.0ms\n",
      "Speed: 3.8ms preprocess, 14.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 14.0ms\n",
      "Speed: 8.3ms preprocess, 14.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.2ms\n",
      "Speed: 6.2ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 12.8ms\n",
      "Speed: 2.3ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 12.9ms\n",
      "Speed: 3.3ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 14.7ms\n",
      "Speed: 12.5ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 14.3ms\n",
      "Speed: 2.6ms preprocess, 14.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.1ms\n",
      "Speed: 3.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.1ms\n",
      "Speed: 4.4ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.1ms\n",
      "Speed: 3.4ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 11.5ms\n",
      "Speed: 3.1ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 48.2ms\n",
      "Speed: 7.3ms preprocess, 48.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 21.8ms\n",
      "Speed: 3.1ms preprocess, 21.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.4ms\n",
      "Speed: 4.2ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.9ms\n",
      "Speed: 8.3ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 16.8ms\n",
      "Speed: 3.1ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.2ms\n",
      "Speed: 2.6ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.7ms\n",
      "Speed: 4.0ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 14.2ms\n",
      "Speed: 3.0ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 20.9ms\n",
      "Speed: 3.7ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.4ms\n",
      "Speed: 5.4ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.2ms\n",
      "Speed: 3.1ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 20.2ms\n",
      "Speed: 3.2ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.8ms\n",
      "Speed: 3.1ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 14.0ms\n",
      "Speed: 3.1ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.7ms\n",
      "Speed: 3.8ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.0ms\n",
      "Speed: 8.8ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.9ms\n",
      "Speed: 3.0ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.6ms\n",
      "Speed: 3.6ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.4ms\n",
      "Speed: 6.7ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.1ms\n",
      "Speed: 6.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.3ms\n",
      "Speed: 2.9ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 14.1ms\n",
      "Speed: 3.5ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.6ms\n",
      "Speed: 3.6ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.7ms\n",
      "Speed: 3.0ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.5ms\n",
      "Speed: 11.3ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.9ms\n",
      "Speed: 2.8ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.7ms\n",
      "Speed: 2.4ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 13.2ms\n",
      "Speed: 2.9ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.2ms\n",
      "Speed: 7.9ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.8ms\n",
      "Speed: 2.4ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.9ms\n",
      "Speed: 3.2ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.1ms\n",
      "Speed: 2.8ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.2ms\n",
      "Speed: 4.9ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.3ms\n",
      "Speed: 10.1ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 14.2ms\n",
      "Speed: 4.4ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 14.1ms\n",
      "Speed: 2.9ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.5ms\n",
      "Speed: 3.2ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.3ms\n",
      "Speed: 3.6ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.2ms\n",
      "Speed: 10.1ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.8ms\n",
      "Speed: 3.5ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 20.3ms\n",
      "Speed: 4.3ms preprocess, 20.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.2ms\n",
      "Speed: 3.2ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.8ms\n",
      "Speed: 3.1ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.2ms\n",
      "Speed: 6.8ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.6ms\n",
      "Speed: 3.3ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.9ms\n",
      "Speed: 3.8ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.6ms\n",
      "Speed: 3.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.8ms\n",
      "Speed: 4.2ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.0ms\n",
      "Speed: 3.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.5ms\n",
      "Speed: 4.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 69.6ms\n",
      "Speed: 2.8ms preprocess, 69.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.8ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.8ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 9.8ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.5ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.4ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.8ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 4.0ms preprocess, 11.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.6ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.9ms\n",
      "Speed: 18.7ms preprocess, 59.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 5.1ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.9ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 76.0ms\n",
      "Speed: 7.0ms preprocess, 76.0ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.4ms\n",
      "Speed: 2.8ms preprocess, 23.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 3.9ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 4.1ms preprocess, 16.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 3.6ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 19.3ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.5ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 3.0ms preprocess, 14.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 3.4ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.5ms preprocess, 14.5ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.1ms\n",
      "Speed: 26.6ms preprocess, 20.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 2.3ms preprocess, 14.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.3ms preprocess, 14.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.2ms\n",
      "Speed: 2.6ms preprocess, 59.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.2ms\n",
      "Speed: 2.2ms preprocess, 23.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 8.8ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 7.8ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 3.1ms preprocess, 15.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.4ms\n",
      "Speed: 3.1ms preprocess, 16.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 2.4ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.3ms\n",
      "Speed: 92.6ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 8.2ms preprocess, 16.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.8ms\n",
      "Speed: 3.7ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 22.2ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 3.4ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.3ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 4.4ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 3.0ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 3.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 4.4ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.8ms\n",
      "Speed: 7.2ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 4.5ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.0ms\n",
      "Speed: 4.3ms preprocess, 21.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 8.1ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.1ms\n",
      "Speed: 4.2ms preprocess, 20.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 6.3ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.6ms\n",
      "Speed: 5.2ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 11.9ms preprocess, 12.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.9ms preprocess, 15.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 75.2ms\n",
      "Speed: 30.4ms preprocess, 75.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.7ms\n",
      "Speed: 4.0ms preprocess, 17.7ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.0ms\n",
      "Speed: 5.1ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.9ms\n",
      "Speed: 13.0ms preprocess, 17.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 4.7ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 4.3ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 5.0ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 4.1ms preprocess, 11.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 5.5ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.7ms\n",
      "Speed: 2.8ms preprocess, 24.7ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 12.4ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.5ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 4.2ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 11.3ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 11.6ms preprocess, 13.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.8ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.9ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 13.1ms preprocess, 14.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 2.8ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 3.3ms preprocess, 13.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 6.1ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.9ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.5ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 2.9ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.8ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 7.3ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 4.0ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 3.2ms preprocess, 15.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 3.2ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 2.4ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 15.9ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 7.4ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.3ms\n",
      "Speed: 3.5ms preprocess, 20.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.7ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 8.1ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 3.0ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.0ms\n",
      "Speed: 2.9ms preprocess, 21.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 7.1ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.7ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 2.9ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.9ms preprocess, 14.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 11.7ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 2.8ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.5ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.4ms preprocess, 14.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 3.0ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 9.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 4.7ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 3.0ms preprocess, 14.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 18.7ms preprocess, 14.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 3.5ms preprocess, 15.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.6ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 4.6ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 10.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 4.3ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.9ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.4ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.0ms\n",
      "Speed: 2.8ms preprocess, 21.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 5.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.1ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.0ms\n",
      "Speed: 3.1ms preprocess, 22.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 3.4ms preprocess, 15.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.6ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.8ms preprocess, 15.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.5ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 2.3ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 3.1ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 13.1ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 3.2ms preprocess, 15.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.9ms\n",
      "Speed: 3.3ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 3.4ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.9ms\n",
      "Speed: 9.3ms preprocess, 59.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 3.0ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.5ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.3ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.8ms preprocess, 12.4ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.9ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 3.8ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.5ms\n",
      "Speed: 3.1ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 4.0ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.8ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.4ms\n",
      "Speed: 47.4ms preprocess, 19.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 5.3ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 2.6ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 9.3ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 2.3ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.7ms\n",
      "Speed: 2.3ms preprocess, 17.7ms inference, 40.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.4ms\n",
      "Speed: 2.7ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 4.5ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 4.4ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.5ms preprocess, 14.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.5ms preprocess, 14.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 2.5ms preprocess, 17.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 10.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 5.1ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 2.9ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.8ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 59.8ms preprocess, 15.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.4ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 2.7ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.8ms preprocess, 14.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 12.7ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.8ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.2ms\n",
      "Speed: 2.6ms preprocess, 16.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 2.8ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.8ms\n",
      "Speed: 60.6ms preprocess, 18.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.7ms\n",
      "Speed: 3.2ms preprocess, 24.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.7ms preprocess, 14.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 2.6ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 2.9ms preprocess, 14.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 3.1ms preprocess, 14.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.5ms preprocess, 14.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 3.9ms preprocess, 14.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.8ms\n",
      "Speed: 13.5ms preprocess, 15.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 61.7ms\n",
      "Speed: 2.9ms preprocess, 61.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 8.8ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 2.7ms preprocess, 15.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 12.3ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.9ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.6ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.7ms\n",
      "Speed: 16.3ms preprocess, 16.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.3ms\n",
      "Speed: 49.6ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 2.6ms preprocess, 14.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.5ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.7ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.6ms\n",
      "Speed: 2.6ms preprocess, 22.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 3.1ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.2ms\n",
      "Speed: 2.6ms preprocess, 21.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 58.3ms\n",
      "Speed: 2.9ms preprocess, 58.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 2.5ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 3.2ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.4ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 13.6ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.6ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.9ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 62.6ms\n",
      "Speed: 10.4ms preprocess, 62.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.9ms\n",
      "Speed: 7.7ms preprocess, 17.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 3.5ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 3.6ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.6ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.8ms\n",
      "Speed: 2.6ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.8ms\n",
      "Speed: 2.7ms preprocess, 15.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 31.9ms preprocess, 20.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 9.7ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.9ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 3.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.4ms preprocess, 14.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 56.5ms\n",
      "Speed: 6.5ms preprocess, 56.5ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 6.5ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 12.4ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.7ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 10.7ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.4ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 65.6ms\n",
      "Speed: 11.9ms preprocess, 65.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 3.0ms preprocess, 13.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 3.2ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 12.1ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.5ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 3.2ms preprocess, 13.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.4ms\n",
      "Speed: 65.6ms preprocess, 20.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.4ms\n",
      "Speed: 2.6ms preprocess, 19.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.9ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.9ms\n",
      "Speed: 15.7ms preprocess, 19.9ms inference, 39.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 3.0ms preprocess, 21.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.6ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.7ms\n",
      "Speed: 3.0ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.6ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 4.5ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 2.8ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 4.2ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 6.5ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 9.9ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.8ms\n",
      "Speed: 3.4ms preprocess, 20.8ms inference, 34.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 3.6ms preprocess, 17.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.4ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 7.1ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 3.0ms preprocess, 13.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.8ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 3.1ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.7ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 9.7ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 36.9ms\n",
      "Speed: 19.0ms preprocess, 36.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 6.1ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 13.1ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.3ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 3.1ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 3.0ms preprocess, 13.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 3.0ms preprocess, 13.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 2.6ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.5ms\n",
      "Speed: 56.2ms preprocess, 19.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.7ms\n",
      "Speed: 10.7ms preprocess, 18.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.8ms\n",
      "Speed: 3.2ms preprocess, 15.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 2.7ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.4ms\n",
      "Speed: 11.1ms preprocess, 17.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 6.0ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.7ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 2.8ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 3.3ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 63.4ms\n",
      "Speed: 3.0ms preprocess, 63.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 19.2ms\n",
      "Speed: 3.2ms preprocess, 19.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 20.7ms\n",
      "Speed: 3.2ms preprocess, 20.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 16.8ms\n",
      "Speed: 5.0ms preprocess, 16.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.4ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 5.9ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.8ms\n",
      "Speed: 3.0ms preprocess, 15.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 4.1ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.9ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.7ms preprocess, 14.8ms inference, 52.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.0ms\n",
      "Speed: 2.7ms preprocess, 21.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 1.7ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 9.1ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.9ms\n",
      "Speed: 2.6ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 13.9ms\n",
      "Speed: 2.8ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 13.4ms\n",
      "Speed: 2.5ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 14.7ms\n",
      "Speed: 2.4ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 1 Ks, 15.7ms\n",
      "Speed: 3.1ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 13.0ms\n",
      "Speed: 3.7ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 75.5ms\n",
      "Speed: 3.1ms preprocess, 75.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 1 Ks, 16.2ms\n",
      "Speed: 18.0ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 1 Ks, 10.9ms\n",
      "Speed: 4.2ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 1 Ks, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 13.2ms\n",
      "Speed: 3.2ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 12.3ms\n",
      "Speed: 2.9ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 1 Qd, 12.6ms\n",
      "Speed: 3.0ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 16.1ms\n",
      "Speed: 2.7ms preprocess, 16.1ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Qs, 15.7ms\n",
      "Speed: 4.0ms preprocess, 15.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Kd, 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 8h, 12.3ms\n",
      "Speed: 4.1ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8h, 13.8ms\n",
      "Speed: 3.7ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 4d, 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 13.1ms\n",
      "Speed: 2.9ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 11.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 6c, 12.6ms\n",
      "Speed: 6.5ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ks, 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 As, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 13.3ms\n",
      "Speed: 2.7ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Qc, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Ad, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 10.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 BJoker, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8c, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8c, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 7h, 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 3d, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jc, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jc, 12.6ms\n",
      "Speed: 5.8ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5c, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5c, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5c, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5c, 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5c, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5c, 13.0ms\n",
      "Speed: 2.9ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5c, 14.1ms\n",
      "Speed: 2.6ms preprocess, 14.1ms inference, 11.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 13.4ms\n",
      "Speed: 4.0ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9c, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9c, 11.7ms\n",
      "Speed: 8.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 12.6ms\n",
      "Speed: 4.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 12.4ms\n",
      "Speed: 8.5ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9h, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.7ms\n",
      "Speed: 5.9ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.6ms\n",
      "Speed: 3.7ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9h, 12.4ms\n",
      "Speed: 4.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.6ms\n",
      "Speed: 2.3ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.1ms\n",
      "Speed: 3.2ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.9ms\n",
      "Speed: 4.2ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 15.9ms\n",
      "Speed: 3.2ms preprocess, 15.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.2ms\n",
      "Speed: 2.6ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.5ms\n",
      "Speed: 5.3ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.3ms\n",
      "Speed: 15.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.0ms\n",
      "Speed: 2.3ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.9ms\n",
      "Speed: 14.0ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.8ms\n",
      "Speed: 2.1ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.5ms\n",
      "Speed: 2.3ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 19.5ms\n",
      "Speed: 2.4ms preprocess, 19.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.0ms\n",
      "Speed: 6.2ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.6ms\n",
      "Speed: 5.9ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.4ms\n",
      "Speed: 2.7ms preprocess, 14.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.0ms\n",
      "Speed: 2.2ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.8ms\n",
      "Speed: 2.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.7ms\n",
      "Speed: 11.1ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.5ms\n",
      "Speed: 2.8ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 67.7ms\n",
      "Speed: 6.1ms preprocess, 67.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.8ms\n",
      "Speed: 2.3ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.3ms\n",
      "Speed: 4.0ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 17.7ms\n",
      "Speed: 7.7ms preprocess, 17.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.5ms\n",
      "Speed: 1.9ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.0ms\n",
      "Speed: 12.5ms preprocess, 13.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.9ms\n",
      "Speed: 2.6ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 15.3ms\n",
      "Speed: 2.4ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.9ms\n",
      "Speed: 3.1ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 15.4ms\n",
      "Speed: 3.2ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 14.6ms\n",
      "Speed: 2.4ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 15.0ms\n",
      "Speed: 1.9ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.4ms\n",
      "Speed: 4.9ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.6ms\n",
      "Speed: 2.2ms preprocess, 13.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.9ms\n",
      "Speed: 5.1ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 15.1ms\n",
      "Speed: 2.6ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 13.6ms\n",
      "Speed: 3.1ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 10.8ms\n",
      "Speed: 9.9ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9h, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 7h, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 17.1ms\n",
      "Speed: 7.5ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.1ms\n",
      "Speed: 4.7ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.1ms\n",
      "Speed: 2.3ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.8ms\n",
      "Speed: 9.0ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.9ms\n",
      "Speed: 11.0ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.0ms\n",
      "Speed: 2.4ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.3ms\n",
      "Speed: 2.2ms preprocess, 13.3ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 15.4ms\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.3ms\n",
      "Speed: 4.9ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.2ms\n",
      "Speed: 2.1ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.6ms\n",
      "Speed: 2.3ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 16.1ms\n",
      "Speed: 10.0ms preprocess, 16.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 15.5ms\n",
      "Speed: 2.1ms preprocess, 15.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.0ms\n",
      "Speed: 2.2ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.4ms\n",
      "Speed: 1.8ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.3ms\n",
      "Speed: 2.4ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.8ms\n",
      "Speed: 10.6ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.3ms\n",
      "Speed: 2.1ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 23.6ms\n",
      "Speed: 51.0ms preprocess, 23.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.9ms\n",
      "Speed: 6.2ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.3ms\n",
      "Speed: 6.6ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.9ms\n",
      "Speed: 2.2ms preprocess, 14.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.1ms\n",
      "Speed: 2.2ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.8ms\n",
      "Speed: 1.9ms preprocess, 14.8ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.3ms\n",
      "Speed: 2.3ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.4ms\n",
      "Speed: 2.1ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.4ms\n",
      "Speed: 2.2ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.8ms\n",
      "Speed: 2.6ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.2ms\n",
      "Speed: 4.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.2ms\n",
      "Speed: 5.2ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.0ms\n",
      "Speed: 2.8ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 16.2ms\n",
      "Speed: 11.3ms preprocess, 16.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.3ms\n",
      "Speed: 2.2ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.2ms\n",
      "Speed: 1.9ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 24.5ms\n",
      "Speed: 2.6ms preprocess, 24.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 14.2ms\n",
      "Speed: 2.4ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.8ms\n",
      "Speed: 1.9ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.4ms\n",
      "Speed: 13.1ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 61.4ms\n",
      "Speed: 3.6ms preprocess, 61.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 18.3ms\n",
      "Speed: 1.9ms preprocess, 18.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.7ms\n",
      "Speed: 8.9ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.8ms\n",
      "Speed: 2.5ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7d, 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7h, 14.1ms\n",
      "Speed: 11.2ms preprocess, 14.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7h, 13.4ms\n",
      "Speed: 2.2ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.2ms\n",
      "Speed: 2.0ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 37.8ms\n",
      "Speed: 2.4ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 28.2ms\n",
      "Speed: 57.8ms preprocess, 28.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.2ms\n",
      "Speed: 3.8ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.6ms\n",
      "Speed: 4.5ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 12.1ms\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.2ms\n",
      "Speed: 22.0ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.4ms\n",
      "Speed: 2.4ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 12.8ms\n",
      "Speed: 4.2ms preprocess, 12.8ms inference, 13.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 15.3ms\n",
      "Speed: 4.8ms preprocess, 15.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.5ms\n",
      "Speed: 3.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 12.4ms\n",
      "Speed: 2.8ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.1ms\n",
      "Speed: 13.4ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 74.9ms\n",
      "Speed: 2.5ms preprocess, 74.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.2ms\n",
      "Speed: 3.1ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 16.2ms\n",
      "Speed: 10.9ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 12.8ms\n",
      "Speed: 2.4ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jh, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Jh, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Jh, 12.5ms\n",
      "Speed: 12.5ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Jh, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 6s, 1 Jh, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 6s, 1 Jh, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 6s, 1 Jh, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 6s, 1 7d, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 2d, 1 6s, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 2d, 1 2h, 1 6s, 14.3ms\n",
      "Speed: 10.2ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 2d, 1 6s, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 5.9ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 9.9ms preprocess, 13.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.7ms\n",
      "Speed: 10.4ms preprocess, 15.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.7ms\n",
      "Speed: 2.2ms preprocess, 18.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 8c, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 1 8s, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.1ms\n",
      "Speed: 3.1ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 1 8s, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 15.8ms\n",
      "Speed: 10.2ms preprocess, 15.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 15.2ms\n",
      "Speed: 2.3ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.0ms\n",
      "Speed: 2.2ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.4ms\n",
      "Speed: 2.3ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.7ms\n",
      "Speed: 2.2ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.3ms\n",
      "Speed: 3.8ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.8ms\n",
      "Speed: 1.8ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 20.7ms\n",
      "Speed: 2.8ms preprocess, 20.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.0ms\n",
      "Speed: 11.1ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.0ms\n",
      "Speed: 2.8ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 22.1ms\n",
      "Speed: 2.5ms preprocess, 22.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.9ms\n",
      "Speed: 3.4ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.3ms\n",
      "Speed: 7.5ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.1ms\n",
      "Speed: 11.7ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.6ms\n",
      "Speed: 2.8ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.2ms\n",
      "Speed: 3.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.7ms\n",
      "Speed: 11.2ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 69.1ms\n",
      "Speed: 2.5ms preprocess, 69.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.1ms\n",
      "Speed: 12.6ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 4.9ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.4ms\n",
      "Speed: 6.5ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.0ms\n",
      "Speed: 1.9ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.3ms\n",
      "Speed: 15.7ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.6ms\n",
      "Speed: 2.3ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.8ms\n",
      "Speed: 2.3ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.9ms\n",
      "Speed: 5.7ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 21.7ms\n",
      "Speed: 6.0ms preprocess, 21.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.6ms\n",
      "Speed: 3.6ms preprocess, 12.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.9ms\n",
      "Speed: 2.6ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.8ms\n",
      "Speed: 11.3ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 62.4ms\n",
      "Speed: 1.8ms preprocess, 62.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.5ms\n",
      "Speed: 11.7ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.8ms\n",
      "Speed: 10.0ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.2ms\n",
      "Speed: 2.5ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.5ms\n",
      "Speed: 10.8ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.7ms\n",
      "Speed: 3.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 58.5ms\n",
      "Speed: 2.8ms preprocess, 58.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 19.2ms\n",
      "Speed: 2.1ms preprocess, 19.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.5ms\n",
      "Speed: 4.6ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 13.4ms\n",
      "Speed: 12.0ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 13.1ms\n",
      "Speed: 2.3ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Th, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Th, 25.2ms\n",
      "Speed: 26.5ms preprocess, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Th, 14.3ms\n",
      "Speed: 5.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2c, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2c, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2c, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2c, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2c, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2c, 13.3ms\n",
      "Speed: 9.9ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 9c, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9c, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9c, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9c, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9c, 13.6ms\n",
      "Speed: 10.3ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9c, 9.8ms\n",
      "Speed: 1.7ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 7h, 1 9c, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 9c, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 9c, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 9c, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 9c, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 15.8ms\n",
      "Speed: 1.9ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 9c, 88.4ms\n",
      "Speed: 4.9ms preprocess, 88.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 9c, 15.5ms\n",
      "Speed: 3.8ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 25.2ms\n",
      "Speed: 3.4ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 16.7ms\n",
      "Speed: 12.7ms preprocess, 16.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 83.4ms\n",
      "Speed: 3.2ms preprocess, 83.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qd, 14.3ms\n",
      "Speed: 2.7ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qd, 15.9ms\n",
      "Speed: 9.8ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qd, 14.0ms\n",
      "Speed: 4.1ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qd, 13.1ms\n",
      "Speed: 3.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qd, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kd, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kd, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kd, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kd, 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kd, 10.6ms\n",
      "Speed: 3.4ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kd, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kd, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Kd, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Kd, 12.7ms\n",
      "Speed: 2.1ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 1 Qs, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qs, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qs, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qs, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qs, 13.0ms\n",
      "Speed: 1.9ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Qs, 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Qs, 11.7ms\n",
      "Speed: 3.7ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Qs, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Qs, 11.5ms\n",
      "Speed: 3.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qs, 12.9ms\n",
      "Speed: 2.6ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qs, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qs, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 12.3ms\n",
      "Speed: 2.1ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8h, 32.8ms\n",
      "Speed: 45.9ms preprocess, 32.8ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7s, 12.4ms\n",
      "Speed: 7.2ms preprocess, 12.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7s, 12.4ms\n",
      "Speed: 5.4ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7s, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7s, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 7s, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 7s, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 7s, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 7s, 34.4ms\n",
      "Speed: 5.8ms preprocess, 34.4ms inference, 18.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Jd, 14.7ms\n",
      "Speed: 3.8ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jd, 13.3ms\n",
      "Speed: 3.5ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jd, 15.9ms\n",
      "Speed: 3.6ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jd, 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jd, 13.4ms\n",
      "Speed: 3.0ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 12.9ms\n",
      "Speed: 4.1ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 13.7ms\n",
      "Speed: 2.6ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 14.6ms\n",
      "Speed: 3.2ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 13.2ms\n",
      "Speed: 3.7ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 14.1ms\n",
      "Speed: 2.4ms preprocess, 14.1ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 178.9ms\n",
      "Speed: 10.7ms preprocess, 178.9ms inference, 20.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 12.7ms\n",
      "Speed: 3.8ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Kh, 22.3ms\n",
      "Speed: 4.5ms preprocess, 22.3ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Kh, 18.4ms\n",
      "Speed: 5.3ms preprocess, 18.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Kh, 20.2ms\n",
      "Speed: 2.6ms preprocess, 20.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jh, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jh, 10.7ms\n",
      "Speed: 4.8ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jh, 10.8ms\n",
      "Speed: 1.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jh, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jh, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ad, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ad, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ad, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ad, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Kd, 10.7ms\n",
      "Speed: 1.7ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 27.7ms\n",
      "Speed: 2.1ms preprocess, 27.7ms inference, 10.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 17.0ms\n",
      "Speed: 7.8ms preprocess, 17.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 13.3ms\n",
      "Speed: 2.3ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 13.4ms\n",
      "Speed: 2.4ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 22.9ms\n",
      "Speed: 2.3ms preprocess, 22.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ah, 14.3ms\n",
      "Speed: 3.8ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ah, 14.5ms\n",
      "Speed: 1.8ms preprocess, 14.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ah, 14.3ms\n",
      "Speed: 2.4ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ah, 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 14.4ms\n",
      "Speed: 10.8ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 13.8ms\n",
      "Speed: 2.2ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 8d, 10.4ms\n",
      "Speed: 5.4ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 13.7ms\n",
      "Speed: 1.8ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 14.1ms\n",
      "Speed: 2.1ms preprocess, 14.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 13.3ms\n",
      "Speed: 2.1ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 15.9ms\n",
      "Speed: 8.0ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 15.7ms\n",
      "Speed: 3.1ms preprocess, 15.7ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6h, 13.8ms\n",
      "Speed: 3.3ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 13.2ms\n",
      "Speed: 3.2ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 13.1ms\n",
      "Speed: 2.8ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 21.0ms\n",
      "Speed: 7.3ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kc, 11.5ms\n",
      "Speed: 4.6ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5h, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5h, 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5h, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5h, 12.4ms\n",
      "Speed: 14.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 11.1ms\n",
      "Speed: 3.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 13.9ms\n",
      "Speed: 6.8ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 12.6ms\n",
      "Speed: 2.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4s, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 28.3ms\n",
      "Speed: 3.2ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 13.5ms\n",
      "Speed: 3.1ms preprocess, 13.5ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 10.6ms\n",
      "Speed: 5.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qc, 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qc, 12.9ms\n",
      "Speed: 3.2ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qc, 13.8ms\n",
      "Speed: 7.7ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qc, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qc, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qc, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qc, 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qc, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 16.6ms\n",
      "Speed: 8.4ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 13.8ms\n",
      "Speed: 2.9ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 19.9ms\n",
      "Speed: 5.9ms preprocess, 19.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 13.4ms\n",
      "Speed: 3.0ms preprocess, 13.4ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Js, 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.3ms\n",
      "Speed: 5.1ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 13.3ms\n",
      "Speed: 2.5ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 14.2ms\n",
      "Speed: 12.0ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 13.3ms\n",
      "Speed: 3.6ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 14.8ms\n",
      "Speed: 9.0ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 6c, 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 12.7ms\n",
      "Speed: 7.8ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 39.8ms\n",
      "Speed: 14.8ms preprocess, 39.8ms inference, 13.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 19.7ms\n",
      "Speed: 2.3ms preprocess, 19.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 15.7ms\n",
      "Speed: 11.1ms preprocess, 15.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 13.0ms\n",
      "Speed: 2.9ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jc, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jc, 22.2ms\n",
      "Speed: 2.3ms preprocess, 22.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 12.8ms\n",
      "Speed: 3.1ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 15.7ms\n",
      "Speed: 2.4ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 16.5ms\n",
      "Speed: 2.9ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 13.3ms\n",
      "Speed: 12.3ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 14.8ms\n",
      "Speed: 10.8ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9h, 10.9ms\n",
      "Speed: 3.7ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 15.5ms\n",
      "Speed: 13.2ms preprocess, 15.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 12.0ms\n",
      "Speed: 7.7ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 19.0ms\n",
      "Speed: 2.3ms preprocess, 19.0ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 21.0ms\n",
      "Speed: 7.6ms preprocess, 21.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 13.1ms\n",
      "Speed: 2.4ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 13.2ms\n",
      "Speed: 2.6ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 9.8ms\n",
      "Speed: 3.6ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 15.3ms\n",
      "Speed: 11.2ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 62.1ms\n",
      "Speed: 2.6ms preprocess, 62.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 9.9ms\n",
      "Speed: 6.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 12.9ms\n",
      "Speed: 8.0ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 12.7ms\n",
      "Speed: 2.8ms preprocess, 12.7ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 12.7ms\n",
      "Speed: 4.4ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 20.5ms\n",
      "Speed: 3.3ms preprocess, 20.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 13.7ms\n",
      "Speed: 2.1ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 67.4ms\n",
      "Speed: 2.4ms preprocess, 67.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 15.2ms\n",
      "Speed: 2.8ms preprocess, 15.2ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 10.6ms\n",
      "Speed: 4.1ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6d, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 21.2ms\n",
      "Speed: 7.2ms preprocess, 21.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 45.0ms\n",
      "Speed: 37.3ms preprocess, 45.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.7ms\n",
      "Speed: 3.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.7ms\n",
      "Speed: 15.1ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 11.9ms\n",
      "Speed: 3.3ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 12.7ms\n",
      "Speed: 4.3ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 12.5ms\n",
      "Speed: 3.5ms preprocess, 12.5ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 15.8ms\n",
      "Speed: 41.9ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 19.4ms\n",
      "Speed: 3.0ms preprocess, 19.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 13.8ms\n",
      "Speed: 3.4ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 12.3ms\n",
      "Speed: 3.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 13.7ms\n",
      "Speed: 12.3ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 13.4ms\n",
      "Speed: 2.3ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4d, 30.7ms\n",
      "Speed: 53.8ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.4ms\n",
      "Speed: 3.4ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.1ms\n",
      "Speed: 3.3ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 19.2ms\n",
      "Speed: 3.7ms preprocess, 19.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 14.0ms\n",
      "Speed: 1.9ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 13.7ms\n",
      "Speed: 59.4ms preprocess, 13.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 13.5ms\n",
      "Speed: 2.3ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.1ms\n",
      "Speed: 3.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 12.8ms\n",
      "Speed: 7.2ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.6ms\n",
      "Speed: 3.4ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 12.9ms\n",
      "Speed: 11.3ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 65.1ms\n",
      "Speed: 2.6ms preprocess, 65.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 13.5ms\n",
      "Speed: 2.2ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 25.2ms\n",
      "Speed: 3.2ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 12.8ms\n",
      "Speed: 1.9ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qh, 13.4ms\n",
      "Speed: 4.5ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 13.7ms\n",
      "Speed: 50.0ms preprocess, 13.7ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 19.5ms\n",
      "Speed: 2.2ms preprocess, 19.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 13.9ms\n",
      "Speed: 2.5ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 13.9ms\n",
      "Speed: 1.9ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.9ms\n",
      "Speed: 16.7ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 26.9ms\n",
      "Speed: 50.1ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.2ms\n",
      "Speed: 6.1ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 11.2ms preprocess, 14.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 57.7ms\n",
      "Speed: 3.3ms preprocess, 57.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 9.6ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 10.3ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.6ms\n",
      "Speed: 2.6ms preprocess, 18.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 3.5ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 4.1ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 6.2ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 10.9ms preprocess, 15.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.3ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.9ms\n",
      "Speed: 36.5ms preprocess, 28.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 2.1ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.3ms\n",
      "Speed: 7.7ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.6ms\n",
      "Speed: 11.4ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 45.2ms\n",
      "Speed: 12.9ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 8.4ms preprocess, 13.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 5.4ms preprocess, 19.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.9ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 7.8ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 14.8ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 39.0ms\n",
      "Speed: 43.5ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 2.9ms preprocess, 17.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.7ms\n",
      "Speed: 4.8ms preprocess, 18.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 3.0ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.9ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 3.3ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 12.0ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 65.4ms\n",
      "Speed: 2.9ms preprocess, 65.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.2ms\n",
      "Speed: 2.1ms preprocess, 19.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.3ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 15.7ms preprocess, 13.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 3.3ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.1ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.9ms preprocess, 14.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 5.9ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.7ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.3ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.7ms\n",
      "Speed: 4.0ms preprocess, 26.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 4.2ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 12.4ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 76.5ms\n",
      "Speed: 3.2ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 3.4ms preprocess, 12.9ms inference, 11.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 2.4ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.6ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 10.7ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 7.6ms preprocess, 13.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 1.8ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.7ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 77.0ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 2.3ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 4.0ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 11.4ms\n",
      "Speed: 4.4ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 19.0ms\n",
      "Speed: 2.5ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 13.6ms\n",
      "Speed: 3.3ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 15.2ms\n",
      "Speed: 10.9ms preprocess, 15.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 12.3ms\n",
      "Speed: 3.6ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Ks, 14.7ms\n",
      "Speed: 9.5ms preprocess, 14.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 20.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 18.4ms\n",
      "Speed: 26.5ms preprocess, 18.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.0ms\n",
      "Speed: 10.7ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.7ms\n",
      "Speed: 2.4ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.0ms\n",
      "Speed: 11.5ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 29.9ms\n",
      "Speed: 52.4ms preprocess, 29.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.5ms\n",
      "Speed: 7.5ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 3.2ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.9ms\n",
      "Speed: 10.3ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 4.1ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 23.4ms\n",
      "Speed: 2.6ms preprocess, 23.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 52.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 25.8ms\n",
      "Speed: 3.7ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 17.0ms\n",
      "Speed: 2.4ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 12.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.2ms\n",
      "Speed: 3.6ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.8ms\n",
      "Speed: 3.0ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.5ms\n",
      "Speed: 2.9ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.9ms\n",
      "Speed: 4.7ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.6ms\n",
      "Speed: 5.2ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.9ms\n",
      "Speed: 4.4ms preprocess, 12.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.5ms\n",
      "Speed: 67.5ms preprocess, 13.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.7ms\n",
      "Speed: 3.2ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 27.2ms\n",
      "Speed: 4.1ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.5ms\n",
      "Speed: 1.9ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.7ms\n",
      "Speed: 1.9ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.6ms\n",
      "Speed: 2.1ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 46.6ms\n",
      "Speed: 2.6ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 23.2ms\n",
      "Speed: 72.7ms preprocess, 23.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.3ms\n",
      "Speed: 9.9ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 24.7ms\n",
      "Speed: 2.7ms preprocess, 24.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.0ms\n",
      "Speed: 3.6ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 35.1ms\n",
      "Speed: 35.8ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.8ms\n",
      "Speed: 9.4ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.7ms\n",
      "Speed: 2.5ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 17.0ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.3ms\n",
      "Speed: 5.6ms preprocess, 14.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.6ms\n",
      "Speed: 4.7ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 69.1ms\n",
      "Speed: 12.5ms preprocess, 69.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 24.1ms\n",
      "Speed: 2.9ms preprocess, 24.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 3.9ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.7ms\n",
      "Speed: 12.3ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.5ms\n",
      "Speed: 4.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 16.6ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 18.7ms\n",
      "Speed: 21.2ms preprocess, 18.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.9ms\n",
      "Speed: 2.9ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.7ms\n",
      "Speed: 4.4ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.9ms\n",
      "Speed: 4.0ms preprocess, 10.9ms inference, 11.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 4.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 29.2ms\n",
      "Speed: 6.8ms preprocess, 29.2ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 19.1ms\n",
      "Speed: 34.1ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.0ms\n",
      "Speed: 2.4ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.5ms\n",
      "Speed: 10.2ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.7ms\n",
      "Speed: 3.7ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.3ms\n",
      "Speed: 14.2ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 31.7ms\n",
      "Speed: 45.8ms preprocess, 31.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 20.2ms\n",
      "Speed: 13.0ms preprocess, 20.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 1.9ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 25.5ms\n",
      "Speed: 2.7ms preprocess, 25.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.4ms\n",
      "Speed: 2.9ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.6ms\n",
      "Speed: 3.4ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.5ms\n",
      "Speed: 18.5ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.5ms\n",
      "Speed: 3.6ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 18.7ms\n",
      "Speed: 2.7ms preprocess, 18.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 17.9ms\n",
      "Speed: 15.0ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 83.3ms\n",
      "Speed: 3.4ms preprocess, 83.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.2ms\n",
      "Speed: 3.9ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 1.8ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.4ms\n",
      "Speed: 4.6ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.7ms\n",
      "Speed: 1.9ms preprocess, 14.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.9ms\n",
      "Speed: 3.5ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.8ms\n",
      "Speed: 1.9ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.1ms\n",
      "Speed: 5.4ms preprocess, 15.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 24.6ms\n",
      "Speed: 2.7ms preprocess, 24.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.1ms\n",
      "Speed: 3.4ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.6ms\n",
      "Speed: 2.2ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 22.3ms\n",
      "Speed: 2.2ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.9ms\n",
      "Speed: 1.8ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.9ms\n",
      "Speed: 10.7ms preprocess, 15.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 6.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.3ms\n",
      "Speed: 12.3ms preprocess, 14.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.4ms\n",
      "Speed: 11.4ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.1ms\n",
      "Speed: 3.9ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 4.2ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 4.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.1ms\n",
      "Speed: 10.2ms preprocess, 15.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 3.8ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.6ms\n",
      "Speed: 3.1ms preprocess, 13.6ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 5.8ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 3.4ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.1ms\n",
      "Speed: 3.1ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 36.4ms\n",
      "Speed: 2.6ms preprocess, 36.4ms inference, 14.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.2ms\n",
      "Speed: 7.9ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.9ms\n",
      "Speed: 3.3ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.6ms\n",
      "Speed: 7.5ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.1ms\n",
      "Speed: 3.6ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 53.8ms\n",
      "Speed: 37.3ms preprocess, 53.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 25.9ms\n",
      "Speed: 3.2ms preprocess, 25.9ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.9ms\n",
      "Speed: 3.8ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.9ms\n",
      "Speed: 5.2ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 17.8ms\n",
      "Speed: 5.6ms preprocess, 17.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 17.7ms\n",
      "Speed: 12.3ms preprocess, 17.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 16.9ms\n",
      "Speed: 11.6ms preprocess, 16.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.7ms\n",
      "Speed: 7.1ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 5.6ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.4ms\n",
      "Speed: 4.1ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 17.0ms\n",
      "Speed: 5.6ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.4ms\n",
      "Speed: 2.8ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.6ms\n",
      "Speed: 7.2ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.3ms\n",
      "Speed: 9.4ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.1ms\n",
      "Speed: 3.3ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.9ms\n",
      "Speed: 3.7ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.1ms\n",
      "Speed: 16.0ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 3.4ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.9ms\n",
      "Speed: 3.9ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 24.2ms\n",
      "Speed: 2.9ms preprocess, 24.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.6ms\n",
      "Speed: 3.7ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.3ms\n",
      "Speed: 3.5ms preprocess, 13.3ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 17.7ms\n",
      "Speed: 2.8ms preprocess, 17.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 22.3ms\n",
      "Speed: 4.4ms preprocess, 22.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.2ms\n",
      "Speed: 3.1ms preprocess, 15.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.7ms\n",
      "Speed: 4.3ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 23.0ms\n",
      "Speed: 2.5ms preprocess, 23.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.1ms\n",
      "Speed: 2.7ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.3ms\n",
      "Speed: 2.9ms preprocess, 14.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.7ms\n",
      "Speed: 6.5ms preprocess, 14.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 26.1ms\n",
      "Speed: 7.5ms preprocess, 26.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.9ms\n",
      "Speed: 5.0ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.7ms\n",
      "Speed: 5.6ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.3ms\n",
      "Speed: 3.9ms preprocess, 13.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 23.5ms\n",
      "Speed: 3.7ms preprocess, 23.5ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.6ms\n",
      "Speed: 4.1ms preprocess, 15.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.3ms\n",
      "Speed: 4.6ms preprocess, 13.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.5ms\n",
      "Speed: 5.4ms preprocess, 12.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 22.8ms\n",
      "Speed: 3.9ms preprocess, 22.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 13.1ms\n",
      "Speed: 3.3ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.1ms\n",
      "Speed: 3.5ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 35.3ms\n",
      "Speed: 9.4ms preprocess, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.5ms\n",
      "Speed: 7.1ms preprocess, 12.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 16.8ms\n",
      "Speed: 8.2ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 51.5ms\n",
      "Speed: 6.4ms preprocess, 51.5ms inference, 47.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 23.8ms\n",
      "Speed: 11.2ms preprocess, 23.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 15.2ms\n",
      "Speed: 16.1ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.9ms\n",
      "Speed: 4.0ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 23.3ms\n",
      "Speed: 2.8ms preprocess, 23.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.6ms\n",
      "Speed: 2.1ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.6ms\n",
      "Speed: 4.1ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 14.5ms\n",
      "Speed: 3.5ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 17.7ms\n",
      "Speed: 3.6ms preprocess, 17.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.4ms\n",
      "Speed: 3.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ks, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 16.2ms\n",
      "Speed: 2.9ms preprocess, 16.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 12.0ms\n",
      "Speed: 3.5ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Jc, 9.7ms\n",
      "Speed: 1.9ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Jc, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qd, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qd, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qd, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qd, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qd, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qd, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Qd, 14.2ms\n",
      "Speed: 2.3ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Qd, 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Qd, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Qd, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7d, 12.9ms\n",
      "Speed: 2.1ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7d, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7d, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7d, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 9d, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 6s, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 6s, 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 6s, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 6s, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 6s, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7s, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7s, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7s, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7s, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7s, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7s, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 3s, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 3s, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 12.9ms\n",
      "Speed: 2.1ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9h, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9h, 16.6ms\n",
      "Speed: 1.9ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9h, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9h, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9h, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Ac, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Ac, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Ac, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Ac, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ac, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ac, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ac, 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 As, 10.8ms\n",
      "Speed: 2.1ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 9c, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 9c, 11.8ms\n",
      "Speed: 1.9ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9c, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9c, 12.6ms\n",
      "Speed: 1.9ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9c, 60.0ms\n",
      "Speed: 1.8ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9c, 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 9c, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4h, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6d, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6d, 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6d, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6d, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6d, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6d, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6d, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6d, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Kd, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4d, 11.4ms\n",
      "Speed: 1.7ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4d, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4d, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7h, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7h, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7h, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7h, 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 As, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 As, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 As, 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 As, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 As, 25.2ms\n",
      "Speed: 13.7ms preprocess, 25.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 As, 61.8ms\n",
      "Speed: 9.7ms preprocess, 61.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 14.6ms\n",
      "Speed: 3.0ms preprocess, 14.6ms inference, 11.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 35.7ms\n",
      "Speed: 16.8ms preprocess, 35.7ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 16.3ms\n",
      "Speed: 12.2ms preprocess, 16.3ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 20.1ms\n",
      "Speed: 16.0ms preprocess, 20.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 15.7ms\n",
      "Speed: 20.1ms preprocess, 15.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 80.9ms\n",
      "Speed: 6.7ms preprocess, 80.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 21.4ms\n",
      "Speed: 14.6ms preprocess, 21.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 12.6ms\n",
      "Speed: 12.0ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Jd, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Qd, 1 Qs, 13.2ms\n",
      "Speed: 3.4ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Qs, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qs, 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qs, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qs, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qs, 20.9ms\n",
      "Speed: 2.5ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qs, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qs, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qs, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qs, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qs, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qs, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qs, 10.7ms\n",
      "Speed: 5.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qs, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qs, 16.7ms\n",
      "Speed: 5.5ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Jh, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Jh, 1 Kh, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 11.2ms\n",
      "Speed: 3.3ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 13.6ms\n",
      "Speed: 2.6ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 14.9ms\n",
      "Speed: 2.8ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 13.8ms\n",
      "Speed: 3.2ms preprocess, 13.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 12.8ms\n",
      "Speed: 5.8ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 8c, 12.5ms\n",
      "Speed: 3.0ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8c, 14.6ms\n",
      "Speed: 3.7ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8c, 11.4ms\n",
      "Speed: 3.7ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8c, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8c, 15.6ms\n",
      "Speed: 10.0ms preprocess, 15.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8c, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8c, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8c, 1 8h, 13.1ms\n",
      "Speed: 3.1ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 15.5ms\n",
      "Speed: 14.3ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 13.5ms\n",
      "Speed: 6.0ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 14.1ms\n",
      "Speed: 12.4ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 9.7ms\n",
      "Speed: 2.9ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 22.9ms\n",
      "Speed: 2.8ms preprocess, 22.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 10.2ms\n",
      "Speed: 4.4ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 11.2ms\n",
      "Speed: 3.4ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 20.8ms\n",
      "Speed: 11.8ms preprocess, 20.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 12.7ms\n",
      "Speed: 3.5ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 12.9ms\n",
      "Speed: 2.9ms preprocess, 12.9ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 12.0ms\n",
      "Speed: 4.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Qc, 10.3ms\n",
      "Speed: 4.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5h, 11.5ms\n",
      "Speed: 3.4ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5h, 11.3ms\n",
      "Speed: 5.6ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 5h, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 14.4ms\n",
      "Speed: 12.9ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 10.2ms\n",
      "Speed: 3.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Qh, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qh, 14.5ms\n",
      "Speed: 10.2ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qh, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qh, 11.9ms\n",
      "Speed: 2.1ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qh, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qh, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qh, 23.6ms\n",
      "Speed: 2.5ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 13.8ms\n",
      "Speed: 2.9ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 14.1ms\n",
      "Speed: 2.7ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 10.5ms\n",
      "Speed: 15.3ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 10.3ms\n",
      "Speed: 3.8ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 11.0ms\n",
      "Speed: 3.3ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6c, 39.1ms\n",
      "Speed: 2.9ms preprocess, 39.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Ah, 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Ah, 13.0ms\n",
      "Speed: 6.0ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Ah, 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Ah, 13.6ms\n",
      "Speed: 3.2ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 13.6ms\n",
      "Speed: 2.9ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 24.9ms\n",
      "Speed: 9.3ms preprocess, 24.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 20.4ms\n",
      "Speed: 10.2ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 13.8ms\n",
      "Speed: 6.4ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 12.3ms\n",
      "Speed: 7.6ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 13.8ms\n",
      "Speed: 2.8ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 13.6ms\n",
      "Speed: 3.9ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 11.2ms\n",
      "Speed: 3.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 15.5ms\n",
      "Speed: 13.9ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 13.6ms\n",
      "Speed: 3.5ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 11.7ms\n",
      "Speed: 4.1ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 12.6ms\n",
      "Speed: 11.9ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 13.6ms\n",
      "Speed: 2.8ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Jd, 12.4ms\n",
      "Speed: 3.8ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 12.1ms\n",
      "Speed: 3.2ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 12.0ms\n",
      "Speed: 7.1ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 10.7ms\n",
      "Speed: 5.2ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 13.2ms\n",
      "Speed: 14.9ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 12.1ms\n",
      "Speed: 4.7ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 14.1ms\n",
      "Speed: 2.9ms preprocess, 14.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 10.8ms\n",
      "Speed: 10.2ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 11.6ms\n",
      "Speed: 4.0ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 12.5ms\n",
      "Speed: 6.3ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 13.5ms\n",
      "Speed: 4.7ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 13.1ms\n",
      "Speed: 3.5ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 14.6ms\n",
      "Speed: 2.7ms preprocess, 14.6ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 9.9ms\n",
      "Speed: 3.3ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8d, 14.3ms\n",
      "Speed: 2.4ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8d, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8d, 21.0ms\n",
      "Speed: 2.8ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ts, 1 8d, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 13.0ms\n",
      "Speed: 2.8ms preprocess, 13.0ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 13.7ms\n",
      "Speed: 2.3ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 11.5ms\n",
      "Speed: 5.6ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 10.4ms\n",
      "Speed: 3.8ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 13.7ms\n",
      "Speed: 12.2ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 12.1ms\n",
      "Speed: 3.3ms preprocess, 12.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 10.1ms\n",
      "Speed: 3.8ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8d, 13.7ms\n",
      "Speed: 14.8ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.8ms\n",
      "Speed: 2.9ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.6ms\n",
      "Speed: 3.4ms preprocess, 12.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 15.0ms\n",
      "Speed: 11.6ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 24.7ms\n",
      "Speed: 2.8ms preprocess, 24.7ms inference, 37.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 23.4ms\n",
      "Speed: 2.7ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 14.1ms\n",
      "Speed: 2.8ms preprocess, 14.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 14.4ms\n",
      "Speed: 11.6ms preprocess, 14.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 15.4ms\n",
      "Speed: 5.8ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 20.6ms\n",
      "Speed: 2.4ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.5ms\n",
      "Speed: 4.4ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.4ms\n",
      "Speed: 3.9ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.3ms\n",
      "Speed: 3.8ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.7ms\n",
      "Speed: 17.7ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 13.4ms\n",
      "Speed: 3.0ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 26.7ms\n",
      "Speed: 9.5ms preprocess, 26.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.3ms\n",
      "Speed: 3.5ms preprocess, 12.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 14.7ms\n",
      "Speed: 3.0ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.3ms\n",
      "Speed: 3.6ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.8ms\n",
      "Speed: 13.8ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 11.2ms\n",
      "Speed: 3.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8s, 10.2ms\n",
      "Speed: 3.9ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 16.4ms\n",
      "Speed: 11.7ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 11.5ms\n",
      "Speed: 5.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 16.3ms\n",
      "Speed: 13.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 22.9ms\n",
      "Speed: 3.6ms preprocess, 22.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 15.2ms\n",
      "Speed: 3.4ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 13.6ms\n",
      "Speed: 3.1ms preprocess, 13.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 14.9ms\n",
      "Speed: 12.4ms preprocess, 14.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 14.0ms\n",
      "Speed: 3.3ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kh, 10.7ms\n",
      "Speed: 3.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 13.1ms\n",
      "Speed: 3.6ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 14.9ms\n",
      "Speed: 10.2ms preprocess, 14.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.8ms\n",
      "Speed: 3.4ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 13.2ms\n",
      "Speed: 3.0ms preprocess, 13.2ms inference, 15.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 22.6ms\n",
      "Speed: 5.7ms preprocess, 22.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 22.6ms\n",
      "Speed: 3.6ms preprocess, 22.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.0ms\n",
      "Speed: 3.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 12.6ms\n",
      "Speed: 3.4ms preprocess, 12.6ms inference, 48.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 30.6ms\n",
      "Speed: 2.5ms preprocess, 30.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 14.1ms\n",
      "Speed: 12.3ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.8ms\n",
      "Speed: 3.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 13.1ms\n",
      "Speed: 11.7ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 2h, 10.2ms\n",
      "Speed: 3.1ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 13.6ms\n",
      "Speed: 2.9ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 18.0ms\n",
      "Speed: 11.9ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.0ms\n",
      "Speed: 3.7ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 14.3ms\n",
      "Speed: 12.5ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.5ms\n",
      "Speed: 3.4ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.3ms\n",
      "Speed: 7.4ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 12.9ms\n",
      "Speed: 3.5ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 14.2ms\n",
      "Speed: 9.9ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 10.9ms\n",
      "Speed: 3.5ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.5ms\n",
      "Speed: 3.4ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.7ms\n",
      "Speed: 12.8ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 22.9ms\n",
      "Speed: 6.3ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.7ms\n",
      "Speed: 3.2ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.3ms\n",
      "Speed: 4.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.0ms\n",
      "Speed: 3.9ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 16.2ms\n",
      "Speed: 13.3ms preprocess, 16.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.2ms\n",
      "Speed: 3.7ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 9.9ms\n",
      "Speed: 3.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 19.6ms\n",
      "Speed: 5.0ms preprocess, 19.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 13.7ms\n",
      "Speed: 3.4ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.6ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 3.6ms preprocess, 19.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.3ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 3.0ms preprocess, 20.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.3ms\n",
      "Speed: 3.4ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.7ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 14.1ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 7.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.3ms\n",
      "Speed: 2.9ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.6ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.5ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 12.3ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 2.7ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 11.7ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 4.5ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 4.4ms preprocess, 13.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.7ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 3.1ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 13.5ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 3.5ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 10.9ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 5.2ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.8ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.7ms\n",
      "Speed: 2.6ms preprocess, 19.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.0ms\n",
      "Speed: 3.1ms preprocess, 23.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 6.0ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 4.4ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 11.7ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.9ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 3.6ms preprocess, 20.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 6.2ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.0ms\n",
      "Speed: 2.6ms preprocess, 28.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.7ms\n",
      "Speed: 29.5ms preprocess, 21.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 12.2ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 3.0ms preprocess, 15.4ms inference, 9.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 4.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.4ms preprocess, 11.9ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.6ms\n",
      "Speed: 3.5ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 4.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.1ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.7ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 12.3ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 1.9ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 10.0ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 33.8ms\n",
      "Speed: 8.1ms preprocess, 33.8ms inference, 14.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 3.1ms preprocess, 13.5ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 5.1ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 6.1ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 64.9ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 3.3ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.8ms\n",
      "Speed: 3.0ms preprocess, 18.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.7ms\n",
      "Speed: 6.8ms preprocess, 59.7ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 4.4ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 3.1ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.1ms\n",
      "Speed: 2.6ms preprocess, 18.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 12.1ms preprocess, 15.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 60.4ms\n",
      "Speed: 2.8ms preprocess, 60.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 4.7ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 15.4ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.4ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 11.3ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 66.2ms preprocess, 19.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 2.5ms preprocess, 17.1ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 4.8ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.9ms\n",
      "Speed: 3.1ms preprocess, 32.9ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.6ms\n",
      "Speed: 2.7ms preprocess, 17.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 3.1ms preprocess, 22.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.9ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 4.6ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.8ms\n",
      "Speed: 52.1ms preprocess, 19.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.6ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.1ms\n",
      "Speed: 2.3ms preprocess, 22.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 6.9ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.1ms\n",
      "Speed: 3.3ms preprocess, 20.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 6.2ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 58.6ms\n",
      "Speed: 13.2ms preprocess, 58.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.9ms\n",
      "Speed: 3.2ms preprocess, 26.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.5ms\n",
      "Speed: 3.2ms preprocess, 22.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.8ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.7ms\n",
      "Speed: 63.8ms preprocess, 17.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.8ms\n",
      "Speed: 9.1ms preprocess, 18.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 10.3ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.4ms\n",
      "Speed: 61.1ms preprocess, 18.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.3ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 11.8ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.8ms\n",
      "Speed: 3.0ms preprocess, 16.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.1ms\n",
      "Speed: 19.4ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.3ms\n",
      "Speed: 12.6ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.7ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.5ms\n",
      "Speed: 2.7ms preprocess, 21.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.5ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 4.1ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.2ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 60.2ms preprocess, 14.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.7ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.0ms\n",
      "Speed: 8.4ms preprocess, 17.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 65.7ms\n",
      "Speed: 2.9ms preprocess, 65.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.2ms\n",
      "Speed: 2.1ms preprocess, 16.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 3.1ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.7ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.8ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 9.4ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.9ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 3.1ms preprocess, 23.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.6ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 36.3ms\n",
      "Speed: 2.5ms preprocess, 36.3ms inference, 32.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.4ms\n",
      "Speed: 2.3ms preprocess, 18.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.9ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.3ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.4ms\n",
      "Speed: 2.7ms preprocess, 19.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.3ms\n",
      "Speed: 3.1ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 37.3ms\n",
      "Speed: 16.5ms preprocess, 37.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.4ms\n",
      "Speed: 2.1ms preprocess, 26.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 4.8ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.9ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 11.8ms preprocess, 14.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.5ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 4.8ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 42.5ms\n",
      "Speed: 6.4ms preprocess, 42.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 8.2ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 15.3ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 4.1ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.8ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 10.8ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 6.2ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.3ms preprocess, 11.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.7ms\n",
      "Speed: 2.1ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 77.6ms\n",
      "Speed: 2.8ms preprocess, 77.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.7ms\n",
      "Speed: 2.1ms preprocess, 26.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.1ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 3.0ms preprocess, 13.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 67.5ms\n",
      "Speed: 2.8ms preprocess, 67.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 23.0ms\n",
      "Speed: 3.1ms preprocess, 23.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 24.4ms\n",
      "Speed: 2.8ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.7ms\n",
      "Speed: 3.2ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 27.5ms\n",
      "Speed: 43.2ms preprocess, 27.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 19.3ms\n",
      "Speed: 2.5ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.2ms\n",
      "Speed: 2.9ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 14.7ms\n",
      "Speed: 14.1ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 39.9ms\n",
      "Speed: 2.6ms preprocess, 39.9ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 15.1ms\n",
      "Speed: 2.4ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.6ms\n",
      "Speed: 11.4ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.4ms\n",
      "Speed: 2.1ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.4ms\n",
      "Speed: 3.4ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 23.5ms\n",
      "Speed: 3.3ms preprocess, 23.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.3ms\n",
      "Speed: 7.3ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.8ms\n",
      "Speed: 3.1ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.6ms\n",
      "Speed: 4.3ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.6ms\n",
      "Speed: 14.1ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 54.5ms\n",
      "Speed: 2.9ms preprocess, 54.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 27.3ms\n",
      "Speed: 2.7ms preprocess, 27.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.6ms\n",
      "Speed: 8.4ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.4ms\n",
      "Speed: 3.5ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 15.8ms\n",
      "Speed: 11.8ms preprocess, 15.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.1ms\n",
      "Speed: 3.6ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 14.3ms\n",
      "Speed: 8.1ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.5ms\n",
      "Speed: 2.6ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 17.8ms\n",
      "Speed: 10.9ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.1ms\n",
      "Speed: 4.3ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.8ms\n",
      "Speed: 12.2ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 66.5ms\n",
      "Speed: 2.8ms preprocess, 66.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.2ms\n",
      "Speed: 3.6ms preprocess, 11.2ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.0ms\n",
      "Speed: 3.8ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 20.5ms\n",
      "Speed: 2.7ms preprocess, 20.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.9ms\n",
      "Speed: 2.1ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.0ms\n",
      "Speed: 6.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 9.7ms\n",
      "Speed: 3.8ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 33.2ms\n",
      "Speed: 37.3ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.3ms\n",
      "Speed: 9.3ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 21.9ms\n",
      "Speed: 2.3ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.0ms\n",
      "Speed: 2.8ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.0ms\n",
      "Speed: 1.9ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.2ms\n",
      "Speed: 4.9ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 26.6ms\n",
      "Speed: 56.4ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.3ms\n",
      "Speed: 3.9ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 20.9ms\n",
      "Speed: 2.8ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 56.1ms\n",
      "Speed: 13.7ms preprocess, 56.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 21.7ms\n",
      "Speed: 2.5ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 15.1ms\n",
      "Speed: 2.9ms preprocess, 15.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 21.7ms\n",
      "Speed: 3.0ms preprocess, 21.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 14.0ms\n",
      "Speed: 11.6ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 25.6ms\n",
      "Speed: 3.2ms preprocess, 25.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 13.1ms\n",
      "Speed: 5.0ms preprocess, 13.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 17.5ms\n",
      "Speed: 5.4ms preprocess, 17.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 12.6ms\n",
      "Speed: 2.3ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9s, 23.1ms\n",
      "Speed: 2.5ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Jd, 14.5ms\n",
      "Speed: 2.8ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 12.9ms\n",
      "Speed: 3.0ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Jd, 23.9ms\n",
      "Speed: 2.0ms preprocess, 23.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Jd, 14.2ms\n",
      "Speed: 2.3ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Jd, 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Jd, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 11.5ms\n",
      "Speed: 4.3ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 10.1ms\n",
      "Speed: 4.2ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 10.2ms\n",
      "Speed: 6.2ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 13.8ms\n",
      "Speed: 2.5ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kc, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 22.5ms\n",
      "Speed: 2.1ms preprocess, 22.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Kc, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Kc, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Kc, 85.7ms\n",
      "Speed: 2.5ms preprocess, 85.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Kc, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Kc, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 6c, 13.6ms\n",
      "Speed: 3.6ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9c, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9c, 13.5ms\n",
      "Speed: 2.2ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9c, 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9c, 12.3ms\n",
      "Speed: 11.6ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qs, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qs, 58.5ms\n",
      "Speed: 2.5ms preprocess, 58.5ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qs, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 19.3ms\n",
      "Speed: 11.4ms preprocess, 19.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 16.6ms\n",
      "Speed: 4.8ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 53.4ms\n",
      "Speed: 16.5ms preprocess, 53.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jh, 19.7ms\n",
      "Speed: 2.7ms preprocess, 19.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Jc, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Jc, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Jc, 11.5ms\n",
      "Speed: 5.4ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Jc, 16.1ms\n",
      "Speed: 11.4ms preprocess, 16.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 7c, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 7c, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 7c, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 7c, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 7c, 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Qd, 10.1ms\n",
      "Speed: 13.0ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qd, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qd, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qd, 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qd, 24.2ms\n",
      "Speed: 2.5ms preprocess, 24.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qd, 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qd, 12.2ms\n",
      "Speed: 3.2ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ah, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ah, 18.6ms\n",
      "Speed: 58.6ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ah, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ah, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ah, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ah, 23.1ms\n",
      "Speed: 2.3ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ah, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Ah, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Ah, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Ah, 26.3ms\n",
      "Speed: 2.8ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6d, 12.8ms\n",
      "Speed: 2.0ms preprocess, 12.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6d, 41.2ms\n",
      "Speed: 4.6ms preprocess, 41.2ms inference, 9.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6d, 21.9ms\n",
      "Speed: 2.3ms preprocess, 21.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 14.5ms\n",
      "Speed: 2.5ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 8c, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 8c, 15.1ms\n",
      "Speed: 12.9ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 8c, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 8c, 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kd, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 13.1ms\n",
      "Speed: 4.1ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 21.4ms\n",
      "Speed: 1.9ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 12.9ms\n",
      "Speed: 2.2ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 46.3ms\n",
      "Speed: 10.3ms preprocess, 46.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 12.2ms\n",
      "Speed: 6.8ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 13.5ms\n",
      "Speed: 11.5ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kd, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Js, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Js, 21.0ms\n",
      "Speed: 2.5ms preprocess, 21.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Js, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 44.6ms\n",
      "Speed: 2.7ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 23.5ms\n",
      "Speed: 3.1ms preprocess, 23.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 23.3ms\n",
      "Speed: 2.9ms preprocess, 23.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Js, 13.5ms\n",
      "Speed: 2.1ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 7s, 1 9d, 17.1ms\n",
      "Speed: 6.4ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 9d, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 9d, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 9d, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 9d, 25.6ms\n",
      "Speed: 9.3ms preprocess, 25.6ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8d, 19.0ms\n",
      "Speed: 22.7ms preprocess, 19.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5s, 13.7ms\n",
      "Speed: 4.2ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5s, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5s, 19.4ms\n",
      "Speed: 3.9ms preprocess, 19.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5s, 11.5ms\n",
      "Speed: 3.1ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5s, 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5s, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 22.6ms\n",
      "Speed: 2.5ms preprocess, 22.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5s, 13.1ms\n",
      "Speed: 2.1ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5s, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5s, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5s, 14.8ms\n",
      "Speed: 11.9ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 5s, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 13.3ms\n",
      "Speed: 6.9ms preprocess, 13.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 18.9ms\n",
      "Speed: 5.5ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 12.8ms\n",
      "Speed: 2.4ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 17.5ms\n",
      "Speed: 52.3ms preprocess, 17.5ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 12.2ms\n",
      "Speed: 4.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 12.3ms\n",
      "Speed: 8.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6s, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 3d, 14.6ms\n",
      "Speed: 12.6ms preprocess, 14.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8d, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8d, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8d, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8d, 66.8ms\n",
      "Speed: 2.7ms preprocess, 66.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8d, 19.8ms\n",
      "Speed: 2.3ms preprocess, 19.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8d, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qc, 14.0ms\n",
      "Speed: 11.4ms preprocess, 14.0ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qc, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qc, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qc, 13.1ms\n",
      "Speed: 11.6ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qc, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qc, 20.7ms\n",
      "Speed: 2.4ms preprocess, 20.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 19.2ms\n",
      "Speed: 57.0ms preprocess, 19.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 21.9ms\n",
      "Speed: 2.9ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 12.8ms\n",
      "Speed: 6.8ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 11.5ms\n",
      "Speed: 15.8ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 14.4ms\n",
      "Speed: 2.3ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 56.7ms\n",
      "Speed: 2.5ms preprocess, 56.7ms inference, 8.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qc, 17.1ms\n",
      "Speed: 2.2ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 13.3ms\n",
      "Speed: 3.8ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7s, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 14.2ms\n",
      "Speed: 11.2ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 14.0ms\n",
      "Speed: 3.1ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 13.4ms\n",
      "Speed: 2.4ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 13.6ms\n",
      "Speed: 2.8ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 13.8ms\n",
      "Speed: 13.0ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 10.9ms\n",
      "Speed: 4.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 18.1ms\n",
      "Speed: 5.1ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8s, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ts, 1 5c, 10.3ms\n",
      "Speed: 6.8ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 26.0ms\n",
      "Speed: 5.7ms preprocess, 26.0ms inference, 31.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 18.0ms\n",
      "Speed: 2.1ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 12.4ms\n",
      "Speed: 3.6ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 12.7ms\n",
      "Speed: 7.8ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 19.8ms\n",
      "Speed: 4.7ms preprocess, 19.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5c, 19.8ms\n",
      "Speed: 34.7ms preprocess, 19.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 2c, 13.8ms\n",
      "Speed: 3.3ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 2c, 15.2ms\n",
      "Speed: 10.5ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7h, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7h, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7h, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7h, 23.1ms\n",
      "Speed: 3.3ms preprocess, 23.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 9.9ms\n",
      "Speed: 4.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 34.1ms\n",
      "Speed: 3.3ms preprocess, 34.1ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 26.8ms\n",
      "Speed: 21.5ms preprocess, 26.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 22.3ms\n",
      "Speed: 2.9ms preprocess, 22.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 21.9ms\n",
      "Speed: 2.3ms preprocess, 21.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 11.5ms\n",
      "Speed: 3.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 18.6ms\n",
      "Speed: 10.1ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 13.5ms\n",
      "Speed: 2.8ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 18.5ms\n",
      "Speed: 3.6ms preprocess, 18.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 67.8ms\n",
      "Speed: 6.8ms preprocess, 67.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 9.9ms\n",
      "Speed: 3.9ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 13.3ms\n",
      "Speed: 3.3ms preprocess, 13.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 10.7ms\n",
      "Speed: 3.9ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 23.6ms\n",
      "Speed: 2.6ms preprocess, 23.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 31.4ms\n",
      "Speed: 53.8ms preprocess, 31.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Kh, 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 27.1ms\n",
      "Speed: 3.0ms preprocess, 27.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 12.6ms\n",
      "Speed: 3.4ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 76.1ms\n",
      "Speed: 2.7ms preprocess, 76.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 15.9ms\n",
      "Speed: 10.6ms preprocess, 15.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 As, 21.6ms\n",
      "Speed: 2.9ms preprocess, 21.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.6ms\n",
      "Speed: 3.6ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 15.3ms\n",
      "Speed: 11.6ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 14.6ms\n",
      "Speed: 12.1ms preprocess, 14.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.6ms\n",
      "Speed: 2.1ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 31.4ms\n",
      "Speed: 49.4ms preprocess, 31.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 20.4ms\n",
      "Speed: 2.4ms preprocess, 20.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 12.6ms\n",
      "Speed: 4.2ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 12.8ms\n",
      "Speed: 2.4ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 76.9ms\n",
      "Speed: 3.0ms preprocess, 76.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 21.8ms\n",
      "Speed: 5.4ms preprocess, 21.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3s, 10.8ms\n",
      "Speed: 4.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 3s, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 3s, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 3s, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 75.7ms\n",
      "Speed: 2.9ms preprocess, 75.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 13.7ms\n",
      "Speed: 2.1ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.7ms\n",
      "Speed: 5.5ms preprocess, 12.7ms inference, 10.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.0ms\n",
      "Speed: 5.5ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 45.9ms\n",
      "Speed: 31.7ms preprocess, 45.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 13.6ms\n",
      "Speed: 3.0ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 11.1ms\n",
      "Speed: 13.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 61.8ms\n",
      "Speed: 2.1ms preprocess, 61.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 9.9ms\n",
      "Speed: 4.3ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 26.4ms\n",
      "Speed: 2.9ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9h, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9h, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 11.1ms\n",
      "Speed: 3.8ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 18.8ms\n",
      "Speed: 2.1ms preprocess, 18.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 54.6ms\n",
      "Speed: 14.8ms preprocess, 54.6ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 22.0ms\n",
      "Speed: 3.1ms preprocess, 22.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 14.2ms\n",
      "Speed: 2.2ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 13.2ms\n",
      "Speed: 14.7ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 13.9ms\n",
      "Speed: 12.0ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 68.3ms\n",
      "Speed: 2.2ms preprocess, 68.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 20.3ms\n",
      "Speed: 2.7ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 15.5ms\n",
      "Speed: 2.5ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 14.7ms\n",
      "Speed: 2.8ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 12.6ms\n",
      "Speed: 10.3ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 19.4ms\n",
      "Speed: 2.7ms preprocess, 19.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 22.9ms\n",
      "Speed: 3.2ms preprocess, 22.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 65.4ms\n",
      "Speed: 7.1ms preprocess, 65.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 21.9ms\n",
      "Speed: 2.8ms preprocess, 21.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.0ms\n",
      "Speed: 5.0ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 26.6ms\n",
      "Speed: 2.7ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 50.7ms\n",
      "Speed: 11.0ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 11.2ms\n",
      "Speed: 7.4ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.8ms\n",
      "Speed: 2.9ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 23.8ms\n",
      "Speed: 3.1ms preprocess, 23.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 9.7ms\n",
      "Speed: 1.9ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 13.5ms\n",
      "Speed: 3.2ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 20.1ms\n",
      "Speed: 2.3ms preprocess, 20.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 11.0ms\n",
      "Speed: 5.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.2ms\n",
      "Speed: 2.6ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 21.6ms\n",
      "Speed: 2.8ms preprocess, 21.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 55.4ms\n",
      "Speed: 2.7ms preprocess, 55.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.5ms\n",
      "Speed: 3.2ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.7ms\n",
      "Speed: 13.3ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 20.1ms\n",
      "Speed: 8.0ms preprocess, 20.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 32.6ms\n",
      "Speed: 21.1ms preprocess, 32.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 15.9ms\n",
      "Speed: 2.6ms preprocess, 15.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.1ms\n",
      "Speed: 4.8ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Qh, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 22.7ms\n",
      "Speed: 2.5ms preprocess, 22.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.4ms\n",
      "Speed: 4.0ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 72.7ms\n",
      "Speed: 10.8ms preprocess, 72.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.1ms\n",
      "Speed: 2.4ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.1ms\n",
      "Speed: 10.6ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.6ms\n",
      "Speed: 13.0ms preprocess, 14.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 20.2ms\n",
      "Speed: 1.9ms preprocess, 20.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 18.4ms\n",
      "Speed: 3.7ms preprocess, 18.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.5ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.3ms\n",
      "Speed: 2.5ms preprocess, 18.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.0ms\n",
      "Speed: 3.0ms preprocess, 22.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 3.2ms preprocess, 14.9ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 4.0ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.3ms\n",
      "Speed: 52.6ms preprocess, 18.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 11.0ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 1.9ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.5ms\n",
      "Speed: 2.9ms preprocess, 23.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 44.7ms\n",
      "Speed: 3.0ms preprocess, 44.7ms inference, 16.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 2.0ms preprocess, 21.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.3ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.7ms\n",
      "Speed: 2.2ms preprocess, 18.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 36.1ms\n",
      "Speed: 35.0ms preprocess, 36.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 4.1ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.9ms\n",
      "Speed: 2.4ms preprocess, 17.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 52.1ms\n",
      "Speed: 26.3ms preprocess, 52.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 2.6ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 2.4ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 5.3ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.5ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 67.4ms\n",
      "Speed: 2.1ms preprocess, 67.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 8.9ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 13.6ms preprocess, 15.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.1ms\n",
      "Speed: 2.8ms preprocess, 24.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.9ms\n",
      "Speed: 49.4ms preprocess, 15.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.9ms\n",
      "Speed: 2.7ms preprocess, 22.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 3.2ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.6ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 5.0ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.1ms\n",
      "Speed: 2.7ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 51.4ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.3ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "Speed: 2.9ms preprocess, 23.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.4ms\n",
      "Speed: 6.3ms preprocess, 17.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 69.8ms\n",
      "Speed: 2.2ms preprocess, 69.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.7ms\n",
      "Speed: 3.8ms preprocess, 22.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 4.3ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 2.8ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 2.8ms preprocess, 15.1ms inference, 10.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 4.1ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 53.0ms\n",
      "Speed: 14.0ms preprocess, 53.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.4ms\n",
      "Speed: 2.2ms preprocess, 19.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 5.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 7.1ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.9ms\n",
      "Speed: 2.2ms preprocess, 22.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.3ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.0ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 2.8ms preprocess, 21.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.2ms\n",
      "Speed: 2.5ms preprocess, 17.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 40.2ms\n",
      "Speed: 23.5ms preprocess, 40.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.4ms\n",
      "Speed: 3.2ms preprocess, 17.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.8ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 9.1ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.2ms\n",
      "Speed: 2.6ms preprocess, 24.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.3ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.1ms\n",
      "Speed: 6.9ms preprocess, 16.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.4ms preprocess, 15.0ms inference, 49.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.3ms\n",
      "Speed: 2.1ms preprocess, 18.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 1.9ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 3.2ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 5.1ms preprocess, 15.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 1.9ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.5ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 65.6ms\n",
      "Speed: 15.5ms preprocess, 65.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 7.3ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.9ms\n",
      "Speed: 2.5ms preprocess, 24.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 69.0ms\n",
      "Speed: 2.8ms preprocess, 69.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 4.8ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.5ms\n",
      "Speed: 2.3ms preprocess, 21.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 3.3ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 37.5ms\n",
      "Speed: 2.7ms preprocess, 37.5ms inference, 28.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.7ms\n",
      "Speed: 2.3ms preprocess, 19.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 3.7ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 14.0ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.2ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 11.1ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 50.1ms\n",
      "Speed: 11.7ms preprocess, 50.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.5ms\n",
      "Speed: 3.2ms preprocess, 21.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 3.3ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.2ms\n",
      "Speed: 2.6ms preprocess, 25.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.8ms\n",
      "Speed: 2.5ms preprocess, 59.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 9.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 23.1ms\n",
      "Speed: 2.5ms preprocess, 23.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 2.2ms preprocess, 21.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 6.0ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 62.5ms\n",
      "Speed: 16.0ms preprocess, 62.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.6ms preprocess, 12.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.4ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.0ms\n",
      "Speed: 4.7ms preprocess, 18.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 3.2ms preprocess, 15.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.7ms\n",
      "Speed: 2.4ms preprocess, 22.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.3ms\n",
      "Speed: 2.2ms preprocess, 25.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.8ms\n",
      "Speed: 4.4ms preprocess, 51.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 3.5ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 4.3ms preprocess, 13.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.3ms\n",
      "Speed: 2.8ms preprocess, 21.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 2.7ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 3.2ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 76.3ms\n",
      "Speed: 3.3ms preprocess, 76.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Jd, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 11.1ms\n",
      "Speed: 5.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.8ms\n",
      "Speed: 11.7ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.8ms\n",
      "Speed: 2.3ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 68.9ms\n",
      "Speed: 2.2ms preprocess, 68.9ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.7ms\n",
      "Speed: 4.8ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 26.9ms\n",
      "Speed: 3.0ms preprocess, 26.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 20.6ms\n",
      "Speed: 2.1ms preprocess, 20.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 65.3ms\n",
      "Speed: 3.0ms preprocess, 65.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 19.9ms\n",
      "Speed: 1.9ms preprocess, 19.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.4ms\n",
      "Speed: 6.6ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 24.8ms\n",
      "Speed: 3.4ms preprocess, 24.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.8ms\n",
      "Speed: 3.1ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 17.3ms\n",
      "Speed: 5.2ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.8ms\n",
      "Speed: 2.7ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 15.9ms\n",
      "Speed: 2.4ms preprocess, 15.9ms inference, 10.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 64.7ms\n",
      "Speed: 2.7ms preprocess, 64.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 16.5ms\n",
      "Speed: 2.8ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 23.6ms\n",
      "Speed: 2.9ms preprocess, 23.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.0ms\n",
      "Speed: 2.4ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.3ms\n",
      "Speed: 2.6ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 21.9ms\n",
      "Speed: 2.3ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 16.0ms\n",
      "Speed: 1.8ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 23.0ms\n",
      "Speed: 6.0ms preprocess, 23.0ms inference, 33.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 16.8ms\n",
      "Speed: 2.2ms preprocess, 16.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.2ms\n",
      "Speed: 9.7ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 22.9ms\n",
      "Speed: 2.5ms preprocess, 22.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 15.3ms\n",
      "Speed: 4.3ms preprocess, 15.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.2ms\n",
      "Speed: 1.8ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.0ms\n",
      "Speed: 13.0ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 18.9ms\n",
      "Speed: 3.3ms preprocess, 18.9ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 22.6ms\n",
      "Speed: 34.6ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.3ms\n",
      "Speed: 2.7ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 20.4ms\n",
      "Speed: 2.3ms preprocess, 20.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.8ms\n",
      "Speed: 3.8ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 24.9ms\n",
      "Speed: 13.4ms preprocess, 24.9ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.6ms\n",
      "Speed: 2.6ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.1ms\n",
      "Speed: 2.9ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 17.9ms\n",
      "Speed: 7.3ms preprocess, 17.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.9ms\n",
      "Speed: 11.6ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 23.4ms\n",
      "Speed: 2.2ms preprocess, 23.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 68.7ms\n",
      "Speed: 17.4ms preprocess, 68.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 15.0ms\n",
      "Speed: 6.5ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.0ms\n",
      "Speed: 2.7ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 60.2ms\n",
      "Speed: 5.9ms preprocess, 60.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.9ms\n",
      "Speed: 2.4ms preprocess, 14.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.5ms\n",
      "Speed: 10.5ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.5ms\n",
      "Speed: 11.4ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.6ms\n",
      "Speed: 2.2ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 79.5ms\n",
      "Speed: 2.5ms preprocess, 79.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 21.2ms\n",
      "Speed: 4.3ms preprocess, 21.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 23.3ms\n",
      "Speed: 3.2ms preprocess, 23.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 56.1ms\n",
      "Speed: 2.1ms preprocess, 56.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.4ms\n",
      "Speed: 5.7ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.6ms\n",
      "Speed: 3.5ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 13.4ms\n",
      "Speed: 2.4ms preprocess, 13.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 9.7ms\n",
      "Speed: 3.5ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 23.1ms\n",
      "Speed: 2.5ms preprocess, 23.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.0ms\n",
      "Speed: 3.5ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 24.4ms\n",
      "Speed: 2.7ms preprocess, 24.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 14.5ms\n",
      "Speed: 3.0ms preprocess, 14.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 19.6ms\n",
      "Speed: 4.6ms preprocess, 19.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 15.9ms\n",
      "Speed: 3.2ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 16.2ms\n",
      "Speed: 11.2ms preprocess, 16.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Ks, 10.6ms\n",
      "Speed: 6.3ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Ks, 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Kh, 1 Ks, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Ks, 58.0ms\n",
      "Speed: 13.0ms preprocess, 58.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Ks, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Kc, 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Kc, 17.7ms\n",
      "Speed: 3.5ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Kc, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Qs, 12.4ms\n",
      "Speed: 3.5ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Qs, 12.0ms\n",
      "Speed: 4.8ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Qs, 14.5ms\n",
      "Speed: 7.2ms preprocess, 14.5ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Qs, 19.6ms\n",
      "Speed: 15.2ms preprocess, 19.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Jh, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Jh, 23.1ms\n",
      "Speed: 2.4ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Jh, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Jh, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 14.2ms\n",
      "Speed: 12.3ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Qd, 13.3ms\n",
      "Speed: 2.0ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Qd, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Qd, 23.3ms\n",
      "Speed: 64.4ms preprocess, 23.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Qd, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Qd, 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Qd, 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Qd, 14.2ms\n",
      "Speed: 14.7ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7d, 11.8ms\n",
      "Speed: 3.3ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7d, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7d, 20.1ms\n",
      "Speed: 2.6ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7d, 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7d, 12.9ms\n",
      "Speed: 7.5ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 4s, 13.2ms\n",
      "Speed: 11.1ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8c, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8c, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8c, 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8c, 19.9ms\n",
      "Speed: 3.8ms preprocess, 19.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8c, 14.3ms\n",
      "Speed: 50.2ms preprocess, 14.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8c, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8c, 26.6ms\n",
      "Speed: 2.4ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 6h, 12.9ms\n",
      "Speed: 2.1ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6h, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9d, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9d, 10.8ms\n",
      "Speed: 13.9ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9d, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 9d, 72.2ms\n",
      "Speed: 2.9ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 9d, 11.5ms\n",
      "Speed: 9.0ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 9d, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6s, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6s, 11.9ms\n",
      "Speed: 4.0ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6s, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6s, 14.0ms\n",
      "Speed: 13.0ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Qc, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Qc, 14.1ms\n",
      "Speed: 2.4ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Qc, 20.4ms\n",
      "Speed: 65.6ms preprocess, 20.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 17.4ms\n",
      "Speed: 12.0ms preprocess, 17.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qc, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qc, 13.4ms\n",
      "Speed: 3.5ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7s, 16.0ms\n",
      "Speed: 11.6ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7s, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7s, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7s, 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7s, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7s, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 23.5ms\n",
      "Speed: 2.6ms preprocess, 23.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 20.1ms\n",
      "Speed: 53.7ms preprocess, 20.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 14.2ms\n",
      "Speed: 2.8ms preprocess, 14.2ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5h, 10.8ms\n",
      "Speed: 4.6ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5h, 14.0ms\n",
      "Speed: 3.3ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5h, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5h, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 5h, 13.4ms\n",
      "Speed: 2.4ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 5h, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 4h, 55.3ms\n",
      "Speed: 19.9ms preprocess, 55.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Qh, 11.6ms\n",
      "Speed: 8.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Qh, 16.4ms\n",
      "Speed: 2.5ms preprocess, 16.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Qh, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 12.0ms\n",
      "Speed: 10.8ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 12.7ms\n",
      "Speed: 3.1ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 18.4ms\n",
      "Speed: 6.0ms preprocess, 18.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Qh, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qh, 12.4ms\n",
      "Speed: 3.5ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ac, 15.2ms\n",
      "Speed: 11.6ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 15.3ms\n",
      "Speed: 51.5ms preprocess, 15.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 10.6ms\n",
      "Speed: 5.3ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 12.4ms\n",
      "Speed: 13.0ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Ac, 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ac, 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 41.2ms\n",
      "Speed: 3.2ms preprocess, 41.2ms inference, 23.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 13.2ms\n",
      "Speed: 3.8ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 15.9ms\n",
      "Speed: 7.0ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6c, 14.3ms\n",
      "Speed: 9.0ms preprocess, 14.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 9c, 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 9c, 13.5ms\n",
      "Speed: 2.4ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 9c, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 9c, 11.8ms\n",
      "Speed: 10.2ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 9c, 13.2ms\n",
      "Speed: 2.0ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 12.6ms\n",
      "Speed: 3.0ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 17.0ms\n",
      "Speed: 2.7ms preprocess, 17.0ms inference, 5.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 17.2ms\n",
      "Speed: 50.1ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 12.7ms\n",
      "Speed: 2.8ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 16.3ms\n",
      "Speed: 6.7ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 60.9ms\n",
      "Speed: 19.7ms preprocess, 60.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 21.7ms\n",
      "Speed: 2.5ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 12.4ms\n",
      "Speed: 2.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 18.0ms\n",
      "Speed: 11.8ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ah, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 6cs, 1 Ah, 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 16.4ms\n",
      "Speed: 5.2ms preprocess, 16.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.2ms\n",
      "Speed: 2.1ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 64.8ms\n",
      "Speed: 2.3ms preprocess, 64.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 19.3ms\n",
      "Speed: 2.3ms preprocess, 19.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 11.2ms\n",
      "Speed: 6.8ms preprocess, 11.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 11.4ms\n",
      "Speed: 4.1ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 11.7ms\n",
      "Speed: 3.6ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 42.4ms\n",
      "Speed: 2.3ms preprocess, 42.4ms inference, 15.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 24.0ms\n",
      "Speed: 3.1ms preprocess, 24.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Js, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 25.7ms\n",
      "Speed: 2.7ms preprocess, 25.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 59.1ms\n",
      "Speed: 13.2ms preprocess, 59.1ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 9.8ms\n",
      "Speed: 3.0ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 17.1ms\n",
      "Speed: 11.1ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kd, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Js, 23.7ms\n",
      "Speed: 7.4ms preprocess, 23.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Js, 14.4ms\n",
      "Speed: 2.2ms preprocess, 14.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Js, 22.7ms\n",
      "Speed: 47.8ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Js, 10.9ms\n",
      "Speed: 3.8ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 7s, 19.7ms\n",
      "Speed: 10.9ms preprocess, 19.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 10.7ms\n",
      "Speed: 1.9ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 23.8ms\n",
      "Speed: 3.6ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 12.2ms\n",
      "Speed: 3.8ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 20.6ms\n",
      "Speed: 3.4ms preprocess, 20.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 2s, 19.8ms\n",
      "Speed: 9.1ms preprocess, 19.8ms inference, 22.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4d, 20.1ms\n",
      "Speed: 2.4ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4d, 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 12.9ms\n",
      "Speed: 17.4ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 14.1ms\n",
      "Speed: 3.9ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 38.6ms\n",
      "Speed: 16.2ms preprocess, 38.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 23.1ms\n",
      "Speed: 2.4ms preprocess, 23.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 12.4ms\n",
      "Speed: 3.5ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 23.8ms\n",
      "Speed: 2.2ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 11.2ms\n",
      "Speed: 3.5ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8d, 66.5ms\n",
      "Speed: 2.8ms preprocess, 66.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8s, 17.1ms\n",
      "Speed: 2.3ms preprocess, 17.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8s, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 27.5ms\n",
      "Speed: 3.1ms preprocess, 27.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 16.7ms\n",
      "Speed: 8.1ms preprocess, 16.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 13.7ms\n",
      "Speed: 3.2ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 8s, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 63.8ms\n",
      "Speed: 2.7ms preprocess, 63.8ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 20.3ms\n",
      "Speed: 2.7ms preprocess, 20.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 25.2ms\n",
      "Speed: 2.4ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 69.5ms\n",
      "Speed: 2.6ms preprocess, 69.5ms inference, 7.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 7h, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Kh, 10.9ms\n",
      "Speed: 6.1ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Kh, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Kh, 23.9ms\n",
      "Speed: 2.4ms preprocess, 23.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 71.0ms\n",
      "Speed: 2.6ms preprocess, 71.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 11.7ms\n",
      "Speed: 4.3ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 11.6ms\n",
      "Speed: 2.1ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 12.8ms\n",
      "Speed: 2.8ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 12.9ms\n",
      "Speed: 11.3ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 12.6ms\n",
      "Speed: 3.6ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 21.9ms\n",
      "Speed: 43.3ms preprocess, 21.9ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 23.1ms\n",
      "Speed: 2.8ms preprocess, 23.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 13.5ms\n",
      "Speed: 3.9ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Kh, 13.2ms\n",
      "Speed: 2.9ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 23.9ms\n",
      "Speed: 3.0ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 20.6ms\n",
      "Speed: 37.0ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 11.4ms\n",
      "Speed: 7.1ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 23.2ms\n",
      "Speed: 2.8ms preprocess, 23.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 15.4ms\n",
      "Speed: 3.4ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 12.5ms\n",
      "Speed: 14.5ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 13.5ms\n",
      "Speed: 1.8ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 As, 13.4ms\n",
      "Speed: 3.1ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 15.8ms\n",
      "Speed: 10.7ms preprocess, 15.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 52.9ms\n",
      "Speed: 2.5ms preprocess, 52.9ms inference, 18.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 14.6ms\n",
      "Speed: 2.5ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 13.8ms\n",
      "Speed: 2.7ms preprocess, 13.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 21.4ms\n",
      "Speed: 4.0ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 68.4ms\n",
      "Speed: 2.7ms preprocess, 68.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 11.5ms\n",
      "Speed: 3.2ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 15.4ms\n",
      "Speed: 3.2ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8h, 15.8ms\n",
      "Speed: 11.7ms preprocess, 15.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 57.9ms\n",
      "Speed: 10.2ms preprocess, 57.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 12.2ms\n",
      "Speed: 9.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 15.6ms\n",
      "Speed: 2.8ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 14.8ms\n",
      "Speed: 12.1ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 14.0ms\n",
      "Speed: 2.9ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 22.1ms\n",
      "Speed: 2.6ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 13.5ms\n",
      "Speed: 1.9ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 14.1ms\n",
      "Speed: 6.5ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 22.5ms\n",
      "Speed: 2.5ms preprocess, 22.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 17.9ms\n",
      "Speed: 50.8ms preprocess, 17.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 18.5ms\n",
      "Speed: 2.8ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 17.5ms\n",
      "Speed: 8.4ms preprocess, 17.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.7ms\n",
      "Speed: 2.1ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 70.6ms\n",
      "Speed: 9.0ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 15.4ms\n",
      "Speed: 3.5ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 12.4ms\n",
      "Speed: 1.7ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.6ms\n",
      "Speed: 3.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 10.7ms\n",
      "Speed: 15.0ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.4ms\n",
      "Speed: 5.2ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 19.3ms\n",
      "Speed: 3.3ms preprocess, 19.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.5ms\n",
      "Speed: 3.0ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 21.9ms\n",
      "Speed: 2.7ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 62.6ms\n",
      "Speed: 3.1ms preprocess, 62.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.9ms\n",
      "Speed: 7.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 21.5ms\n",
      "Speed: 2.7ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 12.7ms\n",
      "Speed: 2.8ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 16.1ms\n",
      "Speed: 7.3ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 11.1ms\n",
      "Speed: 3.4ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 36.3ms\n",
      "Speed: 57.0ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 20.9ms\n",
      "Speed: 2.5ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 13.4ms\n",
      "Speed: 2.3ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 66.8ms\n",
      "Speed: 3.3ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 15.8ms\n",
      "Speed: 2.2ms preprocess, 15.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ad, 14.5ms\n",
      "Speed: 2.9ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.1ms\n",
      "Speed: 11.6ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 77.2ms\n",
      "Speed: 4.3ms preprocess, 77.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 12.9ms\n",
      "Speed: 1.8ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.8ms\n",
      "Speed: 3.4ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 21.2ms\n",
      "Speed: 2.4ms preprocess, 21.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 13.1ms\n",
      "Speed: 2.6ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.8ms\n",
      "Speed: 2.7ms preprocess, 14.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 20.2ms\n",
      "Speed: 3.5ms preprocess, 20.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 13.4ms\n",
      "Speed: 2.9ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 58.7ms\n",
      "Speed: 20.2ms preprocess, 58.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 23.4ms\n",
      "Speed: 2.5ms preprocess, 23.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 14.2ms\n",
      "Speed: 3.8ms preprocess, 14.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 23.4ms\n",
      "Speed: 2.8ms preprocess, 23.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 26.7ms\n",
      "Speed: 3.7ms preprocess, 26.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 21.4ms\n",
      "Speed: 29.7ms preprocess, 21.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 28.4ms\n",
      "Speed: 2.8ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.0ms\n",
      "Speed: 2.8ms preprocess, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.5ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.5ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.7ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.0ms\n",
      "Speed: 20.3ms preprocess, 59.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 2.6ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.7ms\n",
      "Speed: 5.4ms preprocess, 17.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.1ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 5.9ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.3ms\n",
      "Speed: 2.1ms preprocess, 30.3ms inference, 18.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 9.0ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.1ms\n",
      "Speed: 3.0ms preprocess, 23.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 7.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 1.9ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.5ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 52.5ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.6ms\n",
      "Speed: 5.2ms preprocess, 16.6ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.6ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 3.5ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 1.8ms preprocess, 23.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 61.9ms\n",
      "Speed: 2.0ms preprocess, 61.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 10.4ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.4ms\n",
      "Speed: 2.2ms preprocess, 25.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 3.3ms preprocess, 22.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 2.5ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 17.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.8ms\n",
      "Speed: 20.6ms preprocess, 29.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.4ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 2.5ms preprocess, 19.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.1ms\n",
      "Speed: 2.8ms preprocess, 22.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 1.9ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 5.3ms preprocess, 14.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 4.1ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.0ms\n",
      "Speed: 2.3ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 35.6ms\n",
      "Speed: 2.0ms preprocess, 35.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.6ms\n",
      "Speed: 22.2ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.7ms\n",
      "Speed: 2.0ms preprocess, 24.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.1ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 70.3ms\n",
      "Speed: 2.2ms preprocess, 70.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 10.3ms preprocess, 13.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.6ms\n",
      "Speed: 2.3ms preprocess, 26.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 63.2ms\n",
      "Speed: 12.1ms preprocess, 63.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.7ms\n",
      "Speed: 3.5ms preprocess, 19.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.8ms\n",
      "Speed: 1.7ms preprocess, 16.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 45.5ms\n",
      "Speed: 2.9ms preprocess, 45.5ms inference, 20.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.9ms\n",
      "Speed: 1.9ms preprocess, 16.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.1ms\n",
      "Speed: 7.4ms preprocess, 19.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.0ms\n",
      "Speed: 55.2ms preprocess, 22.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 4.9ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.5ms\n",
      "Speed: 2.7ms preprocess, 22.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.8ms\n",
      "Speed: 2.8ms preprocess, 16.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.8ms\n",
      "Speed: 20.7ms preprocess, 51.8ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.8ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.9ms\n",
      "Speed: 11.0ms preprocess, 15.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.7ms\n",
      "Speed: 3.9ms preprocess, 15.7ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.7ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 4.7ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 7.5ms preprocess, 19.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.3ms\n",
      "Speed: 2.4ms preprocess, 59.3ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.1ms\n",
      "Speed: 2.2ms preprocess, 16.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "Speed: 2.7ms preprocess, 23.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 11.2ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 55.0ms\n",
      "Speed: 3.7ms preprocess, 55.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.1ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 2.2ms preprocess, 15.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 2.4ms preprocess, 16.5ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 64.9ms\n",
      "Speed: 5.3ms preprocess, 64.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 4.5ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.2ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 26.0ms\n",
      "Speed: 2.4ms preprocess, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 2.3ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 15.1ms\n",
      "Speed: 59.3ms preprocess, 15.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 2.6ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.4ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.7ms\n",
      "Speed: 2.4ms preprocess, 15.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 4.3ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.1ms\n",
      "Speed: 29.8ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 4.7ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.5ms\n",
      "Speed: 5.2ms preprocess, 19.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.8ms\n",
      "Speed: 3.1ms preprocess, 19.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 2.5ms preprocess, 15.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.7ms\n",
      "Speed: 2.7ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.9ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.2ms\n",
      "Speed: 3.5ms preprocess, 22.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.8ms\n",
      "Speed: 53.0ms preprocess, 18.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 3.0ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.3ms\n",
      "Speed: 49.4ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 6.2ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 11.2ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.1ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 52.0ms\n",
      "Speed: 11.5ms preprocess, 52.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.2ms\n",
      "Speed: 2.3ms preprocess, 18.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.8ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 4.4ms preprocess, 13.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 23.0ms\n",
      "Speed: 3.4ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 24.1ms\n",
      "Speed: 2.9ms preprocess, 24.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 9d, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 15.3ms\n",
      "Speed: 2.9ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 66.1ms\n",
      "Speed: 2.2ms preprocess, 66.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.8ms\n",
      "Speed: 2.3ms preprocess, 20.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 14.8ms\n",
      "Speed: 11.1ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 17.1ms\n",
      "Speed: 3.5ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 21.7ms\n",
      "Speed: 2.6ms preprocess, 21.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 13.1ms\n",
      "Speed: 2.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 17.0ms\n",
      "Speed: 2.6ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 15.1ms\n",
      "Speed: 3.3ms preprocess, 15.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 1 Ah, 13.0ms\n",
      "Speed: 3.1ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 22.1ms\n",
      "Speed: 2.5ms preprocess, 22.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 62.2ms\n",
      "Speed: 2.5ms preprocess, 62.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 1.8ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 27.0ms\n",
      "Speed: 2.3ms preprocess, 27.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 65.0ms\n",
      "Speed: 3.0ms preprocess, 65.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 18.8ms\n",
      "Speed: 2.1ms preprocess, 18.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 26.9ms\n",
      "Speed: 2.6ms preprocess, 26.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 21.0ms\n",
      "Speed: 3.2ms preprocess, 21.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 26.2ms\n",
      "Speed: 2.7ms preprocess, 26.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.3ms\n",
      "Speed: 50.3ms preprocess, 20.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 21.0ms\n",
      "Speed: 2.7ms preprocess, 21.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 3.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 4.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 19.8ms\n",
      "Speed: 3.3ms preprocess, 19.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.2ms\n",
      "Speed: 1.7ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.1ms\n",
      "Speed: 2.7ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 21.0ms\n",
      "Speed: 2.6ms preprocess, 21.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 18.9ms\n",
      "Speed: 5.9ms preprocess, 18.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.4ms\n",
      "Speed: 2.8ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.7ms\n",
      "Speed: 62.9ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.1ms\n",
      "Speed: 3.1ms preprocess, 13.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 21.2ms\n",
      "Speed: 4.8ms preprocess, 21.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 76.3ms\n",
      "Speed: 4.2ms preprocess, 76.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.6ms\n",
      "Speed: 3.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 26.8ms\n",
      "Speed: 2.9ms preprocess, 26.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.6ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.1ms\n",
      "Speed: 3.6ms preprocess, 20.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.9ms\n",
      "Speed: 3.7ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 17.7ms\n",
      "Speed: 15.1ms preprocess, 17.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 16.7ms\n",
      "Speed: 12.6ms preprocess, 16.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 38.9ms\n",
      "Speed: 2.1ms preprocess, 38.9ms inference, 31.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.5ms\n",
      "Speed: 2.2ms preprocess, 20.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.4ms\n",
      "Speed: 15.1ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 54.1ms\n",
      "Speed: 15.2ms preprocess, 54.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 3.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.9ms\n",
      "Speed: 3.2ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.7ms\n",
      "Speed: 10.7ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.0ms\n",
      "Speed: 2.4ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 22.0ms\n",
      "Speed: 2.7ms preprocess, 22.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 1.8ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 3.8ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 72.5ms\n",
      "Speed: 2.6ms preprocess, 72.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.4ms\n",
      "Speed: 3.6ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 22.7ms\n",
      "Speed: 1.8ms preprocess, 22.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 17.8ms\n",
      "Speed: 2.5ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.4ms\n",
      "Speed: 3.2ms preprocess, 20.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.7ms\n",
      "Speed: 2.4ms preprocess, 14.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 23.9ms\n",
      "Speed: 2.5ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.7ms\n",
      "Speed: 17.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 3.5ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.8ms\n",
      "Speed: 5.0ms preprocess, 20.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.3ms\n",
      "Speed: 2.1ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 43.5ms\n",
      "Speed: 2.6ms preprocess, 43.5ms inference, 8.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 17.9ms\n",
      "Speed: 2.5ms preprocess, 17.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.5ms\n",
      "Speed: 3.3ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.8ms\n",
      "Speed: 3.0ms preprocess, 20.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.7ms\n",
      "Speed: 2.6ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.8ms\n",
      "Speed: 3.3ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.9ms\n",
      "Speed: 12.4ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.5ms\n",
      "Speed: 2.5ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 18.0ms\n",
      "Speed: 2.1ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 52.8ms\n",
      "Speed: 10.8ms preprocess, 52.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.9ms\n",
      "Speed: 2.8ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6d, 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 28.8ms\n",
      "Speed: 2.3ms preprocess, 28.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.2ms\n",
      "Speed: 3.8ms preprocess, 11.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 20.3ms\n",
      "Speed: 2.4ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 24.0ms\n",
      "Speed: 4.1ms preprocess, 24.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 9s, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 9s, 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 78.5ms\n",
      "Speed: 3.3ms preprocess, 78.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 14.6ms\n",
      "Speed: 4.3ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 16.0ms\n",
      "Speed: 12.3ms preprocess, 16.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9s, 21.7ms\n",
      "Speed: 67.7ms preprocess, 21.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 20.5ms\n",
      "Speed: 2.8ms preprocess, 20.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 13.1ms\n",
      "Speed: 2.4ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 10.8ms\n",
      "Speed: 4.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 59.2ms\n",
      "Speed: 14.5ms preprocess, 59.2ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 13.4ms\n",
      "Speed: 2.6ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 As, 15.6ms\n",
      "Speed: 13.1ms preprocess, 15.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 As, 13.1ms\n",
      "Speed: 2.4ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 13.5ms\n",
      "Speed: 8.7ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 10.9ms\n",
      "Speed: 3.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 28.3ms\n",
      "Speed: 2.6ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qc, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 21.8ms\n",
      "Speed: 3.0ms preprocess, 21.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 66.4ms\n",
      "Speed: 2.1ms preprocess, 66.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 21.1ms\n",
      "Speed: 2.9ms preprocess, 21.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9d, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 14.6ms\n",
      "Speed: 3.3ms preprocess, 14.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8c, 11.1ms\n",
      "Speed: 4.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 19.4ms\n",
      "Speed: 2.5ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 11.5ms\n",
      "Speed: 3.1ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 12.8ms\n",
      "Speed: 2.9ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Jc, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 43.5ms\n",
      "Speed: 36.8ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 23.5ms\n",
      "Speed: 3.3ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Ks, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 82.9ms\n",
      "Speed: 2.7ms preprocess, 82.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 12.8ms\n",
      "Speed: 2.4ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Qs, 20.9ms\n",
      "Speed: 2.7ms preprocess, 20.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 12.8ms\n",
      "Speed: 2.0ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 13.3ms\n",
      "Speed: 2.8ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 12.3ms\n",
      "Speed: 2.6ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 31.2ms\n",
      "Speed: 6.7ms preprocess, 31.2ms inference, 32.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 15.5ms\n",
      "Speed: 2.6ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 22.9ms\n",
      "Speed: 2.9ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 24.7ms\n",
      "Speed: 2.7ms preprocess, 24.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 12.3ms\n",
      "Speed: 6.3ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 14.2ms\n",
      "Speed: 10.7ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 68.5ms\n",
      "Speed: 5.6ms preprocess, 68.5ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 13.0ms\n",
      "Speed: 1.8ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 24.5ms\n",
      "Speed: 3.1ms preprocess, 24.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 9h, 13.0ms\n",
      "Speed: 1.6ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 24.9ms\n",
      "Speed: 2.3ms preprocess, 24.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 12.2ms\n",
      "Speed: 3.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 20.5ms\n",
      "Speed: 2.4ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 48.3ms\n",
      "Speed: 32.0ms preprocess, 48.3ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kd, 12.6ms\n",
      "Speed: 2.3ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kd, 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 12.5ms\n",
      "Speed: 3.2ms preprocess, 12.5ms inference, 11.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 9.9ms\n",
      "Speed: 4.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 10.9ms\n",
      "Speed: 6.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 13.0ms\n",
      "Speed: 3.2ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 32.1ms\n",
      "Speed: 46.7ms preprocess, 32.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 11.5ms\n",
      "Speed: 4.3ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 14.1ms\n",
      "Speed: 2.9ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9h, 16.4ms\n",
      "Speed: 11.8ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 11.0ms\n",
      "Speed: 6.5ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 11.5ms\n",
      "Speed: 3.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 16.8ms\n",
      "Speed: 10.3ms preprocess, 16.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Qh, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Qh, 57.4ms\n",
      "Speed: 2.8ms preprocess, 57.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 19.9ms\n",
      "Speed: 2.2ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 11.8ms\n",
      "Speed: 6.8ms preprocess, 11.8ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 10.5ms\n",
      "Speed: 5.5ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7d, 13.8ms\n",
      "Speed: 2.9ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 23.4ms\n",
      "Speed: 2.7ms preprocess, 23.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Kh, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 10.2ms\n",
      "Speed: 2.9ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 79.9ms\n",
      "Speed: 2.3ms preprocess, 79.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 18.6ms\n",
      "Speed: 2.7ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 15.6ms\n",
      "Speed: 3.6ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Js, 21.4ms\n",
      "Speed: 2.5ms preprocess, 21.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 19.8ms\n",
      "Speed: 2.2ms preprocess, 19.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 18.2ms\n",
      "Speed: 2.3ms preprocess, 18.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 14.4ms\n",
      "Speed: 8.8ms preprocess, 14.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 16.7ms\n",
      "Speed: 3.5ms preprocess, 16.7ms inference, 9.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 12.6ms\n",
      "Speed: 3.0ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 11.2ms\n",
      "Speed: 3.3ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 22.3ms\n",
      "Speed: 3.0ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7c, 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 15.2ms\n",
      "Speed: 2.6ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 13.4ms\n",
      "Speed: 10.7ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 13.5ms\n",
      "Speed: 2.5ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 22.1ms\n",
      "Speed: 2.3ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 49.6ms\n",
      "Speed: 21.4ms preprocess, 49.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6s, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 20.9ms\n",
      "Speed: 3.1ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 13.3ms\n",
      "Speed: 2.9ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 18.7ms\n",
      "Speed: 11.4ms preprocess, 18.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.6ms\n",
      "Speed: 2.1ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 12.7ms\n",
      "Speed: 2.8ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 19.3ms\n",
      "Speed: 2.7ms preprocess, 19.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 76.4ms\n",
      "Speed: 3.6ms preprocess, 76.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 15.5ms\n",
      "Speed: 3.1ms preprocess, 15.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 19.7ms\n",
      "Speed: 2.9ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.8ms\n",
      "Speed: 2.5ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 32.4ms\n",
      "Speed: 20.2ms preprocess, 32.4ms inference, 16.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 10.8ms\n",
      "Speed: 6.2ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4d, 12.4ms\n",
      "Speed: 4.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 10.7ms\n",
      "Speed: 3.4ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 23.8ms\n",
      "Speed: 2.6ms preprocess, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 37.6ms\n",
      "Speed: 3.4ms preprocess, 37.6ms inference, 28.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 21.6ms\n",
      "Speed: 3.2ms preprocess, 21.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.7ms\n",
      "Speed: 2.1ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 26.8ms\n",
      "Speed: 2.8ms preprocess, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.8ms\n",
      "Speed: 3.3ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 16.0ms\n",
      "Speed: 5.4ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 71.9ms\n",
      "Speed: 2.9ms preprocess, 71.9ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.0ms\n",
      "Speed: 4.5ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.6ms\n",
      "Speed: 2.6ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 23.5ms\n",
      "Speed: 2.3ms preprocess, 23.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.4ms\n",
      "Speed: 2.4ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 78.0ms\n",
      "Speed: 2.6ms preprocess, 78.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.6ms\n",
      "Speed: 2.7ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 19.4ms\n",
      "Speed: 3.7ms preprocess, 19.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.6ms\n",
      "Speed: 2.7ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 19.7ms\n",
      "Speed: 3.2ms preprocess, 19.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 23.2ms\n",
      "Speed: 46.9ms preprocess, 23.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 26.8ms\n",
      "Speed: 2.6ms preprocess, 26.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 19.3ms\n",
      "Speed: 6.5ms preprocess, 19.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 21.6ms\n",
      "Speed: 5.9ms preprocess, 21.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 11.6ms\n",
      "Speed: 3.4ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 67.1ms\n",
      "Speed: 3.0ms preprocess, 67.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 13.4ms\n",
      "Speed: 10.1ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 24.1ms\n",
      "Speed: 2.5ms preprocess, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 23.1ms\n",
      "Speed: 3.1ms preprocess, 23.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 22.8ms\n",
      "Speed: 2.7ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 16.3ms\n",
      "Speed: 2.7ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 64.8ms\n",
      "Speed: 4.8ms preprocess, 64.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 14.4ms\n",
      "Speed: 4.8ms preprocess, 14.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 20.7ms\n",
      "Speed: 4.0ms preprocess, 20.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 13.4ms\n",
      "Speed: 1.9ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 24.2ms\n",
      "Speed: 3.0ms preprocess, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 22.1ms\n",
      "Speed: 3.3ms preprocess, 22.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 11.8ms\n",
      "Speed: 3.4ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 13.6ms\n",
      "Speed: 12.3ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 61.6ms\n",
      "Speed: 11.0ms preprocess, 61.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 21.6ms\n",
      "Speed: 2.6ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.5ms\n",
      "Speed: 2.1ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 25.1ms\n",
      "Speed: 3.2ms preprocess, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 45.3ms\n",
      "Speed: 3.1ms preprocess, 45.3ms inference, 10.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 17.5ms\n",
      "Speed: 6.6ms preprocess, 17.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.7ms\n",
      "Speed: 4.4ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 27.6ms\n",
      "Speed: 2.8ms preprocess, 27.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 51.4ms\n",
      "Speed: 7.0ms preprocess, 51.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 15.5ms\n",
      "Speed: 11.4ms preprocess, 15.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 15.3ms\n",
      "Speed: 2.8ms preprocess, 15.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 17.8ms\n",
      "Speed: 8.6ms preprocess, 17.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 28.0ms\n",
      "Speed: 2.8ms preprocess, 28.0ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 29.1ms\n",
      "Speed: 22.2ms preprocess, 29.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 22.2ms\n",
      "Speed: 3.9ms preprocess, 22.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 15.7ms\n",
      "Speed: 2.7ms preprocess, 15.7ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 11.3ms\n",
      "Speed: 3.7ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 21.8ms\n",
      "Speed: 2.6ms preprocess, 21.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.9ms\n",
      "Speed: 2.2ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 25.4ms\n",
      "Speed: 6.7ms preprocess, 25.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 60.4ms\n",
      "Speed: 1.9ms preprocess, 60.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 10.6ms\n",
      "Speed: 6.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.2ms\n",
      "Speed: 3.3ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 14.8ms\n",
      "Speed: 10.5ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.1ms\n",
      "Speed: 2.3ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 14.8ms\n",
      "Speed: 2.7ms preprocess, 14.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 14.7ms\n",
      "Speed: 10.7ms preprocess, 14.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.4ms\n",
      "Speed: 2.2ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 14.2ms\n",
      "Speed: 3.1ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 22.1ms\n",
      "Speed: 2.7ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 51.4ms\n",
      "Speed: 8.1ms preprocess, 51.4ms inference, 9.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 16.0ms\n",
      "Speed: 2.5ms preprocess, 16.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.8ms\n",
      "Speed: 13.6ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 27.2ms\n",
      "Speed: 2.8ms preprocess, 27.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 19.5ms\n",
      "Speed: 2.8ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 14.3ms\n",
      "Speed: 52.7ms preprocess, 14.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.9ms\n",
      "Speed: 7.2ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 18.0ms\n",
      "Speed: 2.8ms preprocess, 18.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.8ms\n",
      "Speed: 2.9ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.5ms\n",
      "Speed: 12.2ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 13.2ms\n",
      "Speed: 3.0ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.0ms\n",
      "Speed: 2.3ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 66.3ms\n",
      "Speed: 5.6ms preprocess, 66.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.5ms preprocess, 12.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.7ms\n",
      "Speed: 2.7ms preprocess, 22.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.7ms\n",
      "Speed: 4.8ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 13.1ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 36.6ms\n",
      "Speed: 3.3ms preprocess, 36.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.2ms\n",
      "Speed: 11.2ms preprocess, 18.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 11.1ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 3.0ms preprocess, 21.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.7ms\n",
      "Speed: 3.6ms preprocess, 25.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.1ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 2.2ms preprocess, 22.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 58.1ms\n",
      "Speed: 2.9ms preprocess, 58.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 5.9ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.9ms\n",
      "Speed: 8.9ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 1.7ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.1ms\n",
      "Speed: 13.6ms preprocess, 18.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.8ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 12.9ms preprocess, 15.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.3ms\n",
      "Speed: 50.9ms preprocess, 19.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 4.0ms preprocess, 22.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.6ms\n",
      "Speed: 2.9ms preprocess, 18.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 5.3ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.3ms\n",
      "Speed: 2.5ms preprocess, 18.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 62.3ms\n",
      "Speed: 2.7ms preprocess, 62.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.1ms\n",
      "Speed: 2.9ms preprocess, 21.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 1.7ms preprocess, 20.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.7ms\n",
      "Speed: 2.5ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.6ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.2ms\n",
      "Speed: 2.9ms preprocess, 24.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.3ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 42.2ms\n",
      "Speed: 1.8ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.6ms\n",
      "Speed: 2.2ms preprocess, 16.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.6ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 2.6ms preprocess, 23.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 1.6ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.4ms\n",
      "Speed: 2.5ms preprocess, 23.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.6ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.2ms\n",
      "Speed: 3.1ms preprocess, 21.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 55.6ms\n",
      "Speed: 15.9ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 4.8ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.0ms\n",
      "Speed: 3.3ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 3.1ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 77.8ms\n",
      "Speed: 2.1ms preprocess, 77.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 1.8ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.6ms\n",
      "Speed: 3.4ms preprocess, 23.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 73.4ms\n",
      "Speed: 1.6ms preprocess, 73.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.7ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.0ms\n",
      "Speed: 1.8ms preprocess, 16.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.9ms\n",
      "Speed: 2.8ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.9ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 12.1ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.7ms\n",
      "Speed: 3.9ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 73.3ms\n",
      "Speed: 2.5ms preprocess, 73.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 1.8ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 2.3ms preprocess, 22.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.9ms\n",
      "Speed: 2.5ms preprocess, 22.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.3ms preprocess, 14.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 3.1ms preprocess, 22.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 2.7ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 55.3ms\n",
      "Speed: 15.5ms preprocess, 55.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.3ms\n",
      "Speed: 3.0ms preprocess, 19.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.3ms\n",
      "Speed: 3.6ms preprocess, 23.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.4ms preprocess, 14.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 6.9ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 57.5ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 4.0ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.1ms\n",
      "Speed: 2.7ms preprocess, 18.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 4.0ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 69.4ms\n",
      "Speed: 3.4ms preprocess, 69.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.1ms\n",
      "Speed: 3.2ms preprocess, 18.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.3ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.8ms\n",
      "Speed: 3.1ms preprocess, 20.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 42.7ms\n",
      "Speed: 2.1ms preprocess, 42.7ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.7ms\n",
      "Speed: 2.3ms preprocess, 22.7ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.9ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 1.7ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 2.2ms preprocess, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 2.4ms preprocess, 14.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 71.6ms\n",
      "Speed: 3.3ms preprocess, 71.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 5.8ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 6.1ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 10.6ms preprocess, 13.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.3ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 63.9ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 12.0ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 69.7ms\n",
      "Speed: 3.7ms preprocess, 69.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 8.0ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.9ms\n",
      "Speed: 3.1ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.7ms\n",
      "Speed: 2.6ms preprocess, 19.7ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.9ms\n",
      "Speed: 44.8ms preprocess, 19.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.8ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 10.4ms preprocess, 14.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.0ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.0ms\n",
      "Speed: 3.6ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.3ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 7.3ms preprocess, 22.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 61.1ms\n",
      "Speed: 18.3ms preprocess, 61.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.9ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.6ms\n",
      "Speed: 1.8ms preprocess, 21.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 1.9ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.3ms\n",
      "Speed: 2.9ms preprocess, 23.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "Speed: 2.1ms preprocess, 23.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 52.9ms\n",
      "Speed: 2.9ms preprocess, 52.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.9ms\n",
      "Speed: 3.0ms preprocess, 16.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.6ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 68.8ms\n",
      "Speed: 2.4ms preprocess, 68.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 9.1ms preprocess, 14.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 1.7ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.9ms\n",
      "Speed: 3.5ms preprocess, 24.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.4ms\n",
      "Speed: 3.5ms preprocess, 27.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 2.6ms preprocess, 13.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.4ms\n",
      "Speed: 2.7ms preprocess, 19.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 52.6ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 5.9ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.8ms\n",
      "Speed: 5.4ms preprocess, 16.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.7ms\n",
      "Speed: 3.8ms preprocess, 15.7ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 4.3ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.1ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.4ms\n",
      "Speed: 3.0ms preprocess, 24.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.9ms\n",
      "Speed: 3.3ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 60.6ms\n",
      "Speed: 8.3ms preprocess, 60.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 3.4ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.4ms\n",
      "Speed: 2.5ms preprocess, 24.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 2.5ms preprocess, 14.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.2ms\n",
      "Speed: 2.5ms preprocess, 24.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.4ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.7ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.5ms\n",
      "Speed: 2.5ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 57.3ms\n",
      "Speed: 3.7ms preprocess, 57.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 10.5ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 7.1ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 11.6ms preprocess, 13.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.0ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.2ms\n",
      "Speed: 2.5ms preprocess, 23.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.8ms\n",
      "Speed: 3.6ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.2ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 3.1ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 77.2ms\n",
      "Speed: 4.2ms preprocess, 77.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "Speed: 3.2ms preprocess, 23.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 4.2ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 2.5ms preprocess, 21.4ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 4.2ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 39.5ms\n",
      "Speed: 28.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.2ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.1ms\n",
      "Speed: 2.6ms preprocess, 25.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 19.5ms\n",
      "Speed: 1.9ms preprocess, 19.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.2ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 2.3ms preprocess, 22.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 6.6ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 17.7ms preprocess, 13.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.2ms\n",
      "Speed: 2.0ms preprocess, 16.2ms inference, 11.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 4.6ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.8ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.9ms\n",
      "Speed: 2.8ms preprocess, 24.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 50.5ms\n",
      "Speed: 15.2ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.5ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.0ms\n",
      "Speed: 3.9ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.6ms\n",
      "Speed: 2.8ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 22.6ms\n",
      "Speed: 2.9ms preprocess, 22.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.1ms\n",
      "Speed: 3.4ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 59.6ms\n",
      "Speed: 2.7ms preprocess, 59.6ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 21.6ms\n",
      "Speed: 2.3ms preprocess, 21.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.7ms\n",
      "Speed: 1.9ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 13.7ms\n",
      "Speed: 2.4ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 22.6ms\n",
      "Speed: 3.5ms preprocess, 22.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 65.7ms\n",
      "Speed: 2.0ms preprocess, 65.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.1ms\n",
      "Speed: 5.0ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 16.1ms\n",
      "Speed: 2.6ms preprocess, 16.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 18.7ms\n",
      "Speed: 3.1ms preprocess, 18.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 16.6ms\n",
      "Speed: 51.9ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.6ms\n",
      "Speed: 7.1ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 22.9ms\n",
      "Speed: 3.0ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 23.3ms\n",
      "Speed: 3.0ms preprocess, 23.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 14.2ms\n",
      "Speed: 52.1ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.4ms\n",
      "Speed: 3.6ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 15.0ms\n",
      "Speed: 10.7ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 25.7ms\n",
      "Speed: 3.2ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 23.5ms\n",
      "Speed: 3.2ms preprocess, 23.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.6ms\n",
      "Speed: 3.4ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 23.2ms\n",
      "Speed: 3.8ms preprocess, 23.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 13.6ms\n",
      "Speed: 2.3ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 14.6ms\n",
      "Speed: 11.3ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 34.4ms\n",
      "Speed: 34.1ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 26.8ms\n",
      "Speed: 2.6ms preprocess, 26.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 62.5ms\n",
      "Speed: 2.9ms preprocess, 62.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 19.6ms\n",
      "Speed: 2.1ms preprocess, 19.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 27.1ms\n",
      "Speed: 3.0ms preprocess, 27.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 62.5ms\n",
      "Speed: 8.9ms preprocess, 62.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 13.0ms\n",
      "Speed: 9.1ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 18.0ms\n",
      "Speed: 2.5ms preprocess, 18.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 15.7ms\n",
      "Speed: 3.2ms preprocess, 15.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 21.2ms\n",
      "Speed: 3.1ms preprocess, 21.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 14.3ms\n",
      "Speed: 2.5ms preprocess, 14.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 64.7ms\n",
      "Speed: 12.8ms preprocess, 64.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.1ms\n",
      "Speed: 8.9ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 23.6ms\n",
      "Speed: 2.8ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.9ms\n",
      "Speed: 3.7ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 22.2ms\n",
      "Speed: 2.1ms preprocess, 22.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 15.1ms\n",
      "Speed: 3.1ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 20.2ms\n",
      "Speed: 2.6ms preprocess, 20.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 61.7ms\n",
      "Speed: 3.2ms preprocess, 61.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 19.9ms\n",
      "Speed: 2.0ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 13.9ms\n",
      "Speed: 7.9ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 15.4ms\n",
      "Speed: 10.5ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 16.4ms\n",
      "Speed: 3.0ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.3ms\n",
      "Speed: 3.9ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 18.6ms\n",
      "Speed: 10.7ms preprocess, 18.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 68.7ms\n",
      "Speed: 2.4ms preprocess, 68.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.9ms\n",
      "Speed: 5.7ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.4ms\n",
      "Speed: 2.8ms preprocess, 12.4ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 19.2ms\n",
      "Speed: 3.2ms preprocess, 19.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 14.0ms\n",
      "Speed: 3.2ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 73.8ms\n",
      "Speed: 3.3ms preprocess, 73.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 18.7ms\n",
      "Speed: 6.2ms preprocess, 18.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.2ms\n",
      "Speed: 3.5ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 67.0ms\n",
      "Speed: 2.7ms preprocess, 67.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 20.3ms\n",
      "Speed: 2.6ms preprocess, 20.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.2ms\n",
      "Speed: 4.2ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 22.0ms\n",
      "Speed: 2.9ms preprocess, 22.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 15.3ms\n",
      "Speed: 51.7ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 14.1ms\n",
      "Speed: 2.6ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 17.7ms\n",
      "Speed: 11.3ms preprocess, 17.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 5d, 14.0ms\n",
      "Speed: 3.3ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 11.8ms\n",
      "Speed: 3.1ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 43.4ms\n",
      "Speed: 3.2ms preprocess, 43.4ms inference, 8.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ac, 14.2ms\n",
      "Speed: 1.8ms preprocess, 14.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ac, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ac, 19.4ms\n",
      "Speed: 3.1ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ac, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Ac, 15.5ms\n",
      "Speed: 1.8ms preprocess, 15.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 Ac, 13.5ms\n",
      "Speed: 2.7ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 9s, 67.9ms\n",
      "Speed: 12.8ms preprocess, 67.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 9s, 11.7ms\n",
      "Speed: 3.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 9s, 22.8ms\n",
      "Speed: 2.2ms preprocess, 22.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 9s, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9s, 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9s, 11.0ms\n",
      "Speed: 3.8ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 9s, 15.2ms\n",
      "Speed: 13.6ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Jd, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Jd, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Jd, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Jd, 22.6ms\n",
      "Speed: 2.1ms preprocess, 22.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jd, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jd, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Jd, 69.1ms\n",
      "Speed: 2.2ms preprocess, 69.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Kd, 14.7ms\n",
      "Speed: 2.5ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ks, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ks, 12.8ms\n",
      "Speed: 2.8ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ks, 22.9ms\n",
      "Speed: 3.5ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ks, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ks, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 15.7ms\n",
      "Speed: 3.5ms preprocess, 15.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8d, 12.3ms\n",
      "Speed: 5.4ms preprocess, 12.3ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8d, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8d, 10.7ms\n",
      "Speed: 1.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8d, 22.1ms\n",
      "Speed: 4.0ms preprocess, 22.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8d, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 6d, 1 8d, 66.2ms\n",
      "Speed: 15.3ms preprocess, 66.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Qc, 12.0ms\n",
      "Speed: 3.5ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qc, 14.4ms\n",
      "Speed: 3.4ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qc, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qc, 14.0ms\n",
      "Speed: 17.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qc, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qc, 13.2ms\n",
      "Speed: 3.1ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 40.1ms\n",
      "Speed: 26.9ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6c, 14.0ms\n",
      "Speed: 2.9ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6c, 20.7ms\n",
      "Speed: 2.9ms preprocess, 20.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6c, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6c, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6c, 21.6ms\n",
      "Speed: 5.1ms preprocess, 21.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 4d, 11.5ms\n",
      "Speed: 3.5ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 4d, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 4d, 11.9ms\n",
      "Speed: 3.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 4d, 24.1ms\n",
      "Speed: 2.7ms preprocess, 24.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8s, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8s, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8s, 73.8ms\n",
      "Speed: 3.2ms preprocess, 73.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 10.9ms\n",
      "Speed: 8.7ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 12.2ms\n",
      "Speed: 3.8ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 11.7ms\n",
      "Speed: 2.3ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 19.2ms\n",
      "Speed: 2.5ms preprocess, 19.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 11.8ms\n",
      "Speed: 3.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9c, 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qs, 14.3ms\n",
      "Speed: 16.1ms preprocess, 14.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qs, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qs, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qs, 28.1ms\n",
      "Speed: 2.4ms preprocess, 28.1ms inference, 34.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qs, 16.6ms\n",
      "Speed: 2.6ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qs, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qs, 12.4ms\n",
      "Speed: 2.2ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Jh, 13.2ms\n",
      "Speed: 3.0ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Jh, 15.0ms\n",
      "Speed: 12.7ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Jh, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 68.4ms\n",
      "Speed: 2.1ms preprocess, 68.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 21.7ms\n",
      "Speed: 2.0ms preprocess, 21.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 21.2ms\n",
      "Speed: 2.2ms preprocess, 21.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 3h, 1 5c, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 14.2ms\n",
      "Speed: 3.4ms preprocess, 14.2ms inference, 17.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 19.8ms\n",
      "Speed: 21.8ms preprocess, 19.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 12.6ms\n",
      "Speed: 1.8ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 23.4ms\n",
      "Speed: 2.7ms preprocess, 23.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5c, 42.5ms\n",
      "Speed: 2.4ms preprocess, 42.5ms inference, 18.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 18.9ms\n",
      "Speed: 8.3ms preprocess, 18.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 3c, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 3c, 20.4ms\n",
      "Speed: 2.0ms preprocess, 20.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 22.4ms\n",
      "Speed: 2.0ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 12.2ms\n",
      "Speed: 2.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 13.0ms\n",
      "Speed: 2.7ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 16.4ms\n",
      "Speed: 2.7ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 13.5ms\n",
      "Speed: 8.3ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 14.6ms\n",
      "Speed: 3.4ms preprocess, 14.6ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jc, 65.8ms\n",
      "Speed: 3.9ms preprocess, 65.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 4h, 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 14.6ms\n",
      "Speed: 3.0ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 16.5ms\n",
      "Speed: 11.7ms preprocess, 16.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 22.8ms\n",
      "Speed: 3.0ms preprocess, 22.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 20.7ms\n",
      "Speed: 2.7ms preprocess, 20.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 4h, 21.7ms\n",
      "Speed: 2.8ms preprocess, 21.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7c, 53.8ms\n",
      "Speed: 7.6ms preprocess, 53.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7c, 12.7ms\n",
      "Speed: 7.3ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7c, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7c, 22.0ms\n",
      "Speed: 3.2ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7c, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 7h, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 7h, 19.1ms\n",
      "Speed: 12.8ms preprocess, 19.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 7h, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 7h, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 22.1ms\n",
      "Speed: 2.5ms preprocess, 22.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 10.6ms\n",
      "Speed: 3.1ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 68.8ms\n",
      "Speed: 3.1ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 10.7ms\n",
      "Speed: 6.1ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 13.6ms\n",
      "Speed: 3.0ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 20.1ms\n",
      "Speed: 2.6ms preprocess, 20.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 12.8ms\n",
      "Speed: 2.5ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Qd, 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 4hs, 1 7h, 14.7ms\n",
      "Speed: 2.3ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7h, 18.5ms\n",
      "Speed: 10.7ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7h, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7h, 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7h, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 23.8ms\n",
      "Speed: 2.7ms preprocess, 23.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 51.1ms\n",
      "Speed: 18.8ms preprocess, 51.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 28.3ms\n",
      "Speed: 3.5ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 12.2ms\n",
      "Speed: 3.3ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 23.0ms\n",
      "Speed: 5.2ms preprocess, 23.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kh, 66.1ms\n",
      "Speed: 2.2ms preprocess, 66.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 24.0ms\n",
      "Speed: 2.7ms preprocess, 24.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 11.7ms\n",
      "Speed: 3.0ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 77.3ms\n",
      "Speed: 3.3ms preprocess, 77.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 10.4ms\n",
      "Speed: 4.9ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 23.9ms\n",
      "Speed: 3.1ms preprocess, 23.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Kh, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Kh, 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Kh, 72.1ms\n",
      "Speed: 2.6ms preprocess, 72.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Kh, 12.1ms\n",
      "Speed: 12.8ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 14.5ms\n",
      "Speed: 15.8ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 21.0ms\n",
      "Speed: 3.3ms preprocess, 21.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 22.8ms\n",
      "Speed: 2.7ms preprocess, 22.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 67.3ms\n",
      "Speed: 20.0ms preprocess, 67.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 As, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 14.2ms\n",
      "Speed: 2.3ms preprocess, 14.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 15.4ms\n",
      "Speed: 13.0ms preprocess, 15.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 13.9ms\n",
      "Speed: 1.7ms preprocess, 13.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 58.8ms\n",
      "Speed: 12.1ms preprocess, 58.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 18.1ms\n",
      "Speed: 15.6ms preprocess, 18.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 As, 10.2ms\n",
      "Speed: 3.7ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 4s, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 4s, 13.2ms\n",
      "Speed: 5.8ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 4s, 11.6ms\n",
      "Speed: 3.7ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 4s, 13.0ms\n",
      "Speed: 2.4ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 4s, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 4s, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 22.6ms\n",
      "Speed: 3.4ms preprocess, 22.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 17.7ms\n",
      "Speed: 1.7ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 21.7ms\n",
      "Speed: 3.1ms preprocess, 21.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 66.3ms\n",
      "Speed: 12.8ms preprocess, 66.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 10.4ms\n",
      "Speed: 5.5ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 16.4ms\n",
      "Speed: 11.4ms preprocess, 16.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6d, 27.6ms\n",
      "Speed: 2.6ms preprocess, 27.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 6d, 35.4ms\n",
      "Speed: 1.9ms preprocess, 35.4ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 19.9ms\n",
      "Speed: 2.0ms preprocess, 19.9ms inference, 10.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 10.0ms\n",
      "Speed: 4.4ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 14.2ms\n",
      "Speed: 2.7ms preprocess, 14.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 15.1ms\n",
      "Speed: 10.3ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 15.5ms\n",
      "Speed: 3.3ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 12.5ms\n",
      "Speed: 3.5ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 12.6ms\n",
      "Speed: 2.8ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 18.7ms\n",
      "Speed: 2.7ms preprocess, 18.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 53.3ms\n",
      "Speed: 23.2ms preprocess, 53.3ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 10.4ms\n",
      "Speed: 6.1ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 11.4ms\n",
      "Speed: 1.8ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 15.0ms\n",
      "Speed: 10.6ms preprocess, 15.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 18.1ms\n",
      "Speed: 2.9ms preprocess, 18.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8c, 11.5ms\n",
      "Speed: 4.5ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kd, 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kd, 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kd, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kd, 70.8ms\n",
      "Speed: 2.7ms preprocess, 70.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kd, 13.2ms\n",
      "Speed: 12.5ms preprocess, 13.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kd, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 22.7ms\n",
      "Speed: 2.5ms preprocess, 22.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Kd, 14.2ms\n",
      "Speed: 2.7ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 13.5ms\n",
      "Speed: 2.0ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 14.0ms\n",
      "Speed: 3.1ms preprocess, 14.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 13.1ms\n",
      "Speed: 10.7ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 11.8ms\n",
      "Speed: 3.3ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 59.5ms\n",
      "Speed: 7.7ms preprocess, 59.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 21.3ms\n",
      "Speed: 2.4ms preprocess, 21.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 15.7ms\n",
      "Speed: 1.8ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 10.5ms\n",
      "Speed: 3.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 20.6ms\n",
      "Speed: 2.5ms preprocess, 20.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 14.1ms\n",
      "Speed: 2.5ms preprocess, 14.1ms inference, 35.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 22.3ms\n",
      "Speed: 14.0ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 14.7ms\n",
      "Speed: 3.2ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 20.0ms\n",
      "Speed: 4.0ms preprocess, 20.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 12.2ms\n",
      "Speed: 3.6ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 23.9ms\n",
      "Speed: 2.9ms preprocess, 23.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 13.5ms\n",
      "Speed: 2.9ms preprocess, 13.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 8h, 23.2ms\n",
      "Speed: 6.2ms preprocess, 23.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Ad, 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Ad, 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 33.7ms\n",
      "Speed: 46.6ms preprocess, 33.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 25.8ms\n",
      "Speed: 4.0ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 25.2ms\n",
      "Speed: 2.8ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 15.8ms\n",
      "Speed: 2.4ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 20.8ms\n",
      "Speed: 2.8ms preprocess, 20.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 50.4ms\n",
      "Speed: 11.7ms preprocess, 50.4ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 25.1ms\n",
      "Speed: 2.0ms preprocess, 25.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 13.1ms\n",
      "Speed: 3.3ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 20.6ms\n",
      "Speed: 3.4ms preprocess, 20.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Ad, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 13.1ms\n",
      "Speed: 3.7ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 70.1ms\n",
      "Speed: 2.7ms preprocess, 70.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 19.6ms\n",
      "Speed: 2.1ms preprocess, 19.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 25.7ms\n",
      "Speed: 3.7ms preprocess, 25.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 6h, 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 16.9ms\n",
      "Speed: 2.0ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 19.8ms\n",
      "Speed: 3.3ms preprocess, 19.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 17.6ms\n",
      "Speed: 2.5ms preprocess, 17.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 12.9ms\n",
      "Speed: 1.8ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Js, 23.5ms\n",
      "Speed: 1.8ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 28.0ms\n",
      "Speed: 2.8ms preprocess, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.5ms\n",
      "Speed: 4.0ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 16.3ms\n",
      "Speed: 2.8ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 10.1ms\n",
      "Speed: 5.0ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.3ms\n",
      "Speed: 3.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 66.5ms\n",
      "Speed: 9.4ms preprocess, 66.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.4ms\n",
      "Speed: 3.6ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 11.5ms\n",
      "Speed: 3.3ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 27.7ms\n",
      "Speed: 2.4ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 23.0ms\n",
      "Speed: 2.8ms preprocess, 23.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 14.3ms\n",
      "Speed: 2.8ms preprocess, 14.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 9.8ms\n",
      "Speed: 4.0ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 54.6ms\n",
      "Speed: 11.9ms preprocess, 54.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 15.9ms\n",
      "Speed: 3.2ms preprocess, 15.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.4ms\n",
      "Speed: 3.6ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 25.9ms\n",
      "Speed: 3.0ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 13.4ms\n",
      "Speed: 2.2ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Js, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 20.4ms\n",
      "Speed: 2.9ms preprocess, 20.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 14.4ms\n",
      "Speed: 2.9ms preprocess, 14.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 39.3ms\n",
      "Speed: 14.9ms preprocess, 39.3ms inference, 16.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 20.1ms\n",
      "Speed: 2.9ms preprocess, 20.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 19.8ms\n",
      "Speed: 2.9ms preprocess, 19.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 11.0ms\n",
      "Speed: 2.2ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 9d, 24.1ms\n",
      "Speed: 2.2ms preprocess, 24.1ms inference, 32.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 20.9ms\n",
      "Speed: 2.3ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 18.0ms\n",
      "Speed: 2.2ms preprocess, 18.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 66.7ms\n",
      "Speed: 9.0ms preprocess, 66.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.9ms\n",
      "Speed: 3.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 24.4ms\n",
      "Speed: 2.7ms preprocess, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 14.5ms\n",
      "Speed: 2.3ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 23.1ms\n",
      "Speed: 3.2ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 14.3ms\n",
      "Speed: 2.1ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 28.9ms\n",
      "Speed: 3.5ms preprocess, 28.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 61.5ms\n",
      "Speed: 5.9ms preprocess, 61.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 21.9ms\n",
      "Speed: 2.0ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 24.9ms\n",
      "Speed: 3.9ms preprocess, 24.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9h, 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 23.8ms\n",
      "Speed: 2.7ms preprocess, 23.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 15.0ms\n",
      "Speed: 12.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 52.5ms\n",
      "Speed: 16.9ms preprocess, 52.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 24.1ms\n",
      "Speed: 2.1ms preprocess, 24.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 12.7ms\n",
      "Speed: 3.4ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 24.0ms\n",
      "Speed: 2.9ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 20.9ms\n",
      "Speed: 2.5ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 70.4ms\n",
      "Speed: 4.0ms preprocess, 70.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 17.5ms\n",
      "Speed: 2.2ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 14.9ms\n",
      "Speed: 1.9ms preprocess, 14.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 10.1ms\n",
      "Speed: 3.3ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 23.4ms\n",
      "Speed: 2.8ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 19.0ms\n",
      "Speed: 3.6ms preprocess, 19.0ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 14.3ms\n",
      "Speed: 3.0ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 37.2ms\n",
      "Speed: 45.0ms preprocess, 37.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 21.6ms\n",
      "Speed: 3.5ms preprocess, 21.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 18.4ms\n",
      "Speed: 2.5ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 14.3ms\n",
      "Speed: 1.8ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 16.5ms\n",
      "Speed: 3.2ms preprocess, 16.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 40.0ms\n",
      "Speed: 47.1ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 13.4ms\n",
      "Speed: 1.8ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.8ms\n",
      "Speed: 3.5ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 24.8ms\n",
      "Speed: 3.3ms preprocess, 24.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 14.8ms\n",
      "Speed: 2.4ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 72.2ms\n",
      "Speed: 4.7ms preprocess, 72.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 23.2ms\n",
      "Speed: 3.2ms preprocess, 23.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 17.0ms\n",
      "Speed: 2.9ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 22.8ms\n",
      "Speed: 3.5ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.1ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 1.8ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 58.3ms preprocess, 14.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.4ms\n",
      "Speed: 2.6ms preprocess, 25.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.2ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 70.1ms\n",
      "Speed: 2.4ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.1ms\n",
      "Speed: 2.5ms preprocess, 21.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 3.2ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.6ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.1ms\n",
      "Speed: 4.1ms preprocess, 21.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.3ms\n",
      "Speed: 3.6ms preprocess, 25.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 39.6ms\n",
      "Speed: 1.8ms preprocess, 39.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.0ms\n",
      "Speed: 4.2ms preprocess, 23.0ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 4.2ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.5ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.0ms\n",
      "Speed: 2.4ms preprocess, 19.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 53.5ms\n",
      "Speed: 2.2ms preprocess, 53.5ms inference, 17.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 6.8ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.5ms\n",
      "Speed: 1.8ms preprocess, 22.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 67.3ms\n",
      "Speed: 1.9ms preprocess, 67.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.8ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.4ms\n",
      "Speed: 13.8ms preprocess, 16.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.2ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 2.8ms preprocess, 21.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 42.4ms\n",
      "Speed: 2.3ms preprocess, 42.4ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.0ms\n",
      "Speed: 13.6ms preprocess, 28.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 4.2ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.4ms\n",
      "Speed: 3.5ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 2.0ms preprocess, 13.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.2ms\n",
      "Speed: 43.3ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 3.3ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.3ms\n",
      "Speed: 2.5ms preprocess, 22.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.1ms\n",
      "Speed: 3.2ms preprocess, 19.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 36.4ms\n",
      "Speed: 2.5ms preprocess, 36.4ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.3ms\n",
      "Speed: 2.3ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 13.9ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.4ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.1ms\n",
      "Speed: 2.5ms preprocess, 24.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.6ms\n",
      "Speed: 1.9ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.1ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 2.4ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.6ms\n",
      "Speed: 4.0ms preprocess, 20.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 69.3ms\n",
      "Speed: 3.1ms preprocess, 69.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 4.3ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.2ms\n",
      "Speed: 2.3ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 11.7ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 64.3ms\n",
      "Speed: 1.9ms preprocess, 64.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 3.5ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 3.7ms preprocess, 17.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 3.3ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.8ms\n",
      "Speed: 3.3ms preprocess, 28.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 2.4ms preprocess, 23.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 4.0ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.5ms\n",
      "Speed: 7.8ms preprocess, 22.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.0ms\n",
      "Speed: 1.9ms preprocess, 21.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.5ms\n",
      "Speed: 1.7ms preprocess, 18.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 6.4ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.9ms\n",
      "Speed: 2.5ms preprocess, 27.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.6ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 57.7ms\n",
      "Speed: 20.3ms preprocess, 57.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.3ms\n",
      "Speed: 3.4ms preprocess, 29.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 63.8ms\n",
      "Speed: 2.6ms preprocess, 63.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 6.6ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 17.4ms\n",
      "Speed: 10.2ms preprocess, 17.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 3.8ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.9ms\n",
      "Speed: 3.1ms preprocess, 26.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 4.4ms preprocess, 13.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 64.8ms\n",
      "Speed: 2.4ms preprocess, 64.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.6ms\n",
      "Speed: 3.0ms preprocess, 20.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 16.8ms\n",
      "Speed: 2.7ms preprocess, 16.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 12.7ms\n",
      "Speed: 5.3ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 11.9ms\n",
      "Speed: 3.6ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 21.2ms\n",
      "Speed: 3.3ms preprocess, 21.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 12.6ms\n",
      "Speed: 2.3ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 23.0ms\n",
      "Speed: 3.3ms preprocess, 23.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 10.3ms\n",
      "Speed: 4.1ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 14.8ms\n",
      "Speed: 56.2ms preprocess, 14.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 12.7ms\n",
      "Speed: 4.2ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 10.3ms\n",
      "Speed: 24.4ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 19.3ms\n",
      "Speed: 44.6ms preprocess, 19.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 10.6ms\n",
      "Speed: 3.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ks, 23.7ms\n",
      "Speed: 2.9ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Ks, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Ks, 13.3ms\n",
      "Speed: 2.4ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Ks, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Kh, 22.6ms\n",
      "Speed: 2.8ms preprocess, 22.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Kh, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Kh, 10.8ms\n",
      "Speed: 2.9ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Kh, 19.9ms\n",
      "Speed: 2.5ms preprocess, 19.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Kh, 10.0ms\n",
      "Speed: 3.7ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Kh, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 6s, 15.3ms\n",
      "Speed: 53.4ms preprocess, 15.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 6s, 15.0ms\n",
      "Speed: 7.7ms preprocess, 15.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 6s, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 6s, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 7s, 9.8ms\n",
      "Speed: 3.4ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 9c, 21.7ms\n",
      "Speed: 2.6ms preprocess, 21.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qc, 13.5ms\n",
      "Speed: 3.1ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qc, 31.7ms\n",
      "Speed: 49.2ms preprocess, 31.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qc, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Qc, 16.0ms\n",
      "Speed: 1.9ms preprocess, 16.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Ah, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 Ah, 20.9ms\n",
      "Speed: 3.6ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Jc, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 As, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ac, 24.3ms\n",
      "Speed: 2.8ms preprocess, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Ac, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jd, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Qh, 11.0ms\n",
      "Speed: 4.2ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Qh, 48.7ms\n",
      "Speed: 2.6ms preprocess, 48.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Qh, 17.7ms\n",
      "Speed: 3.1ms preprocess, 17.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Qh, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Kd, 26.8ms\n",
      "Speed: 3.9ms preprocess, 26.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Kd, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Kd, 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Kd, 22.3ms\n",
      "Speed: 3.4ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 As, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 As, 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9h, 25.1ms\n",
      "Speed: 2.8ms preprocess, 25.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9h, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9h, 13.5ms\n",
      "Speed: 3.1ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 9h, 11.9ms\n",
      "Speed: 12.8ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 8s, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 8s, 12.8ms\n",
      "Speed: 3.8ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 8s, 14.2ms\n",
      "Speed: 11.5ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6c, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 6c, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4h, 74.1ms\n",
      "Speed: 3.6ms preprocess, 74.1ms inference, 12.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Js, 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kc, 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Kc, 22.1ms\n",
      "Speed: 3.1ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7d, 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7d, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Ad, 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Ad, 29.3ms\n",
      "Speed: 3.2ms preprocess, 29.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7h, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7h, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 7h, 19.0ms\n",
      "Speed: 2.8ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9d, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 9d, 38.3ms\n",
      "Speed: 3.8ms preprocess, 38.3ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 9d, 12.7ms\n",
      "Speed: 4.2ms preprocess, 12.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 9d, 15.1ms\n",
      "Speed: 2.8ms preprocess, 15.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3d, 11.2ms\n",
      "Speed: 3.8ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3d, 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 3d, 20.2ms\n",
      "Speed: 3.0ms preprocess, 20.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7c, 12.0ms\n",
      "Speed: 2.4ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7c, 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 7c, 15.5ms\n",
      "Speed: 4.5ms preprocess, 15.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 7c, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7c, 20.4ms\n",
      "Speed: 2.7ms preprocess, 20.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7c, 11.8ms\n",
      "Speed: 4.5ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 5h, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 5h, 13.8ms\n",
      "Speed: 4.2ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 5h, 12.9ms\n",
      "Speed: 3.1ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 8h, 15.5ms\n",
      "Speed: 13.9ms preprocess, 15.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 8h, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5h, 58.9ms\n",
      "Speed: 2.9ms preprocess, 58.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5h, 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5h, 14.2ms\n",
      "Speed: 11.8ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5d, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5d, 25.2ms\n",
      "Speed: 2.1ms preprocess, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qd, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 Qd, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 BJoker, 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 BJoker, 10.1ms\n",
      "Speed: 4.1ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 BJoker, 27.1ms\n",
      "Speed: 3.3ms preprocess, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 BJoker, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 BJoker, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 BJoker, 69.2ms\n",
      "Speed: 3.1ms preprocess, 69.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 BJoker, 17.9ms\n",
      "Speed: 3.3ms preprocess, 17.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 5s, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qs, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qs, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qs, 22.4ms\n",
      "Speed: 3.5ms preprocess, 22.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 SJoker, 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 SJoker, 15.7ms\n",
      "Speed: 3.0ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 SJoker, 10.1ms\n",
      "Speed: 3.4ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 SJoker, 23.7ms\n",
      "Speed: 3.4ms preprocess, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 SJoker, 10.4ms\n",
      "Speed: 2.7ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 SJoker, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 SJoker, 34.9ms\n",
      "Speed: 2.5ms preprocess, 34.9ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 4s, 17.3ms\n",
      "Speed: 11.5ms preprocess, 17.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 4s, 11.3ms\n",
      "Speed: 18.3ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 4s, 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 4s, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6d, 13.5ms\n",
      "Speed: 1.9ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 6d, 14.8ms\n",
      "Speed: 12.5ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 50.9ms\n",
      "Speed: 2.3ms preprocess, 50.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 27.9ms\n",
      "Speed: 2.2ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.3ms\n",
      "Speed: 5.2ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 22.8ms\n",
      "Speed: 3.1ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 13.4ms\n",
      "Speed: 3.2ms preprocess, 13.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 23.2ms\n",
      "Speed: 2.6ms preprocess, 23.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 15.6ms\n",
      "Speed: 3.5ms preprocess, 15.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 58.6ms\n",
      "Speed: 12.5ms preprocess, 58.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.2ms\n",
      "Speed: 9.6ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 24.7ms\n",
      "Speed: 3.4ms preprocess, 24.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 29.0ms\n",
      "Speed: 3.9ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 9.7ms\n",
      "Speed: 2.9ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 20.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 16.8ms\n",
      "Speed: 3.2ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 6d, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6d, 22.3ms\n",
      "Speed: 2.5ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 15.5ms\n",
      "Speed: 2.8ms preprocess, 15.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 65.4ms\n",
      "Speed: 3.2ms preprocess, 65.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 14.9ms\n",
      "Speed: 3.0ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.0ms\n",
      "Speed: 3.9ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 11.5ms\n",
      "Speed: 3.5ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.8ms\n",
      "Speed: 2.8ms preprocess, 17.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 5.6ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 74.9ms\n",
      "Speed: 2.3ms preprocess, 74.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 6.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.8ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.7ms preprocess, 11.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.5ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 80.1ms\n",
      "Speed: 2.9ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.1ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.9ms\n",
      "Speed: 3.2ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 12.5ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 63.5ms\n",
      "Speed: 2.3ms preprocess, 63.5ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.6ms\n",
      "Speed: 2.8ms preprocess, 25.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.7ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 83.6ms\n",
      "Speed: 2.3ms preprocess, 83.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.3ms\n",
      "Speed: 3.4ms preprocess, 18.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.3ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.7ms\n",
      "Speed: 3.5ms preprocess, 22.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.5ms\n",
      "Speed: 3.0ms preprocess, 20.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.6ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 4.1ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 6.4ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 12.1ms preprocess, 14.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.5ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.7ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 41.3ms\n",
      "Speed: 30.8ms preprocess, 41.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 9.7ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.8ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.2ms\n",
      "Speed: 3.3ms preprocess, 20.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 62.3ms\n",
      "Speed: 3.3ms preprocess, 62.3ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.0ms\n",
      "Speed: 2.3ms preprocess, 15.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.0ms\n",
      "Speed: 11.4ms preprocess, 17.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 2.1ms preprocess, 20.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.8ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.6ms\n",
      "Speed: 2.8ms preprocess, 22.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 2.7ms preprocess, 14.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 6.4ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.6ms\n",
      "Speed: 3.8ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.8ms\n",
      "Speed: 38.4ms preprocess, 17.8ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 5.1ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.3ms\n",
      "Speed: 2.3ms preprocess, 27.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 3.2ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 5.5ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.1ms\n",
      "Speed: 2.6ms preprocess, 27.1ms inference, 39.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.7ms\n",
      "Speed: 3.9ms preprocess, 19.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.9ms\n",
      "Speed: 3.5ms preprocess, 24.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.6ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 7.5ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.2ms\n",
      "Speed: 10.1ms preprocess, 15.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 2.7ms preprocess, 13.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.1ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.7ms\n",
      "Speed: 2.6ms preprocess, 30.7ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 31.2ms\n",
      "Speed: 15.2ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.7ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 3.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 23.5ms\n",
      "Speed: 3.4ms preprocess, 23.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 24.4ms\n",
      "Speed: 3.0ms preprocess, 24.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 1 2d, 12.3ms\n",
      "Speed: 5.6ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.4ms\n",
      "Speed: 4.2ms preprocess, 17.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 67.2ms\n",
      "Speed: 3.4ms preprocess, 67.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 2.5ms preprocess, 17.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.6ms\n",
      "Speed: 1.9ms preprocess, 21.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 1.7ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 14.8ms\n",
      "Speed: 2.0ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 11.3ms\n",
      "Speed: 3.7ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 11.3ms\n",
      "Speed: 3.5ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 14.8ms\n",
      "Speed: 13.3ms preprocess, 14.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 14.5ms\n",
      "Speed: 3.6ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 65.7ms\n",
      "Speed: 3.2ms preprocess, 65.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Ad, 18.9ms\n",
      "Speed: 3.3ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 15.2ms\n",
      "Speed: 3.7ms preprocess, 15.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.7ms\n",
      "Speed: 9.9ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.1ms\n",
      "Speed: 6.8ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.4ms\n",
      "Speed: 4.6ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 22.0ms\n",
      "Speed: 2.1ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 14.5ms\n",
      "Speed: 4.7ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 48.6ms\n",
      "Speed: 9.5ms preprocess, 48.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.7ms\n",
      "Speed: 13.3ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 24.9ms\n",
      "Speed: 3.1ms preprocess, 24.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 13.3ms\n",
      "Speed: 3.3ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 19.3ms\n",
      "Speed: 3.2ms preprocess, 19.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 13.8ms\n",
      "Speed: 4.8ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 10.9ms\n",
      "Speed: 3.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 22.2ms\n",
      "Speed: 3.4ms preprocess, 22.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.6ms\n",
      "Speed: 2.3ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 21.9ms\n",
      "Speed: 3.1ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 65.0ms\n",
      "Speed: 2.3ms preprocess, 65.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 10.0ms\n",
      "Speed: 4.2ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 20.1ms\n",
      "Speed: 2.1ms preprocess, 20.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 22.3ms\n",
      "Speed: 7.3ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.4ms\n",
      "Speed: 3.7ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 43.8ms\n",
      "Speed: 9.7ms preprocess, 43.8ms inference, 19.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 17.8ms\n",
      "Speed: 2.7ms preprocess, 17.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 27.2ms\n",
      "Speed: 2.8ms preprocess, 27.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 27.8ms\n",
      "Speed: 2.4ms preprocess, 27.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 19.0ms\n",
      "Speed: 34.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Ks, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 22.9ms\n",
      "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 13.7ms\n",
      "Speed: 2.6ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 22.8ms\n",
      "Speed: 3.9ms preprocess, 22.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 73.2ms\n",
      "Speed: 4.5ms preprocess, 73.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 18.3ms\n",
      "Speed: 2.6ms preprocess, 18.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ks, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 9c, 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 9c, 23.5ms\n",
      "Speed: 2.6ms preprocess, 23.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 9c, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 9c, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 23.2ms\n",
      "Speed: 2.5ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 68.0ms\n",
      "Speed: 14.0ms preprocess, 68.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 9c, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kc, 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 11.9ms\n",
      "Speed: 3.6ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 18.3ms\n",
      "Speed: 3.4ms preprocess, 18.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 54.8ms\n",
      "Speed: 6.0ms preprocess, 54.8ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 27.1ms\n",
      "Speed: 4.8ms preprocess, 27.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 10.4ms\n",
      "Speed: 4.0ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Kh, 12.9ms\n",
      "Speed: 3.3ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Qh, 11.7ms\n",
      "Speed: 4.0ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ts, 1 6h, 22.7ms\n",
      "Speed: 3.3ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 12.3ms\n",
      "Speed: 2.8ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 24.2ms\n",
      "Speed: 4.8ms preprocess, 24.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 12.9ms\n",
      "Speed: 3.6ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 21.0ms\n",
      "Speed: 2.9ms preprocess, 21.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6h, 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 6s, 62.1ms\n",
      "Speed: 7.6ms preprocess, 62.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6s, 11.5ms\n",
      "Speed: 4.1ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6s, 10.8ms\n",
      "Speed: 3.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6s, 27.4ms\n",
      "Speed: 3.7ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6s, 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6s, 10.5ms\n",
      "Speed: 3.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6s, 16.8ms\n",
      "Speed: 2.0ms preprocess, 16.8ms inference, 44.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 17.4ms\n",
      "Speed: 2.4ms preprocess, 17.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qc, 12.0ms\n",
      "Speed: 6.7ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 14.5ms\n",
      "Speed: 3.6ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 16.3ms\n",
      "Speed: 9.5ms preprocess, 16.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Qc, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7s, 13.8ms\n",
      "Speed: 2.7ms preprocess, 13.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7s, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7s, 23.5ms\n",
      "Speed: 6.1ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7s, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7s, 12.7ms\n",
      "Speed: 2.1ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 7s, 72.7ms\n",
      "Speed: 2.6ms preprocess, 72.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 7s, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 7s, 12.1ms\n",
      "Speed: 3.7ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 7s, 26.6ms\n",
      "Speed: 3.4ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 7s, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 7s, 13.0ms\n",
      "Speed: 2.5ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 11.2ms\n",
      "Speed: 4.1ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Ah, 12.6ms\n",
      "Speed: 3.2ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Ah, 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Ah, 24.0ms\n",
      "Speed: 2.2ms preprocess, 24.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Ah, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Ah, 13.8ms\n",
      "Speed: 3.4ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Ah, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Jc, 13.0ms\n",
      "Speed: 3.4ms preprocess, 13.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Jc, 16.8ms\n",
      "Speed: 6.8ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Jc, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Jc, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Jc, 39.5ms\n",
      "Speed: 8.9ms preprocess, 39.5ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8c, 22.4ms\n",
      "Speed: 13.5ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8c, 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 8c, 10.7ms\n",
      "Speed: 4.1ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 8c, 24.4ms\n",
      "Speed: 2.8ms preprocess, 24.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 8c, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 8c, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Ac, 10.3ms\n",
      "Speed: 3.7ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Ac, 14.8ms\n",
      "Speed: 18.0ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Ac, 12.3ms\n",
      "Speed: 2.6ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ac, 23.2ms\n",
      "Speed: 3.3ms preprocess, 23.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ac, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ac, 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Ac, 24.6ms\n",
      "Speed: 3.5ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 14.3ms\n",
      "Speed: 2.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 12.5ms\n",
      "Speed: 5.3ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 39.0ms\n",
      "Speed: 3.1ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 15.0ms\n",
      "Speed: 11.8ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 9s, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 21.5ms\n",
      "Speed: 3.5ms preprocess, 21.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qh, 10.7ms\n",
      "Speed: 3.9ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 13.6ms\n",
      "Speed: 17.3ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 20.9ms\n",
      "Speed: 2.6ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 12.5ms\n",
      "Speed: 4.2ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 75.5ms\n",
      "Speed: 3.4ms preprocess, 75.5ms inference, 13.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 80.8ms\n",
      "Speed: 4.1ms preprocess, 80.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jh, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jh, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 11.7ms\n",
      "Speed: 6.8ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 15.3ms\n",
      "Speed: 11.4ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 11.2ms\n",
      "Speed: 1.9ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 15.1ms\n",
      "Speed: 3.2ms preprocess, 15.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Jh, 14.5ms\n",
      "Speed: 14.0ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5c, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5c, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5c, 10.3ms\n",
      "Speed: 3.8ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5c, 19.1ms\n",
      "Speed: 69.0ms preprocess, 19.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Qd, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qd, 12.0ms\n",
      "Speed: 4.8ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qd, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qd, 26.5ms\n",
      "Speed: 2.8ms preprocess, 26.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qd, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qd, 72.9ms\n",
      "Speed: 3.4ms preprocess, 72.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 10.2ms\n",
      "Speed: 9.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 10.8ms\n",
      "Speed: 3.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 34.3ms\n",
      "Speed: 8.8ms preprocess, 34.3ms inference, 10.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 16.6ms\n",
      "Speed: 4.0ms preprocess, 16.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 14.0ms\n",
      "Speed: 11.4ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Qd, 13.9ms\n",
      "Speed: 3.2ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8d, 10.1ms\n",
      "Speed: 4.2ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 11.5ms\n",
      "Speed: 3.3ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 42.2ms\n",
      "Speed: 3.3ms preprocess, 42.2ms inference, 26.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 17.0ms\n",
      "Speed: 2.8ms preprocess, 17.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 11.2ms\n",
      "Speed: 3.2ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 12.7ms\n",
      "Speed: 3.4ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 18.9ms\n",
      "Speed: 4.2ms preprocess, 18.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 9h, 14.0ms\n",
      "Speed: 4.1ms preprocess, 14.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8s, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8s, 22.6ms\n",
      "Speed: 2.1ms preprocess, 22.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8s, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8s, 58.9ms\n",
      "Speed: 2.8ms preprocess, 58.9ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8s, 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 BJoker, 21.4ms\n",
      "Speed: 2.8ms preprocess, 21.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 BJoker, 13.0ms\n",
      "Speed: 3.3ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 12.3ms\n",
      "Speed: 3.3ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 22.7ms\n",
      "Speed: 3.4ms preprocess, 22.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 24.8ms\n",
      "Speed: 2.8ms preprocess, 24.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 13.3ms\n",
      "Speed: 3.3ms preprocess, 13.3ms inference, 8.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 BJoker, 30.4ms\n",
      "Speed: 12.5ms preprocess, 30.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 11.5ms\n",
      "Speed: 4.7ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6c, 12.1ms\n",
      "Speed: 2.8ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 24.6ms\n",
      "Speed: 3.2ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 23.8ms\n",
      "Speed: 2.3ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 12.9ms\n",
      "Speed: 3.6ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 15.6ms\n",
      "Speed: 12.5ms preprocess, 15.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 10.4ms\n",
      "Speed: 5.4ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 5s, 52.1ms\n",
      "Speed: 14.2ms preprocess, 52.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Jd, 1 Js, 22.4ms\n",
      "Speed: 4.2ms preprocess, 22.4ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 10.4ms\n",
      "Speed: 4.0ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 11.3ms\n",
      "Speed: 2.9ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 11.5ms\n",
      "Speed: 3.8ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 15.0ms\n",
      "Speed: 12.1ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 13.9ms\n",
      "Speed: 4.4ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 11.9ms\n",
      "Speed: 17.2ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Js, 11.6ms\n",
      "Speed: 4.1ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 22.3ms\n",
      "Speed: 2.7ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 12.0ms\n",
      "Speed: 2.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 19.8ms\n",
      "Speed: 3.3ms preprocess, 19.8ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 51.0ms\n",
      "Speed: 13.1ms preprocess, 51.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 9.9ms\n",
      "Speed: 3.9ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 16.6ms\n",
      "Speed: 1.8ms preprocess, 16.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 10.2ms\n",
      "Speed: 3.3ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 23.0ms\n",
      "Speed: 3.5ms preprocess, 23.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 20.3ms\n",
      "Speed: 3.2ms preprocess, 20.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Qs, 13.2ms\n",
      "Speed: 2.7ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 SJoker, 21.2ms\n",
      "Speed: 3.2ms preprocess, 21.2ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 12.1ms\n",
      "Speed: 3.9ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 73.0ms\n",
      "Speed: 3.0ms preprocess, 73.0ms inference, 9.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 13.3ms\n",
      "Speed: 2.2ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 11.0ms\n",
      "Speed: 4.4ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 20.9ms\n",
      "Speed: 3.2ms preprocess, 20.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 11.2ms\n",
      "Speed: 3.5ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 SJoker, 23.9ms\n",
      "Speed: 3.5ms preprocess, 23.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 25.5ms\n",
      "Speed: 20.3ms preprocess, 25.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 16.8ms\n",
      "Speed: 3.7ms preprocess, 16.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 14.2ms\n",
      "Speed: 10.9ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 20.8ms\n",
      "Speed: 2.8ms preprocess, 20.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 64.9ms\n",
      "Speed: 5.4ms preprocess, 64.9ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 12.8ms\n",
      "Speed: 4.0ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 19.1ms\n",
      "Speed: 7.3ms preprocess, 19.1ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 4s, 15.0ms\n",
      "Speed: 4.8ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 4c, 12.2ms\n",
      "Speed: 4.5ms preprocess, 12.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 4c, 70.0ms\n",
      "Speed: 4.5ms preprocess, 70.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 35.3ms\n",
      "Speed: 4.6ms preprocess, 35.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 21.4ms\n",
      "Speed: 3.1ms preprocess, 21.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 22.7ms\n",
      "Speed: 3.2ms preprocess, 22.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 25.7ms\n",
      "Speed: 2.8ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Kc, 12.0ms\n",
      "Speed: 3.4ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Kc, 12.1ms\n",
      "Speed: 2.7ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Kc, 11.4ms\n",
      "Speed: 3.2ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Kc, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Kc, 22.7ms\n",
      "Speed: 2.9ms preprocess, 22.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 59.9ms\n",
      "Speed: 12.3ms preprocess, 59.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 20.7ms\n",
      "Speed: 2.0ms preprocess, 20.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 11.4ms\n",
      "Speed: 3.9ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 12.6ms\n",
      "Speed: 3.9ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 57.7ms\n",
      "Speed: 6.1ms preprocess, 57.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 22.9ms\n",
      "Speed: 3.1ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 14.1ms\n",
      "Speed: 3.4ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 22.9ms\n",
      "Speed: 3.9ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 15.5ms\n",
      "Speed: 54.6ms preprocess, 15.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2s, 15.2ms\n",
      "Speed: 9.6ms preprocess, 15.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 10.0ms\n",
      "Speed: 5.1ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 64.7ms\n",
      "Speed: 3.2ms preprocess, 64.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 19.5ms\n",
      "Speed: 4.2ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 11.8ms\n",
      "Speed: 3.4ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 11.7ms\n",
      "Speed: 3.8ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 70.7ms\n",
      "Speed: 2.6ms preprocess, 70.7ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 11.2ms\n",
      "Speed: 3.7ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 20.9ms\n",
      "Speed: 4.3ms preprocess, 20.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 15.4ms\n",
      "Speed: 2.9ms preprocess, 15.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 9.8ms\n",
      "Speed: 4.8ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Td, 23.3ms\n",
      "Speed: 3.2ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 2c, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 58.1ms\n",
      "Speed: 3.2ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 20.3ms\n",
      "Speed: 4.1ms preprocess, 20.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 23.7ms\n",
      "Speed: 2.7ms preprocess, 23.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.1ms\n",
      "Speed: 3.3ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.1ms\n",
      "Speed: 4.8ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 69.9ms\n",
      "Speed: 2.0ms preprocess, 69.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.5ms\n",
      "Speed: 9.1ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.4ms\n",
      "Speed: 4.1ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 21.8ms\n",
      "Speed: 3.7ms preprocess, 21.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.0ms\n",
      "Speed: 4.5ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 16.0ms\n",
      "Speed: 3.3ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.1ms\n",
      "Speed: 5.7ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.1ms\n",
      "Speed: 4.9ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 67.1ms\n",
      "Speed: 2.3ms preprocess, 67.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 18.6ms\n",
      "Speed: 2.2ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 9.7ms\n",
      "Speed: 3.4ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 12.4ms\n",
      "Speed: 3.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 14.4ms\n",
      "Speed: 2.6ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 19.2ms\n",
      "Speed: 4.6ms preprocess, 19.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.1ms\n",
      "Speed: 3.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 15.4ms\n",
      "Speed: 4.2ms preprocess, 15.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 13.7ms\n",
      "Speed: 10.4ms preprocess, 13.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 25.1ms\n",
      "Speed: 3.4ms preprocess, 25.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 18.1ms\n",
      "Speed: 2.3ms preprocess, 18.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 37.2ms\n",
      "Speed: 4.0ms preprocess, 37.2ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 18.5ms\n",
      "Speed: 13.1ms preprocess, 18.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.3ms\n",
      "Speed: 3.5ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 21.1ms\n",
      "Speed: 3.9ms preprocess, 21.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 9.9ms\n",
      "Speed: 4.4ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 12.2ms\n",
      "Speed: 3.2ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 24.7ms\n",
      "Speed: 4.3ms preprocess, 24.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 20.9ms\n",
      "Speed: 4.4ms preprocess, 20.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 35.9ms\n",
      "Speed: 32.7ms preprocess, 35.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 14.5ms\n",
      "Speed: 8.4ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 23.9ms\n",
      "Speed: 2.8ms preprocess, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7d, 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 14.1ms\n",
      "Speed: 4.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 24.0ms\n",
      "Speed: 2.2ms preprocess, 24.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 13.7ms\n",
      "Speed: 2.1ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 18.7ms\n",
      "Speed: 11.6ms preprocess, 18.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 12.3ms\n",
      "Speed: 3.4ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 22.3ms\n",
      "Speed: 3.1ms preprocess, 22.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 24.0ms\n",
      "Speed: 4.2ms preprocess, 24.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 67.9ms\n",
      "Speed: 5.8ms preprocess, 67.9ms inference, 7.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 14.0ms\n",
      "Speed: 4.6ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 7d, 11.3ms\n",
      "Speed: 4.1ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 26.3ms\n",
      "Speed: 3.5ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 15.8ms\n",
      "Speed: 2.5ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 11.1ms\n",
      "Speed: 4.1ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 27.1ms\n",
      "Speed: 3.5ms preprocess, 27.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.5ms\n",
      "Speed: 3.5ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 23.6ms\n",
      "Speed: 2.8ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 13.9ms\n",
      "Speed: 2.8ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 25.7ms\n",
      "Speed: 3.5ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 12.2ms\n",
      "Speed: 3.4ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 22.8ms\n",
      "Speed: 3.8ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 54.6ms\n",
      "Speed: 10.3ms preprocess, 54.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 15.8ms\n",
      "Speed: 8.2ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 23.9ms\n",
      "Speed: 3.7ms preprocess, 23.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 14.3ms\n",
      "Speed: 4.6ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.0ms\n",
      "Speed: 4.3ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 15.8ms\n",
      "Speed: 3.1ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 13.9ms\n",
      "Speed: 11.6ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.9ms\n",
      "Speed: 3.8ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 32.9ms\n",
      "Speed: 2.1ms preprocess, 32.9ms inference, 22.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 15.9ms\n",
      "Speed: 4.4ms preprocess, 15.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 13.6ms\n",
      "Speed: 7.8ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.5ms\n",
      "Speed: 3.7ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 12.0ms\n",
      "Speed: 4.0ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.8ms\n",
      "Speed: 4.7ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 17.6ms\n",
      "Speed: 8.3ms preprocess, 17.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 14.3ms\n",
      "Speed: 3.7ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 3.3ms preprocess, 14.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 5.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 4.9ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.3ms\n",
      "Speed: 5.2ms preprocess, 24.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.9ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.6ms\n",
      "Speed: 3.4ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 7.8ms preprocess, 12.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 38.0ms\n",
      "Speed: 8.3ms preprocess, 38.0ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 2.3ms preprocess, 15.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.4ms\n",
      "Speed: 5.7ms preprocess, 17.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.4ms preprocess, 13.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.5ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 2.5ms preprocess, 23.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 3.9ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.8ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.5ms\n",
      "Speed: 4.1ms preprocess, 19.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 8.0ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.8ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.9ms\n",
      "Speed: 2.8ms preprocess, 23.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.7ms\n",
      "Speed: 4.4ms preprocess, 23.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 4.2ms preprocess, 13.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 34.8ms\n",
      "Speed: 55.5ms preprocess, 34.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.6ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 3.6ms preprocess, 14.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.7ms\n",
      "Speed: 3.5ms preprocess, 24.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 3.3ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 59.2ms\n",
      "Speed: 3.6ms preprocess, 59.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 2.4ms preprocess, 17.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 7.9ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.4ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.5ms\n",
      "Speed: 3.4ms preprocess, 27.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.1ms preprocess, 12.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 3.3ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.4ms\n",
      "Speed: 3.4ms preprocess, 24.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 3.9ms preprocess, 13.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 3.4ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 5.5ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.5ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.3ms\n",
      "Speed: 3.9ms preprocess, 23.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 63.7ms\n",
      "Speed: 7.9ms preprocess, 63.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.8ms\n",
      "Speed: 5.8ms preprocess, 13.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 5.5ms preprocess, 15.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.6ms\n",
      "Speed: 4.0ms preprocess, 24.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 2.6ms preprocess, 14.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 4.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 11.2ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 39.3ms\n",
      "Speed: 32.0ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 9.1ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 6.2ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.7ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 3.2ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 4.1ms preprocess, 14.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 12.3ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.8ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 4.0ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.1ms\n",
      "Speed: 3.3ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 4.0ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 4.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.7ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.1ms\n",
      "Speed: 3.5ms preprocess, 18.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 71.0ms\n",
      "Speed: 4.7ms preprocess, 71.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 4.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.3ms\n",
      "Speed: 3.5ms preprocess, 20.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.2ms\n",
      "Speed: 4.2ms preprocess, 22.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.0ms\n",
      "Speed: 2.7ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 4.4ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 60.2ms\n",
      "Speed: 3.1ms preprocess, 60.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.7ms\n",
      "Speed: 2.3ms preprocess, 18.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 5.4ms preprocess, 14.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 4.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.1ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.1ms\n",
      "Speed: 4.2ms preprocess, 26.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 3.4ms preprocess, 14.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 8.5ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 21.5ms\n",
      "Speed: 3.9ms preprocess, 21.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 4.1ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 70.3ms\n",
      "Speed: 2.3ms preprocess, 70.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 6.7ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 6.1ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 3.5ms preprocess, 14.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.0ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.0ms\n",
      "Speed: 2.7ms preprocess, 21.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.4ms\n",
      "Speed: 12.6ms preprocess, 19.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.2ms preprocess, 14.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.7ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 40.4ms\n",
      "Speed: 2.5ms preprocess, 40.4ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.2ms\n",
      "Speed: 12.0ms preprocess, 29.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 4.5ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.9ms\n",
      "Speed: 1.8ms preprocess, 16.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.3ms\n",
      "Speed: 2.2ms preprocess, 23.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.2ms\n",
      "Speed: 2.1ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.7ms\n",
      "Speed: 3.3ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 17.5ms\n",
      "Speed: 9.9ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.8ms\n",
      "Speed: 1.7ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.8ms\n",
      "Speed: 3.4ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.9ms\n",
      "Speed: 11.7ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 55.0ms\n",
      "Speed: 16.0ms preprocess, 55.0ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.4ms\n",
      "Speed: 5.4ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.9ms\n",
      "Speed: 3.5ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.6ms\n",
      "Speed: 62.8ms preprocess, 12.6ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.7ms\n",
      "Speed: 3.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 15.3ms\n",
      "Speed: 2.9ms preprocess, 15.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 21.8ms\n",
      "Speed: 2.4ms preprocess, 21.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.7ms\n",
      "Speed: 2.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 24.3ms\n",
      "Speed: 3.2ms preprocess, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 16.3ms\n",
      "Speed: 8.4ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.4ms\n",
      "Speed: 2.9ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 68.2ms\n",
      "Speed: 3.1ms preprocess, 68.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.4ms\n",
      "Speed: 7.4ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.1ms\n",
      "Speed: 7.2ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 15.5ms\n",
      "Speed: 8.9ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 51.0ms\n",
      "Speed: 2.4ms preprocess, 51.0ms inference, 17.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 19.9ms\n",
      "Speed: 2.8ms preprocess, 19.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.8ms\n",
      "Speed: 2.5ms preprocess, 14.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 17.7ms\n",
      "Speed: 3.9ms preprocess, 17.7ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.5ms\n",
      "Speed: 2.9ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.4ms\n",
      "Speed: 4.5ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 26.1ms\n",
      "Speed: 1.9ms preprocess, 26.1ms inference, 10.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 17.2ms\n",
      "Speed: 30.1ms preprocess, 17.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 9.9ms\n",
      "Speed: 4.4ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 18.8ms\n",
      "Speed: 3.4ms preprocess, 18.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.3ms\n",
      "Speed: 3.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 28.8ms\n",
      "Speed: 2.9ms preprocess, 28.8ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 21.4ms\n",
      "Speed: 36.7ms preprocess, 21.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.5ms\n",
      "Speed: 2.9ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 22.8ms\n",
      "Speed: 2.5ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 23.5ms\n",
      "Speed: 2.1ms preprocess, 23.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.1ms\n",
      "Speed: 2.3ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 19.9ms\n",
      "Speed: 3.1ms preprocess, 19.9ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 40.3ms\n",
      "Speed: 20.0ms preprocess, 40.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 17.2ms\n",
      "Speed: 11.0ms preprocess, 17.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.3ms\n",
      "Speed: 3.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 24.9ms\n",
      "Speed: 3.0ms preprocess, 24.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 24.5ms\n",
      "Speed: 2.3ms preprocess, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 20.2ms\n",
      "Speed: 2.8ms preprocess, 20.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.2ms\n",
      "Speed: 4.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.9ms\n",
      "Speed: 2.3ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.1ms\n",
      "Speed: 4.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 69.1ms\n",
      "Speed: 2.5ms preprocess, 69.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.9ms\n",
      "Speed: 2.2ms preprocess, 14.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 15.1ms\n",
      "Speed: 2.5ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 23.7ms\n",
      "Speed: 2.8ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.2ms\n",
      "Speed: 2.7ms preprocess, 13.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 45.7ms\n",
      "Speed: 24.5ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 20.9ms\n",
      "Speed: 3.2ms preprocess, 20.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.6ms\n",
      "Speed: 2.1ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 17.1ms\n",
      "Speed: 2.5ms preprocess, 17.1ms inference, 10.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 9.9ms\n",
      "Speed: 4.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.3ms\n",
      "Speed: 2.8ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.9ms\n",
      "Speed: 1.8ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 18.4ms\n",
      "Speed: 7.0ms preprocess, 18.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.5ms\n",
      "Speed: 3.1ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 26.3ms\n",
      "Speed: 4.3ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 38.2ms\n",
      "Speed: 11.8ms preprocess, 38.2ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 24.3ms\n",
      "Speed: 2.0ms preprocess, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 24.7ms\n",
      "Speed: 2.1ms preprocess, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.5ms\n",
      "Speed: 2.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 25.9ms\n",
      "Speed: 2.7ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.4ms\n",
      "Speed: 2.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 22.6ms\n",
      "Speed: 2.1ms preprocess, 22.6ms inference, 38.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 14.5ms\n",
      "Speed: 11.3ms preprocess, 14.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.2ms\n",
      "Speed: 2.3ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 17.2ms\n",
      "Speed: 2.5ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 58.5ms\n",
      "Speed: 14.4ms preprocess, 58.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.2ms\n",
      "Speed: 5.8ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.9ms\n",
      "Speed: 3.8ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 23.7ms\n",
      "Speed: 2.1ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 13.8ms\n",
      "Speed: 2.7ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 4h, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5d, 11.9ms\n",
      "Speed: 3.4ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5d, 19.5ms\n",
      "Speed: 3.6ms preprocess, 19.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5d, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5d, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5d, 27.3ms\n",
      "Speed: 2.9ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 7c, 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 7c, 12.5ms\n",
      "Speed: 3.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 7c, 23.8ms\n",
      "Speed: 2.7ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 7c, 56.2ms\n",
      "Speed: 2.3ms preprocess, 56.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 7c, 10.8ms\n",
      "Speed: 7.2ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 7c, 27.3ms\n",
      "Speed: 3.2ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 7c, 1 7s, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qd, 11.9ms\n",
      "Speed: 3.4ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qd, 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qd, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qd, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qd, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qd, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Qd, 26.8ms\n",
      "Speed: 2.7ms preprocess, 26.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ac, 39.8ms\n",
      "Speed: 6.3ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ac, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 1 Ac, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 7h, 24.8ms\n",
      "Speed: 2.5ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 7h, 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 1 7h, 12.1ms\n",
      "Speed: 2.9ms preprocess, 12.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6s, 58.2ms\n",
      "Speed: 2.9ms preprocess, 58.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6s, 11.3ms\n",
      "Speed: 8.7ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6s, 12.0ms\n",
      "Speed: 3.3ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6s, 13.7ms\n",
      "Speed: 2.6ms preprocess, 13.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 6s, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 9s, 25.0ms\n",
      "Speed: 3.0ms preprocess, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 9s, 10.7ms\n",
      "Speed: 3.8ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 9s, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 9s, 27.5ms\n",
      "Speed: 3.0ms preprocess, 27.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7d, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7d, 12.3ms\n",
      "Speed: 2.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7d, 21.2ms\n",
      "Speed: 2.0ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 7d, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jd, 22.1ms\n",
      "Speed: 2.5ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Kh, 25.7ms\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Kh, 31.5ms\n",
      "Speed: 22.8ms preprocess, 31.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Kh, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Kh, 20.9ms\n",
      "Speed: 1.8ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jd, 1 Kh, 12.4ms\n",
      "Speed: 2.7ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Kh, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Kh, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Kh, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Kh, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Kh, 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Kh, 23.4ms\n",
      "Speed: 2.5ms preprocess, 23.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 13.9ms\n",
      "Speed: 2.5ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 Ah, 46.5ms\n",
      "Speed: 2.6ms preprocess, 46.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Kd, 1 Ks, 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 23.2ms\n",
      "Speed: 3.0ms preprocess, 23.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 10.6ms\n",
      "Speed: 3.0ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Ks, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Ah, 39.3ms\n",
      "Speed: 35.2ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Ah, 14.4ms\n",
      "Speed: 2.8ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Ah, 12.8ms\n",
      "Speed: 2.7ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 As, 21.4ms\n",
      "Speed: 1.9ms preprocess, 21.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 As, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 As, 12.8ms\n",
      "Speed: 2.4ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 As, 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 As, 17.1ms\n",
      "Speed: 3.3ms preprocess, 17.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 As, 15.0ms\n",
      "Speed: 2.5ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 As, 15.9ms\n",
      "Speed: 3.2ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 As, 15.5ms\n",
      "Speed: 11.2ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 As, 49.2ms\n",
      "Speed: 19.2ms preprocess, 49.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.2ms\n",
      "Speed: 2.1ms preprocess, 17.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 19.6ms\n",
      "Speed: 2.9ms preprocess, 19.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 12.7ms\n",
      "Speed: 2.9ms preprocess, 12.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 21.5ms\n",
      "Speed: 2.5ms preprocess, 21.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 15.7ms\n",
      "Speed: 4.0ms preprocess, 15.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 12.2ms\n",
      "Speed: 5.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 12.4ms\n",
      "Speed: 3.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 19.7ms\n",
      "Speed: 2.8ms preprocess, 19.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 17.2ms\n",
      "Speed: 2.6ms preprocess, 17.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Kc, 1 Qc, 65.9ms\n",
      "Speed: 11.4ms preprocess, 65.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 12.1ms\n",
      "Speed: 5.8ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qc, 23.5ms\n",
      "Speed: 2.6ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qc, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qc, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qc, 15.6ms\n",
      "Speed: 3.3ms preprocess, 15.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qc, 15.9ms\n",
      "Speed: 11.8ms preprocess, 15.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 6c, 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 12.1ms\n",
      "Speed: 3.4ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 57.2ms\n",
      "Speed: 3.1ms preprocess, 57.2ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 13.1ms\n",
      "Speed: 2.4ms preprocess, 13.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 12.1ms\n",
      "Speed: 3.3ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 13.7ms\n",
      "Speed: 3.5ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 23.6ms\n",
      "Speed: 2.8ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 6d, 13.5ms\n",
      "Speed: 1.7ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6d, 20.5ms\n",
      "Speed: 3.4ms preprocess, 20.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6d, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 6d, 11.9ms\n",
      "Speed: 2.3ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8c, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8c, 75.5ms\n",
      "Speed: 2.8ms preprocess, 75.5ms inference, 10.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8c, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8c, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8c, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 8c, 22.0ms\n",
      "Speed: 3.6ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Th, 1 8c, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 70.8ms\n",
      "Speed: 1.8ms preprocess, 70.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 18.3ms\n",
      "Speed: 2.5ms preprocess, 18.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 21.2ms\n",
      "Speed: 3.1ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 13.0ms\n",
      "Speed: 2.2ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 23.5ms\n",
      "Speed: 51.7ms preprocess, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 8c, 11.7ms\n",
      "Speed: 3.6ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Th, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Th, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Th, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 15.5ms\n",
      "Speed: 75.6ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 11.3ms\n",
      "Speed: 2.6ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 16.7ms\n",
      "Speed: 5.9ms preprocess, 16.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 12.1ms\n",
      "Speed: 3.4ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 11.6ms\n",
      "Speed: 3.9ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 24.2ms\n",
      "Speed: 2.6ms preprocess, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 18.2ms\n",
      "Speed: 54.4ms preprocess, 18.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 9c, 12.0ms\n",
      "Speed: 3.4ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Kd, 14.6ms\n",
      "Speed: 13.0ms preprocess, 14.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 56.7ms\n",
      "Speed: 2.7ms preprocess, 56.7ms inference, 8.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 11.1ms\n",
      "Speed: 13.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 71.7ms\n",
      "Speed: 2.6ms preprocess, 71.7ms inference, 11.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 16.1ms\n",
      "Speed: 1.9ms preprocess, 16.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 11.8ms\n",
      "Speed: 3.1ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Kd, 24.3ms\n",
      "Speed: 3.1ms preprocess, 24.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qs, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qs, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qs, 27.6ms\n",
      "Speed: 2.1ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 12.4ms\n",
      "Speed: 2.2ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 64.7ms\n",
      "Speed: 3.1ms preprocess, 64.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 17.3ms\n",
      "Speed: 3.0ms preprocess, 17.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 18.6ms\n",
      "Speed: 2.9ms preprocess, 18.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Qs, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 17.8ms\n",
      "Speed: 2.4ms preprocess, 17.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 12.0ms\n",
      "Speed: 2.2ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 66.7ms\n",
      "Speed: 3.0ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 10.3ms\n",
      "Speed: 4.4ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 19.4ms\n",
      "Speed: 3.1ms preprocess, 19.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7s, 1 8h, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7s, 12.5ms\n",
      "Speed: 3.5ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7s, 11.6ms\n",
      "Speed: 3.9ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7s, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7s, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7s, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7s, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jh, 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jh, 54.1ms\n",
      "Speed: 4.5ms preprocess, 54.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jh, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jh, 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jh, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jh, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jh, 23.3ms\n",
      "Speed: 3.9ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 57.6ms\n",
      "Speed: 2.8ms preprocess, 57.6ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 11.6ms\n",
      "Speed: 4.3ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 19.4ms\n",
      "Speed: 2.7ms preprocess, 19.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 12.2ms\n",
      "Speed: 1.6ms preprocess, 12.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 14.7ms\n",
      "Speed: 1.9ms preprocess, 14.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 61.4ms\n",
      "Speed: 13.5ms preprocess, 61.4ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 13.3ms\n",
      "Speed: 1.7ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.9ms\n",
      "Speed: 3.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 25.4ms\n",
      "Speed: 2.0ms preprocess, 25.4ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 56.6ms\n",
      "Speed: 16.6ms preprocess, 56.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 13.2ms\n",
      "Speed: 3.1ms preprocess, 13.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 33.7ms\n",
      "Speed: 3.4ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 17.1ms\n",
      "Speed: 3.0ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 21.4ms\n",
      "Speed: 2.8ms preprocess, 21.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 10.9ms\n",
      "Speed: 3.3ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 13.9ms\n",
      "Speed: 3.1ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 74.4ms\n",
      "Speed: 2.4ms preprocess, 74.4ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 9.9ms\n",
      "Speed: 4.0ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 22.5ms\n",
      "Speed: 3.3ms preprocess, 22.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 6h, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6h, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6h, 17.2ms\n",
      "Speed: 2.8ms preprocess, 17.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6h, 12.6ms\n",
      "Speed: 5.0ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6h, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6h, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 36.0ms\n",
      "Speed: 1.8ms preprocess, 36.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 24.5ms\n",
      "Speed: 2.1ms preprocess, 24.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 24.4ms\n",
      "Speed: 2.4ms preprocess, 24.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 24.5ms\n",
      "Speed: 3.2ms preprocess, 24.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 15.4ms\n",
      "Speed: 2.3ms preprocess, 15.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 72.0ms\n",
      "Speed: 4.6ms preprocess, 72.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 24.4ms\n",
      "Speed: 3.3ms preprocess, 24.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 13.7ms\n",
      "Speed: 2.0ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 5h, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 2 7hs, 11.4ms\n",
      "Speed: 1.8ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 56.1ms\n",
      "Speed: 2.5ms preprocess, 56.1ms inference, 17.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 15.2ms\n",
      "Speed: 2.4ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 13.8ms\n",
      "Speed: 12.2ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 12.8ms\n",
      "Speed: 2.3ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 13.3ms\n",
      "Speed: 3.5ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Js, 25.3ms\n",
      "Speed: 2.3ms preprocess, 25.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 13.8ms\n",
      "Speed: 2.0ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 42.3ms\n",
      "Speed: 3.1ms preprocess, 42.3ms inference, 14.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 18.7ms\n",
      "Speed: 2.4ms preprocess, 18.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 11.7ms\n",
      "Speed: 3.3ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 12.2ms\n",
      "Speed: 3.0ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 21.8ms\n",
      "Speed: 2.7ms preprocess, 21.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 12.9ms\n",
      "Speed: 2.6ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 26.3ms\n",
      "Speed: 3.1ms preprocess, 26.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 13.3ms\n",
      "Speed: 2.8ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 52.1ms\n",
      "Speed: 20.3ms preprocess, 52.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 12.4ms\n",
      "Speed: 2.2ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 23.4ms\n",
      "Speed: 2.6ms preprocess, 23.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 17.3ms\n",
      "Speed: 1.9ms preprocess, 17.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 12.6ms\n",
      "Speed: 2.6ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 12.6ms\n",
      "Speed: 2.5ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jc, 13.6ms\n",
      "Speed: 3.0ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 77.0ms\n",
      "Speed: 2.6ms preprocess, 77.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 14.0ms\n",
      "Speed: 3.2ms preprocess, 14.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.9ms\n",
      "Speed: 2.6ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 15.0ms\n",
      "Speed: 14.2ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 18.9ms\n",
      "Speed: 3.7ms preprocess, 18.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 13.6ms\n",
      "Speed: 3.6ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 17.7ms\n",
      "Speed: 6.3ms preprocess, 17.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 77.5ms\n",
      "Speed: 1.8ms preprocess, 77.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.7ms\n",
      "Speed: 8.7ms preprocess, 12.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 16.5ms\n",
      "Speed: 1.7ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 31.2ms\n",
      "Speed: 3.2ms preprocess, 31.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 37.6ms\n",
      "Speed: 2.2ms preprocess, 37.6ms inference, 33.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.9ms\n",
      "Speed: 1.9ms preprocess, 12.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 65.8ms\n",
      "Speed: 2.1ms preprocess, 65.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.4ms\n",
      "Speed: 3.3ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.6ms\n",
      "Speed: 3.2ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 14.9ms\n",
      "Speed: 3.2ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 48.7ms\n",
      "Speed: 3.7ms preprocess, 48.7ms inference, 20.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 14.7ms\n",
      "Speed: 2.1ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.2ms\n",
      "Speed: 3.4ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 25.7ms\n",
      "Speed: 3.9ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9h, 1 Jc, 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 12.7ms\n",
      "Speed: 2.0ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 22.9ms\n",
      "Speed: 1.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 50.0ms\n",
      "Speed: 1.8ms preprocess, 50.0ms inference, 21.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 15.6ms\n",
      "Speed: 2.6ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 25.2ms\n",
      "Speed: 3.4ms preprocess, 25.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 16.6ms\n",
      "Speed: 4.0ms preprocess, 16.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.6ms\n",
      "Speed: 6.5ms preprocess, 10.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 15.0ms\n",
      "Speed: 12.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 12.2ms\n",
      "Speed: 1.7ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 71.5ms\n",
      "Speed: 2.4ms preprocess, 71.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.1ms\n",
      "Speed: 5.4ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 15.4ms\n",
      "Speed: 1.8ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 24.5ms\n",
      "Speed: 2.7ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 13.5ms\n",
      "Speed: 2.2ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 27.1ms\n",
      "Speed: 2.8ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 77.4ms\n",
      "Speed: 1.9ms preprocess, 77.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 13.6ms\n",
      "Speed: 2.2ms preprocess, 13.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.8ms\n",
      "Speed: 3.3ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 12.8ms\n",
      "Speed: 3.7ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 22.8ms\n",
      "Speed: 2.5ms preprocess, 22.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 12.6ms\n",
      "Speed: 1.8ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 18.4ms\n",
      "Speed: 3.0ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.8ms\n",
      "Speed: 2.8ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 32.7ms\n",
      "Speed: 6.7ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 15.3ms\n",
      "Speed: 29.8ms preprocess, 15.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.0ms\n",
      "Speed: 3.8ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 21.6ms\n",
      "Speed: 3.5ms preprocess, 21.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 25.0ms\n",
      "Speed: 3.2ms preprocess, 25.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.4ms\n",
      "Speed: 3.1ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 14.0ms\n",
      "Speed: 1.9ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 17.9ms\n",
      "Speed: 2.7ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 13.7ms\n",
      "Speed: 2.3ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 62.4ms\n",
      "Speed: 2.1ms preprocess, 62.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 10.2ms\n",
      "Speed: 5.2ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 20.1ms\n",
      "Speed: 2.1ms preprocess, 20.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9d, 11.0ms\n",
      "Speed: 3.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 15.1ms\n",
      "Speed: 3.4ms preprocess, 15.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 26.4ms\n",
      "Speed: 2.7ms preprocess, 26.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 50.5ms\n",
      "Speed: 11.5ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.0ms\n",
      "Speed: 2.7ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 28.5ms\n",
      "Speed: 3.3ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.9ms\n",
      "Speed: 2.3ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 11.1ms\n",
      "Speed: 3.1ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 24.1ms\n",
      "Speed: 3.0ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 17.3ms\n",
      "Speed: 2.0ms preprocess, 17.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 21.0ms\n",
      "Speed: 38.0ms preprocess, 21.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 19.1ms\n",
      "Speed: 4.9ms preprocess, 19.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 10.4ms\n",
      "Speed: 2.8ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 72.1ms\n",
      "Speed: 2.3ms preprocess, 72.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 14.5ms\n",
      "Speed: 2.6ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 22.4ms\n",
      "Speed: 3.3ms preprocess, 22.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 13.9ms\n",
      "Speed: 1.9ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 29.0ms\n",
      "Speed: 2.8ms preprocess, 29.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 54.6ms\n",
      "Speed: 2.3ms preprocess, 54.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 11.1ms\n",
      "Speed: 4.9ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 10.5ms\n",
      "Speed: 3.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 21.4ms\n",
      "Speed: 1.9ms preprocess, 21.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 13.8ms\n",
      "Speed: 3.1ms preprocess, 13.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 80.7ms\n",
      "Speed: 1.6ms preprocess, 80.7ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 14.0ms\n",
      "Speed: 1.8ms preprocess, 14.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 27.0ms\n",
      "Speed: 3.6ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 20.4ms\n",
      "Speed: 2.4ms preprocess, 20.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 49.4ms\n",
      "Speed: 17.3ms preprocess, 49.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.1ms\n",
      "Speed: 1.8ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Qh, 17.2ms\n",
      "Speed: 2.8ms preprocess, 17.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 13.4ms\n",
      "Speed: 4.6ms preprocess, 13.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.5ms\n",
      "Speed: 3.1ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 70.4ms\n",
      "Speed: 1.9ms preprocess, 70.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 18.0ms\n",
      "Speed: 2.1ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.7ms\n",
      "Speed: 4.9ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 19.1ms\n",
      "Speed: 4.3ms preprocess, 19.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.8ms\n",
      "Speed: 3.0ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.3ms\n",
      "Speed: 1.8ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.3ms\n",
      "Speed: 2.5ms preprocess, 27.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.1ms preprocess, 12.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 83.7ms\n",
      "Speed: 1.5ms preprocess, 83.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.2ms\n",
      "Speed: 2.0ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.0ms preprocess, 13.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 1.8ms preprocess, 13.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 58.7ms\n",
      "Speed: 1.5ms preprocess, 58.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 3.3ms preprocess, 22.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 4.0ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.4ms\n",
      "Speed: 2.4ms preprocess, 20.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.0ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 2.1ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.2ms preprocess, 13.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 54.5ms\n",
      "Speed: 1.9ms preprocess, 54.5ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 11.0ms preprocess, 12.4ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.0ms\n",
      "Speed: 3.1ms preprocess, 23.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.8ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 78.0ms\n",
      "Speed: 2.1ms preprocess, 78.0ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 1.8ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.9ms\n",
      "Speed: 2.7ms preprocess, 19.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.4ms\n",
      "Speed: 2.1ms preprocess, 13.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 2.9ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.4ms\n",
      "Speed: 1.7ms preprocess, 20.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 39.8ms\n",
      "Speed: 2.4ms preprocess, 39.8ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.4ms\n",
      "Speed: 3.6ms preprocess, 18.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.6ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 1.9ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.3ms\n",
      "Speed: 2.3ms preprocess, 26.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.3ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 1.8ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.7ms\n",
      "Speed: 1.9ms preprocess, 17.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 12.7ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 1.7ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.6ms\n",
      "Speed: 1.7ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.5ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 3.1ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.6ms\n",
      "Speed: 2.3ms preprocess, 17.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 4.5ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 62.8ms\n",
      "Speed: 4.0ms preprocess, 62.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.3ms\n",
      "Speed: 11.2ms preprocess, 13.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 54.8ms\n",
      "Speed: 2.1ms preprocess, 54.8ms inference, 16.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.4ms\n",
      "Speed: 2.6ms preprocess, 15.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.6ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 3.3ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 2.7ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.1ms\n",
      "Speed: 2.6ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.2ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 76.0ms\n",
      "Speed: 2.0ms preprocess, 76.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 7.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 83.7ms\n",
      "Speed: 1.7ms preprocess, 83.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 3.5ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.8ms\n",
      "Speed: 1.9ms preprocess, 16.8ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 10.0ms\n",
      "Speed: 4.1ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ad, 14.1ms\n",
      "Speed: 1.7ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ad, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 63.2ms\n",
      "Speed: 2.0ms preprocess, 63.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.7ms\n",
      "Speed: 3.1ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 23.5ms\n",
      "Speed: 2.7ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 15.2ms\n",
      "Speed: 3.4ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 14.2ms\n",
      "Speed: 1.8ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 71.0ms\n",
      "Speed: 2.1ms preprocess, 71.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 22.6ms\n",
      "Speed: 2.2ms preprocess, 22.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 17.1ms\n",
      "Speed: 2.1ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.7ms\n",
      "Speed: 3.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 22.9ms\n",
      "Speed: 2.3ms preprocess, 22.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 13.3ms\n",
      "Speed: 2.0ms preprocess, 13.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 20.3ms\n",
      "Speed: 3.0ms preprocess, 20.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Ah, 11.6ms\n",
      "Speed: 2.6ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 9c, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 9s, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 23.4ms\n",
      "Speed: 1.9ms preprocess, 23.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 Kc, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 As, 1 Qc, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 Ac, 25.2ms\n",
      "Speed: 2.2ms preprocess, 25.2ms inference, 25.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Jc, 15.7ms\n",
      "Speed: 3.0ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Ks, 12.1ms\n",
      "Speed: 2.3ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 Qs, 24.8ms\n",
      "Speed: 1.9ms preprocess, 24.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 7s, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 8s, 11.6ms\n",
      "Speed: 2.2ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 5s, 15.8ms\n",
      "Speed: 3.1ms preprocess, 15.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 9h, 11.1ms\n",
      "Speed: 16.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 1 Qd, 11.9ms\n",
      "Speed: 4.1ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 8h, 22.8ms\n",
      "Speed: 3.5ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Qh, 64.8ms\n",
      "Speed: 3.8ms preprocess, 64.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 5d, 11.5ms\n",
      "Speed: 3.5ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 1 Kh, 23.6ms\n",
      "Speed: 3.7ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 BJoker, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 4h, 30.1ms\n",
      "Speed: 2.5ms preprocess, 30.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 30.9ms\n",
      "Speed: 26.0ms preprocess, 30.9ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 6s, 15.1ms\n",
      "Speed: 3.0ms preprocess, 15.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jd, 13.7ms\n",
      "Speed: 16.3ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 10.5ms\n",
      "Speed: 2.9ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 11.7ms\n",
      "Speed: 2.0ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Jd, 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ad, 10.5ms\n",
      "Speed: 7.2ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 84.3ms\n",
      "Speed: 1.9ms preprocess, 84.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7d, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Jh, 11.2ms\n",
      "Speed: 1.7ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 27.2ms\n",
      "Speed: 2.2ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 12.0ms\n",
      "Speed: 2.9ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 13.5ms\n",
      "Speed: 2.2ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Jh, 22.7ms\n",
      "Speed: 4.1ms preprocess, 22.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 1 BJoker, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 58.8ms\n",
      "Speed: 23.1ms preprocess, 58.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 1.8ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.9ms\n",
      "Speed: 12.3ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 3.0ms preprocess, 13.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 3.5ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 2.5ms preprocess, 14.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 61.4ms\n",
      "Speed: 2.2ms preprocess, 61.4ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.2ms\n",
      "Speed: 2.2ms preprocess, 22.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.1ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 1.7ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 3.3ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 34.7ms\n",
      "Speed: 3.0ms preprocess, 34.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.5ms\n",
      "Speed: 21.3ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 8.5ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.5ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 2.6ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.8ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.5ms\n",
      "Speed: 2.6ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.6ms\n",
      "Speed: 1.6ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.9ms\n",
      "Speed: 12.8ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 71.0ms\n",
      "Speed: 2.4ms preprocess, 71.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 2.7ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 21.6ms\n",
      "Speed: 2.1ms preprocess, 21.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 2.4ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 19.2ms\n",
      "Speed: 1.5ms preprocess, 19.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.1ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.4ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 85.0ms\n",
      "Speed: 1.6ms preprocess, 85.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 6.0ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.1ms\n",
      "Speed: 2.0ms preprocess, 21.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 81.9ms\n",
      "Speed: 1.8ms preprocess, 81.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 5.2ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.0ms\n",
      "Speed: 1.8ms preprocess, 14.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.1ms\n",
      "Speed: 3.1ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.3ms\n",
      "Speed: 2.3ms preprocess, 15.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 38.6ms\n",
      "Speed: 3.5ms preprocess, 38.6ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.8ms\n",
      "Speed: 12.4ms preprocess, 24.8ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 1.7ms preprocess, 12.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.8ms\n",
      "Speed: 1.8ms preprocess, 29.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 41.8ms\n",
      "Speed: 1.9ms preprocess, 41.8ms inference, 8.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 20.7ms preprocess, 13.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 4.4ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 13.1ms\n",
      "Speed: 3.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 74.6ms\n",
      "Speed: 3.2ms preprocess, 74.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.5ms\n",
      "Speed: 12.7ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 25.5ms\n",
      "Speed: 2.5ms preprocess, 25.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.0ms\n",
      "Speed: 3.2ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 15.2ms\n",
      "Speed: 11.8ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 23.7ms\n",
      "Speed: 2.1ms preprocess, 23.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.6ms\n",
      "Speed: 1.8ms preprocess, 11.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 20.9ms\n",
      "Speed: 2.1ms preprocess, 20.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.9ms\n",
      "Speed: 5.3ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 61.5ms\n",
      "Speed: 3.1ms preprocess, 61.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.4ms\n",
      "Speed: 3.3ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.0ms\n",
      "Speed: 2.4ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.1ms\n",
      "Speed: 2.8ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 41.3ms\n",
      "Speed: 2.8ms preprocess, 41.3ms inference, 15.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 17.3ms\n",
      "Speed: 2.1ms preprocess, 17.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.7ms\n",
      "Speed: 3.1ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.6ms\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 20.5ms\n",
      "Speed: 3.4ms preprocess, 20.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 64.0ms\n",
      "Speed: 2.7ms preprocess, 64.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.4ms\n",
      "Speed: 3.7ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.1ms\n",
      "Speed: 3.1ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 21.5ms\n",
      "Speed: 2.5ms preprocess, 21.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.5ms\n",
      "Speed: 2.5ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 63.7ms\n",
      "Speed: 1.8ms preprocess, 63.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 21.5ms\n",
      "Speed: 4.8ms preprocess, 21.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.1ms\n",
      "Speed: 5.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 20.9ms\n",
      "Speed: 1.9ms preprocess, 20.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 50.9ms\n",
      "Speed: 5.7ms preprocess, 50.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 17.6ms\n",
      "Speed: 3.2ms preprocess, 17.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.4ms\n",
      "Speed: 9.4ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 22.8ms\n",
      "Speed: 2.0ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 67.0ms\n",
      "Speed: 3.1ms preprocess, 67.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 15.6ms\n",
      "Speed: 3.4ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.9ms\n",
      "Speed: 2.8ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 67.8ms\n",
      "Speed: 4.2ms preprocess, 67.8ms inference, 13.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 23.9ms\n",
      "Speed: 2.7ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.4ms\n",
      "Speed: 2.1ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 58.7ms\n",
      "Speed: 1.9ms preprocess, 58.7ms inference, 10.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 17.7ms\n",
      "Speed: 2.1ms preprocess, 17.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.7ms\n",
      "Speed: 3.0ms preprocess, 13.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 25.6ms\n",
      "Speed: 3.5ms preprocess, 25.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 68.3ms\n",
      "Speed: 2.0ms preprocess, 68.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.4ms\n",
      "Speed: 3.4ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 20.6ms\n",
      "Speed: 3.7ms preprocess, 20.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.4ms\n",
      "Speed: 1.9ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.4ms\n",
      "Speed: 3.3ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 81.7ms\n",
      "Speed: 2.9ms preprocess, 81.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.1ms\n",
      "Speed: 2.0ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 16.7ms\n",
      "Speed: 2.0ms preprocess, 16.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.7ms\n",
      "Speed: 8.6ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.0ms\n",
      "Speed: 2.5ms preprocess, 12.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 60.3ms\n",
      "Speed: 3.0ms preprocess, 60.3ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 24.5ms\n",
      "Speed: 3.3ms preprocess, 24.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.5ms\n",
      "Speed: 3.1ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 82.3ms\n",
      "Speed: 4.3ms preprocess, 82.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.8ms\n",
      "Speed: 1.9ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.6ms\n",
      "Speed: 2.7ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.1ms\n",
      "Speed: 1.8ms preprocess, 14.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 43.1ms\n",
      "Speed: 3.5ms preprocess, 43.1ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 31.0ms\n",
      "Speed: 21.2ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.8ms\n",
      "Speed: 2.6ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.0ms\n",
      "Speed: 1.7ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.4ms\n",
      "Speed: 1.9ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 69.3ms\n",
      "Speed: 3.4ms preprocess, 69.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 18.1ms\n",
      "Speed: 1.8ms preprocess, 18.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 72.2ms\n",
      "Speed: 3.0ms preprocess, 72.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.4ms\n",
      "Speed: 2.9ms preprocess, 13.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 85.4ms\n",
      "Speed: 2.3ms preprocess, 85.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.7ms\n",
      "Speed: 2.1ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.4ms\n",
      "Speed: 3.4ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 18.6ms\n",
      "Speed: 6.3ms preprocess, 18.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 60.5ms\n",
      "Speed: 1.9ms preprocess, 60.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.2ms\n",
      "Speed: 25.3ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 13.7ms\n",
      "Speed: 1.7ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 22.3ms\n",
      "Speed: 3.4ms preprocess, 22.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 41.7ms\n",
      "Speed: 2.1ms preprocess, 41.7ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 26.2ms\n",
      "Speed: 10.6ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.3ms\n",
      "Speed: 5.2ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 74.5ms\n",
      "Speed: 2.0ms preprocess, 74.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 15.2ms\n",
      "Speed: 2.7ms preprocess, 15.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.3ms\n",
      "Speed: 3.0ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.7ms\n",
      "Speed: 2.1ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 67.8ms\n",
      "Speed: 3.9ms preprocess, 67.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 15.4ms\n",
      "Speed: 1.8ms preprocess, 15.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.1ms\n",
      "Speed: 3.1ms preprocess, 14.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.9ms\n",
      "Speed: 3.2ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 32.4ms\n",
      "Speed: 2.1ms preprocess, 32.4ms inference, 39.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.7ms\n",
      "Speed: 1.8ms preprocess, 11.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 14.5ms\n",
      "Speed: 2.3ms preprocess, 14.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 18.0ms\n",
      "Speed: 14.5ms preprocess, 18.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 75.9ms\n",
      "Speed: 2.0ms preprocess, 75.9ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 4h, 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8c, 12.9ms\n",
      "Speed: 1.9ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kd, 20.4ms\n",
      "Speed: 7.6ms preprocess, 20.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Ks, 13.6ms\n",
      "Speed: 2.2ms preprocess, 13.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Ks, 12.6ms\n",
      "Speed: 2.9ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Ks, 17.4ms\n",
      "Speed: 55.5ms preprocess, 17.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Ks, 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Ks, 24.8ms\n",
      "Speed: 2.1ms preprocess, 24.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 14.7ms\n",
      "Speed: 1.9ms preprocess, 14.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ks, 57.5ms\n",
      "Speed: 13.6ms preprocess, 57.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 Ad, 14.3ms\n",
      "Speed: 2.9ms preprocess, 14.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ad, 10.8ms\n",
      "Speed: 2.1ms preprocess, 10.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ad, 15.0ms\n",
      "Speed: 1.8ms preprocess, 15.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ad, 11.1ms\n",
      "Speed: 3.6ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ad, 79.6ms\n",
      "Speed: 2.9ms preprocess, 79.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ad, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ad, 13.2ms\n",
      "Speed: 1.8ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ad, 14.2ms\n",
      "Speed: 2.3ms preprocess, 14.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 11.1ms\n",
      "Speed: 5.6ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ah, 18.5ms\n",
      "Speed: 40.1ms preprocess, 18.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 1 Ah, 16.8ms\n",
      "Speed: 11.1ms preprocess, 16.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 13.3ms\n",
      "Speed: 1.9ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 21.5ms\n",
      "Speed: 3.1ms preprocess, 21.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 29.4ms\n",
      "Speed: 53.0ms preprocess, 29.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 11.6ms\n",
      "Speed: 3.0ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 14.9ms\n",
      "Speed: 2.5ms preprocess, 14.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 5c, 22.9ms\n",
      "Speed: 3.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8d, 12.3ms\n",
      "Speed: 2.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8d, 14.4ms\n",
      "Speed: 1.6ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8d, 23.9ms\n",
      "Speed: 2.8ms preprocess, 23.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8d, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8d, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 12.2ms\n",
      "Speed: 2.5ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 23.4ms\n",
      "Speed: 3.3ms preprocess, 23.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 8d, 12.0ms\n",
      "Speed: 3.4ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 22.0ms\n",
      "Speed: 2.5ms preprocess, 22.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 As, 48.4ms\n",
      "Speed: 2.7ms preprocess, 48.4ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 As, 15.2ms\n",
      "Speed: 3.0ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 As, 14.6ms\n",
      "Speed: 13.4ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 As, 11.3ms\n",
      "Speed: 1.9ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 As, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 As, 12.2ms\n",
      "Speed: 2.3ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 As, 70.8ms\n",
      "Speed: 3.2ms preprocess, 70.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 12.4ms\n",
      "Speed: 8.3ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 13.3ms\n",
      "Speed: 2.4ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 24.4ms\n",
      "Speed: 3.4ms preprocess, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 12.5ms\n",
      "Speed: 2.6ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 14.5ms\n",
      "Speed: 2.4ms preprocess, 14.5ms inference, 38.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 6h, 20.5ms\n",
      "Speed: 2.8ms preprocess, 20.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5s, 12.5ms\n",
      "Speed: 1.8ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8s, 12.5ms\n",
      "Speed: 3.8ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8s, 14.4ms\n",
      "Speed: 3.8ms preprocess, 14.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8s, 69.9ms\n",
      "Speed: 1.7ms preprocess, 69.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8s, 14.6ms\n",
      "Speed: 2.6ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8s, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8s, 11.8ms\n",
      "Speed: 3.2ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 8s, 25.8ms\n",
      "Speed: 2.7ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Qd, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Qd, 78.9ms\n",
      "Speed: 2.3ms preprocess, 78.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Qd, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Qd, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Qd, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kc, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kc, 12.5ms\n",
      "Speed: 2.7ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kc, 44.9ms\n",
      "Speed: 12.2ms preprocess, 44.9ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ac, 1 Kc, 19.7ms\n",
      "Speed: 5.7ms preprocess, 19.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Kd, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Kd, 21.9ms\n",
      "Speed: 1.8ms preprocess, 21.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Kd, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Kd, 71.4ms\n",
      "Speed: 1.9ms preprocess, 71.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Kd, 14.3ms\n",
      "Speed: 6.4ms preprocess, 14.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 1 Kd, 13.8ms\n",
      "Speed: 2.5ms preprocess, 13.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 30.4ms\n",
      "Speed: 2.3ms preprocess, 30.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Kd, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 71.7ms\n",
      "Speed: 2.2ms preprocess, 71.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 14.2ms\n",
      "Speed: 2.1ms preprocess, 14.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 12.1ms\n",
      "Speed: 4.9ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 12.6ms\n",
      "Speed: 3.9ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 16.0ms\n",
      "Speed: 8.8ms preprocess, 16.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 7h, 18.6ms\n",
      "Speed: 50.3ms preprocess, 18.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 4s, 1 7h, 12.3ms\n",
      "Speed: 3.4ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7h, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 19.0ms\n",
      "Speed: 2.2ms preprocess, 19.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 10.7ms\n",
      "Speed: 3.7ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 14.8ms\n",
      "Speed: 3.3ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 23.4ms\n",
      "Speed: 1.9ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 12.8ms\n",
      "Speed: 2.6ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 62.8ms\n",
      "Speed: 23.6ms preprocess, 62.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 13.7ms\n",
      "Speed: 1.8ms preprocess, 13.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 6s, 21.8ms\n",
      "Speed: 4.4ms preprocess, 21.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 12.3ms\n",
      "Speed: 2.5ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Qs, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Qs, 48.7ms\n",
      "Speed: 2.3ms preprocess, 48.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 Qs, 19.1ms\n",
      "Speed: 2.1ms preprocess, 19.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 15.8ms\n",
      "Speed: 12.9ms preprocess, 15.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 63.4ms\n",
      "Speed: 2.0ms preprocess, 63.4ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 15.7ms\n",
      "Speed: 2.8ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Qs, 12.2ms\n",
      "Speed: 1.9ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4c, 11.0ms\n",
      "Speed: 2.1ms preprocess, 11.0ms inference, 12.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4c, 10.5ms\n",
      "Speed: 5.5ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4c, 21.0ms\n",
      "Speed: 49.0ms preprocess, 21.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4c, 19.8ms\n",
      "Speed: 2.4ms preprocess, 19.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qc, 14.6ms\n",
      "Speed: 5.7ms preprocess, 14.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qc, 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qc, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 Qc, 35.8ms\n",
      "Speed: 1.8ms preprocess, 35.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 26.4ms\n",
      "Speed: 4.9ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 11.0ms\n",
      "Speed: 8.2ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 23.6ms\n",
      "Speed: 2.0ms preprocess, 23.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 11.1ms\n",
      "Speed: 2.2ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 73.8ms\n",
      "Speed: 2.2ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 12.5ms\n",
      "Speed: 6.7ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 17.8ms\n",
      "Speed: 2.4ms preprocess, 17.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Qc, 13.6ms\n",
      "Speed: 3.2ms preprocess, 13.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 10.8ms\n",
      "Speed: 2.2ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Js, 49.5ms\n",
      "Speed: 2.6ms preprocess, 49.5ms inference, 10.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 16.1ms\n",
      "Speed: 2.0ms preprocess, 16.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 18.3ms\n",
      "Speed: 4.9ms preprocess, 18.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 13.5ms\n",
      "Speed: 3.2ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 19.2ms\n",
      "Speed: 2.8ms preprocess, 19.2ms inference, 51.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 11.4ms\n",
      "Speed: 4.9ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 23.9ms\n",
      "Speed: 3.4ms preprocess, 23.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8h, 1 Js, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 13.3ms\n",
      "Speed: 1.9ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 83.3ms\n",
      "Speed: 2.0ms preprocess, 83.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 Js, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Js, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 Js, 11.6ms\n",
      "Speed: 2.8ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 59.9ms\n",
      "Speed: 2.1ms preprocess, 59.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 14.7ms\n",
      "Speed: 2.9ms preprocess, 14.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 24.4ms\n",
      "Speed: 4.2ms preprocess, 24.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 10.5ms\n",
      "Speed: 3.2ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 10.9ms\n",
      "Speed: 3.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 11.9ms\n",
      "Speed: 1.9ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 59.5ms\n",
      "Speed: 2.2ms preprocess, 59.5ms inference, 11.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 22.8ms\n",
      "Speed: 2.1ms preprocess, 22.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 7d, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7d, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7d, 40.7ms\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7d, 19.0ms\n",
      "Speed: 15.3ms preprocess, 19.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7d, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7d, 24.5ms\n",
      "Speed: 4.0ms preprocess, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 19.5ms\n",
      "Speed: 2.7ms preprocess, 19.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 18.6ms\n",
      "Speed: 2.0ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 11.5ms\n",
      "Speed: 3.0ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 25.5ms\n",
      "Speed: 5.3ms preprocess, 25.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 13.1ms\n",
      "Speed: 1.8ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 11.2ms\n",
      "Speed: 3.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 56.7ms\n",
      "Speed: 2.9ms preprocess, 56.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 10.2ms\n",
      "Speed: 6.2ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 23.3ms\n",
      "Speed: 1.9ms preprocess, 23.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 7s, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jd, 14.7ms\n",
      "Speed: 1.9ms preprocess, 14.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 1 Jd, 31.6ms\n",
      "Speed: 37.5ms preprocess, 31.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 14.6ms\n",
      "Speed: 2.3ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 12.7ms\n",
      "Speed: 3.2ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 11.5ms\n",
      "Speed: 2.9ms preprocess, 11.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 24.2ms\n",
      "Speed: 3.6ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 71.2ms\n",
      "Speed: 3.1ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 13.9ms\n",
      "Speed: 8.9ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 10.5ms\n",
      "Speed: 2.2ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 14.1ms\n",
      "Speed: 1.9ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 27.4ms\n",
      "Speed: 3.5ms preprocess, 27.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 60.7ms\n",
      "Speed: 2.4ms preprocess, 60.7ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 17.8ms\n",
      "Speed: 2.3ms preprocess, 17.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 Jd, 17.3ms\n",
      "Speed: 1.8ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 6c, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7c, 1 7h, 14.2ms\n",
      "Speed: 2.7ms preprocess, 14.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 31.2ms\n",
      "Speed: 38.0ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 19.3ms\n",
      "Speed: 2.5ms preprocess, 19.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 23.7ms\n",
      "Speed: 1.8ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 13.1ms\n",
      "Speed: 3.2ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 12.2ms\n",
      "Speed: 3.8ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 60.1ms\n",
      "Speed: 3.5ms preprocess, 60.1ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 11.3ms\n",
      "Speed: 3.4ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 22.9ms\n",
      "Speed: 3.5ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 13.3ms\n",
      "Speed: 2.1ms preprocess, 13.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 11.5ms\n",
      "Speed: 2.8ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 27.5ms\n",
      "Speed: 2.0ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 20.7ms\n",
      "Speed: 44.8ms preprocess, 20.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 11.3ms\n",
      "Speed: 2.5ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 Jc, 13.3ms\n",
      "Speed: 1.8ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 11.5ms\n",
      "Speed: 3.5ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 26.3ms\n",
      "Speed: 2.6ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 10.6ms\n",
      "Speed: 3.6ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 12.1ms\n",
      "Speed: 2.2ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 13.1ms\n",
      "Speed: 2.1ms preprocess, 13.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 38.4ms\n",
      "Speed: 3.7ms preprocess, 38.4ms inference, 32.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 14.8ms\n",
      "Speed: 2.9ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 13.3ms\n",
      "Speed: 3.4ms preprocess, 13.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 10.9ms\n",
      "Speed: 2.7ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 20.0ms\n",
      "Speed: 28.5ms preprocess, 20.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 13.2ms\n",
      "Speed: 3.5ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9h, 21.5ms\n",
      "Speed: 2.6ms preprocess, 21.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 13.0ms\n",
      "Speed: 3.5ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 10.8ms\n",
      "Speed: 3.9ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 11.8ms\n",
      "Speed: 2.2ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 69.1ms\n",
      "Speed: 1.9ms preprocess, 69.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 14.5ms\n",
      "Speed: 2.7ms preprocess, 14.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 10.7ms\n",
      "Speed: 3.2ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 10.6ms\n",
      "Speed: 2.0ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 12.4ms\n",
      "Speed: 2.5ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 9d, 35.4ms\n",
      "Speed: 5.5ms preprocess, 35.4ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 6d, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.9ms\n",
      "Speed: 3.0ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 18.9ms\n",
      "Speed: 2.7ms preprocess, 18.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.8ms\n",
      "Speed: 3.1ms preprocess, 11.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.8ms\n",
      "Speed: 2.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 66.8ms\n",
      "Speed: 4.2ms preprocess, 66.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 17.5ms\n",
      "Speed: 2.3ms preprocess, 17.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.7ms\n",
      "Speed: 3.9ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 19.8ms\n",
      "Speed: 1.9ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 68.6ms\n",
      "Speed: 1.8ms preprocess, 68.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 18.6ms\n",
      "Speed: 2.7ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 15.6ms\n",
      "Speed: 3.1ms preprocess, 15.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.3ms\n",
      "Speed: 3.0ms preprocess, 11.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 28.6ms\n",
      "Speed: 2.7ms preprocess, 28.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 13.8ms\n",
      "Speed: 2.6ms preprocess, 13.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 50.7ms\n",
      "Speed: 6.9ms preprocess, 50.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 24.8ms\n",
      "Speed: 2.5ms preprocess, 24.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kh, 11.3ms\n",
      "Speed: 2.3ms preprocess, 11.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ts, 1 Kh, 15.9ms\n",
      "Speed: 75.9ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 12.6ms\n",
      "Speed: 2.3ms preprocess, 12.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 11.7ms\n",
      "Speed: 3.2ms preprocess, 11.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 74.8ms\n",
      "Speed: 3.1ms preprocess, 74.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 16.2ms\n",
      "Speed: 4.5ms preprocess, 16.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 12.3ms\n",
      "Speed: 2.9ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 40.8ms\n",
      "Speed: 23.7ms preprocess, 40.8ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 12.9ms\n",
      "Speed: 1.8ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 13.9ms\n",
      "Speed: 3.0ms preprocess, 13.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 22.9ms\n",
      "Speed: 2.0ms preprocess, 22.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 45.0ms\n",
      "Speed: 1.9ms preprocess, 45.0ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Kh, 20.8ms\n",
      "Speed: 2.3ms preprocess, 20.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 16.9ms\n",
      "Speed: 6.4ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 14.2ms\n",
      "Speed: 3.0ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 12.4ms\n",
      "Speed: 3.2ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 71.1ms\n",
      "Speed: 2.8ms preprocess, 71.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 16.0ms\n",
      "Speed: 1.8ms preprocess, 16.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 10.9ms\n",
      "Speed: 3.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 22.9ms\n",
      "Speed: 2.1ms preprocess, 22.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 73.8ms\n",
      "Speed: 2.1ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 10.5ms\n",
      "Speed: 8.2ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 Jh, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9s, 1 Jh, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.5ms\n",
      "Speed: 2.2ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 31.9ms\n",
      "Speed: 1.9ms preprocess, 31.9ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 16.1ms\n",
      "Speed: 24.5ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 15.2ms\n",
      "Speed: 13.3ms preprocess, 15.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 24.9ms\n",
      "Speed: 2.9ms preprocess, 24.9ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 18.2ms\n",
      "Speed: 35.7ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 18.8ms\n",
      "Speed: 8.3ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 13.6ms\n",
      "Speed: 3.0ms preprocess, 13.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 12.0ms\n",
      "Speed: 3.6ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 13.1ms\n",
      "Speed: 2.2ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 74.3ms\n",
      "Speed: 2.2ms preprocess, 74.3ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 12.7ms\n",
      "Speed: 2.7ms preprocess, 12.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.4ms\n",
      "Speed: 2.3ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 42.3ms\n",
      "Speed: 1.9ms preprocess, 42.3ms inference, 8.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 20.0ms\n",
      "Speed: 22.2ms preprocess, 20.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.2ms\n",
      "Speed: 2.5ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 22.8ms\n",
      "Speed: 1.9ms preprocess, 22.8ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 12.7ms\n",
      "Speed: 3.4ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 39.4ms\n",
      "Speed: 4.1ms preprocess, 39.4ms inference, 29.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 17.3ms\n",
      "Speed: 3.0ms preprocess, 17.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 10.8ms\n",
      "Speed: 2.8ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 16.6ms\n",
      "Speed: 2.2ms preprocess, 16.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.7ms\n",
      "Speed: 7.6ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 13.7ms\n",
      "Speed: 2.3ms preprocess, 13.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 66.5ms\n",
      "Speed: 15.2ms preprocess, 66.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 12.1ms\n",
      "Speed: 2.1ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 13.9ms\n",
      "Speed: 1.6ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 15.9ms\n",
      "Speed: 3.2ms preprocess, 15.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 49.4ms\n",
      "Speed: 29.6ms preprocess, 49.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 9.8ms\n",
      "Speed: 3.4ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 15.0ms\n",
      "Speed: 1.8ms preprocess, 15.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 13.9ms\n",
      "Speed: 3.5ms preprocess, 13.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 23.5ms\n",
      "Speed: 2.3ms preprocess, 23.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 60.7ms\n",
      "Speed: 1.9ms preprocess, 60.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 13.3ms\n",
      "Speed: 8.3ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 12.1ms\n",
      "Speed: 3.3ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 21.3ms\n",
      "Speed: 3.4ms preprocess, 21.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.9ms\n",
      "Speed: 3.1ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 73.4ms\n",
      "Speed: 2.0ms preprocess, 73.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Jh, 19.4ms\n",
      "Speed: 1.9ms preprocess, 19.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.6ms\n",
      "Speed: 3.1ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 14.6ms\n",
      "Speed: 2.7ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 16.3ms\n",
      "Speed: 2.6ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.5ms\n",
      "Speed: 2.4ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 12.1ms\n",
      "Speed: 3.6ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 16.9ms\n",
      "Speed: 13.2ms preprocess, 16.9ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 10.9ms\n",
      "Speed: 2.9ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 67.5ms\n",
      "Speed: 2.4ms preprocess, 67.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 15.7ms\n",
      "Speed: 2.4ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 14.4ms\n",
      "Speed: 2.5ms preprocess, 14.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 19.6ms\n",
      "Speed: 2.6ms preprocess, 19.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.3ms\n",
      "Speed: 3.6ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.3ms\n",
      "Speed: 3.9ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 18.0ms\n",
      "Speed: 1.9ms preprocess, 18.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 16.8ms\n",
      "Speed: 1.8ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 49.7ms\n",
      "Speed: 16.1ms preprocess, 49.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 17.2ms\n",
      "Speed: 2.4ms preprocess, 17.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 16.9ms\n",
      "Speed: 7.2ms preprocess, 16.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.2ms\n",
      "Speed: 2.0ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 69.7ms\n",
      "Speed: 1.9ms preprocess, 69.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 15.4ms\n",
      "Speed: 2.2ms preprocess, 15.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.7ms\n",
      "Speed: 3.4ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 17.5ms\n",
      "Speed: 1.8ms preprocess, 17.5ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 31.2ms\n",
      "Speed: 10.0ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 16.3ms\n",
      "Speed: 2.4ms preprocess, 16.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 22.0ms\n",
      "Speed: 2.6ms preprocess, 22.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 14.3ms\n",
      "Speed: 3.2ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 68.3ms\n",
      "Speed: 2.1ms preprocess, 68.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 15.2ms\n",
      "Speed: 9.7ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 14.8ms\n",
      "Speed: 1.8ms preprocess, 14.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 55.4ms\n",
      "Speed: 1.9ms preprocess, 55.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 14.6ms\n",
      "Speed: 2.6ms preprocess, 14.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 1 Qh, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.6ms\n",
      "Speed: 2.4ms preprocess, 12.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 21.5ms\n",
      "Speed: 3.0ms preprocess, 21.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 56.0ms\n",
      "Speed: 1.9ms preprocess, 56.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 23.6ms\n",
      "Speed: 2.2ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.1ms\n",
      "Speed: 2.7ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 21.2ms\n",
      "Speed: 2.4ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.2ms\n",
      "Speed: 2.1ms preprocess, 11.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 72.2ms\n",
      "Speed: 2.1ms preprocess, 72.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 15.5ms\n",
      "Speed: 2.3ms preprocess, 15.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.1ms\n",
      "Speed: 3.1ms preprocess, 12.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 74.6ms\n",
      "Speed: 2.5ms preprocess, 74.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.0ms\n",
      "Speed: 3.1ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 24.0ms\n",
      "Speed: 4.1ms preprocess, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.7ms\n",
      "Speed: 1.9ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 78.6ms\n",
      "Speed: 2.0ms preprocess, 78.6ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.0ms\n",
      "Speed: 4.6ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.8ms\n",
      "Speed: 2.2ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 12.4ms\n",
      "Speed: 3.2ms preprocess, 12.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 20.2ms\n",
      "Speed: 2.9ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 2.7ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 58.5ms\n",
      "Speed: 6.4ms preprocess, 58.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.9ms\n",
      "Speed: 1.9ms preprocess, 17.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.4ms preprocess, 10.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.1ms\n",
      "Speed: 2.1ms preprocess, 17.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.2ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 63.6ms\n",
      "Speed: 2.0ms preprocess, 63.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.5ms\n",
      "Speed: 2.4ms preprocess, 20.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.3ms\n",
      "Speed: 1.9ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.2ms\n",
      "Speed: 3.4ms preprocess, 22.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 63.8ms\n",
      "Speed: 2.4ms preprocess, 63.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.2ms\n",
      "Speed: 2.3ms preprocess, 19.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 6.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.1ms\n",
      "Speed: 2.3ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 60.4ms\n",
      "Speed: 8.6ms preprocess, 60.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 2.0ms preprocess, 13.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.6ms\n",
      "Speed: 2.3ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.4ms preprocess, 14.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.9ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.9ms\n",
      "Speed: 1.9ms preprocess, 14.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 3.2ms preprocess, 14.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.8ms\n",
      "Speed: 3.0ms preprocess, 17.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 4.1ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 45.0ms\n",
      "Speed: 1.8ms preprocess, 45.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.3ms\n",
      "Speed: 6.0ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.4ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 42.8ms\n",
      "Speed: 26.0ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.3ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.0ms\n",
      "Speed: 1.6ms preprocess, 13.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.8ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 2.2ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 83.3ms\n",
      "Speed: 1.7ms preprocess, 83.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.6ms\n",
      "Speed: 2.3ms preprocess, 14.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.1ms\n",
      "Speed: 2.4ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.1ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 81.3ms\n",
      "Speed: 1.8ms preprocess, 81.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 3.5ms preprocess, 12.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 1.8ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.3ms\n",
      "Speed: 1.8ms preprocess, 17.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.1ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 19.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.5ms\n",
      "Speed: 2.2ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 18.1ms\n",
      "Speed: 2.9ms preprocess, 18.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 2.6ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 68.9ms\n",
      "Speed: 3.1ms preprocess, 68.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.6ms\n",
      "Speed: 2.2ms preprocess, 16.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.5ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.3ms\n",
      "Speed: 1.9ms preprocess, 19.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.7ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.5ms\n",
      "Speed: 1.9ms preprocess, 21.5ms inference, 11.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 46.0ms\n",
      "Speed: 14.1ms preprocess, 46.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.5ms preprocess, 11.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.6ms\n",
      "Speed: 2.7ms preprocess, 23.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 13.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 48.7ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 4.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 1.8ms preprocess, 13.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 2.4ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 56.6ms\n",
      "Speed: 2.3ms preprocess, 56.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 2.2ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 3.7ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.4ms\n",
      "Speed: 2.9ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.1ms\n",
      "Speed: 29.8ms preprocess, 30.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 22.4ms\n",
      "Speed: 1.9ms preprocess, 22.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.1ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 11.3ms\n",
      "Speed: 3.1ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 36.8ms\n",
      "Speed: 2.8ms preprocess, 36.8ms inference, 16.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.4ms\n",
      "Speed: 2.3ms preprocess, 16.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 12.9ms\n",
      "Speed: 3.7ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 10.8ms\n",
      "Speed: 3.2ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 27.2ms\n",
      "Speed: 2.0ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 58.8ms\n",
      "Speed: 2.2ms preprocess, 58.8ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 23.8ms\n",
      "Speed: 2.2ms preprocess, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 BJoker, 13.9ms\n",
      "Speed: 1.9ms preprocess, 13.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 BJoker, 67.9ms\n",
      "Speed: 2.4ms preprocess, 67.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 BJoker, 15.8ms\n",
      "Speed: 1.7ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 BJoker, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 BJoker, 20.9ms\n",
      "Speed: 1.8ms preprocess, 20.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Key: Tc, vector len: 13, Card Detections: [[45, 865, 90, 985, 0.57470703125], [47, 866, 88, 961, 0.6376953125], [47, 865, 88, 960, 0.6376953125], [48, 864, 88, 961, 0.6337890625], [48, 864, 88, 961, 0.63427734375], [48, 864, 88, 961, 0.63525390625], [48, 865, 88, 962, 0.638671875], [48, 865, 88, 962, 0.64306640625], [48, 865, 88, 962, 0.6455078125], [48, 866, 88, 963, 0.6533203125], [48, 866, 88, 963, 0.6513671875], [48, 866, 89, 964, 0.6484375], [49, 870, 92, 969, 0.65380859375]]\n",
      "Key: Td, vector len: 12, Card Detections: [[49, 875, 96, 981, 0.5400390625], [46, 875, 90, 969, 0.6875], [47, 875, 89, 968, 0.68896484375], [48, 875, 89, 967, 0.68798828125], [48, 875, 89, 967, 0.6884765625], [47, 875, 89, 968, 0.68994140625], [48, 875, 89, 968, 0.68994140625], [48, 875, 89, 968, 0.68896484375], [48, 875, 89, 968, 0.6845703125], [48, 875, 90, 968, 0.6796875], [48, 875, 90, 968, 0.68212890625], [50, 880, 93, 971, 0.673828125]]\n",
      "Key: Th, vector len: 19, Card Detections: [[325, 903, 366, 985, 0.5791015625], [326, 903, 366, 991, 0.6171875], [327, 903, 366, 991, 0.61669921875], [327, 903, 366, 991, 0.6142578125], [326, 903, 366, 991, 0.607421875], [326, 903, 365, 992, 0.61181640625], [327, 904, 365, 991, 0.6162109375], [327, 904, 365, 992, 0.60595703125], [327, 905, 364, 992, 0.60791015625], [327, 905, 365, 992, 0.6083984375], [327, 904, 365, 992, 0.60888671875], [327, 904, 365, 992, 0.60791015625], [326, 904, 365, 991, 0.60693359375], [326, 904, 365, 992, 0.6103515625], [326, 906, 364, 992, 0.61865234375], [326, 906, 364, 993, 0.62109375], [326, 906, 364, 993, 0.62451171875], [325, 907, 363, 993, 0.619140625], [324, 908, 362, 993, 0.63134765625]]\n",
      "Key: Ts, vector len: 8, Card Detections: [[43, 861, 86, 958, 0.58740234375], [43, 860, 87, 956, 0.5859375], [43, 860, 87, 957, 0.58251953125], [43, 860, 87, 957, 0.5830078125], [43, 860, 87, 958, 0.58837890625], [44, 860, 88, 957, 0.58251953125], [44, 860, 88, 957, 0.58251953125], [46, 863, 90, 958, 0.61767578125]]\n",
      "Key: 2c, vector len: 44, Card Detections: [[330, 900, 372, 991, 0.62744140625], [330, 900, 372, 991, 0.6318359375], [330, 900, 372, 991, 0.63037109375], [329, 901, 372, 992, 0.66015625], [330, 901, 372, 992, 0.6318359375], [330, 900, 372, 992, 0.6279296875], [330, 901, 372, 992, 0.6318359375], [330, 901, 372, 992, 0.634765625], [330, 901, 372, 992, 0.6337890625], [330, 901, 372, 992, 0.6328125], [330, 901, 372, 992, 0.63330078125], [330, 901, 372, 992, 0.63427734375], [330, 901, 372, 992, 0.6337890625], [330, 901, 372, 992, 0.63330078125], [330, 901, 372, 992, 0.63232421875], [330, 901, 372, 992, 0.63134765625], [330, 901, 372, 992, 0.63134765625], [330, 901, 372, 992, 0.63037109375], [330, 901, 372, 992, 0.63037109375], [330, 901, 372, 992, 0.63134765625], [330, 901, 372, 992, 0.63232421875], [330, 901, 372, 992, 0.6318359375], [330, 901, 372, 992, 0.63232421875], [330, 901, 372, 992, 0.63134765625], [330, 901, 372, 992, 0.62890625], [330, 901, 372, 992, 0.626953125], [330, 901, 372, 992, 0.6181640625], [330, 902, 372, 992, 0.6201171875], [329, 901, 372, 992, 0.61767578125], [329, 901, 372, 992, 0.61669921875], [330, 901, 372, 992, 0.61767578125], [329, 902, 372, 993, 0.61767578125], [329, 902, 372, 993, 0.62060546875], [329, 901, 372, 992, 0.61962890625], [329, 901, 372, 992, 0.61767578125], [329, 902, 372, 992, 0.61328125], [329, 902, 372, 993, 0.61962890625], [329, 902, 372, 993, 0.61767578125], [329, 902, 372, 993, 0.6171875], [329, 902, 371, 993, 0.6201171875], [329, 902, 371, 993, 0.62646484375], [329, 902, 371, 993, 0.6259765625], [329, 903, 371, 993, 0.626953125], [328, 904, 370, 994, 0.62548828125]]\n",
      "Key: 2d, vector len: 79, Card Detections: [[335, 903, 374, 991, 0.6279296875], [334, 904, 373, 992, 0.59912109375], [334, 904, 373, 991, 0.5966796875], [335, 905, 373, 991, 0.6025390625], [334, 905, 373, 992, 0.5908203125], [334, 904, 373, 992, 0.59130859375], [334, 904, 373, 992, 0.59619140625], [334, 905, 373, 992, 0.60107421875], [334, 905, 373, 992, 0.59765625], [334, 905, 373, 992, 0.5927734375], [334, 905, 373, 992, 0.5927734375], [334, 905, 373, 992, 0.5966796875], [334, 905, 373, 992, 0.59521484375], [334, 904, 373, 992, 0.5966796875], [334, 904, 373, 992, 0.60009765625], [334, 904, 373, 992, 0.59912109375], [334, 904, 373, 992, 0.5966796875], [334, 905, 373, 992, 0.5966796875], [334, 905, 373, 992, 0.59814453125], [334, 905, 373, 992, 0.599609375], [334, 905, 373, 992, 0.599609375], [334, 905, 373, 992, 0.6005859375], [334, 904, 373, 992, 0.599609375], [334, 904, 373, 992, 0.59814453125], [334, 904, 373, 992, 0.6015625], [334, 904, 373, 991, 0.59912109375], [335, 904, 373, 991, 0.5986328125], [335, 904, 373, 992, 0.6005859375], [335, 904, 373, 991, 0.5966796875], [334, 903, 373, 991, 0.59326171875], [334, 903, 373, 991, 0.591796875], [334, 903, 373, 991, 0.5927734375], [335, 903, 373, 991, 0.59619140625], [334, 903, 374, 991, 0.59521484375], [335, 903, 374, 991, 0.59619140625], [335, 903, 373, 991, 0.59716796875], [334, 903, 373, 991, 0.5966796875], [334, 904, 373, 991, 0.59326171875], [335, 904, 373, 991, 0.59326171875], [334, 904, 374, 991, 0.59326171875], [335, 904, 374, 991, 0.59912109375], [334, 904, 373, 991, 0.59765625], [334, 904, 374, 991, 0.59765625], [335, 904, 373, 992, 0.59912109375], [335, 904, 373, 992, 0.60205078125], [335, 904, 373, 991, 0.60107421875], [335, 904, 373, 991, 0.6025390625], [335, 904, 373, 991, 0.6025390625], [335, 904, 373, 991, 0.60986328125], [334, 905, 373, 992, 0.6181640625], [334, 905, 373, 992, 0.61181640625], [334, 905, 373, 992, 0.611328125], [334, 905, 373, 992, 0.60546875], [334, 905, 373, 992, 0.60400390625], [334, 905, 373, 992, 0.60107421875], [334, 905, 373, 992, 0.59521484375], [334, 906, 372, 992, 0.58837890625], [334, 906, 372, 993, 0.595703125], [334, 907, 372, 993, 0.59326171875], [334, 907, 371, 993, 0.5986328125], [334, 907, 371, 993, 0.60595703125], [334, 907, 371, 993, 0.59912109375], [333, 908, 371, 993, 0.591796875], [333, 908, 370, 993, 0.59765625], [333, 908, 370, 994, 0.6044921875], [333, 908, 370, 994, 0.59814453125], [332, 909, 370, 994, 0.59521484375], [332, 909, 369, 994, 0.63525390625], [332, 909, 369, 994, 0.646484375], [331, 910, 368, 995, 0.6640625], [331, 910, 368, 995, 0.66650390625], [330, 911, 368, 996, 0.6669921875], [330, 911, 367, 996, 0.6767578125], [329, 911, 367, 998, 0.67138671875], [328, 912, 367, 998, 0.67236328125], [327, 912, 367, 998, 0.66357421875], [326, 913, 366, 998, 0.646484375], [326, 914, 366, 998, 0.6318359375], [323, 916, 364, 999, 0.61767578125]]\n",
      "Key: 2h, vector len: 14, Card Detections: [[45, 868, 89, 961, 0.6220703125], [46, 867, 88, 963, 0.62451171875], [46, 866, 88, 962, 0.6279296875], [47, 866, 88, 962, 0.61865234375], [47, 866, 88, 962, 0.61669921875], [47, 865, 88, 962, 0.625], [47, 865, 88, 963, 0.63037109375], [47, 865, 88, 962, 0.626953125], [47, 865, 88, 961, 0.623046875], [47, 866, 88, 962, 0.62353515625], [47, 866, 88, 963, 0.62939453125], [47, 866, 88, 964, 0.62890625], [47, 866, 89, 964, 0.63623046875], [48, 870, 91, 966, 0.62158203125]]\n",
      "Key: 2s, vector len: 18, Card Detections: [[30, 862, 74, 956, 0.65771484375], [30, 861, 73, 957, 0.654296875], [30, 861, 73, 957, 0.66259765625], [30, 861, 74, 957, 0.66552734375], [29, 861, 72, 957, 0.654296875], [29, 860, 72, 955, 0.64306640625], [29, 860, 72, 955, 0.64892578125], [29, 860, 72, 955, 0.6484375], [29, 860, 72, 955, 0.65087890625], [28, 860, 72, 956, 0.654296875], [28, 861, 72, 957, 0.6494140625], [28, 862, 71, 957, 0.64990234375], [28, 862, 71, 957, 0.6435546875], [29, 862, 71, 957, 0.63232421875], [29, 863, 71, 958, 0.642578125], [29, 863, 71, 958, 0.6396484375], [28, 864, 72, 958, 0.64208984375], [29, 866, 73, 958, 0.64599609375]]\n",
      "Key: 3c, vector len: 18, Card Detections: [[47, 898, 91, 985, 0.5546875], [48, 898, 91, 985, 0.57373046875], [48, 898, 92, 988, 0.57275390625], [48, 898, 92, 988, 0.5771484375], [49, 897, 93, 989, 0.58056640625], [48, 898, 93, 988, 0.583984375], [48, 898, 93, 987, 0.587890625], [49, 897, 93, 987, 0.591796875], [48, 897, 93, 985, 0.58740234375], [49, 897, 93, 986, 0.58740234375], [50, 897, 93, 986, 0.58837890625], [50, 897, 94, 986, 0.57763671875], [50, 897, 94, 986, 0.58056640625], [49, 897, 94, 987, 0.58349609375], [50, 896, 94, 987, 0.5859375], [50, 897, 95, 987, 0.58642578125], [50, 897, 94, 987, 0.58447265625], [51, 900, 96, 987, 0.58935546875]]\n",
      "Key: 3d, vector len: 14, Card Detections: [[44, 859, 88, 955, 0.64208984375], [44, 861, 87, 956, 0.63330078125], [44, 861, 87, 956, 0.6298828125], [44, 861, 88, 957, 0.64453125], [44, 861, 88, 956, 0.63720703125], [44, 861, 88, 957, 0.63232421875], [44, 861, 88, 957, 0.6337890625], [44, 861, 88, 957, 0.64404296875], [44, 861, 88, 957, 0.6435546875], [45, 861, 88, 958, 0.62548828125], [45, 861, 88, 958, 0.6328125], [45, 861, 89, 957, 0.609375], [45, 862, 89, 958, 0.61181640625], [46, 864, 90, 961, 0.64013671875]]\n",
      "Key: 3h, vector len: 24, Card Detections: [[327, 903, 368, 1007, 0.6435546875], [328, 903, 368, 992, 0.58984375], [328, 903, 368, 992, 0.59033203125], [328, 903, 368, 992, 0.59423828125], [328, 903, 368, 992, 0.611328125], [328, 904, 368, 992, 0.609375], [328, 904, 368, 992, 0.6044921875], [328, 904, 368, 992, 0.603515625], [328, 904, 368, 993, 0.6103515625], [328, 904, 368, 992, 0.6142578125], [328, 903, 368, 992, 0.6142578125], [328, 903, 368, 992, 0.6103515625], [328, 904, 368, 992, 0.60888671875], [328, 904, 368, 992, 0.6123046875], [328, 904, 368, 992, 0.61669921875], [328, 904, 368, 992, 0.62060546875], [328, 904, 368, 992, 0.60888671875], [328, 903, 367, 992, 0.60107421875], [328, 904, 367, 992, 0.59814453125], [328, 904, 367, 993, 0.59619140625], [328, 904, 367, 993, 0.5947265625], [328, 904, 367, 992, 0.59912109375], [327, 904, 366, 992, 0.599609375], [326, 907, 365, 993, 0.58349609375]]\n",
      "Key: 3s, vector len: 16, Card Detections: [[326, 901, 369, 985, 0.6201171875], [326, 901, 369, 985, 0.6240234375], [326, 901, 369, 985, 0.623046875], [326, 900, 369, 985, 0.62353515625], [326, 900, 369, 985, 0.630859375], [326, 899, 369, 984, 0.6337890625], [326, 899, 369, 985, 0.63330078125], [326, 899, 369, 985, 0.626953125], [326, 899, 369, 985, 0.62890625], [326, 900, 368, 985, 0.62890625], [326, 901, 368, 986, 0.619140625], [326, 901, 368, 986, 0.619140625], [326, 901, 368, 985, 0.619140625], [326, 901, 368, 986, 0.6240234375], [325, 902, 368, 987, 0.61767578125], [324, 903, 368, 987, 0.607421875]]\n",
      "Key: 4c, vector len: 15, Card Detections: [[44, 873, 149, 971, 0.64892578125], [45, 872, 149, 971, 0.6484375], [45, 871, 149, 971, 0.64892578125], [45, 871, 149, 971, 0.642578125], [45, 871, 149, 971, 0.640625], [45, 871, 149, 971, 0.63916015625], [47, 871, 148, 970, 0.63427734375], [47, 870, 148, 970, 0.63525390625], [45, 870, 149, 970, 0.64208984375], [45, 871, 149, 970, 0.634765625], [45, 870, 149, 971, 0.63818359375], [46, 871, 148, 970, 0.6337890625], [46, 871, 148, 970, 0.63818359375], [46, 871, 148, 970, 0.63623046875], [47, 872, 148, 970, 0.6416015625]]\n",
      "Key: 4d, vector len: 30, Card Detections: [[24, 861, 124, 979, 0.6240234375], [24, 862, 119, 961, 0.6064453125], [24, 862, 119, 961, 0.60400390625], [24, 864, 119, 962, 0.60888671875], [23, 866, 118, 963, 0.60888671875], [23, 866, 118, 964, 0.6083984375], [23, 866, 119, 964, 0.607421875], [24, 866, 119, 964, 0.60595703125], [24, 867, 119, 965, 0.6025390625], [24, 868, 119, 966, 0.59912109375], [24, 869, 119, 966, 0.59814453125], [25, 870, 119, 966, 0.59521484375], [24, 870, 119, 967, 0.595703125], [25, 872, 119, 967, 0.595703125], [25, 873, 118, 968, 0.59814453125], [25, 873, 118, 968, 0.599609375], [25, 875, 118, 968, 0.60302734375], [25, 875, 118, 969, 0.6025390625], [25, 875, 118, 969, 0.5986328125], [25, 875, 118, 968, 0.60302734375], [25, 875, 118, 968, 0.60302734375], [25, 875, 118, 969, 0.6025390625], [25, 875, 118, 969, 0.60107421875], [25, 876, 118, 969, 0.59765625], [26, 876, 118, 969, 0.59765625], [26, 876, 118, 969, 0.59912109375], [26, 876, 118, 969, 0.60009765625], [26, 876, 118, 969, 0.59765625], [26, 877, 118, 969, 0.599609375], [27, 881, 119, 969, 0.61328125]]\n",
      "Key: 4h, vector len: 22, Card Detections: [[329, 901, 417, 989, 0.6435546875], [330, 901, 415, 994, 0.6416015625], [330, 901, 415, 994, 0.63525390625], [330, 901, 415, 993, 0.6396484375], [330, 901, 415, 993, 0.63818359375], [330, 901, 415, 993, 0.64111328125], [330, 901, 415, 993, 0.6416015625], [330, 901, 415, 994, 0.64111328125], [330, 902, 415, 994, 0.64404296875], [329, 901, 415, 994, 0.642578125], [330, 901, 415, 994, 0.64306640625], [330, 901, 415, 994, 0.64404296875], [330, 901, 415, 994, 0.64404296875], [330, 901, 415, 994, 0.64208984375], [330, 901, 415, 993, 0.642578125], [330, 901, 415, 993, 0.6455078125], [329, 902, 415, 994, 0.63623046875], [329, 902, 415, 994, 0.63671875], [329, 902, 415, 994, 0.63427734375], [329, 901, 415, 994, 0.630859375], [329, 902, 414, 994, 0.638671875], [329, 904, 414, 994, 0.6357421875]]\n",
      "Key: 4s, vector len: 12, Card Detections: [[43, 859, 138, 961, 0.62451171875], [44, 859, 137, 962, 0.62451171875], [44, 860, 138, 962, 0.62353515625], [45, 860, 137, 962, 0.6201171875], [45, 860, 138, 962, 0.62255859375], [45, 860, 138, 962, 0.626953125], [45, 860, 138, 962, 0.62939453125], [45, 860, 137, 962, 0.62646484375], [45, 860, 137, 962, 0.6240234375], [46, 862, 138, 962, 0.62158203125], [46, 863, 137, 964, 0.61328125], [46, 865, 138, 963, 0.62060546875]]\n",
      "Key: 5c, vector len: 82, Card Detections: [[25, 885, 68, 975, 0.5732421875], [24, 886, 66, 974, 0.62548828125], [24, 885, 66, 974, 0.63134765625], [24, 886, 66, 975, 0.630859375], [23, 886, 66, 976, 0.63134765625], [24, 886, 66, 976, 0.6298828125], [24, 886, 66, 976, 0.63330078125], [24, 886, 66, 976, 0.6376953125], [24, 885, 66, 975, 0.63623046875], [24, 885, 67, 975, 0.63818359375], [24, 884, 67, 973, 0.63330078125], [24, 884, 67, 973, 0.630859375], [24, 885, 67, 974, 0.63330078125], [24, 884, 67, 974, 0.63330078125], [24, 884, 67, 973, 0.6328125], [24, 884, 67, 973, 0.63134765625], [24, 885, 67, 974, 0.6357421875], [24, 885, 67, 974, 0.63720703125], [24, 885, 67, 974, 0.6357421875], [25, 885, 67, 974, 0.63427734375], [25, 885, 67, 974, 0.6337890625], [25, 885, 67, 974, 0.634765625], [25, 885, 68, 974, 0.63525390625], [25, 885, 68, 974, 0.63525390625], [25, 885, 68, 974, 0.6337890625], [25, 885, 68, 974, 0.63818359375], [25, 886, 68, 974, 0.63525390625], [25, 886, 68, 974, 0.6337890625], [25, 886, 68, 975, 0.64697265625], [25, 886, 68, 975, 0.64453125], [26, 887, 68, 974, 0.59716796875], [26, 887, 68, 974, 0.5849609375], [26, 888, 68, 974, 0.61181640625], [26, 888, 68, 975, 0.5966796875], [26, 889, 68, 975, 0.6328125], [26, 891, 68, 976, 0.64599609375], [26, 891, 68, 976, 0.646484375], [26, 891, 68, 976, 0.640625], [27, 892, 68, 976, 0.64794921875], [26, 892, 68, 978, 0.6494140625], [26, 892, 68, 978, 0.6484375], [26, 892, 68, 978, 0.64697265625], [26, 893, 68, 978, 0.63916015625], [26, 893, 68, 978, 0.6376953125], [26, 893, 68, 978, 0.6376953125], [26, 893, 68, 978, 0.63037109375], [26, 894, 67, 979, 0.63232421875], [26, 895, 67, 979, 0.630859375], [26, 895, 67, 979, 0.63037109375], [26, 895, 67, 979, 0.6298828125], [26, 895, 67, 979, 0.63232421875], [26, 895, 68, 979, 0.6328125], [26, 896, 67, 979, 0.62939453125], [26, 896, 67, 979, 0.62841796875], [26, 896, 68, 979, 0.6318359375], [26, 897, 67, 979, 0.61962890625], [26, 896, 67, 978, 0.58740234375], [26, 896, 67, 978, 0.6064453125], [26, 897, 67, 979, 0.61669921875], [26, 896, 67, 978, 0.6123046875], [27, 896, 68, 977, 0.6201171875], [27, 896, 68, 977, 0.626953125], [27, 896, 68, 978, 0.62255859375], [27, 896, 68, 978, 0.62744140625], [27, 896, 68, 978, 0.6337890625], [27, 896, 68, 978, 0.63037109375], [27, 896, 68, 978, 0.6318359375], [27, 896, 68, 978, 0.6337890625], [27, 896, 68, 978, 0.63134765625], [27, 896, 68, 978, 0.63330078125], [27, 896, 68, 978, 0.62548828125], [27, 897, 68, 977, 0.6123046875], [27, 898, 68, 977, 0.6123046875], [27, 898, 68, 978, 0.60986328125], [27, 899, 68, 978, 0.607421875], [27, 899, 68, 978, 0.59716796875], [27, 899, 68, 979, 0.60888671875], [27, 899, 68, 979, 0.60009765625], [27, 899, 69, 979, 0.58349609375], [27, 901, 69, 980, 0.5830078125], [27, 902, 69, 980, 0.6044921875], [27, 905, 70, 981, 0.54638671875]]\n",
      "Key: 5d, vector len: 12, Card Detections: [[43, 862, 85, 956, 0.63037109375], [43, 862, 85, 956, 0.6318359375], [43, 862, 85, 956, 0.630859375], [43, 862, 85, 957, 0.63134765625], [43, 862, 84, 956, 0.62060546875], [43, 861, 85, 956, 0.62939453125], [43, 860, 85, 955, 0.62255859375], [43, 860, 85, 956, 0.623046875], [43, 861, 85, 956, 0.62646484375], [43, 860, 85, 955, 0.6259765625], [43, 860, 85, 955, 0.62353515625], [44, 862, 86, 956, 0.61962890625]]\n",
      "Key: 5h, vector len: 43, Card Detections: [[23, 874, 64, 964, 0.62353515625], [23, 875, 64, 965, 0.60888671875], [23, 875, 64, 965, 0.6064453125], [23, 875, 63, 965, 0.6044921875], [23, 876, 63, 965, 0.6376953125], [24, 876, 64, 965, 0.63330078125], [24, 876, 64, 965, 0.6279296875], [24, 876, 64, 965, 0.626953125], [24, 876, 64, 965, 0.61279296875], [23, 875, 64, 965, 0.60791015625], [24, 876, 64, 965, 0.61376953125], [24, 877, 64, 965, 0.626953125], [24, 877, 64, 967, 0.646484375], [24, 878, 64, 967, 0.6513671875], [24, 878, 64, 967, 0.65380859375], [24, 879, 64, 967, 0.65478515625], [24, 880, 64, 968, 0.654296875], [24, 880, 65, 968, 0.64892578125], [24, 881, 65, 968, 0.6513671875], [24, 882, 65, 969, 0.66015625], [24, 882, 65, 969, 0.66015625], [24, 882, 65, 970, 0.66748046875], [25, 884, 65, 971, 0.65966796875], [24, 885, 65, 972, 0.66259765625], [24, 886, 65, 972, 0.66064453125], [24, 887, 65, 973, 0.6552734375], [24, 888, 65, 973, 0.6572265625], [24, 888, 65, 973, 0.658203125], [25, 889, 65, 974, 0.6572265625], [25, 889, 66, 974, 0.6650390625], [25, 889, 66, 974, 0.66552734375], [25, 889, 66, 974, 0.6650390625], [26, 891, 66, 975, 0.64794921875], [25, 891, 66, 975, 0.642578125], [25, 891, 66, 975, 0.642578125], [25, 891, 66, 975, 0.6416015625], [26, 891, 66, 975, 0.6474609375], [26, 891, 67, 975, 0.64599609375], [26, 892, 66, 975, 0.642578125], [26, 891, 67, 975, 0.6416015625], [26, 892, 67, 975, 0.64697265625], [26, 891, 67, 975, 0.6484375], [27, 889, 69, 976, 0.5966796875]]\n",
      "Key: 5s, vector len: 25, Card Detections: [[323, 897, 367, 985, 0.64111328125], [325, 897, 366, 986, 0.62939453125], [325, 897, 366, 986, 0.63134765625], [325, 897, 366, 986, 0.63232421875], [325, 899, 365, 988, 0.63720703125], [325, 900, 365, 988, 0.63671875], [325, 899, 365, 988, 0.63330078125], [325, 898, 365, 989, 0.64306640625], [325, 899, 365, 989, 0.63330078125], [325, 900, 365, 989, 0.63525390625], [325, 900, 365, 990, 0.607421875], [325, 900, 365, 990, 0.64892578125], [325, 900, 365, 990, 0.646484375], [325, 900, 365, 990, 0.6220703125], [325, 899, 365, 990, 0.5703125], [325, 900, 365, 990, 0.59912109375], [325, 901, 365, 990, 0.6123046875], [325, 901, 365, 990, 0.62744140625], [324, 900, 364, 990, 0.64599609375], [324, 901, 364, 990, 0.6494140625], [323, 901, 364, 990, 0.64990234375], [323, 901, 364, 991, 0.6494140625], [323, 901, 364, 991, 0.64697265625], [323, 902, 363, 991, 0.6474609375], [321, 904, 363, 991, 0.62255859375]]\n",
      "Key: 6c, vector len: 12, Card Detections: [[42, 865, 86, 968, 0.63134765625], [44, 865, 86, 962, 0.66357421875], [43, 865, 86, 961, 0.67138671875], [44, 865, 86, 961, 0.6591796875], [44, 865, 86, 962, 0.65576171875], [44, 864, 86, 961, 0.6728515625], [44, 864, 86, 961, 0.66650390625], [44, 864, 86, 961, 0.6669921875], [44, 865, 86, 960, 0.6728515625], [44, 866, 86, 962, 0.66943359375], [44, 866, 86, 962, 0.666015625], [46, 868, 89, 964, 0.66015625]]\n",
      "Key: 6d, vector len: 316, Card Detections: [[313, 975, 364, 1029, 0.59130859375], [313, 974, 362, 1027, 0.65185546875], [314, 973, 362, 1027, 0.6337890625], [314, 972, 361, 1026, 0.6484375], [314, 972, 361, 1026, 0.6533203125], [314, 970, 362, 1025, 0.62158203125], [314, 969, 363, 1025, 0.6064453125], [314, 969, 362, 1025, 0.63623046875], [314, 967, 362, 1025, 0.63525390625], [315, 966, 362, 1023, 0.615234375], [315, 965, 362, 1023, 0.5595703125], [315, 964, 362, 1022, 0.57568359375], [316, 964, 362, 1022, 0.5556640625], [316, 963, 362, 1022, 0.60986328125], [315, 963, 362, 1022, 0.6259765625], [315, 962, 362, 1021, 0.6220703125], [316, 961, 362, 1021, 0.6328125], [316, 960, 363, 1019, 0.63232421875], [316, 960, 363, 1020, 0.626953125], [316, 960, 363, 1020, 0.615234375], [317, 959, 363, 1019, 0.658203125], [317, 958, 363, 1019, 0.62744140625], [317, 957, 362, 1018, 0.61669921875], [317, 956, 362, 1017, 0.634765625], [317, 955, 362, 1017, 0.6318359375], [316, 955, 362, 1016, 0.64306640625], [316, 954, 362, 1016, 0.6474609375], [316, 953, 362, 1016, 0.62353515625], [316, 953, 362, 1015, 0.6103515625], [316, 953, 362, 1016, 0.61328125], [316, 952, 362, 1015, 0.6435546875], [317, 951, 362, 1014, 0.63818359375], [317, 950, 362, 1014, 0.64501953125], [317, 949, 362, 1014, 0.60791015625], [317, 948, 362, 1013, 0.60791015625], [317, 946, 362, 1012, 0.6259765625], [317, 946, 362, 1011, 0.6318359375], [317, 945, 362, 1011, 0.6376953125], [317, 945, 362, 1011, 0.64306640625], [317, 944, 362, 1011, 0.6533203125], [317, 943, 363, 1011, 0.65185546875], [317, 942, 362, 1009, 0.6513671875], [317, 942, 363, 1009, 0.65185546875], [317, 941, 362, 1009, 0.65478515625], [318, 940, 362, 1008, 0.6552734375], [318, 939, 362, 1008, 0.65966796875], [318, 939, 362, 1007, 0.66357421875], [318, 938, 362, 1007, 0.66259765625], [318, 937, 362, 1006, 0.65771484375], [318, 937, 362, 1006, 0.65625], [318, 936, 362, 1006, 0.65625], [317, 936, 362, 1007, 0.65380859375], [317, 934, 362, 1006, 0.646484375], [317, 933, 362, 1006, 0.64697265625], [317, 933, 362, 1005, 0.642578125], [317, 933, 362, 1005, 0.6416015625], [317, 932, 361, 1005, 0.6396484375], [317, 932, 362, 1004, 0.63916015625], [317, 932, 362, 1003, 0.638671875], [317, 932, 361, 1003, 0.634765625], [317, 931, 361, 1003, 0.63916015625], [317, 929, 361, 1003, 0.63623046875], [317, 929, 361, 1002, 0.63525390625], [317, 929, 361, 1002, 0.63818359375], [317, 929, 361, 1002, 0.64013671875], [317, 928, 360, 1002, 0.6435546875], [317, 928, 360, 1001, 0.646484375], [317, 927, 360, 1001, 0.64501953125], [317, 927, 360, 1000, 0.64599609375], [317, 926, 360, 1000, 0.6494140625], [317, 926, 360, 1000, 0.65380859375], [317, 926, 359, 999, 0.658203125], [317, 925, 359, 998, 0.66552734375], [318, 924, 360, 998, 0.66650390625], [318, 924, 360, 997, 0.66796875], [318, 924, 360, 997, 0.66748046875], [318, 924, 360, 997, 0.66455078125], [318, 923, 360, 997, 0.66455078125], [318, 923, 360, 997, 0.6591796875], [318, 922, 360, 997, 0.6572265625], [318, 922, 360, 997, 0.65869140625], [318, 921, 360, 996, 0.66162109375], [318, 920, 360, 996, 0.66015625], [318, 920, 360, 996, 0.66162109375], [318, 920, 360, 996, 0.66357421875], [318, 919, 361, 996, 0.6611328125], [318, 919, 361, 996, 0.66064453125], [318, 919, 361, 995, 0.66015625], [318, 919, 361, 995, 0.6611328125], [318, 918, 361, 995, 0.66064453125], [318, 918, 361, 995, 0.658203125], [319, 918, 361, 995, 0.66064453125], [319, 917, 361, 994, 0.65869140625], [319, 916, 361, 993, 0.65283203125], [319, 916, 361, 993, 0.6513671875], [319, 916, 361, 993, 0.65185546875], [320, 916, 361, 992, 0.6533203125], [320, 915, 362, 992, 0.65576171875], [320, 915, 361, 991, 0.654296875], [320, 914, 362, 991, 0.65283203125], [320, 914, 362, 991, 0.6533203125], [320, 914, 362, 991, 0.65234375], [320, 914, 361, 991, 0.65283203125], [320, 913, 361, 991, 0.65234375], [320, 913, 361, 990, 0.65283203125], [320, 913, 361, 990, 0.654296875], [320, 912, 361, 990, 0.65576171875], [320, 912, 361, 989, 0.6591796875], [320, 912, 361, 989, 0.65869140625], [320, 912, 361, 989, 0.6591796875], [321, 911, 361, 989, 0.66552734375], [321, 910, 361, 988, 0.67236328125], [321, 910, 362, 988, 0.66748046875], [321, 910, 362, 988, 0.66943359375], [321, 909, 362, 988, 0.66796875], [321, 909, 362, 988, 0.6669921875], [321, 908, 362, 987, 0.66455078125], [322, 908, 362, 987, 0.6640625], [322, 907, 362, 987, 0.6611328125], [322, 907, 362, 987, 0.6572265625], [322, 906, 363, 986, 0.650390625], [322, 906, 363, 986, 0.650390625], [322, 906, 363, 986, 0.64990234375], [322, 905, 363, 986, 0.650390625], [322, 905, 363, 986, 0.6494140625], [322, 905, 363, 986, 0.6474609375], [322, 904, 363, 986, 0.6484375], [322, 904, 363, 986, 0.64697265625], [322, 904, 363, 986, 0.6474609375], [323, 904, 363, 986, 0.6474609375], [323, 904, 363, 986, 0.6474609375], [323, 904, 363, 986, 0.6484375], [323, 903, 364, 986, 0.64501953125], [323, 903, 364, 986, 0.642578125], [323, 903, 364, 985, 0.642578125], [323, 903, 364, 985, 0.64208984375], [323, 903, 364, 985, 0.64208984375], [323, 903, 364, 985, 0.642578125], [323, 903, 364, 985, 0.64453125], [323, 903, 364, 985, 0.64453125], [323, 903, 364, 985, 0.6474609375], [323, 903, 364, 985, 0.6474609375], [323, 903, 364, 985, 0.64697265625], [323, 903, 364, 985, 0.6455078125], [323, 903, 364, 984, 0.64599609375], [323, 903, 364, 984, 0.6474609375], [323, 903, 364, 984, 0.6494140625], [323, 903, 364, 984, 0.650390625], [323, 903, 364, 984, 0.65283203125], [323, 902, 364, 984, 0.65283203125], [324, 902, 364, 984, 0.65234375], [324, 902, 364, 984, 0.65234375], [324, 902, 364, 984, 0.65478515625], [324, 902, 364, 983, 0.66845703125], [324, 902, 364, 983, 0.66162109375], [324, 902, 364, 983, 0.6591796875], [324, 902, 364, 983, 0.662109375], [324, 902, 364, 983, 0.662109375], [324, 902, 364, 983, 0.66357421875], [324, 902, 364, 983, 0.6650390625], [324, 902, 364, 983, 0.66455078125], [324, 902, 364, 983, 0.66455078125], [324, 901, 364, 983, 0.66845703125], [324, 901, 364, 983, 0.66943359375], [324, 901, 364, 983, 0.66796875], [324, 901, 364, 983, 0.66455078125], [324, 901, 364, 983, 0.6650390625], [324, 901, 364, 983, 0.66455078125], [324, 901, 364, 984, 0.6630859375], [324, 901, 364, 983, 0.66357421875], [325, 901, 365, 984, 0.6689453125], [325, 901, 365, 984, 0.6708984375], [325, 901, 365, 984, 0.6689453125], [325, 901, 365, 984, 0.669921875], [325, 901, 365, 984, 0.6689453125], [325, 901, 365, 984, 0.669921875], [325, 901, 365, 984, 0.67041015625], [325, 900, 365, 983, 0.66943359375], [325, 900, 365, 983, 0.669921875], [325, 900, 365, 984, 0.67138671875], [325, 900, 365, 983, 0.67236328125], [325, 900, 365, 983, 0.6728515625], [325, 900, 365, 983, 0.66845703125], [325, 900, 365, 983, 0.6708984375], [325, 900, 365, 983, 0.671875], [325, 900, 365, 983, 0.6708984375], [325, 900, 365, 983, 0.6708984375], [325, 900, 365, 983, 0.6728515625], [325, 900, 365, 983, 0.6728515625], [325, 900, 365, 983, 0.67333984375], [325, 900, 365, 983, 0.67236328125], [325, 900, 365, 983, 0.67138671875], [325, 900, 365, 983, 0.6689453125], [325, 900, 365, 983, 0.669921875], [325, 900, 365, 983, 0.67236328125], [325, 900, 365, 983, 0.671875], [325, 900, 365, 983, 0.67138671875], [325, 900, 365, 984, 0.67138671875], [325, 900, 365, 983, 0.669921875], [325, 900, 365, 983, 0.671875], [325, 900, 365, 983, 0.67529296875], [325, 900, 365, 983, 0.67431640625], [325, 900, 365, 983, 0.6748046875], [325, 900, 365, 983, 0.67529296875], [325, 900, 365, 983, 0.673828125], [325, 900, 365, 983, 0.67529296875], [325, 900, 365, 983, 0.67529296875], [325, 900, 365, 983, 0.673828125], [325, 900, 365, 983, 0.6748046875], [325, 900, 365, 983, 0.673828125], [325, 900, 365, 983, 0.6728515625], [325, 900, 365, 983, 0.67236328125], [325, 900, 365, 983, 0.67529296875], [325, 900, 365, 983, 0.67431640625], [325, 900, 365, 983, 0.671875], [325, 900, 365, 983, 0.67333984375], [325, 901, 365, 983, 0.67431640625], [325, 901, 365, 983, 0.67431640625], [325, 901, 365, 983, 0.67626953125], [325, 901, 365, 983, 0.6767578125], [325, 901, 365, 983, 0.6748046875], [325, 901, 365, 983, 0.67529296875], [325, 901, 365, 983, 0.67529296875], [325, 901, 365, 983, 0.6748046875], [325, 901, 365, 984, 0.6748046875], [325, 901, 365, 983, 0.67626953125], [325, 901, 365, 983, 0.6748046875], [325, 901, 365, 983, 0.67529296875], [325, 901, 365, 983, 0.6748046875], [325, 901, 365, 983, 0.6748046875], [325, 901, 365, 984, 0.671875], [325, 901, 365, 984, 0.673828125], [325, 901, 365, 984, 0.67138671875], [325, 901, 364, 984, 0.66748046875], [325, 901, 365, 984, 0.666015625], [325, 901, 365, 984, 0.6650390625], [325, 901, 364, 984, 0.66357421875], [325, 901, 365, 984, 0.66455078125], [325, 901, 364, 984, 0.6630859375], [325, 901, 364, 984, 0.658203125], [325, 902, 364, 984, 0.65625], [325, 902, 364, 984, 0.6572265625], [325, 902, 364, 984, 0.6572265625], [325, 902, 364, 984, 0.658203125], [325, 902, 364, 984, 0.66064453125], [325, 902, 364, 984, 0.66015625], [325, 902, 364, 985, 0.658203125], [325, 902, 364, 984, 0.65869140625], [325, 901, 364, 984, 0.6640625], [325, 901, 364, 984, 0.6630859375], [325, 902, 364, 984, 0.66015625], [325, 902, 364, 984, 0.65966796875], [325, 902, 364, 984, 0.65966796875], [325, 902, 364, 985, 0.65869140625], [325, 902, 364, 985, 0.65771484375], [325, 902, 364, 985, 0.65771484375], [325, 902, 364, 985, 0.65771484375], [325, 902, 364, 985, 0.65771484375], [325, 902, 364, 985, 0.65771484375], [325, 902, 364, 984, 0.65771484375], [325, 902, 364, 985, 0.65185546875], [324, 902, 364, 985, 0.64990234375], [324, 902, 364, 985, 0.6494140625], [324, 902, 364, 985, 0.64990234375], [324, 902, 364, 985, 0.64892578125], [324, 902, 364, 986, 0.6455078125], [324, 902, 364, 986, 0.6455078125], [324, 902, 364, 986, 0.64501953125], [324, 903, 364, 986, 0.64453125], [324, 903, 364, 986, 0.6435546875], [324, 903, 364, 986, 0.64501953125], [324, 903, 364, 986, 0.64453125], [324, 903, 364, 986, 0.64404296875], [324, 903, 364, 986, 0.642578125], [324, 903, 364, 986, 0.64013671875], [324, 903, 364, 986, 0.640625], [324, 903, 364, 986, 0.6416015625], [324, 903, 364, 986, 0.640625], [324, 903, 364, 986, 0.640625], [324, 903, 364, 986, 0.6416015625], [323, 903, 364, 986, 0.640625], [323, 903, 364, 986, 0.64111328125], [323, 904, 364, 986, 0.64111328125], [323, 904, 364, 986, 0.6416015625], [323, 904, 364, 986, 0.642578125], [323, 904, 364, 986, 0.64208984375], [323, 904, 364, 986, 0.642578125], [323, 904, 364, 986, 0.64306640625], [323, 903, 364, 986, 0.64208984375], [323, 904, 364, 986, 0.64208984375], [323, 904, 364, 986, 0.64404296875], [323, 904, 363, 986, 0.6435546875], [323, 903, 364, 986, 0.64208984375], [323, 903, 364, 986, 0.64306640625], [323, 904, 364, 986, 0.6435546875], [323, 904, 364, 986, 0.6435546875], [323, 904, 364, 986, 0.6435546875], [323, 904, 363, 985, 0.64306640625], [323, 904, 363, 986, 0.64453125], [323, 904, 363, 986, 0.64501953125], [323, 904, 363, 986, 0.64453125], [323, 904, 363, 986, 0.64453125], [323, 904, 363, 986, 0.6455078125], [323, 904, 363, 986, 0.64599609375], [323, 904, 363, 986, 0.64404296875], [323, 904, 363, 986, 0.64453125], [323, 904, 363, 986, 0.64794921875], [323, 904, 363, 986, 0.646484375], [323, 904, 363, 986, 0.64794921875], [323, 904, 363, 986, 0.64990234375], [323, 904, 363, 987, 0.650390625], [323, 904, 363, 987, 0.6513671875], [323, 905, 363, 987, 0.6552734375], [322, 905, 363, 986, 0.65576171875], [322, 905, 362, 986, 0.65625], [320, 907, 362, 985, 0.6455078125]]\n",
      "Key: 6h, vector len: 23, Card Detections: [[48, 887, 90, 979, 0.6025390625], [48, 888, 88, 978, 0.61865234375], [49, 889, 88, 978, 0.63232421875], [48, 888, 88, 979, 0.6337890625], [48, 888, 89, 978, 0.64111328125], [48, 888, 88, 977, 0.63330078125], [48, 888, 89, 978, 0.62060546875], [48, 888, 89, 979, 0.63037109375], [48, 888, 89, 978, 0.6435546875], [48, 888, 89, 979, 0.64306640625], [48, 888, 89, 978, 0.6416015625], [48, 888, 89, 979, 0.6484375], [48, 887, 89, 979, 0.64990234375], [48, 887, 89, 978, 0.64501953125], [48, 887, 89, 978, 0.650390625], [48, 887, 89, 978, 0.6416015625], [48, 886, 89, 978, 0.64208984375], [49, 886, 89, 978, 0.63720703125], [49, 887, 89, 978, 0.64404296875], [48, 886, 89, 979, 0.6474609375], [48, 887, 89, 978, 0.646484375], [49, 887, 89, 978, 0.6484375], [49, 889, 90, 979, 0.64794921875]]\n",
      "Key: 6s, vector len: 34, Card Detections: [[28, 861, 74, 974, 0.60986328125], [28, 861, 69, 958, 0.68603515625], [27, 861, 69, 959, 0.66650390625], [27, 861, 69, 959, 0.67919921875], [27, 862, 68, 960, 0.67431640625], [27, 863, 68, 960, 0.6728515625], [27, 863, 68, 960, 0.67236328125], [26, 863, 68, 960, 0.67626953125], [26, 862, 68, 959, 0.6796875], [26, 862, 67, 959, 0.6787109375], [25, 862, 67, 960, 0.6572265625], [25, 863, 67, 959, 0.68798828125], [25, 862, 67, 959, 0.69482421875], [25, 862, 67, 959, 0.712890625], [25, 862, 67, 959, 0.712890625], [25, 862, 67, 959, 0.70751953125], [25, 862, 67, 959, 0.712890625], [25, 862, 67, 959, 0.7060546875], [25, 862, 67, 959, 0.7060546875], [25, 862, 67, 959, 0.7041015625], [25, 862, 67, 958, 0.7060546875], [25, 862, 66, 958, 0.7060546875], [25, 862, 66, 958, 0.697265625], [25, 861, 67, 958, 0.71337890625], [25, 861, 67, 958, 0.7080078125], [25, 861, 67, 958, 0.71142578125], [25, 862, 67, 958, 0.70947265625], [25, 862, 67, 958, 0.7099609375], [25, 862, 67, 958, 0.68505859375], [25, 862, 67, 958, 0.68505859375], [26, 862, 68, 958, 0.68017578125], [26, 863, 68, 959, 0.677734375], [26, 865, 68, 959, 0.66748046875], [28, 865, 71, 962, 0.6337890625]]\n",
      "Key: 7c, vector len: 26, Card Detections: [[328, 903, 367, 995, 0.61962890625], [328, 903, 367, 995, 0.61328125], [328, 903, 367, 995, 0.6181640625], [328, 904, 367, 996, 0.6171875], [328, 904, 367, 996, 0.61669921875], [328, 903, 367, 995, 0.61767578125], [328, 903, 367, 995, 0.61669921875], [329, 904, 367, 996, 0.61865234375], [328, 904, 367, 996, 0.6171875], [328, 903, 367, 996, 0.62109375], [328, 904, 367, 996, 0.595703125], [329, 904, 367, 995, 0.59912109375], [328, 904, 367, 996, 0.59912109375], [328, 904, 367, 995, 0.60205078125], [329, 904, 367, 996, 0.6005859375], [328, 904, 367, 995, 0.599609375], [329, 903, 367, 994, 0.5986328125], [329, 903, 367, 994, 0.595703125], [328, 904, 367, 995, 0.59619140625], [329, 904, 367, 995, 0.59619140625], [329, 904, 367, 995, 0.5947265625], [328, 904, 367, 995, 0.5927734375], [328, 904, 367, 996, 0.607421875], [327, 904, 367, 996, 0.6083984375], [327, 904, 367, 996, 0.60546875], [324, 906, 367, 998, 0.6240234375]]\n",
      "Key: 7d, vector len: 33, Card Detections: [[333, 901, 372, 991, 0.634765625], [333, 901, 371, 991, 0.6240234375], [333, 901, 371, 991, 0.6279296875], [332, 901, 372, 992, 0.63720703125], [332, 902, 371, 992, 0.6279296875], [332, 901, 371, 991, 0.62744140625], [332, 901, 371, 991, 0.63037109375], [332, 902, 371, 993, 0.6279296875], [332, 902, 371, 993, 0.62548828125], [332, 902, 371, 993, 0.62646484375], [332, 902, 371, 993, 0.6259765625], [332, 902, 371, 993, 0.62451171875], [332, 902, 371, 993, 0.62353515625], [332, 902, 371, 993, 0.62451171875], [332, 902, 371, 993, 0.625], [332, 902, 371, 993, 0.62890625], [332, 902, 371, 993, 0.6279296875], [332, 902, 371, 993, 0.62548828125], [332, 902, 371, 993, 0.6259765625], [332, 902, 371, 993, 0.6240234375], [332, 902, 371, 993, 0.6240234375], [332, 903, 371, 993, 0.62060546875], [332, 903, 371, 993, 0.61962890625], [332, 903, 371, 993, 0.6201171875], [332, 903, 371, 993, 0.61865234375], [332, 903, 370, 993, 0.61962890625], [332, 903, 369, 993, 0.61669921875], [332, 904, 370, 993, 0.61865234375], [333, 903, 369, 993, 0.6171875], [333, 904, 369, 993, 0.619140625], [332, 904, 368, 993, 0.62451171875], [332, 905, 368, 993, 0.630859375], [330, 908, 367, 995, 0.61572265625]]\n",
      "Key: 7h, vector len: 23, Card Detections: [[333, 899, 372, 991, 0.6416015625], [333, 899, 371, 991, 0.64111328125], [333, 899, 372, 991, 0.64111328125], [332, 900, 372, 991, 0.64306640625], [333, 900, 372, 991, 0.64501953125], [333, 899, 372, 991, 0.64111328125], [333, 899, 372, 991, 0.6416015625], [333, 900, 372, 992, 0.6474609375], [332, 900, 371, 992, 0.6474609375], [332, 900, 371, 992, 0.64501953125], [332, 900, 371, 992, 0.64599609375], [332, 900, 371, 992, 0.64599609375], [332, 900, 371, 992, 0.64599609375], [332, 900, 371, 992, 0.64599609375], [332, 900, 371, 992, 0.64453125], [332, 902, 371, 992, 0.6484375], [332, 902, 371, 992, 0.65087890625], [332, 902, 371, 992, 0.658203125], [332, 902, 370, 993, 0.65966796875], [331, 902, 370, 993, 0.6630859375], [331, 903, 369, 993, 0.6630859375], [330, 903, 368, 993, 0.6650390625], [323, 898, 370, 999, 0.65234375]]\n",
      "Key: 7s, vector len: 15, Card Detections: [[325, 899, 364, 985, 0.61572265625], [325, 899, 364, 986, 0.615234375], [325, 899, 364, 986, 0.61474609375], [325, 899, 364, 987, 0.61474609375], [326, 900, 364, 987, 0.615234375], [325, 900, 364, 987, 0.6142578125], [325, 901, 364, 987, 0.61474609375], [325, 901, 364, 987, 0.6162109375], [325, 902, 364, 988, 0.6171875], [324, 902, 363, 988, 0.619140625], [324, 901, 363, 989, 0.62744140625], [324, 900, 363, 989, 0.6201171875], [323, 901, 363, 989, 0.6201171875], [323, 902, 363, 990, 0.61865234375], [320, 904, 362, 991, 0.5810546875]]\n",
      "Key: 8c, vector len: 10, Card Detections: [[327, 901, 367, 987, 0.6337890625], [327, 901, 367, 987, 0.625], [327, 901, 366, 986, 0.62744140625], [326, 901, 367, 987, 0.62890625], [327, 901, 367, 988, 0.63720703125], [326, 901, 367, 989, 0.63916015625], [326, 901, 366, 988, 0.63427734375], [326, 901, 367, 988, 0.6376953125], [325, 901, 366, 988, 0.64794921875], [325, 903, 366, 988, 0.64013671875]]\n",
      "Key: 8d, vector len: 22, Card Detections: [[40, 856, 87, 972, 0.67578125], [40, 855, 81, 949, 0.70703125], [40, 856, 81, 948, 0.70361328125], [40, 856, 81, 949, 0.70654296875], [39, 858, 81, 950, 0.70166015625], [39, 858, 80, 950, 0.69677734375], [39, 858, 81, 950, 0.6962890625], [39, 858, 81, 951, 0.697265625], [39, 858, 81, 951, 0.697265625], [39, 859, 80, 951, 0.69677734375], [39, 860, 81, 952, 0.69384765625], [39, 860, 80, 953, 0.6904296875], [39, 860, 80, 953, 0.69140625], [39, 860, 80, 953, 0.69091796875], [39, 861, 80, 953, 0.6875], [39, 861, 80, 954, 0.68359375], [39, 861, 80, 954, 0.68212890625], [39, 861, 80, 954, 0.68310546875], [39, 862, 80, 954, 0.68359375], [39, 863, 80, 954, 0.685546875], [39, 863, 80, 955, 0.68212890625], [41, 867, 84, 960, 0.7021484375]]\n",
      "Key: 8h, vector len: 13, Card Detections: [[44, 857, 88, 951, 0.70166015625], [46, 858, 87, 950, 0.724609375], [46, 858, 87, 949, 0.71484375], [46, 859, 87, 950, 0.71533203125], [46, 859, 87, 950, 0.7158203125], [46, 859, 87, 950, 0.716796875], [46, 859, 88, 950, 0.71337890625], [46, 859, 88, 950, 0.7138671875], [46, 860, 87, 951, 0.71533203125], [46, 860, 87, 951, 0.71044921875], [46, 861, 88, 951, 0.7060546875], [47, 862, 88, 952, 0.701171875], [48, 865, 89, 954, 0.685546875]]\n",
      "Key: 8s, vector len: 11, Card Detections: [[42, 861, 88, 983, 0.6455078125], [44, 861, 86, 958, 0.662109375], [45, 862, 86, 957, 0.6748046875], [45, 862, 86, 957, 0.6796875], [45, 861, 86, 957, 0.67236328125], [45, 861, 86, 957, 0.66796875], [45, 860, 87, 957, 0.662109375], [45, 860, 87, 956, 0.66015625], [46, 860, 87, 956, 0.6640625], [46, 861, 87, 957, 0.66748046875], [46, 863, 89, 959, 0.6787109375]]\n",
      "Key: 9c, vector len: 19, Card Detections: [[322, 904, 365, 986, 0.59619140625], [322, 904, 365, 987, 0.59912109375], [322, 904, 365, 988, 0.609375], [323, 904, 365, 989, 0.63720703125], [323, 904, 365, 989, 0.63671875], [323, 904, 365, 988, 0.63232421875], [323, 904, 365, 986, 0.6181640625], [323, 904, 365, 987, 0.626953125], [323, 904, 365, 987, 0.6318359375], [323, 903, 365, 988, 0.63525390625], [323, 903, 365, 988, 0.630859375], [323, 904, 365, 989, 0.638671875], [323, 904, 365, 989, 0.64306640625], [323, 904, 365, 989, 0.64208984375], [323, 904, 365, 989, 0.638671875], [323, 904, 364, 989, 0.64501953125], [323, 905, 364, 988, 0.6337890625], [322, 905, 364, 988, 0.64208984375], [321, 909, 362, 989, 0.63232421875]]\n",
      "Key: 9d, vector len: 20, Card Detections: [[314, 989, 360, 1035, 0.53125], [314, 989, 360, 1034, 0.56787109375], [314, 987, 360, 1034, 0.5634765625], [314, 980, 362, 1031, 0.50537109375], [314, 979, 363, 1030, 0.56298828125], [47, 876, 90, 970, 0.65771484375], [48, 876, 89, 968, 0.65283203125], [48, 876, 89, 967, 0.6552734375], [48, 876, 89, 967, 0.65478515625], [48, 876, 89, 968, 0.65625], [48, 876, 89, 968, 0.65771484375], [48, 876, 89, 968, 0.65625], [48, 876, 89, 968, 0.65625], [48, 876, 89, 968, 0.6552734375], [48, 876, 89, 968, 0.66064453125], [48, 877, 89, 968, 0.6591796875], [49, 877, 89, 968, 0.6591796875], [49, 877, 89, 968, 0.66064453125], [49, 877, 90, 968, 0.66455078125], [49, 880, 91, 969, 0.662109375]]\n",
      "Key: 9h, vector len: 26, Card Detections: [[325, 898, 367, 991, 0.57470703125], [327, 899, 366, 986, 0.6474609375], [327, 899, 366, 986, 0.646484375], [327, 899, 366, 986, 0.646484375], [327, 900, 366, 987, 0.6396484375], [327, 900, 366, 987, 0.64208984375], [327, 899, 366, 986, 0.64501953125], [327, 899, 366, 986, 0.6455078125], [326, 901, 365, 988, 0.64111328125], [326, 901, 365, 988, 0.642578125], [326, 901, 365, 988, 0.642578125], [326, 901, 365, 988, 0.64404296875], [326, 901, 365, 988, 0.64404296875], [326, 901, 365, 988, 0.64453125], [326, 901, 365, 988, 0.6435546875], [326, 901, 365, 988, 0.6435546875], [326, 902, 365, 989, 0.64111328125], [326, 902, 365, 989, 0.63916015625], [326, 901, 365, 988, 0.64501953125], [326, 901, 365, 988, 0.64306640625], [325, 903, 364, 989, 0.6435546875], [325, 903, 364, 990, 0.64404296875], [325, 903, 364, 989, 0.650390625], [325, 903, 364, 989, 0.64990234375], [325, 903, 364, 989, 0.65234375], [323, 906, 363, 991, 0.64599609375]]\n",
      "Key: 9s, vector len: 21, Card Detections: [[47, 892, 93, 991, 0.6123046875], [48, 890, 91, 983, 0.68017578125], [48, 891, 91, 982, 0.67041015625], [48, 890, 91, 983, 0.6591796875], [48, 890, 91, 982, 0.65673828125], [49, 889, 91, 982, 0.66064453125], [49, 889, 91, 982, 0.65966796875], [49, 889, 91, 982, 0.6611328125], [49, 888, 91, 981, 0.6484375], [49, 888, 92, 979, 0.6435546875], [49, 888, 92, 979, 0.65234375], [49, 889, 92, 980, 0.65625], [49, 889, 92, 980, 0.65185546875], [49, 888, 92, 980, 0.65576171875], [49, 888, 92, 981, 0.65625], [49, 888, 92, 981, 0.6591796875], [49, 889, 92, 980, 0.64306640625], [49, 888, 92, 980, 0.6533203125], [49, 889, 92, 980, 0.654296875], [49, 889, 92, 980, 0.65087890625], [50, 892, 93, 982, 0.64306640625]]\n",
      "Key: Ac, vector len: 17, Card Detections: [[326, 900, 368, 987, 0.6513671875], [326, 900, 368, 986, 0.65234375], [326, 900, 367, 986, 0.65283203125], [326, 900, 368, 987, 0.65234375], [326, 900, 367, 987, 0.65234375], [326, 900, 367, 987, 0.65234375], [326, 900, 367, 987, 0.6533203125], [326, 900, 367, 987, 0.65234375], [326, 899, 368, 987, 0.6513671875], [326, 900, 368, 988, 0.64599609375], [326, 900, 368, 987, 0.64697265625], [327, 900, 368, 987, 0.6494140625], [327, 901, 367, 987, 0.6416015625], [326, 902, 367, 988, 0.6474609375], [326, 902, 367, 988, 0.6494140625], [326, 901, 367, 989, 0.65087890625], [325, 903, 366, 989, 0.64697265625]]\n",
      "Key: Ad, vector len: 35, Card Detections: [[46, 963, 84, 1025, 0.50732421875], [336, 901, 376, 992, 0.62451171875], [335, 901, 376, 992, 0.6220703125], [336, 902, 376, 992, 0.62451171875], [335, 903, 375, 992, 0.630859375], [335, 903, 375, 992, 0.619140625], [335, 902, 375, 993, 0.6103515625], [335, 902, 375, 993, 0.609375], [335, 903, 375, 993, 0.62109375], [335, 903, 375, 993, 0.6279296875], [335, 903, 375, 993, 0.62548828125], [335, 903, 375, 993, 0.62353515625], [335, 903, 375, 993, 0.625], [335, 903, 375, 993, 0.6279296875], [335, 903, 375, 993, 0.62255859375], [335, 903, 375, 992, 0.62158203125], [335, 903, 375, 993, 0.6240234375], [335, 903, 374, 993, 0.62939453125], [335, 903, 374, 993, 0.62744140625], [335, 903, 374, 993, 0.6279296875], [335, 903, 374, 993, 0.63330078125], [335, 903, 374, 993, 0.63623046875], [335, 903, 374, 993, 0.63720703125], [335, 904, 374, 993, 0.63720703125], [335, 904, 374, 994, 0.63818359375], [334, 904, 374, 994, 0.63818359375], [334, 904, 374, 994, 0.638671875], [334, 904, 374, 994, 0.640625], [334, 905, 374, 994, 0.63623046875], [334, 905, 374, 994, 0.63623046875], [334, 906, 374, 994, 0.6357421875], [334, 906, 373, 994, 0.63671875], [334, 906, 373, 994, 0.63525390625], [333, 907, 373, 994, 0.63525390625], [333, 908, 372, 994, 0.626953125]]\n",
      "Key: Ah, vector len: 277, Card Detections: [[46, 979, 81, 1032, 0.54345703125], [47, 961, 84, 1024, 0.52392578125], [48, 958, 84, 1023, 0.5126953125], [48, 956, 85, 1023, 0.54296875], [48, 955, 86, 1022, 0.552734375], [49, 954, 86, 1022, 0.54638671875], [49, 954, 86, 1022, 0.55419921875], [48, 954, 85, 1022, 0.564453125], [49, 953, 86, 1021, 0.529296875], [49, 951, 86, 1021, 0.55029296875], [49, 951, 86, 1020, 0.56396484375], [50, 950, 86, 1020, 0.54833984375], [50, 950, 86, 1020, 0.57275390625], [49, 949, 87, 1019, 0.56640625], [49, 948, 87, 1019, 0.57861328125], [49, 947, 87, 1017, 0.6513671875], [49, 946, 87, 1017, 0.65380859375], [49, 945, 87, 1016, 0.6572265625], [49, 945, 87, 1016, 0.658203125], [49, 945, 87, 1016, 0.66015625], [49, 944, 87, 1016, 0.66064453125], [49, 943, 87, 1016, 0.66162109375], [49, 943, 87, 1016, 0.66357421875], [49, 942, 87, 1015, 0.662109375], [50, 941, 87, 1014, 0.65966796875], [50, 941, 87, 1014, 0.66015625], [50, 941, 86, 1014, 0.66162109375], [50, 940, 86, 1013, 0.66015625], [50, 940, 86, 1013, 0.65478515625], [50, 939, 86, 1012, 0.65576171875], [50, 939, 86, 1012, 0.64990234375], [50, 939, 86, 1012, 0.650390625], [50, 938, 87, 1012, 0.6513671875], [50, 937, 87, 1012, 0.65185546875], [50, 936, 87, 1011, 0.65283203125], [50, 936, 87, 1010, 0.65380859375], [49, 935, 87, 1010, 0.65380859375], [50, 935, 87, 1010, 0.65771484375], [50, 934, 87, 1010, 0.65380859375], [50, 934, 87, 1009, 0.658203125], [50, 934, 87, 1009, 0.66015625], [50, 933, 88, 1009, 0.6591796875], [50, 932, 88, 1009, 0.65966796875], [50, 932, 88, 1008, 0.65673828125], [50, 931, 89, 1007, 0.646484375], [50, 931, 89, 1007, 0.6474609375], [50, 931, 89, 1007, 0.64794921875], [50, 930, 89, 1007, 0.640625], [51, 929, 90, 1007, 0.63916015625], [51, 929, 89, 1006, 0.6455078125], [51, 928, 90, 1006, 0.6474609375], [51, 927, 90, 1006, 0.64794921875], [51, 927, 90, 1006, 0.64892578125], [51, 926, 90, 1006, 0.65185546875], [51, 926, 90, 1005, 0.65283203125], [51, 925, 91, 1005, 0.6513671875], [51, 924, 91, 1004, 0.64990234375], [51, 924, 91, 1004, 0.650390625], [51, 923, 91, 1003, 0.64892578125], [51, 923, 91, 1003, 0.6484375], [51, 923, 91, 1003, 0.6494140625], [51, 922, 91, 1002, 0.65283203125], [51, 922, 91, 1002, 0.6513671875], [51, 922, 91, 1002, 0.65234375], [51, 921, 91, 1001, 0.6513671875], [51, 921, 91, 1002, 0.64990234375], [51, 920, 91, 1001, 0.6513671875], [51, 920, 91, 1001, 0.650390625], [51, 919, 91, 1001, 0.6484375], [51, 918, 91, 1000, 0.642578125], [52, 918, 91, 1000, 0.6416015625], [52, 918, 91, 1000, 0.6435546875], [52, 918, 91, 999, 0.64404296875], [51, 917, 91, 998, 0.630859375], [51, 916, 91, 998, 0.62109375], [51, 916, 91, 998, 0.6171875], [51, 916, 91, 998, 0.611328125], [51, 916, 91, 998, 0.607421875], [51, 916, 91, 998, 0.59423828125], [51, 915, 91, 998, 0.60400390625], [51, 915, 91, 997, 0.61083984375], [51, 914, 91, 997, 0.60400390625], [51, 914, 91, 997, 0.6123046875], [51, 914, 91, 997, 0.61572265625], [51, 914, 91, 997, 0.60888671875], [51, 914, 91, 997, 0.6083984375], [51, 914, 91, 997, 0.61181640625], [51, 914, 91, 996, 0.6259765625], [51, 913, 91, 996, 0.6279296875], [51, 913, 91, 996, 0.62890625], [51, 913, 91, 996, 0.62890625], [51, 913, 91, 996, 0.62890625], [51, 912, 91, 996, 0.6298828125], [51, 912, 91, 996, 0.62939453125], [51, 912, 91, 995, 0.62939453125], [51, 910, 92, 995, 0.63623046875], [51, 910, 92, 995, 0.634765625], [51, 910, 92, 994, 0.634765625], [51, 910, 92, 994, 0.6328125], [51, 910, 92, 994, 0.6337890625], [51, 910, 92, 994, 0.63525390625], [51, 909, 92, 994, 0.6357421875], [51, 909, 92, 994, 0.638671875], [51, 909, 92, 993, 0.640625], [51, 909, 92, 994, 0.640625], [51, 909, 92, 993, 0.64208984375], [51, 908, 92, 993, 0.64208984375], [51, 908, 92, 993, 0.642578125], [51, 908, 92, 993, 0.6435546875], [51, 908, 92, 993, 0.64599609375], [51, 908, 92, 993, 0.646484375], [51, 908, 92, 993, 0.64697265625], [51, 908, 92, 993, 0.6474609375], [51, 908, 92, 993, 0.64794921875], [51, 908, 92, 993, 0.64794921875], [51, 907, 92, 993, 0.6484375], [51, 907, 92, 993, 0.6494140625], [51, 907, 92, 993, 0.64990234375], [51, 907, 92, 993, 0.6484375], [51, 907, 92, 993, 0.64794921875], [51, 907, 92, 993, 0.6474609375], [51, 907, 92, 992, 0.64892578125], [51, 907, 92, 992, 0.6484375], [51, 907, 92, 992, 0.6474609375], [51, 906, 91, 992, 0.6484375], [51, 906, 92, 992, 0.6494140625], [51, 905, 92, 992, 0.64892578125], [51, 906, 91, 992, 0.64697265625], [50, 906, 91, 993, 0.6474609375], [50, 906, 91, 993, 0.64599609375], [50, 906, 91, 993, 0.6455078125], [50, 906, 91, 992, 0.6455078125], [50, 906, 91, 992, 0.6474609375], [50, 906, 91, 992, 0.64599609375], [50, 906, 91, 992, 0.64599609375], [50, 906, 91, 993, 0.64501953125], [50, 906, 91, 993, 0.6455078125], [50, 906, 91, 993, 0.64599609375], [50, 906, 91, 992, 0.6455078125], [50, 906, 91, 992, 0.6455078125], [50, 905, 91, 992, 0.6455078125], [50, 905, 91, 992, 0.64599609375], [50, 905, 91, 992, 0.6455078125], [50, 905, 91, 993, 0.64599609375], [50, 905, 91, 993, 0.646484375], [50, 905, 91, 992, 0.64599609375], [50, 906, 91, 992, 0.646484375], [51, 905, 91, 992, 0.64697265625], [51, 905, 91, 992, 0.64599609375], [51, 905, 91, 992, 0.6455078125], [51, 905, 91, 991, 0.64501953125], [51, 905, 91, 991, 0.646484375], [51, 905, 91, 991, 0.64599609375], [51, 905, 91, 992, 0.6474609375], [51, 905, 91, 992, 0.6474609375], [51, 905, 91, 992, 0.646484375], [51, 905, 91, 991, 0.646484375], [51, 905, 91, 991, 0.64697265625], [51, 905, 91, 991, 0.64794921875], [51, 905, 91, 991, 0.6484375], [51, 905, 91, 991, 0.64794921875], [51, 904, 91, 991, 0.6474609375], [51, 904, 92, 991, 0.6484375], [51, 904, 92, 991, 0.64892578125], [51, 904, 92, 991, 0.6494140625], [51, 904, 92, 991, 0.64892578125], [51, 904, 92, 991, 0.64794921875], [51, 904, 91, 991, 0.64794921875], [51, 904, 91, 991, 0.64697265625], [51, 904, 91, 991, 0.64599609375], [50, 904, 91, 991, 0.64599609375], [50, 904, 91, 991, 0.64599609375], [51, 904, 91, 991, 0.6455078125], [50, 904, 91, 991, 0.646484375], [50, 903, 91, 991, 0.646484375], [50, 903, 91, 991, 0.64697265625], [50, 903, 91, 991, 0.646484375], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 991, 0.64599609375], [50, 904, 91, 991, 0.64697265625], [50, 904, 91, 991, 0.64501953125], [50, 904, 91, 991, 0.64697265625], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 991, 0.64697265625], [50, 904, 91, 991, 0.64697265625], [50, 903, 91, 991, 0.64697265625], [50, 903, 91, 991, 0.64794921875], [50, 903, 91, 991, 0.64794921875], [50, 903, 91, 991, 0.6484375], [51, 903, 92, 991, 0.6484375], [51, 903, 92, 990, 0.6484375], [51, 903, 92, 991, 0.6474609375], [51, 903, 92, 991, 0.64794921875], [51, 903, 92, 991, 0.6474609375], [51, 903, 93, 991, 0.6455078125], [52, 903, 93, 990, 0.64453125], [52, 903, 93, 990, 0.6455078125], [52, 903, 93, 990, 0.6455078125], [52, 903, 93, 990, 0.64599609375], [52, 903, 93, 990, 0.64697265625], [52, 903, 93, 990, 0.64794921875], [53, 903, 93, 990, 0.64794921875], [52, 903, 93, 989, 0.64794921875], [53, 903, 93, 990, 0.64892578125], [53, 903, 93, 990, 0.64892578125], [53, 903, 93, 989, 0.64794921875], [53, 903, 93, 990, 0.6474609375], [53, 902, 93, 990, 0.6474609375], [53, 902, 93, 989, 0.646484375], [53, 902, 93, 990, 0.6455078125], [53, 902, 93, 990, 0.6455078125], [53, 902, 93, 989, 0.64501953125], [53, 902, 93, 989, 0.64501953125], [53, 902, 93, 990, 0.64453125], [53, 902, 93, 989, 0.64453125], [52, 902, 93, 990, 0.64404296875], [52, 902, 93, 990, 0.64404296875], [52, 902, 93, 990, 0.642578125], [52, 902, 93, 990, 0.640625], [52, 902, 93, 990, 0.63818359375], [52, 902, 93, 990, 0.63916015625], [52, 902, 92, 990, 0.64453125], [51, 902, 92, 990, 0.64697265625], [51, 902, 92, 990, 0.646484375], [51, 902, 92, 990, 0.64697265625], [51, 902, 92, 990, 0.6494140625], [51, 902, 92, 990, 0.64990234375], [51, 903, 92, 991, 0.64892578125], [51, 902, 92, 991, 0.6484375], [51, 903, 92, 991, 0.6484375], [51, 903, 92, 991, 0.6494140625], [51, 903, 92, 991, 0.64990234375], [51, 903, 92, 991, 0.6494140625], [51, 903, 92, 991, 0.6484375], [51, 903, 92, 991, 0.6474609375], [51, 903, 92, 991, 0.6494140625], [51, 903, 92, 991, 0.6494140625], [51, 903, 92, 991, 0.64697265625], [51, 903, 92, 990, 0.64794921875], [51, 903, 92, 990, 0.64794921875], [51, 903, 92, 991, 0.64697265625], [51, 903, 93, 991, 0.64697265625], [51, 903, 93, 990, 0.646484375], [51, 903, 93, 990, 0.6455078125], [51, 903, 93, 990, 0.64453125], [51, 903, 93, 990, 0.642578125], [51, 903, 93, 990, 0.64013671875], [51, 903, 93, 991, 0.64013671875], [51, 903, 93, 990, 0.64111328125], [52, 902, 93, 990, 0.64404296875], [51, 903, 93, 990, 0.642578125], [51, 903, 93, 990, 0.642578125], [51, 903, 93, 990, 0.6474609375], [51, 902, 93, 989, 0.6494140625], [51, 902, 93, 989, 0.6484375], [51, 902, 93, 990, 0.6484375], [51, 902, 93, 990, 0.650390625], [51, 902, 92, 990, 0.6484375], [51, 902, 92, 990, 0.6484375], [51, 902, 92, 990, 0.6474609375], [51, 902, 92, 990, 0.64794921875], [51, 902, 92, 990, 0.64697265625], [51, 902, 92, 990, 0.646484375], [51, 902, 92, 990, 0.64892578125], [51, 902, 92, 990, 0.64892578125], [51, 902, 92, 989, 0.65087890625], [51, 902, 92, 989, 0.6513671875], [51, 902, 92, 990, 0.65087890625], [51, 902, 92, 990, 0.64990234375], [51, 902, 92, 990, 0.6494140625], [51, 902, 92, 990, 0.6494140625], [51, 902, 92, 990, 0.6494140625], [51, 902, 92, 990, 0.6494140625], [51, 902, 92, 990, 0.6484375], [52, 908, 92, 990, 0.64501953125]]\n",
      "Key: As, vector len: 14, Card Detections: [[327, 900, 369, 986, 0.68603515625], [327, 900, 369, 986, 0.6923828125], [327, 900, 368, 986, 0.69189453125], [327, 900, 368, 986, 0.69482421875], [327, 900, 368, 986, 0.6943359375], [327, 901, 368, 987, 0.68408203125], [327, 901, 368, 987, 0.6875], [327, 901, 368, 987, 0.6865234375], [327, 901, 368, 987, 0.68603515625], [326, 902, 368, 987, 0.68115234375], [326, 902, 368, 987, 0.6826171875], [326, 903, 367, 988, 0.6806640625], [325, 903, 367, 988, 0.6884765625], [323, 906, 366, 989, 0.671875]]\n",
      "Key: Jc, vector len: 13, Card Detections: [[325, 898, 364, 981, 0.673828125], [325, 898, 364, 984, 0.65673828125], [325, 898, 364, 984, 0.6572265625], [325, 898, 364, 984, 0.658203125], [325, 899, 364, 984, 0.66552734375], [325, 898, 364, 984, 0.66455078125], [325, 898, 364, 984, 0.662109375], [324, 898, 363, 984, 0.671875], [325, 899, 363, 985, 0.658203125], [324, 899, 363, 985, 0.6533203125], [324, 899, 363, 985, 0.65966796875], [324, 900, 363, 985, 0.65234375], [321, 900, 362, 988, 0.61279296875]]\n",
      "Key: Jd, vector len: 52, Card Detections: [[331, 897, 372, 984, 0.6337890625], [334, 898, 371, 988, 0.6396484375], [334, 898, 371, 988, 0.6376953125], [334, 899, 371, 989, 0.638671875], [334, 899, 371, 990, 0.63623046875], [334, 899, 371, 990, 0.6337890625], [334, 899, 371, 989, 0.638671875], [334, 899, 371, 989, 0.63525390625], [334, 900, 371, 990, 0.62548828125], [334, 899, 371, 990, 0.62548828125], [333, 899, 371, 990, 0.62646484375], [334, 899, 371, 990, 0.6259765625], [333, 899, 371, 990, 0.61962890625], [333, 899, 371, 990, 0.62158203125], [333, 899, 371, 990, 0.619140625], [333, 899, 371, 990, 0.62060546875], [333, 899, 371, 990, 0.6201171875], [333, 899, 371, 990, 0.6171875], [333, 900, 371, 991, 0.615234375], [333, 900, 371, 990, 0.61083984375], [333, 900, 371, 990, 0.60986328125], [333, 900, 371, 990, 0.6103515625], [333, 900, 371, 990, 0.60986328125], [333, 900, 371, 990, 0.6123046875], [333, 900, 371, 990, 0.6123046875], [333, 900, 371, 991, 0.60302734375], [333, 900, 371, 991, 0.60107421875], [333, 900, 371, 991, 0.60107421875], [333, 900, 371, 991, 0.60009765625], [333, 900, 371, 991, 0.6005859375], [333, 900, 371, 991, 0.6005859375], [333, 899, 371, 991, 0.607421875], [333, 900, 371, 991, 0.603515625], [333, 900, 371, 991, 0.59912109375], [333, 899, 371, 991, 0.6005859375], [333, 900, 371, 990, 0.60302734375], [333, 901, 370, 991, 0.59619140625], [333, 901, 370, 991, 0.59521484375], [333, 901, 370, 991, 0.59619140625], [333, 901, 370, 991, 0.59619140625], [333, 901, 370, 991, 0.59423828125], [333, 901, 370, 991, 0.59619140625], [333, 901, 370, 992, 0.5947265625], [333, 901, 370, 992, 0.59423828125], [333, 901, 370, 992, 0.591796875], [333, 901, 370, 992, 0.59228515625], [332, 902, 370, 992, 0.59765625], [332, 902, 370, 992, 0.59765625], [332, 902, 370, 991, 0.59765625], [332, 902, 370, 991, 0.59912109375], [332, 902, 370, 991, 0.59814453125], [332, 904, 368, 991, 0.6083984375]]\n",
      "Key: Jh, vector len: 79, Card Detections: [[29, 895, 71, 960, 0.6083984375], [29, 897, 69, 979, 0.61962890625], [29, 897, 69, 980, 0.619140625], [29, 898, 69, 981, 0.6171875], [29, 899, 69, 982, 0.6201171875], [29, 900, 68, 982, 0.6220703125], [28, 900, 69, 982, 0.6220703125], [28, 899, 68, 982, 0.619140625], [28, 899, 68, 982, 0.6181640625], [28, 900, 68, 983, 0.62060546875], [28, 900, 68, 983, 0.6181640625], [28, 899, 69, 983, 0.61767578125], [28, 900, 68, 982, 0.61669921875], [28, 900, 69, 982, 0.6171875], [28, 899, 69, 982, 0.619140625], [28, 899, 69, 981, 0.61474609375], [28, 899, 69, 981, 0.61181640625], [28, 898, 69, 981, 0.6123046875], [28, 897, 69, 980, 0.615234375], [28, 897, 69, 980, 0.6181640625], [28, 897, 69, 980, 0.6171875], [28, 897, 69, 980, 0.61962890625], [28, 896, 69, 980, 0.62109375], [28, 896, 69, 980, 0.62109375], [29, 896, 69, 979, 0.61767578125], [29, 896, 69, 979, 0.6162109375], [29, 896, 69, 979, 0.61572265625], [29, 896, 69, 979, 0.6162109375], [29, 896, 69, 979, 0.61669921875], [29, 896, 69, 979, 0.6171875], [29, 896, 69, 979, 0.61767578125], [29, 896, 69, 979, 0.6171875], [29, 897, 69, 979, 0.61669921875], [29, 897, 69, 980, 0.61669921875], [29, 897, 69, 980, 0.61572265625], [29, 897, 70, 979, 0.61669921875], [29, 897, 70, 979, 0.615234375], [29, 897, 70, 980, 0.615234375], [29, 897, 70, 979, 0.615234375], [29, 897, 70, 979, 0.615234375], [29, 897, 70, 979, 0.61328125], [29, 897, 70, 979, 0.61376953125], [29, 897, 70, 980, 0.6123046875], [29, 897, 70, 980, 0.611328125], [30, 897, 70, 980, 0.61376953125], [30, 897, 70, 980, 0.615234375], [29, 897, 70, 980, 0.6103515625], [29, 897, 70, 980, 0.61083984375], [29, 897, 70, 979, 0.6083984375], [29, 897, 71, 979, 0.60791015625], [29, 896, 71, 979, 0.60400390625], [30, 895, 71, 977, 0.62060546875], [30, 895, 71, 977, 0.62646484375], [30, 895, 71, 977, 0.626953125], [30, 896, 71, 976, 0.62744140625], [30, 896, 71, 976, 0.62548828125], [30, 896, 71, 977, 0.62548828125], [30, 896, 71, 976, 0.6279296875], [30, 895, 72, 976, 0.62646484375], [30, 895, 72, 976, 0.626953125], [31, 895, 72, 976, 0.626953125], [31, 894, 72, 976, 0.62890625], [31, 894, 72, 976, 0.6337890625], [31, 894, 72, 976, 0.63427734375], [31, 894, 73, 976, 0.63623046875], [31, 894, 73, 976, 0.634765625], [31, 893, 73, 976, 0.63232421875], [31, 893, 73, 976, 0.630859375], [31, 893, 73, 976, 0.630859375], [31, 893, 73, 976, 0.63134765625], [31, 893, 73, 976, 0.62939453125], [31, 893, 73, 976, 0.62890625], [31, 893, 73, 976, 0.62890625], [31, 893, 73, 976, 0.62841796875], [32, 893, 73, 975, 0.63037109375], [31, 893, 74, 975, 0.62939453125], [32, 893, 74, 975, 0.62939453125], [32, 893, 75, 975, 0.6259765625], [33, 893, 75, 973, 0.63232421875]]\n",
      "Key: Js, vector len: 21, Card Detections: [[327, 903, 365, 966, 0.5751953125], [328, 905, 366, 993, 0.6689453125], [328, 905, 366, 993, 0.66943359375], [328, 905, 366, 993, 0.6630859375], [328, 904, 366, 993, 0.66796875], [328, 904, 366, 992, 0.6650390625], [328, 904, 366, 992, 0.6630859375], [328, 904, 366, 993, 0.66650390625], [328, 905, 366, 994, 0.67138671875], [328, 905, 366, 994, 0.66796875], [328, 905, 366, 994, 0.65185546875], [327, 904, 366, 994, 0.6669921875], [327, 904, 366, 994, 0.662109375], [327, 904, 366, 994, 0.66650390625], [327, 905, 366, 994, 0.6650390625], [327, 905, 366, 994, 0.6650390625], [327, 904, 366, 994, 0.66259765625], [327, 905, 366, 994, 0.6650390625], [327, 905, 366, 994, 0.66552734375], [327, 905, 365, 995, 0.6689453125], [327, 906, 365, 996, 0.6767578125]]\n",
      "Key: Kc, vector len: 14, Card Detections: [[325, 896, 366, 982, 0.70361328125], [325, 895, 365, 982, 0.68701171875], [325, 896, 365, 982, 0.6865234375], [325, 897, 365, 983, 0.69091796875], [325, 896, 365, 983, 0.68701171875], [325, 896, 365, 984, 0.68505859375], [325, 896, 365, 983, 0.6884765625], [325, 896, 365, 984, 0.68505859375], [325, 897, 365, 984, 0.68359375], [325, 897, 365, 984, 0.6767578125], [324, 897, 365, 984, 0.6708984375], [324, 898, 365, 984, 0.66650390625], [323, 899, 365, 984, 0.6689453125], [321, 900, 364, 986, 0.68701171875]]\n",
      "Key: Kd, vector len: 20, Card Detections: [[326, 899, 363, 968, 0.61376953125], [326, 900, 364, 988, 0.6416015625], [325, 899, 365, 988, 0.642578125], [326, 899, 364, 988, 0.64453125], [325, 900, 364, 989, 0.6474609375], [325, 900, 364, 989, 0.64501953125], [324, 901, 364, 989, 0.64501953125], [324, 901, 364, 989, 0.646484375], [324, 901, 364, 990, 0.6474609375], [324, 902, 364, 991, 0.6494140625], [324, 902, 364, 990, 0.65673828125], [324, 901, 364, 990, 0.650390625], [324, 901, 364, 989, 0.65234375], [324, 902, 364, 990, 0.66357421875], [324, 902, 364, 991, 0.66064453125], [323, 903, 364, 991, 0.66357421875], [323, 903, 364, 992, 0.66650390625], [323, 903, 364, 992, 0.66748046875], [323, 903, 363, 992, 0.66748046875], [321, 905, 363, 994, 0.65576171875]]\n",
      "Key: Kh, vector len: 17, Card Detections: [[42, 853, 85, 950, 0.623046875], [43, 853, 84, 949, 0.61083984375], [43, 853, 84, 949, 0.60888671875], [43, 853, 84, 949, 0.60888671875], [43, 853, 84, 949, 0.61279296875], [43, 853, 83, 949, 0.61083984375], [43, 853, 83, 949, 0.61083984375], [43, 853, 83, 949, 0.6103515625], [43, 853, 83, 948, 0.615234375], [43, 854, 83, 948, 0.61328125], [43, 854, 83, 949, 0.6171875], [43, 854, 83, 949, 0.61572265625], [43, 854, 83, 949, 0.61865234375], [43, 854, 83, 949, 0.6181640625], [42, 856, 83, 950, 0.61767578125], [42, 855, 83, 952, 0.63037109375], [44, 859, 85, 954, 0.625]]\n",
      "Key: Ks, vector len: 17, Card Detections: [[325, 894, 366, 979, 0.6103515625], [326, 894, 367, 986, 0.68408203125], [326, 894, 367, 986, 0.6875], [326, 894, 367, 985, 0.68359375], [326, 895, 367, 986, 0.6826171875], [325, 895, 367, 987, 0.68310546875], [326, 895, 367, 987, 0.68212890625], [326, 895, 367, 987, 0.681640625], [326, 895, 367, 987, 0.68212890625], [326, 895, 366, 986, 0.6826171875], [325, 896, 366, 987, 0.67138671875], [325, 896, 366, 987, 0.66650390625], [325, 896, 366, 987, 0.68017578125], [325, 896, 366, 987, 0.68212890625], [324, 897, 365, 987, 0.67431640625], [324, 898, 364, 987, 0.669921875], [321, 899, 364, 989, 0.67041015625]]\n",
      "Key: Qc, vector len: 13, Card Detections: [[49, 883, 91, 977, 0.66650390625], [49, 883, 91, 977, 0.6298828125], [49, 883, 91, 975, 0.62353515625], [50, 883, 91, 975, 0.62548828125], [49, 883, 92, 976, 0.61865234375], [49, 882, 91, 975, 0.6220703125], [50, 882, 91, 975, 0.625], [50, 882, 92, 974, 0.623046875], [50, 882, 92, 974, 0.62109375], [50, 882, 92, 974, 0.62109375], [50, 882, 92, 975, 0.6298828125], [50, 882, 92, 974, 0.63427734375], [51, 883, 93, 975, 0.6435546875]]\n",
      "Key: Qd, vector len: 7, Card Detections: [[45, 857, 87, 954, 0.6162109375], [45, 858, 87, 953, 0.62255859375], [45, 858, 87, 953, 0.62158203125], [45, 858, 88, 953, 0.6171875], [45, 858, 88, 953, 0.6162109375], [46, 857, 88, 953, 0.6142578125], [48, 861, 91, 961, 0.58935546875]]\n",
      "Key: Qh, vector len: 16, Card Detections: [[46, 857, 87, 951, 0.63671875], [46, 857, 87, 951, 0.62939453125], [46, 857, 87, 952, 0.62353515625], [46, 858, 87, 951, 0.62939453125], [46, 858, 87, 951, 0.6298828125], [46, 858, 87, 952, 0.62890625], [46, 858, 87, 952, 0.62890625], [46, 859, 87, 952, 0.62646484375], [47, 860, 87, 953, 0.62890625], [46, 860, 87, 953, 0.62890625], [46, 860, 88, 953, 0.62841796875], [47, 860, 87, 954, 0.630859375], [47, 861, 88, 954, 0.63525390625], [47, 861, 88, 955, 0.63916015625], [47, 861, 88, 955, 0.6435546875], [47, 862, 89, 955, 0.6416015625]]\n",
      "Key: Qs, vector len: 10, Card Detections: [[326, 897, 367, 998, 0.6494140625], [328, 897, 367, 987, 0.66845703125], [327, 896, 368, 987, 0.6708984375], [327, 897, 367, 987, 0.66650390625], [327, 899, 367, 987, 0.65966796875], [327, 899, 367, 988, 0.6611328125], [327, 899, 367, 989, 0.66064453125], [326, 899, 366, 989, 0.666015625], [325, 900, 366, 988, 0.65087890625], [323, 903, 365, 989, 0.6552734375]]\n",
      "Key: SJoker, vector len: 71, Card Detections: [[326, 910, 369, 1000, 0.58447265625], [325, 910, 370, 1011, 0.6328125], [325, 910, 369, 999, 0.625], [325, 910, 369, 998, 0.6171875], [324, 911, 369, 1001, 0.61376953125], [325, 910, 368, 1001, 0.6044921875], [325, 910, 369, 1001, 0.62451171875], [325, 910, 369, 1001, 0.61962890625], [325, 910, 368, 1001, 0.6123046875], [325, 910, 368, 1001, 0.61181640625], [325, 910, 368, 1001, 0.609375], [325, 910, 368, 1001, 0.6123046875], [325, 910, 368, 1001, 0.61376953125], [325, 910, 368, 1001, 0.61376953125], [325, 910, 368, 1001, 0.61376953125], [325, 910, 368, 1002, 0.61572265625], [325, 910, 368, 1002, 0.6181640625], [325, 910, 368, 1002, 0.61767578125], [325, 910, 368, 1002, 0.61767578125], [325, 910, 368, 1002, 0.615234375], [325, 910, 368, 1002, 0.61376953125], [325, 910, 368, 1002, 0.6162109375], [325, 910, 368, 1002, 0.6171875], [325, 909, 368, 1002, 0.61962890625], [325, 909, 368, 1002, 0.62109375], [324, 910, 368, 1002, 0.6220703125], [324, 909, 368, 1002, 0.62158203125], [324, 910, 368, 1003, 0.62353515625], [324, 910, 368, 1002, 0.62255859375], [324, 910, 368, 1003, 0.6201171875], [324, 910, 368, 1003, 0.6201171875], [324, 910, 367, 1003, 0.62109375], [324, 910, 367, 1003, 0.61962890625], [324, 910, 367, 1003, 0.61962890625], [324, 910, 367, 1003, 0.62158203125], [324, 910, 367, 1003, 0.6201171875], [324, 910, 367, 1003, 0.6201171875], [324, 910, 367, 1003, 0.623046875], [324, 910, 367, 1003, 0.62451171875], [324, 910, 367, 1003, 0.62451171875], [324, 911, 367, 1003, 0.62353515625], [324, 910, 367, 1003, 0.625], [324, 910, 367, 1003, 0.6279296875], [324, 910, 367, 1003, 0.6279296875], [323, 911, 367, 1004, 0.63037109375], [323, 911, 367, 1004, 0.62939453125], [324, 911, 367, 1004, 0.62939453125], [324, 911, 367, 1004, 0.63134765625], [324, 910, 367, 1003, 0.62939453125], [324, 910, 367, 1004, 0.6279296875], [324, 911, 367, 1004, 0.62646484375], [323, 911, 367, 1004, 0.6259765625], [324, 910, 367, 1003, 0.626953125], [324, 911, 367, 1004, 0.626953125], [323, 911, 367, 1004, 0.6318359375], [323, 912, 367, 1004, 0.63232421875], [323, 911, 367, 1004, 0.63232421875], [323, 911, 367, 1004, 0.6328125], [323, 911, 367, 1004, 0.6328125], [323, 912, 367, 1003, 0.63037109375], [323, 912, 367, 1003, 0.6337890625], [323, 912, 367, 1003, 0.63427734375], [323, 912, 366, 1004, 0.63427734375], [322, 912, 366, 1004, 0.63720703125], [322, 913, 366, 1004, 0.63720703125], [322, 913, 366, 1004, 0.6416015625], [322, 913, 365, 1004, 0.6357421875], [322, 914, 365, 1005, 0.63232421875], [321, 915, 364, 1005, 0.630859375], [321, 917, 363, 1004, 0.62890625], [319, 920, 363, 1006, 0.607421875]]\n",
      "Key: BJoker, vector len: 13, Card Detections: [[31, 861, 79, 987, 0.61474609375], [27, 862, 77, 1003, 0.65283203125], [27, 862, 77, 1003, 0.6474609375], [27, 862, 77, 1004, 0.65478515625], [27, 862, 77, 1004, 0.65576171875], [27, 860, 77, 1003, 0.65966796875], [27, 860, 77, 1003, 0.666015625], [26, 860, 77, 1003, 0.66552734375], [27, 861, 77, 1003, 0.66259765625], [27, 861, 76, 1003, 0.65576171875], [27, 861, 76, 1003, 0.658203125], [27, 862, 76, 1003, 0.6552734375], [28, 862, 80, 1003, 0.5830078125]]\n",
      "Key: Tc, vector len: 1, Card Detections: [[370, 816, 399, 879, 0.6396484375]]\n",
      "Key: Td, vector len: 2, Card Detections: [[164, 794, 194, 862, 0.67333984375], [163, 796, 194, 865, 0.677734375]]\n",
      "Key: Th, vector len: 1, Card Detections: [[175, 808, 205, 872, 0.6083984375]]\n",
      "Key: Ts, vector len: 0, Card Detections: []\n",
      "Key: 2c, vector len: 2, Card Detections: [[370, 816, 399, 879, 0.6494140625], [370, 817, 399, 880, 0.6416015625]]\n",
      "Key: 2d, vector len: 2, Card Detections: [[371, 822, 402, 889, 0.58154296875], [373, 821, 402, 886, 0.61767578125]]\n",
      "Key: 2h, vector len: 0, Card Detections: []\n",
      "Key: 2s, vector len: 20, Card Detections: [[158, 802, 190, 869, 0.6748046875], [158, 802, 190, 869, 0.68017578125], [158, 803, 190, 870, 0.67578125], [158, 803, 190, 870, 0.6796875], [158, 804, 190, 870, 0.67822265625], [158, 804, 190, 871, 0.67822265625], [158, 804, 190, 871, 0.67724609375], [158, 805, 190, 871, 0.67138671875], [158, 805, 190, 871, 0.666015625], [158, 805, 190, 871, 0.66455078125], [158, 806, 190, 871, 0.66357421875], [158, 806, 190, 872, 0.6630859375], [158, 806, 190, 872, 0.65966796875], [158, 806, 190, 872, 0.6640625], [158, 806, 190, 872, 0.66064453125], [159, 807, 191, 872, 0.6611328125], [159, 808, 190, 872, 0.65625], [159, 808, 191, 873, 0.66064453125], [159, 809, 190, 873, 0.67041015625], [160, 808, 190, 868, 0.65478515625]]\n",
      "Key: 3c, vector len: 0, Card Detections: []\n",
      "Key: 3d, vector len: 2, Card Detections: [[373, 819, 402, 884, 0.634765625], [374, 818, 402, 884, 0.61865234375]]\n",
      "Key: 3h, vector len: 1, Card Detections: [[175, 797, 206, 865, 0.59765625]]\n",
      "Key: 3s, vector len: 1, Card Detections: [[176, 801, 208, 871, 0.564453125]]\n",
      "Key: 4c, vector len: 143, Card Detections: [[157, 814, 232, 878, 0.60888671875], [158, 813, 231, 875, 0.6611328125], [158, 813, 231, 876, 0.6728515625], [157, 813, 230, 877, 0.6455078125], [158, 813, 230, 877, 0.646484375], [158, 813, 230, 877, 0.65087890625], [158, 814, 230, 877, 0.64990234375], [158, 814, 230, 877, 0.65234375], [158, 814, 230, 877, 0.65283203125], [158, 814, 230, 877, 0.65087890625], [159, 814, 232, 876, 0.66259765625], [159, 814, 232, 876, 0.6640625], [159, 814, 232, 876, 0.66650390625], [158, 813, 230, 877, 0.65576171875], [158, 814, 230, 877, 0.65625], [159, 814, 232, 876, 0.65966796875], [159, 814, 232, 876, 0.66552734375], [159, 814, 232, 876, 0.66650390625], [158, 814, 230, 877, 0.654296875], [158, 814, 230, 877, 0.65380859375], [158, 814, 230, 877, 0.65478515625], [158, 814, 230, 878, 0.65283203125], [158, 814, 230, 877, 0.6533203125], [158, 814, 230, 877, 0.6533203125], [158, 814, 230, 877, 0.65576171875], [158, 814, 230, 877, 0.6533203125], [158, 814, 230, 877, 0.654296875], [158, 814, 230, 877, 0.65478515625], [158, 814, 230, 877, 0.65478515625], [158, 814, 230, 877, 0.65478515625], [158, 814, 230, 877, 0.6533203125], [158, 814, 232, 877, 0.6533203125], [158, 814, 232, 877, 0.65283203125], [158, 814, 232, 877, 0.65380859375], [158, 814, 232, 877, 0.65185546875], [158, 814, 232, 877, 0.6533203125], [158, 814, 232, 877, 0.6533203125], [158, 814, 230, 877, 0.65283203125], [158, 814, 230, 877, 0.65283203125], [158, 814, 230, 877, 0.65478515625], [158, 814, 230, 877, 0.6552734375], [158, 814, 230, 877, 0.65478515625], [158, 814, 230, 877, 0.65478515625], [158, 814, 230, 877, 0.6552734375], [158, 814, 230, 877, 0.6552734375], [158, 814, 230, 877, 0.654296875], [158, 813, 231, 877, 0.6552734375], [159, 813, 231, 877, 0.65576171875], [159, 813, 231, 877, 0.65576171875], [159, 813, 231, 877, 0.65478515625], [159, 813, 231, 877, 0.65478515625], [159, 813, 232, 877, 0.65625], [159, 813, 232, 877, 0.65576171875], [159, 813, 231, 877, 0.6533203125], [159, 813, 231, 877, 0.654296875], [159, 813, 231, 877, 0.65478515625], [159, 813, 233, 877, 0.66015625], [159, 814, 233, 877, 0.658203125], [159, 813, 233, 877, 0.654296875], [159, 813, 233, 876, 0.6640625], [159, 813, 233, 877, 0.66015625], [159, 813, 233, 877, 0.66357421875], [159, 813, 233, 877, 0.6591796875], [159, 813, 233, 877, 0.66162109375], [159, 813, 233, 877, 0.6640625], [160, 813, 233, 877, 0.662109375], [160, 813, 233, 877, 0.66357421875], [159, 814, 233, 876, 0.65087890625], [159, 814, 233, 876, 0.64990234375], [159, 814, 233, 876, 0.64990234375], [159, 814, 233, 876, 0.65087890625], [159, 814, 233, 876, 0.6513671875], [159, 814, 233, 876, 0.6513671875], [159, 814, 233, 876, 0.6513671875], [159, 814, 233, 876, 0.65185546875], [159, 813, 233, 877, 0.6611328125], [159, 813, 233, 877, 0.66015625], [159, 813, 233, 877, 0.65576171875], [160, 813, 233, 877, 0.65869140625], [160, 813, 233, 877, 0.65673828125], [160, 813, 233, 877, 0.65478515625], [160, 813, 233, 877, 0.65576171875], [160, 813, 233, 877, 0.65673828125], [160, 813, 233, 877, 0.65478515625], [160, 813, 233, 877, 0.658203125], [160, 813, 233, 877, 0.658203125], [160, 813, 233, 877, 0.65576171875], [160, 813, 233, 877, 0.6533203125], [159, 813, 233, 876, 0.65234375], [159, 813, 233, 876, 0.65185546875], [159, 813, 233, 876, 0.65185546875], [159, 813, 233, 876, 0.65185546875], [159, 813, 233, 876, 0.6513671875], [159, 813, 233, 876, 0.650390625], [159, 813, 233, 876, 0.65087890625], [159, 813, 233, 876, 0.64990234375], [159, 813, 233, 876, 0.6513671875], [159, 813, 233, 876, 0.6494140625], [159, 813, 233, 876, 0.64892578125], [159, 813, 233, 876, 0.64892578125], [159, 813, 233, 876, 0.64892578125], [159, 813, 234, 876, 0.64990234375], [159, 813, 234, 875, 0.65185546875], [159, 813, 232, 876, 0.66064453125], [159, 813, 232, 876, 0.66455078125], [159, 813, 232, 876, 0.66552734375], [159, 813, 234, 875, 0.66455078125], [159, 813, 234, 875, 0.66552734375], [159, 813, 234, 875, 0.66552734375], [159, 813, 234, 875, 0.666015625], [160, 813, 234, 875, 0.66552734375], [160, 813, 234, 875, 0.666015625], [160, 813, 234, 875, 0.66552734375], [160, 813, 234, 875, 0.666015625], [160, 813, 234, 875, 0.6650390625], [160, 813, 234, 875, 0.66455078125], [160, 814, 234, 875, 0.66552734375], [160, 814, 234, 875, 0.66552734375], [160, 814, 234, 875, 0.66455078125], [160, 814, 234, 875, 0.6650390625], [160, 814, 234, 875, 0.6650390625], [160, 814, 234, 875, 0.66455078125], [160, 814, 234, 875, 0.66455078125], [160, 814, 234, 875, 0.6640625], [160, 814, 234, 875, 0.6650390625], [160, 814, 234, 875, 0.66357421875], [160, 814, 234, 875, 0.66357421875], [160, 814, 234, 875, 0.662109375], [160, 814, 234, 875, 0.66162109375], [160, 814, 234, 875, 0.66015625], [160, 814, 234, 875, 0.662109375], [160, 814, 234, 875, 0.6630859375], [160, 815, 234, 875, 0.66064453125], [160, 815, 233, 876, 0.66259765625], [160, 815, 233, 876, 0.66552734375], [160, 815, 233, 876, 0.66357421875], [160, 816, 233, 876, 0.66455078125], [161, 816, 233, 876, 0.6630859375], [161, 817, 234, 877, 0.66357421875], [161, 817, 234, 877, 0.66064453125], [161, 818, 234, 877, 0.65771484375], [161, 819, 234, 877, 0.65673828125], [162, 815, 233, 874, 0.63525390625]]\n",
      "Key: 4d, vector len: 3, Card Detections: [[373, 815, 427, 884, 0.5986328125], [371, 816, 427, 885, 0.60693359375], [159, 807, 235, 871, 0.533203125]]\n",
      "Key: 4h, vector len: 93, Card Detections: [[160, 806, 226, 871, 0.5830078125], [158, 806, 245, 871, 0.58544921875], [159, 807, 231, 869, 0.60888671875], [159, 807, 225, 869, 0.63916015625], [159, 808, 225, 870, 0.6357421875], [159, 808, 225, 870, 0.6298828125], [159, 808, 225, 870, 0.62451171875], [159, 809, 225, 869, 0.623046875], [159, 808, 225, 869, 0.62353515625], [159, 808, 225, 869, 0.62255859375], [159, 808, 225, 869, 0.62255859375], [159, 808, 225, 869, 0.62109375], [159, 808, 225, 869, 0.6220703125], [159, 808, 225, 869, 0.62255859375], [159, 808, 225, 869, 0.6240234375], [159, 808, 225, 869, 0.62353515625], [159, 809, 225, 870, 0.6240234375], [159, 809, 225, 870, 0.62548828125], [159, 809, 225, 870, 0.62646484375], [159, 809, 225, 870, 0.62939453125], [159, 809, 225, 870, 0.62890625], [159, 809, 225, 870, 0.6279296875], [159, 809, 225, 870, 0.62841796875], [159, 809, 225, 870, 0.6279296875], [159, 809, 225, 870, 0.62841796875], [159, 809, 225, 870, 0.62939453125], [159, 809, 225, 870, 0.62939453125], [159, 809, 225, 870, 0.62939453125], [159, 809, 225, 870, 0.62939453125], [159, 809, 225, 870, 0.63037109375], [159, 809, 225, 870, 0.63134765625], [159, 809, 225, 870, 0.6318359375], [159, 809, 225, 871, 0.63134765625], [159, 810, 225, 871, 0.6328125], [159, 810, 225, 871, 0.6328125], [159, 810, 225, 871, 0.63232421875], [159, 810, 225, 871, 0.63330078125], [159, 810, 225, 871, 0.6337890625], [159, 810, 225, 871, 0.63427734375], [159, 810, 225, 871, 0.634765625], [159, 810, 225, 871, 0.634765625], [159, 810, 225, 871, 0.64013671875], [159, 810, 225, 871, 0.64013671875], [159, 810, 225, 871, 0.638671875], [159, 810, 225, 871, 0.6396484375], [159, 810, 225, 871, 0.6396484375], [159, 810, 225, 871, 0.64013671875], [159, 811, 225, 871, 0.64111328125], [159, 811, 225, 871, 0.640625], [159, 811, 225, 871, 0.64013671875], [159, 811, 225, 871, 0.640625], [159, 811, 225, 872, 0.64013671875], [159, 811, 225, 872, 0.640625], [159, 811, 225, 872, 0.64111328125], [159, 811, 225, 872, 0.64404296875], [159, 811, 225, 872, 0.6435546875], [159, 811, 225, 872, 0.6435546875], [159, 811, 225, 872, 0.6435546875], [159, 812, 225, 872, 0.64501953125], [159, 812, 225, 872, 0.64404296875], [159, 812, 225, 872, 0.64306640625], [159, 812, 225, 872, 0.64306640625], [159, 812, 225, 872, 0.642578125], [159, 812, 225, 872, 0.642578125], [159, 812, 225, 872, 0.642578125], [159, 812, 225, 872, 0.6416015625], [159, 812, 225, 872, 0.6416015625], [159, 813, 225, 873, 0.6396484375], [159, 813, 225, 873, 0.64013671875], [159, 813, 225, 873, 0.640625], [159, 813, 225, 873, 0.64013671875], [159, 813, 225, 873, 0.64013671875], [159, 813, 225, 873, 0.638671875], [159, 813, 225, 873, 0.6376953125], [159, 813, 226, 873, 0.63720703125], [160, 813, 226, 873, 0.6376953125], [160, 813, 226, 873, 0.63720703125], [160, 814, 226, 873, 0.63623046875], [160, 814, 226, 873, 0.6357421875], [160, 814, 226, 873, 0.634765625], [160, 814, 226, 873, 0.6337890625], [160, 814, 226, 873, 0.63330078125], [160, 814, 226, 873, 0.63330078125], [160, 814, 226, 874, 0.6328125], [160, 815, 226, 874, 0.630859375], [160, 815, 226, 874, 0.63037109375], [160, 815, 226, 874, 0.63037109375], [160, 815, 227, 874, 0.630859375], [160, 816, 226, 875, 0.6416015625], [160, 814, 227, 877, 0.53662109375], [160, 814, 227, 876, 0.580078125], [159, 813, 227, 876, 0.638671875], [159, 813, 227, 876, 0.51806640625]]\n",
      "Key: 4s, vector len: 1, Card Detections: [[374, 818, 431, 887, 0.6103515625]]\n",
      "Key: 5c, vector len: 8, Card Detections: [[373, 820, 402, 887, 0.62451171875], [372, 821, 402, 888, 0.64990234375], [372, 821, 401, 887, 0.64794921875], [371, 821, 401, 887, 0.6494140625], [371, 821, 401, 888, 0.64599609375], [372, 822, 401, 888, 0.65673828125], [372, 822, 401, 888, 0.65478515625], [372, 822, 401, 888, 0.65478515625]]\n",
      "Key: 5d, vector len: 0, Card Detections: []\n",
      "Key: 5h, vector len: 2, Card Detections: [[374, 815, 400, 880, 0.68212890625], [373, 814, 400, 880, 0.68310546875]]\n",
      "Key: 5s, vector len: 2, Card Detections: [[373, 814, 400, 881, 0.62158203125], [372, 816, 399, 881, 0.64794921875]]\n",
      "Key: 6c, vector len: 1, Card Detections: [[372, 815, 403, 882, 0.6630859375]]\n",
      "Key: 6d, vector len: 2, Card Detections: [[184, 817, 216, 882, 0.6884765625], [183, 815, 215, 881, 0.69189453125]]\n",
      "Key: 6h, vector len: 0, Card Detections: []\n",
      "Key: 6s, vector len: 10, Card Detections: [[161, 817, 193, 883, 0.6728515625], [161, 813, 192, 880, 0.685546875], [161, 813, 192, 880, 0.67822265625], [160, 813, 193, 881, 0.6806640625], [160, 814, 193, 883, 0.6875], [161, 814, 192, 880, 0.6806640625], [161, 814, 192, 880, 0.6787109375], [161, 814, 192, 880, 0.67333984375], [160, 815, 192, 881, 0.6728515625], [161, 815, 191, 881, 0.67041015625]]\n",
      "Key: 7c, vector len: 0, Card Detections: []\n",
      "Key: 7d, vector len: 103, Card Detections: [[372, 820, 401, 886, 0.58935546875], [373, 820, 400, 884, 0.60107421875], [373, 820, 400, 884, 0.6025390625], [373, 820, 400, 884, 0.6015625], [373, 820, 400, 884, 0.60107421875], [373, 820, 400, 884, 0.5986328125], [373, 820, 400, 884, 0.59912109375], [373, 820, 400, 884, 0.595703125], [373, 820, 400, 885, 0.5966796875], [373, 820, 400, 884, 0.59765625], [373, 820, 400, 885, 0.5986328125], [373, 820, 400, 885, 0.59814453125], [373, 820, 400, 884, 0.6005859375], [373, 820, 400, 885, 0.5986328125], [373, 820, 400, 885, 0.59765625], [373, 820, 400, 885, 0.59716796875], [373, 820, 400, 885, 0.59765625], [373, 820, 400, 885, 0.59716796875], [373, 820, 400, 885, 0.59765625], [373, 820, 400, 885, 0.59814453125], [373, 820, 400, 885, 0.59716796875], [373, 820, 400, 885, 0.59716796875], [373, 820, 400, 885, 0.59619140625], [373, 820, 399, 885, 0.59814453125], [373, 820, 399, 885, 0.59765625], [373, 820, 399, 885, 0.59814453125], [373, 820, 399, 885, 0.5986328125], [373, 820, 399, 885, 0.59912109375], [373, 820, 399, 885, 0.599609375], [373, 820, 399, 885, 0.59912109375], [373, 820, 399, 885, 0.59912109375], [373, 820, 399, 885, 0.59912109375], [373, 820, 399, 885, 0.60009765625], [373, 820, 399, 885, 0.599609375], [373, 820, 399, 885, 0.5986328125], [373, 820, 399, 885, 0.5986328125], [373, 820, 399, 885, 0.59765625], [373, 820, 399, 885, 0.59521484375], [373, 820, 399, 885, 0.59765625], [373, 820, 399, 885, 0.5986328125], [373, 820, 399, 885, 0.59814453125], [373, 821, 399, 885, 0.5986328125], [373, 820, 399, 885, 0.5986328125], [373, 821, 399, 885, 0.5986328125], [373, 821, 399, 885, 0.599609375], [373, 821, 399, 885, 0.599609375], [373, 821, 399, 885, 0.5986328125], [373, 821, 399, 885, 0.59814453125], [373, 820, 399, 885, 0.59814453125], [373, 820, 399, 885, 0.5966796875], [373, 820, 399, 885, 0.5966796875], [373, 820, 399, 885, 0.5966796875], [373, 820, 400, 885, 0.59619140625], [373, 821, 399, 885, 0.5966796875], [373, 821, 399, 885, 0.59716796875], [373, 820, 399, 885, 0.5966796875], [373, 820, 399, 885, 0.59814453125], [373, 820, 399, 885, 0.5966796875], [373, 820, 399, 885, 0.5966796875], [373, 820, 400, 885, 0.59716796875], [373, 820, 399, 885, 0.59716796875], [373, 820, 400, 885, 0.59619140625], [373, 820, 400, 885, 0.59814453125], [373, 820, 400, 885, 0.5986328125], [373, 820, 400, 885, 0.5986328125], [373, 820, 400, 885, 0.59912109375], [373, 820, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.59765625], [373, 821, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.59814453125], [373, 821, 400, 885, 0.59814453125], [373, 821, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.59912109375], [373, 821, 400, 885, 0.59912109375], [373, 821, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.59814453125], [373, 821, 400, 885, 0.59814453125], [373, 821, 400, 885, 0.59814453125], [373, 821, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.5986328125], [373, 821, 400, 885, 0.59912109375], [373, 821, 400, 885, 0.59912109375], [373, 821, 400, 885, 0.599609375], [373, 821, 400, 885, 0.599609375], [373, 821, 400, 885, 0.59912109375], [373, 821, 400, 885, 0.5986328125], [373, 821, 399, 885, 0.60205078125], [373, 821, 399, 885, 0.6025390625], [373, 821, 399, 885, 0.60205078125], [373, 821, 399, 885, 0.60205078125], [373, 821, 399, 885, 0.6015625], [372, 821, 399, 885, 0.60205078125], [372, 821, 399, 885, 0.60400390625], [372, 821, 399, 885, 0.603515625], [372, 821, 399, 885, 0.6044921875], [372, 821, 399, 885, 0.60205078125], [372, 822, 399, 885, 0.60498046875], [372, 822, 399, 885, 0.60302734375], [372, 822, 399, 885, 0.60400390625], [372, 822, 398, 885, 0.60302734375], [373, 821, 400, 882, 0.599609375]]\n",
      "Key: 7h, vector len: 6, Card Detections: [[372, 817, 400, 883, 0.62744140625], [371, 817, 400, 885, 0.623046875], [371, 818, 399, 884, 0.63623046875], [371, 820, 400, 886, 0.61669921875], [372, 819, 405, 883, 0.63916015625], [370, 820, 402, 889, 0.64208984375]]\n",
      "Key: 7s, vector len: 1, Card Detections: [[370, 816, 398, 881, 0.62890625]]\n",
      "Key: 8c, vector len: 2, Card Detections: [[164, 793, 196, 862, 0.6171875], [165, 796, 196, 864, 0.634765625]]\n",
      "Key: 8d, vector len: 0, Card Detections: []\n",
      "Key: 8h, vector len: 2, Card Detections: [[182, 809, 214, 874, 0.6611328125], [181, 809, 213, 874, 0.6630859375]]\n",
      "Key: 8s, vector len: 1, Card Detections: [[374, 817, 402, 882, 0.5830078125]]\n",
      "Key: 9c, vector len: 1, Card Detections: [[371, 821, 401, 888, 0.5009765625]]\n",
      "Key: 9d, vector len: 1, Card Detections: [[166, 791, 196, 861, 0.67041015625]]\n",
      "Key: 9h, vector len: 102, Card Detections: [[372, 820, 402, 891, 0.62109375], [373, 820, 401, 883, 0.65966796875], [373, 820, 401, 884, 0.64599609375], [373, 820, 401, 884, 0.64501953125], [373, 820, 401, 885, 0.64794921875], [373, 820, 401, 884, 0.64501953125], [373, 820, 401, 884, 0.64453125], [373, 820, 401, 884, 0.6376953125], [373, 820, 401, 884, 0.63916015625], [373, 820, 401, 884, 0.626953125], [373, 820, 401, 884, 0.6328125], [373, 820, 401, 885, 0.64208984375], [373, 820, 401, 884, 0.65771484375], [373, 820, 401, 884, 0.66064453125], [373, 820, 401, 884, 0.66064453125], [373, 820, 401, 884, 0.6611328125], [373, 820, 400, 884, 0.6611328125], [373, 820, 401, 884, 0.65869140625], [373, 820, 400, 884, 0.65576171875], [373, 820, 401, 884, 0.65478515625], [373, 820, 401, 884, 0.65625], [373, 820, 401, 884, 0.64306640625], [373, 820, 401, 884, 0.64501953125], [373, 820, 400, 884, 0.64453125], [373, 820, 401, 884, 0.6435546875], [373, 820, 400, 884, 0.64697265625], [373, 820, 400, 884, 0.650390625], [373, 820, 400, 884, 0.650390625], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.65234375], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.65185546875], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.650390625], [373, 820, 400, 884, 0.64990234375], [373, 820, 400, 884, 0.650390625], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.65185546875], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.64892578125], [373, 820, 400, 884, 0.64990234375], [373, 820, 400, 884, 0.6494140625], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.65185546875], [373, 820, 400, 884, 0.65234375], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.650390625], [373, 820, 400, 884, 0.6494140625], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.65380859375], [373, 820, 400, 884, 0.65380859375], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.65234375], [373, 820, 400, 884, 0.65478515625], [373, 820, 400, 884, 0.6552734375], [373, 820, 400, 884, 0.65478515625], [373, 820, 400, 884, 0.65576171875], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.65185546875], [373, 820, 400, 884, 0.65234375], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.6552734375], [373, 820, 400, 884, 0.654296875], [373, 820, 400, 884, 0.65283203125], [373, 820, 400, 884, 0.65380859375], [373, 820, 400, 884, 0.6533203125], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.65234375], [373, 820, 400, 884, 0.65185546875], [373, 820, 400, 884, 0.65234375], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.65087890625], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.6513671875], [373, 820, 400, 884, 0.65185546875], [373, 820, 400, 884, 0.65234375], [373, 820, 400, 884, 0.64990234375], [372, 820, 400, 884, 0.64697265625], [372, 820, 400, 884, 0.64599609375], [372, 821, 400, 884, 0.6435546875], [372, 821, 400, 884, 0.64892578125], [372, 821, 400, 884, 0.64501953125], [372, 821, 399, 884, 0.64501953125]]\n",
      "Key: 9s, vector len: 1, Card Detections: [[174, 801, 206, 870, 0.62353515625]]\n",
      "Key: Ac, vector len: 1, Card Detections: [[168, 792, 201, 861, 0.6484375]]\n",
      "Key: Ad, vector len: 6, Card Detections: [[178, 870, 209, 908, 0.63525390625], [183, 851, 214, 901, 0.669921875], [185, 845, 215, 898, 0.54052734375], [375, 817, 403, 882, 0.68017578125], [375, 818, 403, 882, 0.63818359375], [374, 818, 402, 884, 0.65478515625]]\n",
      "Key: Ah, vector len: 2, Card Detections: [[187, 825, 217, 887, 0.50390625], [187, 824, 217, 886, 0.60791015625]]\n",
      "Key: As, vector len: 1, Card Detections: [[170, 794, 202, 863, 0.63916015625]]\n",
      "Key: Jc, vector len: 2, Card Detections: [[161, 798, 192, 866, 0.65478515625], [161, 799, 192, 867, 0.67724609375]]\n",
      "Key: Jd, vector len: 1, Card Detections: [[373, 814, 400, 880, 0.63525390625]]\n",
      "Key: Jh, vector len: 41, Card Detections: [[373, 821, 400, 885, 0.59912109375], [373, 821, 400, 885, 0.599609375], [373, 821, 400, 885, 0.603515625], [373, 821, 400, 885, 0.6064453125], [373, 821, 400, 885, 0.61474609375], [373, 821, 400, 885, 0.60888671875], [373, 821, 400, 885, 0.6103515625], [373, 821, 400, 885, 0.6142578125], [373, 821, 400, 885, 0.61181640625], [373, 821, 400, 885, 0.6123046875], [372, 821, 400, 885, 0.61572265625], [372, 821, 400, 885, 0.61328125], [372, 821, 400, 886, 0.611328125], [372, 821, 400, 886, 0.60546875], [372, 821, 400, 886, 0.60693359375], [372, 821, 400, 886, 0.60791015625], [372, 821, 400, 886, 0.60888671875], [372, 821, 400, 886, 0.607421875], [372, 821, 400, 886, 0.60595703125], [372, 821, 400, 886, 0.6044921875], [372, 821, 400, 886, 0.6015625], [372, 822, 399, 886, 0.6015625], [372, 822, 399, 886, 0.60107421875], [372, 822, 399, 886, 0.6025390625], [372, 822, 399, 886, 0.60693359375], [372, 822, 399, 886, 0.607421875], [372, 822, 399, 886, 0.60302734375], [372, 822, 399, 886, 0.6064453125], [372, 822, 399, 886, 0.6083984375], [372, 822, 399, 886, 0.61376953125], [372, 822, 399, 886, 0.611328125], [372, 822, 399, 886, 0.61181640625], [372, 822, 399, 887, 0.60888671875], [372, 822, 399, 887, 0.60595703125], [372, 822, 399, 887, 0.6083984375], [372, 822, 399, 887, 0.611328125], [372, 822, 399, 887, 0.62060546875], [371, 822, 399, 887, 0.61328125], [371, 822, 399, 887, 0.61669921875], [371, 822, 398, 887, 0.6103515625], [371, 822, 398, 887, 0.62109375]]\n",
      "Key: Js, vector len: 1, Card Detections: [[169, 792, 199, 861, 0.6689453125]]\n",
      "Key: Kc, vector len: 1, Card Detections: [[172, 797, 203, 865, 0.66748046875]]\n",
      "Key: Kd, vector len: 1, Card Detections: [[183, 811, 214, 877, 0.6640625]]\n",
      "Key: Kh, vector len: 0, Card Detections: []\n",
      "Key: Ks, vector len: 16, Card Detections: [[359, 859, 395, 904, 0.66845703125], [362, 850, 395, 899, 0.6572265625], [361, 843, 395, 895, 0.63134765625], [362, 836, 394, 892, 0.63818359375], [362, 830, 395, 889, 0.642578125], [364, 825, 395, 884, 0.65771484375], [364, 822, 395, 882, 0.6552734375], [364, 822, 394, 882, 0.6513671875], [365, 820, 394, 881, 0.6484375], [365, 820, 395, 881, 0.65185546875], [365, 820, 395, 881, 0.6591796875], [366, 820, 395, 881, 0.65380859375], [366, 819, 395, 881, 0.65771484375], [367, 818, 396, 881, 0.66650390625], [367, 818, 396, 881, 0.6689453125], [367, 818, 396, 881, 0.68310546875]]\n",
      "Key: Qc, vector len: 1, Card Detections: [[169, 795, 200, 862, 0.62353515625]]\n",
      "Key: Qd, vector len: 1, Card Detections: [[186, 819, 217, 882, 0.5986328125]]\n",
      "Key: Qh, vector len: 1, Card Detections: [[177, 801, 207, 867, 0.67626953125]]\n",
      "Key: Qs, vector len: 1, Card Detections: [[369, 818, 398, 881, 0.638671875]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 1, Card Detections: [[156, 790, 201, 895, 0.63037109375]]\n",
      "Key: Tc, vector len: 6, Card Detections: [[504, 884, 557, 990, 0.65380859375], [504, 883, 556, 988, 0.65478515625], [504, 883, 556, 989, 0.6533203125], [504, 883, 556, 989, 0.65576171875], [504, 884, 556, 990, 0.6572265625], [501, 887, 555, 991, 0.6484375]]\n",
      "Key: Td, vector len: 127, Card Detections: [[136, 957, 186, 1039, 0.67041015625], [143, 929, 195, 1022, 0.66552734375], [149, 902, 202, 1004, 0.64404296875], [149, 898, 201, 1000, 0.64990234375], [149, 897, 201, 999, 0.6533203125], [149, 895, 201, 998, 0.65087890625], [148, 895, 201, 998, 0.650390625], [148, 895, 201, 998, 0.65771484375], [147, 895, 200, 998, 0.662109375], [147, 895, 199, 998, 0.66162109375], [147, 895, 199, 998, 0.66455078125], [146, 896, 199, 998, 0.6669921875], [146, 895, 199, 998, 0.66943359375], [147, 895, 200, 998, 0.66357421875], [148, 894, 201, 998, 0.6611328125], [148, 894, 202, 998, 0.6650390625], [149, 893, 202, 997, 0.666015625], [149, 892, 202, 997, 0.6669921875], [149, 892, 203, 997, 0.66650390625], [149, 892, 203, 997, 0.6689453125], [149, 891, 203, 996, 0.67138671875], [150, 891, 203, 995, 0.6728515625], [149, 890, 203, 994, 0.6728515625], [149, 889, 203, 994, 0.67529296875], [149, 889, 203, 994, 0.67578125], [150, 888, 203, 994, 0.67822265625], [150, 888, 203, 993, 0.6787109375], [150, 888, 203, 993, 0.677734375], [150, 887, 203, 993, 0.6796875], [150, 887, 203, 993, 0.6796875], [150, 887, 203, 992, 0.68017578125], [151, 887, 203, 992, 0.68115234375], [151, 886, 203, 992, 0.6806640625], [151, 886, 203, 992, 0.6806640625], [150, 886, 203, 992, 0.6806640625], [150, 885, 203, 992, 0.6796875], [150, 885, 203, 991, 0.6787109375], [150, 885, 203, 991, 0.67529296875], [150, 885, 203, 991, 0.67529296875], [150, 884, 203, 991, 0.67529296875], [150, 883, 203, 990, 0.67431640625], [150, 883, 204, 990, 0.67431640625], [151, 882, 204, 990, 0.67626953125], [151, 882, 204, 989, 0.677734375], [151, 881, 204, 989, 0.6787109375], [151, 880, 204, 988, 0.67724609375], [151, 880, 204, 987, 0.67919921875], [151, 879, 204, 987, 0.6796875], [151, 878, 204, 986, 0.6806640625], [151, 878, 204, 986, 0.68212890625], [151, 877, 204, 986, 0.68212890625], [151, 877, 204, 986, 0.68212890625], [151, 876, 204, 985, 0.68017578125], [151, 876, 204, 985, 0.68408203125], [151, 876, 204, 985, 0.68359375], [152, 876, 205, 985, 0.68359375], [152, 876, 205, 985, 0.68359375], [152, 876, 205, 985, 0.68408203125], [152, 876, 205, 985, 0.68310546875], [152, 876, 205, 985, 0.6845703125], [152, 876, 205, 985, 0.68505859375], [152, 876, 205, 985, 0.6845703125], [152, 876, 206, 986, 0.68505859375], [153, 876, 206, 986, 0.685546875], [153, 876, 206, 986, 0.68505859375], [153, 876, 205, 986, 0.6845703125], [152, 876, 205, 986, 0.6845703125], [152, 877, 206, 986, 0.68505859375], [153, 876, 205, 985, 0.68310546875], [152, 876, 205, 985, 0.68359375], [153, 876, 206, 985, 0.68408203125], [153, 876, 206, 985, 0.6845703125], [153, 876, 206, 985, 0.68408203125], [153, 876, 206, 985, 0.68359375], [153, 876, 206, 985, 0.68212890625], [153, 876, 206, 985, 0.68359375], [153, 876, 206, 985, 0.68310546875], [152, 876, 206, 985, 0.6845703125], [152, 876, 206, 985, 0.68310546875], [152, 876, 206, 985, 0.68359375], [152, 876, 206, 985, 0.68359375], [152, 876, 206, 985, 0.68505859375], [152, 876, 206, 986, 0.68603515625], [152, 876, 206, 986, 0.68603515625], [152, 877, 206, 986, 0.68603515625], [152, 877, 206, 986, 0.6865234375], [152, 877, 205, 986, 0.68505859375], [152, 877, 205, 986, 0.681640625], [152, 877, 205, 986, 0.68017578125], [152, 877, 205, 986, 0.68359375], [152, 877, 205, 986, 0.68408203125], [152, 877, 205, 986, 0.6845703125], [152, 877, 205, 986, 0.6845703125], [152, 877, 205, 986, 0.68505859375], [152, 876, 206, 986, 0.6845703125], [153, 876, 206, 986, 0.6865234375], [153, 876, 206, 986, 0.68505859375], [154, 877, 206, 986, 0.68212890625], [154, 877, 206, 986, 0.6826171875], [154, 877, 206, 986, 0.6845703125], [154, 877, 206, 986, 0.685546875], [154, 877, 206, 986, 0.685546875], [154, 877, 206, 986, 0.68505859375], [154, 877, 206, 986, 0.68603515625], [153, 877, 206, 986, 0.6845703125], [153, 877, 206, 986, 0.6845703125], [153, 876, 206, 986, 0.68212890625], [153, 876, 205, 986, 0.68212890625], [153, 876, 205, 986, 0.68310546875], [152, 876, 205, 986, 0.67919921875], [153, 876, 206, 986, 0.6796875], [153, 875, 206, 986, 0.67919921875], [153, 875, 206, 985, 0.6806640625], [154, 875, 206, 985, 0.681640625], [154, 875, 207, 984, 0.6796875], [155, 874, 208, 984, 0.677734375], [156, 873, 209, 985, 0.677734375], [156, 873, 210, 984, 0.67529296875], [157, 872, 210, 984, 0.677734375], [158, 872, 211, 982, 0.67724609375], [159, 872, 212, 982, 0.67822265625], [159, 872, 212, 982, 0.6767578125], [159, 871, 212, 982, 0.67529296875], [159, 871, 213, 982, 0.6748046875], [160, 871, 213, 982, 0.67431640625], [163, 874, 218, 987, 0.64892578125], [507, 881, 560, 990, 0.640625]]\n",
      "Key: Th, vector len: 9, Card Detections: [[504, 882, 557, 985, 0.63720703125], [505, 882, 555, 985, 0.61474609375], [505, 882, 555, 986, 0.6171875], [505, 882, 555, 987, 0.62451171875], [505, 882, 555, 987, 0.61376953125], [505, 882, 555, 986, 0.615234375], [505, 882, 555, 987, 0.6181640625], [505, 882, 555, 988, 0.623046875], [503, 882, 554, 988, 0.63037109375]]\n",
      "Key: Ts, vector len: 47, Card Detections: [[508, 884, 558, 1003, 0.529296875], [508, 885, 557, 1003, 0.5283203125], [507, 885, 557, 1003, 0.55126953125], [507, 885, 556, 1003, 0.50390625], [507, 885, 556, 1003, 0.52685546875], [507, 885, 556, 1003, 0.54443359375], [507, 885, 556, 1003, 0.50537109375], [507, 885, 555, 1004, 0.5341796875], [506, 886, 555, 1004, 0.52099609375], [506, 886, 555, 1005, 0.53076171875], [506, 887, 555, 1005, 0.5234375], [506, 886, 555, 1005, 0.54833984375], [506, 886, 555, 1005, 0.5166015625], [506, 886, 555, 1005, 0.5185546875], [506, 886, 555, 1005, 0.51513671875], [506, 887, 555, 1005, 0.529296875], [506, 887, 555, 1005, 0.54345703125], [505, 887, 555, 1005, 0.53271484375], [505, 887, 555, 1005, 0.5244140625], [505, 887, 555, 1005, 0.52099609375], [505, 887, 555, 1005, 0.51416015625], [505, 887, 555, 1005, 0.515625], [505, 887, 554, 1005, 0.53173828125], [505, 887, 554, 1005, 0.52294921875], [505, 887, 555, 1005, 0.5380859375], [505, 888, 554, 1005, 0.54931640625], [505, 888, 554, 1005, 0.546875], [504, 888, 554, 1006, 0.5693359375], [505, 888, 554, 1006, 0.5537109375], [504, 889, 554, 1006, 0.54736328125], [504, 889, 553, 1006, 0.548828125], [504, 889, 553, 1007, 0.537109375], [504, 889, 553, 1006, 0.52197265625], [504, 889, 553, 1007, 0.5458984375], [504, 890, 553, 1007, 0.55615234375], [504, 890, 553, 1006, 0.529296875], [504, 890, 553, 1007, 0.51611328125], [504, 891, 552, 1007, 0.501953125], [504, 891, 552, 1007, 0.5341796875], [504, 891, 552, 1007, 0.5283203125], [504, 891, 551, 1007, 0.53759765625], [504, 892, 551, 1007, 0.5302734375], [504, 892, 551, 1007, 0.52734375], [503, 892, 551, 1008, 0.53271484375], [503, 891, 550, 1008, 0.54931640625], [503, 892, 550, 1008, 0.55419921875], [502, 893, 549, 1008, 0.5458984375]]\n",
      "Key: 2c, vector len: 7, Card Detections: [[157, 868, 213, 986, 0.6708984375], [157, 868, 213, 986, 0.66162109375], [158, 868, 213, 986, 0.66943359375], [157, 867, 213, 986, 0.67041015625], [157, 867, 214, 986, 0.6748046875], [157, 868, 214, 986, 0.67529296875], [160, 871, 218, 987, 0.68896484375]]\n",
      "Key: 2d, vector len: 11, Card Detections: [[148, 812, 200, 928, 0.6416015625], [149, 812, 199, 928, 0.63720703125], [149, 812, 199, 928, 0.64208984375], [149, 812, 199, 928, 0.638671875], [149, 812, 199, 928, 0.6376953125], [149, 813, 199, 930, 0.63623046875], [149, 814, 199, 931, 0.63720703125], [149, 815, 199, 932, 0.64208984375], [149, 816, 199, 933, 0.64990234375], [148, 816, 199, 933, 0.65478515625], [151, 821, 203, 940, 0.62744140625]]\n",
      "Key: 2h, vector len: 21, Card Detections: [[127, 830, 181, 950, 0.60546875], [127, 830, 181, 952, 0.60400390625], [125, 833, 180, 953, 0.595703125], [126, 832, 180, 953, 0.5927734375], [126, 833, 180, 953, 0.59375], [125, 833, 180, 953, 0.5947265625], [125, 834, 179, 954, 0.59521484375], [125, 834, 179, 954, 0.59326171875], [125, 835, 179, 955, 0.59619140625], [125, 835, 179, 955, 0.6025390625], [125, 835, 179, 954, 0.60302734375], [125, 835, 179, 954, 0.59716796875], [124, 835, 179, 954, 0.5966796875], [124, 835, 179, 954, 0.595703125], [124, 835, 179, 955, 0.60009765625], [125, 835, 179, 954, 0.59716796875], [125, 835, 179, 954, 0.6005859375], [125, 835, 180, 955, 0.607421875], [125, 836, 180, 956, 0.6103515625], [126, 837, 180, 957, 0.62109375], [127, 841, 182, 958, 0.6123046875]]\n",
      "Key: 2s, vector len: 5, Card Detections: [[150, 822, 204, 940, 0.65478515625], [150, 823, 205, 941, 0.66796875], [150, 823, 204, 940, 0.66845703125], [150, 823, 205, 941, 0.66748046875], [152, 823, 206, 943, 0.662109375]]\n",
      "Key: 3c, vector len: 23, Card Detections: [[507, 870, 561, 985, 0.54833984375], [508, 870, 561, 986, 0.60302734375], [507, 871, 560, 986, 0.615234375], [507, 871, 560, 986, 0.61572265625], [507, 872, 560, 987, 0.6240234375], [507, 871, 559, 987, 0.62060546875], [507, 871, 560, 987, 0.63427734375], [507, 871, 560, 987, 0.63037109375], [507, 872, 559, 987, 0.619140625], [507, 872, 560, 987, 0.62109375], [507, 873, 560, 987, 0.654296875], [507, 873, 560, 987, 0.65576171875], [507, 873, 560, 987, 0.6533203125], [507, 872, 560, 987, 0.654296875], [507, 873, 560, 987, 0.6591796875], [507, 873, 559, 987, 0.66015625], [507, 873, 559, 987, 0.6572265625], [506, 873, 559, 987, 0.65185546875], [506, 874, 559, 988, 0.6484375], [505, 874, 558, 988, 0.6484375], [505, 875, 558, 988, 0.64697265625], [505, 875, 557, 989, 0.646484375], [502, 877, 554, 990, 0.5615234375]]\n",
      "Key: 3d, vector len: 9, Card Detections: [[150, 817, 203, 932, 0.6611328125], [150, 816, 202, 931, 0.6689453125], [150, 817, 203, 932, 0.66650390625], [152, 816, 204, 933, 0.6552734375], [152, 816, 204, 933, 0.6552734375], [153, 816, 205, 934, 0.65380859375], [153, 816, 205, 933, 0.65185546875], [154, 816, 206, 934, 0.64501953125], [156, 814, 209, 934, 0.65380859375]]\n",
      "Key: 3h, vector len: 12, Card Detections: [[509, 869, 561, 982, 0.603515625], [509, 871, 560, 984, 0.59814453125], [509, 871, 560, 985, 0.60205078125], [509, 870, 560, 984, 0.6025390625], [508, 871, 560, 984, 0.60302734375], [508, 872, 559, 985, 0.599609375], [508, 871, 559, 984, 0.5869140625], [508, 871, 559, 985, 0.6005859375], [508, 871, 559, 984, 0.60595703125], [507, 872, 559, 985, 0.6201171875], [507, 873, 559, 986, 0.623046875], [506, 873, 558, 986, 0.615234375]]\n",
      "Key: 3s, vector len: 14, Card Detections: [[507, 879, 559, 994, 0.6044921875], [506, 879, 558, 993, 0.623046875], [506, 880, 558, 993, 0.63037109375], [506, 881, 557, 994, 0.6240234375], [506, 881, 557, 994, 0.625], [505, 881, 557, 994, 0.62158203125], [505, 881, 556, 995, 0.63671875], [505, 881, 556, 996, 0.6318359375], [504, 882, 555, 998, 0.62939453125], [503, 882, 555, 996, 0.63623046875], [504, 882, 555, 996, 0.634765625], [504, 882, 555, 997, 0.63037109375], [503, 883, 554, 997, 0.6376953125], [502, 883, 554, 998, 0.64013671875]]\n",
      "Key: 4c, vector len: 4, Card Detections: [[152, 824, 280, 947, 0.6494140625], [152, 823, 280, 947, 0.64990234375], [153, 824, 280, 947, 0.650390625], [155, 826, 280, 948, 0.6572265625]]\n",
      "Key: 4d, vector len: 75, Card Detections: [[122, 858, 237, 975, 0.607421875], [121, 857, 237, 975, 0.60595703125], [121, 857, 237, 976, 0.609375], [121, 858, 237, 977, 0.61376953125], [121, 858, 237, 977, 0.61376953125], [121, 860, 236, 978, 0.60888671875], [121, 860, 236, 978, 0.6064453125], [121, 860, 236, 979, 0.6064453125], [121, 861, 237, 979, 0.6103515625], [121, 861, 237, 979, 0.61083984375], [121, 861, 237, 979, 0.609375], [121, 861, 237, 979, 0.60986328125], [121, 861, 237, 979, 0.6103515625], [121, 861, 237, 979, 0.6103515625], [121, 860, 237, 979, 0.60986328125], [121, 860, 237, 979, 0.609375], [121, 860, 237, 979, 0.607421875], [121, 860, 237, 979, 0.6064453125], [121, 860, 236, 979, 0.60693359375], [121, 860, 237, 979, 0.60791015625], [121, 860, 237, 979, 0.60693359375], [121, 860, 237, 979, 0.60693359375], [121, 860, 237, 979, 0.60595703125], [121, 860, 237, 979, 0.60546875], [121, 859, 236, 978, 0.6064453125], [121, 859, 236, 978, 0.607421875], [121, 859, 236, 978, 0.61083984375], [120, 859, 236, 978, 0.6103515625], [120, 859, 236, 978, 0.61083984375], [120, 859, 236, 978, 0.60986328125], [120, 859, 236, 978, 0.609375], [121, 859, 236, 978, 0.60986328125], [120, 859, 236, 978, 0.60986328125], [120, 858, 236, 978, 0.60986328125], [120, 858, 236, 978, 0.60888671875], [120, 858, 236, 978, 0.607421875], [120, 856, 235, 977, 0.6064453125], [120, 856, 235, 977, 0.60693359375], [119, 856, 234, 977, 0.6064453125], [119, 855, 234, 976, 0.60986328125], [119, 855, 234, 976, 0.60888671875], [119, 855, 234, 976, 0.6083984375], [119, 854, 233, 976, 0.6103515625], [119, 854, 233, 976, 0.60888671875], [119, 854, 233, 976, 0.60888671875], [119, 855, 233, 976, 0.607421875], [119, 855, 233, 976, 0.60888671875], [119, 855, 234, 976, 0.6083984375], [119, 856, 234, 977, 0.6103515625], [119, 857, 234, 977, 0.60888671875], [119, 857, 234, 977, 0.609375], [119, 857, 234, 978, 0.6083984375], [119, 858, 234, 978, 0.60888671875], [119, 858, 234, 978, 0.6083984375], [119, 858, 234, 978, 0.6083984375], [119, 858, 234, 978, 0.60791015625], [119, 858, 234, 978, 0.607421875], [119, 859, 234, 978, 0.607421875], [119, 859, 234, 978, 0.607421875], [119, 859, 234, 979, 0.60791015625], [119, 859, 234, 979, 0.6083984375], [120, 859, 234, 979, 0.60986328125], [120, 859, 234, 979, 0.6103515625], [120, 860, 234, 979, 0.609375], [120, 859, 234, 979, 0.609375], [120, 860, 235, 979, 0.60986328125], [120, 860, 235, 979, 0.61083984375], [120, 860, 235, 980, 0.6103515625], [120, 861, 235, 980, 0.60888671875], [121, 861, 235, 980, 0.60888671875], [121, 861, 236, 981, 0.60986328125], [121, 862, 236, 981, 0.611328125], [121, 863, 236, 982, 0.6123046875], [121, 865, 236, 982, 0.607421875], [122, 870, 238, 984, 0.60791015625]]\n",
      "Key: 4h, vector len: 1, Card Detections: [[137, 983, 255, 1053, 0.6318359375]]\n",
      "Key: 4s, vector len: 13, Card Detections: [[139, 824, 251, 947, 0.61279296875], [139, 825, 251, 950, 0.60400390625], [138, 826, 249, 947, 0.60400390625], [139, 826, 249, 950, 0.6044921875], [138, 826, 249, 950, 0.60791015625], [138, 826, 249, 950, 0.6044921875], [137, 826, 248, 951, 0.6064453125], [137, 826, 248, 951, 0.6044921875], [137, 826, 249, 950, 0.60546875], [137, 826, 249, 951, 0.60107421875], [137, 826, 247, 952, 0.6025390625], [137, 826, 247, 952, 0.60107421875], [136, 827, 247, 954, 0.59326171875]]\n",
      "Key: 5c, vector len: 11, Card Detections: [[508, 872, 559, 987, 0.62255859375], [508, 873, 559, 989, 0.615234375], [507, 874, 559, 989, 0.59619140625], [508, 874, 559, 988, 0.544921875], [507, 873, 558, 989, 0.60302734375], [507, 874, 558, 990, 0.626953125], [507, 874, 558, 989, 0.64501953125], [507, 874, 558, 990, 0.65625], [506, 874, 558, 990, 0.65576171875], [506, 875, 557, 990, 0.638671875], [503, 876, 556, 992, 0.5947265625]]\n",
      "Key: 5d, vector len: 5, Card Detections: [[159, 861, 210, 976, 0.63037109375], [160, 861, 210, 973, 0.63330078125], [161, 859, 211, 973, 0.634765625], [161, 859, 212, 974, 0.64013671875], [164, 861, 216, 978, 0.59912109375]]\n",
      "Key: 5h, vector len: 13, Card Detections: [[511, 871, 560, 985, 0.64306640625], [511, 871, 560, 986, 0.64794921875], [510, 872, 560, 987, 0.650390625], [510, 873, 560, 988, 0.6484375], [509, 873, 559, 988, 0.64501953125], [509, 872, 559, 988, 0.64501953125], [509, 872, 559, 988, 0.6455078125], [509, 873, 559, 988, 0.64404296875], [508, 871, 559, 987, 0.6396484375], [508, 872, 558, 987, 0.642578125], [507, 873, 557, 986, 0.6513671875], [506, 873, 556, 988, 0.654296875], [505, 873, 555, 988, 0.66064453125]]\n",
      "Key: 5s, vector len: 5, Card Detections: [[162, 849, 214, 969, 0.64111328125], [163, 848, 214, 968, 0.6494140625], [163, 848, 215, 968, 0.6279296875], [163, 847, 215, 967, 0.6318359375], [164, 847, 216, 966, 0.65087890625]]\n",
      "Key: 6c, vector len: 22, Card Detections: [[123, 834, 177, 954, 0.69189453125], [122, 835, 175, 954, 0.6884765625], [121, 839, 176, 959, 0.71044921875], [122, 838, 176, 958, 0.7021484375], [122, 839, 176, 959, 0.70458984375], [122, 840, 176, 960, 0.708984375], [122, 841, 176, 961, 0.70751953125], [122, 842, 176, 962, 0.70166015625], [122, 842, 176, 962, 0.70166015625], [122, 841, 175, 961, 0.70263671875], [122, 842, 176, 962, 0.69873046875], [122, 843, 176, 962, 0.70263671875], [122, 843, 175, 963, 0.6943359375], [122, 843, 175, 963, 0.69091796875], [122, 843, 175, 964, 0.69189453125], [122, 844, 175, 964, 0.6865234375], [123, 845, 175, 965, 0.68212890625], [123, 846, 175, 967, 0.6884765625], [123, 846, 175, 967, 0.6875], [123, 847, 176, 967, 0.69189453125], [123, 847, 176, 968, 0.68994140625], [123, 849, 176, 969, 0.69580078125]]\n",
      "Key: 6d, vector len: 60, Card Detections: [[120, 847, 171, 964, 0.6474609375], [118, 847, 169, 964, 0.64990234375], [118, 847, 169, 965, 0.6494140625], [118, 847, 169, 964, 0.64892578125], [118, 848, 168, 966, 0.646484375], [118, 849, 168, 967, 0.640625], [118, 849, 168, 967, 0.6435546875], [118, 849, 168, 968, 0.640625], [118, 850, 168, 968, 0.64208984375], [118, 850, 168, 968, 0.64208984375], [118, 851, 168, 968, 0.6484375], [118, 852, 168, 968, 0.68359375], [118, 851, 168, 968, 0.66552734375], [118, 852, 168, 968, 0.68310546875], [118, 852, 168, 968, 0.67431640625], [118, 852, 168, 968, 0.67431640625], [119, 852, 168, 968, 0.66845703125], [119, 853, 168, 968, 0.6669921875], [119, 853, 168, 969, 0.66650390625], [119, 853, 168, 969, 0.6650390625], [119, 854, 168, 970, 0.66650390625], [119, 854, 169, 970, 0.6640625], [119, 854, 169, 970, 0.662109375], [119, 854, 169, 970, 0.66455078125], [120, 855, 169, 970, 0.66162109375], [120, 855, 170, 970, 0.65673828125], [120, 855, 170, 970, 0.64990234375], [121, 855, 171, 971, 0.625], [121, 855, 171, 971, 0.62451171875], [122, 855, 171, 970, 0.6279296875], [122, 855, 172, 971, 0.62890625], [122, 855, 172, 971, 0.6318359375], [123, 855, 173, 971, 0.630859375], [123, 856, 173, 973, 0.63134765625], [123, 856, 173, 972, 0.63232421875], [123, 857, 173, 973, 0.63671875], [124, 857, 173, 973, 0.64306640625], [124, 858, 173, 974, 0.64208984375], [124, 858, 174, 974, 0.64794921875], [124, 859, 174, 975, 0.6572265625], [124, 859, 174, 975, 0.6572265625], [124, 859, 174, 975, 0.64599609375], [124, 859, 174, 973, 0.640625], [124, 859, 174, 972, 0.6416015625], [124, 859, 174, 972, 0.64404296875], [124, 858, 174, 972, 0.6455078125], [124, 858, 174, 972, 0.64453125], [124, 857, 174, 971, 0.646484375], [125, 857, 174, 971, 0.64111328125], [125, 857, 174, 971, 0.64111328125], [125, 857, 175, 971, 0.640625], [125, 857, 175, 970, 0.640625], [125, 857, 175, 970, 0.640625], [125, 857, 175, 970, 0.64306640625], [125, 857, 175, 970, 0.6435546875], [125, 857, 175, 970, 0.64404296875], [125, 858, 175, 970, 0.64306640625], [126, 859, 176, 971, 0.64501953125], [126, 859, 176, 971, 0.6435546875], [127, 864, 177, 971, 0.64990234375]]\n",
      "Key: 6h, vector len: 15, Card Detections: [[510, 875, 559, 987, 0.6396484375], [510, 875, 559, 988, 0.642578125], [509, 876, 559, 990, 0.63037109375], [510, 876, 559, 990, 0.63330078125], [510, 876, 559, 989, 0.6318359375], [510, 876, 559, 989, 0.6328125], [509, 876, 559, 989, 0.63720703125], [509, 876, 558, 989, 0.6376953125], [509, 877, 559, 990, 0.6376953125], [509, 876, 558, 989, 0.63427734375], [509, 876, 558, 989, 0.63330078125], [509, 876, 558, 989, 0.6318359375], [509, 877, 558, 990, 0.63330078125], [508, 877, 558, 990, 0.63134765625], [506, 879, 555, 992, 0.6298828125]]\n",
      "Key: 6s, vector len: 3, Card Detections: [[158, 824, 207, 947, 0.66650390625], [158, 824, 206, 943, 0.6650390625], [159, 823, 207, 942, 0.6591796875]]\n",
      "Key: 7c, vector len: 5, Card Detections: [[156, 855, 211, 996, 0.53369140625], [160, 855, 212, 973, 0.65283203125], [160, 854, 212, 973, 0.650390625], [162, 853, 214, 971, 0.66064453125], [163, 853, 214, 970, 0.6552734375]]\n",
      "Key: 7d, vector len: 3, Card Detections: [[150, 818, 198, 934, 0.6279296875], [151, 818, 198, 931, 0.62841796875], [155, 819, 203, 937, 0.63232421875]]\n",
      "Key: 7h, vector len: 7, Card Detections: [[160, 831, 210, 951, 0.68603515625], [160, 830, 208, 948, 0.64794921875], [160, 830, 208, 949, 0.6572265625], [160, 829, 209, 948, 0.66015625], [160, 829, 208, 948, 0.65087890625], [160, 830, 209, 948, 0.66455078125], [161, 826, 217, 957, 0.62353515625]]\n",
      "Key: 7s, vector len: 9, Card Detections: [[508, 873, 557, 988, 0.62255859375], [507, 872, 556, 988, 0.63037109375], [507, 872, 556, 989, 0.63818359375], [507, 872, 557, 989, 0.64697265625], [507, 873, 555, 990, 0.64599609375], [507, 874, 555, 990, 0.65185546875], [507, 874, 555, 989, 0.6435546875], [506, 876, 555, 990, 0.65234375], [504, 876, 554, 990, 0.67236328125]]\n",
      "Key: 8c, vector len: 116, Card Detections: [[507, 908, 563, 1007, 0.5166015625], [509, 897, 564, 998, 0.5576171875], [511, 890, 564, 991, 0.56591796875], [511, 888, 564, 989, 0.59521484375], [511, 887, 564, 989, 0.599609375], [511, 887, 564, 989, 0.58984375], [511, 886, 563, 988, 0.61865234375], [511, 885, 563, 988, 0.6259765625], [511, 885, 563, 987, 0.62841796875], [511, 884, 563, 987, 0.62548828125], [511, 883, 563, 986, 0.6259765625], [511, 883, 563, 985, 0.62744140625], [511, 882, 562, 985, 0.626953125], [511, 882, 562, 985, 0.63330078125], [511, 881, 562, 984, 0.62744140625], [511, 881, 562, 983, 0.6298828125], [511, 881, 561, 983, 0.63232421875], [511, 880, 561, 982, 0.63134765625], [511, 880, 561, 981, 0.63037109375], [511, 880, 561, 982, 0.6328125], [511, 880, 561, 981, 0.63427734375], [511, 880, 561, 981, 0.63623046875], [511, 880, 561, 981, 0.6376953125], [511, 880, 561, 981, 0.6357421875], [511, 879, 561, 980, 0.63671875], [511, 879, 561, 980, 0.63720703125], [511, 879, 562, 980, 0.63671875], [511, 878, 562, 980, 0.6357421875], [511, 878, 562, 980, 0.6376953125], [511, 878, 563, 980, 0.6357421875], [512, 877, 563, 980, 0.63330078125], [512, 877, 563, 979, 0.63037109375], [513, 876, 563, 979, 0.63037109375], [513, 876, 563, 979, 0.63037109375], [513, 876, 564, 978, 0.630859375], [514, 875, 564, 979, 0.63037109375], [514, 875, 564, 979, 0.630859375], [514, 875, 564, 978, 0.63623046875], [514, 876, 564, 978, 0.634765625], [514, 875, 564, 978, 0.6337890625], [514, 875, 564, 978, 0.6357421875], [514, 875, 564, 978, 0.6357421875], [514, 875, 564, 978, 0.6357421875], [514, 875, 564, 978, 0.63623046875], [514, 875, 564, 978, 0.6357421875], [514, 876, 564, 978, 0.6357421875], [514, 876, 564, 978, 0.63623046875], [514, 876, 564, 978, 0.63671875], [514, 876, 564, 979, 0.63720703125], [514, 876, 564, 979, 0.6357421875], [514, 876, 564, 979, 0.63623046875], [514, 876, 564, 979, 0.63623046875], [513, 876, 564, 980, 0.63525390625], [513, 877, 564, 980, 0.6357421875], [513, 877, 564, 980, 0.63427734375], [514, 877, 564, 980, 0.63720703125], [513, 876, 564, 979, 0.638671875], [513, 877, 564, 980, 0.638671875], [513, 877, 564, 980, 0.6416015625], [513, 877, 564, 980, 0.638671875], [513, 877, 564, 980, 0.63818359375], [513, 877, 564, 979, 0.638671875], [513, 877, 564, 979, 0.64013671875], [513, 877, 563, 979, 0.6435546875], [513, 877, 563, 979, 0.64404296875], [512, 877, 563, 979, 0.642578125], [512, 877, 563, 979, 0.6435546875], [512, 878, 563, 980, 0.642578125], [512, 878, 563, 980, 0.6416015625], [512, 878, 563, 980, 0.64111328125], [512, 878, 563, 980, 0.64111328125], [512, 878, 563, 980, 0.6416015625], [512, 878, 563, 980, 0.64208984375], [512, 878, 562, 980, 0.640625], [512, 878, 562, 980, 0.640625], [512, 878, 562, 981, 0.642578125], [512, 878, 562, 981, 0.6435546875], [512, 878, 561, 981, 0.642578125], [512, 878, 561, 981, 0.64208984375], [511, 878, 561, 981, 0.642578125], [511, 878, 561, 981, 0.6435546875], [511, 878, 561, 982, 0.6416015625], [511, 878, 561, 982, 0.64111328125], [511, 879, 561, 982, 0.64111328125], [511, 879, 561, 982, 0.6416015625], [511, 879, 561, 982, 0.6396484375], [511, 879, 561, 983, 0.6396484375], [511, 879, 561, 984, 0.64111328125], [511, 879, 560, 984, 0.64208984375], [511, 879, 560, 984, 0.6435546875], [510, 879, 560, 984, 0.6416015625], [510, 879, 560, 984, 0.6416015625], [510, 879, 560, 985, 0.6435546875], [509, 880, 560, 985, 0.64111328125], [509, 880, 560, 985, 0.64208984375], [509, 880, 559, 985, 0.63818359375], [509, 880, 560, 986, 0.6357421875], [509, 881, 559, 986, 0.63037109375], [508, 881, 559, 986, 0.63720703125], [508, 881, 559, 986, 0.6357421875], [508, 881, 559, 987, 0.63525390625], [508, 881, 559, 986, 0.62744140625], [508, 882, 559, 987, 0.61328125], [507, 882, 558, 987, 0.6201171875], [507, 883, 558, 987, 0.625], [507, 883, 558, 988, 0.6240234375], [507, 883, 558, 989, 0.62744140625], [507, 884, 558, 989, 0.623046875], [507, 884, 558, 989, 0.623046875], [506, 885, 557, 990, 0.626953125], [506, 885, 557, 990, 0.6220703125], [505, 885, 557, 991, 0.6181640625], [505, 886, 557, 991, 0.62158203125], [504, 887, 556, 991, 0.6298828125], [504, 887, 556, 991, 0.625], [503, 888, 556, 992, 0.62548828125]]\n",
      "Key: 8d, vector len: 8, Card Detections: [[153, 817, 204, 930, 0.705078125], [153, 818, 201, 930, 0.70458984375], [153, 818, 201, 930, 0.70751953125], [153, 818, 201, 932, 0.70849609375], [154, 818, 201, 932, 0.70947265625], [154, 818, 201, 932, 0.7099609375], [154, 819, 202, 932, 0.7109375], [158, 823, 209, 937, 0.6904296875]]\n",
      "Key: 8h, vector len: 7, Card Detections: [[508, 875, 558, 983, 0.66796875], [508, 875, 557, 984, 0.6611328125], [508, 875, 557, 985, 0.6591796875], [507, 874, 557, 985, 0.66552734375], [507, 874, 556, 984, 0.6689453125], [506, 875, 556, 985, 0.67333984375], [503, 877, 553, 985, 0.64208984375]]\n",
      "Key: 8s, vector len: 8, Card Detections: [[496, 948, 558, 1033, 0.5634765625], [508, 875, 558, 987, 0.63427734375], [508, 874, 558, 986, 0.6328125], [508, 874, 557, 987, 0.64404296875], [507, 874, 557, 987, 0.62939453125], [507, 874, 556, 987, 0.65576171875], [507, 876, 555, 988, 0.6328125], [506, 876, 555, 989, 0.638671875]]\n",
      "Key: 9c, vector len: 14, Card Detections: [[505, 877, 559, 986, 0.673828125], [506, 878, 557, 986, 0.69287109375], [506, 877, 557, 984, 0.6904296875], [506, 877, 558, 987, 0.6953125], [507, 876, 558, 988, 0.6953125], [507, 876, 558, 988, 0.69580078125], [507, 876, 558, 988, 0.6845703125], [506, 876, 558, 987, 0.66943359375], [506, 876, 558, 986, 0.67431640625], [506, 876, 558, 988, 0.67919921875], [506, 876, 558, 988, 0.67529296875], [506, 877, 558, 988, 0.6845703125], [505, 877, 558, 989, 0.68408203125], [503, 881, 555, 989, 0.6533203125]]\n",
      "Key: 9d, vector len: 26, Card Detections: [[508, 880, 556, 994, 0.6650390625], [508, 880, 556, 994, 0.662109375], [508, 881, 556, 995, 0.6640625], [508, 881, 556, 995, 0.66943359375], [508, 881, 556, 995, 0.6708984375], [508, 881, 556, 995, 0.67138671875], [508, 881, 556, 995, 0.66943359375], [508, 881, 556, 995, 0.66748046875], [508, 881, 556, 995, 0.66259765625], [508, 881, 556, 995, 0.6640625], [508, 881, 556, 995, 0.6650390625], [508, 881, 556, 995, 0.6650390625], [508, 881, 556, 995, 0.66259765625], [508, 881, 556, 995, 0.66455078125], [508, 881, 556, 995, 0.66455078125], [508, 881, 556, 996, 0.66748046875], [508, 882, 555, 996, 0.6669921875], [508, 882, 555, 996, 0.6689453125], [507, 882, 555, 996, 0.669921875], [507, 882, 555, 996, 0.671875], [507, 883, 554, 997, 0.6708984375], [507, 884, 554, 997, 0.66064453125], [507, 884, 554, 997, 0.66162109375], [506, 884, 553, 998, 0.66259765625], [505, 885, 552, 998, 0.66162109375], [505, 885, 552, 998, 0.66552734375]]\n",
      "Key: 9h, vector len: 17, Card Detections: [[504, 880, 554, 993, 0.638671875], [504, 880, 554, 994, 0.64013671875], [504, 881, 554, 992, 0.63427734375], [504, 881, 554, 994, 0.63916015625], [504, 881, 554, 994, 0.64208984375], [504, 881, 554, 994, 0.64208984375], [504, 881, 554, 996, 0.642578125], [504, 881, 554, 996, 0.64599609375], [504, 881, 554, 995, 0.64697265625], [504, 881, 554, 995, 0.64697265625], [504, 881, 554, 996, 0.6474609375], [504, 881, 554, 996, 0.64599609375], [504, 881, 554, 996, 0.642578125], [504, 882, 554, 994, 0.638671875], [504, 882, 554, 994, 0.638671875], [504, 882, 553, 994, 0.6376953125], [503, 883, 552, 995, 0.63525390625]]\n",
      "Key: 9s, vector len: 6, Card Detections: [[154, 822, 207, 942, 0.65478515625], [155, 822, 204, 941, 0.6357421875], [155, 822, 204, 941, 0.6474609375], [155, 822, 204, 942, 0.64697265625], [155, 823, 204, 944, 0.650390625], [156, 825, 205, 945, 0.6396484375]]\n",
      "Key: Ac, vector len: 6, Card Detections: [[159, 837, 215, 958, 0.65380859375], [159, 837, 215, 958, 0.66064453125], [159, 838, 215, 959, 0.65771484375], [160, 837, 216, 958, 0.65185546875], [159, 837, 216, 958, 0.654296875], [160, 837, 216, 958, 0.65234375]]\n",
      "Key: Ad, vector len: 16, Card Detections: [[510, 874, 558, 985, 0.63720703125], [510, 875, 558, 985, 0.642578125], [511, 875, 558, 985, 0.638671875], [511, 875, 558, 985, 0.64208984375], [511, 875, 558, 986, 0.63720703125], [510, 876, 558, 986, 0.62646484375], [511, 876, 558, 986, 0.62939453125], [511, 876, 558, 986, 0.630859375], [511, 876, 558, 986, 0.6328125], [510, 876, 558, 987, 0.63232421875], [510, 876, 557, 987, 0.6337890625], [510, 877, 557, 987, 0.63232421875], [509, 877, 557, 988, 0.63427734375], [509, 877, 557, 988, 0.63037109375], [508, 878, 556, 989, 0.63134765625], [507, 881, 554, 990, 0.65673828125]]\n",
      "Key: Ah, vector len: 8, Card Detections: [[155, 813, 206, 927, 0.646484375], [155, 814, 206, 929, 0.64453125], [155, 814, 206, 930, 0.6513671875], [155, 815, 206, 930, 0.6494140625], [155, 816, 206, 932, 0.65576171875], [155, 817, 207, 932, 0.66064453125], [156, 818, 207, 934, 0.662109375], [158, 820, 209, 935, 0.6455078125]]\n",
      "Key: As, vector len: 6, Card Detections: [[150, 815, 203, 933, 0.63916015625], [149, 816, 203, 933, 0.65087890625], [149, 816, 203, 934, 0.64990234375], [150, 815, 203, 933, 0.64404296875], [149, 815, 204, 933, 0.64501953125], [151, 815, 204, 933, 0.65625]]\n",
      "Key: Jc, vector len: 15, Card Detections: [[501, 881, 554, 996, 0.6669921875], [501, 882, 553, 995, 0.662109375], [501, 883, 553, 994, 0.65234375], [501, 884, 552, 995, 0.654296875], [501, 884, 553, 995, 0.654296875], [501, 884, 553, 995, 0.6533203125], [500, 883, 552, 995, 0.65234375], [500, 883, 552, 995, 0.65185546875], [500, 884, 553, 995, 0.6533203125], [500, 884, 552, 995, 0.65087890625], [501, 884, 552, 996, 0.65966796875], [500, 884, 552, 996, 0.65673828125], [500, 885, 552, 996, 0.65771484375], [500, 885, 552, 997, 0.66015625], [497, 888, 550, 1001, 0.66455078125]]\n",
      "Key: Jd, vector len: 5, Card Detections: [[151, 813, 202, 929, 0.65380859375], [151, 814, 202, 929, 0.65234375], [151, 814, 202, 929, 0.6494140625], [153, 814, 204, 930, 0.6533203125], [154, 815, 206, 931, 0.662109375]]\n",
      "Key: Jh, vector len: 8, Card Detections: [[506, 871, 557, 964, 0.5693359375], [506, 872, 555, 984, 0.61376953125], [506, 872, 556, 985, 0.62255859375], [505, 872, 557, 987, 0.61376953125], [504, 872, 556, 986, 0.615234375], [505, 874, 555, 987, 0.61865234375], [505, 874, 555, 987, 0.62353515625], [504, 875, 554, 987, 0.6220703125]]\n",
      "Key: Js, vector len: 21, Card Detections: [[507, 876, 558, 990, 0.67919921875], [507, 876, 558, 991, 0.6796875], [507, 877, 558, 991, 0.681640625], [507, 878, 557, 992, 0.681640625], [507, 877, 557, 991, 0.6806640625], [507, 877, 557, 992, 0.67919921875], [507, 877, 557, 991, 0.6806640625], [507, 877, 557, 991, 0.689453125], [506, 877, 557, 992, 0.68505859375], [506, 878, 556, 993, 0.68994140625], [506, 877, 556, 993, 0.693359375], [506, 878, 556, 993, 0.69140625], [505, 878, 556, 993, 0.69384765625], [505, 878, 555, 993, 0.69921875], [505, 879, 555, 994, 0.703125], [504, 879, 554, 994, 0.70166015625], [504, 879, 554, 994, 0.70068359375], [503, 880, 553, 994, 0.69580078125], [503, 880, 553, 994, 0.6953125], [502, 881, 552, 995, 0.69384765625], [501, 882, 552, 996, 0.69189453125]]\n",
      "Key: Kc, vector len: 6, Card Detections: [[141, 817, 196, 936, 0.697265625], [140, 819, 195, 937, 0.69384765625], [140, 820, 195, 938, 0.6865234375], [140, 820, 196, 939, 0.68212890625], [140, 822, 196, 940, 0.68505859375], [139, 823, 195, 942, 0.68310546875]]\n",
      "Key: Kd, vector len: 10, Card Detections: [[507, 874, 557, 983, 0.6484375], [506, 873, 557, 983, 0.64501953125], [506, 875, 557, 985, 0.650390625], [507, 874, 557, 985, 0.654296875], [507, 874, 557, 985, 0.654296875], [507, 874, 557, 985, 0.6572265625], [507, 874, 557, 985, 0.65673828125], [506, 874, 556, 985, 0.6484375], [505, 874, 555, 984, 0.6435546875], [151, 813, 210, 969, 0.50048828125]]\n",
      "Key: Kh, vector len: 11, Card Detections: [[150, 814, 203, 934, 0.65478515625], [151, 814, 203, 929, 0.65966796875], [151, 814, 202, 929, 0.65576171875], [151, 814, 203, 929, 0.65869140625], [151, 814, 203, 930, 0.66015625], [151, 817, 203, 931, 0.65380859375], [152, 817, 203, 931, 0.65185546875], [152, 817, 203, 931, 0.65478515625], [152, 817, 203, 932, 0.64990234375], [152, 817, 203, 931, 0.640625], [156, 820, 209, 937, 0.611328125]]\n",
      "Key: Ks, vector len: 6, Card Detections: [[153, 813, 209, 934, 0.67138671875], [154, 813, 208, 933, 0.6728515625], [154, 813, 208, 933, 0.67236328125], [155, 813, 209, 933, 0.66845703125], [155, 814, 210, 934, 0.6689453125], [159, 816, 213, 937, 0.64501953125]]\n",
      "Key: Qc, vector len: 19, Card Detections: [[132, 827, 185, 943, 0.63134765625], [131, 828, 185, 946, 0.6025390625], [131, 829, 185, 945, 0.5888671875], [131, 829, 186, 945, 0.60498046875], [132, 830, 185, 946, 0.55224609375], [132, 830, 185, 947, 0.57666015625], [131, 831, 185, 948, 0.587890625], [131, 831, 185, 948, 0.599609375], [131, 832, 185, 949, 0.61328125], [131, 832, 184, 950, 0.6142578125], [131, 832, 184, 950, 0.62109375], [131, 832, 184, 950, 0.61865234375], [131, 832, 184, 950, 0.62255859375], [130, 831, 183, 950, 0.62158203125], [130, 831, 183, 950, 0.61767578125], [129, 831, 183, 950, 0.61572265625], [129, 831, 183, 950, 0.6181640625], [130, 832, 183, 951, 0.611328125], [130, 834, 183, 952, 0.6083984375]]\n",
      "Key: Qd, vector len: 5, Card Detections: [[164, 843, 220, 991, 0.53125], [165, 842, 217, 957, 0.61328125], [166, 842, 216, 955, 0.60693359375], [166, 841, 218, 956, 0.60986328125], [169, 841, 227, 963, 0.57666015625]]\n",
      "Key: Qh, vector len: 48, Card Detections: [[502, 887, 552, 998, 0.56201171875], [502, 889, 551, 1000, 0.6201171875], [502, 889, 551, 1000, 0.63330078125], [502, 888, 551, 1000, 0.6396484375], [502, 888, 551, 1000, 0.6416015625], [502, 888, 551, 999, 0.60498046875], [502, 888, 551, 999, 0.62548828125], [502, 888, 551, 1000, 0.630859375], [502, 888, 551, 1000, 0.63330078125], [502, 888, 551, 999, 0.580078125], [502, 888, 551, 999, 0.56787109375], [502, 888, 551, 1000, 0.5419921875], [502, 888, 551, 1000, 0.54296875], [502, 888, 551, 1000, 0.5322265625], [502, 888, 551, 1000, 0.56005859375], [502, 888, 551, 1000, 0.5966796875], [502, 888, 551, 1000, 0.63232421875], [502, 888, 551, 1000, 0.62646484375], [502, 888, 551, 1000, 0.630859375], [502, 888, 551, 1000, 0.63037109375], [502, 888, 551, 1000, 0.63330078125], [502, 889, 551, 1001, 0.6328125], [502, 889, 551, 1000, 0.55908203125], [502, 889, 551, 1001, 0.5166015625], [502, 889, 550, 1001, 0.54052734375], [502, 889, 550, 1001, 0.5859375], [502, 889, 550, 1001, 0.6162109375], [501, 889, 550, 1001, 0.60693359375], [502, 889, 550, 1002, 0.60986328125], [501, 890, 549, 1001, 0.6171875], [501, 890, 549, 1001, 0.6337890625], [501, 890, 549, 1001, 0.6328125], [501, 890, 549, 1001, 0.64111328125], [501, 890, 549, 1001, 0.6337890625], [501, 890, 549, 1001, 0.642578125], [501, 889, 549, 1002, 0.6015625], [501, 889, 549, 1002, 0.60888671875], [500, 891, 549, 1001, 0.6005859375], [500, 889, 550, 1003, 0.56103515625], [498, 889, 549, 1002, 0.51904296875], [499, 889, 549, 1002, 0.53076171875], [499, 889, 549, 1002, 0.53173828125], [498, 889, 549, 1002, 0.5224609375], [498, 890, 548, 1001, 0.5771484375], [498, 890, 549, 1002, 0.52978515625], [498, 890, 548, 1002, 0.5244140625], [496, 893, 547, 1002, 0.58447265625], [492, 895, 543, 1006, 0.62744140625]]\n",
      "Key: Qs, vector len: 10, Card Detections: [[510, 872, 559, 984, 0.58056640625], [511, 872, 558, 985, 0.64453125], [511, 873, 559, 986, 0.603515625], [511, 873, 559, 986, 0.54296875], [510, 873, 559, 986, 0.6162109375], [510, 874, 558, 987, 0.6318359375], [510, 873, 558, 986, 0.650390625], [509, 873, 558, 987, 0.6142578125], [508, 875, 557, 986, 0.6591796875], [508, 875, 557, 987, 0.65185546875]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 0, Card Detections: []\n",
      "Key: Tc, vector len: 7, Card Detections: [[44, 891, 99, 1001, 0.6201171875], [45, 890, 100, 1003, 0.65966796875], [45, 889, 100, 1004, 0.66064453125], [45, 889, 99, 1003, 0.64990234375], [44, 889, 99, 1003, 0.65087890625], [44, 889, 98, 1002, 0.64892578125], [44, 893, 99, 1005, 0.64892578125]]\n",
      "Key: Td, vector len: 11, Card Detections: [[407, 868, 460, 984, 0.65234375], [407, 870, 458, 980, 0.6796875], [407, 870, 458, 981, 0.685546875], [408, 870, 458, 983, 0.67822265625], [407, 869, 458, 983, 0.68115234375], [408, 870, 457, 983, 0.67919921875], [407, 871, 457, 984, 0.67578125], [408, 871, 457, 983, 0.6669921875], [408, 871, 457, 983, 0.68115234375], [408, 872, 457, 983, 0.68359375], [406, 875, 456, 985, 0.669921875]]\n",
      "Key: Th, vector len: 66, Card Detections: [[6, 877, 60, 991, 0.6181640625], [7, 877, 60, 991, 0.62939453125], [6, 877, 60, 991, 0.63037109375], [6, 877, 60, 992, 0.640625], [6, 878, 60, 993, 0.640625], [6, 879, 60, 994, 0.64013671875], [6, 879, 60, 994, 0.638671875], [6, 879, 60, 994, 0.63671875], [6, 879, 60, 994, 0.6396484375], [6, 879, 60, 994, 0.6396484375], [6, 879, 60, 994, 0.64208984375], [7, 879, 60, 994, 0.64208984375], [7, 879, 61, 994, 0.64306640625], [7, 878, 61, 994, 0.6435546875], [7, 878, 61, 994, 0.6455078125], [7, 878, 61, 994, 0.6455078125], [7, 878, 61, 994, 0.64599609375], [8, 877, 61, 993, 0.64501953125], [8, 877, 61, 993, 0.64599609375], [8, 877, 61, 993, 0.64453125], [8, 876, 61, 992, 0.64013671875], [8, 876, 61, 992, 0.64013671875], [8, 876, 61, 992, 0.64111328125], [8, 876, 61, 992, 0.64013671875], [8, 876, 61, 992, 0.640625], [8, 876, 62, 992, 0.6396484375], [9, 876, 62, 992, 0.6376953125], [9, 875, 62, 992, 0.63525390625], [9, 875, 62, 992, 0.63330078125], [9, 875, 62, 991, 0.63037109375], [9, 875, 62, 991, 0.626953125], [9, 875, 62, 991, 0.6240234375], [9, 874, 63, 991, 0.6240234375], [9, 874, 63, 991, 0.6220703125], [9, 874, 63, 990, 0.623046875], [9, 874, 63, 990, 0.62255859375], [9, 874, 63, 990, 0.61767578125], [10, 873, 63, 989, 0.61572265625], [10, 873, 63, 989, 0.62158203125], [10, 873, 63, 989, 0.61962890625], [10, 872, 63, 988, 0.61376953125], [10, 872, 63, 988, 0.61572265625], [10, 872, 63, 987, 0.6025390625], [10, 871, 63, 987, 0.6064453125], [10, 870, 63, 986, 0.61181640625], [10, 870, 63, 986, 0.6181640625], [10, 870, 63, 986, 0.61865234375], [10, 869, 63, 986, 0.61865234375], [10, 869, 63, 985, 0.62109375], [10, 869, 63, 985, 0.62060546875], [10, 869, 63, 985, 0.6201171875], [10, 869, 63, 985, 0.6171875], [10, 869, 63, 986, 0.615234375], [10, 870, 63, 985, 0.6220703125], [10, 869, 63, 985, 0.62353515625], [10, 869, 63, 985, 0.6201171875], [10, 869, 63, 985, 0.611328125], [10, 869, 63, 985, 0.6044921875], [11, 869, 63, 985, 0.60009765625], [11, 869, 64, 985, 0.59619140625], [11, 869, 64, 985, 0.59912109375], [11, 869, 64, 985, 0.59814453125], [11, 869, 64, 985, 0.5908203125], [11, 869, 64, 985, 0.59130859375], [11, 870, 65, 984, 0.6025390625], [13, 875, 65, 987, 0.6083984375]]\n",
      "Key: Ts, vector len: 62, Card Detections: [[8, 870, 60, 987, 0.62841796875], [7, 870, 60, 989, 0.6240234375], [6, 870, 60, 990, 0.6220703125], [7, 870, 61, 989, 0.63134765625], [7, 871, 61, 990, 0.64453125], [7, 871, 61, 990, 0.64990234375], [6, 871, 61, 991, 0.6513671875], [6, 872, 61, 991, 0.650390625], [7, 871, 61, 990, 0.6435546875], [7, 870, 61, 990, 0.6396484375], [7, 870, 61, 989, 0.62939453125], [7, 870, 61, 989, 0.6259765625], [7, 869, 61, 989, 0.62939453125], [7, 868, 61, 988, 0.6337890625], [7, 868, 61, 988, 0.63623046875], [7, 868, 61, 988, 0.63623046875], [7, 868, 61, 988, 0.6357421875], [7, 867, 61, 988, 0.63671875], [7, 867, 61, 988, 0.63720703125], [7, 867, 61, 988, 0.6376953125], [7, 868, 61, 988, 0.63623046875], [7, 868, 61, 988, 0.6357421875], [7, 868, 61, 989, 0.63037109375], [7, 868, 61, 989, 0.6298828125], [7, 868, 61, 989, 0.63037109375], [7, 868, 61, 989, 0.62939453125], [7, 868, 61, 989, 0.6279296875], [8, 869, 61, 989, 0.62451171875], [8, 869, 61, 989, 0.6240234375], [8, 869, 62, 990, 0.62060546875], [8, 869, 62, 990, 0.61865234375], [8, 870, 62, 990, 0.6171875], [9, 870, 62, 989, 0.6123046875], [9, 871, 62, 990, 0.61767578125], [8, 871, 62, 990, 0.6318359375], [8, 871, 62, 990, 0.63134765625], [8, 871, 62, 990, 0.6328125], [8, 871, 62, 990, 0.6328125], [8, 871, 62, 990, 0.63037109375], [8, 871, 62, 990, 0.62939453125], [9, 871, 62, 989, 0.6220703125], [9, 871, 62, 989, 0.61962890625], [9, 871, 62, 989, 0.6181640625], [9, 871, 62, 989, 0.6171875], [9, 871, 62, 989, 0.62060546875], [9, 871, 62, 989, 0.61865234375], [9, 871, 62, 989, 0.6240234375], [9, 872, 62, 990, 0.62939453125], [9, 872, 62, 990, 0.6298828125], [9, 872, 62, 990, 0.634765625], [9, 873, 62, 991, 0.64013671875], [9, 873, 62, 991, 0.64013671875], [9, 874, 62, 991, 0.638671875], [9, 875, 62, 991, 0.63623046875], [9, 875, 62, 991, 0.6357421875], [10, 876, 62, 991, 0.63330078125], [10, 877, 62, 991, 0.6337890625], [10, 877, 63, 991, 0.6328125], [10, 878, 62, 991, 0.6328125], [10, 880, 62, 992, 0.6328125], [10, 881, 63, 992, 0.640625], [10, 890, 63, 996, 0.64111328125]]\n",
      "Key: 2c, vector len: 7, Card Detections: [[400, 876, 455, 987, 0.6787109375], [400, 876, 455, 988, 0.66357421875], [400, 876, 455, 988, 0.65966796875], [401, 875, 455, 988, 0.650390625], [401, 875, 455, 988, 0.638671875], [401, 876, 455, 988, 0.669921875], [400, 877, 454, 988, 0.6611328125]]\n",
      "Key: 2d, vector len: 6, Card Detections: [[406, 873, 456, 984, 0.642578125], [406, 874, 456, 984, 0.64111328125], [406, 874, 456, 985, 0.6484375], [406, 875, 456, 985, 0.64794921875], [405, 876, 455, 984, 0.6435546875], [403, 877, 454, 983, 0.63427734375]]\n",
      "Key: 2h, vector len: 30, Card Detections: [[410, 885, 466, 979, 0.52587890625], [413, 887, 464, 1002, 0.5859375], [412, 887, 464, 1003, 0.58740234375], [412, 889, 464, 1004, 0.59033203125], [412, 890, 464, 1004, 0.58642578125], [412, 890, 464, 1004, 0.59130859375], [412, 890, 463, 1005, 0.59228515625], [412, 890, 463, 1005, 0.59228515625], [412, 890, 463, 1005, 0.58984375], [412, 890, 463, 1005, 0.59033203125], [412, 890, 463, 1005, 0.59814453125], [412, 891, 463, 1005, 0.595703125], [411, 891, 463, 1005, 0.59521484375], [411, 891, 463, 1005, 0.5966796875], [411, 891, 463, 1005, 0.6015625], [411, 891, 463, 1005, 0.60546875], [411, 891, 463, 1005, 0.59912109375], [411, 891, 463, 1005, 0.6015625], [411, 891, 463, 1006, 0.6015625], [411, 891, 463, 1006, 0.6005859375], [411, 892, 463, 1006, 0.6044921875], [411, 892, 463, 1006, 0.6103515625], [411, 892, 463, 1006, 0.611328125], [411, 892, 463, 1006, 0.60986328125], [411, 892, 462, 1006, 0.61083984375], [411, 892, 463, 1007, 0.61474609375], [410, 893, 462, 1007, 0.62255859375], [410, 893, 462, 1008, 0.62646484375], [410, 894, 462, 1008, 0.6298828125], [405, 897, 458, 1012, 0.6337890625]]\n",
      "Key: 2s, vector len: 29, Card Detections: [[392, 886, 453, 994, 0.626953125], [9, 856, 63, 976, 0.66259765625], [9, 857, 62, 977, 0.65234375], [9, 858, 62, 978, 0.66015625], [9, 858, 62, 978, 0.65869140625], [9, 858, 62, 979, 0.658203125], [9, 860, 62, 979, 0.662109375], [9, 860, 62, 980, 0.6650390625], [9, 861, 62, 981, 0.6669921875], [9, 861, 62, 981, 0.66845703125], [9, 861, 62, 981, 0.6689453125], [9, 861, 62, 981, 0.66943359375], [9, 861, 62, 981, 0.6728515625], [9, 861, 62, 981, 0.6748046875], [9, 861, 62, 981, 0.67626953125], [10, 861, 62, 981, 0.67626953125], [10, 861, 63, 981, 0.6806640625], [10, 862, 63, 982, 0.6845703125], [10, 863, 63, 982, 0.68603515625], [10, 863, 63, 983, 0.68603515625], [10, 864, 63, 983, 0.6865234375], [10, 865, 63, 983, 0.685546875], [10, 866, 63, 984, 0.681640625], [10, 866, 63, 984, 0.671875], [10, 867, 64, 985, 0.66650390625], [11, 868, 64, 986, 0.66455078125], [11, 869, 64, 986, 0.66650390625], [11, 873, 64, 989, 0.65478515625], [12, 876, 64, 991, 0.65478515625]]\n",
      "Key: 3c, vector len: 20, Card Detections: [[411, 873, 467, 991, 0.63671875], [412, 874, 466, 991, 0.5703125], [412, 875, 466, 991, 0.6357421875], [412, 875, 466, 993, 0.64013671875], [411, 875, 466, 993, 0.64697265625], [411, 875, 466, 993, 0.6474609375], [411, 874, 466, 993, 0.6533203125], [411, 875, 465, 993, 0.6455078125], [411, 874, 465, 994, 0.66455078125], [411, 875, 465, 994, 0.6494140625], [411, 874, 465, 994, 0.65869140625], [411, 874, 465, 993, 0.6650390625], [411, 874, 465, 994, 0.66552734375], [411, 874, 465, 994, 0.67041015625], [410, 876, 465, 994, 0.67041015625], [411, 874, 464, 994, 0.673828125], [411, 874, 464, 995, 0.67333984375], [410, 875, 464, 996, 0.65478515625], [410, 875, 464, 996, 0.65771484375], [410, 878, 464, 995, 0.66259765625]]\n",
      "Key: 3d, vector len: 6, Card Detections: [[401, 877, 455, 988, 0.64208984375], [401, 877, 455, 988, 0.65234375], [401, 877, 455, 988, 0.65185546875], [401, 877, 455, 988, 0.65283203125], [402, 876, 454, 988, 0.64892578125], [400, 879, 452, 990, 0.6513671875]]\n",
      "Key: 3h, vector len: 8, Card Detections: [[43, 875, 100, 995, 0.5859375], [43, 877, 98, 995, 0.59326171875], [43, 876, 98, 994, 0.59912109375], [43, 877, 99, 995, 0.5966796875], [43, 877, 99, 995, 0.59521484375], [42, 877, 98, 994, 0.5966796875], [42, 877, 98, 994, 0.59814453125], [42, 878, 99, 994, 0.60498046875]]\n",
      "Key: 3s, vector len: 8, Card Detections: [[36, 867, 95, 986, 0.6484375], [36, 867, 94, 986, 0.642578125], [35, 866, 94, 986, 0.64794921875], [36, 866, 94, 985, 0.6474609375], [36, 865, 94, 984, 0.654296875], [36, 866, 94, 984, 0.64794921875], [36, 866, 94, 984, 0.64990234375], [36, 866, 97, 998, 0.6279296875]]\n",
      "Key: 4c, vector len: 8, Card Detections: [[26, 858, 165, 981, 0.642578125], [29, 856, 159, 981, 0.63916015625], [30, 857, 159, 981, 0.642578125], [28, 856, 164, 982, 0.640625], [28, 856, 166, 982, 0.642578125], [27, 856, 166, 982, 0.6416015625], [30, 857, 159, 981, 0.64111328125], [30, 857, 160, 981, 0.64111328125]]\n",
      "Key: 4d, vector len: 7, Card Detections: [[28, 847, 150, 994, 0.55029296875], [28, 847, 146, 970, 0.6337890625], [28, 847, 146, 971, 0.63330078125], [28, 847, 146, 970, 0.63525390625], [29, 847, 146, 970, 0.63525390625], [29, 848, 147, 971, 0.62890625], [30, 855, 148, 974, 0.619140625]]\n",
      "Key: 4h, vector len: 6, Card Detections: [[407, 871, 516, 966, 0.53564453125], [406, 871, 513, 989, 0.64453125], [406, 871, 513, 989, 0.6435546875], [406, 871, 513, 990, 0.64404296875], [405, 871, 512, 990, 0.6455078125], [401, 876, 511, 991, 0.64501953125]]\n",
      "Key: 4s, vector len: 15, Card Detections: [[411, 870, 515, 996, 0.61669921875], [411, 870, 515, 996, 0.6171875], [410, 870, 516, 998, 0.62353515625], [410, 868, 515, 997, 0.61669921875], [410, 870, 514, 997, 0.6201171875], [410, 870, 515, 998, 0.625], [410, 870, 515, 998, 0.625], [410, 871, 515, 998, 0.62548828125], [410, 871, 515, 998, 0.6240234375], [410, 871, 515, 998, 0.6240234375], [410, 871, 514, 998, 0.62353515625], [409, 871, 514, 999, 0.62646484375], [409, 871, 514, 999, 0.62255859375], [409, 870, 514, 1000, 0.6220703125], [402, 880, 513, 1003, 0.61767578125]]\n",
      "Key: 5c, vector len: 19, Card Detections: [[410, 869, 462, 987, 0.63623046875], [410, 871, 463, 989, 0.66796875], [410, 870, 462, 991, 0.64990234375], [410, 871, 462, 988, 0.64990234375], [410, 871, 461, 991, 0.6337890625], [410, 871, 462, 989, 0.6533203125], [410, 871, 462, 989, 0.64306640625], [410, 871, 462, 989, 0.640625], [410, 871, 462, 989, 0.63818359375], [410, 871, 461, 991, 0.630859375], [410, 872, 461, 992, 0.62109375], [410, 872, 462, 990, 0.64208984375], [410, 872, 462, 990, 0.6474609375], [409, 872, 462, 992, 0.61572265625], [410, 872, 462, 991, 0.63916015625], [410, 873, 462, 991, 0.63818359375], [410, 873, 462, 991, 0.64306640625], [409, 873, 462, 992, 0.666015625], [409, 873, 461, 993, 0.62060546875]]\n",
      "Key: 5d, vector len: 20, Card Detections: [[20, 842, 76, 965, 0.64501953125], [20, 842, 72, 960, 0.62451171875], [20, 843, 71, 962, 0.6015625], [19, 844, 71, 963, 0.6103515625], [19, 844, 70, 963, 0.5986328125], [18, 845, 70, 964, 0.60400390625], [18, 845, 69, 965, 0.59912109375], [18, 845, 69, 965, 0.6025390625], [18, 846, 68, 968, 0.59814453125], [17, 846, 68, 968, 0.60693359375], [17, 846, 67, 968, 0.60888671875], [17, 847, 68, 969, 0.60791015625], [17, 848, 68, 969, 0.60546875], [17, 848, 68, 970, 0.587890625], [17, 848, 68, 970, 0.583984375], [16, 848, 68, 970, 0.5830078125], [16, 849, 68, 970, 0.568359375], [16, 849, 68, 971, 0.57666015625], [16, 849, 68, 972, 0.52587890625], [17, 853, 69, 974, 0.587890625]]\n",
      "Key: 5h, vector len: 14, Card Detections: [[27, 840, 84, 983, 0.57421875], [27, 839, 78, 958, 0.654296875], [26, 840, 77, 960, 0.65380859375], [26, 839, 78, 959, 0.66162109375], [26, 839, 77, 961, 0.64111328125], [26, 840, 76, 961, 0.63623046875], [25, 841, 76, 963, 0.64306640625], [25, 842, 76, 962, 0.64404296875], [24, 842, 76, 962, 0.64453125], [24, 842, 76, 962, 0.6474609375], [24, 842, 76, 962, 0.64892578125], [24, 842, 76, 962, 0.65380859375], [24, 843, 76, 964, 0.6474609375], [24, 844, 76, 965, 0.6494140625]]\n",
      "Key: 5s, vector len: 15, Card Detections: [[411, 868, 460, 988, 0.669921875], [410, 870, 461, 986, 0.68115234375], [411, 869, 460, 989, 0.6796875], [410, 869, 461, 989, 0.67724609375], [410, 871, 461, 987, 0.677734375], [410, 871, 460, 990, 0.67529296875], [410, 870, 460, 991, 0.6787109375], [410, 870, 460, 988, 0.68603515625], [410, 870, 460, 988, 0.68310546875], [410, 871, 460, 988, 0.68115234375], [410, 871, 460, 989, 0.671875], [409, 871, 459, 991, 0.666015625], [409, 871, 459, 991, 0.6591796875], [409, 871, 459, 991, 0.66455078125], [408, 872, 458, 991, 0.65478515625]]\n",
      "Key: 6c, vector len: 17, Card Detections: [[413, 875, 465, 990, 0.65966796875], [413, 876, 464, 992, 0.65869140625], [413, 875, 464, 991, 0.658203125], [413, 876, 464, 991, 0.65966796875], [413, 876, 464, 992, 0.66015625], [413, 876, 464, 992, 0.66015625], [413, 876, 464, 993, 0.662109375], [413, 876, 464, 993, 0.6630859375], [413, 875, 464, 994, 0.6650390625], [412, 875, 464, 993, 0.6650390625], [412, 876, 464, 994, 0.6611328125], [412, 876, 464, 995, 0.6591796875], [412, 876, 464, 995, 0.6591796875], [411, 875, 464, 995, 0.67578125], [411, 876, 464, 998, 0.67431640625], [411, 877, 463, 998, 0.673828125], [411, 877, 463, 998, 0.67431640625]]\n",
      "Key: 6d, vector len: 8, Card Detections: [[406, 871, 457, 985, 0.63916015625], [406, 871, 456, 984, 0.6318359375], [406, 872, 456, 983, 0.66455078125], [406, 871, 456, 986, 0.64404296875], [406, 872, 456, 984, 0.67919921875], [406, 873, 456, 985, 0.66650390625], [406, 874, 456, 986, 0.66064453125], [405, 876, 455, 986, 0.65673828125]]\n",
      "Key: 6h, vector len: 8, Card Detections: [[30, 834, 80, 953, 0.630859375], [30, 833, 80, 953, 0.6328125], [30, 834, 81, 955, 0.63427734375], [30, 835, 81, 955, 0.64013671875], [30, 837, 81, 955, 0.642578125], [30, 838, 81, 956, 0.64208984375], [30, 839, 81, 957, 0.6416015625], [31, 845, 84, 963, 0.6357421875]]\n",
      "Key: 6s, vector len: 6, Card Detections: [[39, 873, 94, 999, 0.5361328125], [41, 873, 93, 992, 0.6328125], [41, 873, 93, 992, 0.62255859375], [41, 873, 93, 992, 0.63671875], [40, 873, 93, 991, 0.64111328125], [41, 873, 93, 991, 0.6484375]]\n",
      "Key: 7c, vector len: 12, Card Detections: [[28, 836, 80, 959, 0.6533203125], [27, 835, 80, 958, 0.64306640625], [28, 836, 80, 960, 0.6572265625], [28, 837, 80, 960, 0.65283203125], [28, 837, 80, 960, 0.65234375], [28, 838, 80, 960, 0.650390625], [28, 838, 80, 960, 0.650390625], [28, 838, 81, 961, 0.65234375], [29, 839, 81, 961, 0.6513671875], [29, 839, 81, 961, 0.6494140625], [29, 840, 82, 962, 0.64697265625], [31, 843, 83, 965, 0.65673828125]]\n",
      "Key: 7d, vector len: 8, Card Detections: [[399, 881, 448, 991, 0.6220703125], [399, 882, 447, 991, 0.61572265625], [400, 882, 448, 992, 0.61962890625], [399, 882, 447, 992, 0.62744140625], [399, 881, 447, 992, 0.63037109375], [398, 881, 447, 991, 0.63232421875], [398, 882, 446, 990, 0.6357421875], [392, 894, 443, 1000, 0.623046875]]\n",
      "Key: 7h, vector len: 7, Card Detections: [[403, 869, 458, 969, 0.61474609375], [403, 871, 455, 986, 0.6845703125], [404, 872, 455, 987, 0.6689453125], [403, 870, 455, 987, 0.65576171875], [404, 872, 455, 988, 0.68896484375], [402, 872, 453, 987, 0.68017578125], [401, 875, 453, 990, 0.66650390625]]\n",
      "Key: 7s, vector len: 5, Card Detections: [[36, 871, 90, 991, 0.6630859375], [36, 871, 89, 991, 0.66162109375], [36, 870, 90, 991, 0.66455078125], [35, 870, 90, 990, 0.6669921875], [37, 872, 91, 991, 0.6630859375]]\n",
      "Key: 8c, vector len: 8, Card Detections: [[28, 838, 82, 958, 0.64208984375], [28, 838, 81, 957, 0.634765625], [29, 839, 81, 957, 0.63671875], [29, 839, 82, 959, 0.642578125], [30, 839, 83, 958, 0.638671875], [30, 839, 83, 959, 0.640625], [30, 839, 83, 960, 0.6435546875], [31, 839, 87, 978, 0.5380859375]]\n",
      "Key: 8d, vector len: 16, Card Detections: [[415, 876, 464, 989, 0.68359375], [415, 876, 465, 991, 0.6884765625], [415, 876, 465, 992, 0.677734375], [416, 877, 464, 992, 0.6826171875], [416, 877, 464, 992, 0.6875], [416, 877, 464, 993, 0.6875], [415, 877, 465, 992, 0.6904296875], [416, 877, 465, 992, 0.69091796875], [416, 877, 464, 993, 0.69189453125], [415, 877, 464, 993, 0.6904296875], [415, 877, 464, 993, 0.6904296875], [416, 877, 464, 994, 0.69140625], [415, 877, 464, 994, 0.6953125], [415, 877, 464, 994, 0.69384765625], [415, 878, 464, 994, 0.69677734375], [415, 878, 463, 994, 0.69921875]]\n",
      "Key: 8h, vector len: 13, Card Detections: [[407, 873, 457, 986, 0.65234375], [408, 873, 457, 983, 0.65087890625], [408, 874, 457, 986, 0.6591796875], [407, 873, 458, 987, 0.673828125], [407, 875, 457, 985, 0.65625], [407, 875, 457, 986, 0.65625], [407, 874, 457, 987, 0.66259765625], [407, 875, 457, 986, 0.66259765625], [407, 874, 457, 987, 0.66259765625], [407, 874, 457, 988, 0.65771484375], [407, 874, 457, 988, 0.66455078125], [407, 874, 457, 988, 0.65966796875], [405, 876, 456, 989, 0.6552734375]]\n",
      "Key: 8s, vector len: 40, Card Detections: [[417, 876, 466, 994, 0.6220703125], [417, 876, 466, 995, 0.62744140625], [417, 876, 466, 995, 0.62548828125], [417, 877, 466, 995, 0.62841796875], [417, 877, 466, 996, 0.6279296875], [417, 877, 466, 996, 0.62939453125], [417, 877, 466, 996, 0.62841796875], [417, 877, 466, 996, 0.62548828125], [417, 877, 466, 996, 0.623046875], [417, 878, 466, 997, 0.62451171875], [417, 878, 466, 997, 0.6201171875], [417, 878, 466, 997, 0.62353515625], [417, 878, 465, 997, 0.62353515625], [416, 878, 465, 997, 0.6220703125], [416, 878, 465, 998, 0.625], [417, 878, 465, 998, 0.62548828125], [416, 878, 465, 998, 0.6220703125], [416, 878, 465, 999, 0.62255859375], [416, 878, 465, 998, 0.61962890625], [416, 878, 465, 999, 0.6201171875], [416, 878, 465, 999, 0.61865234375], [416, 879, 465, 999, 0.625], [416, 879, 465, 999, 0.6259765625], [416, 879, 465, 999, 0.6259765625], [416, 879, 465, 999, 0.625], [416, 879, 465, 999, 0.62548828125], [416, 879, 465, 999, 0.62646484375], [416, 879, 465, 999, 0.62548828125], [415, 879, 465, 1000, 0.62255859375], [415, 880, 465, 1000, 0.6220703125], [415, 880, 464, 1000, 0.6220703125], [415, 880, 464, 1000, 0.62109375], [415, 880, 464, 1000, 0.62255859375], [415, 880, 464, 1000, 0.6220703125], [415, 881, 464, 1000, 0.6240234375], [415, 881, 464, 1000, 0.6240234375], [414, 881, 463, 1001, 0.62890625], [414, 882, 463, 1001, 0.62939453125], [414, 882, 463, 1001, 0.62890625], [413, 885, 462, 1003, 0.62841796875]]\n",
      "Key: 9c, vector len: 7, Card Detections: [[32, 861, 85, 980, 0.66259765625], [33, 861, 85, 978, 0.642578125], [32, 861, 85, 981, 0.64990234375], [32, 861, 85, 981, 0.65625], [32, 861, 85, 981, 0.64501953125], [33, 861, 85, 980, 0.64599609375], [33, 864, 86, 981, 0.64892578125]]\n",
      "Key: 9d, vector len: 5, Card Detections: [[401, 882, 451, 991, 0.60595703125], [402, 880, 450, 989, 0.611328125], [402, 880, 450, 989, 0.61474609375], [402, 882, 450, 991, 0.61083984375], [400, 885, 449, 992, 0.607421875]]\n",
      "Key: 9h, vector len: 9, Card Detections: [[403, 874, 454, 985, 0.62548828125], [404, 874, 454, 984, 0.62890625], [404, 874, 454, 984, 0.630859375], [404, 874, 454, 984, 0.63037109375], [404, 874, 454, 985, 0.62841796875], [404, 873, 454, 986, 0.63720703125], [404, 874, 454, 986, 0.63037109375], [404, 874, 454, 985, 0.63037109375], [402, 878, 451, 986, 0.654296875]]\n",
      "Key: 9s, vector len: 303, Card Detections: [[0, 906, 38, 1022, 0.60595703125], [0, 905, 53, 1021, 0.62548828125], [19, 905, 72, 1018, 0.63037109375], [35, 902, 89, 1015, 0.6728515625], [37, 902, 91, 1014, 0.67529296875], [38, 903, 93, 1014, 0.66748046875], [40, 903, 94, 1014, 0.65087890625], [42, 903, 96, 1014, 0.65478515625], [44, 902, 97, 1013, 0.62744140625], [45, 902, 99, 1013, 0.60693359375], [47, 902, 100, 1013, 0.6171875], [49, 903, 102, 1013, 0.61279296875], [51, 903, 103, 1013, 0.6181640625], [53, 904, 105, 1013, 0.61572265625], [55, 904, 107, 1013, 0.62646484375], [56, 904, 109, 1013, 0.6279296875], [58, 905, 110, 1013, 0.62060546875], [59, 905, 112, 1013, 0.63671875], [61, 905, 114, 1013, 0.6474609375], [63, 904, 116, 1013, 0.640625], [66, 904, 119, 1013, 0.66259765625], [67, 904, 120, 1013, 0.66357421875], [68, 904, 121, 1013, 0.66064453125], [69, 904, 123, 1013, 0.6591796875], [70, 904, 124, 1013, 0.65087890625], [72, 904, 125, 1013, 0.65185546875], [73, 905, 126, 1012, 0.65185546875], [74, 904, 127, 1012, 0.6513671875], [75, 904, 128, 1012, 0.64453125], [75, 904, 128, 1012, 0.64111328125], [76, 904, 129, 1011, 0.63623046875], [77, 903, 130, 1011, 0.63671875], [78, 903, 131, 1011, 0.64111328125], [78, 903, 131, 1011, 0.642578125], [79, 903, 132, 1011, 0.64013671875], [80, 903, 133, 1011, 0.64111328125], [80, 903, 133, 1011, 0.64306640625], [81, 903, 133, 1011, 0.6474609375], [81, 903, 134, 1011, 0.646484375], [82, 903, 135, 1011, 0.650390625], [82, 903, 135, 1011, 0.6435546875], [83, 903, 136, 1011, 0.6435546875], [83, 903, 136, 1011, 0.64794921875], [83, 903, 136, 1011, 0.64208984375], [84, 903, 137, 1011, 0.6396484375], [84, 903, 137, 1011, 0.638671875], [84, 904, 137, 1011, 0.6376953125], [84, 903, 137, 1011, 0.64013671875], [84, 902, 137, 1010, 0.6376953125], [84, 903, 137, 1010, 0.6435546875], [84, 902, 137, 1010, 0.63916015625], [84, 902, 137, 1010, 0.63916015625], [84, 902, 137, 1010, 0.63916015625], [84, 902, 137, 1010, 0.63623046875], [84, 902, 137, 1010, 0.63671875], [84, 902, 137, 1010, 0.6357421875], [84, 902, 137, 1010, 0.638671875], [84, 902, 137, 1010, 0.63818359375], [84, 902, 137, 1010, 0.63720703125], [84, 902, 137, 1010, 0.63916015625], [84, 902, 137, 1010, 0.63720703125], [84, 902, 137, 1010, 0.6357421875], [84, 902, 137, 1010, 0.634765625], [84, 902, 137, 1010, 0.6328125], [84, 902, 137, 1010, 0.6328125], [84, 901, 137, 1010, 0.6328125], [84, 902, 137, 1010, 0.6328125], [84, 902, 137, 1010, 0.6328125], [84, 902, 137, 1010, 0.6357421875], [84, 901, 137, 1010, 0.634765625], [84, 901, 136, 1010, 0.63525390625], [84, 901, 136, 1010, 0.63330078125], [83, 901, 136, 1010, 0.63623046875], [83, 900, 135, 1010, 0.6337890625], [83, 900, 135, 1010, 0.62451171875], [83, 900, 135, 1010, 0.625], [83, 900, 135, 1010, 0.6201171875], [83, 900, 135, 1010, 0.62158203125], [83, 899, 135, 1010, 0.62060546875], [83, 899, 135, 1010, 0.61767578125], [83, 900, 135, 1009, 0.625], [83, 899, 135, 1009, 0.62158203125], [83, 899, 135, 1009, 0.6181640625], [82, 899, 134, 1009, 0.6103515625], [82, 899, 134, 1009, 0.6103515625], [81, 900, 133, 1009, 0.6103515625], [81, 900, 132, 1009, 0.611328125], [81, 900, 132, 1009, 0.61181640625], [81, 899, 133, 1009, 0.6103515625], [80, 899, 132, 1009, 0.609375], [80, 899, 132, 1009, 0.607421875], [80, 899, 132, 1009, 0.60791015625], [80, 898, 132, 1009, 0.607421875], [80, 898, 132, 1009, 0.609375], [79, 898, 131, 1009, 0.6103515625], [78, 899, 131, 1009, 0.615234375], [78, 898, 130, 1010, 0.6171875], [78, 898, 130, 1010, 0.6162109375], [78, 898, 130, 1009, 0.62060546875], [78, 898, 130, 1009, 0.6220703125], [78, 898, 130, 1009, 0.62109375], [78, 898, 130, 1009, 0.62158203125], [77, 898, 130, 1009, 0.6220703125], [77, 898, 130, 1009, 0.6162109375], [77, 898, 130, 1009, 0.61669921875], [78, 898, 130, 1009, 0.61572265625], [77, 898, 130, 1009, 0.619140625], [77, 898, 130, 1009, 0.61767578125], [77, 898, 130, 1009, 0.61669921875], [77, 898, 129, 1009, 0.61962890625], [76, 899, 129, 1009, 0.61962890625], [76, 899, 129, 1009, 0.62060546875], [76, 899, 129, 1008, 0.62060546875], [75, 899, 129, 1009, 0.6474609375], [75, 899, 128, 1009, 0.6435546875], [74, 899, 128, 1009, 0.65087890625], [74, 900, 127, 1009, 0.65185546875], [73, 899, 126, 1008, 0.65380859375], [73, 899, 126, 1008, 0.6552734375], [72, 899, 126, 1008, 0.65478515625], [72, 899, 126, 1008, 0.65380859375], [72, 899, 125, 1008, 0.65185546875], [72, 899, 125, 1008, 0.65234375], [72, 899, 125, 1008, 0.65380859375], [72, 899, 125, 1008, 0.65380859375], [72, 899, 125, 1008, 0.6513671875], [72, 899, 125, 1008, 0.6513671875], [72, 899, 125, 1008, 0.65087890625], [72, 899, 125, 1007, 0.6552734375], [72, 899, 125, 1007, 0.65283203125], [72, 899, 125, 1008, 0.6552734375], [72, 899, 125, 1007, 0.65576171875], [72, 899, 125, 1007, 0.6533203125], [72, 899, 125, 1007, 0.65185546875], [72, 899, 125, 1007, 0.6513671875], [72, 899, 125, 1007, 0.65234375], [72, 899, 125, 1007, 0.65478515625], [71, 899, 124, 1007, 0.65234375], [71, 899, 124, 1007, 0.6513671875], [70, 898, 124, 1007, 0.64599609375], [70, 898, 124, 1007, 0.646484375], [70, 898, 123, 1007, 0.64501953125], [69, 898, 123, 1007, 0.6435546875], [69, 898, 123, 1007, 0.64111328125], [69, 898, 122, 1007, 0.64306640625], [69, 898, 122, 1007, 0.6435546875], [69, 898, 122, 1007, 0.64306640625], [69, 898, 122, 1007, 0.64501953125], [69, 898, 122, 1008, 0.64697265625], [69, 898, 122, 1008, 0.64697265625], [69, 898, 122, 1008, 0.646484375], [69, 898, 122, 1008, 0.64794921875], [69, 898, 122, 1008, 0.64697265625], [69, 898, 122, 1008, 0.64794921875], [69, 898, 122, 1008, 0.64697265625], [69, 898, 122, 1008, 0.6455078125], [69, 898, 122, 1008, 0.64404296875], [69, 899, 122, 1008, 0.64453125], [69, 899, 122, 1008, 0.6435546875], [68, 899, 121, 1008, 0.6435546875], [68, 899, 121, 1008, 0.6376953125], [68, 899, 121, 1008, 0.6376953125], [68, 899, 120, 1008, 0.63232421875], [68, 899, 120, 1008, 0.62841796875], [67, 899, 120, 1008, 0.62744140625], [67, 899, 119, 1008, 0.626953125], [66, 900, 118, 1008, 0.62646484375], [66, 900, 118, 1008, 0.6279296875], [66, 900, 118, 1008, 0.62744140625], [66, 900, 118, 1008, 0.63037109375], [66, 900, 118, 1008, 0.62939453125], [66, 900, 118, 1008, 0.63037109375], [66, 900, 118, 1008, 0.6318359375], [66, 900, 118, 1008, 0.62890625], [66, 899, 118, 1009, 0.6494140625], [66, 900, 118, 1009, 0.6396484375], [66, 900, 118, 1009, 0.6318359375], [64, 901, 116, 1009, 0.62548828125], [64, 902, 116, 1010, 0.62890625], [63, 902, 115, 1011, 0.62890625], [62, 902, 115, 1011, 0.62646484375], [61, 903, 114, 1011, 0.6220703125], [61, 903, 114, 1011, 0.62255859375], [60, 902, 113, 1011, 0.625], [60, 902, 112, 1011, 0.62939453125], [59, 903, 111, 1011, 0.6240234375], [59, 904, 111, 1011, 0.6220703125], [58, 904, 110, 1012, 0.62255859375], [58, 904, 110, 1011, 0.62255859375], [57, 904, 109, 1011, 0.62890625], [56, 905, 109, 1012, 0.6259765625], [56, 905, 108, 1012, 0.62841796875], [55, 905, 108, 1012, 0.62890625], [56, 905, 108, 1012, 0.62939453125], [55, 905, 108, 1012, 0.6298828125], [55, 906, 108, 1012, 0.62890625], [55, 906, 108, 1013, 0.626953125], [56, 906, 108, 1012, 0.6279296875], [56, 906, 108, 1012, 0.62744140625], [56, 906, 108, 1012, 0.6376953125], [55, 906, 107, 1012, 0.6328125], [55, 906, 107, 1012, 0.63330078125], [55, 906, 108, 1012, 0.6328125], [55, 906, 108, 1012, 0.63330078125], [55, 906, 108, 1012, 0.6337890625], [55, 906, 107, 1012, 0.6337890625], [55, 906, 107, 1012, 0.634765625], [54, 906, 107, 1012, 0.63330078125], [54, 906, 106, 1012, 0.63134765625], [54, 906, 106, 1012, 0.62890625], [53, 906, 105, 1013, 0.62646484375], [53, 906, 105, 1013, 0.6240234375], [52, 906, 105, 1013, 0.62255859375], [52, 906, 104, 1013, 0.623046875], [52, 906, 104, 1013, 0.6220703125], [52, 907, 104, 1013, 0.62548828125], [51, 907, 103, 1013, 0.62646484375], [51, 907, 103, 1013, 0.62841796875], [52, 907, 103, 1013, 0.6259765625], [52, 907, 103, 1013, 0.62646484375], [52, 907, 103, 1013, 0.62841796875], [51, 907, 103, 1013, 0.62890625], [51, 907, 103, 1013, 0.6279296875], [51, 906, 103, 1013, 0.62646484375], [51, 907, 102, 1013, 0.62255859375], [50, 906, 102, 1013, 0.62060546875], [50, 906, 102, 1013, 0.61865234375], [50, 906, 102, 1013, 0.619140625], [50, 906, 102, 1013, 0.61962890625], [50, 905, 102, 1013, 0.6142578125], [49, 906, 102, 1013, 0.61474609375], [50, 905, 102, 1013, 0.61767578125], [49, 904, 102, 1013, 0.61474609375], [49, 904, 102, 1013, 0.6201171875], [49, 904, 102, 1013, 0.62255859375], [48, 905, 101, 1013, 0.61865234375], [48, 906, 101, 1013, 0.6201171875], [47, 904, 100, 1013, 0.6171875], [47, 904, 100, 1013, 0.6162109375], [47, 904, 99, 1014, 0.6162109375], [46, 905, 99, 1014, 0.61279296875], [45, 905, 99, 1014, 0.6123046875], [45, 905, 99, 1013, 0.6123046875], [45, 906, 99, 1014, 0.6123046875], [45, 906, 99, 1014, 0.6171875], [45, 907, 99, 1014, 0.61181640625], [45, 906, 99, 1014, 0.611328125], [45, 906, 99, 1013, 0.607421875], [45, 906, 99, 1013, 0.6005859375], [45, 906, 98, 1013, 0.60302734375], [45, 906, 98, 1013, 0.6015625], [45, 906, 99, 1013, 0.59814453125], [45, 906, 99, 1013, 0.599609375], [45, 906, 98, 1013, 0.59912109375], [45, 906, 98, 1013, 0.599609375], [45, 906, 98, 1013, 0.60009765625], [45, 906, 98, 1013, 0.60009765625], [45, 906, 98, 1013, 0.599609375], [45, 905, 98, 1013, 0.59326171875], [45, 905, 99, 1013, 0.60986328125], [45, 905, 99, 1013, 0.6083984375], [45, 905, 98, 1013, 0.60791015625], [45, 905, 99, 1013, 0.61083984375], [45, 905, 98, 1013, 0.60986328125], [45, 905, 98, 1013, 0.6103515625], [45, 905, 98, 1013, 0.60986328125], [45, 905, 98, 1013, 0.6103515625], [45, 904, 98, 1013, 0.60986328125], [45, 904, 98, 1013, 0.611328125], [45, 903, 98, 1012, 0.61181640625], [45, 905, 98, 1012, 0.60888671875], [45, 905, 98, 1012, 0.60791015625], [45, 904, 98, 1012, 0.60693359375], [45, 904, 99, 1012, 0.6083984375], [45, 904, 99, 1012, 0.60791015625], [45, 904, 99, 1012, 0.60986328125], [45, 904, 99, 1012, 0.60595703125], [45, 904, 99, 1012, 0.60791015625], [45, 904, 99, 1012, 0.60546875], [45, 901, 99, 1012, 0.60498046875], [45, 901, 99, 1012, 0.60546875], [45, 903, 99, 1011, 0.60546875], [45, 903, 99, 1012, 0.60595703125], [45, 903, 98, 1012, 0.60498046875], [45, 903, 98, 1012, 0.60791015625], [45, 903, 98, 1012, 0.607421875], [45, 903, 98, 1012, 0.607421875], [45, 903, 98, 1011, 0.60791015625], [45, 903, 98, 1011, 0.6064453125], [45, 903, 98, 1011, 0.60888671875], [45, 902, 98, 1011, 0.60546875], [45, 902, 98, 1010, 0.607421875], [45, 902, 99, 1010, 0.60546875], [45, 901, 99, 1010, 0.60888671875], [45, 901, 99, 1010, 0.60986328125], [45, 901, 99, 1010, 0.609375], [45, 901, 99, 1010, 0.607421875], [45, 900, 99, 1009, 0.60693359375], [45, 900, 99, 1009, 0.60546875], [45, 900, 99, 1009, 0.6064453125], [45, 900, 99, 1009, 0.607421875], [45, 900, 99, 1009, 0.6083984375], [47, 905, 99, 1010, 0.5888671875]]\n",
      "Key: Ac, vector len: 7, Card Detections: [[34, 863, 92, 985, 0.66015625], [34, 864, 90, 985, 0.658203125], [34, 864, 90, 985, 0.66162109375], [34, 863, 91, 985, 0.66064453125], [33, 862, 91, 985, 0.65771484375], [33, 863, 90, 985, 0.658203125], [33, 863, 90, 986, 0.66357421875]]\n",
      "Key: Ad, vector len: 45, Card Detections: [[407, 897, 456, 1007, 0.64013671875], [407, 897, 456, 1008, 0.6416015625], [407, 897, 456, 1009, 0.6416015625], [407, 897, 455, 1009, 0.640625], [407, 897, 455, 1009, 0.6416015625], [407, 896, 455, 1009, 0.6416015625], [407, 897, 455, 1009, 0.64013671875], [407, 897, 455, 1009, 0.638671875], [406, 897, 455, 1009, 0.63720703125], [406, 897, 455, 1009, 0.63916015625], [406, 897, 455, 1009, 0.6396484375], [406, 897, 455, 1009, 0.638671875], [406, 897, 455, 1009, 0.63818359375], [406, 897, 455, 1009, 0.6376953125], [406, 897, 455, 1009, 0.63818359375], [406, 897, 455, 1009, 0.63623046875], [406, 897, 455, 1010, 0.6318359375], [406, 897, 455, 1010, 0.63037109375], [406, 899, 455, 1010, 0.6328125], [406, 899, 455, 1010, 0.6328125], [406, 899, 455, 1010, 0.6318359375], [406, 899, 455, 1010, 0.63232421875], [404, 899, 455, 1010, 0.63037109375], [404, 898, 455, 1010, 0.6240234375], [405, 900, 455, 1010, 0.6298828125], [404, 899, 455, 1011, 0.6279296875], [404, 899, 455, 1011, 0.62841796875], [404, 899, 454, 1011, 0.62841796875], [404, 899, 454, 1011, 0.626953125], [404, 901, 454, 1011, 0.6240234375], [403, 901, 453, 1011, 0.6201171875], [403, 901, 453, 1011, 0.6220703125], [403, 902, 453, 1011, 0.6220703125], [403, 902, 453, 1011, 0.61865234375], [402, 903, 452, 1012, 0.61474609375], [402, 903, 452, 1012, 0.615234375], [402, 903, 452, 1012, 0.61572265625], [402, 904, 452, 1012, 0.61669921875], [402, 904, 452, 1012, 0.615234375], [401, 904, 452, 1012, 0.61572265625], [401, 904, 451, 1012, 0.61328125], [400, 904, 451, 1012, 0.60888671875], [400, 904, 451, 1012, 0.60205078125], [400, 904, 451, 1013, 0.6064453125], [398, 906, 449, 1013, 0.61181640625]]\n",
      "Key: Ah, vector len: 26, Card Detections: [[13, 852, 68, 972, 0.66015625], [15, 852, 66, 972, 0.65771484375], [14, 852, 65, 974, 0.65380859375], [14, 852, 66, 974, 0.65380859375], [14, 852, 66, 974, 0.650390625], [13, 852, 65, 974, 0.65673828125], [13, 852, 65, 975, 0.65869140625], [13, 853, 65, 975, 0.65234375], [13, 853, 65, 975, 0.65087890625], [12, 853, 65, 975, 0.65673828125], [12, 853, 65, 975, 0.65478515625], [12, 853, 65, 975, 0.65625], [12, 853, 65, 975, 0.6591796875], [12, 854, 65, 975, 0.65869140625], [12, 854, 65, 975, 0.65771484375], [12, 854, 65, 975, 0.662109375], [12, 854, 65, 975, 0.65966796875], [12, 855, 65, 975, 0.65576171875], [13, 855, 65, 976, 0.65771484375], [13, 856, 65, 976, 0.66015625], [13, 856, 65, 976, 0.66064453125], [13, 856, 65, 976, 0.66064453125], [13, 857, 66, 977, 0.66162109375], [13, 857, 66, 976, 0.66259765625], [13, 857, 66, 977, 0.6640625], [14, 863, 66, 978, 0.6728515625]]\n",
      "Key: As, vector len: 7, Card Detections: [[33, 866, 91, 996, 0.6103515625], [30, 844, 85, 963, 0.64208984375], [30, 845, 84, 964, 0.65087890625], [31, 845, 85, 965, 0.6572265625], [31, 844, 85, 964, 0.6591796875], [32, 844, 85, 964, 0.65185546875], [34, 843, 88, 978, 0.6572265625]]\n",
      "Key: Jc, vector len: 7, Card Detections: [[396, 886, 450, 996, 0.62890625], [396, 886, 449, 998, 0.6689453125], [397, 887, 449, 1000, 0.669921875], [397, 887, 449, 999, 0.677734375], [397, 886, 449, 999, 0.6796875], [397, 887, 449, 999, 0.68017578125], [396, 888, 449, 1000, 0.6728515625]]\n",
      "Key: Jd, vector len: 12, Card Detections: [[31, 839, 81, 957, 0.61669921875], [30, 838, 81, 954, 0.5849609375], [30, 839, 81, 956, 0.6044921875], [31, 839, 81, 956, 0.62109375], [31, 839, 81, 956, 0.62060546875], [31, 839, 81, 957, 0.623046875], [31, 839, 82, 957, 0.62158203125], [31, 840, 82, 957, 0.62451171875], [31, 840, 82, 957, 0.62744140625], [31, 839, 82, 957, 0.6171875], [31, 839, 82, 957, 0.61376953125], [30, 841, 85, 968, 0.64013671875]]\n",
      "Key: Jh, vector len: 7, Card Detections: [[29, 837, 81, 958, 0.60791015625], [28, 836, 80, 956, 0.61083984375], [28, 837, 81, 957, 0.6201171875], [29, 838, 81, 957, 0.6201171875], [29, 838, 82, 958, 0.62109375], [29, 838, 82, 958, 0.6171875], [29, 839, 82, 958, 0.6142578125]]\n",
      "Key: Js, vector len: 24, Card Detections: [[412, 877, 464, 996, 0.66748046875], [412, 878, 463, 998, 0.662109375], [412, 879, 463, 998, 0.6640625], [412, 879, 463, 998, 0.66064453125], [412, 879, 463, 998, 0.66064453125], [412, 879, 463, 998, 0.6591796875], [411, 879, 463, 998, 0.6611328125], [411, 879, 463, 998, 0.66064453125], [411, 879, 463, 998, 0.66064453125], [412, 879, 463, 998, 0.662109375], [412, 880, 463, 998, 0.662109375], [412, 880, 463, 998, 0.66162109375], [412, 880, 463, 999, 0.66259765625], [412, 880, 463, 999, 0.662109375], [411, 880, 463, 999, 0.66162109375], [411, 880, 463, 999, 0.66259765625], [411, 880, 463, 999, 0.662109375], [412, 880, 463, 999, 0.66259765625], [412, 880, 463, 999, 0.66357421875], [411, 881, 463, 999, 0.662109375], [411, 881, 463, 999, 0.65966796875], [411, 881, 463, 1000, 0.6591796875], [410, 882, 462, 1000, 0.6572265625], [410, 882, 462, 1000, 0.65673828125]]\n",
      "Key: Kc, vector len: 7, Card Detections: [[26, 837, 83, 960, 0.71826171875], [27, 837, 83, 958, 0.712890625], [27, 838, 83, 959, 0.71875], [27, 838, 83, 960, 0.72119140625], [28, 838, 84, 960, 0.6943359375], [28, 839, 84, 961, 0.69921875], [31, 847, 85, 965, 0.68115234375]]\n",
      "Key: Kd, vector len: 8, Card Detections: [[30, 849, 84, 967, 0.65576171875], [30, 849, 83, 966, 0.6513671875], [30, 849, 84, 966, 0.654296875], [30, 848, 83, 966, 0.66357421875], [30, 847, 83, 965, 0.67041015625], [30, 848, 83, 965, 0.67431640625], [30, 847, 84, 964, 0.6728515625], [31, 848, 84, 964, 0.67138671875]]\n",
      "Key: Kh, vector len: 23, Card Detections: [[413, 880, 465, 998, 0.662109375], [413, 880, 465, 999, 0.66064453125], [413, 881, 465, 999, 0.66064453125], [413, 882, 465, 1001, 0.658203125], [413, 882, 465, 1001, 0.658203125], [413, 882, 465, 1001, 0.6572265625], [412, 882, 464, 1001, 0.65283203125], [412, 882, 464, 1001, 0.65234375], [412, 883, 464, 1001, 0.64111328125], [412, 883, 464, 1003, 0.640625], [412, 883, 464, 1002, 0.64453125], [412, 883, 464, 1002, 0.64013671875], [412, 883, 464, 1002, 0.638671875], [412, 883, 464, 1002, 0.6376953125], [412, 884, 464, 1002, 0.63623046875], [412, 884, 464, 1003, 0.63525390625], [412, 884, 463, 1003, 0.63623046875], [412, 884, 463, 1003, 0.63330078125], [411, 884, 463, 1004, 0.63037109375], [411, 885, 463, 1004, 0.63037109375], [411, 885, 463, 1004, 0.630859375], [410, 886, 462, 1005, 0.6328125], [409, 888, 461, 1006, 0.63818359375]]\n",
      "Key: Ks, vector len: 325, Card Detections: [[325, 932, 389, 1042, 0.61474609375], [330, 917, 391, 1030, 0.66259765625], [333, 905, 392, 1021, 0.68017578125], [335, 899, 393, 1015, 0.6689453125], [336, 892, 393, 1010, 0.67578125], [337, 889, 393, 1007, 0.66259765625], [337, 888, 394, 1007, 0.6279296875], [337, 888, 394, 1008, 0.64501953125], [337, 887, 394, 1008, 0.615234375], [339, 886, 395, 1007, 0.58984375], [339, 886, 395, 1006, 0.5498046875], [340, 885, 396, 1005, 0.5927734375], [341, 883, 396, 1004, 0.5849609375], [341, 883, 396, 1004, 0.51904296875], [342, 882, 397, 1002, 0.63232421875], [347, 882, 402, 1001, 0.625], [356, 881, 412, 1000, 0.6435546875], [369, 880, 425, 997, 0.650390625], [384, 880, 439, 995, 0.619140625], [395, 880, 448, 994, 0.68408203125], [398, 880, 450, 994, 0.6708984375], [397, 880, 450, 994, 0.67236328125], [397, 880, 450, 994, 0.67333984375], [397, 880, 450, 994, 0.67236328125], [397, 880, 450, 994, 0.67626953125], [397, 880, 450, 995, 0.67333984375], [396, 881, 450, 994, 0.66796875], [396, 881, 450, 994, 0.6640625], [396, 881, 450, 995, 0.6513671875], [396, 881, 450, 995, 0.65283203125], [395, 882, 449, 995, 0.6484375], [395, 882, 449, 995, 0.66064453125], [395, 882, 449, 995, 0.6591796875], [395, 882, 449, 996, 0.67041015625], [395, 882, 449, 996, 0.6728515625], [395, 882, 449, 996, 0.67138671875], [395, 883, 449, 996, 0.6796875], [395, 883, 449, 996, 0.68212890625], [395, 883, 449, 996, 0.68017578125], [395, 883, 449, 996, 0.68212890625], [395, 882, 449, 996, 0.67529296875], [395, 882, 449, 996, 0.67626953125], [395, 882, 449, 996, 0.67626953125], [395, 883, 449, 996, 0.6728515625], [395, 883, 449, 996, 0.66748046875], [395, 883, 449, 995, 0.67041015625], [396, 882, 449, 995, 0.6689453125], [396, 883, 449, 994, 0.66748046875], [396, 883, 450, 994, 0.669921875], [397, 883, 451, 995, 0.6533203125], [398, 883, 451, 995, 0.6484375], [399, 884, 452, 994, 0.65478515625], [400, 884, 453, 995, 0.65234375], [400, 884, 453, 995, 0.6708984375], [401, 885, 454, 995, 0.67333984375], [401, 885, 454, 996, 0.67333984375], [402, 884, 455, 996, 0.65234375], [402, 884, 455, 995, 0.64501953125], [402, 884, 456, 996, 0.63671875], [402, 884, 456, 996, 0.6171875], [403, 884, 456, 996, 0.63134765625], [403, 883, 456, 995, 0.6494140625], [403, 883, 456, 995, 0.6435546875], [403, 883, 456, 995, 0.6513671875], [403, 883, 456, 995, 0.66015625], [403, 883, 456, 995, 0.650390625], [403, 883, 457, 994, 0.66015625], [403, 883, 456, 995, 0.66259765625], [403, 883, 456, 995, 0.67333984375], [403, 884, 456, 995, 0.67529296875], [403, 884, 456, 995, 0.6728515625], [402, 884, 456, 995, 0.6728515625], [402, 884, 456, 996, 0.67578125], [402, 885, 456, 997, 0.68017578125], [402, 885, 456, 997, 0.681640625], [402, 885, 456, 997, 0.68115234375], [402, 886, 455, 997, 0.68017578125], [402, 886, 455, 997, 0.68017578125], [402, 886, 455, 998, 0.68212890625], [401, 886, 455, 997, 0.67822265625], [401, 886, 455, 998, 0.67919921875], [401, 886, 455, 998, 0.6787109375], [402, 887, 455, 997, 0.6767578125], [402, 887, 455, 997, 0.67578125], [402, 887, 455, 997, 0.67626953125], [402, 887, 455, 997, 0.67431640625], [402, 887, 455, 997, 0.6748046875], [402, 887, 455, 998, 0.67431640625], [402, 887, 455, 998, 0.677734375], [402, 887, 455, 998, 0.67724609375], [402, 887, 455, 998, 0.67578125], [402, 887, 455, 997, 0.67529296875], [402, 887, 455, 998, 0.67578125], [401, 887, 455, 997, 0.67626953125], [402, 887, 455, 998, 0.6767578125], [402, 887, 455, 998, 0.6767578125], [402, 887, 455, 998, 0.67724609375], [402, 887, 455, 998, 0.68017578125], [402, 887, 455, 998, 0.6806640625], [402, 887, 455, 998, 0.68017578125], [402, 887, 455, 997, 0.6796875], [402, 887, 455, 997, 0.6796875], [402, 887, 455, 997, 0.68017578125], [402, 887, 455, 997, 0.68115234375], [402, 887, 455, 997, 0.68115234375], [402, 887, 455, 997, 0.68115234375], [402, 886, 455, 997, 0.68115234375], [402, 886, 455, 997, 0.68212890625], [402, 886, 455, 997, 0.68212890625], [402, 886, 455, 997, 0.68359375], [402, 886, 455, 997, 0.68408203125], [402, 886, 455, 997, 0.68115234375], [402, 886, 455, 997, 0.68017578125], [402, 886, 455, 998, 0.68310546875], [402, 886, 455, 998, 0.68310546875], [402, 886, 455, 997, 0.6845703125], [402, 886, 455, 998, 0.68310546875], [402, 886, 455, 998, 0.68359375], [402, 887, 455, 998, 0.681640625], [402, 887, 455, 998, 0.6826171875], [402, 887, 455, 998, 0.68115234375], [402, 886, 455, 998, 0.681640625], [402, 887, 455, 998, 0.6787109375], [402, 887, 455, 998, 0.6767578125], [402, 887, 455, 998, 0.67822265625], [402, 887, 455, 998, 0.67822265625], [401, 886, 455, 998, 0.67236328125], [401, 886, 455, 998, 0.67626953125], [402, 886, 455, 998, 0.67529296875], [402, 886, 455, 998, 0.6748046875], [402, 886, 455, 997, 0.67626953125], [402, 886, 455, 997, 0.67626953125], [402, 886, 455, 997, 0.677734375], [402, 886, 455, 997, 0.67919921875], [402, 886, 455, 997, 0.68017578125], [402, 886, 455, 997, 0.68212890625], [402, 886, 455, 998, 0.68212890625], [402, 886, 455, 998, 0.68115234375], [402, 886, 455, 997, 0.6806640625], [402, 886, 455, 998, 0.6787109375], [402, 886, 455, 998, 0.6806640625], [402, 886, 455, 997, 0.68212890625], [402, 886, 455, 997, 0.677734375], [402, 886, 455, 998, 0.677734375], [402, 886, 456, 998, 0.6787109375], [402, 886, 456, 998, 0.67919921875], [402, 886, 456, 998, 0.67919921875], [402, 886, 455, 998, 0.6806640625], [401, 886, 455, 997, 0.6806640625], [402, 886, 455, 998, 0.677734375], [402, 886, 455, 998, 0.67724609375], [402, 886, 455, 998, 0.67919921875], [402, 886, 455, 998, 0.6787109375], [402, 886, 455, 998, 0.68017578125], [402, 886, 455, 998, 0.6787109375], [402, 886, 455, 998, 0.6806640625], [402, 886, 455, 998, 0.677734375], [402, 886, 455, 998, 0.67724609375], [402, 887, 455, 998, 0.6767578125], [402, 887, 455, 998, 0.67724609375], [401, 886, 455, 998, 0.67724609375], [401, 886, 455, 998, 0.6767578125], [401, 887, 455, 998, 0.677734375], [401, 887, 455, 998, 0.677734375], [401, 887, 455, 998, 0.68017578125], [401, 887, 455, 998, 0.6806640625], [401, 887, 455, 999, 0.6806640625], [401, 887, 455, 999, 0.6806640625], [401, 887, 455, 998, 0.6796875], [401, 887, 455, 999, 0.67919921875], [401, 887, 455, 998, 0.67724609375], [401, 887, 455, 999, 0.677734375], [401, 887, 455, 999, 0.67578125], [401, 887, 455, 999, 0.67626953125], [401, 887, 455, 998, 0.677734375], [401, 887, 455, 998, 0.67626953125], [401, 887, 455, 998, 0.6787109375], [401, 887, 455, 998, 0.67578125], [401, 887, 455, 998, 0.67578125], [401, 886, 454, 998, 0.67578125], [401, 886, 455, 998, 0.6796875], [401, 886, 455, 998, 0.68017578125], [401, 886, 455, 998, 0.67919921875], [401, 886, 455, 998, 0.67822265625], [401, 886, 455, 998, 0.6787109375], [401, 886, 455, 997, 0.6796875], [401, 885, 455, 997, 0.67822265625], [401, 885, 455, 997, 0.677734375], [402, 885, 455, 997, 0.68017578125], [402, 885, 455, 997, 0.6806640625], [402, 885, 455, 997, 0.68212890625], [402, 885, 456, 997, 0.6796875], [402, 885, 456, 997, 0.68115234375], [402, 885, 455, 997, 0.68212890625], [402, 884, 456, 997, 0.6806640625], [402, 884, 456, 997, 0.68115234375], [402, 884, 456, 996, 0.6826171875], [403, 884, 456, 995, 0.6806640625], [403, 883, 457, 995, 0.685546875], [403, 883, 457, 995, 0.68603515625], [403, 883, 457, 995, 0.68896484375], [403, 883, 457, 995, 0.68603515625], [403, 883, 457, 995, 0.68603515625], [403, 883, 457, 995, 0.6875], [403, 883, 457, 995, 0.6875], [403, 883, 457, 995, 0.6884765625], [403, 883, 457, 995, 0.6884765625], [403, 883, 457, 995, 0.68505859375], [403, 883, 457, 995, 0.68701171875], [403, 883, 457, 995, 0.68701171875], [403, 883, 456, 995, 0.685546875], [403, 883, 456, 995, 0.68505859375], [403, 883, 456, 995, 0.68603515625], [403, 884, 456, 995, 0.689453125], [403, 884, 456, 995, 0.6865234375], [402, 884, 456, 995, 0.6865234375], [403, 884, 456, 995, 0.68408203125], [402, 884, 455, 995, 0.68017578125], [402, 884, 455, 995, 0.68115234375], [402, 884, 455, 995, 0.6806640625], [402, 884, 455, 995, 0.6806640625], [402, 884, 455, 995, 0.6796875], [402, 884, 455, 995, 0.6806640625], [402, 884, 455, 996, 0.6787109375], [402, 885, 455, 996, 0.6826171875], [402, 885, 455, 996, 0.681640625], [402, 885, 455, 996, 0.6806640625], [402, 885, 454, 996, 0.68115234375], [402, 885, 454, 996, 0.6806640625], [402, 885, 454, 995, 0.6787109375], [402, 885, 454, 995, 0.6767578125], [402, 885, 454, 996, 0.6767578125], [401, 885, 454, 995, 0.67822265625], [401, 885, 454, 996, 0.68017578125], [401, 885, 453, 995, 0.6826171875], [401, 885, 453, 995, 0.6806640625], [401, 885, 453, 995, 0.68310546875], [400, 885, 452, 995, 0.68115234375], [400, 885, 452, 995, 0.68017578125], [400, 885, 452, 995, 0.68017578125], [400, 885, 452, 995, 0.6787109375], [400, 885, 452, 995, 0.6787109375], [399, 885, 452, 995, 0.67529296875], [399, 885, 452, 995, 0.67578125], [399, 885, 452, 995, 0.67431640625], [400, 885, 452, 995, 0.67138671875], [399, 885, 452, 995, 0.67138671875], [399, 885, 452, 995, 0.6708984375], [399, 885, 452, 995, 0.6708984375], [399, 885, 452, 995, 0.67236328125], [399, 885, 452, 995, 0.67236328125], [399, 885, 452, 995, 0.6748046875], [400, 885, 452, 995, 0.669921875], [399, 885, 452, 995, 0.6708984375], [399, 885, 452, 995, 0.67041015625], [399, 885, 451, 995, 0.67041015625], [399, 885, 451, 995, 0.66796875], [399, 885, 451, 996, 0.66845703125], [399, 886, 451, 996, 0.66845703125], [399, 885, 451, 996, 0.6689453125], [399, 886, 451, 996, 0.6689453125], [399, 886, 451, 996, 0.66943359375], [399, 886, 450, 996, 0.67333984375], [398, 886, 450, 996, 0.67138671875], [398, 886, 450, 996, 0.673828125], [398, 886, 450, 996, 0.6728515625], [398, 886, 450, 995, 0.67529296875], [398, 885, 450, 995, 0.67333984375], [398, 885, 450, 995, 0.67138671875], [397, 885, 449, 994, 0.6708984375], [397, 885, 449, 994, 0.671875], [397, 885, 449, 994, 0.67041015625], [397, 885, 449, 994, 0.66845703125], [397, 885, 449, 994, 0.6640625], [396, 885, 449, 994, 0.66552734375], [396, 885, 449, 994, 0.66357421875], [396, 885, 449, 995, 0.6669921875], [396, 885, 449, 995, 0.66748046875], [396, 885, 449, 995, 0.6689453125], [396, 885, 449, 995, 0.669921875], [396, 885, 449, 994, 0.66943359375], [396, 885, 449, 994, 0.6689453125], [396, 885, 449, 995, 0.66748046875], [396, 885, 449, 995, 0.666015625], [396, 885, 449, 995, 0.66796875], [396, 885, 449, 994, 0.66748046875], [396, 885, 449, 994, 0.67041015625], [396, 885, 448, 994, 0.66845703125], [396, 885, 448, 995, 0.67041015625], [396, 885, 448, 994, 0.669921875], [396, 885, 448, 994, 0.66943359375], [396, 885, 448, 995, 0.67138671875], [396, 885, 448, 995, 0.67138671875], [396, 885, 448, 995, 0.67138671875], [396, 885, 448, 995, 0.669921875], [396, 885, 448, 994, 0.6708984375], [396, 885, 448, 994, 0.67041015625], [396, 885, 448, 994, 0.673828125], [396, 885, 448, 994, 0.67333984375], [396, 885, 448, 994, 0.6728515625], [396, 885, 448, 994, 0.67431640625], [396, 885, 448, 994, 0.673828125], [396, 885, 448, 994, 0.67333984375], [396, 885, 448, 994, 0.671875], [396, 884, 448, 994, 0.6748046875], [396, 884, 449, 994, 0.6689453125], [396, 884, 449, 994, 0.6689453125], [396, 884, 449, 994, 0.66796875], [396, 884, 449, 994, 0.67041015625], [396, 884, 449, 994, 0.6748046875], [397, 884, 449, 994, 0.67626953125], [397, 884, 449, 994, 0.6748046875], [397, 884, 449, 994, 0.67529296875], [397, 884, 449, 994, 0.67578125], [397, 884, 449, 994, 0.677734375], [397, 884, 449, 994, 0.6767578125], [397, 884, 449, 994, 0.67626953125], [396, 884, 449, 994, 0.67724609375], [396, 884, 449, 994, 0.67431640625], [396, 884, 449, 994, 0.6767578125], [395, 883, 448, 994, 0.67822265625], [395, 884, 448, 993, 0.666015625], [394, 885, 448, 994, 0.67333984375], [394, 886, 448, 993, 0.6767578125], [391, 890, 446, 996, 0.68115234375]]\n",
      "Key: Qc, vector len: 18, Card Detections: [[28, 839, 81, 960, 0.6337890625], [29, 839, 79, 958, 0.6328125], [29, 840, 79, 960, 0.63916015625], [30, 840, 80, 960, 0.63623046875], [30, 840, 79, 960, 0.6337890625], [29, 842, 80, 962, 0.6376953125], [30, 842, 80, 962, 0.63623046875], [30, 842, 80, 962, 0.63623046875], [30, 841, 81, 962, 0.6376953125], [30, 842, 82, 961, 0.63525390625], [30, 842, 82, 962, 0.640625], [31, 842, 82, 962, 0.64306640625], [31, 842, 83, 962, 0.64306640625], [31, 842, 83, 962, 0.640625], [31, 842, 83, 962, 0.64208984375], [31, 842, 83, 963, 0.64501953125], [31, 842, 83, 963, 0.646484375], [31, 843, 83, 963, 0.646484375]]\n",
      "Key: Qd, vector len: 9, Card Detections: [[46, 887, 98, 996, 0.55712890625], [46, 886, 98, 996, 0.55078125], [46, 886, 99, 996, 0.52587890625], [46, 886, 99, 997, 0.5224609375], [46, 885, 99, 997, 0.52978515625], [46, 885, 99, 996, 0.517578125], [46, 885, 98, 995, 0.58447265625], [46, 885, 98, 995, 0.580078125], [47, 890, 101, 998, 0.57177734375]]\n",
      "Key: Qh, vector len: 17, Card Detections: [[415, 870, 465, 986, 0.572265625], [415, 871, 465, 985, 0.59521484375], [415, 871, 464, 986, 0.57568359375], [415, 872, 464, 986, 0.5966796875], [415, 872, 464, 986, 0.63037109375], [415, 872, 464, 987, 0.634765625], [415, 872, 464, 986, 0.626953125], [414, 872, 464, 986, 0.626953125], [414, 872, 464, 986, 0.623046875], [414, 873, 464, 987, 0.6337890625], [414, 873, 464, 987, 0.6298828125], [413, 873, 464, 987, 0.6376953125], [413, 873, 463, 987, 0.63525390625], [413, 873, 463, 988, 0.61962890625], [413, 873, 463, 988, 0.6162109375], [412, 873, 463, 988, 0.62841796875], [411, 874, 462, 989, 0.642578125]]\n",
      "Key: Qs, vector len: 15, Card Detections: [[409, 870, 461, 989, 0.55419921875], [410, 870, 460, 986, 0.6611328125], [410, 871, 461, 989, 0.673828125], [410, 871, 460, 987, 0.68505859375], [410, 872, 460, 989, 0.6875], [410, 872, 460, 989, 0.68994140625], [410, 872, 460, 987, 0.65771484375], [410, 872, 460, 987, 0.66259765625], [410, 873, 460, 987, 0.6748046875], [410, 872, 460, 988, 0.68310546875], [409, 873, 459, 987, 0.6826171875], [409, 874, 460, 988, 0.685546875], [409, 874, 460, 988, 0.68212890625], [409, 874, 460, 988, 0.681640625], [404, 879, 457, 992, 0.66064453125]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 0, Card Detections: []\n",
      "Key: Tc, vector len: 6, Card Detections: [[172, 851, 229, 971, 0.6591796875], [174, 851, 229, 969, 0.65966796875], [174, 850, 229, 968, 0.6513671875], [175, 849, 229, 968, 0.6533203125], [174, 848, 229, 970, 0.65625], [175, 851, 230, 971, 0.654296875]]\n",
      "Key: Td, vector len: 11, Card Detections: [[528, 871, 579, 983, 0.67626953125], [528, 872, 580, 984, 0.6787109375], [528, 871, 580, 984, 0.681640625], [528, 871, 580, 984, 0.68115234375], [527, 872, 579, 984, 0.67919921875], [527, 872, 579, 984, 0.68408203125], [527, 872, 579, 985, 0.67822265625], [527, 872, 579, 985, 0.67919921875], [527, 872, 578, 985, 0.68115234375], [527, 872, 578, 985, 0.68017578125], [527, 873, 578, 985, 0.68017578125]]\n",
      "Key: Th, vector len: 28, Card Detections: [[527, 890, 582, 1005, 0.62841796875], [528, 890, 583, 1005, 0.63916015625], [528, 892, 582, 1006, 0.65576171875], [528, 892, 582, 1007, 0.60791015625], [528, 893, 582, 1008, 0.607421875], [528, 893, 582, 1008, 0.607421875], [528, 894, 581, 1009, 0.6142578125], [528, 894, 581, 1009, 0.61181640625], [528, 894, 581, 1009, 0.62353515625], [528, 895, 580, 1009, 0.61962890625], [527, 895, 580, 1010, 0.62255859375], [527, 895, 580, 1010, 0.6240234375], [527, 895, 580, 1010, 0.6162109375], [527, 896, 580, 1010, 0.61181640625], [526, 896, 579, 1010, 0.61376953125], [526, 896, 579, 1011, 0.603515625], [526, 896, 579, 1011, 0.60009765625], [526, 896, 579, 1011, 0.5986328125], [526, 897, 579, 1011, 0.59765625], [526, 897, 578, 1012, 0.59765625], [526, 897, 578, 1012, 0.5966796875], [525, 898, 578, 1012, 0.59814453125], [525, 899, 578, 1013, 0.59912109375], [525, 899, 577, 1013, 0.60107421875], [525, 900, 577, 1012, 0.59033203125], [524, 901, 576, 1013, 0.5869140625], [523, 902, 576, 1013, 0.599609375], [521, 905, 574, 1014, 0.6337890625]]\n",
      "Key: Ts, vector len: 13, Card Detections: [[530, 876, 585, 989, 0.52490234375], [532, 877, 585, 993, 0.6494140625], [532, 879, 585, 994, 0.6640625], [532, 878, 585, 993, 0.6533203125], [532, 878, 585, 994, 0.65087890625], [532, 879, 584, 995, 0.66455078125], [532, 879, 584, 995, 0.66357421875], [531, 879, 584, 995, 0.6611328125], [531, 880, 584, 994, 0.65283203125], [530, 880, 583, 994, 0.65283203125], [530, 880, 583, 995, 0.65576171875], [529, 880, 583, 995, 0.6591796875], [530, 882, 582, 996, 0.654296875]]\n",
      "Key: 2c, vector len: 6, Card Detections: [[134, 839, 193, 958, 0.66064453125], [135, 840, 191, 960, 0.666015625], [134, 841, 190, 960, 0.66064453125], [134, 842, 190, 961, 0.66015625], [134, 844, 190, 962, 0.6572265625], [135, 847, 190, 963, 0.66796875]]\n",
      "Key: 2d, vector len: 8, Card Detections: [[519, 885, 569, 992, 0.65234375], [518, 886, 569, 992, 0.6435546875], [518, 886, 570, 992, 0.646484375], [519, 886, 569, 993, 0.6572265625], [519, 886, 570, 993, 0.658203125], [518, 886, 570, 993, 0.65234375], [518, 889, 569, 995, 0.63623046875], [516, 874, 578, 1002, 0.59619140625]]\n",
      "Key: 2h, vector len: 24, Card Detections: [[529, 884, 583, 998, 0.6220703125], [529, 885, 583, 999, 0.62109375], [529, 886, 583, 1000, 0.62353515625], [529, 886, 583, 1001, 0.625], [529, 887, 583, 1001, 0.619140625], [528, 887, 583, 1001, 0.6162109375], [528, 887, 583, 1002, 0.6171875], [528, 888, 583, 1002, 0.6123046875], [528, 888, 583, 1002, 0.6103515625], [528, 889, 582, 1002, 0.60498046875], [528, 889, 582, 1003, 0.6044921875], [528, 889, 582, 1003, 0.60400390625], [528, 889, 582, 1003, 0.6044921875], [528, 889, 582, 1003, 0.60205078125], [527, 890, 582, 1004, 0.60107421875], [527, 889, 582, 1004, 0.595703125], [528, 890, 582, 1005, 0.60302734375], [527, 891, 581, 1005, 0.59912109375], [527, 891, 581, 1005, 0.5947265625], [527, 891, 581, 1005, 0.59326171875], [527, 892, 581, 1005, 0.59716796875], [527, 892, 581, 1005, 0.59716796875], [527, 892, 580, 1006, 0.60107421875], [526, 893, 580, 1006, 0.61865234375]]\n",
      "Key: 2s, vector len: 15, Card Detections: [[528, 874, 581, 987, 0.66552734375], [528, 874, 581, 987, 0.666015625], [528, 874, 581, 987, 0.669921875], [528, 874, 581, 987, 0.67041015625], [528, 875, 581, 988, 0.662109375], [529, 876, 580, 987, 0.654296875], [528, 875, 581, 988, 0.6513671875], [528, 876, 581, 989, 0.650390625], [528, 876, 581, 989, 0.65478515625], [528, 876, 581, 989, 0.65380859375], [528, 876, 581, 989, 0.64501953125], [527, 876, 580, 989, 0.640625], [527, 876, 580, 989, 0.63818359375], [528, 877, 580, 989, 0.63525390625], [527, 876, 579, 989, 0.6572265625]]\n",
      "Key: 3c, vector len: 12, Card Detections: [[521, 877, 578, 990, 0.6474609375], [521, 876, 577, 990, 0.64599609375], [521, 875, 576, 989, 0.64306640625], [521, 876, 577, 989, 0.6689453125], [522, 877, 577, 990, 0.66650390625], [522, 877, 577, 991, 0.65869140625], [522, 877, 577, 990, 0.64794921875], [521, 877, 577, 990, 0.6494140625], [521, 877, 577, 990, 0.646484375], [521, 877, 577, 991, 0.64990234375], [521, 879, 576, 992, 0.65673828125], [521, 881, 574, 992, 0.66748046875]]\n",
      "Key: 3d, vector len: 7, Card Detections: [[151, 820, 205, 941, 0.66064453125], [151, 820, 204, 940, 0.6630859375], [150, 821, 204, 941, 0.6650390625], [150, 821, 204, 941, 0.6611328125], [150, 821, 204, 941, 0.66064453125], [150, 823, 205, 943, 0.65576171875], [150, 823, 205, 943, 0.65673828125]]\n",
      "Key: 3h, vector len: 12, Card Detections: [[157, 829, 213, 946, 0.6240234375], [158, 828, 213, 948, 0.60302734375], [157, 827, 212, 948, 0.60546875], [157, 828, 212, 947, 0.6123046875], [157, 828, 212, 948, 0.61572265625], [157, 828, 212, 948, 0.6171875], [157, 829, 212, 949, 0.6181640625], [157, 829, 212, 949, 0.6162109375], [157, 830, 212, 950, 0.6142578125], [157, 830, 211, 949, 0.61669921875], [157, 829, 212, 950, 0.615234375], [158, 831, 213, 951, 0.61279296875]]\n",
      "Key: 3s, vector len: 65, Card Detections: [[128, 842, 184, 961, 0.52587890625], [128, 842, 183, 963, 0.65673828125], [127, 844, 182, 966, 0.6376953125], [127, 843, 182, 966, 0.64013671875], [126, 844, 182, 968, 0.64111328125], [126, 846, 182, 969, 0.64013671875], [126, 846, 182, 969, 0.63330078125], [126, 846, 182, 969, 0.63232421875], [126, 846, 182, 970, 0.63232421875], [125, 847, 182, 970, 0.63427734375], [126, 847, 182, 970, 0.634765625], [125, 847, 182, 970, 0.63525390625], [125, 846, 182, 971, 0.63623046875], [125, 846, 182, 971, 0.63671875], [125, 847, 182, 971, 0.6376953125], [125, 847, 182, 972, 0.638671875], [125, 847, 182, 971, 0.638671875], [125, 847, 182, 972, 0.63818359375], [125, 848, 182, 972, 0.6396484375], [124, 849, 181, 972, 0.6396484375], [124, 850, 181, 972, 0.6416015625], [124, 850, 181, 973, 0.64404296875], [124, 850, 181, 973, 0.640625], [123, 851, 181, 973, 0.642578125], [123, 851, 181, 973, 0.64111328125], [123, 851, 181, 973, 0.64404296875], [123, 850, 180, 973, 0.638671875], [123, 850, 180, 973, 0.6357421875], [123, 850, 180, 973, 0.63232421875], [123, 850, 180, 972, 0.63134765625], [123, 849, 180, 972, 0.630859375], [123, 849, 180, 972, 0.6328125], [123, 848, 180, 971, 0.63134765625], [123, 847, 180, 971, 0.62939453125], [123, 847, 180, 971, 0.630859375], [123, 847, 180, 971, 0.62939453125], [123, 846, 180, 971, 0.62939453125], [123, 846, 180, 970, 0.6279296875], [123, 846, 179, 970, 0.62353515625], [123, 847, 179, 970, 0.623046875], [123, 848, 179, 971, 0.62744140625], [123, 848, 179, 971, 0.6279296875], [123, 848, 179, 971, 0.62451171875], [123, 847, 180, 971, 0.6279296875], [123, 847, 180, 971, 0.62939453125], [123, 848, 180, 971, 0.626953125], [123, 848, 180, 971, 0.6318359375], [123, 848, 180, 971, 0.6298828125], [123, 849, 180, 971, 0.63037109375], [123, 850, 179, 972, 0.6318359375], [123, 850, 179, 972, 0.63330078125], [123, 850, 180, 972, 0.634765625], [123, 850, 179, 972, 0.63623046875], [122, 851, 179, 972, 0.6376953125], [122, 851, 179, 973, 0.63427734375], [123, 852, 179, 973, 0.634765625], [122, 852, 179, 973, 0.6318359375], [122, 853, 179, 974, 0.6318359375], [122, 853, 179, 975, 0.6337890625], [122, 855, 179, 975, 0.634765625], [122, 855, 179, 976, 0.6337890625], [122, 856, 179, 976, 0.63525390625], [122, 856, 179, 976, 0.630859375], [122, 858, 178, 977, 0.626953125], [122, 863, 178, 978, 0.62255859375]]\n",
      "Key: 4c, vector len: 6, Card Detections: [[522, 875, 640, 996, 0.67626953125], [522, 877, 638, 997, 0.6875], [522, 876, 638, 997, 0.69140625], [522, 876, 637, 995, 0.65771484375], [521, 877, 637, 997, 0.6611328125], [519, 879, 637, 999, 0.6533203125]]\n",
      "Key: 4d, vector len: 14, Card Detections: [[532, 876, 642, 997, 0.62353515625], [532, 877, 643, 997, 0.61865234375], [532, 877, 643, 997, 0.6181640625], [532, 876, 643, 997, 0.61767578125], [531, 877, 641, 997, 0.61767578125], [531, 878, 642, 998, 0.6201171875], [531, 878, 642, 998, 0.62255859375], [530, 878, 642, 998, 0.62451171875], [530, 878, 642, 998, 0.62646484375], [530, 878, 642, 998, 0.6259765625], [530, 878, 640, 998, 0.6259765625], [530, 879, 640, 998, 0.626953125], [529, 879, 640, 998, 0.6318359375], [523, 884, 637, 1002, 0.6318359375]]\n",
      "Key: 4h, vector len: 9, Card Detections: [[523, 880, 635, 994, 0.638671875], [524, 879, 635, 993, 0.638671875], [524, 880, 635, 992, 0.6376953125], [523, 879, 635, 993, 0.63720703125], [523, 879, 635, 992, 0.640625], [523, 880, 634, 993, 0.63818359375], [522, 880, 634, 994, 0.6376953125], [521, 881, 634, 993, 0.63623046875], [523, 875, 635, 1013, 0.61083984375]]\n",
      "Key: 4s, vector len: 6, Card Detections: [[159, 837, 275, 964, 0.63134765625], [160, 836, 274, 963, 0.6259765625], [160, 836, 275, 963, 0.62890625], [160, 835, 275, 963, 0.62646484375], [161, 836, 275, 963, 0.6240234375], [161, 837, 275, 964, 0.625]]\n",
      "Key: 5c, vector len: 12, Card Detections: [[139, 828, 196, 948, 0.6630859375], [138, 827, 193, 951, 0.65625], [138, 830, 193, 954, 0.64306640625], [137, 830, 193, 953, 0.64501953125], [137, 833, 192, 954, 0.62939453125], [137, 833, 193, 956, 0.642578125], [137, 834, 192, 955, 0.640625], [137, 834, 192, 956, 0.64404296875], [137, 835, 193, 958, 0.6435546875], [137, 835, 193, 958, 0.6435546875], [137, 835, 193, 958, 0.64208984375], [137, 838, 194, 960, 0.6240234375]]\n",
      "Key: 5d, vector len: 105, Card Detections: [[549, 930, 608, 1026, 0.5380859375], [549, 910, 607, 1012, 0.62060546875], [544, 897, 599, 1002, 0.5966796875], [536, 888, 590, 992, 0.6005859375], [531, 885, 585, 991, 0.60302734375], [525, 882, 577, 987, 0.63525390625], [521, 881, 572, 986, 0.65478515625], [521, 881, 572, 986, 0.65380859375], [521, 881, 572, 985, 0.65283203125], [521, 881, 571, 985, 0.6484375], [520, 881, 571, 985, 0.64501953125], [520, 881, 570, 985, 0.6396484375], [519, 881, 570, 985, 0.638671875], [518, 881, 569, 986, 0.63525390625], [518, 881, 568, 986, 0.6328125], [517, 881, 568, 986, 0.62744140625], [517, 881, 567, 986, 0.62353515625], [517, 881, 567, 986, 0.6181640625], [516, 881, 567, 986, 0.6171875], [516, 881, 567, 986, 0.61572265625], [516, 881, 566, 987, 0.6103515625], [516, 881, 566, 987, 0.6103515625], [516, 881, 566, 986, 0.6083984375], [516, 881, 566, 986, 0.60888671875], [516, 881, 566, 986, 0.607421875], [516, 881, 566, 986, 0.6083984375], [516, 881, 566, 986, 0.6064453125], [516, 881, 566, 986, 0.607421875], [516, 881, 566, 986, 0.6103515625], [517, 880, 567, 985, 0.62646484375], [517, 880, 567, 985, 0.623046875], [517, 880, 567, 985, 0.6240234375], [517, 880, 566, 985, 0.6103515625], [517, 880, 566, 986, 0.61181640625], [517, 880, 566, 985, 0.60888671875], [517, 880, 567, 985, 0.60888671875], [517, 880, 567, 986, 0.61279296875], [517, 880, 567, 986, 0.61279296875], [517, 880, 567, 986, 0.61181640625], [517, 880, 567, 986, 0.611328125], [517, 881, 567, 986, 0.61328125], [517, 881, 567, 986, 0.6083984375], [517, 881, 567, 986, 0.60986328125], [517, 880, 567, 986, 0.611328125], [517, 881, 567, 986, 0.609375], [517, 881, 567, 986, 0.609375], [517, 881, 567, 986, 0.61328125], [517, 881, 567, 987, 0.61376953125], [518, 881, 567, 986, 0.61083984375], [517, 881, 567, 986, 0.611328125], [518, 881, 567, 987, 0.61376953125], [518, 881, 567, 987, 0.61572265625], [518, 881, 567, 987, 0.61474609375], [518, 881, 567, 987, 0.6162109375], [518, 881, 567, 987, 0.61572265625], [518, 881, 568, 987, 0.6181640625], [518, 881, 568, 988, 0.61865234375], [518, 881, 568, 988, 0.61669921875], [518, 881, 568, 988, 0.6171875], [517, 881, 568, 988, 0.61669921875], [517, 882, 568, 989, 0.6171875], [517, 882, 567, 989, 0.61181640625], [517, 883, 567, 989, 0.60888671875], [517, 883, 567, 989, 0.60595703125], [517, 883, 567, 989, 0.6044921875], [516, 883, 567, 990, 0.59765625], [516, 883, 567, 990, 0.595703125], [516, 883, 567, 990, 0.595703125], [516, 883, 567, 990, 0.6005859375], [516, 884, 567, 989, 0.57958984375], [516, 884, 567, 990, 0.58154296875], [516, 884, 567, 990, 0.583984375], [516, 884, 567, 990, 0.58935546875], [516, 884, 567, 990, 0.59033203125], [516, 884, 566, 990, 0.58935546875], [516, 884, 566, 990, 0.59716796875], [516, 884, 566, 990, 0.5966796875], [515, 884, 566, 991, 0.59765625], [515, 884, 566, 990, 0.599609375], [515, 884, 567, 991, 0.60302734375], [515, 884, 567, 990, 0.58837890625], [515, 884, 567, 991, 0.5595703125], [515, 885, 567, 991, 0.56396484375], [515, 885, 567, 991, 0.55126953125], [515, 885, 567, 991, 0.5654296875], [515, 885, 567, 991, 0.55078125], [515, 885, 567, 991, 0.5625], [515, 885, 567, 992, 0.54638671875], [515, 885, 567, 992, 0.5576171875], [515, 885, 567, 992, 0.56689453125], [515, 886, 567, 992, 0.560546875], [515, 886, 567, 992, 0.564453125], [515, 886, 567, 992, 0.54296875], [515, 886, 567, 992, 0.55029296875], [515, 886, 567, 992, 0.55126953125], [515, 886, 566, 994, 0.52197265625], [515, 886, 567, 992, 0.52197265625], [515, 886, 567, 992, 0.521484375], [515, 886, 567, 992, 0.54052734375], [515, 886, 566, 994, 0.517578125], [515, 886, 566, 994, 0.51611328125], [515, 886, 566, 994, 0.513671875], [515, 886, 566, 995, 0.52197265625], [513, 889, 565, 996, 0.5634765625], [512, 891, 564, 995, 0.59326171875]]\n",
      "Key: 5h, vector len: 9, Card Detections: [[132, 840, 185, 959, 0.65673828125], [131, 842, 184, 959, 0.64697265625], [131, 842, 184, 960, 0.65087890625], [131, 843, 183, 960, 0.64990234375], [130, 844, 183, 962, 0.6484375], [130, 846, 183, 963, 0.6494140625], [130, 847, 183, 963, 0.65185546875], [130, 847, 183, 964, 0.650390625], [131, 848, 184, 964, 0.6494140625]]\n",
      "Key: 5s, vector len: 11, Card Detections: [[154, 822, 207, 947, 0.63330078125], [154, 823, 207, 946, 0.634765625], [154, 822, 207, 947, 0.6162109375], [154, 823, 206, 946, 0.607421875], [154, 824, 206, 947, 0.5966796875], [154, 824, 206, 948, 0.59228515625], [154, 824, 206, 949, 0.583984375], [154, 824, 206, 949, 0.61279296875], [154, 825, 206, 949, 0.6220703125], [154, 824, 206, 949, 0.60498046875], [154, 824, 206, 949, 0.62158203125]]\n",
      "Key: 6c, vector len: 6, Card Detections: [[520, 883, 573, 994, 0.67431640625], [520, 884, 574, 995, 0.673828125], [521, 883, 574, 995, 0.67626953125], [521, 883, 574, 996, 0.6806640625], [520, 885, 573, 996, 0.681640625], [519, 886, 573, 996, 0.67138671875]]\n",
      "Key: 6d, vector len: 7, Card Detections: [[527, 872, 577, 983, 0.61376953125], [528, 872, 576, 984, 0.630859375], [528, 874, 576, 985, 0.62744140625], [527, 875, 576, 985, 0.62744140625], [527, 875, 576, 984, 0.62060546875], [527, 876, 576, 985, 0.619140625], [526, 877, 575, 986, 0.625]]\n",
      "Key: 6h, vector len: 8, Card Detections: [[155, 827, 207, 944, 0.6337890625], [156, 827, 206, 944, 0.63232421875], [155, 827, 206, 945, 0.63232421875], [156, 826, 206, 944, 0.63427734375], [156, 826, 206, 943, 0.63232421875], [156, 826, 206, 943, 0.6337890625], [156, 827, 207, 943, 0.63037109375], [157, 827, 208, 944, 0.62548828125]]\n",
      "Key: 6s, vector len: 9, Card Detections: [[152, 820, 203, 942, 0.63134765625], [151, 820, 202, 941, 0.6533203125], [151, 821, 202, 941, 0.65771484375], [151, 821, 202, 940, 0.6796875], [151, 821, 202, 941, 0.67236328125], [151, 822, 202, 942, 0.66552734375], [151, 822, 202, 942, 0.65869140625], [151, 821, 203, 941, 0.67138671875], [152, 821, 203, 941, 0.66259765625]]\n",
      "Key: 7c, vector len: 4, Card Detections: [[164, 842, 217, 962, 0.658203125], [164, 842, 217, 962, 0.658203125], [164, 842, 217, 962, 0.65966796875], [164, 842, 218, 962, 0.6640625]]\n",
      "Key: 7d, vector len: 7, Card Detections: [[160, 838, 209, 956, 0.62548828125], [159, 838, 208, 955, 0.6318359375], [159, 839, 208, 956, 0.6328125], [159, 839, 208, 956, 0.6318359375], [159, 839, 209, 957, 0.62841796875], [159, 839, 209, 957, 0.625], [164, 840, 216, 975, 0.57080078125]]\n",
      "Key: 7h, vector len: 14, Card Detections: [[527, 878, 580, 994, 0.6884765625], [527, 878, 580, 994, 0.6884765625], [527, 878, 579, 994, 0.6865234375], [527, 879, 579, 994, 0.68505859375], [528, 880, 578, 995, 0.67919921875], [527, 880, 578, 995, 0.68017578125], [527, 880, 578, 995, 0.6796875], [527, 880, 578, 995, 0.677734375], [527, 880, 578, 995, 0.677734375], [527, 881, 578, 996, 0.673828125], [526, 882, 578, 996, 0.67431640625], [526, 882, 577, 996, 0.67041015625], [526, 882, 577, 997, 0.66845703125], [526, 883, 577, 997, 0.666015625]]\n",
      "Key: 7s, vector len: 14, Card Detections: [[142, 824, 194, 946, 0.61474609375], [141, 824, 194, 946, 0.6103515625], [141, 825, 192, 947, 0.61865234375], [141, 825, 192, 947, 0.61767578125], [141, 825, 192, 947, 0.6162109375], [140, 826, 192, 948, 0.61669921875], [141, 826, 192, 948, 0.619140625], [140, 826, 192, 948, 0.619140625], [140, 826, 192, 948, 0.6162109375], [140, 826, 192, 948, 0.6171875], [140, 827, 192, 949, 0.6142578125], [140, 827, 192, 950, 0.61328125], [140, 828, 192, 951, 0.6142578125], [140, 830, 192, 952, 0.6123046875]]\n",
      "Key: 8c, vector len: 5, Card Detections: [[157, 832, 210, 949, 0.6533203125], [157, 832, 210, 949, 0.6455078125], [157, 832, 210, 948, 0.64208984375], [158, 832, 210, 948, 0.64111328125], [158, 832, 210, 948, 0.64697265625]]\n",
      "Key: 8d, vector len: 13, Card Detections: [[532, 872, 582, 985, 0.701171875], [532, 873, 582, 985, 0.69921875], [532, 873, 582, 985, 0.69873046875], [532, 873, 582, 985, 0.69775390625], [532, 873, 582, 986, 0.6982421875], [531, 874, 581, 987, 0.69287109375], [531, 874, 581, 986, 0.68994140625], [530, 874, 581, 987, 0.6953125], [530, 874, 581, 988, 0.69677734375], [530, 876, 581, 988, 0.68896484375], [530, 876, 581, 988, 0.6884765625], [529, 876, 580, 988, 0.67822265625], [529, 876, 580, 988, 0.6630859375]]\n",
      "Key: 8h, vector len: 29, Card Detections: [[524, 903, 576, 1012, 0.69482421875], [524, 903, 576, 1013, 0.69775390625], [524, 906, 576, 1015, 0.6982421875], [523, 907, 575, 1017, 0.6904296875], [523, 908, 575, 1017, 0.68896484375], [522, 908, 575, 1017, 0.68798828125], [522, 908, 575, 1017, 0.68359375], [522, 908, 575, 1017, 0.6826171875], [522, 908, 575, 1017, 0.6826171875], [522, 908, 575, 1017, 0.68310546875], [522, 908, 574, 1018, 0.68505859375], [522, 909, 574, 1018, 0.6865234375], [522, 909, 574, 1018, 0.68603515625], [522, 909, 574, 1018, 0.685546875], [521, 909, 574, 1018, 0.68603515625], [521, 909, 574, 1018, 0.6865234375], [521, 909, 574, 1019, 0.68798828125], [521, 910, 574, 1019, 0.68798828125], [521, 910, 574, 1019, 0.6884765625], [521, 910, 573, 1019, 0.6904296875], [521, 910, 573, 1019, 0.69189453125], [521, 910, 573, 1019, 0.69384765625], [521, 911, 573, 1019, 0.69091796875], [521, 911, 573, 1020, 0.693359375], [521, 912, 573, 1020, 0.69482421875], [520, 912, 573, 1020, 0.69677734375], [520, 912, 572, 1020, 0.6943359375], [520, 913, 572, 1021, 0.69677734375], [519, 913, 572, 1021, 0.6875]]\n",
      "Key: 8s, vector len: 13, Card Detections: [[531, 873, 582, 990, 0.62939453125], [530, 874, 581, 991, 0.62353515625], [530, 874, 581, 991, 0.623046875], [530, 874, 581, 991, 0.62353515625], [530, 876, 581, 992, 0.6279296875], [530, 876, 581, 992, 0.626953125], [529, 876, 581, 992, 0.6279296875], [529, 876, 580, 992, 0.6279296875], [529, 876, 580, 992, 0.62939453125], [529, 876, 580, 992, 0.62939453125], [529, 876, 580, 992, 0.62890625], [529, 876, 580, 993, 0.63427734375], [528, 877, 579, 993, 0.6298828125]]\n",
      "Key: 9c, vector len: 6, Card Detections: [[520, 882, 572, 988, 0.64208984375], [520, 882, 572, 989, 0.6435546875], [520, 881, 573, 989, 0.65966796875], [520, 881, 572, 990, 0.65771484375], [519, 881, 572, 992, 0.685546875], [519, 883, 572, 992, 0.669921875]]\n",
      "Key: 9d, vector len: 5, Card Detections: [[153, 825, 209, 969, 0.5439453125], [156, 823, 206, 938, 0.64501953125], [156, 824, 206, 940, 0.64892578125], [156, 823, 207, 939, 0.646484375], [158, 826, 209, 942, 0.65966796875]]\n",
      "Key: 9h, vector len: 27, Card Detections: [[119, 861, 175, 975, 0.6533203125], [119, 861, 173, 972, 0.6376953125], [119, 861, 172, 974, 0.63671875], [119, 862, 172, 975, 0.6435546875], [119, 863, 172, 976, 0.6474609375], [118, 865, 171, 976, 0.63818359375], [118, 865, 171, 977, 0.6435546875], [118, 865, 171, 977, 0.64892578125], [118, 865, 170, 978, 0.65283203125], [118, 866, 170, 978, 0.65625], [117, 866, 170, 978, 0.65234375], [117, 866, 170, 978, 0.654296875], [117, 866, 170, 978, 0.65576171875], [117, 866, 170, 978, 0.65478515625], [117, 867, 170, 978, 0.6533203125], [117, 867, 170, 978, 0.65234375], [117, 868, 170, 979, 0.650390625], [117, 868, 170, 978, 0.65185546875], [117, 869, 170, 979, 0.646484375], [117, 871, 169, 980, 0.64404296875], [117, 871, 169, 981, 0.642578125], [117, 872, 169, 981, 0.6376953125], [117, 872, 169, 981, 0.638671875], [117, 872, 169, 981, 0.6396484375], [117, 873, 170, 981, 0.6376953125], [117, 873, 169, 981, 0.6396484375], [117, 873, 169, 981, 0.64208984375]]\n",
      "Key: 9s, vector len: 106, Card Detections: [[183, 952, 234, 1042, 0.65869140625], [183, 926, 236, 1026, 0.6552734375], [185, 911, 238, 1016, 0.66162109375], [194, 892, 247, 1005, 0.64404296875], [194, 882, 247, 996, 0.6572265625], [194, 880, 247, 994, 0.6376953125], [197, 876, 250, 991, 0.65576171875], [197, 876, 250, 991, 0.6552734375], [197, 876, 250, 991, 0.65673828125], [197, 875, 250, 990, 0.66357421875], [197, 875, 250, 990, 0.66162109375], [197, 875, 250, 990, 0.658203125], [197, 874, 250, 989, 0.65283203125], [197, 874, 250, 989, 0.64990234375], [196, 874, 250, 988, 0.64794921875], [196, 874, 249, 988, 0.64697265625], [195, 874, 249, 988, 0.64501953125], [195, 874, 248, 988, 0.642578125], [195, 874, 248, 988, 0.64306640625], [195, 874, 247, 989, 0.640625], [194, 874, 246, 990, 0.6376953125], [193, 874, 246, 989, 0.63623046875], [193, 874, 245, 989, 0.63427734375], [193, 874, 245, 989, 0.6328125], [193, 874, 245, 989, 0.63427734375], [193, 874, 245, 989, 0.63427734375], [192, 874, 245, 989, 0.634765625], [192, 873, 245, 989, 0.63720703125], [192, 874, 245, 989, 0.6298828125], [192, 874, 245, 989, 0.6298828125], [192, 873, 244, 989, 0.6298828125], [192, 873, 244, 988, 0.6318359375], [191, 873, 244, 989, 0.6298828125], [191, 873, 243, 989, 0.6357421875], [190, 873, 243, 989, 0.63671875], [190, 873, 243, 989, 0.6376953125], [189, 873, 242, 989, 0.63916015625], [189, 873, 241, 988, 0.64111328125], [189, 873, 241, 988, 0.6416015625], [188, 873, 241, 989, 0.6455078125], [188, 874, 240, 989, 0.64453125], [188, 874, 240, 989, 0.646484375], [187, 874, 240, 989, 0.6474609375], [187, 874, 239, 989, 0.646484375], [187, 874, 239, 989, 0.64501953125], [186, 875, 239, 989, 0.6435546875], [186, 875, 239, 989, 0.64453125], [186, 875, 239, 989, 0.64453125], [186, 875, 239, 989, 0.64599609375], [186, 876, 239, 990, 0.64501953125], [186, 876, 239, 990, 0.646484375], [186, 876, 239, 990, 0.646484375], [186, 876, 239, 990, 0.6455078125], [186, 876, 239, 990, 0.6474609375], [187, 876, 239, 990, 0.6484375], [187, 876, 239, 989, 0.6474609375], [187, 876, 239, 990, 0.64990234375], [186, 876, 239, 990, 0.64697265625], [186, 875, 239, 989, 0.64453125], [186, 875, 238, 989, 0.64306640625], [186, 875, 238, 989, 0.64306640625], [186, 875, 238, 989, 0.64599609375], [186, 875, 238, 989, 0.64892578125], [186, 875, 238, 990, 0.646484375], [185, 875, 238, 990, 0.6494140625], [185, 875, 238, 991, 0.65185546875], [185, 876, 238, 991, 0.6533203125], [185, 876, 238, 991, 0.6533203125], [185, 876, 238, 991, 0.654296875], [185, 876, 238, 991, 0.6533203125], [185, 876, 238, 992, 0.64990234375], [185, 876, 238, 992, 0.650390625], [184, 877, 238, 992, 0.650390625], [184, 877, 238, 992, 0.650390625], [184, 877, 238, 992, 0.64794921875], [184, 877, 238, 992, 0.64453125], [184, 877, 238, 992, 0.64404296875], [184, 877, 237, 992, 0.6435546875], [184, 877, 237, 992, 0.64501953125], [183, 877, 237, 992, 0.64599609375], [183, 877, 236, 992, 0.64501953125], [183, 877, 236, 993, 0.646484375], [183, 877, 236, 993, 0.64453125], [182, 877, 236, 993, 0.64501953125], [182, 877, 236, 993, 0.64892578125], [182, 877, 235, 993, 0.6513671875], [181, 877, 235, 994, 0.65087890625], [181, 878, 235, 994, 0.6484375], [181, 878, 234, 994, 0.642578125], [180, 878, 234, 994, 0.64208984375], [180, 879, 234, 994, 0.642578125], [180, 879, 233, 995, 0.64453125], [180, 879, 233, 995, 0.64453125], [180, 879, 233, 995, 0.64501953125], [180, 879, 234, 995, 0.64599609375], [180, 879, 234, 995, 0.64599609375], [180, 878, 234, 994, 0.6474609375], [181, 877, 234, 994, 0.6435546875], [181, 876, 235, 992, 0.64990234375], [182, 876, 235, 992, 0.64501953125], [182, 875, 235, 991, 0.64892578125], [182, 874, 235, 990, 0.65087890625], [182, 873, 235, 990, 0.65087890625], [182, 873, 236, 989, 0.650390625], [182, 872, 236, 989, 0.64990234375], [182, 872, 236, 989, 0.64892578125]]\n",
      "Key: Ac, vector len: 4, Card Detections: [[518, 889, 573, 999, 0.53369140625], [518, 890, 573, 1000, 0.572265625], [518, 890, 573, 1000, 0.5625], [518, 890, 572, 1000, 0.64599609375]]\n",
      "Key: Ad, vector len: 59, Card Detections: [[520, 915, 568, 1020, 0.63671875], [520, 916, 568, 1020, 0.626953125], [520, 917, 568, 1022, 0.625], [519, 917, 568, 1022, 0.62353515625], [519, 917, 568, 1022, 0.62255859375], [519, 917, 567, 1022, 0.62353515625], [519, 916, 567, 1021, 0.625], [519, 917, 568, 1022, 0.6240234375], [519, 917, 568, 1022, 0.6240234375], [519, 916, 568, 1022, 0.6240234375], [520, 917, 568, 1022, 0.62158203125], [520, 917, 568, 1022, 0.62353515625], [520, 917, 568, 1022, 0.623046875], [520, 917, 568, 1022, 0.62255859375], [520, 917, 568, 1022, 0.62255859375], [520, 917, 568, 1022, 0.62353515625], [520, 917, 568, 1021, 0.62451171875], [520, 917, 568, 1021, 0.62451171875], [520, 917, 568, 1021, 0.625], [520, 917, 568, 1021, 0.6259765625], [520, 917, 568, 1022, 0.62548828125], [520, 917, 568, 1022, 0.62548828125], [520, 917, 568, 1021, 0.62451171875], [520, 917, 568, 1021, 0.62646484375], [520, 917, 568, 1021, 0.62548828125], [520, 917, 568, 1021, 0.625], [520, 917, 568, 1021, 0.62451171875], [520, 917, 568, 1021, 0.6240234375], [520, 917, 568, 1021, 0.62548828125], [520, 917, 568, 1021, 0.62451171875], [520, 917, 568, 1021, 0.625], [520, 917, 568, 1021, 0.6259765625], [520, 917, 568, 1021, 0.62548828125], [520, 917, 568, 1021, 0.6240234375], [520, 917, 568, 1021, 0.6259765625], [520, 917, 568, 1021, 0.625], [520, 917, 568, 1021, 0.62548828125], [520, 917, 568, 1021, 0.62548828125], [520, 917, 568, 1021, 0.62548828125], [520, 917, 568, 1022, 0.6259765625], [520, 918, 568, 1022, 0.62060546875], [520, 918, 567, 1021, 0.625], [519, 918, 568, 1021, 0.63427734375], [518, 918, 568, 1021, 0.62158203125], [518, 919, 568, 1022, 0.623046875], [517, 919, 567, 1022, 0.65576171875], [517, 919, 567, 1022, 0.6455078125], [517, 919, 567, 1022, 0.6328125], [517, 919, 567, 1022, 0.6328125], [517, 920, 567, 1022, 0.63330078125], [517, 920, 567, 1022, 0.6298828125], [517, 920, 567, 1023, 0.62646484375], [517, 920, 567, 1022, 0.625], [517, 920, 566, 1023, 0.62890625], [517, 920, 566, 1023, 0.63134765625], [516, 920, 566, 1023, 0.63134765625], [516, 920, 566, 1023, 0.63330078125], [516, 920, 566, 1023, 0.63037109375], [516, 920, 566, 1023, 0.6318359375]]\n",
      "Key: Ah, vector len: 10, Card Detections: [[526, 876, 576, 983, 0.61669921875], [525, 875, 576, 985, 0.62060546875], [526, 875, 576, 985, 0.62353515625], [526, 875, 576, 985, 0.62548828125], [525, 875, 576, 985, 0.623046875], [525, 875, 576, 985, 0.6279296875], [525, 875, 576, 985, 0.62158203125], [525, 875, 576, 985, 0.61279296875], [525, 876, 576, 986, 0.619140625], [524, 877, 575, 986, 0.609375]]\n",
      "Key: As, vector len: 12, Card Detections: [[529, 887, 584, 1001, 0.63916015625], [529, 887, 584, 1002, 0.6376953125], [529, 887, 583, 1002, 0.6240234375], [529, 888, 584, 1003, 0.6396484375], [529, 889, 584, 1004, 0.64599609375], [530, 889, 583, 1004, 0.64013671875], [530, 889, 583, 1004, 0.63720703125], [530, 890, 583, 1003, 0.6435546875], [529, 890, 583, 1004, 0.642578125], [529, 891, 583, 1005, 0.64990234375], [529, 892, 583, 1005, 0.64697265625], [526, 897, 581, 1007, 0.615234375]]\n",
      "Key: Jc, vector len: 4, Card Detections: [[163, 844, 219, 966, 0.67919921875], [164, 843, 220, 963, 0.6875], [164, 843, 220, 964, 0.6865234375], [165, 844, 221, 964, 0.693359375]]\n",
      "Key: Jd, vector len: 6, Card Detections: [[181, 864, 233, 980, 0.64697265625], [181, 864, 233, 980, 0.6513671875], [180, 863, 233, 981, 0.638671875], [180, 863, 233, 981, 0.64306640625], [180, 863, 232, 980, 0.650390625], [181, 867, 234, 983, 0.61474609375]]\n",
      "Key: Jh, vector len: 9, Card Detections: [[164, 847, 226, 997, 0.5546875], [166, 848, 221, 967, 0.62744140625], [165, 848, 220, 968, 0.62060546875], [165, 849, 219, 969, 0.6259765625], [165, 849, 219, 968, 0.626953125], [165, 850, 220, 968, 0.62744140625], [165, 849, 220, 968, 0.62744140625], [165, 850, 220, 968, 0.6279296875], [162, 844, 220, 992, 0.57373046875]]\n",
      "Key: Js, vector len: 11, Card Detections: [[528, 874, 579, 988, 0.658203125], [528, 874, 579, 988, 0.6591796875], [528, 875, 579, 988, 0.68115234375], [528, 874, 579, 989, 0.65234375], [528, 875, 579, 989, 0.6630859375], [528, 877, 579, 990, 0.6640625], [528, 876, 579, 989, 0.66748046875], [528, 875, 579, 989, 0.6640625], [527, 876, 578, 990, 0.6640625], [527, 877, 578, 991, 0.6640625], [527, 878, 578, 992, 0.65576171875]]\n",
      "Key: Kc, vector len: 7, Card Detections: [[173, 856, 231, 975, 0.65771484375], [174, 856, 230, 976, 0.6669921875], [174, 856, 229, 975, 0.66455078125], [174, 855, 230, 975, 0.67236328125], [174, 854, 230, 974, 0.67626953125], [174, 854, 230, 974, 0.67626953125], [175, 856, 231, 974, 0.6806640625]]\n",
      "Key: Kd, vector len: 10, Card Detections: [[527, 873, 578, 984, 0.6435546875], [526, 873, 578, 984, 0.65478515625], [526, 873, 578, 984, 0.64306640625], [526, 873, 578, 983, 0.650390625], [526, 873, 578, 984, 0.64892578125], [526, 874, 578, 985, 0.6484375], [526, 874, 578, 985, 0.64697265625], [525, 875, 577, 986, 0.64208984375], [525, 875, 577, 986, 0.64697265625], [524, 877, 575, 986, 0.64990234375]]\n",
      "Key: Kh, vector len: 24, Card Detections: [[528, 880, 580, 991, 0.65087890625], [528, 880, 580, 993, 0.658203125], [528, 880, 580, 993, 0.65380859375], [528, 881, 580, 993, 0.65576171875], [527, 881, 580, 994, 0.65283203125], [527, 881, 580, 994, 0.65771484375], [527, 881, 580, 994, 0.6552734375], [527, 882, 580, 994, 0.654296875], [527, 881, 580, 995, 0.654296875], [527, 882, 580, 995, 0.65966796875], [527, 882, 580, 995, 0.658203125], [527, 882, 580, 995, 0.65673828125], [527, 881, 580, 995, 0.65625], [527, 882, 580, 995, 0.65380859375], [527, 883, 580, 996, 0.65380859375], [526, 883, 579, 996, 0.65087890625], [526, 883, 579, 996, 0.65087890625], [526, 883, 579, 996, 0.65087890625], [526, 884, 579, 996, 0.64990234375], [526, 884, 579, 997, 0.64990234375], [526, 884, 579, 997, 0.64794921875], [525, 884, 579, 997, 0.646484375], [525, 885, 579, 997, 0.642578125], [525, 885, 578, 998, 0.64013671875]]\n",
      "Key: Ks, vector len: 6, Card Detections: [[177, 864, 233, 984, 0.65478515625], [177, 864, 232, 984, 0.67431640625], [177, 863, 233, 985, 0.6767578125], [178, 862, 233, 983, 0.6669921875], [178, 862, 233, 983, 0.66650390625], [178, 863, 234, 983, 0.68212890625]]\n",
      "Key: Qc, vector len: 19, Card Detections: [[148, 824, 202, 939, 0.61767578125], [148, 823, 202, 941, 0.64013671875], [148, 825, 201, 941, 0.60546875], [148, 826, 201, 942, 0.623046875], [147, 826, 201, 944, 0.64599609375], [147, 827, 201, 944, 0.64599609375], [147, 826, 201, 945, 0.642578125], [147, 827, 201, 945, 0.64306640625], [147, 827, 201, 945, 0.63818359375], [147, 827, 201, 945, 0.6435546875], [146, 827, 201, 945, 0.6298828125], [146, 828, 200, 946, 0.62109375], [146, 829, 200, 946, 0.62158203125], [146, 829, 200, 946, 0.6298828125], [146, 829, 200, 946, 0.6279296875], [146, 829, 200, 946, 0.62890625], [146, 829, 200, 946, 0.6279296875], [146, 829, 200, 947, 0.63623046875], [146, 829, 199, 947, 0.63671875]]\n",
      "Key: Qd, vector len: 6, Card Detections: [[165, 840, 219, 960, 0.59326171875], [165, 840, 217, 953, 0.60107421875], [165, 841, 217, 954, 0.6064453125], [165, 841, 217, 954, 0.6015625], [165, 841, 217, 954, 0.61181640625], [165, 842, 217, 956, 0.61474609375]]\n",
      "Key: Qh, vector len: 70, Card Detections: [[115, 868, 171, 996, 0.6337890625], [114, 868, 167, 980, 0.67919921875], [114, 867, 166, 981, 0.6630859375], [113, 869, 166, 983, 0.669921875], [113, 870, 166, 983, 0.66650390625], [113, 872, 166, 985, 0.63916015625], [113, 874, 166, 986, 0.65283203125], [113, 874, 166, 987, 0.6640625], [113, 874, 167, 986, 0.66455078125], [113, 874, 166, 986, 0.65869140625], [114, 872, 166, 985, 0.66650390625], [114, 872, 167, 984, 0.6689453125], [114, 871, 167, 984, 0.671875], [114, 871, 167, 984, 0.68115234375], [114, 870, 167, 984, 0.6845703125], [114, 870, 167, 984, 0.6845703125], [114, 871, 167, 984, 0.68408203125], [114, 871, 167, 985, 0.6767578125], [114, 871, 167, 985, 0.67431640625], [114, 871, 167, 985, 0.67041015625], [114, 872, 167, 985, 0.6708984375], [114, 872, 167, 986, 0.6650390625], [114, 872, 167, 986, 0.6669921875], [114, 872, 167, 986, 0.66650390625], [114, 872, 167, 985, 0.66845703125], [114, 872, 166, 985, 0.67041015625], [114, 872, 166, 985, 0.66650390625], [113, 872, 166, 986, 0.66064453125], [113, 871, 166, 985, 0.66943359375], [113, 871, 165, 986, 0.66796875], [113, 871, 165, 986, 0.6689453125], [112, 871, 165, 986, 0.6669921875], [112, 871, 165, 986, 0.6669921875], [112, 871, 165, 986, 0.66796875], [112, 871, 165, 986, 0.6689453125], [112, 871, 165, 986, 0.6640625], [112, 872, 165, 986, 0.66455078125], [113, 872, 165, 986, 0.66650390625], [113, 872, 165, 986, 0.6630859375], [113, 872, 165, 986, 0.662109375], [113, 872, 165, 986, 0.66162109375], [113, 872, 165, 986, 0.66162109375], [113, 872, 165, 986, 0.65869140625], [113, 872, 165, 986, 0.66259765625], [113, 872, 165, 986, 0.66455078125], [113, 872, 165, 986, 0.66845703125], [113, 872, 165, 986, 0.67041015625], [113, 872, 165, 986, 0.6708984375], [113, 872, 165, 986, 0.66845703125], [113, 872, 165, 986, 0.671875], [113, 872, 165, 986, 0.6708984375], [113, 872, 165, 986, 0.67236328125], [113, 872, 165, 986, 0.67236328125], [113, 872, 165, 986, 0.67041015625], [113, 872, 165, 985, 0.6728515625], [113, 872, 165, 985, 0.67431640625], [113, 872, 165, 986, 0.673828125], [113, 872, 165, 986, 0.6708984375], [113, 872, 165, 986, 0.66845703125], [113, 872, 165, 986, 0.66748046875], [113, 872, 165, 986, 0.6689453125], [113, 873, 165, 986, 0.6728515625], [113, 873, 165, 986, 0.66845703125], [113, 873, 165, 987, 0.67041015625], [113, 874, 165, 987, 0.66259765625], [113, 875, 165, 987, 0.66357421875], [113, 876, 165, 988, 0.66552734375], [113, 876, 165, 988, 0.6728515625], [113, 876, 165, 989, 0.6748046875], [114, 881, 166, 990, 0.67138671875]]\n",
      "Key: Qs, vector len: 5, Card Detections: [[174, 851, 230, 974, 0.6162109375], [174, 851, 229, 974, 0.630859375], [174, 852, 228, 973, 0.625], [173, 852, 228, 975, 0.619140625], [173, 852, 228, 975, 0.6259765625]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 0, Card Detections: []\n",
      "Key: Tc, vector len: 8, Card Detections: [[77, 870, 137, 1016, 0.5068359375], [78, 871, 131, 986, 0.64111328125], [78, 872, 131, 985, 0.6337890625], [79, 870, 132, 987, 0.6494140625], [79, 870, 131, 986, 0.64208984375], [79, 870, 131, 986, 0.6357421875], [78, 871, 131, 985, 0.6337890625], [79, 870, 132, 987, 0.63916015625]]\n",
      "Key: Td, vector len: 17, Card Detections: [[72, 828, 125, 944, 0.68017578125], [71, 828, 124, 944, 0.681640625], [71, 829, 124, 945, 0.67333984375], [71, 829, 124, 945, 0.671875], [71, 830, 124, 946, 0.68017578125], [71, 831, 124, 946, 0.6796875], [71, 832, 124, 948, 0.68896484375], [71, 833, 124, 949, 0.68798828125], [71, 834, 124, 949, 0.68896484375], [71, 834, 124, 950, 0.6923828125], [71, 835, 124, 950, 0.69140625], [71, 835, 124, 951, 0.69189453125], [71, 836, 124, 951, 0.6904296875], [72, 836, 125, 951, 0.6884765625], [72, 837, 125, 951, 0.6875], [72, 837, 125, 952, 0.685546875], [72, 841, 126, 953, 0.68212890625]]\n",
      "Key: Th, vector len: 33, Card Detections: [[439, 885, 490, 998, 0.640625], [439, 885, 490, 997, 0.63720703125], [439, 886, 490, 998, 0.63525390625], [439, 888, 489, 1000, 0.6318359375], [439, 888, 489, 1000, 0.6318359375], [439, 888, 489, 1000, 0.63134765625], [439, 888, 489, 1000, 0.6318359375], [439, 888, 489, 1000, 0.6298828125], [439, 888, 489, 999, 0.62841796875], [439, 888, 489, 1001, 0.62744140625], [439, 888, 489, 1001, 0.62646484375], [439, 889, 488, 1001, 0.625], [439, 888, 489, 1000, 0.62646484375], [438, 889, 488, 1001, 0.62548828125], [439, 889, 488, 1001, 0.626953125], [438, 889, 488, 1001, 0.62548828125], [438, 889, 488, 1001, 0.625], [438, 889, 488, 1001, 0.62646484375], [438, 889, 488, 1001, 0.626953125], [438, 889, 488, 1001, 0.6259765625], [438, 889, 488, 1001, 0.6259765625], [438, 889, 488, 1001, 0.626953125], [438, 889, 488, 1001, 0.626953125], [438, 889, 488, 1001, 0.626953125], [438, 889, 488, 1001, 0.62646484375], [438, 889, 488, 1001, 0.6279296875], [438, 890, 488, 1002, 0.63134765625], [438, 890, 488, 1002, 0.6318359375], [438, 890, 488, 1002, 0.6318359375], [437, 890, 488, 1002, 0.6328125], [437, 891, 487, 1002, 0.64599609375], [437, 892, 487, 1003, 0.64794921875], [434, 896, 485, 1006, 0.6064453125]]\n",
      "Key: Ts, vector len: 12, Card Detections: [[442, 876, 493, 992, 0.6044921875], [443, 877, 493, 991, 0.61865234375], [442, 877, 493, 992, 0.5888671875], [443, 878, 492, 993, 0.611328125], [442, 879, 492, 993, 0.634765625], [442, 879, 492, 993, 0.62841796875], [443, 879, 492, 993, 0.64013671875], [442, 880, 492, 994, 0.64208984375], [442, 880, 492, 994, 0.64794921875], [441, 881, 491, 995, 0.640625], [441, 881, 492, 995, 0.64013671875], [440, 883, 491, 995, 0.6533203125]]\n",
      "Key: 2c, vector len: 9, Card Detections: [[73, 844, 127, 963, 0.6474609375], [72, 844, 127, 963, 0.640625], [72, 844, 127, 963, 0.63427734375], [72, 844, 127, 963, 0.6328125], [72, 844, 127, 964, 0.638671875], [73, 844, 127, 963, 0.63623046875], [72, 844, 127, 963, 0.6357421875], [73, 844, 127, 963, 0.62548828125], [74, 845, 128, 963, 0.640625]]\n",
      "Key: 2d, vector len: 8, Card Detections: [[68, 825, 121, 939, 0.6376953125], [69, 825, 121, 939, 0.62841796875], [69, 825, 121, 940, 0.63818359375], [70, 824, 122, 940, 0.6376953125], [70, 824, 122, 940, 0.63671875], [71, 825, 122, 940, 0.64111328125], [71, 826, 123, 942, 0.6455078125], [74, 834, 128, 953, 0.607421875]]\n",
      "Key: 2h, vector len: 31, Card Detections: [[439, 882, 491, 994, 0.63134765625], [439, 882, 491, 994, 0.62939453125], [439, 882, 490, 994, 0.634765625], [439, 883, 490, 995, 0.63623046875], [439, 884, 490, 995, 0.63427734375], [439, 884, 490, 995, 0.634765625], [439, 884, 490, 996, 0.630859375], [439, 884, 490, 996, 0.6279296875], [439, 884, 490, 996, 0.62744140625], [439, 885, 490, 996, 0.626953125], [439, 885, 490, 996, 0.62744140625], [439, 885, 490, 996, 0.62548828125], [439, 885, 490, 996, 0.62548828125], [439, 884, 490, 996, 0.63037109375], [439, 885, 490, 997, 0.62744140625], [439, 884, 490, 997, 0.62890625], [439, 885, 490, 997, 0.6298828125], [439, 885, 490, 997, 0.6279296875], [439, 885, 490, 997, 0.62841796875], [439, 885, 490, 997, 0.62548828125], [439, 886, 489, 997, 0.6328125], [439, 886, 489, 997, 0.6279296875], [439, 886, 489, 997, 0.6318359375], [439, 886, 489, 997, 0.6298828125], [439, 886, 490, 997, 0.6220703125], [439, 886, 489, 998, 0.61962890625], [439, 886, 489, 998, 0.62109375], [438, 886, 489, 998, 0.61865234375], [438, 887, 489, 998, 0.623046875], [438, 888, 489, 999, 0.63671875], [433, 890, 487, 1002, 0.6142578125]]\n",
      "Key: 2s, vector len: 14, Card Detections: [[441, 876, 493, 988, 0.66455078125], [441, 877, 493, 989, 0.6689453125], [441, 877, 493, 988, 0.67578125], [441, 877, 492, 989, 0.671875], [441, 878, 492, 989, 0.67138671875], [441, 878, 492, 990, 0.6708984375], [441, 878, 492, 990, 0.66845703125], [441, 878, 492, 990, 0.66796875], [441, 878, 492, 990, 0.66748046875], [440, 878, 492, 990, 0.6669921875], [440, 878, 492, 990, 0.66455078125], [440, 878, 492, 990, 0.666015625], [440, 878, 491, 990, 0.6796875], [439, 879, 491, 991, 0.66162109375]]\n",
      "Key: 3c, vector len: 12, Card Detections: [[443, 871, 496, 987, 0.62255859375], [443, 873, 496, 989, 0.63916015625], [442, 872, 496, 989, 0.6328125], [442, 872, 495, 989, 0.6396484375], [442, 873, 495, 990, 0.64697265625], [442, 872, 495, 989, 0.63818359375], [441, 872, 495, 990, 0.6435546875], [441, 873, 495, 990, 0.6455078125], [440, 874, 495, 990, 0.64892578125], [440, 874, 495, 990, 0.64306640625], [440, 874, 494, 990, 0.6484375], [439, 877, 492, 991, 0.65966796875]]\n",
      "Key: 3d, vector len: 5, Card Detections: [[74, 843, 128, 962, 0.63623046875], [74, 844, 127, 961, 0.64208984375], [75, 843, 128, 962, 0.6318359375], [75, 843, 129, 962, 0.634765625], [76, 842, 137, 975, 0.63330078125]]\n",
      "Key: 3h, vector len: 9, Card Detections: [[75, 853, 132, 972, 0.61474609375], [76, 852, 131, 970, 0.6142578125], [77, 851, 132, 971, 0.60888671875], [77, 851, 132, 971, 0.60498046875], [76, 850, 132, 970, 0.60205078125], [76, 851, 132, 971, 0.60546875], [77, 851, 132, 971, 0.61767578125], [76, 851, 132, 971, 0.6123046875], [76, 851, 132, 972, 0.6103515625]]\n",
      "Key: 3s, vector len: 6, Card Detections: [[72, 834, 128, 953, 0.63818359375], [73, 832, 128, 950, 0.6328125], [72, 832, 128, 953, 0.62939453125], [74, 831, 128, 952, 0.626953125], [74, 832, 129, 951, 0.634765625], [74, 832, 129, 953, 0.64013671875]]\n",
      "Key: 4c, vector len: 8, Card Detections: [[71, 824, 198, 946, 0.61669921875], [70, 824, 204, 948, 0.62060546875], [73, 824, 197, 948, 0.62353515625], [73, 824, 198, 947, 0.62548828125], [74, 824, 197, 948, 0.646484375], [74, 825, 200, 950, 0.62060546875], [74, 825, 200, 950, 0.62255859375], [75, 827, 200, 952, 0.6220703125]]\n",
      "Key: 4d, vector len: 20, Card Detections: [[70, 836, 191, 967, 0.6181640625], [71, 835, 186, 957, 0.61328125], [70, 836, 185, 958, 0.62109375], [70, 835, 185, 958, 0.619140625], [70, 836, 185, 958, 0.62060546875], [69, 836, 185, 958, 0.62255859375], [69, 837, 184, 959, 0.62353515625], [69, 836, 184, 958, 0.623046875], [69, 836, 184, 958, 0.62353515625], [69, 836, 184, 958, 0.6240234375], [69, 837, 184, 958, 0.6240234375], [69, 837, 184, 959, 0.6240234375], [69, 838, 182, 958, 0.6240234375], [69, 838, 182, 959, 0.6240234375], [69, 838, 182, 959, 0.62548828125], [69, 838, 182, 959, 0.62451171875], [69, 839, 182, 959, 0.6240234375], [68, 839, 182, 960, 0.61376953125], [69, 840, 181, 961, 0.61865234375], [70, 844, 186, 964, 0.6162109375]]\n",
      "Key: 4h, vector len: 9, Card Detections: [[432, 875, 543, 999, 0.54541015625], [70, 826, 191, 954, 0.650390625], [71, 825, 190, 943, 0.63818359375], [72, 825, 189, 944, 0.640625], [72, 825, 190, 944, 0.64306640625], [72, 824, 191, 944, 0.64599609375], [73, 826, 191, 945, 0.64111328125], [74, 826, 191, 945, 0.64453125], [75, 831, 195, 949, 0.634765625]]\n",
      "Key: 4s, vector len: 7, Card Detections: [[442, 874, 544, 996, 0.638671875], [442, 874, 545, 995, 0.62353515625], [442, 874, 545, 995, 0.626953125], [442, 874, 545, 995, 0.62841796875], [442, 874, 544, 995, 0.625], [441, 876, 543, 996, 0.62841796875], [435, 884, 544, 1001, 0.61376953125]]\n",
      "Key: 5c, vector len: 10, Card Detections: [[441, 874, 494, 986, 0.6806640625], [441, 873, 494, 987, 0.67236328125], [441, 874, 494, 988, 0.67626953125], [441, 874, 494, 988, 0.677734375], [441, 875, 494, 989, 0.68115234375], [440, 875, 493, 988, 0.67822265625], [440, 876, 494, 990, 0.6787109375], [440, 875, 494, 989, 0.6923828125], [440, 877, 493, 990, 0.69921875], [439, 878, 493, 990, 0.6943359375]]\n",
      "Key: 5d, vector len: 8, Card Detections: [[442, 875, 492, 987, 0.63623046875], [442, 875, 491, 987, 0.62939453125], [442, 875, 491, 987, 0.63134765625], [442, 875, 491, 987, 0.62939453125], [442, 875, 491, 988, 0.61767578125], [441, 876, 490, 987, 0.61767578125], [441, 876, 490, 988, 0.62158203125], [441, 876, 490, 988, 0.6171875]]\n",
      "Key: 5h, vector len: 6, Card Detections: [[440, 877, 492, 987, 0.6728515625], [441, 877, 492, 987, 0.6708984375], [441, 877, 492, 987, 0.66796875], [441, 877, 492, 987, 0.6669921875], [440, 878, 492, 988, 0.65673828125], [439, 878, 491, 988, 0.65869140625]]\n",
      "Key: 5s, vector len: 7, Card Detections: [[442, 876, 492, 988, 0.68359375], [441, 875, 492, 987, 0.6845703125], [441, 876, 492, 988, 0.68603515625], [441, 875, 492, 987, 0.681640625], [440, 875, 491, 987, 0.68115234375], [439, 877, 491, 988, 0.6796875], [438, 878, 491, 989, 0.6845703125]]\n",
      "Key: 6c, vector len: 13, Card Detections: [[444, 876, 495, 989, 0.67529296875], [444, 876, 494, 990, 0.67822265625], [444, 875, 494, 991, 0.6806640625], [443, 875, 494, 990, 0.68115234375], [444, 876, 494, 991, 0.68115234375], [443, 876, 494, 991, 0.68359375], [443, 876, 494, 991, 0.68359375], [443, 876, 494, 992, 0.68359375], [443, 875, 494, 992, 0.68603515625], [443, 876, 494, 993, 0.6806640625], [442, 876, 494, 993, 0.685546875], [442, 876, 494, 993, 0.68798828125], [441, 878, 493, 994, 0.6884765625]]\n",
      "Key: 6d, vector len: 16, Card Detections: [[74, 825, 123, 941, 0.6728515625], [74, 825, 123, 941, 0.67041015625], [74, 825, 123, 941, 0.65576171875], [74, 825, 123, 941, 0.65478515625], [74, 826, 123, 942, 0.67431640625], [74, 826, 123, 943, 0.68798828125], [74, 827, 123, 944, 0.68505859375], [74, 827, 123, 944, 0.6943359375], [74, 827, 124, 945, 0.689453125], [74, 827, 124, 945, 0.6728515625], [75, 828, 124, 945, 0.673828125], [75, 828, 124, 945, 0.67138671875], [75, 828, 124, 945, 0.67138671875], [75, 829, 125, 946, 0.67041015625], [76, 829, 125, 947, 0.65478515625], [78, 833, 127, 950, 0.6767578125]]\n",
      "Key: 6h, vector len: 5, Card Detections: [[441, 878, 494, 988, 0.64208984375], [441, 878, 493, 988, 0.6328125], [442, 879, 492, 989, 0.64013671875], [442, 879, 492, 989, 0.634765625], [442, 880, 492, 990, 0.63037109375]]\n",
      "Key: 6s, vector len: 6, Card Detections: [[74, 845, 125, 965, 0.66064453125], [75, 844, 124, 966, 0.6474609375], [74, 844, 124, 967, 0.65234375], [75, 844, 125, 967, 0.66015625], [75, 844, 125, 966, 0.65673828125], [76, 844, 125, 966, 0.6513671875]]\n",
      "Key: 7c, vector len: 5, Card Detections: [[440, 874, 493, 988, 0.65478515625], [438, 873, 492, 986, 0.625], [438, 874, 492, 987, 0.623046875], [439, 875, 492, 987, 0.642578125], [439, 875, 492, 988, 0.64794921875]]\n",
      "Key: 7d, vector len: 5, Card Detections: [[74, 861, 124, 977, 0.6533203125], [74, 859, 124, 977, 0.65771484375], [75, 858, 125, 975, 0.63427734375], [76, 857, 126, 975, 0.61474609375], [77, 858, 126, 975, 0.61181640625]]\n",
      "Key: 7h, vector len: 25, Card Detections: [[65, 835, 119, 955, 0.69287109375], [66, 835, 118, 955, 0.69873046875], [65, 837, 117, 956, 0.70361328125], [65, 838, 117, 956, 0.70458984375], [65, 838, 117, 956, 0.71044921875], [65, 838, 118, 957, 0.70849609375], [65, 839, 118, 957, 0.7099609375], [66, 839, 118, 957, 0.70849609375], [66, 839, 118, 957, 0.70458984375], [66, 840, 118, 957, 0.703125], [66, 840, 118, 957, 0.70166015625], [66, 839, 118, 957, 0.70361328125], [65, 838, 118, 956, 0.70703125], [66, 838, 118, 956, 0.703125], [66, 838, 118, 956, 0.70361328125], [66, 838, 118, 956, 0.70068359375], [66, 838, 119, 956, 0.6943359375], [67, 838, 119, 956, 0.69775390625], [67, 838, 119, 956, 0.697265625], [67, 838, 119, 956, 0.69921875], [67, 839, 119, 957, 0.6962890625], [67, 839, 119, 956, 0.697265625], [67, 839, 120, 956, 0.7041015625], [68, 838, 120, 956, 0.70068359375], [68, 840, 120, 956, 0.69970703125]]\n",
      "Key: 7s, vector len: 8, Card Detections: [[73, 840, 124, 960, 0.677734375], [72, 839, 123, 958, 0.6533203125], [73, 840, 124, 960, 0.67138671875], [73, 839, 124, 960, 0.66552734375], [73, 840, 124, 960, 0.66796875], [74, 841, 125, 962, 0.65478515625], [74, 843, 125, 963, 0.654296875], [77, 843, 130, 977, 0.52001953125]]\n",
      "Key: 8c, vector len: 7, Card Detections: [[443, 878, 496, 988, 0.6396484375], [444, 879, 495, 990, 0.65087890625], [444, 879, 495, 990, 0.63916015625], [443, 878, 495, 989, 0.6474609375], [443, 879, 495, 991, 0.64453125], [443, 881, 494, 990, 0.65771484375], [440, 883, 493, 991, 0.640625]]\n",
      "Key: 8d, vector len: 16, Card Detections: [[443, 873, 495, 985, 0.685546875], [444, 873, 492, 986, 0.6884765625], [444, 873, 493, 985, 0.6884765625], [444, 873, 493, 985, 0.69287109375], [444, 874, 492, 986, 0.69189453125], [444, 874, 492, 986, 0.69091796875], [444, 874, 492, 986, 0.689453125], [444, 874, 492, 986, 0.6904296875], [444, 874, 492, 986, 0.69189453125], [444, 874, 492, 987, 0.693359375], [444, 874, 492, 987, 0.6953125], [443, 875, 491, 987, 0.693359375], [443, 875, 491, 988, 0.6904296875], [443, 875, 491, 988, 0.69140625], [442, 876, 490, 988, 0.6796875], [429, 872, 487, 999, 0.53173828125]]\n",
      "Key: 8h, vector len: 80, Card Detections: [[70, 838, 122, 952, 0.68310546875], [69, 839, 121, 952, 0.69189453125], [69, 840, 121, 954, 0.705078125], [69, 840, 121, 955, 0.69287109375], [69, 842, 121, 956, 0.6904296875], [69, 843, 121, 956, 0.6875], [68, 844, 121, 957, 0.6904296875], [68, 845, 121, 957, 0.6884765625], [69, 845, 121, 957, 0.68896484375], [69, 844, 121, 956, 0.68896484375], [69, 844, 121, 956, 0.6884765625], [69, 843, 121, 957, 0.68896484375], [69, 842, 121, 956, 0.69287109375], [69, 841, 121, 956, 0.68798828125], [69, 841, 121, 955, 0.6904296875], [69, 841, 121, 955, 0.69482421875], [69, 841, 121, 955, 0.69384765625], [69, 841, 121, 955, 0.70263671875], [69, 840, 121, 955, 0.70458984375], [69, 841, 121, 954, 0.70556640625], [69, 841, 121, 954, 0.70458984375], [69, 841, 121, 955, 0.6962890625], [69, 841, 121, 955, 0.69970703125], [69, 841, 121, 955, 0.697265625], [69, 841, 121, 955, 0.7041015625], [69, 841, 121, 955, 0.70263671875], [69, 841, 121, 955, 0.69873046875], [69, 841, 121, 955, 0.69970703125], [69, 841, 121, 955, 0.69873046875], [69, 841, 120, 955, 0.7001953125], [69, 841, 120, 955, 0.69775390625], [69, 841, 120, 955, 0.69921875], [69, 841, 120, 955, 0.701171875], [69, 841, 120, 955, 0.703125], [69, 841, 120, 955, 0.70361328125], [69, 840, 120, 954, 0.70703125], [69, 840, 120, 954, 0.708984375], [69, 839, 120, 954, 0.70751953125], [69, 839, 120, 953, 0.70166015625], [69, 838, 120, 952, 0.693359375], [69, 838, 120, 951, 0.68408203125], [69, 838, 120, 951, 0.68115234375], [69, 837, 120, 951, 0.68017578125], [69, 837, 120, 950, 0.6689453125], [69, 836, 121, 949, 0.66796875], [69, 835, 120, 949, 0.66748046875], [69, 835, 120, 949, 0.66845703125], [69, 835, 120, 948, 0.66748046875], [69, 833, 120, 948, 0.671875], [69, 833, 120, 947, 0.68310546875], [69, 832, 120, 947, 0.6826171875], [69, 831, 119, 947, 0.677734375], [68, 831, 119, 946, 0.669921875], [68, 831, 120, 946, 0.666015625], [68, 830, 119, 946, 0.66650390625], [68, 830, 120, 945, 0.6689453125], [68, 830, 120, 945, 0.67041015625], [68, 830, 120, 945, 0.67138671875], [68, 830, 120, 945, 0.669921875], [68, 830, 120, 945, 0.6708984375], [68, 830, 120, 945, 0.66796875], [69, 830, 120, 945, 0.66796875], [69, 829, 120, 945, 0.6689453125], [69, 829, 120, 945, 0.67041015625], [69, 829, 120, 945, 0.67236328125], [69, 829, 120, 945, 0.6728515625], [69, 829, 120, 945, 0.67333984375], [69, 829, 120, 945, 0.671875], [69, 829, 120, 945, 0.67626953125], [69, 829, 120, 945, 0.67529296875], [69, 829, 120, 945, 0.67626953125], [69, 829, 120, 944, 0.67529296875], [69, 829, 120, 944, 0.67431640625], [69, 829, 121, 944, 0.67236328125], [70, 828, 121, 944, 0.6748046875], [70, 828, 121, 943, 0.67578125], [70, 829, 122, 943, 0.673828125], [70, 828, 122, 943, 0.68115234375], [70, 828, 122, 943, 0.68505859375], [71, 828, 123, 942, 0.677734375]]\n",
      "Key: 8s, vector len: 13, Card Detections: [[443, 872, 491, 989, 0.6357421875], [443, 874, 491, 990, 0.638671875], [442, 873, 492, 989, 0.654296875], [442, 874, 491, 990, 0.65625], [442, 874, 491, 990, 0.65478515625], [442, 874, 491, 990, 0.65576171875], [442, 874, 491, 990, 0.658203125], [442, 875, 491, 990, 0.6572265625], [442, 875, 491, 990, 0.65771484375], [442, 875, 491, 990, 0.65673828125], [442, 875, 490, 990, 0.658203125], [441, 876, 490, 991, 0.6611328125], [439, 879, 488, 992, 0.623046875]]\n",
      "Key: 9c, vector len: 12, Card Detections: [[70, 827, 121, 945, 0.6689453125], [70, 828, 121, 944, 0.67041015625], [70, 828, 121, 946, 0.6796875], [70, 828, 121, 946, 0.67724609375], [70, 829, 121, 946, 0.67529296875], [70, 829, 122, 947, 0.6748046875], [70, 829, 122, 947, 0.677734375], [70, 830, 122, 949, 0.67822265625], [71, 830, 123, 949, 0.68017578125], [71, 831, 123, 949, 0.68017578125], [71, 831, 123, 950, 0.68359375], [73, 832, 125, 951, 0.68994140625]]\n",
      "Key: 9d, vector len: 7, Card Detections: [[77, 851, 126, 964, 0.6572265625], [77, 851, 126, 965, 0.66064453125], [77, 851, 126, 965, 0.66015625], [77, 851, 126, 965, 0.662109375], [77, 851, 126, 965, 0.6650390625], [76, 852, 125, 967, 0.6669921875], [77, 854, 126, 967, 0.65869140625]]\n",
      "Key: 9h, vector len: 10, Card Detections: [[72, 832, 125, 950, 0.66357421875], [72, 833, 123, 948, 0.62939453125], [72, 832, 122, 946, 0.63671875], [72, 833, 123, 947, 0.64404296875], [72, 833, 122, 947, 0.64111328125], [71, 833, 122, 947, 0.64306640625], [71, 833, 122, 948, 0.646484375], [71, 834, 122, 948, 0.642578125], [71, 835, 122, 950, 0.64111328125], [74, 832, 126, 955, 0.67333984375]]\n",
      "Key: 9s, vector len: 140, Card Detections: [[65, 969, 116, 1053, 0.64599609375], [67, 967, 115, 1049, 0.650390625], [68, 963, 116, 1046, 0.69482421875], [69, 959, 116, 1043, 0.6728515625], [70, 954, 118, 1040, 0.68505859375], [70, 952, 118, 1039, 0.6787109375], [71, 946, 121, 1036, 0.70556640625], [72, 943, 122, 1034, 0.6865234375], [73, 939, 122, 1032, 0.6962890625], [73, 935, 124, 1030, 0.68212890625], [74, 932, 125, 1028, 0.66357421875], [75, 929, 126, 1026, 0.6591796875], [75, 926, 126, 1025, 0.6611328125], [76, 923, 127, 1023, 0.658203125], [77, 920, 128, 1021, 0.66455078125], [77, 916, 128, 1019, 0.6435546875], [78, 914, 129, 1018, 0.6357421875], [77, 914, 129, 1017, 0.63427734375], [78, 912, 129, 1015, 0.62646484375], [78, 910, 129, 1015, 0.609375], [78, 908, 129, 1013, 0.61376953125], [77, 908, 128, 1012, 0.615234375], [77, 907, 128, 1012, 0.6220703125], [76, 906, 127, 1011, 0.62939453125], [76, 906, 128, 1011, 0.63671875], [76, 905, 127, 1011, 0.63525390625], [76, 904, 127, 1010, 0.6337890625], [76, 903, 127, 1010, 0.6298828125], [76, 903, 128, 1009, 0.6337890625], [76, 902, 128, 1009, 0.62890625], [76, 900, 128, 1008, 0.62255859375], [77, 900, 128, 1007, 0.6240234375], [77, 899, 128, 1006, 0.6259765625], [77, 898, 129, 1006, 0.6259765625], [78, 896, 129, 1005, 0.6259765625], [78, 895, 129, 1005, 0.6298828125], [78, 894, 129, 1004, 0.6279296875], [77, 895, 129, 1004, 0.626953125], [77, 894, 129, 1004, 0.63037109375], [76, 893, 128, 1003, 0.63134765625], [76, 893, 128, 1002, 0.6318359375], [76, 892, 128, 1001, 0.6357421875], [75, 892, 127, 1001, 0.63720703125], [75, 891, 127, 1001, 0.666015625], [75, 891, 127, 1001, 0.67333984375], [74, 890, 127, 1000, 0.67724609375], [74, 891, 127, 1000, 0.67431640625], [74, 891, 127, 1000, 0.67236328125], [75, 891, 128, 1000, 0.6669921875], [75, 891, 128, 1000, 0.66455078125], [75, 890, 128, 999, 0.62890625], [75, 890, 128, 1001, 0.62939453125], [76, 889, 128, 999, 0.6279296875], [76, 889, 128, 999, 0.6279296875], [76, 888, 129, 999, 0.6279296875], [76, 888, 129, 998, 0.62646484375], [76, 887, 128, 998, 0.6259765625], [76, 887, 129, 998, 0.6259765625], [76, 887, 129, 998, 0.6279296875], [76, 886, 128, 998, 0.62890625], [76, 886, 129, 997, 0.64111328125], [76, 886, 128, 997, 0.64013671875], [76, 885, 128, 997, 0.6572265625], [75, 885, 128, 996, 0.6669921875], [75, 885, 128, 996, 0.666015625], [75, 884, 128, 996, 0.6650390625], [76, 884, 128, 996, 0.6650390625], [75, 884, 128, 996, 0.6669921875], [76, 884, 128, 995, 0.6640625], [76, 884, 128, 995, 0.6455078125], [77, 884, 128, 996, 0.61474609375], [77, 884, 129, 996, 0.61767578125], [78, 884, 129, 996, 0.61865234375], [78, 884, 130, 996, 0.6240234375], [78, 884, 130, 996, 0.62548828125], [79, 884, 130, 996, 0.62646484375], [79, 884, 130, 996, 0.62841796875], [79, 884, 130, 996, 0.626953125], [79, 884, 130, 996, 0.62646484375], [79, 884, 131, 996, 0.62841796875], [79, 884, 131, 996, 0.626953125], [79, 884, 131, 996, 0.6259765625], [79, 884, 131, 996, 0.6279296875], [79, 884, 131, 996, 0.6337890625], [79, 884, 131, 996, 0.630859375], [79, 884, 130, 996, 0.6298828125], [79, 884, 130, 996, 0.62939453125], [79, 884, 130, 996, 0.63037109375], [79, 884, 130, 996, 0.6328125], [79, 884, 130, 995, 0.63232421875], [79, 884, 131, 996, 0.64013671875], [80, 884, 131, 995, 0.63720703125], [80, 883, 131, 995, 0.642578125], [81, 883, 132, 995, 0.64794921875], [81, 883, 132, 995, 0.65185546875], [81, 883, 132, 995, 0.6533203125], [82, 883, 133, 995, 0.6533203125], [82, 884, 133, 995, 0.65283203125], [82, 884, 133, 995, 0.65087890625], [82, 884, 133, 995, 0.64892578125], [82, 884, 133, 995, 0.6484375], [81, 884, 132, 995, 0.64697265625], [82, 884, 132, 995, 0.64794921875], [81, 883, 132, 996, 0.64794921875], [81, 883, 132, 996, 0.6494140625], [80, 883, 131, 995, 0.64111328125], [80, 883, 131, 996, 0.638671875], [80, 883, 131, 996, 0.640625], [80, 884, 131, 996, 0.638671875], [80, 884, 131, 995, 0.63525390625], [80, 884, 131, 995, 0.63623046875], [80, 884, 131, 995, 0.6357421875], [80, 884, 131, 996, 0.63916015625], [80, 884, 131, 996, 0.638671875], [80, 884, 131, 996, 0.642578125], [80, 884, 131, 996, 0.64599609375], [80, 884, 131, 996, 0.6474609375], [80, 884, 131, 996, 0.64794921875], [80, 884, 131, 996, 0.64990234375], [80, 884, 131, 996, 0.64990234375], [80, 884, 131, 996, 0.6484375], [80, 884, 131, 996, 0.6533203125], [80, 884, 131, 996, 0.64501953125], [80, 884, 131, 996, 0.640625], [79, 884, 131, 996, 0.63818359375], [79, 884, 130, 996, 0.6376953125], [79, 883, 130, 996, 0.63525390625], [79, 883, 130, 996, 0.63525390625], [78, 883, 130, 996, 0.63427734375], [78, 883, 130, 996, 0.6376953125], [78, 883, 130, 996, 0.64111328125], [78, 883, 130, 996, 0.6416015625], [78, 883, 130, 996, 0.64013671875], [78, 883, 129, 996, 0.6396484375], [78, 883, 129, 996, 0.64013671875], [78, 884, 130, 996, 0.63818359375], [78, 884, 130, 996, 0.63818359375], [79, 884, 130, 996, 0.63623046875], [79, 884, 130, 996, 0.63671875], [80, 890, 132, 997, 0.6171875]]\n",
      "Key: Ac, vector len: 11, Card Detections: [[67, 830, 124, 950, 0.66259765625], [67, 829, 124, 949, 0.66064453125], [68, 829, 123, 948, 0.66552734375], [67, 829, 123, 948, 0.66357421875], [67, 829, 123, 949, 0.66162109375], [67, 829, 123, 948, 0.66357421875], [67, 829, 123, 948, 0.6630859375], [67, 829, 123, 948, 0.6640625], [67, 828, 123, 948, 0.66455078125], [67, 828, 123, 948, 0.6640625], [71, 833, 126, 951, 0.65869140625]]\n",
      "Key: Ad, vector len: 64, Card Detections: [[437, 895, 484, 1003, 0.62353515625], [437, 894, 484, 1002, 0.62060546875], [437, 895, 484, 1004, 0.6220703125], [437, 895, 484, 1004, 0.6181640625], [437, 895, 484, 1004, 0.6181640625], [437, 895, 484, 1004, 0.6220703125], [437, 895, 484, 1004, 0.623046875], [437, 894, 484, 1004, 0.6279296875], [438, 894, 484, 1004, 0.6298828125], [438, 894, 484, 1004, 0.62841796875], [438, 894, 485, 1004, 0.630859375], [438, 894, 485, 1004, 0.63134765625], [438, 893, 485, 1004, 0.6318359375], [438, 893, 485, 1003, 0.63134765625], [438, 893, 485, 1003, 0.63037109375], [438, 893, 485, 1003, 0.630859375], [438, 893, 485, 1003, 0.630859375], [438, 893, 485, 1003, 0.63232421875], [438, 893, 485, 1003, 0.6337890625], [438, 893, 485, 1003, 0.6337890625], [438, 893, 485, 1003, 0.63427734375], [438, 893, 485, 1003, 0.63525390625], [438, 894, 485, 1003, 0.634765625], [439, 894, 485, 1003, 0.63427734375], [439, 894, 485, 1003, 0.63525390625], [438, 894, 485, 1002, 0.6318359375], [438, 894, 485, 1003, 0.6328125], [438, 894, 485, 1003, 0.6337890625], [438, 894, 485, 1003, 0.6318359375], [437, 895, 486, 1004, 0.62646484375], [437, 895, 485, 1003, 0.619140625], [437, 895, 485, 1004, 0.62255859375], [437, 895, 484, 1003, 0.61962890625], [437, 895, 484, 1003, 0.61767578125], [437, 896, 484, 1003, 0.6162109375], [436, 896, 484, 1004, 0.6162109375], [436, 896, 484, 1004, 0.615234375], [436, 896, 484, 1004, 0.60986328125], [436, 896, 484, 1004, 0.6083984375], [436, 896, 484, 1004, 0.609375], [436, 896, 484, 1004, 0.609375], [436, 896, 484, 1004, 0.6103515625], [436, 896, 484, 1004, 0.60986328125], [436, 896, 484, 1004, 0.61083984375], [436, 896, 483, 1004, 0.609375], [436, 896, 484, 1004, 0.6103515625], [436, 896, 483, 1004, 0.6103515625], [436, 897, 483, 1004, 0.60986328125], [436, 897, 483, 1004, 0.60986328125], [436, 897, 483, 1004, 0.6083984375], [436, 897, 483, 1004, 0.62451171875], [436, 897, 483, 1003, 0.626953125], [436, 897, 483, 1004, 0.630859375], [436, 897, 483, 1004, 0.6318359375], [436, 897, 483, 1003, 0.63232421875], [436, 898, 483, 1003, 0.6279296875], [436, 898, 483, 1003, 0.62841796875], [436, 898, 483, 1003, 0.62939453125], [436, 898, 483, 1003, 0.62939453125], [436, 898, 483, 1003, 0.62890625], [436, 898, 483, 1003, 0.63037109375], [436, 898, 483, 1003, 0.6298828125], [436, 899, 482, 1003, 0.62939453125], [433, 903, 480, 1005, 0.6328125]]\n",
      "Key: Ah, vector len: 17, Card Detections: [[443, 876, 493, 986, 0.62744140625], [443, 876, 492, 987, 0.6259765625], [443, 876, 493, 988, 0.6337890625], [443, 876, 492, 987, 0.63525390625], [442, 877, 492, 989, 0.63330078125], [442, 877, 492, 989, 0.63330078125], [442, 877, 492, 989, 0.63232421875], [442, 877, 492, 989, 0.63427734375], [441, 877, 492, 989, 0.63671875], [441, 877, 492, 989, 0.63525390625], [441, 877, 492, 989, 0.63720703125], [441, 877, 491, 990, 0.638671875], [441, 877, 491, 990, 0.638671875], [441, 878, 491, 990, 0.6376953125], [441, 878, 490, 990, 0.63818359375], [441, 878, 490, 990, 0.638671875], [440, 880, 490, 990, 0.64501953125]]\n",
      "Key: As, vector len: 32, Card Detections: [[66, 836, 121, 956, 0.6435546875], [66, 836, 121, 956, 0.65185546875], [66, 837, 120, 956, 0.64990234375], [66, 838, 120, 957, 0.64794921875], [66, 838, 120, 957, 0.6474609375], [67, 838, 120, 958, 0.650390625], [67, 839, 120, 958, 0.64404296875], [67, 841, 120, 958, 0.6474609375], [67, 841, 120, 958, 0.64599609375], [67, 841, 121, 958, 0.6494140625], [67, 840, 121, 958, 0.6494140625], [68, 840, 121, 958, 0.650390625], [68, 840, 121, 957, 0.64990234375], [68, 840, 121, 957, 0.64990234375], [68, 840, 121, 957, 0.65234375], [68, 840, 122, 957, 0.6533203125], [68, 839, 122, 956, 0.65673828125], [68, 839, 122, 956, 0.65625], [69, 839, 122, 956, 0.658203125], [69, 839, 123, 956, 0.66015625], [69, 839, 123, 956, 0.6591796875], [69, 838, 123, 956, 0.65625], [69, 839, 124, 956, 0.65869140625], [69, 839, 124, 956, 0.65771484375], [70, 839, 124, 956, 0.6591796875], [70, 839, 124, 956, 0.66064453125], [70, 840, 124, 956, 0.6611328125], [70, 840, 124, 957, 0.65966796875], [70, 841, 124, 957, 0.66015625], [70, 841, 124, 957, 0.658203125], [70, 844, 125, 958, 0.66455078125], [71, 851, 124, 961, 0.66552734375]]\n",
      "Key: Jc, vector len: 6, Card Detections: [[75, 866, 133, 997, 0.57568359375], [74, 866, 129, 985, 0.67041015625], [74, 866, 129, 985, 0.6787109375], [74, 866, 129, 985, 0.681640625], [75, 867, 128, 985, 0.68994140625], [75, 870, 129, 987, 0.68603515625]]\n",
      "Key: Jd, vector len: 140, Card Detections: [[427, 932, 478, 1019, 0.53564453125], [428, 927, 480, 1018, 0.505859375], [430, 924, 480, 1014, 0.60107421875], [431, 922, 480, 1013, 0.61572265625], [432, 917, 483, 1010, 0.6357421875], [433, 914, 483, 1007, 0.65234375], [434, 911, 484, 1005, 0.65234375], [436, 907, 485, 1003, 0.634765625], [436, 903, 485, 1001, 0.6455078125], [437, 902, 486, 1001, 0.6435546875], [438, 899, 487, 999, 0.62890625], [438, 896, 488, 998, 0.62890625], [439, 893, 489, 996, 0.62744140625], [440, 891, 489, 995, 0.63134765625], [441, 890, 490, 994, 0.63330078125], [441, 890, 490, 992, 0.62353515625], [441, 889, 490, 991, 0.6279296875], [442, 887, 491, 991, 0.64453125], [442, 886, 491, 988, 0.63671875], [443, 886, 491, 988, 0.638671875], [443, 885, 492, 987, 0.634765625], [444, 884, 492, 987, 0.63037109375], [444, 884, 492, 986, 0.62548828125], [444, 883, 493, 986, 0.61962890625], [445, 883, 493, 986, 0.61669921875], [445, 883, 493, 987, 0.62109375], [445, 883, 493, 987, 0.62060546875], [445, 882, 493, 986, 0.61376953125], [445, 882, 494, 984, 0.6142578125], [446, 882, 494, 984, 0.61962890625], [446, 881, 494, 983, 0.619140625], [446, 881, 495, 983, 0.6220703125], [446, 881, 495, 983, 0.62548828125], [447, 880, 495, 982, 0.626953125], [447, 880, 496, 982, 0.626953125], [447, 879, 496, 982, 0.62744140625], [447, 879, 496, 983, 0.626953125], [447, 879, 496, 982, 0.62646484375], [447, 879, 496, 982, 0.626953125], [447, 878, 496, 982, 0.62841796875], [447, 878, 496, 982, 0.63037109375], [447, 878, 496, 982, 0.6298828125], [447, 878, 496, 982, 0.63134765625], [447, 878, 496, 982, 0.62939453125], [447, 878, 496, 982, 0.62890625], [447, 878, 496, 981, 0.63037109375], [447, 878, 496, 981, 0.62841796875], [447, 878, 496, 981, 0.62890625], [448, 878, 496, 981, 0.63134765625], [448, 878, 496, 981, 0.6298828125], [448, 878, 496, 982, 0.63232421875], [448, 878, 496, 981, 0.63037109375], [448, 878, 496, 982, 0.6318359375], [449, 878, 496, 981, 0.63427734375], [449, 878, 497, 981, 0.63134765625], [449, 878, 497, 981, 0.63037109375], [449, 878, 497, 981, 0.62939453125], [449, 878, 497, 981, 0.63037109375], [449, 878, 497, 981, 0.63037109375], [449, 878, 497, 981, 0.62548828125], [449, 878, 497, 981, 0.6279296875], [449, 878, 497, 981, 0.62548828125], [449, 878, 497, 981, 0.62744140625], [449, 878, 497, 981, 0.62548828125], [449, 878, 497, 982, 0.625], [449, 878, 497, 982, 0.62841796875], [449, 878, 497, 982, 0.6279296875], [449, 878, 497, 982, 0.6279296875], [449, 878, 497, 982, 0.62548828125], [449, 878, 497, 982, 0.6279296875], [449, 877, 497, 982, 0.62939453125], [449, 878, 497, 982, 0.62841796875], [449, 878, 497, 982, 0.6298828125], [449, 877, 497, 982, 0.626953125], [449, 877, 497, 982, 0.62939453125], [449, 878, 498, 981, 0.6279296875], [450, 877, 497, 981, 0.6279296875], [450, 877, 497, 982, 0.626953125], [450, 877, 497, 981, 0.62744140625], [450, 877, 497, 981, 0.62744140625], [450, 877, 498, 981, 0.62548828125], [450, 877, 498, 981, 0.6279296875], [450, 877, 498, 981, 0.6279296875], [450, 877, 498, 981, 0.6298828125], [450, 877, 498, 981, 0.63134765625], [450, 877, 498, 981, 0.62939453125], [450, 877, 498, 981, 0.630859375], [450, 877, 498, 982, 0.63134765625], [450, 877, 498, 981, 0.62646484375], [450, 876, 498, 981, 0.634765625], [450, 877, 498, 981, 0.63134765625], [450, 877, 498, 981, 0.6318359375], [450, 877, 498, 981, 0.6318359375], [450, 877, 498, 981, 0.630859375], [450, 877, 498, 981, 0.6318359375], [450, 877, 498, 981, 0.63427734375], [450, 877, 498, 982, 0.63427734375], [450, 877, 498, 982, 0.6318359375], [450, 877, 497, 982, 0.630859375], [450, 877, 497, 983, 0.6328125], [449, 878, 497, 983, 0.6337890625], [449, 878, 497, 983, 0.63623046875], [449, 878, 497, 983, 0.63818359375], [449, 878, 497, 983, 0.634765625], [449, 878, 497, 983, 0.6376953125], [449, 878, 497, 984, 0.6376953125], [449, 878, 497, 983, 0.63525390625], [449, 878, 497, 984, 0.63427734375], [449, 878, 497, 984, 0.634765625], [449, 879, 497, 984, 0.63623046875], [449, 879, 496, 984, 0.63623046875], [449, 879, 496, 984, 0.6357421875], [448, 879, 496, 984, 0.630859375], [448, 879, 496, 983, 0.6328125], [448, 878, 496, 983, 0.63330078125], [448, 878, 495, 983, 0.6337890625], [448, 878, 495, 983, 0.63525390625], [448, 878, 495, 983, 0.6318359375], [447, 878, 495, 983, 0.62890625], [447, 879, 495, 983, 0.62646484375], [447, 878, 495, 983, 0.626953125], [447, 878, 495, 983, 0.62646484375], [447, 878, 495, 984, 0.62646484375], [446, 878, 495, 984, 0.625], [446, 878, 495, 984, 0.62646484375], [446, 879, 495, 985, 0.62744140625], [446, 879, 495, 985, 0.62646484375], [446, 879, 495, 985, 0.62744140625], [446, 879, 494, 985, 0.6279296875], [446, 879, 494, 985, 0.626953125], [446, 880, 494, 986, 0.62744140625], [445, 880, 494, 986, 0.626953125], [445, 881, 493, 986, 0.626953125], [445, 881, 493, 986, 0.626953125], [444, 881, 492, 986, 0.62451171875], [444, 882, 492, 986, 0.623046875], [443, 882, 491, 987, 0.6220703125], [443, 883, 491, 987, 0.62158203125], [441, 883, 490, 988, 0.62890625], [440, 885, 489, 988, 0.640625]]\n",
      "Key: Jh, vector len: 4, Card Detections: [[441, 877, 491, 983, 0.62646484375], [440, 876, 490, 986, 0.61767578125], [440, 876, 490, 987, 0.6181640625], [440, 877, 490, 987, 0.619140625]]\n",
      "Key: Js, vector len: 26, Card Detections: [[442, 876, 492, 991, 0.67919921875], [442, 877, 491, 991, 0.68212890625], [442, 877, 491, 992, 0.68359375], [442, 877, 492, 992, 0.68310546875], [442, 877, 492, 992, 0.6845703125], [442, 877, 492, 992, 0.68603515625], [442, 877, 492, 992, 0.68603515625], [442, 877, 492, 992, 0.6865234375], [442, 877, 492, 992, 0.68603515625], [442, 877, 492, 992, 0.6865234375], [443, 876, 492, 991, 0.68408203125], [442, 877, 492, 991, 0.6845703125], [442, 877, 492, 992, 0.69140625], [443, 877, 492, 991, 0.70068359375], [442, 877, 492, 992, 0.7001953125], [442, 877, 492, 992, 0.69970703125], [442, 877, 492, 991, 0.69873046875], [442, 877, 492, 992, 0.69921875], [442, 877, 492, 992, 0.69873046875], [442, 877, 492, 991, 0.69970703125], [442, 877, 492, 991, 0.69921875], [442, 877, 492, 991, 0.7001953125], [442, 877, 492, 993, 0.68212890625], [442, 877, 491, 993, 0.69384765625], [441, 878, 491, 994, 0.69091796875], [441, 879, 491, 993, 0.69091796875]]\n",
      "Key: Kc, vector len: 5, Card Detections: [[440, 880, 494, 989, 0.70751953125], [441, 880, 495, 989, 0.71142578125], [440, 880, 495, 989, 0.71923828125], [441, 881, 494, 989, 0.712890625], [440, 883, 493, 990, 0.70556640625]]\n",
      "Key: Kd, vector len: 12, Card Detections: [[73, 825, 127, 942, 0.642578125], [73, 825, 127, 940, 0.64990234375], [73, 826, 127, 942, 0.64501953125], [73, 826, 127, 942, 0.64208984375], [74, 827, 127, 942, 0.64501953125], [74, 827, 127, 943, 0.64599609375], [74, 827, 127, 943, 0.64453125], [74, 827, 127, 943, 0.64208984375], [74, 828, 127, 943, 0.64111328125], [74, 828, 128, 943, 0.642578125], [74, 828, 128, 944, 0.6484375], [77, 833, 130, 946, 0.63720703125]]\n",
      "Key: Kh, vector len: 22, Card Detections: [[439, 876, 490, 989, 0.65966796875], [439, 876, 489, 991, 0.6591796875], [439, 877, 489, 991, 0.66064453125], [439, 877, 489, 992, 0.66943359375], [439, 879, 489, 992, 0.6728515625], [439, 879, 489, 993, 0.67724609375], [439, 879, 489, 992, 0.67822265625], [438, 880, 488, 992, 0.67529296875], [438, 880, 488, 993, 0.67236328125], [438, 881, 488, 993, 0.66796875], [438, 881, 488, 993, 0.662109375], [438, 881, 487, 994, 0.66064453125], [437, 882, 487, 994, 0.66015625], [437, 882, 487, 994, 0.6591796875], [437, 882, 487, 994, 0.65966796875], [437, 882, 487, 994, 0.65576171875], [437, 882, 487, 995, 0.654296875], [437, 882, 487, 995, 0.64990234375], [437, 883, 486, 995, 0.646484375], [437, 883, 486, 995, 0.64404296875], [437, 884, 486, 994, 0.64501953125], [434, 887, 485, 997, 0.6259765625]]\n",
      "Key: Ks, vector len: 5, Card Detections: [[77, 880, 131, 994, 0.650390625], [77, 881, 131, 996, 0.66455078125], [77, 878, 133, 995, 0.67822265625], [77, 878, 132, 995, 0.65673828125], [77, 878, 133, 995, 0.66357421875]]\n",
      "Key: Qc, vector len: 10, Card Detections: [[444, 878, 498, 984, 0.55419921875], [444, 878, 495, 987, 0.60107421875], [444, 878, 496, 988, 0.59912109375], [444, 878, 496, 990, 0.6171875], [443, 879, 496, 990, 0.615234375], [443, 879, 496, 991, 0.61767578125], [443, 880, 496, 990, 0.6142578125], [443, 880, 496, 991, 0.60302734375], [443, 881, 495, 991, 0.625], [441, 883, 495, 992, 0.63623046875]]\n",
      "Key: Qd, vector len: 7, Card Detections: [[77, 866, 130, 980, 0.6201171875], [77, 867, 129, 978, 0.6044921875], [77, 867, 129, 979, 0.61181640625], [77, 866, 130, 978, 0.61279296875], [77, 866, 130, 978, 0.61376953125], [78, 866, 131, 978, 0.61328125], [80, 873, 133, 980, 0.576171875]]\n",
      "Key: Qh, vector len: 14, Card Detections: [[444, 875, 494, 985, 0.66552734375], [443, 875, 494, 985, 0.66455078125], [444, 875, 494, 986, 0.66357421875], [444, 875, 494, 986, 0.65869140625], [444, 875, 494, 986, 0.66064453125], [443, 875, 494, 986, 0.64990234375], [443, 875, 493, 986, 0.646484375], [443, 875, 493, 986, 0.65283203125], [443, 875, 493, 986, 0.65380859375], [443, 875, 493, 986, 0.65380859375], [443, 875, 493, 986, 0.6484375], [442, 876, 493, 986, 0.646484375], [442, 876, 492, 987, 0.64501953125], [441, 876, 492, 986, 0.6533203125]]\n",
      "Key: Qs, vector len: 5, Card Detections: [[444, 879, 494, 986, 0.67529296875], [443, 880, 493, 986, 0.68505859375], [443, 880, 494, 988, 0.671875], [443, 880, 493, 989, 0.6748046875], [441, 881, 493, 991, 0.6826171875]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 0, Card Detections: []\n",
      "Key: Tc, vector len: 6, Card Detections: [[47, 865, 88, 961, 0.61962890625], [48, 864, 88, 960, 0.63134765625], [48, 865, 88, 962, 0.63427734375], [48, 865, 88, 962, 0.640625], [48, 866, 88, 962, 0.65185546875], [49, 871, 92, 969, 0.64990234375]]\n",
      "Key: Td, vector len: 6, Card Detections: [[46, 875, 90, 969, 0.6845703125], [47, 875, 89, 967, 0.6865234375], [47, 875, 89, 968, 0.6884765625], [47, 875, 89, 968, 0.68603515625], [48, 875, 90, 967, 0.68359375], [50, 881, 93, 971, 0.6669921875]]\n",
      "Key: Th, vector len: 9, Card Detections: [[326, 903, 366, 992, 0.62109375], [326, 903, 366, 991, 0.61865234375], [326, 903, 366, 992, 0.615234375], [326, 904, 365, 992, 0.609375], [326, 904, 365, 992, 0.61328125], [326, 904, 365, 992, 0.6123046875], [326, 904, 365, 992, 0.6142578125], [325, 906, 364, 993, 0.62939453125], [325, 906, 364, 993, 0.62548828125]]\n",
      "Key: Ts, vector len: 4, Card Detections: [[44, 860, 87, 956, 0.58349609375], [43, 861, 87, 957, 0.58203125], [44, 860, 87, 956, 0.58056640625], [46, 863, 90, 958, 0.615234375]]\n",
      "Key: 2c, vector len: 22, Card Detections: [[330, 900, 372, 991, 0.63232421875], [329, 901, 373, 992, 0.63232421875], [330, 900, 372, 991, 0.62841796875], [330, 901, 372, 992, 0.6337890625], [330, 900, 372, 992, 0.6279296875], [330, 901, 372, 992, 0.62939453125], [330, 901, 372, 992, 0.626953125], [330, 901, 372, 992, 0.62353515625], [330, 901, 372, 992, 0.62109375], [330, 901, 372, 992, 0.62353515625], [330, 901, 372, 992, 0.62646484375], [330, 901, 372, 992, 0.6259765625], [330, 901, 372, 992, 0.63427734375], [330, 902, 372, 992, 0.6142578125], [329, 901, 372, 992, 0.611328125], [329, 902, 372, 992, 0.6123046875], [329, 902, 372, 991, 0.61376953125], [329, 902, 372, 992, 0.611328125], [329, 902, 372, 992, 0.6123046875], [329, 902, 371, 993, 0.6103515625], [329, 903, 372, 993, 0.61474609375], [328, 905, 370, 994, 0.607421875]]\n",
      "Key: 2d, vector len: 39, Card Detections: [[335, 904, 373, 991, 0.5927734375], [334, 904, 374, 991, 0.6015625], [334, 904, 373, 992, 0.58935546875], [334, 905, 373, 992, 0.609375], [334, 905, 373, 992, 0.609375], [334, 905, 373, 992, 0.60400390625], [334, 904, 373, 992, 0.59765625], [334, 905, 373, 992, 0.59716796875], [334, 904, 373, 992, 0.58984375], [334, 904, 373, 992, 0.59521484375], [334, 904, 373, 992, 0.595703125], [334, 904, 373, 992, 0.58740234375], [334, 904, 374, 991, 0.58349609375], [334, 904, 374, 992, 0.58447265625], [334, 903, 374, 991, 0.58447265625], [334, 903, 374, 991, 0.5859375], [334, 903, 374, 991, 0.59033203125], [335, 903, 374, 991, 0.5908203125], [334, 903, 374, 991, 0.587890625], [334, 904, 374, 991, 0.58837890625], [334, 904, 374, 992, 0.5927734375], [334, 904, 374, 992, 0.5927734375], [334, 904, 374, 992, 0.58984375], [334, 904, 373, 991, 0.59375], [334, 905, 373, 992, 0.609375], [334, 905, 373, 992, 0.60693359375], [334, 905, 373, 992, 0.603515625], [334, 906, 373, 992, 0.5927734375], [334, 906, 372, 992, 0.59912109375], [334, 907, 372, 993, 0.59765625], [333, 907, 371, 993, 0.60205078125], [333, 908, 370, 993, 0.60986328125], [332, 908, 371, 993, 0.60546875], [332, 909, 369, 994, 0.6357421875], [331, 910, 368, 994, 0.66748046875], [330, 911, 368, 995, 0.666015625], [329, 911, 367, 997, 0.6669921875], [327, 913, 367, 998, 0.6552734375], [326, 914, 366, 998, 0.6318359375]]\n",
      "Key: 2h, vector len: 7, Card Detections: [[45, 868, 89, 961, 0.6298828125], [46, 866, 89, 962, 0.6279296875], [46, 866, 89, 962, 0.6220703125], [46, 865, 89, 963, 0.6318359375], [47, 865, 89, 962, 0.6259765625], [47, 867, 89, 962, 0.6318359375], [47, 866, 89, 964, 0.63427734375]]\n",
      "Key: 2s, vector len: 9, Card Detections: [[30, 861, 74, 957, 0.65625], [30, 860, 74, 957, 0.66015625], [29, 860, 72, 956, 0.6513671875], [29, 860, 72, 956, 0.65234375], [28, 861, 72, 956, 0.6533203125], [28, 862, 72, 957, 0.6533203125], [28, 862, 72, 958, 0.6494140625], [28, 864, 72, 958, 0.6513671875], [29, 866, 73, 959, 0.65673828125]]\n",
      "Key: 3c, vector len: 9, Card Detections: [[47, 899, 91, 984, 0.556640625], [48, 898, 91, 985, 0.57421875], [48, 898, 92, 988, 0.57763671875], [49, 897, 93, 988, 0.58203125], [49, 897, 93, 987, 0.587890625], [49, 896, 93, 986, 0.5888671875], [49, 897, 94, 985, 0.5810546875], [50, 896, 94, 987, 0.58642578125], [49, 896, 95, 987, 0.58544921875]]\n",
      "Key: 3d, vector len: 7, Card Detections: [[44, 860, 88, 956, 0.6357421875], [44, 861, 88, 956, 0.630859375], [44, 860, 88, 956, 0.62646484375], [44, 861, 88, 957, 0.626953125], [44, 861, 88, 957, 0.63037109375], [44, 861, 89, 958, 0.638671875], [45, 862, 89, 958, 0.6103515625]]\n",
      "Key: 3h, vector len: 12, Card Detections: [[327, 903, 368, 995, 0.642578125], [328, 903, 368, 993, 0.5986328125], [328, 903, 369, 992, 0.623046875], [328, 904, 369, 992, 0.615234375], [328, 904, 368, 993, 0.61181640625], [328, 903, 369, 992, 0.6142578125], [328, 904, 369, 992, 0.61181640625], [328, 904, 368, 992, 0.6103515625], [328, 904, 368, 993, 0.60498046875], [328, 904, 367, 993, 0.59326171875], [328, 904, 367, 993, 0.59033203125], [327, 904, 367, 993, 0.59716796875]]\n",
      "Key: 3s, vector len: 8, Card Detections: [[326, 901, 369, 985, 0.62451171875], [326, 900, 369, 985, 0.6259765625], [326, 899, 369, 984, 0.6337890625], [326, 899, 369, 985, 0.63232421875], [326, 899, 369, 985, 0.6328125], [326, 901, 369, 986, 0.62158203125], [324, 902, 368, 987, 0.61181640625], [324, 903, 368, 987, 0.6015625]]\n",
      "Key: 4c, vector len: 8, Card Detections: [[45, 873, 148, 971, 0.64697265625], [45, 871, 149, 971, 0.6474609375], [45, 871, 149, 971, 0.64892578125], [46, 871, 148, 970, 0.63818359375], [44, 871, 149, 970, 0.646484375], [46, 871, 148, 970, 0.634765625], [46, 871, 148, 970, 0.6435546875], [47, 873, 148, 970, 0.6416015625]]\n",
      "Key: 4d, vector len: 15, Card Detections: [[24, 862, 119, 961, 0.6064453125], [24, 864, 119, 962, 0.60693359375], [23, 867, 119, 964, 0.609375], [24, 866, 119, 964, 0.60498046875], [24, 868, 119, 966, 0.599609375], [24, 870, 118, 966, 0.5966796875], [24, 872, 119, 967, 0.595703125], [25, 874, 118, 968, 0.599609375], [25, 875, 118, 968, 0.60400390625], [25, 875, 117, 968, 0.60400390625], [25, 875, 117, 969, 0.60546875], [25, 876, 118, 969, 0.60205078125], [25, 876, 118, 969, 0.60302734375], [26, 876, 118, 969, 0.6005859375], [26, 882, 119, 969, 0.6123046875]]\n",
      "Key: 4h, vector len: 11, Card Detections: [[330, 901, 417, 987, 0.64013671875], [330, 902, 415, 994, 0.6376953125], [330, 902, 416, 994, 0.638671875], [330, 902, 415, 994, 0.64111328125], [330, 902, 415, 994, 0.64404296875], [330, 901, 415, 994, 0.6435546875], [330, 901, 415, 994, 0.64501953125], [330, 901, 415, 993, 0.64501953125], [329, 902, 415, 994, 0.63671875], [329, 902, 415, 994, 0.63525390625], [329, 902, 414, 994, 0.634765625]]\n",
      "Key: 4s, vector len: 6, Card Detections: [[44, 859, 138, 962, 0.623046875], [44, 860, 138, 962, 0.6240234375], [44, 860, 138, 962, 0.626953125], [44, 860, 137, 962, 0.62939453125], [45, 861, 138, 963, 0.626953125], [45, 865, 138, 963, 0.623046875]]\n",
      "Key: 5c, vector len: 40, Card Detections: [[24, 885, 66, 974, 0.6240234375], [24, 885, 66, 975, 0.62841796875], [23, 885, 66, 976, 0.62548828125], [24, 885, 66, 976, 0.63134765625], [24, 885, 67, 975, 0.6328125], [24, 884, 67, 973, 0.63330078125], [24, 884, 67, 974, 0.6298828125], [24, 884, 67, 973, 0.63427734375], [24, 884, 67, 974, 0.6328125], [24, 885, 67, 974, 0.630859375], [24, 884, 67, 974, 0.63232421875], [25, 884, 68, 974, 0.630859375], [25, 885, 68, 974, 0.6416015625], [25, 886, 68, 974, 0.6103515625], [25, 886, 68, 974, 0.61328125], [25, 887, 69, 974, 0.6025390625], [25, 887, 69, 975, 0.60107421875], [26, 890, 68, 976, 0.6455078125], [26, 890, 68, 976, 0.64013671875], [26, 892, 68, 978, 0.64599609375], [26, 892, 68, 978, 0.64306640625], [26, 893, 68, 978, 0.6318359375], [26, 893, 68, 978, 0.630859375], [26, 894, 68, 979, 0.6220703125], [26, 895, 68, 979, 0.615234375], [26, 895, 68, 979, 0.6171875], [26, 895, 68, 979, 0.60205078125], [26, 896, 67, 979, 0.59033203125], [26, 896, 67, 978, 0.5517578125], [26, 896, 67, 978, 0.57080078125], [27, 895, 68, 977, 0.59228515625], [26, 896, 68, 977, 0.5703125], [27, 896, 68, 977, 0.6123046875], [27, 896, 68, 978, 0.6171875], [27, 896, 68, 978, 0.61083984375], [27, 897, 68, 978, 0.60791015625], [27, 898, 68, 978, 0.60009765625], [27, 899, 68, 978, 0.59375], [26, 899, 68, 979, 0.57861328125], [27, 900, 68, 980, 0.53076171875]]\n",
      "Key: 5d, vector len: 6, Card Detections: [[43, 862, 85, 957, 0.6318359375], [43, 862, 85, 957, 0.63232421875], [42, 862, 85, 956, 0.62158203125], [43, 861, 85, 956, 0.62890625], [43, 861, 85, 956, 0.63427734375], [43, 860, 85, 955, 0.63134765625]]\n",
      "Key: 5h, vector len: 22, Card Detections: [[23, 874, 64, 964, 0.62353515625], [23, 875, 64, 965, 0.60595703125], [23, 875, 64, 966, 0.64111328125], [24, 875, 64, 966, 0.64111328125], [23, 875, 64, 965, 0.62646484375], [24, 875, 64, 965, 0.62353515625], [24, 877, 65, 967, 0.64990234375], [24, 878, 65, 967, 0.65380859375], [24, 880, 65, 968, 0.6630859375], [24, 881, 65, 969, 0.66015625], [24, 882, 65, 970, 0.6650390625], [25, 884, 65, 971, 0.66064453125], [24, 886, 65, 973, 0.6611328125], [24, 888, 65, 973, 0.66162109375], [24, 889, 65, 974, 0.6533203125], [25, 890, 66, 974, 0.65576171875], [26, 891, 66, 975, 0.64111328125], [25, 891, 66, 975, 0.63525390625], [25, 891, 66, 975, 0.642578125], [26, 892, 66, 975, 0.63818359375], [26, 891, 67, 975, 0.6455078125], [27, 888, 69, 977, 0.6142578125]]\n",
      "Key: 5s, vector len: 13, Card Detections: [[324, 898, 367, 980, 0.6640625], [325, 897, 366, 986, 0.6318359375], [325, 900, 365, 988, 0.640625], [325, 899, 365, 988, 0.6435546875], [325, 899, 365, 989, 0.6337890625], [325, 901, 365, 989, 0.6015625], [325, 901, 365, 989, 0.6337890625], [325, 899, 365, 989, 0.6357421875], [324, 901, 365, 990, 0.5634765625], [324, 900, 365, 990, 0.625], [322, 901, 364, 991, 0.64697265625], [322, 901, 364, 991, 0.6474609375], [320, 903, 363, 991, 0.63671875]]\n",
      "Key: 6c, vector len: 6, Card Detections: [[44, 864, 86, 962, 0.6611328125], [43, 865, 86, 961, 0.65869140625], [44, 864, 86, 962, 0.66748046875], [44, 864, 86, 961, 0.666015625], [44, 866, 86, 962, 0.66455078125], [45, 869, 90, 964, 0.66552734375]]\n",
      "Key: 6d, vector len: 158, Card Detections: [[314, 976, 363, 1029, 0.55078125], [314, 973, 363, 1027, 0.56982421875], [314, 971, 361, 1025, 0.59814453125], [314, 969, 361, 1024, 0.62060546875], [314, 967, 361, 1024, 0.6171875], [315, 965, 361, 1022, 0.60205078125], [316, 963, 362, 1022, 0.57666015625], [315, 963, 362, 1022, 0.6005859375], [315, 961, 362, 1020, 0.6083984375], [316, 960, 363, 1020, 0.62451171875], [316, 959, 363, 1020, 0.6416015625], [316, 957, 362, 1018, 0.62255859375], [317, 956, 362, 1016, 0.63330078125], [316, 954, 362, 1016, 0.63916015625], [316, 953, 362, 1015, 0.62744140625], [316, 952, 362, 1015, 0.6396484375], [317, 949, 362, 1014, 0.634765625], [317, 948, 362, 1013, 0.61083984375], [317, 946, 362, 1012, 0.62890625], [317, 945, 362, 1011, 0.6474609375], [317, 943, 362, 1010, 0.65283203125], [317, 941, 362, 1009, 0.654296875], [317, 940, 362, 1008, 0.65966796875], [318, 938, 362, 1007, 0.6630859375], [317, 937, 362, 1007, 0.66015625], [317, 936, 362, 1006, 0.65625], [317, 935, 362, 1006, 0.6357421875], [317, 933, 362, 1005, 0.63525390625], [317, 933, 361, 1004, 0.62451171875], [317, 931, 361, 1003, 0.62744140625], [317, 931, 360, 1002, 0.63427734375], [317, 929, 361, 1002, 0.6396484375], [317, 929, 360, 1001, 0.638671875], [316, 928, 359, 1000, 0.6455078125], [316, 927, 359, 1000, 0.6484375], [317, 926, 359, 999, 0.65234375], [317, 925, 359, 998, 0.66357421875], [318, 924, 359, 997, 0.66845703125], [318, 924, 359, 996, 0.6708984375], [318, 923, 360, 997, 0.6611328125], [318, 922, 360, 997, 0.6572265625], [317, 921, 361, 996, 0.65771484375], [317, 920, 361, 996, 0.658203125], [317, 919, 361, 995, 0.66015625], [318, 919, 361, 995, 0.658203125], [318, 918, 361, 995, 0.6533203125], [318, 917, 361, 994, 0.65576171875], [319, 916, 361, 993, 0.6494140625], [319, 916, 361, 992, 0.64892578125], [319, 915, 361, 991, 0.6494140625], [319, 914, 361, 991, 0.650390625], [320, 914, 361, 990, 0.6494140625], [320, 913, 361, 990, 0.64892578125], [320, 913, 361, 989, 0.650390625], [320, 912, 361, 989, 0.65478515625], [320, 912, 362, 989, 0.66015625], [321, 910, 362, 987, 0.66455078125], [321, 910, 362, 987, 0.6689453125], [321, 908, 362, 986, 0.666015625], [321, 907, 363, 986, 0.658203125], [322, 906, 363, 986, 0.65283203125], [322, 906, 363, 986, 0.65478515625], [322, 905, 363, 986, 0.6474609375], [322, 905, 363, 985, 0.65087890625], [322, 904, 363, 986, 0.6455078125], [322, 904, 363, 986, 0.64453125], [323, 903, 364, 985, 0.64501953125], [323, 903, 364, 984, 0.64404296875], [323, 903, 364, 984, 0.64404296875], [323, 903, 364, 985, 0.642578125], [323, 903, 364, 985, 0.64501953125], [323, 903, 364, 985, 0.64794921875], [323, 903, 364, 984, 0.6484375], [323, 903, 364, 984, 0.65234375], [323, 902, 364, 984, 0.65478515625], [323, 903, 364, 984, 0.65380859375], [324, 902, 364, 983, 0.658203125], [324, 902, 364, 983, 0.66064453125], [324, 902, 364, 983, 0.6611328125], [324, 902, 364, 983, 0.6640625], [324, 902, 364, 983, 0.6640625], [324, 901, 364, 983, 0.66796875], [324, 901, 364, 983, 0.66748046875], [324, 901, 364, 983, 0.66357421875], [324, 901, 364, 983, 0.66162109375], [324, 901, 365, 983, 0.669921875], [324, 901, 365, 983, 0.6689453125], [324, 901, 365, 983, 0.66796875], [324, 901, 365, 983, 0.66748046875], [324, 900, 365, 983, 0.6689453125], [324, 900, 365, 983, 0.67041015625], [325, 900, 365, 983, 0.66796875], [325, 900, 365, 983, 0.67041015625], [325, 900, 365, 983, 0.669921875], [325, 900, 365, 983, 0.6708984375], [325, 900, 365, 983, 0.66748046875], [325, 900, 365, 983, 0.666015625], [325, 900, 365, 983, 0.66796875], [325, 900, 365, 983, 0.66943359375], [325, 900, 365, 983, 0.67041015625], [325, 900, 365, 983, 0.669921875], [325, 900, 365, 983, 0.669921875], [325, 900, 365, 983, 0.67041015625], [325, 900, 365, 983, 0.66943359375], [325, 900, 365, 983, 0.67138671875], [325, 900, 365, 983, 0.67138671875], [325, 900, 365, 983, 0.67431640625], [325, 900, 365, 983, 0.66845703125], [325, 900, 365, 983, 0.67138671875], [325, 901, 365, 983, 0.67138671875], [325, 901, 365, 983, 0.66845703125], [325, 901, 364, 983, 0.66796875], [325, 901, 364, 983, 0.66552734375], [325, 900, 365, 983, 0.66748046875], [325, 900, 365, 983, 0.66650390625], [325, 901, 365, 983, 0.666015625], [325, 901, 365, 984, 0.66064453125], [324, 901, 365, 984, 0.6591796875], [324, 901, 364, 984, 0.66064453125], [324, 901, 364, 984, 0.66064453125], [324, 902, 364, 984, 0.658203125], [324, 902, 364, 984, 0.6591796875], [325, 902, 364, 984, 0.65869140625], [325, 902, 364, 984, 0.65771484375], [325, 901, 364, 984, 0.6630859375], [325, 902, 364, 984, 0.66064453125], [325, 902, 364, 984, 0.6611328125], [325, 902, 364, 984, 0.65869140625], [325, 902, 364, 984, 0.65869140625], [325, 902, 364, 984, 0.65283203125], [324, 902, 364, 985, 0.64892578125], [324, 902, 364, 985, 0.64599609375], [324, 903, 364, 986, 0.642578125], [324, 903, 364, 986, 0.64306640625], [324, 903, 364, 986, 0.642578125], [324, 903, 364, 986, 0.64306640625], [324, 903, 364, 986, 0.642578125], [324, 903, 364, 986, 0.64208984375], [324, 903, 364, 986, 0.64013671875], [324, 903, 364, 986, 0.63916015625], [323, 904, 364, 986, 0.64208984375], [323, 904, 364, 986, 0.64306640625], [324, 904, 364, 986, 0.64404296875], [323, 904, 364, 986, 0.64306640625], [323, 904, 364, 986, 0.63916015625], [323, 904, 364, 985, 0.64306640625], [323, 903, 364, 986, 0.640625], [323, 904, 364, 986, 0.6455078125], [323, 904, 364, 986, 0.6484375], [323, 904, 363, 986, 0.6484375], [323, 904, 364, 986, 0.64794921875], [323, 904, 364, 986, 0.6484375], [323, 904, 364, 986, 0.64697265625], [323, 904, 364, 986, 0.64892578125], [323, 904, 363, 986, 0.6484375], [323, 904, 363, 987, 0.64990234375], [323, 905, 363, 987, 0.6533203125], [320, 907, 362, 985, 0.64599609375]]\n",
      "Key: 6h, vector len: 11, Card Detections: [[49, 889, 88, 978, 0.63037109375], [48, 889, 88, 979, 0.62939453125], [48, 888, 88, 978, 0.62744140625], [48, 888, 88, 978, 0.63330078125], [48, 888, 89, 978, 0.6298828125], [48, 888, 89, 979, 0.6376953125], [48, 887, 89, 978, 0.6416015625], [48, 887, 89, 978, 0.63623046875], [48, 886, 89, 978, 0.63623046875], [48, 887, 89, 978, 0.64697265625], [48, 887, 89, 978, 0.650390625]]\n",
      "Key: 6s, vector len: 17, Card Detections: [[28, 861, 69, 958, 0.68603515625], [27, 861, 69, 959, 0.67724609375], [26, 862, 68, 960, 0.67041015625], [26, 863, 68, 960, 0.673828125], [25, 862, 67, 959, 0.68017578125], [25, 862, 67, 959, 0.68017578125], [25, 862, 67, 959, 0.70751953125], [25, 862, 67, 959, 0.7001953125], [25, 862, 67, 959, 0.6953125], [25, 862, 67, 958, 0.6943359375], [25, 861, 67, 958, 0.697265625], [25, 861, 67, 958, 0.7080078125], [25, 861, 67, 958, 0.70947265625], [25, 861, 67, 958, 0.70751953125], [25, 862, 67, 958, 0.6845703125], [26, 863, 68, 959, 0.67578125], [28, 867, 71, 962, 0.63330078125]]\n",
      "Key: 7c, vector len: 13, Card Detections: [[328, 903, 368, 995, 0.619140625], [328, 903, 368, 995, 0.6123046875], [328, 903, 367, 996, 0.6181640625], [328, 903, 368, 995, 0.62109375], [328, 904, 367, 996, 0.619140625], [327, 904, 367, 996, 0.5947265625], [328, 904, 367, 996, 0.60400390625], [328, 904, 368, 996, 0.59765625], [329, 903, 367, 994, 0.59619140625], [328, 904, 367, 995, 0.59423828125], [328, 904, 367, 995, 0.5947265625], [328, 904, 367, 996, 0.607421875], [327, 904, 367, 996, 0.60498046875]]\n",
      "Key: 7d, vector len: 17, Card Detections: [[332, 901, 372, 991, 0.638671875], [332, 901, 371, 991, 0.6279296875], [332, 902, 371, 992, 0.6279296875], [332, 901, 371, 991, 0.6298828125], [332, 902, 371, 993, 0.62646484375], [332, 902, 371, 993, 0.62841796875], [332, 902, 371, 993, 0.62646484375], [332, 902, 371, 993, 0.62744140625], [332, 902, 371, 993, 0.62939453125], [332, 902, 371, 993, 0.6279296875], [332, 902, 371, 993, 0.6259765625], [332, 902, 371, 993, 0.62548828125], [332, 903, 371, 993, 0.6240234375], [331, 903, 370, 994, 0.62060546875], [332, 904, 369, 993, 0.61669921875], [332, 904, 368, 993, 0.62158203125], [330, 908, 367, 994, 0.60693359375]]\n",
      "Key: 7h, vector len: 11, Card Detections: [[333, 899, 372, 991, 0.642578125], [332, 900, 372, 991, 0.64501953125], [333, 899, 372, 991, 0.64111328125], [333, 900, 372, 992, 0.6484375], [332, 900, 371, 992, 0.64697265625], [332, 900, 371, 992, 0.6474609375], [332, 900, 371, 992, 0.6455078125], [332, 902, 371, 992, 0.6484375], [332, 902, 371, 992, 0.65576171875], [331, 902, 370, 993, 0.66455078125], [330, 903, 369, 993, 0.66650390625]]\n",
      "Key: 7s, vector len: 7, Card Detections: [[326, 898, 365, 985, 0.61328125], [325, 899, 364, 986, 0.61328125], [325, 900, 364, 986, 0.61328125], [325, 901, 364, 987, 0.611328125], [324, 902, 363, 988, 0.61328125], [323, 900, 363, 989, 0.6181640625], [322, 902, 363, 990, 0.60888671875]]\n",
      "Key: 8c, vector len: 5, Card Detections: [[326, 900, 367, 987, 0.63525390625], [326, 901, 367, 986, 0.6201171875], [326, 901, 367, 988, 0.6376953125], [325, 901, 367, 988, 0.63818359375], [325, 903, 366, 987, 0.63134765625]]\n",
      "Key: 8d, vector len: 11, Card Detections: [[40, 856, 87, 973, 0.6591796875], [40, 855, 81, 948, 0.70263671875], [39, 858, 81, 950, 0.70068359375], [39, 858, 81, 951, 0.69677734375], [39, 858, 81, 951, 0.6982421875], [39, 860, 81, 953, 0.69140625], [39, 860, 80, 953, 0.69189453125], [39, 861, 80, 953, 0.6884765625], [38, 861, 80, 954, 0.68505859375], [39, 862, 80, 954, 0.6875], [39, 863, 80, 955, 0.68505859375]]\n",
      "Key: 8h, vector len: 6, Card Detections: [[46, 859, 87, 950, 0.728515625], [46, 859, 87, 950, 0.71044921875], [46, 859, 87, 951, 0.71044921875], [46, 859, 88, 951, 0.708984375], [46, 860, 88, 951, 0.708984375], [46, 861, 88, 951, 0.69921875]]\n",
      "Key: 8s, vector len: 5, Card Detections: [[44, 861, 87, 959, 0.6640625], [44, 862, 86, 957, 0.67529296875], [45, 861, 86, 957, 0.67724609375], [45, 860, 87, 956, 0.66552734375], [45, 861, 87, 956, 0.66748046875]]\n",
      "Key: 9c, vector len: 9, Card Detections: [[322, 904, 365, 987, 0.6162109375], [323, 903, 365, 988, 0.6337890625], [323, 903, 365, 988, 0.63037109375], [323, 904, 365, 987, 0.625], [323, 903, 365, 987, 0.62353515625], [323, 904, 365, 989, 0.638671875], [323, 903, 365, 989, 0.64404296875], [323, 904, 364, 988, 0.63671875], [322, 905, 364, 988, 0.64404296875]]\n",
      "Key: 9d, vector len: 11, Card Detections: [[314, 989, 361, 1035, 0.59375], [314, 987, 361, 1034, 0.56982421875], [314, 980, 363, 1030, 0.5498046875], [47, 876, 90, 971, 0.650390625], [48, 876, 89, 967, 0.64892578125], [48, 876, 89, 968, 0.6494140625], [48, 876, 89, 968, 0.65087890625], [48, 876, 89, 968, 0.65234375], [48, 876, 89, 968, 0.65625], [49, 877, 89, 968, 0.65966796875], [49, 877, 90, 969, 0.662109375]]\n",
      "Key: 9h, vector len: 13, Card Detections: [[327, 899, 366, 986, 0.64404296875], [327, 899, 366, 986, 0.64404296875], [327, 900, 366, 987, 0.64306640625], [327, 899, 366, 986, 0.6455078125], [326, 901, 365, 988, 0.63916015625], [326, 901, 365, 988, 0.640625], [326, 901, 365, 988, 0.642578125], [326, 901, 365, 988, 0.6396484375], [326, 902, 365, 989, 0.6357421875], [326, 901, 365, 988, 0.640625], [325, 903, 364, 990, 0.640625], [325, 903, 364, 989, 0.64453125], [323, 906, 363, 991, 0.6416015625]]\n",
      "Key: 9s, vector len: 11, Card Detections: [[47, 892, 93, 1000, 0.6328125], [48, 890, 91, 983, 0.68798828125], [48, 891, 91, 982, 0.6572265625], [48, 889, 92, 983, 0.6533203125], [49, 889, 92, 982, 0.65380859375], [49, 889, 91, 979, 0.65087890625], [48, 889, 92, 979, 0.64599609375], [49, 888, 92, 980, 0.64501953125], [49, 888, 92, 981, 0.65380859375], [49, 889, 91, 980, 0.6484375], [49, 889, 91, 980, 0.64599609375]]\n",
      "Key: Ac, vector len: 9, Card Detections: [[326, 900, 368, 987, 0.64501953125], [326, 900, 368, 987, 0.64794921875], [326, 900, 368, 987, 0.6484375], [326, 900, 368, 987, 0.6484375], [326, 899, 369, 989, 0.64794921875], [326, 900, 368, 987, 0.65234375], [326, 901, 368, 988, 0.64794921875], [326, 901, 368, 989, 0.65185546875], [325, 903, 367, 989, 0.65185546875]]\n",
      "Key: Ad, vector len: 19, Card Detections: [[45, 975, 82, 1031, 0.5126953125], [46, 962, 84, 1025, 0.5078125], [335, 902, 375, 992, 0.6298828125], [335, 902, 376, 992, 0.623046875], [335, 903, 375, 992, 0.62548828125], [335, 903, 375, 993, 0.62255859375], [335, 903, 375, 993, 0.62744140625], [334, 903, 375, 993, 0.6259765625], [334, 903, 375, 993, 0.62744140625], [335, 902, 375, 992, 0.62841796875], [334, 903, 375, 993, 0.62646484375], [334, 903, 375, 993, 0.6240234375], [334, 903, 374, 993, 0.62548828125], [334, 904, 374, 993, 0.62744140625], [334, 904, 374, 994, 0.62841796875], [334, 904, 374, 994, 0.6318359375], [334, 905, 374, 994, 0.630859375], [334, 906, 374, 994, 0.6357421875], [333, 907, 373, 994, 0.6357421875]]\n",
      "Key: Ah, vector len: 139, Card Detections: [[48, 958, 85, 1023, 0.56787109375], [48, 957, 85, 1022, 0.58837890625], [48, 955, 85, 1022, 0.6162109375], [48, 954, 86, 1022, 0.607421875], [48, 953, 86, 1022, 0.5595703125], [49, 951, 86, 1021, 0.55078125], [49, 950, 86, 1020, 0.59228515625], [49, 949, 87, 1019, 0.59326171875], [49, 947, 87, 1017, 0.640625], [49, 946, 87, 1017, 0.65380859375], [49, 945, 87, 1017, 0.65869140625], [49, 944, 87, 1016, 0.66162109375], [49, 942, 86, 1015, 0.66064453125], [49, 941, 87, 1014, 0.66357421875], [49, 941, 87, 1013, 0.66455078125], [49, 939, 87, 1012, 0.66064453125], [50, 939, 87, 1012, 0.65966796875], [49, 937, 87, 1011, 0.66015625], [49, 936, 87, 1010, 0.65966796875], [49, 935, 88, 1009, 0.6611328125], [49, 934, 88, 1009, 0.6630859375], [50, 933, 88, 1009, 0.6630859375], [50, 932, 89, 1008, 0.66162109375], [50, 931, 89, 1007, 0.65087890625], [50, 930, 89, 1007, 0.64794921875], [50, 929, 89, 1006, 0.654296875], [51, 928, 90, 1006, 0.65234375], [51, 926, 90, 1005, 0.65478515625], [51, 925, 91, 1004, 0.65234375], [51, 924, 91, 1003, 0.65087890625], [51, 923, 91, 1003, 0.650390625], [50, 923, 91, 1002, 0.65234375], [51, 922, 91, 1001, 0.654296875], [51, 921, 91, 1001, 0.6513671875], [51, 920, 91, 1001, 0.6494140625], [51, 918, 91, 1000, 0.642578125], [51, 918, 91, 999, 0.6435546875], [51, 917, 91, 998, 0.6279296875], [51, 917, 91, 998, 0.6201171875], [51, 916, 91, 998, 0.60546875], [51, 916, 91, 998, 0.53955078125], [51, 914, 91, 997, 0.51416015625], [51, 914, 91, 997, 0.560546875], [50, 914, 91, 997, 0.5595703125], [50, 914, 91, 996, 0.6201171875], [51, 913, 91, 996, 0.62646484375], [51, 913, 91, 996, 0.62548828125], [51, 912, 91, 995, 0.6318359375], [51, 911, 92, 995, 0.6376953125], [51, 910, 92, 994, 0.63720703125], [51, 910, 92, 994, 0.63623046875], [52, 910, 92, 994, 0.63525390625], [52, 910, 92, 994, 0.6376953125], [52, 909, 92, 994, 0.63818359375], [52, 909, 92, 993, 0.6376953125], [52, 909, 92, 993, 0.640625], [52, 908, 92, 993, 0.6416015625], [51, 908, 92, 993, 0.642578125], [52, 907, 92, 993, 0.64599609375], [51, 907, 92, 993, 0.64697265625], [51, 907, 92, 993, 0.64501953125], [52, 907, 92, 992, 0.6474609375], [51, 907, 91, 992, 0.646484375], [51, 906, 91, 992, 0.64892578125], [50, 907, 91, 992, 0.64794921875], [50, 907, 91, 992, 0.64599609375], [50, 907, 91, 992, 0.64599609375], [50, 906, 91, 992, 0.6484375], [49, 906, 91, 992, 0.6484375], [49, 906, 91, 992, 0.64892578125], [49, 906, 91, 992, 0.6484375], [49, 906, 91, 992, 0.6474609375], [49, 906, 91, 992, 0.6474609375], [50, 906, 91, 992, 0.64501953125], [50, 906, 91, 992, 0.64453125], [50, 906, 91, 992, 0.64453125], [50, 905, 91, 991, 0.64501953125], [51, 905, 91, 991, 0.64599609375], [51, 905, 91, 991, 0.64599609375], [51, 905, 91, 991, 0.64599609375], [51, 905, 91, 991, 0.64794921875], [51, 904, 91, 991, 0.64697265625], [51, 905, 91, 991, 0.6484375], [51, 905, 91, 991, 0.64794921875], [50, 904, 91, 991, 0.6474609375], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 991, 0.64697265625], [50, 904, 91, 991, 0.64599609375], [50, 904, 91, 990, 0.64794921875], [50, 904, 91, 991, 0.6474609375], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 991, 0.64599609375], [50, 904, 91, 991, 0.64599609375], [50, 904, 91, 991, 0.646484375], [50, 904, 91, 990, 0.64794921875], [50, 904, 91, 990, 0.6484375], [50, 904, 92, 990, 0.6484375], [51, 903, 92, 991, 0.6484375], [51, 903, 92, 990, 0.6474609375], [51, 903, 93, 990, 0.6474609375], [52, 903, 93, 989, 0.64794921875], [52, 903, 93, 989, 0.64794921875], [52, 903, 93, 989, 0.64892578125], [52, 903, 93, 989, 0.64892578125], [52, 903, 93, 989, 0.6484375], [52, 902, 93, 990, 0.6484375], [52, 902, 93, 990, 0.64697265625], [52, 902, 93, 990, 0.6474609375], [52, 902, 93, 990, 0.64794921875], [52, 902, 93, 989, 0.6484375], [51, 902, 92, 989, 0.64501953125], [51, 903, 92, 990, 0.6494140625], [51, 902, 92, 990, 0.6474609375], [51, 903, 92, 990, 0.65380859375], [51, 903, 92, 990, 0.65185546875], [51, 903, 92, 990, 0.65087890625], [51, 903, 92, 990, 0.6513671875], [51, 903, 92, 990, 0.65234375], [51, 903, 92, 990, 0.6513671875], [51, 903, 92, 990, 0.65087890625], [51, 903, 92, 990, 0.650390625], [51, 903, 93, 990, 0.64990234375], [51, 903, 93, 990, 0.6494140625], [51, 903, 93, 990, 0.64794921875], [51, 903, 93, 990, 0.64794921875], [51, 903, 93, 990, 0.6474609375], [51, 903, 93, 990, 0.64697265625], [51, 902, 93, 989, 0.6484375], [51, 902, 93, 990, 0.64794921875], [51, 902, 92, 990, 0.64794921875], [51, 902, 93, 990, 0.64697265625], [51, 902, 92, 990, 0.64697265625], [51, 902, 92, 990, 0.6484375], [51, 902, 92, 989, 0.650390625], [51, 902, 92, 990, 0.64990234375], [51, 902, 92, 990, 0.64990234375], [51, 903, 92, 990, 0.65087890625], [51, 903, 92, 990, 0.650390625]]\n",
      "Key: As, vector len: 8, Card Detections: [[328, 900, 369, 986, 0.6865234375], [327, 900, 369, 986, 0.69140625], [327, 900, 369, 986, 0.68896484375], [327, 901, 368, 987, 0.685546875], [327, 901, 368, 987, 0.68896484375], [326, 902, 368, 987, 0.68310546875], [325, 903, 367, 988, 0.68359375], [323, 906, 366, 989, 0.67529296875]]\n",
      "Key: Jc, vector len: 7, Card Detections: [[324, 898, 364, 981, 0.669921875], [325, 898, 364, 984, 0.65771484375], [325, 898, 364, 984, 0.6630859375], [325, 898, 364, 984, 0.662109375], [324, 898, 363, 985, 0.6435546875], [324, 898, 363, 985, 0.65185546875], [321, 900, 363, 988, 0.630859375]]\n",
      "Key: Jd, vector len: 26, Card Detections: [[334, 898, 371, 988, 0.638671875], [334, 899, 371, 989, 0.63330078125], [334, 899, 371, 990, 0.62939453125], [334, 899, 371, 989, 0.62548828125], [333, 900, 371, 990, 0.61962890625], [333, 900, 371, 990, 0.6181640625], [333, 899, 371, 990, 0.61865234375], [333, 899, 371, 990, 0.62060546875], [333, 899, 371, 990, 0.61279296875], [333, 900, 371, 990, 0.60888671875], [333, 900, 371, 990, 0.60986328125], [333, 900, 371, 990, 0.61083984375], [333, 900, 371, 990, 0.60400390625], [333, 900, 371, 991, 0.60107421875], [333, 900, 371, 991, 0.60205078125], [333, 900, 371, 990, 0.60400390625], [333, 900, 371, 990, 0.599609375], [333, 900, 371, 990, 0.60546875], [333, 901, 370, 991, 0.59521484375], [333, 901, 370, 991, 0.5966796875], [333, 901, 371, 991, 0.60009765625], [333, 901, 370, 991, 0.595703125], [333, 901, 370, 991, 0.59423828125], [332, 902, 370, 991, 0.595703125], [332, 902, 370, 991, 0.59814453125], [332, 904, 368, 992, 0.609375]]\n",
      "Key: Jh, vector len: 39, Card Detections: [[29, 897, 69, 979, 0.6201171875], [28, 898, 69, 981, 0.6201171875], [29, 900, 68, 982, 0.623046875], [28, 899, 68, 982, 0.6201171875], [28, 900, 68, 983, 0.623046875], [28, 900, 69, 983, 0.62060546875], [28, 900, 68, 982, 0.62158203125], [28, 899, 69, 982, 0.626953125], [28, 899, 69, 982, 0.62939453125], [28, 897, 69, 980, 0.6220703125], [28, 897, 69, 980, 0.62255859375], [28, 897, 69, 980, 0.6201171875], [29, 896, 69, 980, 0.619140625], [29, 896, 70, 980, 0.61865234375], [29, 896, 70, 980, 0.619140625], [29, 896, 70, 979, 0.61767578125], [29, 897, 70, 980, 0.61669921875], [29, 897, 70, 980, 0.6162109375], [29, 897, 70, 980, 0.61474609375], [29, 897, 70, 979, 0.61474609375], [29, 897, 70, 980, 0.61572265625], [29, 897, 70, 980, 0.61279296875], [29, 897, 70, 980, 0.6123046875], [29, 897, 70, 980, 0.61328125], [29, 897, 71, 979, 0.611328125], [29, 896, 71, 978, 0.60107421875], [30, 895, 71, 977, 0.62548828125], [30, 895, 71, 977, 0.638671875], [30, 895, 71, 977, 0.6337890625], [30, 895, 72, 977, 0.63134765625], [30, 894, 72, 976, 0.62646484375], [30, 894, 72, 976, 0.63232421875], [31, 894, 72, 976, 0.634765625], [31, 893, 73, 976, 0.6318359375], [31, 893, 73, 976, 0.63232421875], [31, 893, 73, 976, 0.63037109375], [31, 893, 73, 975, 0.62939453125], [31, 893, 74, 975, 0.63134765625], [32, 893, 75, 975, 0.62841796875]]\n",
      "Key: Js, vector len: 10, Card Detections: [[328, 904, 366, 993, 0.6611328125], [328, 904, 366, 993, 0.666015625], [328, 904, 366, 992, 0.6533203125], [328, 904, 366, 993, 0.65771484375], [327, 904, 366, 994, 0.638671875], [327, 904, 366, 994, 0.65283203125], [327, 905, 366, 994, 0.64892578125], [327, 904, 366, 994, 0.6494140625], [327, 905, 366, 994, 0.65185546875], [326, 906, 365, 996, 0.666015625]]\n",
      "Key: Kc, vector len: 7, Card Detections: [[325, 895, 366, 981, 0.70166015625], [325, 897, 365, 983, 0.6943359375], [325, 896, 365, 983, 0.6923828125], [325, 896, 365, 983, 0.69287109375], [324, 896, 365, 984, 0.68310546875], [324, 897, 365, 984, 0.669921875], [323, 899, 365, 984, 0.66357421875]]\n",
      "Key: Kd, vector len: 10, Card Detections: [[326, 899, 365, 989, 0.64111328125], [326, 899, 365, 989, 0.6416015625], [325, 900, 365, 990, 0.64453125], [325, 901, 365, 990, 0.64453125], [324, 901, 364, 991, 0.64501953125], [324, 901, 364, 991, 0.646484375], [324, 901, 364, 991, 0.658203125], [323, 902, 364, 992, 0.66015625], [323, 902, 364, 992, 0.6640625], [321, 905, 363, 993, 0.6357421875]]\n",
      "Key: Kh, vector len: 8, Card Detections: [[42, 853, 85, 949, 0.609375], [42, 853, 84, 950, 0.611328125], [42, 853, 84, 949, 0.61279296875], [42, 853, 84, 949, 0.61181640625], [42, 853, 84, 949, 0.6103515625], [42, 853, 84, 950, 0.6171875], [42, 854, 84, 950, 0.61572265625], [42, 856, 84, 951, 0.61865234375]]\n",
      "Key: Ks, vector len: 8, Card Detections: [[326, 894, 367, 986, 0.68505859375], [326, 894, 367, 986, 0.6845703125], [325, 895, 367, 987, 0.67724609375], [326, 895, 367, 987, 0.681640625], [325, 895, 367, 987, 0.68505859375], [325, 896, 366, 986, 0.67578125], [325, 896, 366, 987, 0.68359375], [323, 898, 365, 988, 0.67724609375]]\n",
      "Key: Qc, vector len: 6, Card Detections: [[50, 883, 91, 975, 0.62353515625], [49, 883, 91, 975, 0.625], [49, 882, 91, 976, 0.626953125], [50, 882, 92, 975, 0.6171875], [50, 882, 92, 975, 0.62548828125], [51, 883, 93, 975, 0.6416015625]]\n",
      "Key: Qd, vector len: 4, Card Detections: [[45, 858, 87, 955, 0.6240234375], [45, 858, 87, 953, 0.626953125], [45, 858, 87, 953, 0.6220703125], [49, 864, 91, 961, 0.57373046875]]\n",
      "Key: Qh, vector len: 8, Card Detections: [[46, 857, 87, 951, 0.62890625], [46, 857, 87, 952, 0.62939453125], [46, 857, 87, 952, 0.6298828125], [46, 859, 87, 952, 0.62548828125], [46, 860, 87, 954, 0.6318359375], [46, 860, 88, 954, 0.6328125], [47, 861, 88, 955, 0.63671875], [47, 862, 89, 956, 0.640625]]\n",
      "Key: Qs, vector len: 5, Card Detections: [[327, 897, 370, 998, 0.63427734375], [327, 896, 368, 987, 0.67578125], [326, 899, 367, 987, 0.662109375], [326, 899, 367, 989, 0.6630859375], [325, 900, 366, 988, 0.65576171875]]\n",
      "Key: SJoker, vector len: 36, Card Detections: [[325, 910, 369, 999, 0.57763671875], [325, 910, 369, 999, 0.6162109375], [324, 910, 369, 1002, 0.6064453125], [324, 910, 369, 1000, 0.61962890625], [324, 910, 369, 1001, 0.6005859375], [324, 910, 368, 1000, 0.60546875], [324, 910, 368, 1000, 0.6064453125], [324, 910, 368, 1001, 0.607421875], [325, 910, 368, 1001, 0.61376953125], [325, 910, 369, 1001, 0.6162109375], [325, 910, 368, 1001, 0.6142578125], [325, 909, 368, 1001, 0.6171875], [325, 909, 368, 1001, 0.6162109375], [324, 910, 368, 1001, 0.6162109375], [324, 910, 368, 1002, 0.6142578125], [324, 910, 368, 1002, 0.6220703125], [323, 910, 368, 1002, 0.62060546875], [323, 910, 367, 1002, 0.623046875], [323, 910, 367, 1002, 0.62353515625], [323, 910, 367, 1003, 0.6279296875], [323, 911, 367, 1003, 0.626953125], [323, 910, 368, 1003, 0.62841796875], [323, 911, 367, 1004, 0.6298828125], [323, 911, 367, 1004, 0.62890625], [323, 910, 367, 1003, 0.6328125], [323, 911, 367, 1004, 0.63037109375], [323, 910, 367, 1003, 0.6328125], [323, 911, 367, 1004, 0.6337890625], [323, 911, 367, 1004, 0.63330078125], [323, 911, 367, 1004, 0.6318359375], [323, 912, 367, 1004, 0.63037109375], [323, 912, 367, 1004, 0.62939453125], [322, 913, 366, 1004, 0.630859375], [322, 913, 366, 1005, 0.6318359375], [321, 915, 365, 1005, 0.62841796875], [319, 921, 364, 1005, 0.59912109375]]\n",
      "Key: BJoker, vector len: 7, Card Detections: [[31, 861, 79, 991, 0.607421875], [27, 861, 77, 1003, 0.64404296875], [26, 862, 77, 1004, 0.6552734375], [26, 860, 78, 1004, 0.67236328125], [26, 861, 77, 1003, 0.66650390625], [26, 861, 77, 1003, 0.6650390625], [27, 862, 81, 1003, 0.59814453125]]\n",
      "Key: Tc, vector len: 7, Card Detections: [[80, 848, 136, 965, 0.6640625], [81, 848, 136, 964, 0.66650390625], [80, 847, 136, 965, 0.66943359375], [80, 847, 136, 964, 0.66552734375], [81, 848, 134, 964, 0.66162109375], [81, 850, 134, 964, 0.65087890625], [81, 856, 136, 971, 0.64208984375]]\n",
      "Key: Td, vector len: 128, Card Detections: [[441, 969, 498, 1041, 0.6044921875], [445, 949, 501, 1027, 0.65673828125], [447, 933, 502, 1017, 0.65234375], [449, 916, 503, 1007, 0.6357421875], [450, 903, 503, 997, 0.66552734375], [449, 893, 499, 990, 0.67822265625], [448, 890, 498, 987, 0.66845703125], [449, 885, 499, 984, 0.66259765625], [449, 884, 498, 983, 0.66455078125], [449, 884, 498, 983, 0.662109375], [448, 883, 498, 983, 0.6630859375], [448, 883, 497, 983, 0.66357421875], [448, 883, 497, 983, 0.6640625], [448, 883, 497, 983, 0.66552734375], [448, 883, 497, 983, 0.66650390625], [448, 884, 498, 983, 0.66650390625], [448, 883, 498, 983, 0.666015625], [448, 883, 497, 982, 0.6650390625], [448, 883, 497, 983, 0.6650390625], [448, 883, 498, 983, 0.66650390625], [448, 883, 497, 983, 0.66455078125], [448, 884, 497, 983, 0.6640625], [448, 883, 497, 983, 0.66552734375], [448, 883, 497, 983, 0.6669921875], [448, 883, 497, 982, 0.66552734375], [448, 883, 497, 982, 0.6689453125], [448, 882, 496, 982, 0.67138671875], [448, 882, 496, 981, 0.67041015625], [448, 882, 496, 981, 0.671875], [448, 882, 496, 981, 0.6728515625], [448, 882, 496, 981, 0.6748046875], [448, 881, 496, 981, 0.67529296875], [447, 881, 496, 981, 0.67431640625], [448, 881, 496, 981, 0.673828125], [447, 881, 496, 981, 0.6728515625], [447, 880, 496, 981, 0.673828125], [448, 881, 496, 981, 0.67529296875], [448, 881, 496, 981, 0.67529296875], [448, 881, 496, 981, 0.67431640625], [447, 880, 496, 981, 0.6767578125], [448, 881, 496, 981, 0.67919921875], [447, 880, 496, 980, 0.6806640625], [447, 880, 496, 980, 0.681640625], [448, 880, 496, 981, 0.68017578125], [447, 880, 496, 981, 0.6806640625], [447, 880, 496, 980, 0.68115234375], [447, 880, 496, 981, 0.6796875], [448, 880, 496, 980, 0.67919921875], [448, 880, 496, 981, 0.6796875], [448, 880, 496, 981, 0.68017578125], [448, 880, 496, 981, 0.6787109375], [448, 880, 496, 981, 0.6796875], [448, 880, 496, 981, 0.6796875], [448, 880, 496, 981, 0.67919921875], [448, 880, 496, 981, 0.67919921875], [448, 880, 496, 981, 0.6796875], [448, 880, 496, 981, 0.68017578125], [448, 880, 496, 981, 0.6796875], [447, 880, 496, 981, 0.6796875], [447, 880, 496, 981, 0.67822265625], [447, 880, 496, 981, 0.6787109375], [447, 880, 496, 981, 0.67919921875], [447, 880, 496, 981, 0.67919921875], [447, 880, 496, 981, 0.6787109375], [447, 880, 496, 981, 0.677734375], [447, 880, 496, 981, 0.67822265625], [447, 880, 496, 981, 0.67919921875], [447, 880, 496, 981, 0.68017578125], [447, 880, 496, 981, 0.6806640625], [447, 880, 496, 981, 0.68115234375], [448, 881, 496, 982, 0.68212890625], [447, 881, 496, 982, 0.68212890625], [448, 881, 496, 982, 0.681640625], [448, 881, 496, 982, 0.68212890625], [447, 881, 496, 982, 0.681640625], [447, 881, 496, 982, 0.68212890625], [447, 881, 496, 982, 0.68212890625], [447, 881, 496, 982, 0.681640625], [447, 881, 496, 982, 0.68115234375], [447, 881, 496, 982, 0.68115234375], [447, 881, 496, 982, 0.68115234375], [447, 881, 496, 982, 0.68115234375], [447, 881, 496, 982, 0.68115234375], [447, 881, 496, 982, 0.68017578125], [447, 881, 496, 982, 0.68017578125], [447, 881, 496, 982, 0.67919921875], [447, 881, 496, 982, 0.67822265625], [447, 882, 496, 982, 0.67919921875], [447, 882, 496, 982, 0.67822265625], [447, 882, 496, 983, 0.677734375], [447, 882, 496, 983, 0.677734375], [447, 882, 495, 983, 0.6787109375], [447, 882, 495, 983, 0.67724609375], [447, 883, 495, 983, 0.67626953125], [447, 882, 495, 983, 0.6767578125], [447, 882, 495, 983, 0.67626953125], [447, 882, 495, 983, 0.67626953125], [447, 882, 495, 983, 0.6767578125], [447, 882, 495, 983, 0.6767578125], [447, 883, 495, 983, 0.67626953125], [447, 883, 495, 984, 0.6728515625], [447, 883, 495, 984, 0.6728515625], [447, 883, 495, 984, 0.67333984375], [446, 883, 495, 984, 0.67333984375], [446, 883, 495, 984, 0.67138671875], [446, 883, 495, 984, 0.67138671875], [446, 883, 495, 984, 0.6708984375], [446, 883, 495, 984, 0.67138671875], [446, 884, 495, 984, 0.66943359375], [446, 884, 495, 985, 0.66748046875], [446, 884, 494, 985, 0.66943359375], [446, 884, 494, 985, 0.66748046875], [446, 884, 494, 984, 0.6669921875], [445, 884, 494, 985, 0.6669921875], [445, 884, 494, 984, 0.66455078125], [445, 884, 494, 985, 0.66796875], [445, 885, 493, 984, 0.6669921875], [445, 884, 493, 985, 0.66552734375], [445, 885, 493, 985, 0.671875], [445, 885, 492, 985, 0.671875], [444, 885, 492, 985, 0.6689453125], [443, 886, 492, 985, 0.67138671875], [443, 886, 491, 985, 0.6767578125], [442, 886, 491, 985, 0.67919921875], [441, 887, 490, 986, 0.6826171875], [441, 888, 490, 986, 0.68359375], [440, 889, 489, 987, 0.68603515625], [439, 891, 488, 988, 0.68505859375]]\n",
      "Key: Th, vector len: 28, Card Detections: [[420, 881, 470, 993, 0.6240234375], [420, 881, 469, 992, 0.61865234375], [420, 881, 469, 993, 0.6142578125], [419, 881, 468, 993, 0.611328125], [418, 881, 467, 993, 0.61181640625], [418, 881, 467, 993, 0.60791015625], [418, 881, 467, 993, 0.60791015625], [418, 881, 467, 993, 0.607421875], [418, 881, 467, 993, 0.6083984375], [418, 881, 467, 992, 0.60693359375], [416, 882, 466, 993, 0.607421875], [417, 881, 466, 993, 0.6083984375], [417, 881, 466, 992, 0.60595703125], [417, 881, 466, 992, 0.6044921875], [417, 881, 466, 992, 0.603515625], [416, 881, 465, 993, 0.607421875], [416, 882, 465, 993, 0.60791015625], [416, 882, 465, 993, 0.6171875], [416, 882, 465, 993, 0.61669921875], [416, 882, 465, 993, 0.61669921875], [416, 882, 465, 994, 0.60546875], [415, 883, 464, 994, 0.6025390625], [415, 883, 465, 993, 0.5927734375], [415, 883, 464, 993, 0.59130859375], [414, 883, 464, 994, 0.591796875], [414, 884, 464, 994, 0.59423828125], [414, 884, 463, 994, 0.59765625], [414, 885, 463, 994, 0.6015625]]\n",
      "Key: Ts, vector len: 13, Card Detections: [[442, 875, 493, 988, 0.642578125], [443, 876, 493, 988, 0.65576171875], [443, 876, 492, 988, 0.650390625], [443, 876, 492, 989, 0.6591796875], [443, 876, 492, 989, 0.662109375], [442, 876, 492, 988, 0.65966796875], [442, 877, 492, 989, 0.66357421875], [442, 877, 492, 990, 0.6328125], [442, 877, 492, 989, 0.64306640625], [442, 877, 492, 989, 0.60400390625], [442, 877, 492, 989, 0.6044921875], [442, 877, 492, 989, 0.60546875], [440, 878, 492, 990, 0.630859375]]\n",
      "Key: 2c, vector len: 15, Card Detections: [[440, 875, 493, 986, 0.662109375], [440, 875, 493, 986, 0.6650390625], [440, 875, 493, 986, 0.666015625], [440, 875, 493, 986, 0.666015625], [440, 876, 492, 987, 0.6669921875], [440, 876, 492, 986, 0.66796875], [440, 876, 492, 986, 0.6640625], [440, 876, 492, 986, 0.66748046875], [440, 876, 492, 987, 0.66552734375], [439, 877, 492, 987, 0.669921875], [439, 877, 491, 988, 0.658203125], [438, 877, 491, 987, 0.65869140625], [438, 878, 491, 989, 0.65234375], [438, 878, 491, 989, 0.6474609375], [437, 879, 490, 989, 0.65185546875]]\n",
      "Key: 2d, vector len: 8, Card Detections: [[433, 883, 488, 996, 0.53466796875], [80, 859, 140, 1000, 0.6279296875], [84, 859, 138, 971, 0.63037109375], [84, 859, 138, 972, 0.63232421875], [84, 859, 138, 971, 0.63623046875], [84, 859, 138, 972, 0.63623046875], [84, 859, 138, 971, 0.63232421875], [85, 862, 140, 975, 0.630859375]]\n",
      "Key: 2h, vector len: 22, Card Detections: [[424, 879, 476, 988, 0.6279296875], [424, 878, 475, 989, 0.623046875], [424, 879, 475, 990, 0.62060546875], [424, 879, 475, 990, 0.62158203125], [424, 879, 475, 991, 0.62109375], [423, 879, 474, 991, 0.61962890625], [423, 879, 474, 991, 0.62109375], [423, 880, 473, 992, 0.6220703125], [423, 880, 473, 992, 0.6240234375], [423, 880, 473, 992, 0.62109375], [422, 879, 473, 992, 0.62109375], [422, 879, 473, 992, 0.62158203125], [422, 879, 472, 992, 0.62255859375], [421, 880, 472, 992, 0.62060546875], [421, 880, 472, 993, 0.62060546875], [421, 880, 472, 993, 0.62060546875], [421, 880, 471, 993, 0.6181640625], [420, 880, 471, 993, 0.6181640625], [420, 881, 471, 993, 0.6171875], [420, 881, 470, 994, 0.6181640625], [419, 881, 470, 994, 0.6171875], [418, 883, 469, 993, 0.6171875]]\n",
      "Key: 2s, vector len: 7, Card Detections: [[438, 884, 491, 990, 0.65625], [438, 884, 491, 991, 0.6484375], [438, 885, 490, 991, 0.64892578125], [438, 884, 490, 992, 0.66064453125], [437, 884, 490, 991, 0.65966796875], [437, 884, 490, 991, 0.65966796875], [437, 885, 490, 991, 0.6533203125]]\n",
      "Key: 3c, vector len: 12, Card Detections: [[73, 832, 128, 953, 0.6240234375], [73, 831, 129, 952, 0.626953125], [73, 831, 129, 953, 0.62744140625], [73, 831, 128, 952, 0.62939453125], [73, 831, 128, 953, 0.62841796875], [73, 832, 128, 953, 0.6279296875], [73, 832, 128, 953, 0.626953125], [73, 832, 128, 953, 0.6240234375], [73, 832, 128, 953, 0.62548828125], [73, 831, 128, 953, 0.62744140625], [73, 831, 128, 953, 0.6298828125], [72, 829, 134, 967, 0.50341796875]]\n",
      "Key: 3d, vector len: 8, Card Detections: [[441, 879, 492, 986, 0.669921875], [441, 879, 492, 987, 0.66845703125], [440, 879, 492, 986, 0.67041015625], [441, 879, 492, 987, 0.6611328125], [441, 879, 492, 987, 0.6669921875], [441, 880, 492, 988, 0.66357421875], [441, 880, 492, 987, 0.66552734375], [440, 880, 491, 987, 0.66845703125]]\n",
      "Key: 3h, vector len: 26, Card Detections: [[38, 824, 93, 944, 0.615234375], [38, 823, 93, 942, 0.61279296875], [38, 825, 92, 945, 0.61328125], [38, 824, 93, 945, 0.611328125], [38, 826, 93, 946, 0.61376953125], [38, 827, 92, 946, 0.60791015625], [38, 828, 92, 946, 0.6044921875], [38, 828, 92, 948, 0.6005859375], [38, 829, 92, 948, 0.60595703125], [38, 829, 92, 948, 0.60400390625], [38, 829, 92, 948, 0.603515625], [38, 829, 92, 948, 0.60205078125], [38, 830, 92, 948, 0.60205078125], [38, 830, 92, 949, 0.5986328125], [38, 830, 92, 949, 0.59619140625], [38, 831, 92, 949, 0.59814453125], [38, 831, 92, 949, 0.59765625], [38, 831, 92, 949, 0.59619140625], [38, 832, 91, 950, 0.59375], [38, 832, 91, 950, 0.5908203125], [38, 832, 91, 950, 0.58935546875], [38, 833, 91, 950, 0.58544921875], [38, 833, 92, 950, 0.58935546875], [38, 833, 92, 952, 0.58984375], [38, 834, 92, 952, 0.5927734375], [38, 834, 94, 967, 0.63623046875]]\n",
      "Key: 3s, vector len: 44, Card Detections: [[410, 890, 464, 1004, 0.60693359375], [410, 892, 464, 1003, 0.64208984375], [409, 892, 464, 1003, 0.64892578125], [409, 893, 463, 1005, 0.64599609375], [409, 892, 463, 1005, 0.64404296875], [409, 892, 463, 1005, 0.64697265625], [409, 891, 463, 1005, 0.64404296875], [409, 891, 463, 1005, 0.6455078125], [409, 892, 463, 1005, 0.638671875], [409, 893, 463, 1005, 0.63623046875], [409, 892, 463, 1005, 0.6337890625], [409, 892, 463, 1005, 0.63232421875], [409, 892, 462, 1005, 0.63330078125], [408, 892, 463, 1005, 0.63330078125], [408, 893, 463, 1005, 0.63330078125], [408, 893, 462, 1005, 0.63232421875], [408, 893, 462, 1005, 0.63134765625], [408, 893, 462, 1005, 0.63427734375], [408, 893, 462, 1006, 0.63037109375], [408, 893, 462, 1006, 0.62939453125], [408, 893, 462, 1006, 0.630859375], [408, 893, 462, 1006, 0.63232421875], [408, 893, 463, 1006, 0.63720703125], [408, 893, 462, 1006, 0.6376953125], [408, 893, 462, 1006, 0.640625], [408, 893, 462, 1006, 0.6416015625], [408, 893, 462, 1006, 0.64208984375], [408, 893, 462, 1006, 0.642578125], [408, 893, 462, 1006, 0.63525390625], [408, 894, 462, 1006, 0.63525390625], [408, 894, 462, 1006, 0.63330078125], [408, 894, 462, 1006, 0.64013671875], [408, 894, 462, 1006, 0.63525390625], [408, 894, 461, 1007, 0.625], [408, 895, 461, 1007, 0.6328125], [408, 895, 461, 1007, 0.63037109375], [408, 895, 461, 1007, 0.63037109375], [408, 896, 461, 1007, 0.62890625], [408, 896, 461, 1007, 0.62841796875], [408, 896, 461, 1007, 0.6279296875], [408, 897, 461, 1007, 0.6279296875], [407, 897, 460, 1007, 0.62939453125], [407, 898, 460, 1007, 0.63232421875], [403, 901, 459, 1009, 0.5810546875]]\n",
      "Key: 4c, vector len: 13, Card Detections: [[67, 821, 193, 945, 0.634765625], [66, 821, 192, 945, 0.63818359375], [66, 821, 191, 944, 0.63623046875], [65, 821, 192, 946, 0.6396484375], [65, 821, 191, 946, 0.64111328125], [65, 821, 192, 946, 0.640625], [65, 821, 192, 946, 0.6416015625], [64, 821, 192, 946, 0.638671875], [64, 821, 192, 946, 0.640625], [64, 822, 191, 946, 0.64208984375], [64, 822, 191, 947, 0.6435546875], [64, 822, 191, 947, 0.64599609375], [64, 823, 191, 948, 0.64599609375]]\n",
      "Key: 4d, vector len: 9, Card Detections: [[440, 879, 543, 996, 0.60400390625], [440, 880, 543, 997, 0.59716796875], [440, 879, 543, 997, 0.5830078125], [440, 879, 543, 997, 0.5966796875], [440, 879, 542, 997, 0.58984375], [439, 879, 543, 997, 0.595703125], [439, 880, 543, 997, 0.611328125], [439, 882, 543, 997, 0.60888671875], [437, 884, 541, 998, 0.61865234375]]\n",
      "Key: 4h, vector len: 12, Card Detections: [[72, 827, 191, 944, 0.62841796875], [73, 826, 191, 945, 0.63720703125], [73, 826, 191, 945, 0.6376953125], [73, 826, 191, 944, 0.63671875], [73, 826, 191, 944, 0.63720703125], [73, 827, 191, 945, 0.6357421875], [73, 827, 191, 946, 0.6357421875], [73, 828, 191, 945, 0.63818359375], [73, 828, 191, 945, 0.6376953125], [73, 827, 191, 946, 0.63623046875], [73, 827, 191, 946, 0.6357421875], [73, 833, 193, 949, 0.63720703125]]\n",
      "Key: 4s, vector len: 14, Card Detections: [[55, 823, 167, 949, 0.60205078125], [54, 823, 167, 950, 0.60888671875], [54, 823, 168, 949, 0.611328125], [54, 823, 168, 948, 0.60791015625], [54, 823, 168, 949, 0.60791015625], [54, 824, 168, 949, 0.6044921875], [54, 824, 168, 950, 0.60400390625], [54, 825, 167, 950, 0.60400390625], [54, 825, 167, 950, 0.6015625], [54, 824, 166, 950, 0.6044921875], [54, 825, 167, 950, 0.59814453125], [54, 825, 167, 950, 0.6005859375], [54, 825, 166, 950, 0.5986328125], [54, 825, 167, 950, 0.59912109375]]\n",
      "Key: 5c, vector len: 13, Card Detections: [[439, 871, 490, 985, 0.64599609375], [440, 873, 491, 987, 0.67431640625], [440, 873, 490, 986, 0.67529296875], [439, 873, 490, 987, 0.6796875], [439, 874, 491, 987, 0.6708984375], [439, 874, 491, 989, 0.68505859375], [439, 874, 491, 989, 0.6875], [439, 874, 491, 989, 0.685546875], [439, 874, 491, 988, 0.6845703125], [439, 874, 491, 988, 0.681640625], [439, 874, 491, 989, 0.685546875], [439, 874, 491, 989, 0.67724609375], [438, 874, 490, 989, 0.66552734375]]\n",
      "Key: 5d, vector len: 127, Card Detections: [[69, 943, 114, 1029, 0.62451171875], [64, 929, 111, 1023, 0.61181640625], [66, 915, 114, 1014, 0.59326171875], [69, 900, 117, 1002, 0.6337890625], [69, 897, 118, 1000, 0.623046875], [73, 893, 122, 997, 0.62548828125], [78, 891, 127, 995, 0.61572265625], [80, 892, 128, 994, 0.61181640625], [80, 892, 128, 995, 0.62255859375], [80, 892, 129, 995, 0.62060546875], [81, 892, 129, 995, 0.61962890625], [81, 892, 129, 995, 0.61376953125], [81, 892, 129, 996, 0.6162109375], [81, 892, 130, 996, 0.61328125], [81, 892, 130, 996, 0.60986328125], [81, 893, 130, 996, 0.61181640625], [81, 893, 130, 996, 0.61328125], [82, 893, 130, 996, 0.6162109375], [81, 893, 130, 996, 0.61474609375], [82, 893, 130, 996, 0.611328125], [81, 893, 130, 996, 0.61181640625], [81, 891, 131, 996, 0.6123046875], [81, 891, 131, 996, 0.61572265625], [82, 891, 131, 996, 0.6240234375], [82, 891, 132, 995, 0.62255859375], [83, 891, 133, 995, 0.6240234375], [84, 891, 134, 995, 0.62744140625], [84, 891, 134, 995, 0.6279296875], [85, 891, 135, 995, 0.63330078125], [86, 891, 136, 995, 0.63818359375], [86, 891, 136, 995, 0.64453125], [87, 891, 137, 995, 0.64453125], [87, 891, 137, 996, 0.64453125], [87, 891, 137, 995, 0.64599609375], [87, 891, 137, 995, 0.64794921875], [87, 891, 137, 995, 0.646484375], [87, 891, 137, 995, 0.6435546875], [87, 891, 137, 995, 0.642578125], [87, 892, 137, 995, 0.638671875], [87, 891, 137, 995, 0.6376953125], [87, 891, 137, 995, 0.64111328125], [87, 891, 137, 995, 0.63916015625], [87, 891, 137, 995, 0.638671875], [87, 891, 137, 995, 0.64208984375], [87, 891, 137, 995, 0.64453125], [87, 891, 137, 994, 0.6435546875], [87, 891, 137, 994, 0.64599609375], [87, 890, 138, 994, 0.65087890625], [88, 890, 138, 994, 0.65283203125], [88, 890, 138, 994, 0.650390625], [89, 890, 139, 994, 0.65087890625], [89, 890, 139, 994, 0.6494140625], [89, 890, 139, 994, 0.6484375], [89, 890, 139, 994, 0.64599609375], [89, 890, 140, 994, 0.6484375], [89, 890, 140, 994, 0.64697265625], [89, 890, 139, 994, 0.64599609375], [89, 890, 139, 995, 0.64697265625], [89, 890, 139, 995, 0.6484375], [89, 890, 139, 995, 0.64892578125], [88, 890, 139, 995, 0.6513671875], [88, 890, 138, 995, 0.6513671875], [88, 890, 138, 995, 0.6494140625], [88, 890, 138, 995, 0.6513671875], [88, 890, 138, 995, 0.6533203125], [88, 890, 139, 995, 0.6513671875], [88, 890, 139, 995, 0.65283203125], [88, 890, 139, 995, 0.65283203125], [89, 890, 139, 995, 0.64892578125], [89, 890, 139, 995, 0.6474609375], [90, 890, 140, 995, 0.64697265625], [90, 890, 140, 995, 0.64599609375], [90, 890, 140, 995, 0.64453125], [90, 890, 140, 994, 0.6435546875], [90, 890, 140, 994, 0.64501953125], [90, 890, 140, 994, 0.64501953125], [90, 890, 140, 994, 0.64453125], [90, 890, 140, 994, 0.64404296875], [91, 890, 140, 994, 0.6455078125], [91, 890, 140, 994, 0.64697265625], [91, 890, 140, 994, 0.6455078125], [91, 890, 140, 994, 0.6474609375], [91, 890, 140, 994, 0.64453125], [91, 890, 141, 994, 0.64453125], [91, 890, 140, 994, 0.6416015625], [91, 890, 141, 994, 0.64453125], [91, 890, 140, 994, 0.6435546875], [91, 890, 140, 994, 0.64208984375], [91, 889, 140, 993, 0.638671875], [91, 889, 141, 993, 0.6328125], [92, 889, 141, 994, 0.6181640625], [92, 888, 142, 994, 0.6142578125], [92, 888, 142, 994, 0.61572265625], [92, 888, 142, 995, 0.61474609375], [92, 888, 142, 995, 0.61474609375], [92, 888, 142, 995, 0.6162109375], [92, 888, 142, 995, 0.61669921875], [91, 888, 142, 995, 0.6171875], [92, 888, 142, 994, 0.62451171875], [92, 888, 142, 994, 0.62646484375], [92, 888, 142, 994, 0.62744140625], [92, 888, 142, 994, 0.6318359375], [92, 888, 142, 994, 0.62841796875], [92, 887, 142, 994, 0.6279296875], [92, 887, 142, 994, 0.62744140625], [92, 887, 142, 994, 0.62890625], [92, 887, 142, 993, 0.6279296875], [92, 887, 142, 993, 0.6220703125], [92, 887, 142, 993, 0.6201171875], [92, 887, 142, 993, 0.62353515625], [92, 886, 142, 993, 0.63037109375], [91, 886, 142, 993, 0.630859375], [91, 886, 142, 993, 0.63134765625], [91, 886, 142, 993, 0.63427734375], [92, 886, 141, 993, 0.63427734375], [91, 886, 142, 993, 0.6328125], [91, 886, 142, 993, 0.6318359375], [92, 886, 142, 993, 0.62890625], [92, 886, 142, 993, 0.626953125], [92, 886, 142, 993, 0.62744140625], [92, 885, 142, 993, 0.6337890625], [91, 885, 142, 993, 0.634765625], [91, 885, 141, 993, 0.63818359375], [91, 885, 141, 992, 0.63671875], [91, 884, 141, 992, 0.63818359375], [91, 884, 141, 992, 0.63525390625], [91, 884, 141, 992, 0.6298828125]]\n",
      "Key: 5h, vector len: 18, Card Detections: [[409, 884, 459, 996, 0.671875], [409, 886, 459, 996, 0.677734375], [409, 886, 459, 997, 0.67822265625], [408, 886, 458, 999, 0.68017578125], [408, 886, 458, 998, 0.6787109375], [408, 886, 458, 998, 0.67626953125], [408, 886, 458, 998, 0.673828125], [407, 887, 458, 999, 0.67529296875], [407, 888, 458, 1000, 0.6806640625], [407, 888, 458, 1000, 0.6806640625], [407, 888, 457, 1000, 0.68212890625], [407, 888, 457, 999, 0.6826171875], [407, 888, 457, 1000, 0.68212890625], [407, 889, 457, 1000, 0.68115234375], [406, 889, 457, 1000, 0.677734375], [406, 890, 457, 1000, 0.67138671875], [406, 891, 457, 1001, 0.67138671875], [406, 891, 456, 1001, 0.669921875]]\n",
      "Key: 5s, vector len: 5, Card Detections: [[435, 885, 489, 992, 0.658203125], [435, 884, 489, 994, 0.67138671875], [436, 885, 489, 994, 0.67041015625], [435, 885, 489, 995, 0.67626953125], [433, 887, 488, 995, 0.65283203125]]\n",
      "Key: 6c, vector len: 6, Card Detections: [[81, 852, 136, 971, 0.67431640625], [82, 851, 136, 968, 0.7216796875], [82, 851, 136, 969, 0.7216796875], [83, 851, 136, 970, 0.7197265625], [83, 850, 136, 969, 0.71826171875], [84, 855, 138, 973, 0.6728515625]]\n",
      "Key: 6d, vector len: 16, Card Detections: [[51, 821, 101, 936, 0.662109375], [51, 822, 101, 936, 0.6591796875], [51, 822, 100, 936, 0.65380859375], [51, 822, 101, 936, 0.65625], [51, 822, 100, 937, 0.65625], [51, 822, 100, 938, 0.646484375], [50, 822, 100, 938, 0.646484375], [50, 823, 100, 939, 0.64404296875], [50, 823, 100, 938, 0.64453125], [50, 823, 100, 939, 0.6435546875], [50, 823, 100, 939, 0.64453125], [50, 824, 100, 940, 0.64453125], [50, 824, 100, 940, 0.64404296875], [50, 824, 100, 940, 0.64501953125], [50, 824, 100, 940, 0.64404296875], [51, 829, 102, 947, 0.64794921875]]\n",
      "Key: 6h, vector len: 31, Card Detections: [[37, 831, 88, 948, 0.6484375], [36, 833, 87, 950, 0.63623046875], [35, 834, 87, 951, 0.6318359375], [35, 834, 87, 951, 0.63427734375], [36, 835, 87, 952, 0.626953125], [36, 836, 87, 953, 0.6298828125], [36, 838, 87, 954, 0.6455078125], [36, 839, 87, 954, 0.64501953125], [36, 839, 87, 954, 0.64599609375], [36, 839, 87, 954, 0.65087890625], [36, 840, 87, 954, 0.65185546875], [36, 840, 86, 954, 0.6552734375], [36, 841, 87, 954, 0.65576171875], [36, 841, 87, 954, 0.65771484375], [36, 841, 87, 955, 0.65771484375], [36, 841, 86, 954, 0.66064453125], [36, 841, 87, 955, 0.66015625], [36, 842, 87, 955, 0.65869140625], [36, 842, 87, 955, 0.65966796875], [36, 842, 87, 955, 0.658203125], [36, 842, 87, 955, 0.6591796875], [36, 842, 87, 955, 0.65966796875], [36, 842, 87, 955, 0.65869140625], [36, 841, 87, 955, 0.65771484375], [36, 841, 86, 954, 0.6494140625], [36, 841, 86, 954, 0.6533203125], [36, 841, 86, 954, 0.654296875], [36, 841, 86, 954, 0.65087890625], [36, 841, 86, 954, 0.65087890625], [36, 841, 86, 954, 0.6513671875], [37, 846, 88, 956, 0.6689453125]]\n",
      "Key: 6s, vector len: 5, Card Detections: [[438, 888, 492, 1001, 0.59912109375], [440, 888, 492, 997, 0.6513671875], [440, 888, 491, 997, 0.64501953125], [440, 889, 491, 997, 0.64111328125], [439, 889, 490, 996, 0.62255859375]]\n",
      "Key: 7c, vector len: 9, Card Detections: [[69, 824, 120, 943, 0.654296875], [69, 824, 120, 943, 0.65087890625], [70, 825, 120, 943, 0.662109375], [70, 825, 120, 943, 0.65966796875], [70, 825, 120, 943, 0.66162109375], [70, 825, 120, 943, 0.66162109375], [70, 824, 121, 943, 0.662109375], [70, 824, 121, 943, 0.66015625], [70, 824, 121, 943, 0.66552734375]]\n",
      "Key: 7d, vector len: 11, Card Detections: [[61, 819, 111, 937, 0.62841796875], [61, 820, 110, 935, 0.6220703125], [61, 820, 110, 936, 0.6240234375], [61, 819, 110, 935, 0.62158203125], [61, 820, 110, 936, 0.62841796875], [60, 820, 110, 937, 0.62939453125], [60, 821, 110, 937, 0.63134765625], [60, 821, 109, 938, 0.6328125], [60, 821, 109, 938, 0.6318359375], [60, 821, 109, 938, 0.63134765625], [60, 822, 109, 938, 0.6279296875]]\n",
      "Key: 7h, vector len: 19, Card Detections: [[436, 875, 489, 983, 0.6826171875], [437, 875, 487, 988, 0.689453125], [437, 876, 487, 988, 0.68408203125], [437, 876, 487, 988, 0.685546875], [436, 876, 487, 988, 0.69189453125], [436, 876, 487, 989, 0.68896484375], [437, 876, 486, 989, 0.6865234375], [436, 876, 486, 989, 0.6865234375], [436, 876, 486, 989, 0.68701171875], [436, 877, 486, 989, 0.685546875], [436, 876, 485, 990, 0.68505859375], [436, 876, 485, 990, 0.6845703125], [435, 877, 485, 990, 0.6767578125], [435, 877, 485, 991, 0.6708984375], [434, 876, 484, 990, 0.6640625], [434, 877, 484, 990, 0.65478515625], [434, 878, 484, 990, 0.68798828125], [433, 878, 484, 990, 0.685546875], [429, 881, 481, 996, 0.61767578125]]\n",
      "Key: 7s, vector len: 9, Card Detections: [[440, 875, 490, 988, 0.68310546875], [440, 876, 490, 989, 0.68408203125], [440, 876, 490, 989, 0.6865234375], [440, 876, 490, 989, 0.68798828125], [440, 876, 490, 989, 0.6875], [440, 877, 490, 990, 0.68798828125], [440, 877, 490, 989, 0.6875], [438, 877, 489, 989, 0.68408203125], [438, 878, 489, 991, 0.68310546875]]\n",
      "Key: 8c, vector len: 21, Card Detections: [[47, 823, 99, 940, 0.62353515625], [47, 823, 99, 937, 0.6162109375], [47, 823, 99, 940, 0.61376953125], [47, 823, 99, 939, 0.619140625], [47, 823, 99, 940, 0.62646484375], [47, 824, 98, 941, 0.640625], [46, 824, 99, 941, 0.64404296875], [46, 824, 98, 941, 0.64111328125], [46, 824, 98, 941, 0.64111328125], [46, 824, 98, 941, 0.64501953125], [46, 824, 98, 941, 0.6435546875], [46, 825, 97, 941, 0.64013671875], [46, 825, 97, 941, 0.6435546875], [46, 824, 97, 941, 0.64306640625], [45, 825, 97, 941, 0.6396484375], [45, 825, 96, 942, 0.6337890625], [45, 825, 96, 943, 0.63427734375], [45, 825, 96, 943, 0.63330078125], [45, 826, 96, 943, 0.63623046875], [45, 826, 96, 944, 0.6376953125], [45, 835, 98, 950, 0.63623046875]]\n",
      "Key: 8d, vector len: 5, Card Detections: [[441, 880, 490, 986, 0.7109375], [441, 880, 489, 985, 0.7177734375], [441, 880, 489, 987, 0.71484375], [441, 880, 489, 986, 0.716796875], [440, 880, 489, 987, 0.70947265625]]\n",
      "Key: 8h, vector len: 27, Card Detections: [[415, 882, 464, 993, 0.658203125], [414, 883, 463, 993, 0.66650390625], [414, 883, 463, 994, 0.666015625], [414, 883, 463, 993, 0.66943359375], [414, 883, 463, 994, 0.6611328125], [414, 883, 462, 994, 0.6611328125], [414, 884, 462, 994, 0.66064453125], [414, 884, 462, 994, 0.65771484375], [414, 884, 462, 994, 0.65966796875], [413, 884, 462, 995, 0.66162109375], [413, 884, 462, 995, 0.6650390625], [413, 885, 462, 996, 0.6748046875], [413, 885, 462, 996, 0.6748046875], [413, 885, 462, 996, 0.673828125], [413, 885, 462, 996, 0.6708984375], [413, 885, 462, 996, 0.6728515625], [413, 885, 461, 996, 0.6748046875], [413, 886, 461, 997, 0.67236328125], [413, 886, 461, 997, 0.66796875], [412, 886, 461, 997, 0.66748046875], [412, 886, 461, 997, 0.6640625], [412, 886, 461, 997, 0.66650390625], [412, 886, 461, 997, 0.66748046875], [412, 886, 461, 997, 0.6640625], [412, 887, 460, 997, 0.6650390625], [412, 887, 460, 997, 0.65771484375], [411, 887, 460, 998, 0.65283203125]]\n",
      "Key: 8s, vector len: 12, Card Detections: [[440, 876, 490, 985, 0.662109375], [441, 876, 490, 985, 0.6591796875], [441, 877, 490, 986, 0.65869140625], [441, 876, 491, 987, 0.662109375], [441, 876, 490, 985, 0.64990234375], [441, 877, 490, 986, 0.65087890625], [441, 876, 490, 987, 0.65234375], [441, 876, 490, 987, 0.6513671875], [441, 876, 490, 986, 0.6494140625], [441, 877, 490, 986, 0.6513671875], [440, 877, 490, 987, 0.65576171875], [436, 878, 487, 990, 0.6083984375]]\n",
      "Key: 9c, vector len: 8, Card Detections: [[78, 849, 132, 966, 0.6494140625], [79, 850, 130, 963, 0.63037109375], [78, 850, 131, 964, 0.6328125], [78, 848, 131, 964, 0.64892578125], [78, 848, 131, 964, 0.646484375], [78, 850, 130, 964, 0.6396484375], [78, 849, 131, 964, 0.6435546875], [80, 854, 132, 966, 0.63916015625]]\n",
      "Key: 9d, vector len: 77, Card Detections: [[28, 853, 84, 989, 0.62158203125], [30, 854, 80, 966, 0.6611328125], [30, 854, 79, 966, 0.658203125], [29, 856, 80, 967, 0.6513671875], [29, 856, 79, 968, 0.65576171875], [29, 857, 79, 969, 0.65771484375], [29, 858, 79, 971, 0.6513671875], [29, 859, 79, 972, 0.6484375], [29, 859, 79, 972, 0.64697265625], [29, 859, 80, 971, 0.6474609375], [29, 858, 80, 971, 0.64453125], [29, 858, 80, 971, 0.6474609375], [29, 856, 80, 968, 0.66162109375], [29, 856, 80, 968, 0.65966796875], [29, 855, 80, 968, 0.66064453125], [29, 855, 80, 968, 0.6572265625], [29, 855, 80, 967, 0.654296875], [29, 854, 80, 966, 0.6552734375], [30, 854, 80, 966, 0.658203125], [30, 853, 80, 965, 0.65625], [30, 853, 80, 966, 0.65576171875], [30, 853, 80, 966, 0.65625], [30, 852, 80, 966, 0.65625], [30, 852, 80, 965, 0.658203125], [30, 852, 80, 966, 0.66259765625], [30, 852, 80, 966, 0.662109375], [30, 852, 80, 965, 0.6591796875], [30, 852, 80, 965, 0.66162109375], [30, 852, 80, 965, 0.66162109375], [30, 852, 80, 965, 0.666015625], [30, 852, 80, 965, 0.66552734375], [30, 852, 80, 965, 0.666015625], [30, 852, 80, 964, 0.66650390625], [30, 851, 80, 964, 0.66455078125], [30, 851, 80, 964, 0.6640625], [31, 850, 80, 964, 0.66552734375], [31, 850, 81, 963, 0.66748046875], [31, 849, 80, 963, 0.66455078125], [31, 849, 81, 963, 0.65966796875], [31, 849, 81, 962, 0.65771484375], [30, 849, 80, 962, 0.65771484375], [30, 849, 80, 963, 0.658203125], [30, 849, 81, 963, 0.65478515625], [30, 847, 80, 962, 0.64990234375], [30, 848, 80, 962, 0.65283203125], [30, 847, 80, 962, 0.6513671875], [30, 847, 80, 962, 0.650390625], [30, 847, 80, 961, 0.64990234375], [30, 847, 80, 961, 0.6513671875], [30, 847, 80, 961, 0.6513671875], [30, 847, 80, 962, 0.65087890625], [30, 847, 80, 962, 0.6494140625], [30, 847, 80, 961, 0.6513671875], [30, 846, 80, 961, 0.6494140625], [30, 846, 80, 960, 0.6513671875], [30, 846, 80, 960, 0.64892578125], [30, 846, 80, 960, 0.64990234375], [30, 846, 80, 959, 0.64892578125], [30, 845, 80, 959, 0.65087890625], [30, 845, 80, 959, 0.65234375], [30, 845, 80, 959, 0.65185546875], [30, 845, 81, 959, 0.6513671875], [31, 845, 81, 959, 0.6513671875], [31, 845, 81, 959, 0.64990234375], [31, 845, 81, 959, 0.650390625], [31, 845, 81, 959, 0.65087890625], [31, 845, 81, 959, 0.6513671875], [31, 845, 81, 959, 0.6484375], [31, 845, 81, 958, 0.64599609375], [31, 845, 81, 958, 0.640625], [31, 845, 82, 958, 0.64306640625], [32, 845, 82, 958, 0.642578125], [32, 845, 82, 958, 0.6435546875], [32, 845, 82, 957, 0.6435546875], [32, 845, 83, 957, 0.64208984375], [33, 845, 83, 956, 0.646484375], [33, 845, 84, 956, 0.64501953125]]\n",
      "Key: 9h, vector len: 30, Card Detections: [[406, 893, 457, 1003, 0.65283203125], [405, 892, 457, 1004, 0.65625], [406, 893, 457, 1004, 0.66796875], [405, 893, 457, 1006, 0.66943359375], [405, 893, 457, 1006, 0.66552734375], [405, 893, 457, 1006, 0.669921875], [405, 893, 457, 1006, 0.66796875], [405, 893, 457, 1006, 0.66748046875], [405, 893, 457, 1006, 0.6669921875], [405, 894, 457, 1006, 0.66943359375], [405, 894, 457, 1006, 0.66796875], [405, 894, 457, 1006, 0.66845703125], [405, 894, 457, 1006, 0.66796875], [405, 894, 457, 1006, 0.66796875], [405, 894, 456, 1006, 0.65625], [405, 894, 456, 1006, 0.65966796875], [405, 894, 456, 1006, 0.654296875], [405, 894, 456, 1006, 0.6572265625], [405, 894, 456, 1006, 0.65576171875], [405, 895, 456, 1008, 0.6552734375], [405, 895, 456, 1007, 0.6533203125], [404, 895, 456, 1007, 0.65478515625], [405, 896, 456, 1007, 0.6533203125], [404, 896, 456, 1007, 0.64990234375], [404, 895, 456, 1007, 0.64990234375], [404, 896, 456, 1007, 0.64697265625], [404, 896, 456, 1007, 0.6455078125], [404, 896, 455, 1007, 0.64599609375], [404, 897, 455, 1008, 0.6376953125], [403, 898, 455, 1008, 0.62939453125]]\n",
      "Key: 9s, vector len: 7, Card Detections: [[88, 875, 146, 1010, 0.6298828125], [90, 874, 142, 987, 0.6591796875], [90, 874, 142, 987, 0.65087890625], [90, 873, 141, 986, 0.6513671875], [90, 872, 141, 986, 0.64990234375], [90, 872, 142, 987, 0.6474609375], [90, 872, 142, 987, 0.646484375]]\n",
      "Key: Ac, vector len: 6, Card Detections: [[88, 879, 145, 995, 0.6396484375], [88, 878, 145, 994, 0.64453125], [88, 878, 145, 994, 0.642578125], [88, 878, 146, 993, 0.64111328125], [88, 877, 146, 993, 0.6494140625], [88, 877, 146, 993, 0.64306640625]]\n",
      "Key: Ad, vector len: 25, Card Detections: [[414, 885, 463, 994, 0.65771484375], [414, 885, 462, 995, 0.65283203125], [414, 885, 462, 994, 0.65380859375], [414, 886, 462, 995, 0.64697265625], [414, 887, 461, 996, 0.64599609375], [414, 886, 461, 995, 0.64892578125], [414, 886, 461, 995, 0.64453125], [414, 886, 461, 995, 0.64404296875], [414, 886, 461, 995, 0.6474609375], [414, 886, 461, 995, 0.6484375], [414, 886, 461, 996, 0.6484375], [414, 886, 461, 995, 0.6474609375], [414, 886, 461, 995, 0.64306640625], [414, 887, 461, 995, 0.64501953125], [413, 887, 461, 996, 0.642578125], [414, 887, 461, 996, 0.6435546875], [414, 887, 461, 996, 0.6435546875], [414, 887, 460, 996, 0.64501953125], [413, 887, 460, 996, 0.6455078125], [413, 887, 460, 996, 0.6455078125], [413, 887, 460, 996, 0.646484375], [413, 888, 460, 996, 0.64892578125], [413, 888, 460, 996, 0.6484375], [412, 888, 460, 997, 0.6484375], [412, 890, 459, 998, 0.64453125]]\n",
      "Key: Ah, vector len: 16, Card Detections: [[59, 821, 113, 937, 0.6455078125], [60, 822, 111, 937, 0.6416015625], [59, 822, 112, 939, 0.6416015625], [58, 822, 112, 939, 0.642578125], [58, 823, 111, 940, 0.64013671875], [57, 824, 110, 941, 0.64404296875], [56, 824, 110, 941, 0.64697265625], [56, 824, 110, 941, 0.6494140625], [56, 824, 109, 941, 0.64990234375], [56, 824, 109, 941, 0.64990234375], [56, 824, 109, 941, 0.6513671875], [56, 824, 109, 942, 0.6494140625], [56, 825, 109, 942, 0.6494140625], [55, 825, 109, 942, 0.6474609375], [56, 825, 109, 943, 0.64794921875], [58, 832, 109, 949, 0.642578125]]\n",
      "Key: As, vector len: 20, Card Detections: [[431, 881, 483, 994, 0.640625], [430, 881, 482, 994, 0.62939453125], [430, 881, 482, 994, 0.63232421875], [429, 882, 481, 995, 0.626953125], [429, 882, 480, 996, 0.62158203125], [429, 882, 480, 996, 0.61669921875], [429, 882, 479, 995, 0.6171875], [428, 883, 479, 996, 0.6142578125], [428, 883, 479, 996, 0.60400390625], [428, 884, 478, 997, 0.60205078125], [427, 884, 478, 997, 0.6005859375], [427, 884, 478, 997, 0.59912109375], [427, 884, 478, 997, 0.58984375], [427, 884, 478, 998, 0.58935546875], [426, 886, 477, 999, 0.6044921875], [426, 885, 477, 998, 0.6025390625], [426, 885, 477, 998, 0.60205078125], [426, 886, 477, 999, 0.60888671875], [426, 886, 477, 999, 0.61328125], [425, 887, 476, 999, 0.60595703125]]\n",
      "Key: Jc, vector len: 10, Card Detections: [[70, 827, 124, 945, 0.69970703125], [70, 827, 125, 945, 0.69873046875], [70, 827, 125, 944, 0.7021484375], [70, 826, 125, 944, 0.70654296875], [70, 827, 125, 945, 0.70654296875], [70, 827, 125, 945, 0.70751953125], [70, 827, 125, 945, 0.70458984375], [71, 827, 125, 945, 0.70361328125], [71, 827, 126, 945, 0.70361328125], [71, 827, 126, 946, 0.70751953125]]\n",
      "Key: Jd, vector len: 6, Card Detections: [[90, 866, 141, 978, 0.6337890625], [89, 866, 141, 978, 0.62744140625], [90, 866, 141, 978, 0.63330078125], [89, 865, 141, 979, 0.63818359375], [89, 866, 141, 978, 0.63525390625], [89, 866, 141, 978, 0.64697265625]]\n",
      "Key: Jh, vector len: 7, Card Detections: [[75, 836, 128, 953, 0.6123046875], [74, 835, 127, 951, 0.60888671875], [74, 835, 128, 951, 0.611328125], [74, 834, 128, 951, 0.615234375], [74, 834, 127, 950, 0.6103515625], [74, 836, 127, 952, 0.611328125], [74, 835, 127, 952, 0.6123046875]]\n",
      "Key: Js, vector len: 44, Card Detections: [[31, 835, 84, 955, 0.693359375], [30, 836, 83, 956, 0.68798828125], [30, 839, 82, 959, 0.68701171875], [30, 839, 82, 959, 0.68701171875], [30, 840, 83, 960, 0.68798828125], [30, 842, 82, 961, 0.68505859375], [30, 843, 82, 962, 0.6865234375], [30, 844, 82, 962, 0.685546875], [30, 844, 82, 963, 0.6865234375], [30, 845, 82, 964, 0.6875], [30, 846, 81, 964, 0.6875], [30, 846, 81, 965, 0.69091796875], [30, 845, 81, 964, 0.68896484375], [30, 846, 81, 965, 0.6923828125], [30, 846, 81, 965, 0.6923828125], [30, 846, 81, 965, 0.693359375], [30, 846, 81, 965, 0.69384765625], [30, 846, 81, 965, 0.693359375], [30, 846, 81, 965, 0.69384765625], [30, 846, 81, 965, 0.693359375], [30, 847, 81, 966, 0.69384765625], [30, 847, 81, 966, 0.6923828125], [30, 847, 81, 966, 0.6923828125], [30, 847, 81, 966, 0.6923828125], [30, 848, 81, 966, 0.689453125], [30, 848, 82, 967, 0.6884765625], [30, 850, 82, 967, 0.689453125], [30, 851, 82, 968, 0.6884765625], [30, 852, 81, 968, 0.69140625], [30, 852, 81, 968, 0.6923828125], [30, 854, 81, 969, 0.69091796875], [30, 854, 81, 969, 0.68994140625], [30, 855, 81, 970, 0.69091796875], [30, 855, 82, 969, 0.68994140625], [30, 855, 82, 970, 0.689453125], [30, 856, 82, 970, 0.68896484375], [30, 856, 82, 970, 0.6904296875], [30, 856, 82, 970, 0.69091796875], [30, 856, 82, 970, 0.6904296875], [30, 856, 82, 970, 0.68994140625], [30, 857, 82, 970, 0.6865234375], [30, 857, 82, 971, 0.68701171875], [30, 858, 82, 971, 0.68701171875], [31, 860, 82, 971, 0.6826171875]]\n",
      "Key: Kc, vector len: 5, Card Detections: [[81, 855, 138, 973, 0.734375], [81, 855, 137, 973, 0.74658203125], [82, 855, 137, 972, 0.74365234375], [82, 855, 137, 972, 0.74658203125], [83, 857, 138, 972, 0.7490234375]]\n",
      "Key: Kd, vector len: 12, Card Detections: [[89, 864, 145, 1000, 0.5947265625], [42, 822, 97, 939, 0.6533203125], [41, 822, 96, 937, 0.6630859375], [41, 823, 96, 939, 0.65771484375], [41, 823, 96, 939, 0.658203125], [41, 824, 96, 939, 0.6513671875], [41, 824, 96, 940, 0.650390625], [41, 825, 95, 941, 0.6494140625], [41, 825, 95, 941, 0.650390625], [41, 825, 95, 941, 0.6484375], [41, 825, 95, 941, 0.65234375], [41, 827, 95, 942, 0.64794921875]]\n",
      "Key: Kh, vector len: 24, Card Detections: [[435, 874, 485, 988, 0.6318359375], [435, 875, 485, 987, 0.63818359375], [435, 875, 484, 987, 0.63720703125], [434, 875, 484, 987, 0.63671875], [434, 876, 484, 988, 0.63134765625], [434, 876, 483, 987, 0.63134765625], [434, 876, 483, 988, 0.62939453125], [433, 876, 483, 988, 0.62548828125], [433, 876, 483, 988, 0.623046875], [432, 876, 482, 987, 0.62939453125], [432, 876, 482, 987, 0.64013671875], [432, 876, 482, 988, 0.64306640625], [431, 876, 482, 987, 0.640625], [431, 876, 481, 987, 0.63671875], [431, 877, 480, 988, 0.63818359375], [430, 877, 480, 988, 0.62939453125], [429, 877, 480, 989, 0.62646484375], [429, 877, 479, 989, 0.62646484375], [429, 877, 479, 989, 0.62744140625], [428, 878, 479, 990, 0.62109375], [428, 878, 479, 990, 0.6171875], [428, 878, 478, 990, 0.623046875], [427, 879, 478, 990, 0.62841796875], [426, 881, 476, 991, 0.6279296875]]\n",
      "Key: Ks, vector len: 6, Card Detections: [[86, 864, 142, 982, 0.646484375], [86, 864, 142, 982, 0.64990234375], [86, 864, 142, 982, 0.650390625], [87, 864, 142, 982, 0.64892578125], [87, 864, 142, 981, 0.65380859375], [86, 865, 142, 982, 0.66552734375]]\n",
      "Key: Qc, vector len: 6, Card Detections: [[440, 883, 493, 990, 0.66796875], [440, 882, 493, 991, 0.64794921875], [439, 883, 493, 991, 0.658203125], [439, 883, 492, 991, 0.6533203125], [439, 883, 492, 991, 0.646484375], [439, 884, 491, 991, 0.6513671875]]\n",
      "Key: Qd, vector len: 9, Card Detections: [[72, 822, 123, 935, 0.6181640625], [72, 822, 123, 936, 0.61962890625], [72, 822, 123, 936, 0.61669921875], [72, 822, 123, 936, 0.61279296875], [72, 823, 123, 936, 0.61181640625], [72, 823, 123, 937, 0.61083984375], [72, 823, 123, 937, 0.6142578125], [71, 824, 123, 937, 0.61279296875], [72, 828, 124, 942, 0.59423828125]]\n",
      "Key: Qh, vector len: 56, Card Detections: [[399, 883, 449, 995, 0.6259765625], [399, 884, 449, 995, 0.62060546875], [399, 884, 449, 996, 0.63916015625], [399, 885, 448, 996, 0.64208984375], [399, 885, 448, 996, 0.64794921875], [399, 885, 448, 996, 0.6474609375], [398, 885, 448, 996, 0.6259765625], [398, 885, 448, 996, 0.626953125], [398, 885, 448, 996, 0.62158203125], [398, 885, 448, 996, 0.642578125], [399, 885, 448, 996, 0.6337890625], [399, 885, 448, 996, 0.64404296875], [399, 885, 448, 996, 0.64208984375], [399, 884, 447, 996, 0.6376953125], [399, 884, 447, 995, 0.63134765625], [399, 884, 447, 995, 0.63037109375], [399, 884, 447, 995, 0.630859375], [399, 884, 447, 995, 0.623046875], [399, 884, 447, 995, 0.61376953125], [399, 885, 448, 995, 0.6083984375], [399, 885, 447, 995, 0.61328125], [399, 885, 447, 995, 0.6044921875], [399, 884, 448, 995, 0.61279296875], [399, 884, 448, 995, 0.62109375], [399, 884, 448, 995, 0.6220703125], [399, 884, 448, 995, 0.6162109375], [399, 884, 448, 995, 0.6279296875], [399, 885, 447, 995, 0.62255859375], [399, 885, 447, 995, 0.62548828125], [399, 884, 447, 995, 0.6123046875], [399, 884, 447, 995, 0.60595703125], [399, 884, 447, 995, 0.6201171875], [399, 884, 447, 995, 0.6240234375], [399, 885, 447, 995, 0.62255859375], [398, 885, 448, 995, 0.6337890625], [398, 886, 448, 996, 0.64404296875], [398, 885, 448, 996, 0.64306640625], [398, 886, 447, 996, 0.642578125], [398, 886, 447, 996, 0.646484375], [397, 886, 447, 997, 0.64453125], [397, 886, 447, 996, 0.6484375], [397, 886, 447, 996, 0.6474609375], [398, 886, 447, 996, 0.64599609375], [397, 886, 447, 996, 0.64306640625], [397, 886, 447, 996, 0.640625], [397, 887, 447, 996, 0.6435546875], [397, 887, 446, 996, 0.64453125], [397, 887, 446, 996, 0.64599609375], [397, 888, 446, 997, 0.6533203125], [396, 888, 445, 997, 0.6494140625], [395, 889, 445, 997, 0.64404296875], [395, 889, 444, 998, 0.638671875], [394, 890, 443, 998, 0.64794921875], [393, 892, 443, 999, 0.6455078125], [391, 893, 442, 1000, 0.64794921875], [386, 897, 437, 1003, 0.630859375]]\n",
      "Key: Qs, vector len: 7, Card Detections: [[80, 845, 132, 962, 0.6376953125], [80, 845, 132, 961, 0.650390625], [80, 845, 132, 962, 0.65185546875], [80, 844, 132, 961, 0.65673828125], [80, 844, 132, 960, 0.65673828125], [80, 844, 132, 961, 0.6552734375], [81, 846, 134, 962, 0.65673828125]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 0, Card Detections: []\n",
      "Key: Tc, vector len: 2, Card Detections: [[138, 1047, 192, 1181, 0.62646484375], [139, 1049, 192, 1179, 0.6318359375]]\n",
      "Key: Td, vector len: 21, Card Detections: [[522, 1088, 576, 1212, 0.6455078125], [523, 1091, 577, 1211, 0.64599609375], [523, 1092, 577, 1212, 0.64208984375], [524, 1092, 576, 1213, 0.642578125], [525, 1092, 577, 1213, 0.6455078125], [525, 1092, 576, 1213, 0.646484375], [526, 1092, 577, 1213, 0.6474609375], [526, 1092, 577, 1213, 0.64794921875], [526, 1092, 577, 1213, 0.646484375], [526, 1092, 577, 1213, 0.64599609375], [525, 1093, 576, 1213, 0.64501953125], [525, 1093, 576, 1213, 0.64501953125], [525, 1093, 576, 1213, 0.6455078125], [525, 1092, 576, 1214, 0.6435546875], [525, 1093, 576, 1213, 0.64599609375], [525, 1092, 576, 1214, 0.6455078125], [525, 1093, 576, 1213, 0.64501953125], [525, 1093, 576, 1213, 0.64501953125], [526, 1092, 576, 1214, 0.6416015625], [525, 1093, 576, 1214, 0.6416015625], [523, 1095, 574, 1214, 0.63330078125]]\n",
      "Key: Th, vector len: 15, Card Detections: [[123, 1063, 179, 1192, 0.62158203125], [125, 1065, 179, 1193, 0.60498046875], [125, 1067, 180, 1195, 0.61474609375], [126, 1069, 180, 1196, 0.638671875], [125, 1069, 180, 1197, 0.6357421875], [125, 1071, 180, 1198, 0.642578125], [125, 1072, 180, 1199, 0.64892578125], [125, 1072, 180, 1199, 0.646484375], [125, 1074, 181, 1200, 0.65087890625], [125, 1074, 181, 1200, 0.65576171875], [125, 1075, 181, 1201, 0.65185546875], [126, 1075, 182, 1201, 0.64990234375], [126, 1075, 183, 1200, 0.6533203125], [128, 1076, 183, 1199, 0.6513671875], [130, 1077, 184, 1199, 0.65771484375]]\n",
      "Key: Ts, vector len: 0, Card Detections: []\n",
      "Key: 2c, vector len: 1, Card Detections: [[517, 1099, 574, 1220, 0.61328125]]\n",
      "Key: 2d, vector len: 17, Card Detections: [[87, 1182, 150, 1283, 0.5927734375], [91, 1168, 155, 1276, 0.63330078125], [93, 1162, 154, 1272, 0.623046875], [98, 1154, 158, 1264, 0.63720703125], [102, 1144, 164, 1261, 0.6279296875], [105, 1143, 164, 1259, 0.6328125], [108, 1140, 167, 1257, 0.66943359375], [112, 1135, 172, 1255, 0.63427734375], [119, 1131, 177, 1251, 0.62060546875], [121, 1127, 178, 1248, 0.6396484375], [121, 1126, 178, 1247, 0.63720703125], [121, 1126, 179, 1247, 0.6416015625], [123, 1125, 181, 1246, 0.6357421875], [123, 1124, 181, 1246, 0.64501953125], [123, 1123, 181, 1246, 0.64697265625], [123, 1123, 181, 1246, 0.6484375], [126, 1123, 185, 1246, 0.6318359375]]\n",
      "Key: 2h, vector len: 7, Card Detections: [[517, 1084, 570, 1206, 0.6123046875], [517, 1083, 568, 1201, 0.6279296875], [518, 1083, 568, 1202, 0.62548828125], [517, 1083, 568, 1202, 0.62890625], [515, 1085, 570, 1205, 0.6201171875], [516, 1086, 569, 1204, 0.6298828125], [515, 1086, 568, 1205, 0.6279296875]]\n",
      "Key: 2s, vector len: 2, Card Detections: [[522, 1093, 577, 1214, 0.65283203125], [522, 1095, 576, 1217, 0.65673828125]]\n",
      "Key: 3c, vector len: 2, Card Detections: [[127, 1030, 186, 1164, 0.61181640625], [129, 1029, 186, 1164, 0.6025390625]]\n",
      "Key: 3d, vector len: 4, Card Detections: [[128, 1032, 188, 1166, 0.61181640625], [130, 1029, 186, 1164, 0.59619140625], [130, 1029, 187, 1163, 0.595703125], [130, 1030, 186, 1162, 0.6005859375]]\n",
      "Key: 3h, vector len: 2, Card Detections: [[136, 1069, 194, 1204, 0.59765625], [140, 1068, 196, 1204, 0.50390625]]\n",
      "Key: 3s, vector len: 5, Card Detections: [[124, 1030, 181, 1165, 0.625], [123, 1031, 180, 1164, 0.625], [124, 1032, 180, 1164, 0.615234375], [124, 1033, 180, 1165, 0.61962890625], [125, 1034, 180, 1167, 0.60888671875]]\n",
      "Key: 4c, vector len: 4, Card Detections: [[514, 1081, 633, 1210, 0.654296875], [514, 1081, 633, 1213, 0.6474609375], [514, 1083, 633, 1211, 0.6591796875], [512, 1083, 631, 1214, 0.65771484375]]\n",
      "Key: 4d, vector len: 5, Card Detections: [[514, 1080, 622, 1214, 0.59033203125], [516, 1081, 624, 1213, 0.5947265625], [516, 1083, 624, 1212, 0.5927734375], [516, 1084, 623, 1212, 0.6005859375], [517, 1084, 622, 1215, 0.5927734375]]\n",
      "Key: 4h, vector len: 3, Card Detections: [[134, 1065, 258, 1194, 0.6435546875], [135, 1065, 259, 1193, 0.640625], [134, 1063, 259, 1196, 0.63427734375]]\n",
      "Key: 4s, vector len: 3, Card Detections: [[526, 1088, 634, 1219, 0.63525390625], [526, 1089, 633, 1220, 0.63134765625], [525, 1089, 633, 1220, 0.63525390625]]\n",
      "Key: 5c, vector len: 4, Card Detections: [[123, 1034, 177, 1167, 0.65966796875], [122, 1033, 178, 1168, 0.6533203125], [123, 1036, 177, 1168, 0.666015625], [124, 1039, 178, 1172, 0.65576171875]]\n",
      "Key: 5d, vector len: 6, Card Detections: [[519, 1085, 570, 1206, 0.66796875], [520, 1084, 570, 1206, 0.67138671875], [519, 1084, 571, 1207, 0.6298828125], [520, 1085, 571, 1206, 0.63134765625], [518, 1084, 571, 1207, 0.6396484375], [516, 1086, 572, 1211, 0.64697265625]]\n",
      "Key: 5h, vector len: 8, Card Detections: [[517, 1081, 571, 1206, 0.626953125], [519, 1082, 570, 1203, 0.62939453125], [519, 1083, 570, 1204, 0.6220703125], [519, 1085, 571, 1206, 0.6240234375], [519, 1085, 570, 1206, 0.62353515625], [517, 1085, 569, 1206, 0.6328125], [516, 1086, 569, 1208, 0.6513671875], [516, 1087, 568, 1209, 0.6484375]]\n",
      "Key: 5s, vector len: 6, Card Detections: [[522, 1083, 575, 1208, 0.62548828125], [522, 1084, 576, 1207, 0.63134765625], [522, 1085, 575, 1208, 0.64111328125], [522, 1085, 575, 1208, 0.6484375], [522, 1086, 575, 1210, 0.64794921875], [523, 1088, 573, 1209, 0.63525390625]]\n",
      "Key: 6c, vector len: 5, Card Detections: [[514, 1082, 568, 1202, 0.6806640625], [514, 1082, 568, 1202, 0.68310546875], [513, 1082, 567, 1202, 0.67919921875], [513, 1082, 567, 1202, 0.6865234375], [512, 1083, 567, 1203, 0.69189453125]]\n",
      "Key: 6d, vector len: 31, Card Detections: [[126, 1072, 182, 1202, 0.60693359375], [128, 1072, 180, 1202, 0.6787109375], [127, 1073, 180, 1202, 0.6748046875], [126, 1074, 180, 1203, 0.67041015625], [127, 1074, 180, 1202, 0.68017578125], [127, 1073, 180, 1202, 0.67333984375], [127, 1074, 180, 1202, 0.681640625], [128, 1073, 180, 1201, 0.6767578125], [128, 1074, 181, 1201, 0.67724609375], [129, 1075, 181, 1201, 0.6728515625], [129, 1074, 182, 1202, 0.67333984375], [130, 1076, 183, 1202, 0.67626953125], [131, 1077, 183, 1202, 0.68994140625], [131, 1077, 183, 1201, 0.69580078125], [131, 1078, 184, 1202, 0.69921875], [132, 1079, 184, 1203, 0.6982421875], [132, 1080, 185, 1202, 0.70166015625], [133, 1080, 185, 1202, 0.7021484375], [133, 1079, 185, 1202, 0.701171875], [134, 1078, 186, 1201, 0.7001953125], [134, 1076, 186, 1199, 0.6923828125], [134, 1075, 186, 1198, 0.68359375], [135, 1074, 186, 1198, 0.67724609375], [135, 1073, 187, 1197, 0.6708984375], [136, 1073, 189, 1198, 0.6787109375], [137, 1073, 190, 1199, 0.673828125], [138, 1072, 191, 1198, 0.64013671875], [139, 1071, 192, 1197, 0.63916015625], [140, 1070, 193, 1197, 0.623046875], [140, 1068, 195, 1196, 0.61474609375], [141, 1066, 196, 1194, 0.619140625]]\n",
      "Key: 6h, vector len: 4, Card Detections: [[131, 1105, 186, 1233, 0.71728515625], [133, 1104, 187, 1232, 0.7080078125], [133, 1104, 187, 1230, 0.7041015625], [135, 1104, 187, 1231, 0.70068359375]]\n",
      "Key: 6s, vector len: 5, Card Detections: [[508, 1093, 565, 1210, 0.67041015625], [509, 1093, 564, 1210, 0.6689453125], [509, 1093, 564, 1210, 0.66357421875], [509, 1093, 563, 1210, 0.6650390625], [509, 1093, 562, 1210, 0.6796875]]\n",
      "Key: 7c, vector len: 6, Card Detections: [[512, 1080, 570, 1206, 0.599609375], [515, 1081, 570, 1206, 0.6376953125], [515, 1082, 570, 1207, 0.64501953125], [516, 1082, 571, 1206, 0.64794921875], [515, 1082, 570, 1207, 0.64501953125], [514, 1083, 570, 1208, 0.63916015625]]\n",
      "Key: 7d, vector len: 3, Card Detections: [[516, 1081, 567, 1203, 0.60546875], [516, 1081, 567, 1203, 0.59716796875], [513, 1080, 567, 1204, 0.60302734375]]\n",
      "Key: 7h, vector len: 3, Card Detections: [[130, 1042, 187, 1176, 0.615234375], [131, 1044, 186, 1176, 0.6669921875], [133, 1046, 186, 1177, 0.6650390625]]\n",
      "Key: 7s, vector len: 8, Card Detections: [[133, 1098, 184, 1229, 0.6376953125], [132, 1098, 185, 1229, 0.6533203125], [132, 1098, 184, 1227, 0.63525390625], [132, 1099, 183, 1227, 0.62646484375], [132, 1099, 181, 1227, 0.6123046875], [131, 1098, 182, 1227, 0.63330078125], [130, 1098, 183, 1228, 0.638671875], [129, 1098, 184, 1229, 0.64599609375]]\n",
      "Key: 8c, vector len: 2, Card Detections: [[508, 1093, 565, 1211, 0.6396484375], [508, 1094, 564, 1211, 0.64794921875]]\n",
      "Key: 8d, vector len: 2, Card Detections: [[142, 1069, 195, 1195, 0.6767578125], [143, 1068, 195, 1194, 0.67431640625]]\n",
      "Key: 8h, vector len: 2, Card Detections: [[124, 1038, 179, 1164, 0.654296875], [124, 1038, 178, 1164, 0.65673828125]]\n",
      "Key: 8s, vector len: 5, Card Detections: [[138, 1068, 193, 1198, 0.59716796875], [138, 1068, 192, 1198, 0.650390625], [138, 1068, 193, 1198, 0.6552734375], [138, 1068, 192, 1198, 0.6484375], [138, 1070, 193, 1199, 0.6533203125]]\n",
      "Key: 9c, vector len: 8, Card Detections: [[129, 1119, 186, 1243, 0.619140625], [131, 1116, 187, 1239, 0.61572265625], [132, 1116, 187, 1240, 0.615234375], [131, 1114, 187, 1238, 0.61376953125], [131, 1113, 187, 1238, 0.61279296875], [131, 1114, 185, 1238, 0.607421875], [130, 1114, 184, 1238, 0.61083984375], [130, 1116, 184, 1238, 0.60986328125]]\n",
      "Key: 9d, vector len: 4, Card Detections: [[131, 1042, 186, 1174, 0.64892578125], [131, 1044, 185, 1170, 0.646484375], [131, 1043, 185, 1170, 0.6533203125], [132, 1043, 185, 1170, 0.65478515625]]\n",
      "Key: 9h, vector len: 4, Card Detections: [[512, 1085, 564, 1199, 0.5947265625], [513, 1085, 563, 1197, 0.5947265625], [512, 1086, 562, 1199, 0.60791015625], [511, 1088, 562, 1200, 0.60986328125]]\n",
      "Key: 9s, vector len: 3, Card Detections: [[507, 1091, 563, 1209, 0.55517578125], [508, 1090, 562, 1207, 0.6162109375], [507, 1091, 561, 1206, 0.60791015625]]\n",
      "Key: Ac, vector len: 2, Card Detections: [[135, 1087, 190, 1219, 0.6298828125], [139, 1086, 192, 1217, 0.6240234375]]\n",
      "Key: Ad, vector len: 2, Card Detections: [[137, 1046, 190, 1176, 0.65087890625], [137, 1045, 190, 1176, 0.640625]]\n",
      "Key: Ah, vector len: 2, Card Detections: [[509, 1091, 561, 1204, 0.62841796875], [509, 1092, 560, 1204, 0.6298828125]]\n",
      "Key: As, vector len: 2, Card Detections: [[512, 1086, 567, 1204, 0.57861328125], [511, 1087, 567, 1205, 0.63720703125]]\n",
      "Key: Jc, vector len: 2, Card Detections: [[129, 1095, 187, 1226, 0.67919921875], [132, 1094, 188, 1224, 0.67333984375]]\n",
      "Key: Jd, vector len: 6, Card Detections: [[135, 1081, 191, 1210, 0.611328125], [138, 1081, 190, 1209, 0.5927734375], [138, 1082, 190, 1209, 0.59375], [138, 1083, 189, 1210, 0.59326171875], [137, 1084, 189, 1210, 0.5888671875], [136, 1084, 190, 1210, 0.599609375]]\n",
      "Key: Jh, vector len: 2, Card Detections: [[134, 1080, 189, 1209, 0.6064453125], [137, 1081, 189, 1207, 0.59521484375]]\n",
      "Key: Js, vector len: 1, Card Detections: [[133, 1064, 192, 1191, 0.67333984375]]\n",
      "Key: Kc, vector len: 2, Card Detections: [[134, 1059, 192, 1191, 0.66943359375], [137, 1058, 192, 1187, 0.64697265625]]\n",
      "Key: Kd, vector len: 4, Card Detections: [[512, 1081, 564, 1200, 0.65283203125], [512, 1081, 564, 1199, 0.65478515625], [511, 1083, 564, 1202, 0.65869140625], [510, 1085, 563, 1203, 0.6474609375]]\n",
      "Key: Kh, vector len: 6, Card Detections: [[507, 1097, 561, 1211, 0.6123046875], [507, 1096, 561, 1211, 0.61083984375], [509, 1096, 560, 1209, 0.60986328125], [508, 1096, 561, 1209, 0.607421875], [508, 1096, 561, 1210, 0.60791015625], [507, 1096, 559, 1211, 0.6025390625]]\n",
      "Key: Ks, vector len: 20, Card Detections: [[520, 1117, 592, 1216, 0.6787109375], [519, 1110, 586, 1215, 0.6826171875], [518, 1109, 582, 1218, 0.6767578125], [517, 1107, 579, 1220, 0.7060546875], [508, 1104, 569, 1219, 0.71142578125], [505, 1099, 564, 1216, 0.703125], [505, 1097, 562, 1214, 0.69482421875], [505, 1095, 561, 1214, 0.7001953125], [504, 1095, 561, 1214, 0.6962890625], [505, 1093, 562, 1213, 0.6982421875], [504, 1093, 561, 1213, 0.69873046875], [504, 1095, 562, 1213, 0.69580078125], [504, 1096, 560, 1214, 0.68603515625], [503, 1097, 560, 1215, 0.689453125], [503, 1097, 560, 1215, 0.68798828125], [503, 1097, 560, 1215, 0.69189453125], [503, 1097, 560, 1215, 0.685546875], [504, 1099, 560, 1214, 0.70751953125], [504, 1100, 559, 1214, 0.708984375], [504, 1100, 559, 1215, 0.70947265625]]\n",
      "Key: Qc, vector len: 4, Card Detections: [[511, 1094, 564, 1209, 0.646484375], [511, 1094, 564, 1209, 0.6435546875], [510, 1095, 563, 1210, 0.6396484375], [509, 1096, 562, 1212, 0.6416015625]]\n",
      "Key: Qd, vector len: 2, Card Detections: [[125, 1044, 178, 1172, 0.61962890625], [127, 1047, 177, 1175, 0.609375]]\n",
      "Key: Qh, vector len: 4, Card Detections: [[512, 1089, 566, 1208, 0.62255859375], [513, 1090, 564, 1204, 0.61865234375], [514, 1090, 564, 1204, 0.6162109375], [513, 1090, 563, 1204, 0.61572265625]]\n",
      "Key: Qs, vector len: 2, Card Detections: [[524, 1089, 576, 1209, 0.65673828125], [522, 1091, 575, 1210, 0.66650390625]]\n",
      "Key: SJoker, vector len: 6, Card Detections: [[517, 1091, 583, 1227, 0.57275390625], [517, 1091, 582, 1226, 0.57666015625], [518, 1091, 580, 1226, 0.56787109375], [517, 1093, 580, 1225, 0.5771484375], [517, 1093, 581, 1230, 0.5751953125], [517, 1092, 580, 1229, 0.58740234375]]\n",
      "Key: BJoker, vector len: 6, Card Detections: [[107, 1053, 177, 1230, 0.548828125], [108, 1054, 178, 1228, 0.53125], [109, 1056, 178, 1230, 0.5107421875], [108, 1057, 177, 1234, 0.54052734375], [108, 1059, 178, 1236, 0.544921875], [115, 1060, 183, 1234, 0.57177734375]]\n",
      "Key: Tc, vector len: 34, Card Detections: [[141, 1061, 202, 1185, 0.63037109375], [143, 1065, 200, 1188, 0.63525390625], [143, 1067, 199, 1188, 0.640625], [142, 1069, 199, 1190, 0.6416015625], [142, 1070, 199, 1191, 0.63037109375], [143, 1070, 198, 1191, 0.62255859375], [143, 1071, 198, 1192, 0.6240234375], [143, 1070, 198, 1191, 0.630859375], [143, 1070, 198, 1192, 0.6220703125], [143, 1069, 198, 1192, 0.62890625], [143, 1069, 198, 1192, 0.62890625], [143, 1069, 198, 1192, 0.6298828125], [143, 1069, 198, 1191, 0.63134765625], [143, 1068, 198, 1190, 0.6357421875], [142, 1068, 198, 1188, 0.64208984375], [142, 1068, 198, 1188, 0.64111328125], [142, 1069, 198, 1189, 0.64306640625], [142, 1069, 198, 1188, 0.64208984375], [142, 1069, 198, 1188, 0.64453125], [142, 1071, 198, 1189, 0.64111328125], [142, 1071, 198, 1189, 0.6435546875], [142, 1072, 198, 1191, 0.6318359375], [143, 1074, 198, 1191, 0.62451171875], [143, 1074, 197, 1190, 0.6201171875], [143, 1076, 197, 1191, 0.62109375], [143, 1077, 197, 1192, 0.62109375], [142, 1077, 197, 1191, 0.62158203125], [142, 1078, 197, 1192, 0.62548828125], [142, 1080, 197, 1192, 0.630859375], [142, 1081, 197, 1192, 0.6298828125], [141, 1081, 197, 1193, 0.63037109375], [142, 1081, 197, 1193, 0.62939453125], [142, 1083, 197, 1194, 0.62451171875], [141, 1081, 199, 1196, 0.61328125]]\n",
      "Key: Td, vector len: 19, Card Detections: [[533, 1090, 586, 1208, 0.68115234375], [533, 1091, 585, 1209, 0.68115234375], [532, 1092, 586, 1203, 0.6689453125], [532, 1092, 586, 1208, 0.69091796875], [532, 1093, 586, 1207, 0.69091796875], [532, 1093, 586, 1208, 0.68896484375], [531, 1093, 585, 1207, 0.68994140625], [532, 1093, 585, 1208, 0.69140625], [532, 1093, 585, 1208, 0.69091796875], [532, 1093, 585, 1209, 0.69091796875], [531, 1094, 584, 1209, 0.69091796875], [531, 1094, 584, 1209, 0.68896484375], [531, 1095, 584, 1210, 0.68896484375], [530, 1095, 583, 1210, 0.6904296875], [530, 1095, 583, 1210, 0.6904296875], [529, 1096, 583, 1210, 0.69091796875], [529, 1096, 583, 1211, 0.689453125], [529, 1097, 582, 1211, 0.68603515625], [528, 1099, 581, 1212, 0.67626953125]]\n",
      "Key: Th, vector len: 12, Card Detections: [[534, 1084, 586, 1201, 0.625], [534, 1084, 585, 1203, 0.63037109375], [534, 1085, 585, 1201, 0.6279296875], [535, 1087, 585, 1203, 0.62744140625], [535, 1086, 585, 1203, 0.6318359375], [535, 1087, 585, 1204, 0.63037109375], [535, 1088, 584, 1204, 0.62744140625], [535, 1088, 584, 1204, 0.626953125], [534, 1089, 584, 1204, 0.62548828125], [534, 1089, 584, 1204, 0.60595703125], [533, 1090, 582, 1205, 0.6201171875], [531, 1092, 580, 1207, 0.59814453125]]\n",
      "Key: Ts, vector len: 10, Card Detections: [[514, 1096, 568, 1217, 0.513671875], [516, 1096, 570, 1213, 0.611328125], [516, 1095, 570, 1212, 0.60595703125], [516, 1097, 570, 1212, 0.60888671875], [516, 1096, 570, 1213, 0.61328125], [516, 1096, 570, 1213, 0.5947265625], [516, 1096, 570, 1213, 0.6025390625], [516, 1097, 570, 1212, 0.5947265625], [516, 1098, 570, 1213, 0.60107421875], [514, 1099, 569, 1213, 0.5966796875]]\n",
      "Key: 2c, vector len: 52, Card Detections: [[518, 1087, 575, 1212, 0.59033203125], [530, 1097, 587, 1210, 0.61962890625], [531, 1097, 586, 1215, 0.642578125], [530, 1098, 586, 1213, 0.62548828125], [531, 1099, 586, 1215, 0.6298828125], [530, 1099, 585, 1214, 0.63720703125], [529, 1099, 586, 1217, 0.6337890625], [529, 1099, 586, 1216, 0.6337890625], [529, 1099, 586, 1217, 0.63330078125], [529, 1099, 586, 1217, 0.6328125], [529, 1099, 586, 1216, 0.63330078125], [529, 1100, 586, 1217, 0.638671875], [529, 1100, 586, 1216, 0.64013671875], [528, 1101, 585, 1219, 0.6328125], [528, 1101, 585, 1219, 0.63232421875], [528, 1101, 586, 1219, 0.6298828125], [528, 1101, 586, 1219, 0.626953125], [528, 1101, 586, 1219, 0.625], [528, 1101, 586, 1220, 0.62451171875], [528, 1101, 586, 1220, 0.62353515625], [528, 1101, 586, 1220, 0.625], [528, 1101, 586, 1220, 0.62548828125], [528, 1101, 586, 1220, 0.625], [528, 1101, 586, 1220, 0.62548828125], [528, 1101, 585, 1219, 0.625], [528, 1101, 586, 1220, 0.62451171875], [528, 1101, 586, 1220, 0.62451171875], [528, 1102, 585, 1221, 0.62646484375], [528, 1102, 585, 1221, 0.62548828125], [527, 1102, 585, 1221, 0.62548828125], [528, 1102, 585, 1221, 0.62548828125], [527, 1102, 585, 1221, 0.62890625], [527, 1102, 585, 1221, 0.62939453125], [527, 1102, 585, 1222, 0.63232421875], [527, 1102, 584, 1222, 0.6298828125], [527, 1103, 584, 1221, 0.6298828125], [527, 1103, 584, 1221, 0.63037109375], [527, 1103, 584, 1221, 0.6318359375], [527, 1103, 584, 1221, 0.63330078125], [527, 1103, 584, 1221, 0.634765625], [527, 1103, 584, 1222, 0.63427734375], [527, 1103, 583, 1222, 0.63427734375], [527, 1103, 583, 1222, 0.6328125], [527, 1103, 583, 1222, 0.6337890625], [527, 1103, 583, 1222, 0.6318359375], [527, 1104, 583, 1222, 0.630859375], [527, 1104, 583, 1222, 0.630859375], [527, 1104, 583, 1222, 0.63037109375], [527, 1104, 582, 1222, 0.63037109375], [526, 1104, 583, 1222, 0.6298828125], [526, 1104, 582, 1223, 0.6357421875], [523, 1106, 580, 1223, 0.64599609375]]\n",
      "Key: 2d, vector len: 7, Card Detections: [[145, 1200, 201, 1284, 0.61376953125], [145, 1182, 202, 1274, 0.6474609375], [148, 1169, 205, 1267, 0.6318359375], [155, 1153, 209, 1258, 0.634765625], [154, 1141, 209, 1252, 0.64306640625], [156, 1136, 210, 1248, 0.63134765625], [157, 1130, 210, 1240, 0.64453125]]\n",
      "Key: 2h, vector len: 8, Card Detections: [[516, 1096, 569, 1210, 0.60498046875], [516, 1095, 568, 1209, 0.615234375], [516, 1096, 568, 1210, 0.6171875], [516, 1097, 568, 1210, 0.615234375], [516, 1096, 568, 1210, 0.61181640625], [516, 1096, 568, 1210, 0.615234375], [515, 1097, 567, 1210, 0.62255859375], [514, 1097, 567, 1212, 0.611328125]]\n",
      "Key: 2s, vector len: 18, Card Detections: [[537, 1090, 588, 1207, 0.64208984375], [537, 1091, 589, 1208, 0.65380859375], [536, 1090, 588, 1203, 0.64404296875], [536, 1091, 588, 1208, 0.64306640625], [534, 1092, 588, 1206, 0.642578125], [535, 1094, 588, 1209, 0.638671875], [536, 1094, 587, 1209, 0.640625], [535, 1093, 588, 1207, 0.63427734375], [535, 1093, 587, 1209, 0.6328125], [534, 1093, 587, 1208, 0.63134765625], [535, 1093, 587, 1209, 0.63427734375], [534, 1093, 587, 1208, 0.630859375], [534, 1094, 587, 1209, 0.6396484375], [535, 1095, 586, 1210, 0.6435546875], [534, 1095, 586, 1209, 0.646484375], [533, 1097, 586, 1209, 0.64453125], [533, 1097, 585, 1209, 0.64697265625], [531, 1100, 583, 1212, 0.67138671875]]\n",
      "Key: 3c, vector len: 7, Card Detections: [[521, 1089, 576, 1208, 0.6416015625], [521, 1088, 576, 1208, 0.6455078125], [521, 1089, 576, 1208, 0.642578125], [521, 1090, 576, 1208, 0.638671875], [521, 1089, 576, 1208, 0.64208984375], [520, 1090, 577, 1209, 0.63916015625], [520, 1091, 576, 1209, 0.64501953125]]\n",
      "Key: 3d, vector len: 10, Card Detections: [[520, 1091, 571, 1206, 0.63330078125], [520, 1091, 571, 1207, 0.62939453125], [520, 1091, 571, 1207, 0.6298828125], [520, 1091, 571, 1206, 0.626953125], [519, 1090, 572, 1207, 0.62939453125], [519, 1090, 572, 1207, 0.625], [520, 1090, 571, 1207, 0.6240234375], [519, 1091, 572, 1207, 0.62890625], [520, 1092, 571, 1207, 0.62939453125], [519, 1090, 572, 1209, 0.5966796875]]\n",
      "Key: 3h, vector len: 5, Card Detections: [[137, 1051, 197, 1182, 0.5966796875], [138, 1052, 197, 1181, 0.5908203125], [138, 1052, 198, 1179, 0.59619140625], [141, 1052, 197, 1181, 0.609375], [141, 1053, 198, 1182, 0.62939453125]]\n",
      "Key: 3s, vector len: 7, Card Detections: [[527, 1086, 582, 1206, 0.63037109375], [527, 1087, 582, 1206, 0.64013671875], [527, 1086, 582, 1206, 0.638671875], [527, 1086, 582, 1205, 0.6416015625], [527, 1087, 582, 1206, 0.6435546875], [526, 1087, 581, 1206, 0.64990234375], [525, 1090, 580, 1207, 0.65478515625]]\n",
      "Key: 4c, vector len: 26, Card Detections: [[136, 1060, 278, 1185, 0.6533203125], [137, 1060, 278, 1185, 0.65869140625], [136, 1060, 278, 1186, 0.65869140625], [137, 1060, 278, 1185, 0.658203125], [136, 1060, 278, 1185, 0.65673828125], [137, 1059, 278, 1184, 0.65673828125], [137, 1060, 278, 1185, 0.65625], [136, 1059, 278, 1184, 0.6533203125], [137, 1058, 279, 1183, 0.65283203125], [137, 1057, 279, 1183, 0.65087890625], [137, 1055, 279, 1182, 0.6552734375], [137, 1055, 278, 1181, 0.64990234375], [138, 1052, 279, 1178, 0.64453125], [138, 1052, 279, 1178, 0.64501953125], [138, 1048, 278, 1177, 0.6533203125], [139, 1048, 277, 1177, 0.654296875], [139, 1048, 277, 1177, 0.654296875], [139, 1048, 278, 1177, 0.65625], [139, 1049, 278, 1176, 0.65576171875], [140, 1049, 279, 1176, 0.658203125], [140, 1051, 279, 1177, 0.66162109375], [141, 1051, 280, 1177, 0.66259765625], [141, 1052, 280, 1177, 0.6669921875], [141, 1053, 280, 1178, 0.66845703125], [141, 1055, 281, 1178, 0.66650390625], [142, 1057, 281, 1179, 0.6669921875]]\n",
      "Key: 4d, vector len: 8, Card Detections: [[515, 1100, 627, 1221, 0.6044921875], [516, 1100, 627, 1221, 0.59765625], [515, 1099, 627, 1221, 0.59619140625], [515, 1101, 627, 1222, 0.603515625], [515, 1100, 627, 1221, 0.609375], [514, 1101, 628, 1222, 0.6103515625], [514, 1101, 627, 1222, 0.61083984375], [514, 1102, 627, 1222, 0.6103515625]]\n",
      "Key: 4h, vector len: 9, Card Detections: [[141, 1059, 267, 1180, 0.62939453125], [141, 1059, 267, 1180, 0.62890625], [140, 1059, 268, 1180, 0.63623046875], [140, 1060, 267, 1183, 0.63720703125], [140, 1059, 268, 1181, 0.64111328125], [140, 1061, 268, 1182, 0.63671875], [140, 1061, 268, 1182, 0.638671875], [141, 1062, 269, 1183, 0.642578125], [141, 1063, 269, 1183, 0.64697265625]]\n",
      "Key: 4s, vector len: 13, Card Detections: [[536, 1085, 645, 1216, 0.646484375], [535, 1085, 646, 1210, 0.64794921875], [536, 1086, 646, 1211, 0.64453125], [536, 1086, 645, 1215, 0.6435546875], [535, 1087, 646, 1215, 0.64208984375], [536, 1087, 645, 1216, 0.642578125], [535, 1087, 646, 1216, 0.64453125], [535, 1087, 646, 1216, 0.646484375], [535, 1087, 646, 1216, 0.64501953125], [535, 1088, 645, 1217, 0.64501953125], [535, 1088, 645, 1217, 0.64599609375], [534, 1088, 644, 1217, 0.650390625], [533, 1090, 643, 1218, 0.64306640625]]\n",
      "Key: 5c, vector len: 10, Card Detections: [[530, 1084, 583, 1206, 0.69091796875], [530, 1084, 583, 1207, 0.68701171875], [531, 1084, 583, 1206, 0.6796875], [530, 1085, 583, 1206, 0.6796875], [530, 1085, 583, 1206, 0.67724609375], [530, 1085, 583, 1206, 0.67529296875], [529, 1085, 583, 1206, 0.66650390625], [529, 1085, 583, 1207, 0.68212890625], [528, 1086, 583, 1207, 0.68310546875], [526, 1089, 582, 1209, 0.67333984375]]\n",
      "Key: 5d, vector len: 16, Card Detections: [[532, 1084, 583, 1204, 0.591796875], [533, 1083, 583, 1203, 0.6328125], [532, 1086, 583, 1205, 0.60107421875], [532, 1084, 583, 1204, 0.6162109375], [532, 1086, 583, 1204, 0.619140625], [532, 1087, 583, 1204, 0.6259765625], [532, 1084, 582, 1204, 0.60888671875], [532, 1087, 582, 1204, 0.6328125], [532, 1086, 582, 1204, 0.6318359375], [532, 1086, 582, 1204, 0.63623046875], [531, 1087, 582, 1204, 0.64111328125], [531, 1086, 582, 1205, 0.6484375], [531, 1087, 581, 1207, 0.63818359375], [530, 1086, 580, 1207, 0.6416015625], [530, 1088, 579, 1206, 0.63525390625], [529, 1088, 579, 1206, 0.63330078125]]\n",
      "Key: 5h, vector len: 14, Card Detections: [[529, 1083, 579, 1202, 0.650390625], [529, 1084, 579, 1201, 0.6552734375], [529, 1083, 579, 1201, 0.65380859375], [529, 1084, 578, 1203, 0.6435546875], [529, 1083, 579, 1200, 0.63818359375], [529, 1083, 579, 1203, 0.6630859375], [529, 1083, 578, 1202, 0.640625], [529, 1084, 578, 1203, 0.6435546875], [529, 1083, 578, 1202, 0.64501953125], [529, 1084, 578, 1203, 0.63720703125], [529, 1085, 577, 1203, 0.63818359375], [529, 1084, 577, 1203, 0.638671875], [528, 1085, 577, 1204, 0.63818359375], [526, 1085, 577, 1206, 0.63134765625]]\n",
      "Key: 5s, vector len: 19, Card Detections: [[533, 1084, 585, 1206, 0.65234375], [533, 1084, 585, 1206, 0.6611328125], [532, 1084, 586, 1206, 0.65673828125], [533, 1084, 585, 1207, 0.64794921875], [533, 1084, 585, 1205, 0.65087890625], [532, 1086, 585, 1208, 0.64990234375], [532, 1084, 584, 1206, 0.65283203125], [532, 1086, 585, 1207, 0.65478515625], [532, 1085, 585, 1206, 0.65869140625], [532, 1085, 585, 1206, 0.65625], [531, 1086, 584, 1207, 0.654296875], [531, 1086, 585, 1207, 0.66455078125], [531, 1087, 584, 1209, 0.66552734375], [532, 1086, 583, 1208, 0.6630859375], [531, 1087, 583, 1208, 0.65673828125], [530, 1087, 583, 1208, 0.66064453125], [531, 1087, 583, 1207, 0.66064453125], [529, 1087, 583, 1210, 0.654296875], [528, 1089, 581, 1211, 0.6484375]]\n",
      "Key: 6c, vector len: 12, Card Detections: [[139, 1057, 199, 1191, 0.6171875], [140, 1060, 196, 1186, 0.69970703125], [140, 1059, 196, 1184, 0.69384765625], [140, 1060, 196, 1186, 0.703125], [140, 1060, 196, 1186, 0.705078125], [141, 1060, 197, 1186, 0.70166015625], [141, 1061, 197, 1188, 0.70166015625], [141, 1060, 198, 1186, 0.705078125], [141, 1062, 198, 1189, 0.703125], [141, 1062, 198, 1188, 0.701171875], [142, 1062, 198, 1189, 0.69970703125], [143, 1061, 200, 1190, 0.69287109375]]\n",
      "Key: 6d, vector len: 49, Card Detections: [[521, 1103, 575, 1217, 0.65478515625], [522, 1103, 575, 1207, 0.6259765625], [521, 1104, 575, 1212, 0.60986328125], [521, 1104, 575, 1210, 0.61669921875], [520, 1104, 576, 1212, 0.60986328125], [520, 1104, 576, 1211, 0.61376953125], [521, 1104, 576, 1211, 0.61328125], [521, 1104, 576, 1212, 0.615234375], [521, 1103, 576, 1211, 0.61572265625], [521, 1103, 576, 1212, 0.6142578125], [521, 1102, 576, 1212, 0.61767578125], [521, 1102, 576, 1212, 0.61474609375], [521, 1102, 576, 1212, 0.615234375], [521, 1103, 576, 1212, 0.61474609375], [521, 1103, 576, 1212, 0.61669921875], [522, 1103, 576, 1213, 0.62548828125], [522, 1105, 576, 1216, 0.63916015625], [522, 1106, 576, 1215, 0.6279296875], [522, 1105, 576, 1215, 0.625], [521, 1106, 576, 1215, 0.6298828125], [521, 1106, 576, 1215, 0.6328125], [521, 1106, 576, 1215, 0.634765625], [521, 1107, 576, 1216, 0.634765625], [521, 1107, 576, 1216, 0.6357421875], [521, 1108, 575, 1216, 0.65185546875], [521, 1108, 575, 1216, 0.6513671875], [521, 1107, 576, 1216, 0.65673828125], [521, 1108, 575, 1216, 0.65771484375], [521, 1107, 575, 1216, 0.65380859375], [521, 1107, 575, 1216, 0.65478515625], [521, 1107, 575, 1216, 0.66162109375], [521, 1107, 575, 1217, 0.66455078125], [521, 1107, 575, 1217, 0.666015625], [521, 1107, 575, 1217, 0.66650390625], [521, 1107, 575, 1217, 0.66845703125], [521, 1107, 575, 1217, 0.6708984375], [521, 1107, 575, 1217, 0.6728515625], [521, 1108, 575, 1218, 0.6728515625], [520, 1108, 575, 1218, 0.67431640625], [520, 1108, 574, 1218, 0.671875], [520, 1108, 574, 1218, 0.6689453125], [520, 1108, 574, 1218, 0.6689453125], [520, 1108, 574, 1218, 0.6650390625], [520, 1108, 574, 1218, 0.6640625], [520, 1109, 574, 1218, 0.662109375], [520, 1109, 574, 1218, 0.6630859375], [519, 1110, 574, 1219, 0.6669921875], [519, 1111, 574, 1219, 0.66259765625], [517, 1112, 573, 1218, 0.6552734375]]\n",
      "Key: 6h, vector len: 9, Card Detections: [[151, 1102, 205, 1220, 0.66015625], [151, 1101, 206, 1219, 0.65576171875], [151, 1100, 205, 1219, 0.65673828125], [151, 1101, 205, 1219, 0.65478515625], [151, 1100, 205, 1218, 0.64306640625], [151, 1100, 205, 1218, 0.64794921875], [151, 1100, 205, 1218, 0.64794921875], [151, 1100, 205, 1218, 0.64697265625], [152, 1102, 205, 1219, 0.64111328125]]\n",
      "Key: 6s, vector len: 7, Card Detections: [[150, 1093, 207, 1226, 0.6337890625], [151, 1093, 206, 1219, 0.63818359375], [151, 1092, 206, 1217, 0.6435546875], [152, 1093, 206, 1218, 0.64111328125], [152, 1094, 206, 1218, 0.64013671875], [152, 1094, 206, 1218, 0.6455078125], [152, 1094, 206, 1217, 0.64599609375]]\n",
      "Key: 7c, vector len: 11, Card Detections: [[520, 1086, 574, 1209, 0.64111328125], [519, 1086, 575, 1209, 0.64111328125], [519, 1086, 575, 1208, 0.64306640625], [519, 1086, 575, 1208, 0.64111328125], [519, 1086, 575, 1208, 0.63330078125], [521, 1087, 574, 1209, 0.63525390625], [521, 1087, 574, 1209, 0.634765625], [521, 1087, 574, 1208, 0.63525390625], [521, 1088, 574, 1208, 0.6337890625], [519, 1087, 574, 1208, 0.638671875], [518, 1089, 574, 1211, 0.642578125]]\n",
      "Key: 7d, vector len: 65, Card Detections: [[135, 1079, 191, 1193, 0.62646484375], [135, 1080, 190, 1194, 0.6103515625], [135, 1081, 191, 1194, 0.61865234375], [135, 1081, 191, 1195, 0.61865234375], [134, 1082, 191, 1197, 0.61181640625], [134, 1083, 190, 1198, 0.61572265625], [135, 1083, 190, 1197, 0.61767578125], [135, 1084, 190, 1198, 0.61767578125], [135, 1084, 190, 1198, 0.62060546875], [135, 1086, 190, 1199, 0.6220703125], [135, 1086, 190, 1199, 0.6259765625], [135, 1086, 190, 1200, 0.62158203125], [135, 1087, 190, 1200, 0.6201171875], [135, 1088, 190, 1200, 0.6220703125], [135, 1089, 190, 1201, 0.62109375], [135, 1089, 190, 1201, 0.62158203125], [135, 1089, 190, 1202, 0.6220703125], [135, 1090, 190, 1203, 0.6220703125], [135, 1089, 190, 1204, 0.62646484375], [135, 1089, 190, 1204, 0.6240234375], [135, 1088, 189, 1204, 0.62353515625], [135, 1087, 190, 1204, 0.6259765625], [134, 1087, 190, 1204, 0.6259765625], [134, 1087, 190, 1204, 0.62939453125], [134, 1087, 190, 1204, 0.62890625], [134, 1087, 189, 1204, 0.63037109375], [134, 1086, 189, 1204, 0.6298828125], [134, 1086, 190, 1204, 0.630859375], [134, 1086, 190, 1204, 0.62841796875], [134, 1086, 190, 1204, 0.62841796875], [134, 1086, 190, 1204, 0.6279296875], [134, 1086, 190, 1204, 0.62841796875], [134, 1086, 190, 1204, 0.62646484375], [134, 1086, 190, 1204, 0.626953125], [134, 1086, 190, 1204, 0.62646484375], [134, 1085, 191, 1203, 0.6279296875], [134, 1085, 190, 1203, 0.626953125], [135, 1086, 191, 1203, 0.625], [135, 1086, 191, 1203, 0.62646484375], [135, 1086, 191, 1203, 0.62841796875], [135, 1088, 192, 1203, 0.62646484375], [135, 1088, 192, 1203, 0.62451171875], [136, 1088, 192, 1203, 0.6279296875], [136, 1088, 192, 1203, 0.6298828125], [136, 1088, 192, 1203, 0.62939453125], [136, 1088, 193, 1203, 0.63037109375], [136, 1088, 193, 1202, 0.63037109375], [136, 1088, 193, 1202, 0.63232421875], [136, 1088, 193, 1202, 0.63232421875], [136, 1088, 193, 1202, 0.63330078125], [136, 1088, 193, 1203, 0.63232421875], [136, 1087, 193, 1201, 0.63525390625], [136, 1088, 193, 1201, 0.6328125], [136, 1088, 193, 1201, 0.6337890625], [136, 1089, 192, 1202, 0.634765625], [136, 1090, 192, 1203, 0.63623046875], [136, 1090, 193, 1204, 0.63671875], [136, 1092, 193, 1204, 0.6416015625], [136, 1092, 193, 1204, 0.64013671875], [136, 1093, 194, 1205, 0.64208984375], [136, 1093, 194, 1205, 0.646484375], [136, 1095, 194, 1206, 0.64892578125], [136, 1096, 194, 1206, 0.6513671875], [137, 1097, 195, 1206, 0.65625], [138, 1098, 196, 1205, 0.662109375]]\n",
      "Key: 7h, vector len: 15, Card Detections: [[511, 1100, 565, 1216, 0.64501953125], [512, 1100, 564, 1215, 0.65234375], [512, 1101, 564, 1216, 0.65380859375], [512, 1100, 564, 1215, 0.65087890625], [512, 1100, 564, 1215, 0.64208984375], [512, 1100, 564, 1215, 0.64501953125], [512, 1100, 564, 1215, 0.64697265625], [512, 1100, 564, 1215, 0.6494140625], [512, 1100, 564, 1215, 0.6474609375], [512, 1100, 564, 1215, 0.64501953125], [512, 1100, 564, 1215, 0.64404296875], [511, 1100, 565, 1215, 0.64013671875], [511, 1101, 565, 1216, 0.63330078125], [511, 1101, 565, 1217, 0.63330078125], [509, 1102, 563, 1217, 0.6484375]]\n",
      "Key: 7s, vector len: 11, Card Detections: [[146, 1086, 202, 1211, 0.6611328125], [147, 1086, 201, 1210, 0.66455078125], [147, 1085, 201, 1209, 0.66552734375], [147, 1086, 201, 1210, 0.6630859375], [147, 1086, 201, 1210, 0.6650390625], [147, 1085, 201, 1209, 0.666015625], [147, 1085, 201, 1210, 0.66357421875], [147, 1084, 201, 1210, 0.66552734375], [147, 1085, 201, 1209, 0.666015625], [147, 1086, 201, 1210, 0.6611328125], [147, 1087, 202, 1212, 0.6572265625]]\n",
      "Key: 8c, vector len: 6, Card Detections: [[145, 1074, 203, 1200, 0.63232421875], [147, 1074, 202, 1199, 0.63671875], [147, 1075, 202, 1198, 0.6396484375], [147, 1075, 201, 1200, 0.64404296875], [147, 1075, 202, 1200, 0.6376953125], [147, 1075, 203, 1203, 0.61669921875]]\n",
      "Key: 8d, vector len: 10, Card Detections: [[144, 1051, 198, 1174, 0.72119140625], [145, 1051, 198, 1174, 0.71337890625], [146, 1051, 198, 1174, 0.7138671875], [145, 1051, 199, 1174, 0.71728515625], [146, 1051, 199, 1174, 0.71435546875], [146, 1052, 199, 1175, 0.72021484375], [146, 1053, 200, 1176, 0.720703125], [146, 1053, 200, 1176, 0.7158203125], [146, 1054, 200, 1177, 0.71923828125], [147, 1056, 200, 1178, 0.70947265625]]\n",
      "Key: 8h, vector len: 11, Card Detections: [[529, 1090, 580, 1204, 0.68115234375], [530, 1089, 579, 1204, 0.66259765625], [530, 1088, 579, 1203, 0.666015625], [530, 1090, 579, 1204, 0.6689453125], [530, 1088, 579, 1203, 0.6689453125], [530, 1089, 579, 1203, 0.65771484375], [529, 1089, 579, 1205, 0.6640625], [529, 1090, 579, 1204, 0.66259765625], [529, 1091, 579, 1205, 0.671875], [528, 1090, 578, 1204, 0.68896484375], [528, 1093, 577, 1206, 0.693359375]]\n",
      "Key: 8s, vector len: 7, Card Detections: [[141, 1056, 198, 1183, 0.6474609375], [142, 1057, 197, 1183, 0.654296875], [143, 1056, 197, 1182, 0.65185546875], [142, 1058, 197, 1183, 0.65966796875], [143, 1057, 197, 1183, 0.654296875], [142, 1059, 197, 1183, 0.666015625], [143, 1060, 198, 1184, 0.6640625]]\n",
      "Key: 9c, vector len: 12, Card Detections: [[153, 1111, 209, 1232, 0.63916015625], [153, 1112, 209, 1230, 0.630859375], [153, 1111, 208, 1230, 0.62744140625], [153, 1110, 209, 1230, 0.6337890625], [152, 1111, 208, 1230, 0.6455078125], [152, 1111, 207, 1229, 0.64453125], [152, 1111, 207, 1229, 0.64794921875], [152, 1111, 207, 1229, 0.64453125], [152, 1110, 207, 1229, 0.64111328125], [153, 1110, 207, 1229, 0.6474609375], [153, 1111, 207, 1228, 0.64990234375], [153, 1111, 208, 1228, 0.650390625]]\n",
      "Key: 9d, vector len: 9, Card Detections: [[515, 1101, 565, 1212, 0.6669921875], [515, 1101, 565, 1211, 0.6728515625], [515, 1101, 565, 1212, 0.6728515625], [515, 1102, 565, 1212, 0.6728515625], [515, 1101, 565, 1212, 0.6708984375], [515, 1102, 565, 1212, 0.66845703125], [515, 1102, 565, 1212, 0.6689453125], [515, 1102, 564, 1212, 0.669921875], [514, 1102, 565, 1213, 0.66650390625]]\n",
      "Key: 9h, vector len: 10, Card Detections: [[143, 1053, 198, 1183, 0.62939453125], [144, 1056, 197, 1177, 0.6455078125], [144, 1054, 197, 1176, 0.64794921875], [145, 1057, 198, 1177, 0.63720703125], [145, 1057, 199, 1178, 0.6337890625], [146, 1057, 199, 1177, 0.6328125], [146, 1059, 199, 1180, 0.619140625], [146, 1059, 200, 1178, 0.62744140625], [146, 1059, 200, 1179, 0.62548828125], [147, 1060, 201, 1180, 0.64013671875]]\n",
      "Key: 9s, vector len: 5, Card Detections: [[143, 1066, 202, 1203, 0.63623046875], [144, 1068, 197, 1193, 0.677734375], [145, 1068, 197, 1193, 0.67431640625], [145, 1068, 198, 1193, 0.68017578125], [145, 1070, 199, 1197, 0.66845703125]]\n",
      "Key: Ac, vector len: 7, Card Detections: [[143, 1073, 202, 1199, 0.63671875], [144, 1072, 202, 1200, 0.63623046875], [143, 1072, 202, 1199, 0.62939453125], [144, 1073, 201, 1200, 0.64111328125], [144, 1072, 202, 1198, 0.640625], [144, 1072, 202, 1199, 0.6396484375], [145, 1074, 201, 1200, 0.642578125]]\n",
      "Key: Ad, vector len: 51, Card Detections: [[507, 1170, 567, 1240, 0.64892578125], [508, 1152, 566, 1233, 0.6513671875], [510, 1147, 566, 1233, 0.66943359375], [514, 1139, 568, 1233, 0.6728515625], [514, 1129, 568, 1229, 0.677734375], [517, 1117, 571, 1224, 0.673828125], [519, 1106, 572, 1215, 0.640625], [520, 1098, 573, 1211, 0.6533203125], [522, 1098, 573, 1210, 0.63037109375], [523, 1098, 573, 1210, 0.62841796875], [522, 1095, 572, 1210, 0.63330078125], [522, 1095, 572, 1210, 0.63427734375], [522, 1095, 572, 1209, 0.63232421875], [521, 1095, 572, 1210, 0.63232421875], [521, 1095, 571, 1209, 0.62890625], [521, 1094, 572, 1209, 0.6337890625], [521, 1094, 572, 1209, 0.634765625], [522, 1094, 571, 1208, 0.6328125], [522, 1094, 571, 1207, 0.63232421875], [522, 1094, 571, 1207, 0.63330078125], [522, 1094, 571, 1207, 0.6328125], [522, 1094, 571, 1207, 0.6337890625], [522, 1094, 571, 1207, 0.634765625], [522, 1094, 571, 1208, 0.63525390625], [522, 1094, 571, 1208, 0.634765625], [522, 1094, 571, 1207, 0.634765625], [522, 1094, 571, 1208, 0.63525390625], [522, 1094, 571, 1208, 0.63525390625], [522, 1094, 571, 1208, 0.6357421875], [522, 1094, 571, 1208, 0.6357421875], [522, 1095, 571, 1208, 0.634765625], [522, 1095, 571, 1208, 0.63525390625], [521, 1095, 571, 1209, 0.63818359375], [521, 1095, 571, 1209, 0.6337890625], [521, 1095, 571, 1210, 0.62841796875], [520, 1095, 571, 1211, 0.6279296875], [520, 1095, 571, 1211, 0.62841796875], [520, 1096, 571, 1212, 0.62744140625], [520, 1096, 570, 1212, 0.62744140625], [520, 1097, 570, 1212, 0.62939453125], [519, 1098, 569, 1213, 0.634765625], [519, 1099, 569, 1213, 0.63818359375], [518, 1099, 568, 1213, 0.6435546875], [517, 1100, 568, 1213, 0.64306640625], [517, 1101, 568, 1214, 0.64013671875], [517, 1101, 568, 1215, 0.64111328125], [516, 1101, 567, 1215, 0.642578125], [516, 1102, 567, 1216, 0.64306640625], [517, 1104, 567, 1216, 0.63916015625], [516, 1104, 567, 1216, 0.64111328125], [515, 1104, 566, 1217, 0.6455078125]]\n",
      "Key: Ah, vector len: 7, Card Detections: [[151, 1083, 204, 1205, 0.6279296875], [153, 1082, 203, 1205, 0.62548828125], [151, 1082, 205, 1204, 0.6318359375], [151, 1082, 204, 1204, 0.62890625], [153, 1081, 203, 1204, 0.63134765625], [152, 1082, 204, 1203, 0.6298828125], [152, 1084, 204, 1204, 0.626953125]]\n",
      "Key: As, vector len: 5, Card Detections: [[141, 1051, 201, 1177, 0.68017578125], [142, 1050, 201, 1178, 0.6787109375], [142, 1051, 201, 1177, 0.68359375], [143, 1052, 201, 1177, 0.677734375], [144, 1051, 202, 1179, 0.6865234375]]\n",
      "Key: Jc, vector len: 5, Card Detections: [[143, 1078, 203, 1207, 0.64013671875], [145, 1078, 200, 1204, 0.67236328125], [147, 1077, 200, 1202, 0.67236328125], [148, 1078, 201, 1202, 0.6787109375], [147, 1080, 203, 1203, 0.66748046875]]\n",
      "Key: Jd, vector len: 4, Card Detections: [[139, 1065, 192, 1189, 0.64404296875], [141, 1063, 193, 1187, 0.63720703125], [141, 1064, 192, 1188, 0.634765625], [140, 1063, 193, 1193, 0.60888671875]]\n",
      "Key: Jh, vector len: 8, Card Detections: [[138, 1057, 191, 1183, 0.60986328125], [140, 1057, 191, 1180, 0.60986328125], [139, 1057, 191, 1180, 0.61279296875], [139, 1057, 191, 1180, 0.60400390625], [140, 1057, 192, 1180, 0.59814453125], [141, 1057, 192, 1180, 0.6015625], [141, 1056, 192, 1179, 0.58935546875], [141, 1059, 195, 1181, 0.6162109375]]\n",
      "Key: Js, vector len: 21, Card Detections: [[138, 1060, 197, 1189, 0.6171875], [140, 1060, 195, 1187, 0.66650390625], [140, 1060, 195, 1186, 0.6669921875], [139, 1062, 195, 1188, 0.66455078125], [140, 1061, 195, 1187, 0.66796875], [140, 1062, 195, 1187, 0.66748046875], [139, 1064, 195, 1188, 0.6611328125], [140, 1064, 196, 1188, 0.662109375], [140, 1064, 195, 1189, 0.6630859375], [140, 1064, 195, 1188, 0.66552734375], [140, 1064, 195, 1188, 0.66357421875], [141, 1064, 195, 1188, 0.6650390625], [141, 1063, 195, 1188, 0.66650390625], [141, 1065, 195, 1188, 0.66796875], [141, 1063, 196, 1188, 0.6669921875], [141, 1064, 197, 1188, 0.66748046875], [142, 1063, 196, 1188, 0.66845703125], [142, 1064, 196, 1188, 0.6689453125], [142, 1064, 197, 1187, 0.6689453125], [143, 1065, 197, 1187, 0.66796875], [143, 1066, 198, 1189, 0.65283203125]]\n",
      "Key: Kc, vector len: 15, Card Detections: [[152, 1105, 209, 1231, 0.6572265625], [140, 1051, 201, 1178, 0.66943359375], [141, 1054, 197, 1177, 0.63818359375], [140, 1054, 197, 1177, 0.6376953125], [142, 1055, 196, 1177, 0.63671875], [141, 1055, 197, 1177, 0.64111328125], [142, 1055, 197, 1177, 0.64306640625], [142, 1056, 197, 1177, 0.64306640625], [142, 1056, 197, 1178, 0.6416015625], [142, 1057, 198, 1179, 0.64013671875], [143, 1059, 199, 1180, 0.64501953125], [142, 1061, 200, 1181, 0.65087890625], [142, 1062, 200, 1181, 0.64794921875], [144, 1064, 200, 1182, 0.65966796875], [144, 1068, 201, 1184, 0.65087890625]]\n",
      "Key: Kd, vector len: 8, Card Detections: [[139, 1060, 195, 1183, 0.66357421875], [141, 1060, 194, 1185, 0.6572265625], [140, 1059, 194, 1184, 0.65673828125], [141, 1060, 194, 1185, 0.65185546875], [141, 1060, 194, 1183, 0.6416015625], [141, 1060, 194, 1184, 0.65087890625], [141, 1060, 194, 1185, 0.6494140625], [142, 1062, 195, 1186, 0.6474609375]]\n",
      "Key: Kh, vector len: 8, Card Detections: [[153, 1105, 205, 1223, 0.60693359375], [153, 1106, 206, 1223, 0.59814453125], [153, 1105, 206, 1224, 0.603515625], [153, 1105, 206, 1224, 0.6181640625], [153, 1105, 206, 1224, 0.615234375], [153, 1105, 206, 1223, 0.60400390625], [153, 1105, 206, 1223, 0.60546875], [154, 1106, 205, 1224, 0.61083984375]]\n",
      "Key: Ks, vector len: 54, Card Detections: [[158, 1125, 213, 1238, 0.65673828125], [157, 1123, 211, 1237, 0.66552734375], [158, 1120, 213, 1235, 0.6630859375], [157, 1120, 211, 1235, 0.67041015625], [157, 1120, 212, 1235, 0.66650390625], [157, 1119, 211, 1235, 0.66845703125], [157, 1118, 212, 1234, 0.6630859375], [157, 1117, 212, 1233, 0.6689453125], [157, 1117, 212, 1233, 0.6708984375], [159, 1116, 213, 1232, 0.66796875], [160, 1115, 214, 1232, 0.6572265625], [160, 1116, 214, 1232, 0.65673828125], [160, 1116, 213, 1232, 0.65673828125], [160, 1116, 213, 1232, 0.65625], [160, 1115, 213, 1231, 0.66015625], [159, 1115, 213, 1231, 0.65966796875], [159, 1114, 213, 1231, 0.6572265625], [159, 1114, 213, 1231, 0.66064453125], [159, 1114, 213, 1231, 0.66064453125], [159, 1114, 213, 1231, 0.662109375], [159, 1114, 213, 1231, 0.66162109375], [159, 1114, 213, 1231, 0.66259765625], [160, 1114, 213, 1231, 0.6611328125], [160, 1114, 213, 1231, 0.66455078125], [160, 1114, 214, 1231, 0.66455078125], [160, 1114, 214, 1231, 0.66357421875], [160, 1114, 214, 1231, 0.66357421875], [160, 1114, 214, 1231, 0.66943359375], [160, 1114, 214, 1231, 0.6689453125], [160, 1114, 214, 1231, 0.6669921875], [161, 1114, 213, 1231, 0.6640625], [160, 1114, 213, 1231, 0.66650390625], [160, 1114, 213, 1231, 0.66650390625], [160, 1113, 213, 1230, 0.66357421875], [160, 1113, 213, 1230, 0.66357421875], [160, 1113, 213, 1230, 0.6630859375], [160, 1113, 212, 1230, 0.66259765625], [160, 1113, 213, 1230, 0.666015625], [160, 1114, 213, 1231, 0.66748046875], [159, 1113, 213, 1230, 0.66845703125], [159, 1113, 213, 1231, 0.66796875], [159, 1113, 213, 1231, 0.66845703125], [159, 1113, 212, 1231, 0.6689453125], [159, 1113, 213, 1229, 0.6650390625], [159, 1113, 213, 1229, 0.66796875], [160, 1113, 212, 1229, 0.65869140625], [160, 1113, 212, 1228, 0.66455078125], [159, 1113, 213, 1228, 0.6640625], [159, 1112, 213, 1228, 0.66455078125], [160, 1113, 213, 1228, 0.6650390625], [160, 1113, 212, 1228, 0.6591796875], [159, 1113, 213, 1228, 0.66455078125], [159, 1113, 213, 1228, 0.66455078125], [160, 1115, 213, 1230, 0.67529296875]]\n",
      "Key: Qc, vector len: 5, Card Detections: [[153, 1094, 205, 1215, 0.619140625], [155, 1095, 204, 1216, 0.60986328125], [155, 1095, 204, 1216, 0.607421875], [155, 1095, 204, 1216, 0.60986328125], [155, 1095, 205, 1216, 0.61083984375]]\n",
      "Key: Qd, vector len: 15, Card Detections: [[532, 1085, 580, 1201, 0.61669921875], [533, 1085, 581, 1201, 0.6396484375], [534, 1086, 580, 1202, 0.63818359375], [533, 1087, 579, 1201, 0.6376953125], [533, 1088, 579, 1201, 0.638671875], [533, 1087, 579, 1201, 0.6396484375], [533, 1088, 579, 1202, 0.642578125], [533, 1088, 579, 1202, 0.64599609375], [533, 1088, 579, 1202, 0.64404296875], [532, 1089, 579, 1203, 0.6455078125], [532, 1088, 579, 1202, 0.64892578125], [532, 1088, 579, 1202, 0.64990234375], [531, 1089, 578, 1204, 0.65234375], [531, 1089, 578, 1203, 0.65478515625], [530, 1087, 578, 1206, 0.6552734375]]\n",
      "Key: Qh, vector len: 3, Card Detections: [[143, 1068, 195, 1190, 0.6494140625], [144, 1070, 195, 1191, 0.642578125], [145, 1070, 195, 1190, 0.6376953125]]\n",
      "Key: Qs, vector len: 12, Card Detections: [[535, 1088, 585, 1206, 0.66552734375], [534, 1088, 584, 1207, 0.67431640625], [535, 1089, 585, 1206, 0.66796875], [535, 1088, 585, 1208, 0.6669921875], [535, 1088, 585, 1206, 0.66064453125], [535, 1089, 585, 1208, 0.66357421875], [535, 1089, 585, 1207, 0.6630859375], [535, 1090, 585, 1207, 0.666015625], [535, 1090, 585, 1207, 0.66845703125], [534, 1090, 584, 1208, 0.6650390625], [534, 1091, 584, 1209, 0.66455078125], [532, 1091, 583, 1208, 0.66552734375]]\n",
      "Key: SJoker, vector len: 12, Card Detections: [[532, 1089, 586, 1217, 0.59912109375], [528, 1090, 591, 1240, 0.65625], [530, 1092, 588, 1232, 0.6689453125], [529, 1093, 589, 1233, 0.66259765625], [529, 1092, 588, 1231, 0.6591796875], [529, 1092, 589, 1232, 0.65478515625], [529, 1092, 588, 1231, 0.666015625], [528, 1093, 588, 1231, 0.662109375], [528, 1093, 588, 1232, 0.65283203125], [528, 1095, 588, 1232, 0.65576171875], [528, 1096, 588, 1233, 0.67041015625], [525, 1086, 591, 1222, 0.63427734375]]\n",
      "Key: BJoker, vector len: 11, Card Detections: [[528, 1085, 584, 1211, 0.55126953125], [528, 1084, 593, 1243, 0.58203125], [528, 1084, 589, 1225, 0.58984375], [529, 1086, 589, 1227, 0.62353515625], [529, 1087, 592, 1239, 0.623046875], [529, 1087, 589, 1229, 0.62841796875], [528, 1088, 589, 1230, 0.63037109375], [528, 1087, 589, 1232, 0.63134765625], [527, 1088, 589, 1233, 0.64013671875], [526, 1087, 589, 1231, 0.63720703125], [526, 1089, 589, 1234, 0.638671875]]\n",
      "Key: Tc, vector len: 12, Card Detections: [[116, 826, 166, 942, 0.67041015625], [116, 826, 166, 944, 0.66650390625], [115, 826, 167, 943, 0.67138671875], [115, 826, 168, 943, 0.6708984375], [116, 827, 168, 944, 0.67041015625], [116, 828, 168, 945, 0.67578125], [116, 828, 168, 945, 0.67333984375], [116, 828, 168, 945, 0.67626953125], [116, 829, 168, 945, 0.6796875], [116, 829, 168, 946, 0.68359375], [116, 830, 168, 948, 0.6787109375], [117, 833, 170, 948, 0.6748046875]]\n",
      "Key: Td, vector len: 130, Card Detections: [[115, 989, 168, 1054, 0.6328125], [121, 965, 173, 1041, 0.650390625], [129, 947, 178, 1027, 0.646484375], [131, 944, 180, 1026, 0.650390625], [131, 940, 181, 1023, 0.6572265625], [132, 938, 181, 1022, 0.662109375], [132, 936, 181, 1021, 0.65185546875], [132, 935, 181, 1020, 0.64892578125], [132, 933, 181, 1019, 0.65087890625], [131, 931, 181, 1018, 0.6484375], [132, 929, 181, 1017, 0.6494140625], [132, 927, 182, 1015, 0.6572265625], [133, 925, 183, 1014, 0.658203125], [133, 924, 183, 1014, 0.65478515625], [134, 920, 184, 1012, 0.666015625], [135, 918, 186, 1011, 0.68310546875], [136, 916, 186, 1010, 0.67919921875], [137, 914, 188, 1009, 0.66650390625], [138, 913, 189, 1007, 0.66259765625], [139, 911, 190, 1006, 0.65771484375], [139, 909, 191, 1005, 0.64501953125], [139, 907, 191, 1004, 0.64208984375], [140, 905, 192, 1002, 0.64599609375], [140, 904, 192, 1001, 0.6513671875], [141, 902, 192, 1000, 0.65771484375], [141, 900, 193, 998, 0.65771484375], [141, 899, 192, 997, 0.66259765625], [141, 897, 192, 997, 0.66064453125], [141, 896, 192, 996, 0.6611328125], [140, 895, 192, 995, 0.6611328125], [140, 893, 192, 994, 0.662109375], [140, 893, 192, 994, 0.658203125], [139, 891, 191, 993, 0.66064453125], [138, 891, 189, 993, 0.666015625], [137, 891, 188, 993, 0.6689453125], [135, 892, 187, 993, 0.66943359375], [134, 891, 187, 993, 0.66943359375], [133, 892, 186, 994, 0.6669921875], [132, 892, 185, 994, 0.666015625], [132, 892, 185, 994, 0.666015625], [132, 891, 184, 994, 0.666015625], [131, 891, 184, 994, 0.6669921875], [131, 891, 184, 994, 0.6689453125], [131, 891, 184, 994, 0.669921875], [131, 891, 184, 994, 0.66943359375], [131, 891, 184, 993, 0.66748046875], [131, 890, 184, 993, 0.66748046875], [132, 889, 184, 993, 0.6669921875], [132, 888, 184, 993, 0.66796875], [132, 888, 185, 992, 0.6689453125], [133, 888, 185, 992, 0.66943359375], [133, 887, 185, 992, 0.671875], [133, 887, 185, 992, 0.67333984375], [133, 887, 185, 992, 0.67431640625], [133, 887, 185, 992, 0.67529296875], [133, 886, 186, 992, 0.67578125], [133, 886, 186, 992, 0.6767578125], [133, 886, 186, 992, 0.67626953125], [133, 886, 186, 992, 0.67724609375], [133, 886, 186, 992, 0.67529296875], [132, 886, 185, 992, 0.67333984375], [132, 886, 185, 991, 0.67333984375], [132, 886, 185, 992, 0.67236328125], [132, 886, 185, 992, 0.671875], [132, 886, 185, 992, 0.67236328125], [132, 887, 185, 991, 0.67236328125], [132, 887, 185, 991, 0.671875], [132, 886, 185, 991, 0.67236328125], [132, 886, 185, 991, 0.67138671875], [132, 886, 185, 991, 0.6728515625], [132, 886, 185, 991, 0.67333984375], [133, 886, 185, 991, 0.6728515625], [133, 886, 185, 991, 0.673828125], [132, 886, 185, 991, 0.6728515625], [132, 885, 185, 991, 0.6728515625], [132, 885, 185, 991, 0.671875], [133, 885, 185, 990, 0.6708984375], [132, 885, 185, 990, 0.67236328125], [132, 885, 185, 990, 0.6728515625], [132, 885, 185, 990, 0.67333984375], [132, 885, 185, 990, 0.67431640625], [132, 885, 184, 990, 0.6748046875], [132, 885, 184, 990, 0.673828125], [132, 885, 184, 990, 0.67333984375], [132, 885, 184, 990, 0.67236328125], [132, 885, 184, 990, 0.6728515625], [132, 885, 185, 991, 0.6728515625], [132, 885, 185, 991, 0.6728515625], [132, 886, 185, 991, 0.673828125], [132, 886, 185, 991, 0.67431640625], [132, 885, 185, 991, 0.67578125], [132, 885, 185, 992, 0.67578125], [132, 886, 185, 992, 0.6748046875], [132, 886, 185, 992, 0.67529296875], [132, 886, 185, 992, 0.6748046875], [132, 887, 185, 992, 0.671875], [132, 887, 185, 992, 0.67138671875], [132, 887, 185, 992, 0.67236328125], [132, 887, 185, 992, 0.67041015625], [132, 887, 185, 992, 0.67041015625], [132, 887, 184, 992, 0.66943359375], [132, 887, 184, 992, 0.66943359375], [132, 887, 184, 992, 0.66845703125], [132, 887, 184, 992, 0.669921875], [132, 887, 184, 992, 0.67041015625], [132, 887, 184, 992, 0.669921875], [132, 887, 184, 992, 0.669921875], [132, 887, 185, 992, 0.67236328125], [133, 887, 185, 992, 0.67138671875], [133, 887, 185, 992, 0.67138671875], [133, 887, 186, 992, 0.6748046875], [134, 887, 187, 992, 0.67626953125], [134, 887, 187, 992, 0.67724609375], [135, 887, 188, 991, 0.6787109375], [135, 887, 188, 991, 0.6767578125], [135, 886, 188, 991, 0.677734375], [135, 886, 188, 991, 0.67626953125], [136, 885, 188, 991, 0.677734375], [136, 885, 188, 991, 0.677734375], [136, 885, 188, 991, 0.67919921875], [136, 885, 188, 991, 0.68017578125], [136, 884, 188, 991, 0.6806640625], [136, 884, 188, 991, 0.68017578125], [136, 884, 188, 990, 0.67919921875], [135, 884, 188, 990, 0.677734375], [135, 884, 187, 989, 0.67626953125], [135, 883, 187, 989, 0.6767578125], [135, 884, 187, 989, 0.67724609375], [135, 884, 187, 989, 0.67724609375], [136, 886, 188, 990, 0.67578125]]\n",
      "Key: Th, vector len: 12, Card Detections: [[471, 874, 522, 983, 0.63330078125], [471, 875, 522, 984, 0.6328125], [471, 875, 522, 984, 0.6337890625], [472, 875, 521, 984, 0.63232421875], [471, 876, 521, 985, 0.64453125], [471, 877, 521, 985, 0.6474609375], [471, 876, 521, 985, 0.64697265625], [471, 877, 521, 985, 0.64599609375], [470, 877, 520, 985, 0.64599609375], [470, 877, 520, 985, 0.64599609375], [470, 877, 520, 985, 0.640625], [466, 884, 518, 988, 0.60986328125]]\n",
      "Key: Ts, vector len: 100, Card Detections: [[97, 838, 151, 952, 0.6484375], [98, 838, 150, 953, 0.62255859375], [98, 837, 149, 953, 0.61279296875], [98, 839, 149, 955, 0.61328125], [98, 839, 149, 955, 0.619140625], [98, 840, 149, 956, 0.64501953125], [97, 841, 149, 957, 0.61376953125], [98, 841, 149, 957, 0.61669921875], [98, 842, 149, 959, 0.623046875], [98, 843, 149, 959, 0.626953125], [97, 842, 149, 959, 0.6279296875], [98, 843, 149, 959, 0.63037109375], [98, 843, 149, 959, 0.625], [98, 843, 149, 959, 0.62255859375], [98, 843, 149, 959, 0.59521484375], [98, 844, 149, 959, 0.607421875], [98, 844, 149, 959, 0.60693359375], [97, 844, 149, 960, 0.609375], [98, 845, 149, 960, 0.6123046875], [98, 847, 149, 961, 0.61767578125], [98, 847, 149, 961, 0.61962890625], [98, 848, 149, 962, 0.6220703125], [97, 849, 149, 962, 0.62255859375], [97, 849, 149, 963, 0.623046875], [97, 849, 149, 964, 0.62646484375], [97, 850, 149, 964, 0.6279296875], [97, 850, 149, 964, 0.626953125], [97, 850, 149, 964, 0.62451171875], [97, 851, 149, 965, 0.625], [97, 852, 148, 966, 0.6240234375], [97, 852, 148, 966, 0.62548828125], [97, 852, 148, 966, 0.6240234375], [97, 852, 148, 966, 0.6259765625], [97, 852, 148, 967, 0.626953125], [96, 853, 148, 967, 0.6279296875], [96, 853, 148, 967, 0.6337890625], [96, 853, 148, 967, 0.6328125], [96, 852, 148, 967, 0.63427734375], [96, 852, 148, 966, 0.62744140625], [96, 852, 148, 966, 0.626953125], [96, 851, 148, 966, 0.619140625], [96, 851, 148, 965, 0.619140625], [96, 850, 148, 965, 0.6123046875], [96, 850, 148, 965, 0.6103515625], [96, 850, 148, 965, 0.61962890625], [96, 850, 148, 965, 0.61865234375], [96, 849, 148, 964, 0.6201171875], [96, 849, 148, 964, 0.62451171875], [96, 849, 148, 964, 0.6240234375], [96, 849, 148, 964, 0.62451171875], [96, 849, 148, 964, 0.6279296875], [96, 848, 148, 963, 0.6259765625], [96, 848, 148, 963, 0.6259765625], [96, 847, 148, 962, 0.62841796875], [95, 846, 148, 961, 0.61279296875], [95, 846, 148, 961, 0.609375], [94, 845, 147, 960, 0.6181640625], [95, 845, 147, 960, 0.61669921875], [95, 844, 148, 959, 0.6162109375], [94, 844, 147, 959, 0.61474609375], [95, 844, 147, 959, 0.6181640625], [95, 844, 148, 960, 0.6533203125], [95, 843, 148, 959, 0.6484375], [95, 843, 148, 959, 0.64501953125], [95, 842, 147, 958, 0.640625], [95, 842, 148, 958, 0.6376953125], [95, 841, 148, 958, 0.63671875], [95, 841, 148, 957, 0.63623046875], [95, 841, 148, 957, 0.63525390625], [96, 840, 148, 957, 0.63525390625], [96, 840, 148, 957, 0.63623046875], [96, 840, 148, 956, 0.63623046875], [96, 840, 148, 956, 0.63671875], [96, 840, 148, 956, 0.63671875], [95, 840, 148, 956, 0.6328125], [96, 840, 148, 956, 0.6328125], [96, 839, 148, 955, 0.6328125], [96, 839, 148, 955, 0.63330078125], [96, 839, 148, 955, 0.63330078125], [96, 839, 148, 955, 0.6318359375], [96, 839, 148, 955, 0.6328125], [96, 839, 148, 955, 0.6318359375], [96, 839, 148, 955, 0.62841796875], [96, 839, 148, 955, 0.62939453125], [96, 839, 149, 955, 0.630859375], [96, 839, 149, 955, 0.62890625], [97, 839, 149, 955, 0.6298828125], [97, 839, 149, 955, 0.62890625], [97, 840, 149, 955, 0.640625], [97, 840, 149, 955, 0.64892578125], [97, 840, 150, 955, 0.62451171875], [97, 840, 150, 955, 0.623046875], [97, 840, 150, 955, 0.62744140625], [97, 840, 150, 955, 0.62890625], [97, 841, 150, 955, 0.63232421875], [98, 841, 151, 955, 0.6337890625], [98, 841, 151, 955, 0.63330078125], [98, 841, 151, 955, 0.63525390625], [98, 841, 152, 954, 0.6357421875], [98, 841, 152, 954, 0.638671875]]\n",
      "Key: 2c, vector len: 5, Card Detections: [[471, 881, 524, 985, 0.68115234375], [469, 881, 524, 984, 0.65576171875], [469, 881, 524, 985, 0.6572265625], [468, 881, 523, 987, 0.6396484375], [466, 884, 522, 988, 0.55810546875]]\n",
      "Key: 2d, vector len: 6, Card Detections: [[116, 835, 172, 988, 0.5537109375], [120, 835, 171, 950, 0.6474609375], [119, 835, 171, 951, 0.64111328125], [119, 834, 171, 951, 0.640625], [120, 835, 171, 951, 0.640625], [120, 836, 172, 954, 0.63330078125]]\n",
      "Key: 2h, vector len: 7, Card Detections: [[474, 871, 525, 980, 0.60986328125], [475, 873, 525, 982, 0.60888671875], [475, 872, 526, 981, 0.609375], [474, 872, 525, 982, 0.62353515625], [474, 873, 524, 982, 0.62109375], [473, 873, 525, 983, 0.6240234375], [469, 880, 521, 986, 0.58203125]]\n",
      "Key: 2s, vector len: 4, Card Detections: [[126, 860, 181, 975, 0.66259765625], [126, 859, 181, 975, 0.66357421875], [126, 858, 181, 974, 0.666015625], [129, 861, 186, 979, 0.65966796875]]\n",
      "Key: 3c, vector len: 36, Card Detections: [[97, 833, 154, 951, 0.6279296875], [97, 833, 153, 952, 0.63330078125], [97, 836, 152, 955, 0.64306640625], [97, 836, 152, 955, 0.646484375], [97, 837, 152, 956, 0.64306640625], [96, 838, 153, 958, 0.65478515625], [96, 838, 152, 958, 0.658203125], [96, 839, 152, 959, 0.66162109375], [96, 840, 152, 959, 0.66357421875], [96, 840, 152, 959, 0.6630859375], [96, 840, 152, 959, 0.662109375], [96, 840, 152, 958, 0.65869140625], [96, 839, 152, 959, 0.66064453125], [96, 839, 152, 959, 0.662109375], [96, 839, 152, 958, 0.65966796875], [96, 839, 152, 958, 0.65478515625], [96, 838, 152, 958, 0.65478515625], [96, 838, 152, 958, 0.65576171875], [96, 838, 152, 958, 0.6572265625], [96, 838, 152, 958, 0.65673828125], [96, 838, 152, 958, 0.6572265625], [96, 838, 152, 957, 0.65478515625], [96, 838, 153, 957, 0.6552734375], [96, 838, 152, 958, 0.658203125], [96, 838, 152, 958, 0.65869140625], [96, 839, 153, 958, 0.6572265625], [96, 839, 153, 957, 0.65869140625], [97, 839, 153, 957, 0.66796875], [97, 838, 153, 957, 0.6640625], [97, 838, 153, 957, 0.66357421875], [97, 837, 153, 956, 0.65478515625], [97, 838, 154, 956, 0.6552734375], [97, 838, 154, 956, 0.65673828125], [97, 840, 154, 957, 0.6650390625], [97, 841, 154, 957, 0.65966796875], [98, 843, 154, 958, 0.662109375]]\n",
      "Key: 3d, vector len: 8, Card Detections: [[123, 850, 175, 965, 0.65234375], [122, 849, 175, 964, 0.65625], [123, 849, 175, 966, 0.65087890625], [122, 849, 175, 965, 0.65625], [123, 849, 175, 966, 0.654296875], [122, 850, 175, 967, 0.66064453125], [122, 850, 175, 968, 0.6533203125], [123, 853, 176, 968, 0.65673828125]]\n",
      "Key: 3h, vector len: 13, Card Detections: [[470, 873, 526, 973, 0.62255859375], [472, 874, 525, 985, 0.6162109375], [472, 875, 525, 985, 0.611328125], [472, 874, 524, 985, 0.609375], [472, 875, 524, 986, 0.6083984375], [471, 875, 524, 987, 0.62060546875], [472, 875, 524, 987, 0.6142578125], [471, 875, 524, 986, 0.626953125], [472, 876, 523, 987, 0.61474609375], [472, 876, 523, 987, 0.6123046875], [471, 877, 523, 988, 0.6162109375], [471, 878, 523, 988, 0.6044921875], [470, 878, 521, 988, 0.62939453125]]\n",
      "Key: 3s, vector len: 15, Card Detections: [[472, 883, 525, 994, 0.63037109375], [472, 883, 525, 995, 0.638671875], [471, 884, 524, 993, 0.63330078125], [472, 884, 524, 995, 0.63671875], [471, 884, 524, 995, 0.64013671875], [471, 884, 524, 995, 0.638671875], [471, 884, 524, 996, 0.63916015625], [471, 884, 524, 995, 0.64111328125], [471, 884, 524, 996, 0.64208984375], [470, 885, 523, 996, 0.64501953125], [470, 885, 523, 996, 0.6455078125], [469, 885, 523, 996, 0.646484375], [469, 886, 523, 996, 0.63720703125], [469, 886, 523, 996, 0.6337890625], [468, 888, 522, 998, 0.6337890625]]\n",
      "Key: 4c, vector len: 7, Card Detections: [[470, 874, 583, 996, 0.603515625], [470, 875, 583, 996, 0.5771484375], [469, 875, 583, 996, 0.61474609375], [469, 875, 583, 995, 0.6005859375], [470, 877, 583, 997, 0.59033203125], [468, 877, 583, 997, 0.63232421875], [466, 881, 584, 999, 0.603515625]]\n",
      "Key: 4d, vector len: 9, Card Detections: [[116, 834, 231, 968, 0.6123046875], [117, 833, 226, 953, 0.61279296875], [117, 833, 226, 953, 0.61376953125], [117, 832, 226, 953, 0.61376953125], [117, 832, 226, 953, 0.61376953125], [117, 833, 226, 953, 0.6142578125], [117, 832, 227, 953, 0.60693359375], [117, 832, 227, 953, 0.6064453125], [118, 833, 228, 954, 0.59912109375]]\n",
      "Key: 4h, vector len: 128, Card Detections: [[467, 927, 574, 1017, 0.6201171875], [468, 917, 573, 1011, 0.63623046875], [468, 916, 572, 1010, 0.63330078125], [468, 914, 573, 1008, 0.63720703125], [468, 912, 573, 1007, 0.63427734375], [469, 910, 572, 1006, 0.63671875], [469, 909, 572, 1005, 0.634765625], [469, 907, 572, 1004, 0.63037109375], [469, 906, 572, 1003, 0.63623046875], [470, 904, 573, 1003, 0.6337890625], [469, 902, 573, 1001, 0.63427734375], [470, 901, 574, 1000, 0.634765625], [470, 901, 574, 999, 0.63525390625], [470, 899, 574, 999, 0.6357421875], [470, 897, 574, 999, 0.6376953125], [470, 896, 575, 998, 0.63720703125], [471, 895, 575, 998, 0.63818359375], [471, 894, 576, 997, 0.63623046875], [472, 892, 576, 997, 0.6376953125], [472, 891, 576, 996, 0.63623046875], [473, 890, 576, 995, 0.6337890625], [473, 890, 577, 995, 0.63623046875], [474, 889, 577, 995, 0.6376953125], [475, 888, 577, 994, 0.63623046875], [475, 888, 577, 993, 0.63623046875], [476, 887, 577, 993, 0.6328125], [477, 887, 578, 992, 0.63232421875], [477, 886, 579, 991, 0.63134765625], [477, 886, 579, 991, 0.6318359375], [478, 885, 579, 991, 0.63037109375], [478, 884, 580, 991, 0.630859375], [478, 884, 580, 990, 0.6298828125], [479, 884, 580, 990, 0.6279296875], [479, 884, 580, 990, 0.6279296875], [478, 883, 580, 989, 0.62939453125], [478, 883, 580, 989, 0.6279296875], [478, 883, 580, 989, 0.6279296875], [478, 883, 580, 989, 0.626953125], [479, 883, 580, 988, 0.6259765625], [479, 882, 581, 988, 0.62548828125], [479, 881, 581, 988, 0.6259765625], [479, 881, 581, 988, 0.62744140625], [479, 881, 581, 988, 0.62841796875], [480, 881, 581, 988, 0.63134765625], [480, 881, 581, 988, 0.6318359375], [480, 880, 582, 988, 0.63330078125], [480, 880, 582, 988, 0.6328125], [480, 880, 582, 988, 0.6328125], [480, 880, 582, 988, 0.63427734375], [480, 880, 582, 988, 0.6357421875], [481, 880, 583, 988, 0.634765625], [481, 880, 583, 988, 0.63525390625], [481, 880, 583, 988, 0.634765625], [481, 880, 583, 988, 0.63525390625], [481, 880, 583, 988, 0.63525390625], [481, 880, 583, 988, 0.634765625], [481, 880, 583, 988, 0.6337890625], [481, 881, 583, 988, 0.63427734375], [481, 881, 583, 988, 0.6337890625], [481, 881, 583, 988, 0.63330078125], [481, 881, 583, 988, 0.6337890625], [481, 881, 583, 988, 0.6337890625], [481, 881, 583, 988, 0.6337890625], [481, 881, 583, 988, 0.6337890625], [481, 879, 583, 988, 0.63720703125], [481, 879, 583, 988, 0.6376953125], [481, 879, 583, 988, 0.6376953125], [481, 879, 583, 988, 0.63916015625], [481, 879, 583, 988, 0.64111328125], [481, 879, 583, 988, 0.6416015625], [481, 879, 583, 987, 0.64208984375], [482, 879, 583, 987, 0.64306640625], [482, 879, 583, 988, 0.642578125], [482, 878, 584, 987, 0.642578125], [482, 878, 584, 987, 0.64306640625], [482, 879, 583, 987, 0.64111328125], [482, 879, 583, 987, 0.64111328125], [482, 879, 584, 987, 0.64208984375], [482, 878, 583, 987, 0.64306640625], [482, 878, 583, 987, 0.6435546875], [482, 878, 583, 987, 0.64501953125], [482, 878, 584, 987, 0.64453125], [482, 878, 584, 986, 0.64404296875], [482, 877, 584, 986, 0.64453125], [482, 877, 584, 987, 0.64599609375], [482, 877, 584, 987, 0.64599609375], [482, 877, 583, 986, 0.64599609375], [482, 877, 583, 986, 0.64599609375], [482, 877, 583, 986, 0.64599609375], [482, 877, 583, 986, 0.646484375], [482, 877, 583, 986, 0.646484375], [482, 877, 583, 986, 0.646484375], [482, 878, 584, 987, 0.6455078125], [482, 877, 584, 987, 0.6455078125], [482, 878, 583, 986, 0.6455078125], [481, 878, 583, 986, 0.64453125], [481, 878, 583, 986, 0.64599609375], [481, 878, 583, 987, 0.64404296875], [481, 878, 583, 987, 0.6435546875], [481, 878, 583, 987, 0.6435546875], [481, 877, 583, 986, 0.64453125], [481, 878, 583, 987, 0.64306640625], [481, 877, 583, 987, 0.6416015625], [481, 878, 582, 987, 0.64013671875], [481, 877, 582, 987, 0.6396484375], [480, 877, 582, 987, 0.638671875], [480, 877, 582, 987, 0.63818359375], [480, 877, 582, 987, 0.6376953125], [479, 877, 581, 987, 0.63818359375], [479, 877, 581, 987, 0.63671875], [479, 878, 580, 987, 0.63525390625], [478, 878, 579, 987, 0.63525390625], [478, 878, 579, 987, 0.6337890625], [478, 879, 578, 988, 0.63037109375], [477, 879, 578, 988, 0.630859375], [476, 879, 578, 986, 0.6328125], [476, 879, 576, 988, 0.63134765625], [476, 880, 577, 987, 0.630859375], [476, 880, 576, 987, 0.63134765625], [475, 880, 576, 988, 0.6318359375], [475, 880, 576, 988, 0.6318359375], [475, 880, 576, 988, 0.63330078125], [474, 881, 576, 988, 0.63427734375], [474, 881, 575, 988, 0.63525390625], [473, 882, 575, 989, 0.63525390625], [473, 883, 574, 989, 0.634765625], [472, 883, 574, 989, 0.63720703125], [470, 884, 573, 990, 0.64208984375]]\n",
      "Key: 4s, vector len: 14, Card Detections: [[475, 869, 576, 991, 0.609375], [475, 870, 576, 992, 0.60302734375], [475, 870, 576, 992, 0.6064453125], [476, 870, 576, 991, 0.60546875], [476, 870, 575, 991, 0.611328125], [475, 870, 575, 992, 0.60888671875], [476, 871, 575, 989, 0.6123046875], [476, 871, 575, 990, 0.61376953125], [476, 871, 575, 990, 0.611328125], [476, 871, 575, 990, 0.611328125], [475, 870, 575, 992, 0.607421875], [475, 871, 574, 990, 0.60986328125], [475, 871, 574, 990, 0.61865234375], [473, 873, 574, 991, 0.6171875]]\n",
      "Key: 5c, vector len: 13, Card Detections: [[99, 832, 153, 950, 0.6357421875], [98, 831, 152, 952, 0.60693359375], [98, 832, 151, 951, 0.60498046875], [98, 832, 152, 951, 0.6123046875], [98, 832, 152, 952, 0.61376953125], [99, 832, 152, 953, 0.61181640625], [99, 833, 152, 953, 0.61328125], [99, 833, 152, 953, 0.61474609375], [99, 833, 152, 953, 0.6123046875], [99, 833, 152, 953, 0.61474609375], [99, 833, 152, 952, 0.62548828125], [99, 833, 152, 952, 0.626953125], [100, 837, 154, 953, 0.64697265625]]\n",
      "Key: 5d, vector len: 7, Card Detections: [[135, 878, 185, 985, 0.61865234375], [137, 877, 186, 988, 0.61962890625], [137, 877, 186, 988, 0.625], [137, 876, 187, 988, 0.630859375], [137, 877, 187, 987, 0.62451171875], [137, 876, 187, 987, 0.62890625], [131, 871, 190, 1015, 0.65234375]]\n",
      "Key: 5h, vector len: 20, Card Detections: [[469, 874, 525, 973, 0.650390625], [471, 875, 521, 986, 0.65625], [471, 875, 521, 988, 0.6640625], [471, 875, 522, 988, 0.66552734375], [471, 876, 521, 988, 0.6650390625], [471, 876, 521, 988, 0.6640625], [471, 876, 521, 988, 0.6650390625], [471, 877, 521, 988, 0.6630859375], [471, 877, 521, 988, 0.66259765625], [471, 877, 521, 988, 0.6494140625], [471, 877, 521, 988, 0.646484375], [471, 877, 521, 988, 0.6533203125], [470, 879, 520, 989, 0.646484375], [470, 879, 520, 989, 0.64697265625], [469, 879, 520, 989, 0.65576171875], [469, 879, 520, 989, 0.658203125], [469, 880, 520, 989, 0.65869140625], [469, 879, 519, 989, 0.66064453125], [469, 880, 519, 990, 0.66064453125], [469, 880, 519, 990, 0.65869140625]]\n",
      "Key: 5s, vector len: 5, Card Detections: [[136, 873, 186, 989, 0.64404296875], [135, 872, 186, 989, 0.6513671875], [136, 872, 187, 988, 0.64306640625], [136, 871, 188, 989, 0.6572265625], [137, 874, 189, 990, 0.609375]]\n",
      "Key: 6c, vector len: 10, Card Detections: [[116, 830, 169, 950, 0.69287109375], [117, 829, 167, 946, 0.68603515625], [116, 831, 168, 949, 0.69287109375], [116, 831, 169, 949, 0.693359375], [117, 831, 169, 950, 0.68994140625], [117, 833, 169, 951, 0.68994140625], [117, 833, 168, 951, 0.6875], [117, 833, 169, 952, 0.693359375], [117, 833, 169, 952, 0.69580078125], [118, 835, 170, 953, 0.69287109375]]\n",
      "Key: 6d, vector len: 12, Card Detections: [[476, 874, 525, 982, 0.65087890625], [476, 873, 525, 982, 0.65234375], [477, 873, 525, 983, 0.6533203125], [477, 873, 525, 983, 0.650390625], [476, 874, 524, 983, 0.6396484375], [476, 875, 524, 983, 0.6396484375], [476, 875, 524, 983, 0.64404296875], [476, 875, 524, 983, 0.638671875], [475, 876, 524, 984, 0.640625], [475, 875, 523, 985, 0.64892578125], [474, 875, 522, 986, 0.64404296875], [472, 877, 522, 985, 0.67431640625]]\n",
      "Key: 6h, vector len: 16, Card Detections: [[470, 878, 521, 989, 0.677734375], [470, 878, 521, 988, 0.6796875], [470, 878, 521, 988, 0.677734375], [470, 879, 521, 989, 0.67626953125], [470, 879, 521, 989, 0.6728515625], [470, 879, 521, 989, 0.67333984375], [470, 879, 521, 989, 0.67236328125], [470, 879, 521, 989, 0.671875], [470, 879, 521, 989, 0.6708984375], [470, 879, 521, 989, 0.67041015625], [470, 879, 521, 989, 0.66748046875], [470, 879, 521, 989, 0.669921875], [470, 879, 520, 990, 0.66552734375], [470, 879, 521, 990, 0.66162109375], [469, 880, 520, 991, 0.65869140625], [469, 880, 520, 991, 0.65771484375]]\n",
      "Key: 6s, vector len: 8, Card Detections: [[129, 862, 178, 978, 0.66552734375], [128, 862, 178, 979, 0.66796875], [129, 863, 178, 979, 0.6669921875], [129, 863, 178, 980, 0.66943359375], [129, 863, 178, 980, 0.67578125], [128, 863, 178, 981, 0.67626953125], [129, 863, 178, 981, 0.66796875], [131, 872, 181, 984, 0.6416015625]]\n",
      "Key: 7c, vector len: 6, Card Detections: [[466, 876, 522, 985, 0.60302734375], [467, 876, 520, 986, 0.62841796875], [465, 876, 520, 988, 0.62255859375], [465, 876, 520, 988, 0.62548828125], [465, 877, 520, 989, 0.6337890625], [465, 877, 520, 989, 0.63330078125]]\n",
      "Key: 7d, vector len: 7, Card Detections: [[470, 875, 520, 985, 0.63671875], [470, 874, 519, 983, 0.63818359375], [469, 875, 519, 983, 0.6474609375], [468, 875, 518, 982, 0.65087890625], [469, 876, 519, 983, 0.64697265625], [469, 876, 519, 984, 0.65087890625], [466, 878, 517, 984, 0.62451171875]]\n",
      "Key: 7h, vector len: 7, Card Detections: [[468, 876, 519, 986, 0.69091796875], [468, 876, 519, 985, 0.6904296875], [468, 877, 519, 986, 0.69091796875], [467, 876, 518, 985, 0.6875], [466, 877, 518, 985, 0.68310546875], [467, 878, 518, 986, 0.68115234375], [467, 877, 533, 1005, 0.529296875]]\n",
      "Key: 7s, vector len: 15, Card Detections: [[107, 824, 157, 945, 0.64892578125], [106, 825, 156, 945, 0.6455078125], [106, 825, 156, 946, 0.6640625], [106, 826, 157, 946, 0.6650390625], [106, 827, 156, 946, 0.67041015625], [106, 828, 156, 947, 0.67626953125], [106, 828, 156, 948, 0.6806640625], [106, 829, 156, 949, 0.6826171875], [106, 829, 156, 949, 0.681640625], [105, 830, 156, 950, 0.69140625], [105, 830, 155, 950, 0.68212890625], [104, 830, 155, 951, 0.68310546875], [105, 830, 155, 950, 0.673828125], [105, 832, 156, 951, 0.658203125], [109, 834, 165, 964, 0.55126953125]]\n",
      "Key: 8c, vector len: 15, Card Detections: [[476, 875, 527, 986, 0.58642578125], [475, 875, 526, 984, 0.61376953125], [475, 876, 525, 986, 0.630859375], [475, 876, 525, 985, 0.62890625], [475, 876, 525, 986, 0.62939453125], [474, 876, 524, 986, 0.6337890625], [474, 876, 525, 985, 0.63720703125], [474, 876, 525, 986, 0.64013671875], [474, 876, 525, 985, 0.63720703125], [474, 876, 525, 985, 0.63818359375], [473, 875, 525, 984, 0.64111328125], [473, 876, 524, 987, 0.6376953125], [472, 876, 524, 988, 0.64453125], [472, 876, 524, 986, 0.6376953125], [472, 877, 524, 986, 0.6435546875]]\n",
      "Key: 8d, vector len: 6, Card Detections: [[118, 843, 178, 989, 0.6357421875], [121, 843, 170, 957, 0.70458984375], [121, 842, 170, 956, 0.705078125], [121, 840, 171, 956, 0.70166015625], [122, 840, 171, 954, 0.69775390625], [123, 842, 172, 955, 0.701171875]]\n",
      "Key: 8h, vector len: 18, Card Detections: [[471, 876, 522, 983, 0.68017578125], [472, 876, 522, 984, 0.6806640625], [472, 877, 522, 985, 0.68017578125], [471, 877, 522, 984, 0.68994140625], [471, 877, 522, 984, 0.69091796875], [471, 877, 522, 984, 0.6904296875], [471, 877, 522, 984, 0.68994140625], [471, 877, 521, 984, 0.68994140625], [471, 877, 521, 985, 0.68408203125], [471, 878, 521, 985, 0.67529296875], [471, 878, 520, 984, 0.67431640625], [471, 878, 520, 986, 0.67138671875], [471, 878, 520, 986, 0.67724609375], [471, 878, 520, 986, 0.6796875], [470, 878, 520, 985, 0.67578125], [471, 878, 520, 986, 0.67919921875], [470, 879, 520, 986, 0.673828125], [469, 879, 519, 987, 0.671875]]\n",
      "Key: 8s, vector len: 12, Card Detections: [[114, 828, 165, 946, 0.650390625], [115, 829, 165, 945, 0.64501953125], [114, 829, 165, 946, 0.64404296875], [114, 828, 165, 946, 0.646484375], [114, 828, 165, 946, 0.64697265625], [114, 828, 165, 947, 0.6474609375], [114, 828, 165, 947, 0.646484375], [114, 829, 165, 948, 0.64453125], [114, 830, 165, 948, 0.6416015625], [114, 831, 165, 948, 0.64306640625], [115, 831, 165, 949, 0.638671875], [115, 833, 166, 950, 0.63330078125]]\n",
      "Key: 9c, vector len: 10, Card Detections: [[112, 832, 167, 945, 0.6591796875], [113, 832, 165, 946, 0.65673828125], [113, 832, 165, 948, 0.658203125], [113, 832, 165, 948, 0.65673828125], [114, 832, 165, 948, 0.65478515625], [113, 832, 165, 948, 0.654296875], [113, 833, 165, 948, 0.6572265625], [114, 833, 165, 948, 0.65185546875], [114, 833, 166, 949, 0.65478515625], [118, 840, 170, 952, 0.591796875]]\n",
      "Key: 9d, vector len: 52, Card Detections: [[470, 886, 519, 996, 0.65234375], [470, 885, 518, 996, 0.66748046875], [469, 886, 518, 997, 0.671875], [469, 887, 518, 998, 0.673828125], [469, 887, 518, 997, 0.671875], [469, 887, 518, 998, 0.67626953125], [469, 887, 517, 998, 0.67578125], [469, 887, 517, 997, 0.671875], [469, 887, 517, 997, 0.66650390625], [469, 887, 517, 997, 0.66943359375], [469, 887, 517, 997, 0.66796875], [469, 887, 517, 997, 0.669921875], [469, 887, 517, 997, 0.666015625], [469, 887, 517, 997, 0.66796875], [469, 887, 517, 997, 0.66748046875], [469, 887, 517, 997, 0.66796875], [469, 887, 517, 997, 0.6689453125], [469, 887, 517, 997, 0.66748046875], [469, 887, 517, 998, 0.66552734375], [469, 887, 517, 998, 0.666015625], [469, 887, 517, 998, 0.66748046875], [469, 887, 517, 998, 0.6669921875], [469, 887, 517, 998, 0.66650390625], [469, 888, 517, 998, 0.6669921875], [469, 887, 517, 998, 0.66259765625], [469, 887, 517, 998, 0.66259765625], [469, 888, 517, 998, 0.66162109375], [469, 888, 517, 999, 0.66455078125], [468, 888, 517, 999, 0.658203125], [468, 888, 517, 999, 0.65869140625], [468, 888, 516, 999, 0.65673828125], [468, 889, 517, 998, 0.6591796875], [468, 888, 516, 999, 0.65673828125], [468, 889, 516, 999, 0.6572265625], [468, 889, 516, 1000, 0.65234375], [468, 889, 516, 999, 0.64208984375], [468, 889, 516, 999, 0.64794921875], [467, 889, 516, 1000, 0.64697265625], [467, 889, 516, 1000, 0.6455078125], [467, 889, 515, 1000, 0.6435546875], [467, 889, 515, 1000, 0.646484375], [467, 889, 515, 1000, 0.6484375], [467, 890, 515, 1000, 0.6455078125], [467, 891, 515, 999, 0.64599609375], [467, 891, 515, 999, 0.6455078125], [467, 891, 515, 999, 0.646484375], [467, 891, 515, 999, 0.6484375], [466, 891, 514, 999, 0.650390625], [466, 891, 514, 1000, 0.64892578125], [466, 892, 514, 1000, 0.6494140625], [466, 893, 514, 1000, 0.64697265625], [465, 894, 513, 1000, 0.642578125]]\n",
      "Key: 9h, vector len: 45, Card Detections: [[469, 882, 521, 990, 0.62646484375], [470, 882, 520, 992, 0.630859375], [469, 883, 520, 994, 0.62451171875], [469, 883, 520, 993, 0.626953125], [469, 883, 520, 993, 0.62646484375], [470, 883, 520, 993, 0.6298828125], [470, 883, 520, 993, 0.626953125], [470, 883, 520, 994, 0.62744140625], [470, 883, 520, 994, 0.62841796875], [470, 883, 520, 994, 0.6318359375], [470, 883, 520, 994, 0.6337890625], [470, 884, 520, 994, 0.63525390625], [469, 884, 520, 994, 0.63427734375], [470, 884, 520, 994, 0.63623046875], [470, 884, 520, 994, 0.63525390625], [469, 884, 520, 995, 0.6279296875], [469, 884, 520, 995, 0.62744140625], [469, 884, 520, 995, 0.6240234375], [469, 884, 519, 995, 0.63818359375], [469, 884, 519, 995, 0.63671875], [469, 885, 519, 995, 0.638671875], [469, 885, 519, 995, 0.638671875], [469, 885, 519, 995, 0.63818359375], [469, 885, 519, 995, 0.638671875], [469, 885, 519, 995, 0.63720703125], [469, 885, 519, 995, 0.63525390625], [469, 885, 519, 995, 0.6357421875], [469, 885, 519, 995, 0.63525390625], [469, 885, 519, 995, 0.63427734375], [469, 885, 519, 995, 0.6328125], [469, 885, 519, 995, 0.6337890625], [469, 885, 519, 995, 0.6328125], [469, 886, 519, 995, 0.6318359375], [468, 886, 518, 995, 0.625], [468, 886, 518, 995, 0.62451171875], [468, 886, 518, 996, 0.625], [468, 886, 518, 996, 0.62109375], [467, 886, 518, 996, 0.62060546875], [467, 886, 518, 996, 0.62109375], [467, 887, 518, 997, 0.62353515625], [467, 887, 517, 997, 0.62255859375], [467, 888, 517, 997, 0.6240234375], [466, 887, 517, 998, 0.63232421875], [466, 888, 517, 998, 0.6318359375], [466, 888, 517, 999, 0.6318359375]]\n",
      "Key: 9s, vector len: 4, Card Detections: [[128, 862, 179, 980, 0.64697265625], [128, 863, 178, 979, 0.6279296875], [129, 863, 179, 978, 0.6357421875], [130, 863, 180, 977, 0.62744140625]]\n",
      "Key: Ac, vector len: 10, Card Detections: [[133, 869, 188, 982, 0.63916015625], [132, 869, 188, 984, 0.662109375], [132, 869, 187, 984, 0.6640625], [131, 868, 187, 983, 0.66064453125], [130, 869, 186, 983, 0.66455078125], [129, 869, 186, 985, 0.6689453125], [129, 869, 186, 986, 0.66552734375], [129, 869, 185, 986, 0.65869140625], [128, 871, 184, 986, 0.6640625], [131, 870, 191, 992, 0.5654296875]]\n",
      "Key: Ad, vector len: 16, Card Detections: [[474, 878, 522, 985, 0.62744140625], [474, 878, 522, 987, 0.63134765625], [473, 878, 521, 986, 0.63525390625], [473, 879, 521, 986, 0.63720703125], [473, 879, 521, 987, 0.6376953125], [473, 879, 521, 987, 0.6416015625], [473, 879, 521, 986, 0.642578125], [473, 879, 521, 987, 0.642578125], [473, 879, 521, 987, 0.6435546875], [473, 879, 521, 987, 0.64404296875], [472, 879, 521, 987, 0.64453125], [472, 879, 521, 987, 0.64208984375], [472, 880, 521, 987, 0.6396484375], [472, 880, 520, 988, 0.646484375], [471, 880, 520, 988, 0.64013671875], [470, 880, 520, 989, 0.6494140625]]\n",
      "Key: Ah, vector len: 9, Card Detections: [[475, 876, 524, 981, 0.619140625], [475, 877, 524, 981, 0.62158203125], [474, 877, 524, 981, 0.611328125], [475, 877, 524, 982, 0.62158203125], [475, 878, 523, 982, 0.6259765625], [475, 878, 523, 982, 0.62353515625], [474, 878, 523, 983, 0.62255859375], [474, 878, 522, 983, 0.62744140625], [467, 883, 521, 987, 0.505859375]]\n",
      "Key: As, vector len: 9, Card Detections: [[477, 876, 527, 986, 0.599609375], [476, 876, 528, 985, 0.60107421875], [476, 876, 528, 986, 0.59716796875], [477, 876, 528, 986, 0.59423828125], [476, 877, 528, 987, 0.60302734375], [476, 877, 528, 987, 0.60791015625], [476, 877, 528, 987, 0.61474609375], [476, 877, 528, 987, 0.62158203125], [475, 877, 528, 988, 0.60205078125]]\n",
      "Key: Jc, vector len: 67, Card Detections: [[94, 833, 150, 951, 0.6435546875], [93, 835, 148, 954, 0.6845703125], [93, 837, 147, 955, 0.68701171875], [92, 837, 147, 956, 0.68798828125], [93, 837, 147, 955, 0.68701171875], [92, 838, 147, 956, 0.68505859375], [93, 838, 147, 957, 0.68798828125], [92, 839, 147, 957, 0.6884765625], [93, 839, 147, 958, 0.68798828125], [92, 839, 147, 957, 0.68603515625], [93, 839, 147, 958, 0.68701171875], [93, 839, 147, 957, 0.68701171875], [93, 839, 147, 957, 0.68701171875], [93, 839, 147, 958, 0.6865234375], [93, 839, 147, 957, 0.685546875], [93, 839, 147, 957, 0.6845703125], [93, 839, 147, 957, 0.68603515625], [93, 839, 147, 957, 0.68505859375], [93, 839, 147, 956, 0.68310546875], [93, 838, 147, 956, 0.68359375], [93, 838, 147, 956, 0.685546875], [93, 838, 147, 956, 0.68701171875], [93, 837, 147, 955, 0.68798828125], [93, 837, 147, 955, 0.68798828125], [93, 837, 147, 955, 0.689453125], [94, 837, 148, 955, 0.6865234375], [94, 837, 148, 955, 0.68798828125], [94, 837, 148, 955, 0.68798828125], [94, 837, 148, 955, 0.685546875], [94, 837, 148, 955, 0.6845703125], [95, 837, 149, 955, 0.68505859375], [95, 837, 149, 955, 0.6865234375], [95, 837, 149, 955, 0.6875], [95, 837, 149, 955, 0.6865234375], [95, 837, 149, 955, 0.68896484375], [95, 837, 150, 955, 0.6884765625], [96, 836, 150, 955, 0.69140625], [96, 837, 150, 954, 0.69140625], [96, 837, 150, 954, 0.69189453125], [96, 836, 151, 954, 0.69384765625], [96, 836, 151, 954, 0.69140625], [96, 836, 151, 954, 0.68994140625], [96, 836, 151, 953, 0.68994140625], [97, 836, 151, 953, 0.689453125], [97, 836, 151, 954, 0.68994140625], [97, 836, 151, 954, 0.69091796875], [97, 836, 151, 953, 0.69482421875], [97, 836, 151, 953, 0.6953125], [97, 836, 151, 953, 0.69482421875], [97, 836, 152, 953, 0.697265625], [97, 836, 152, 953, 0.69775390625], [97, 837, 152, 953, 0.6982421875], [98, 837, 152, 954, 0.69873046875], [97, 837, 152, 954, 0.6982421875], [97, 837, 152, 954, 0.69970703125], [97, 838, 152, 954, 0.69775390625], [98, 838, 152, 954, 0.69873046875], [98, 838, 152, 954, 0.69775390625], [98, 838, 152, 954, 0.69970703125], [98, 838, 152, 955, 0.701171875], [98, 838, 152, 955, 0.69970703125], [98, 838, 153, 955, 0.69921875], [98, 838, 153, 955, 0.7001953125], [98, 839, 153, 955, 0.7021484375], [98, 840, 154, 954, 0.70654296875], [98, 840, 154, 955, 0.70654296875], [99, 842, 155, 956, 0.69873046875]]\n",
      "Key: Jd, vector len: 6, Card Detections: [[126, 850, 178, 965, 0.63623046875], [126, 850, 177, 965, 0.626953125], [126, 850, 177, 965, 0.630859375], [126, 850, 177, 965, 0.63525390625], [126, 850, 177, 965, 0.6396484375], [128, 858, 181, 971, 0.5810546875]]\n",
      "Key: Jh, vector len: 22, Card Detections: [[102, 829, 155, 946, 0.61865234375], [102, 828, 155, 946, 0.61181640625], [102, 829, 155, 947, 0.61962890625], [102, 829, 155, 946, 0.61865234375], [102, 830, 155, 947, 0.62109375], [101, 831, 154, 948, 0.62255859375], [101, 831, 154, 948, 0.62255859375], [101, 831, 154, 948, 0.62109375], [101, 831, 154, 948, 0.62109375], [101, 832, 154, 949, 0.62158203125], [101, 832, 154, 948, 0.62158203125], [101, 832, 154, 948, 0.62109375], [101, 832, 154, 949, 0.62158203125], [101, 832, 154, 949, 0.62060546875], [101, 833, 154, 949, 0.62060546875], [100, 833, 154, 949, 0.62109375], [100, 833, 154, 950, 0.62109375], [100, 833, 154, 950, 0.62255859375], [100, 834, 154, 950, 0.62255859375], [100, 834, 154, 950, 0.61962890625], [100, 834, 154, 951, 0.6171875], [103, 841, 157, 955, 0.63134765625]]\n",
      "Key: Js, vector len: 17, Card Detections: [[472, 878, 522, 991, 0.6787109375], [472, 880, 522, 993, 0.67724609375], [472, 881, 522, 992, 0.67822265625], [472, 881, 522, 992, 0.67578125], [472, 881, 522, 993, 0.67626953125], [472, 881, 522, 992, 0.67236328125], [472, 881, 521, 993, 0.67626953125], [471, 882, 521, 993, 0.6748046875], [471, 882, 521, 993, 0.6748046875], [471, 882, 521, 994, 0.67626953125], [471, 882, 521, 994, 0.68310546875], [470, 883, 521, 995, 0.6591796875], [469, 884, 520, 995, 0.65625], [469, 884, 520, 996, 0.65966796875], [469, 884, 520, 996, 0.65966796875], [468, 885, 519, 996, 0.658203125], [467, 888, 518, 997, 0.65087890625]]\n",
      "Key: Kc, vector len: 13, Card Detections: [[115, 835, 171, 953, 0.7314453125], [115, 836, 170, 954, 0.73095703125], [115, 836, 171, 953, 0.72998046875], [115, 836, 171, 954, 0.72900390625], [115, 837, 170, 955, 0.71875], [115, 837, 171, 954, 0.71923828125], [115, 837, 171, 954, 0.71826171875], [115, 837, 171, 954, 0.71533203125], [115, 837, 170, 955, 0.716796875], [115, 837, 171, 955, 0.71923828125], [115, 837, 171, 955, 0.720703125], [116, 837, 171, 955, 0.72265625], [117, 837, 172, 955, 0.7275390625]]\n",
      "Key: Kd, vector len: 15, Card Detections: [[471, 876, 521, 984, 0.66943359375], [471, 875, 521, 984, 0.66357421875], [471, 875, 521, 985, 0.6708984375], [471, 876, 521, 985, 0.6669921875], [471, 876, 521, 985, 0.666015625], [471, 876, 520, 985, 0.66455078125], [471, 876, 520, 985, 0.66552734375], [471, 876, 520, 985, 0.6630859375], [471, 876, 520, 985, 0.66552734375], [471, 877, 520, 986, 0.6630859375], [471, 877, 520, 986, 0.66259765625], [471, 877, 520, 986, 0.66015625], [471, 878, 520, 986, 0.66015625], [469, 878, 520, 986, 0.6484375], [469, 879, 519, 987, 0.6484375]]\n",
      "Key: Kh, vector len: 11, Card Detections: [[469, 873, 521, 983, 0.65087890625], [470, 873, 520, 982, 0.64501953125], [470, 873, 521, 983, 0.6513671875], [470, 874, 521, 982, 0.6494140625], [470, 873, 521, 983, 0.65087890625], [470, 873, 521, 983, 0.65087890625], [469, 873, 521, 982, 0.650390625], [470, 874, 521, 984, 0.65380859375], [470, 874, 521, 984, 0.650390625], [470, 875, 521, 984, 0.64794921875], [469, 876, 521, 985, 0.64453125]]\n",
      "Key: Ks, vector len: 4, Card Detections: [[119, 848, 175, 968, 0.67041015625], [120, 848, 175, 966, 0.67822265625], [121, 848, 176, 966, 0.67138671875], [122, 848, 176, 965, 0.68017578125]]\n",
      "Key: Qc, vector len: 6, Card Detections: [[118, 836, 170, 951, 0.59619140625], [119, 835, 169, 950, 0.623046875], [119, 836, 170, 952, 0.6240234375], [119, 835, 171, 951, 0.6240234375], [119, 835, 171, 952, 0.62109375], [120, 837, 171, 953, 0.60888671875]]\n",
      "Key: Qd, vector len: 5, Card Detections: [[472, 879, 523, 986, 0.57421875], [471, 879, 521, 984, 0.61474609375], [471, 879, 522, 984, 0.6240234375], [471, 879, 522, 985, 0.578125], [471, 881, 522, 986, 0.54443359375]]\n",
      "Key: Qh, vector len: 59, Card Detections: [[458, 885, 508, 996, 0.642578125], [458, 885, 508, 995, 0.6474609375], [458, 885, 507, 996, 0.650390625], [458, 885, 507, 996, 0.64306640625], [458, 885, 507, 996, 0.646484375], [458, 885, 507, 996, 0.65283203125], [458, 885, 507, 995, 0.64013671875], [458, 885, 507, 995, 0.64306640625], [458, 885, 507, 995, 0.64404296875], [458, 885, 507, 995, 0.642578125], [458, 885, 507, 995, 0.64208984375], [458, 885, 507, 995, 0.63916015625], [458, 885, 507, 995, 0.6376953125], [458, 885, 507, 995, 0.64013671875], [458, 885, 507, 995, 0.6376953125], [458, 885, 507, 995, 0.63720703125], [459, 885, 507, 995, 0.64013671875], [459, 885, 507, 995, 0.6416015625], [459, 885, 507, 995, 0.642578125], [459, 885, 507, 995, 0.64208984375], [459, 886, 507, 995, 0.642578125], [459, 886, 507, 995, 0.64111328125], [459, 886, 507, 995, 0.64208984375], [459, 886, 507, 995, 0.64306640625], [459, 886, 507, 995, 0.6435546875], [459, 886, 507, 995, 0.64599609375], [459, 886, 507, 995, 0.64501953125], [459, 886, 507, 995, 0.6474609375], [459, 886, 507, 995, 0.6474609375], [459, 886, 507, 995, 0.64697265625], [459, 886, 507, 995, 0.6474609375], [458, 886, 507, 996, 0.6474609375], [458, 886, 506, 994, 0.6474609375], [458, 886, 506, 996, 0.646484375], [458, 886, 506, 995, 0.64892578125], [458, 886, 506, 996, 0.64794921875], [458, 887, 506, 995, 0.64794921875], [458, 886, 506, 995, 0.6572265625], [458, 887, 506, 995, 0.65576171875], [458, 887, 506, 995, 0.65478515625], [458, 887, 506, 995, 0.6572265625], [458, 887, 506, 995, 0.65966796875], [458, 887, 506, 995, 0.658203125], [457, 887, 505, 996, 0.6689453125], [457, 887, 505, 996, 0.67041015625], [457, 887, 505, 996, 0.6669921875], [457, 887, 505, 996, 0.6640625], [456, 888, 506, 998, 0.66357421875], [455, 888, 506, 998, 0.6640625], [455, 888, 505, 998, 0.66455078125], [455, 889, 505, 997, 0.66259765625], [454, 889, 505, 997, 0.66064453125], [454, 889, 505, 997, 0.6611328125], [454, 889, 505, 997, 0.65869140625], [453, 889, 504, 998, 0.6533203125], [452, 891, 503, 1000, 0.6513671875], [451, 893, 502, 1001, 0.642578125], [450, 897, 501, 1001, 0.6328125], [442, 904, 496, 1006, 0.6474609375]]\n",
      "Key: Qs, vector len: 10, Card Detections: [[113, 829, 165, 946, 0.6240234375], [113, 829, 165, 949, 0.63232421875], [113, 828, 165, 947, 0.6298828125], [113, 830, 165, 949, 0.63134765625], [113, 830, 165, 949, 0.6298828125], [112, 830, 165, 950, 0.6337890625], [112, 831, 165, 950, 0.63916015625], [112, 831, 165, 950, 0.6357421875], [113, 831, 165, 950, 0.634765625], [113, 832, 165, 950, 0.62939453125]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 0, Card Detections: []\n",
      "Key: Tc, vector len: 1, Card Detections: [[48, 866, 89, 963, 0.6474609375]]\n",
      "Key: Td, vector len: 1, Card Detections: [[48, 875, 89, 968, 0.68408203125]]\n",
      "Key: Th, vector len: 2, Card Detections: [[326, 903, 366, 991, 0.61279296875], [325, 906, 364, 993, 0.61865234375]]\n",
      "Key: Ts, vector len: 0, Card Detections: []\n",
      "Key: 2c, vector len: 2, Card Detections: [[329, 901, 372, 993, 0.64794921875], [329, 901, 372, 992, 0.64306640625]]\n",
      "Key: 2d, vector len: 4, Card Detections: [[334, 905, 373, 992, 0.6123046875], [335, 904, 374, 992, 0.60302734375], [335, 904, 374, 992, 0.60205078125], [332, 909, 369, 994, 0.63720703125]]\n",
      "Key: 2h, vector len: 1, Card Detections: [[47, 865, 88, 962, 0.62451171875]]\n",
      "Key: 2s, vector len: 1, Card Detections: [[28, 861, 72, 956, 0.6552734375]]\n",
      "Key: 3c, vector len: 1, Card Detections: [[48, 899, 92, 988, 0.568359375]]\n",
      "Key: 3d, vector len: 1, Card Detections: [[45, 861, 88, 958, 0.615234375]]\n",
      "Key: 3h, vector len: 1, Card Detections: [[328, 904, 368, 992, 0.61767578125]]\n",
      "Key: 3s, vector len: 0, Card Detections: []\n",
      "Key: 4c, vector len: 1, Card Detections: [[46, 871, 148, 970, 0.64990234375]]\n",
      "Key: 4d, vector len: 1, Card Detections: [[25, 876, 118, 969, 0.6025390625]]\n",
      "Key: 4h, vector len: 1, Card Detections: [[330, 901, 415, 994, 0.642578125]]\n",
      "Key: 4s, vector len: 1, Card Detections: [[45, 860, 138, 962, 0.6376953125]]\n",
      "Key: 5c, vector len: 4, Card Detections: [[24, 885, 67, 973, 0.62060546875], [25, 886, 68, 974, 0.63916015625], [26, 894, 67, 978, 0.63232421875], [26, 896, 68, 978, 0.626953125]]\n",
      "Key: 5d, vector len: 1, Card Detections: [[43, 860, 86, 956, 0.62744140625]]\n",
      "Key: 5h, vector len: 3, Card Detections: [[24, 876, 64, 966, 0.6328125], [25, 884, 65, 971, 0.65576171875], [26, 892, 66, 975, 0.6357421875]]\n",
      "Key: 5s, vector len: 2, Card Detections: [[325, 899, 365, 989, 0.6279296875], [321, 903, 363, 991, 0.64208984375]]\n",
      "Key: 6c, vector len: 0, Card Detections: []\n",
      "Key: 6d, vector len: 19, Card Detections: [[316, 963, 362, 1022, 0.5361328125], [316, 953, 362, 1016, 0.62548828125], [317, 936, 362, 1007, 0.65673828125], [317, 936, 362, 1007, 0.64892578125], [318, 923, 360, 998, 0.666015625], [319, 916, 362, 994, 0.64990234375], [320, 912, 361, 989, 0.65625], [322, 905, 363, 986, 0.6494140625], [323, 903, 364, 985, 0.64208984375], [324, 902, 364, 983, 0.65966796875], [324, 901, 365, 983, 0.67138671875], [325, 900, 365, 983, 0.6748046875], [325, 900, 365, 983, 0.669921875], [325, 901, 365, 984, 0.67236328125], [325, 901, 365, 984, 0.65966796875], [325, 901, 364, 984, 0.65966796875], [324, 903, 364, 986, 0.64208984375], [324, 904, 364, 986, 0.64697265625], [324, 904, 364, 986, 0.6474609375]]\n",
      "Key: 6h, vector len: 2, Card Detections: [[48, 888, 90, 979, 0.60595703125], [49, 888, 88, 978, 0.63427734375]]\n",
      "Key: 6s, vector len: 3, Card Detections: [[26, 863, 68, 960, 0.6728515625], [25, 862, 67, 958, 0.68408203125], [25, 862, 67, 958, 0.681640625]]\n",
      "Key: 7c, vector len: 2, Card Detections: [[328, 903, 368, 994, 0.61474609375], [329, 903, 367, 994, 0.59521484375]]\n",
      "Key: 7d, vector len: 3, Card Detections: [[332, 902, 371, 992, 0.62939453125], [331, 903, 370, 993, 0.62255859375], [332, 904, 370, 993, 0.62109375]]\n",
      "Key: 7h, vector len: 1, Card Detections: [[333, 900, 372, 992, 0.6474609375]]\n",
      "Key: 7s, vector len: 1, Card Detections: [[325, 901, 364, 988, 0.60791015625]]\n",
      "Key: 8c, vector len: 0, Card Detections: []\n",
      "Key: 8d, vector len: 1, Card Detections: [[39, 860, 80, 953, 0.69384765625]]\n",
      "Key: 8h, vector len: 1, Card Detections: [[46, 860, 88, 951, 0.7138671875]]\n",
      "Key: 8s, vector len: 1, Card Detections: [[44, 861, 87, 959, 0.6611328125]]\n",
      "Key: 9c, vector len: 2, Card Detections: [[322, 904, 365, 987, 0.59130859375], [323, 904, 364, 988, 0.6298828125]]\n",
      "Key: 9d, vector len: 1, Card Detections: [[48, 876, 89, 968, 0.6552734375]]\n",
      "Key: 9h, vector len: 1, Card Detections: [[326, 902, 365, 988, 0.63330078125]]\n",
      "Key: 9s, vector len: 1, Card Detections: [[47, 892, 93, 990, 0.60546875]]\n",
      "Key: Ac, vector len: 1, Card Detections: [[326, 901, 367, 988, 0.65234375]]\n",
      "Key: Ad, vector len: 2, Card Detections: [[335, 903, 375, 992, 0.623046875], [334, 906, 373, 994, 0.63427734375]]\n",
      "Key: Ah, vector len: 17, Card Detections: [[50, 949, 87, 1020, 0.62890625], [49, 948, 87, 1019, 0.630859375], [49, 933, 88, 1009, 0.6513671875], [51, 924, 91, 1004, 0.64990234375], [51, 918, 92, 999, 0.6435546875], [51, 914, 91, 996, 0.62890625], [52, 910, 92, 993, 0.638671875], [52, 907, 92, 992, 0.64794921875], [50, 906, 91, 992, 0.64697265625], [51, 905, 91, 991, 0.6474609375], [51, 905, 91, 991, 0.6474609375], [49, 904, 91, 992, 0.64501953125], [52, 903, 93, 990, 0.64892578125], [52, 902, 93, 990, 0.6474609375], [51, 903, 92, 991, 0.64990234375], [51, 903, 93, 991, 0.642578125], [51, 903, 92, 990, 0.64599609375]]\n",
      "Key: As, vector len: 1, Card Detections: [[325, 903, 367, 988, 0.68310546875]]\n",
      "Key: Jc, vector len: 1, Card Detections: [[325, 898, 364, 981, 0.6748046875]]\n",
      "Key: Jd, vector len: 4, Card Detections: [[334, 899, 371, 989, 0.638671875], [334, 900, 371, 990, 0.611328125], [333, 900, 371, 990, 0.60400390625], [332, 904, 368, 992, 0.60498046875]]\n",
      "Key: Jh, vector len: 5, Card Detections: [[29, 895, 71, 965, 0.61279296875], [29, 897, 69, 980, 0.6162109375], [29, 897, 70, 980, 0.61376953125], [29, 897, 70, 980, 0.6103515625], [31, 893, 73, 976, 0.6298828125]]\n",
      "Key: Js, vector len: 1, Card Detections: [[328, 903, 366, 992, 0.63720703125]]\n",
      "Key: Kc, vector len: 2, Card Detections: [[325, 895, 366, 981, 0.6865234375], [325, 896, 365, 982, 0.67626953125]]\n",
      "Key: Kd, vector len: 1, Card Detections: [[325, 901, 364, 990, 0.64990234375]]\n",
      "Key: Kh, vector len: 1, Card Detections: [[42, 853, 84, 949, 0.62158203125]]\n",
      "Key: Ks, vector len: 1, Card Detections: [[326, 894, 367, 985, 0.6845703125]]\n",
      "Key: Qc, vector len: 1, Card Detections: [[50, 883, 90, 975, 0.6328125]]\n",
      "Key: Qd, vector len: 1, Card Detections: [[45, 858, 87, 955, 0.62109375]]\n",
      "Key: Qh, vector len: 1, Card Detections: [[47, 861, 88, 954, 0.630859375]]\n",
      "Key: Qs, vector len: 1, Card Detections: [[327, 897, 368, 987, 0.66552734375]]\n",
      "Key: SJoker, vector len: 5, Card Detections: [[324, 910, 370, 1002, 0.5478515625], [324, 910, 369, 1002, 0.56640625], [323, 910, 367, 1003, 0.61572265625], [323, 911, 367, 1003, 0.60498046875], [321, 917, 364, 1004, 0.630859375]]\n",
      "Key: BJoker, vector len: 1, Card Detections: [[26, 859, 78, 1003, 0.6708984375]]\n",
      "Key: Tc, vector len: 4, Card Detections: [[123, 876, 176, 990, 0.64892578125], [123, 875, 176, 988, 0.64501953125], [125, 874, 178, 988, 0.6552734375], [125, 873, 179, 987, 0.65625]]\n",
      "Key: Td, vector len: 7, Card Detections: [[122, 869, 182, 1011, 0.6533203125], [124, 870, 177, 981, 0.67724609375], [125, 869, 178, 981, 0.68212890625], [125, 868, 178, 981, 0.673828125], [125, 867, 178, 981, 0.6689453125], [128, 870, 181, 981, 0.6845703125], [473, 881, 525, 992, 0.576171875]]\n",
      "Key: Th, vector len: 5, Card Detections: [[123, 862, 175, 976, 0.62060546875], [124, 862, 174, 975, 0.5947265625], [124, 860, 176, 975, 0.60400390625], [125, 860, 176, 974, 0.60595703125], [125, 860, 176, 973, 0.6044921875]]\n",
      "Key: Ts, vector len: 31, Card Detections: [[476, 882, 524, 995, 0.6259765625], [475, 883, 524, 996, 0.6279296875], [474, 883, 524, 996, 0.64404296875], [474, 884, 523, 998, 0.638671875], [475, 884, 523, 997, 0.60595703125], [475, 883, 523, 997, 0.6103515625], [474, 883, 523, 997, 0.62158203125], [475, 883, 523, 997, 0.6220703125], [475, 884, 523, 998, 0.6201171875], [475, 884, 523, 998, 0.61962890625], [474, 884, 523, 998, 0.61767578125], [474, 884, 523, 998, 0.61669921875], [474, 884, 523, 998, 0.61328125], [475, 885, 523, 999, 0.60595703125], [475, 885, 523, 999, 0.6025390625], [475, 885, 523, 999, 0.59228515625], [475, 885, 523, 999, 0.59228515625], [475, 885, 523, 999, 0.59326171875], [474, 884, 522, 999, 0.6064453125], [474, 885, 522, 1000, 0.595703125], [474, 885, 522, 1000, 0.60302734375], [474, 885, 522, 1000, 0.61474609375], [474, 885, 522, 1000, 0.61279296875], [474, 886, 522, 1000, 0.62353515625], [473, 886, 522, 1000, 0.6240234375], [473, 886, 521, 1000, 0.62646484375], [473, 886, 521, 999, 0.6220703125], [473, 886, 521, 1000, 0.611328125], [472, 887, 520, 1001, 0.6025390625], [472, 887, 520, 1001, 0.6005859375], [472, 889, 519, 1001, 0.56787109375]]\n",
      "Key: 2c, vector len: 6, Card Detections: [[123, 859, 179, 979, 0.65283203125], [123, 859, 178, 977, 0.64111328125], [124, 857, 179, 978, 0.65185546875], [124, 858, 180, 976, 0.6396484375], [124, 858, 180, 977, 0.638671875], [125, 859, 181, 977, 0.64306640625]]\n",
      "Key: 2d, vector len: 11, Card Detections: [[476, 870, 526, 981, 0.62109375], [476, 871, 525, 981, 0.6240234375], [476, 871, 526, 982, 0.638671875], [477, 871, 525, 982, 0.6455078125], [477, 872, 525, 982, 0.64599609375], [476, 873, 525, 982, 0.6318359375], [476, 873, 525, 983, 0.63037109375], [476, 873, 525, 982, 0.62255859375], [476, 873, 525, 983, 0.62890625], [475, 874, 524, 984, 0.64208984375], [474, 876, 524, 984, 0.6474609375]]\n",
      "Key: 2h, vector len: 13, Card Detections: [[471, 875, 524, 988, 0.64111328125], [472, 875, 523, 987, 0.63818359375], [471, 875, 523, 988, 0.63525390625], [471, 875, 523, 988, 0.6318359375], [471, 876, 523, 988, 0.625], [471, 876, 523, 988, 0.6240234375], [471, 876, 523, 988, 0.6240234375], [471, 876, 523, 989, 0.62353515625], [471, 876, 523, 989, 0.62158203125], [471, 876, 523, 989, 0.62060546875], [471, 877, 523, 989, 0.62060546875], [470, 877, 522, 989, 0.6162109375], [467, 879, 519, 992, 0.587890625]]\n",
      "Key: 2s, vector len: 3, Card Detections: [[101, 834, 157, 952, 0.68115234375], [101, 834, 157, 952, 0.6796875], [105, 840, 160, 956, 0.658203125]]\n",
      "Key: 3c, vector len: 10, Card Detections: [[474, 869, 527, 984, 0.64013671875], [474, 870, 527, 984, 0.646484375], [474, 870, 527, 984, 0.64111328125], [474, 870, 527, 985, 0.6435546875], [474, 871, 527, 986, 0.650390625], [473, 871, 527, 986, 0.650390625], [474, 871, 527, 986, 0.6494140625], [473, 871, 526, 987, 0.64111328125], [472, 872, 526, 987, 0.66455078125], [471, 874, 526, 989, 0.6591796875]]\n",
      "Key: 3d, vector len: 131, Card Detections: [[452, 973, 516, 1048, 0.52490234375], [462, 944, 521, 1031, 0.6474609375], [467, 923, 525, 1015, 0.63037109375], [471, 910, 527, 1006, 0.6474609375], [469, 899, 524, 999, 0.63427734375], [469, 899, 523, 998, 0.6611328125], [469, 898, 523, 997, 0.6640625], [468, 896, 523, 996, 0.66259765625], [467, 896, 522, 995, 0.66064453125], [467, 894, 522, 994, 0.65625], [468, 893, 522, 994, 0.65966796875], [468, 892, 522, 993, 0.662109375], [468, 891, 522, 991, 0.66650390625], [468, 891, 522, 990, 0.6669921875], [469, 890, 522, 990, 0.66455078125], [469, 889, 522, 989, 0.66357421875], [470, 888, 522, 988, 0.66552734375], [470, 887, 522, 987, 0.66357421875], [470, 886, 523, 986, 0.6611328125], [471, 885, 523, 985, 0.6591796875], [470, 885, 523, 985, 0.65673828125], [471, 884, 523, 985, 0.654296875], [471, 883, 523, 984, 0.65869140625], [471, 883, 523, 984, 0.66259765625], [471, 883, 523, 984, 0.6630859375], [471, 883, 523, 984, 0.66552734375], [471, 882, 523, 984, 0.66650390625], [471, 882, 523, 984, 0.6650390625], [471, 881, 523, 983, 0.66357421875], [471, 881, 523, 983, 0.66259765625], [471, 880, 523, 983, 0.6640625], [472, 880, 523, 983, 0.66015625], [472, 880, 524, 983, 0.650390625], [473, 880, 524, 982, 0.64599609375], [473, 879, 524, 982, 0.63623046875], [474, 879, 524, 982, 0.63623046875], [474, 879, 524, 981, 0.63134765625], [474, 878, 524, 981, 0.62744140625], [474, 878, 524, 980, 0.6259765625], [474, 878, 524, 980, 0.6279296875], [474, 877, 524, 980, 0.62939453125], [474, 877, 524, 980, 0.62841796875], [475, 877, 524, 979, 0.62744140625], [475, 877, 525, 980, 0.6279296875], [475, 877, 524, 979, 0.626953125], [475, 877, 525, 980, 0.6279296875], [475, 877, 525, 980, 0.626953125], [475, 877, 525, 980, 0.62646484375], [475, 877, 525, 980, 0.62744140625], [475, 877, 525, 980, 0.626953125], [475, 877, 525, 980, 0.62744140625], [475, 877, 525, 980, 0.6279296875], [475, 877, 525, 980, 0.626953125], [475, 877, 525, 980, 0.6279296875], [475, 877, 525, 980, 0.62890625], [475, 877, 525, 980, 0.62939453125], [475, 877, 525, 980, 0.6279296875], [475, 876, 526, 979, 0.62890625], [475, 876, 525, 979, 0.6298828125], [476, 876, 525, 979, 0.62890625], [476, 876, 525, 979, 0.630859375], [476, 876, 526, 979, 0.630859375], [476, 876, 526, 979, 0.63134765625], [476, 876, 526, 979, 0.6337890625], [476, 876, 526, 979, 0.6328125], [476, 876, 526, 979, 0.63134765625], [476, 876, 526, 979, 0.630859375], [476, 876, 525, 979, 0.62890625], [475, 876, 525, 979, 0.62841796875], [475, 876, 525, 979, 0.62744140625], [475, 876, 525, 979, 0.62646484375], [475, 876, 525, 980, 0.6240234375], [475, 877, 525, 980, 0.6259765625], [475, 877, 525, 980, 0.6240234375], [474, 877, 525, 980, 0.62451171875], [474, 877, 525, 980, 0.623046875], [474, 877, 525, 980, 0.6220703125], [474, 877, 524, 980, 0.619140625], [474, 877, 524, 980, 0.619140625], [474, 877, 525, 980, 0.619140625], [474, 877, 525, 980, 0.6201171875], [474, 877, 525, 980, 0.6201171875], [474, 877, 525, 980, 0.6201171875], [474, 876, 524, 980, 0.61865234375], [474, 877, 524, 980, 0.6181640625], [474, 877, 525, 980, 0.62109375], [474, 877, 525, 980, 0.62109375], [474, 877, 525, 980, 0.623046875], [474, 876, 525, 980, 0.623046875], [474, 877, 525, 980, 0.62158203125], [474, 876, 524, 980, 0.62255859375], [474, 877, 524, 980, 0.623046875], [474, 877, 524, 980, 0.6318359375], [473, 877, 524, 980, 0.630859375], [473, 877, 524, 980, 0.6318359375], [473, 877, 524, 981, 0.6337890625], [473, 877, 524, 981, 0.6337890625], [473, 877, 524, 980, 0.640625], [473, 877, 524, 981, 0.64404296875], [473, 877, 524, 981, 0.64453125], [473, 877, 524, 981, 0.6474609375], [473, 877, 524, 981, 0.64794921875], [473, 877, 524, 981, 0.6494140625], [473, 877, 523, 981, 0.6494140625], [473, 878, 523, 981, 0.650390625], [473, 878, 523, 981, 0.65087890625], [473, 878, 523, 981, 0.6513671875], [473, 878, 523, 981, 0.65234375], [473, 878, 523, 981, 0.65283203125], [473, 878, 524, 981, 0.65185546875], [473, 878, 524, 982, 0.64990234375], [473, 878, 524, 982, 0.65185546875], [473, 878, 523, 982, 0.650390625], [473, 878, 523, 982, 0.646484375], [473, 878, 523, 982, 0.64990234375], [473, 878, 523, 982, 0.64794921875], [473, 878, 523, 982, 0.6455078125], [473, 878, 523, 982, 0.64453125], [473, 878, 523, 982, 0.6455078125], [473, 878, 523, 982, 0.64794921875], [473, 878, 523, 982, 0.65087890625], [472, 878, 523, 982, 0.650390625], [472, 878, 523, 983, 0.65283203125], [472, 878, 523, 983, 0.6552734375], [472, 879, 523, 983, 0.65283203125], [472, 879, 523, 984, 0.65283203125], [471, 879, 522, 984, 0.65234375], [471, 880, 522, 984, 0.658203125], [470, 880, 522, 984, 0.6591796875], [469, 882, 521, 985, 0.66650390625], [467, 884, 519, 985, 0.65625]]\n",
      "Key: 3h, vector len: 45, Card Detections: [[87, 849, 144, 968, 0.6103515625], [86, 849, 143, 970, 0.60205078125], [84, 849, 141, 970, 0.58740234375], [84, 849, 141, 970, 0.58740234375], [84, 851, 140, 972, 0.60791015625], [83, 852, 140, 974, 0.60546875], [83, 853, 140, 974, 0.62060546875], [83, 853, 140, 974, 0.6279296875], [83, 853, 140, 974, 0.6328125], [83, 853, 140, 974, 0.634765625], [83, 854, 139, 974, 0.6328125], [83, 854, 139, 974, 0.6328125], [83, 854, 139, 974, 0.6337890625], [83, 854, 139, 974, 0.6357421875], [83, 854, 139, 974, 0.634765625], [82, 854, 139, 974, 0.63427734375], [83, 854, 139, 974, 0.63525390625], [82, 854, 139, 973, 0.6337890625], [82, 854, 139, 973, 0.6328125], [82, 854, 139, 973, 0.63037109375], [82, 855, 139, 974, 0.630859375], [82, 855, 139, 975, 0.6318359375], [82, 855, 139, 975, 0.62939453125], [82, 855, 139, 975, 0.62548828125], [82, 855, 139, 975, 0.625], [82, 855, 139, 975, 0.62646484375], [83, 855, 139, 975, 0.625], [83, 855, 139, 974, 0.6298828125], [83, 855, 139, 974, 0.63232421875], [83, 855, 139, 973, 0.6328125], [83, 854, 140, 973, 0.63525390625], [83, 854, 140, 973, 0.63525390625], [83, 854, 140, 973, 0.6337890625], [84, 854, 140, 972, 0.63134765625], [84, 853, 140, 972, 0.63330078125], [84, 854, 140, 972, 0.6318359375], [84, 854, 141, 972, 0.630859375], [85, 854, 141, 972, 0.63623046875], [85, 854, 141, 972, 0.63720703125], [85, 854, 141, 972, 0.63330078125], [85, 855, 141, 972, 0.63330078125], [85, 856, 142, 973, 0.6357421875], [86, 856, 142, 973, 0.62939453125], [86, 857, 143, 974, 0.634765625], [87, 853, 145, 978, 0.62060546875]]\n",
      "Key: 3s, vector len: 22, Card Detections: [[475, 876, 528, 992, 0.6005859375], [475, 876, 528, 992, 0.6015625], [475, 876, 528, 992, 0.607421875], [475, 877, 527, 993, 0.60205078125], [474, 877, 527, 993, 0.6142578125], [474, 877, 527, 992, 0.6376953125], [473, 877, 527, 992, 0.62255859375], [473, 878, 527, 993, 0.61767578125], [473, 877, 527, 993, 0.626953125], [473, 878, 526, 993, 0.61962890625], [473, 878, 526, 993, 0.62158203125], [473, 878, 526, 993, 0.62353515625], [473, 878, 526, 993, 0.6201171875], [473, 878, 526, 993, 0.61962890625], [473, 878, 526, 992, 0.61865234375], [472, 878, 526, 993, 0.62060546875], [472, 878, 526, 993, 0.61962890625], [472, 879, 525, 993, 0.6201171875], [472, 879, 525, 993, 0.619140625], [472, 879, 525, 993, 0.6171875], [471, 880, 524, 993, 0.6328125], [468, 882, 523, 994, 0.62353515625]]\n",
      "Key: 4c, vector len: 8, Card Detections: [[106, 834, 232, 956, 0.61279296875], [105, 833, 231, 957, 0.6181640625], [106, 835, 225, 956, 0.62744140625], [106, 833, 232, 957, 0.62060546875], [106, 834, 231, 957, 0.63037109375], [106, 834, 232, 958, 0.623046875], [107, 834, 231, 958, 0.630859375], [110, 839, 236, 962, 0.6064453125]]\n",
      "Key: 4d, vector len: 50, Card Detections: [[475, 870, 566, 1008, 0.58935546875], [473, 886, 572, 1010, 0.60986328125], [472, 887, 572, 1005, 0.607421875], [472, 887, 572, 1008, 0.61181640625], [472, 888, 571, 1009, 0.60888671875], [472, 888, 571, 1008, 0.60986328125], [472, 889, 571, 1009, 0.6083984375], [472, 889, 571, 1009, 0.60791015625], [472, 889, 571, 1009, 0.607421875], [472, 889, 570, 1009, 0.6083984375], [472, 890, 571, 1010, 0.60693359375], [472, 890, 571, 1010, 0.60693359375], [472, 890, 571, 1010, 0.6083984375], [472, 890, 571, 1010, 0.60986328125], [472, 890, 570, 1010, 0.60986328125], [472, 890, 570, 1010, 0.60986328125], [472, 890, 570, 1010, 0.6103515625], [472, 891, 570, 1010, 0.6083984375], [472, 891, 570, 1010, 0.6083984375], [472, 891, 570, 1010, 0.60888671875], [472, 891, 570, 1010, 0.6083984375], [471, 891, 570, 1011, 0.6083984375], [471, 892, 570, 1011, 0.609375], [471, 892, 570, 1011, 0.609375], [471, 892, 570, 1011, 0.60888671875], [471, 892, 570, 1011, 0.60986328125], [472, 892, 570, 1011, 0.6103515625], [472, 892, 570, 1011, 0.6103515625], [472, 892, 570, 1011, 0.60986328125], [472, 892, 569, 1012, 0.609375], [472, 892, 569, 1012, 0.60986328125], [472, 892, 570, 1012, 0.61083984375], [472, 893, 569, 1012, 0.6103515625], [472, 892, 569, 1012, 0.6123046875], [471, 893, 569, 1012, 0.6123046875], [470, 892, 568, 1010, 0.61181640625], [471, 892, 569, 1010, 0.61083984375], [470, 892, 569, 1010, 0.611328125], [471, 892, 569, 1010, 0.6103515625], [471, 892, 569, 1011, 0.61083984375], [471, 892, 568, 1011, 0.61279296875], [471, 892, 568, 1011, 0.61328125], [471, 893, 568, 1012, 0.615234375], [471, 893, 568, 1011, 0.615234375], [470, 893, 568, 1012, 0.6171875], [470, 893, 568, 1012, 0.6171875], [470, 893, 568, 1012, 0.6201171875], [470, 894, 568, 1012, 0.62060546875], [470, 894, 568, 1013, 0.6240234375], [469, 895, 568, 1014, 0.626953125]]\n",
      "Key: 4h, vector len: 129, Card Detections: [[113, 978, 234, 1052, 0.619140625], [123, 945, 240, 1034, 0.615234375], [132, 916, 246, 1016, 0.64208984375], [136, 893, 246, 1002, 0.62890625], [135, 892, 245, 1001, 0.62841796875], [134, 891, 246, 1001, 0.6396484375], [133, 890, 246, 999, 0.64208984375], [133, 890, 244, 999, 0.6484375], [132, 889, 244, 999, 0.65234375], [131, 889, 244, 998, 0.65625], [131, 888, 243, 998, 0.65673828125], [130, 888, 242, 998, 0.66064453125], [129, 889, 242, 998, 0.66162109375], [128, 889, 241, 998, 0.66162109375], [127, 890, 241, 999, 0.6611328125], [126, 890, 240, 999, 0.66064453125], [125, 890, 240, 999, 0.65673828125], [125, 891, 239, 999, 0.65087890625], [124, 891, 239, 1000, 0.64990234375], [124, 892, 239, 1000, 0.6455078125], [124, 892, 239, 1000, 0.6435546875], [124, 892, 239, 1000, 0.642578125], [124, 891, 239, 1000, 0.64208984375], [124, 892, 239, 1000, 0.6435546875], [124, 892, 239, 1000, 0.64501953125], [124, 892, 239, 1000, 0.64453125], [124, 892, 239, 1000, 0.64404296875], [124, 892, 239, 1000, 0.6416015625], [123, 892, 239, 1001, 0.6396484375], [123, 892, 239, 1001, 0.6376953125], [122, 892, 239, 1001, 0.63671875], [122, 893, 239, 1001, 0.63720703125], [122, 893, 239, 1002, 0.63720703125], [122, 893, 239, 1002, 0.63671875], [122, 893, 238, 1001, 0.634765625], [122, 892, 238, 1001, 0.634765625], [122, 892, 238, 1000, 0.63623046875], [121, 892, 238, 1000, 0.63623046875], [121, 891, 238, 1000, 0.63671875], [121, 891, 238, 1000, 0.63671875], [121, 891, 238, 999, 0.63623046875], [122, 890, 238, 999, 0.6357421875], [122, 889, 238, 998, 0.64306640625], [122, 889, 238, 998, 0.6474609375], [122, 888, 238, 997, 0.64990234375], [122, 887, 239, 997, 0.654296875], [123, 886, 239, 997, 0.65576171875], [123, 886, 239, 997, 0.6572265625], [123, 886, 239, 996, 0.658203125], [123, 885, 239, 996, 0.66015625], [123, 885, 239, 996, 0.66064453125], [123, 885, 239, 996, 0.6611328125], [123, 885, 239, 995, 0.6611328125], [123, 885, 239, 995, 0.66162109375], [123, 885, 239, 995, 0.6611328125], [123, 885, 239, 995, 0.65673828125], [123, 885, 239, 995, 0.65673828125], [123, 884, 238, 994, 0.65380859375], [123, 884, 238, 995, 0.65380859375], [123, 884, 238, 995, 0.6533203125], [122, 884, 238, 995, 0.65380859375], [122, 884, 238, 995, 0.65234375], [122, 884, 238, 995, 0.65185546875], [122, 884, 238, 995, 0.65185546875], [123, 884, 238, 995, 0.65576171875], [123, 884, 239, 995, 0.65576171875], [123, 884, 239, 995, 0.65625], [123, 884, 239, 994, 0.6572265625], [124, 884, 239, 995, 0.66015625], [124, 884, 239, 995, 0.6630859375], [124, 884, 239, 995, 0.6630859375], [124, 884, 240, 994, 0.66455078125], [124, 883, 239, 994, 0.6630859375], [124, 883, 240, 994, 0.66455078125], [124, 883, 240, 994, 0.66455078125], [124, 883, 240, 994, 0.6650390625], [124, 883, 239, 994, 0.66357421875], [124, 883, 239, 994, 0.6630859375], [124, 883, 239, 994, 0.66259765625], [123, 883, 239, 994, 0.66162109375], [123, 883, 239, 994, 0.6591796875], [123, 883, 239, 994, 0.66064453125], [123, 883, 239, 995, 0.65966796875], [123, 884, 239, 994, 0.65771484375], [123, 884, 239, 995, 0.6572265625], [123, 884, 239, 995, 0.65625], [123, 884, 239, 995, 0.6572265625], [123, 884, 239, 995, 0.65869140625], [123, 884, 239, 995, 0.658203125], [123, 884, 239, 995, 0.65771484375], [123, 884, 239, 995, 0.65869140625], [123, 884, 239, 995, 0.66064453125], [123, 884, 239, 995, 0.66162109375], [124, 884, 239, 995, 0.662109375], [124, 884, 239, 995, 0.66259765625], [124, 884, 239, 995, 0.66162109375], [124, 884, 239, 995, 0.66455078125], [123, 884, 239, 995, 0.6640625], [123, 884, 239, 995, 0.662109375], [123, 884, 239, 996, 0.6591796875], [122, 884, 239, 996, 0.65771484375], [122, 884, 239, 995, 0.65576171875], [122, 884, 239, 996, 0.654296875], [121, 884, 239, 996, 0.6533203125], [121, 884, 239, 996, 0.65234375], [121, 885, 239, 997, 0.65087890625], [121, 885, 239, 997, 0.65283203125], [122, 885, 239, 997, 0.6533203125], [122, 885, 239, 997, 0.65576171875], [122, 886, 239, 997, 0.6572265625], [123, 886, 239, 997, 0.66064453125], [123, 886, 240, 997, 0.662109375], [123, 886, 240, 997, 0.66064453125], [123, 886, 240, 997, 0.662109375], [124, 886, 240, 997, 0.6650390625], [124, 885, 241, 997, 0.66748046875], [125, 885, 241, 997, 0.66845703125], [125, 885, 241, 997, 0.6689453125], [124, 884, 241, 997, 0.6689453125], [124, 884, 241, 997, 0.6689453125], [125, 884, 241, 996, 0.6689453125], [125, 884, 242, 996, 0.66943359375], [125, 884, 241, 996, 0.66943359375], [125, 883, 241, 996, 0.669921875], [124, 883, 241, 996, 0.6708984375], [124, 883, 241, 995, 0.67041015625], [125, 883, 241, 995, 0.66845703125], [124, 883, 240, 995, 0.66796875], [125, 885, 241, 995, 0.66650390625]]\n",
      "Key: 4s, vector len: 16, Card Detections: [[475, 869, 577, 994, 0.61083984375], [475, 870, 577, 995, 0.63818359375], [475, 870, 577, 994, 0.61279296875], [476, 869, 577, 994, 0.61376953125], [474, 871, 576, 994, 0.6181640625], [475, 870, 576, 993, 0.61572265625], [474, 871, 575, 993, 0.6162109375], [474, 871, 575, 994, 0.6171875], [474, 871, 575, 994, 0.6162109375], [475, 870, 575, 995, 0.6162109375], [474, 871, 575, 995, 0.615234375], [474, 871, 575, 995, 0.6162109375], [474, 872, 574, 995, 0.62060546875], [474, 872, 573, 995, 0.6171875], [473, 873, 573, 996, 0.61767578125], [472, 873, 574, 996, 0.6240234375]]\n",
      "Key: 5c, vector len: 6, Card Detections: [[469, 875, 522, 989, 0.67041015625], [469, 874, 520, 989, 0.66455078125], [468, 874, 521, 989, 0.67626953125], [468, 874, 522, 989, 0.6767578125], [469, 874, 522, 989, 0.66845703125], [466, 877, 521, 991, 0.66357421875]]\n",
      "Key: 5d, vector len: 4, Card Detections: [[122, 850, 178, 981, 0.626953125], [124, 850, 176, 968, 0.64453125], [125, 850, 176, 967, 0.64697265625], [126, 850, 176, 967, 0.64599609375]]\n",
      "Key: 5h, vector len: 10, Card Detections: [[475, 870, 525, 983, 0.63037109375], [475, 869, 525, 985, 0.6337890625], [475, 871, 525, 984, 0.642578125], [475, 870, 526, 986, 0.64990234375], [474, 871, 525, 985, 0.650390625], [474, 871, 524, 986, 0.642578125], [474, 871, 525, 986, 0.64697265625], [474, 872, 524, 985, 0.65185546875], [474, 873, 524, 985, 0.6572265625], [472, 874, 523, 985, 0.66455078125]]\n",
      "Key: 5s, vector len: 6, Card Detections: [[115, 846, 173, 991, 0.55029296875], [116, 847, 169, 967, 0.66552734375], [116, 847, 169, 968, 0.64111328125], [116, 847, 169, 969, 0.65478515625], [116, 848, 169, 969, 0.65966796875], [117, 848, 169, 970, 0.65966796875]]\n",
      "Key: 6c, vector len: 16, Card Detections: [[472, 876, 524, 990, 0.6591796875], [472, 877, 523, 991, 0.689453125], [472, 877, 524, 990, 0.69384765625], [472, 877, 523, 991, 0.69091796875], [472, 877, 523, 991, 0.6923828125], [472, 877, 523, 991, 0.689453125], [472, 877, 523, 991, 0.69091796875], [472, 877, 523, 991, 0.69482421875], [472, 877, 523, 991, 0.69384765625], [472, 878, 523, 991, 0.6962890625], [472, 878, 523, 991, 0.69580078125], [471, 878, 522, 991, 0.70166015625], [471, 878, 523, 992, 0.697265625], [471, 879, 522, 992, 0.69384765625], [470, 879, 522, 993, 0.68310546875], [469, 880, 520, 995, 0.67041015625]]\n",
      "Key: 6d, vector len: 23, Card Detections: [[473, 878, 522, 989, 0.68310546875], [473, 878, 522, 991, 0.671875], [473, 879, 522, 992, 0.66650390625], [473, 879, 522, 993, 0.6630859375], [473, 880, 521, 993, 0.66015625], [473, 880, 522, 993, 0.66015625], [473, 880, 521, 993, 0.65966796875], [473, 880, 521, 993, 0.6591796875], [473, 880, 521, 993, 0.66064453125], [473, 880, 521, 993, 0.658203125], [473, 880, 521, 993, 0.65625], [473, 880, 521, 993, 0.6533203125], [473, 880, 521, 993, 0.65478515625], [473, 881, 521, 993, 0.6533203125], [473, 881, 521, 993, 0.64990234375], [473, 881, 521, 993, 0.6494140625], [473, 881, 521, 993, 0.64794921875], [472, 881, 521, 993, 0.64453125], [472, 882, 520, 993, 0.64697265625], [472, 882, 520, 994, 0.64306640625], [472, 882, 520, 994, 0.64111328125], [471, 883, 520, 994, 0.642578125], [470, 885, 519, 995, 0.6435546875]]\n",
      "Key: 6h, vector len: 6, Card Detections: [[475, 871, 525, 983, 0.62744140625], [474, 871, 524, 983, 0.619140625], [474, 872, 525, 984, 0.6240234375], [474, 871, 524, 984, 0.61865234375], [474, 872, 524, 984, 0.62060546875], [473, 874, 523, 984, 0.63623046875]]\n",
      "Key: 6s, vector len: 10, Card Detections: [[107, 831, 158, 953, 0.671875], [108, 831, 158, 952, 0.6669921875], [107, 831, 158, 953, 0.67041015625], [108, 831, 159, 953, 0.67724609375], [108, 832, 158, 954, 0.6767578125], [108, 832, 158, 954, 0.6767578125], [109, 832, 159, 954, 0.6806640625], [109, 832, 159, 954, 0.6796875], [109, 832, 159, 954, 0.681640625], [110, 833, 160, 955, 0.68505859375]]\n",
      "Key: 7c, vector len: 5, Card Detections: [[123, 849, 173, 967, 0.67138671875], [122, 850, 173, 966, 0.6767578125], [123, 850, 173, 967, 0.67333984375], [123, 850, 173, 967, 0.67138671875], [125, 852, 175, 968, 0.67138671875]]\n",
      "Key: 7d, vector len: 20, Card Detections: [[98, 827, 148, 943, 0.5849609375], [97, 827, 147, 943, 0.5849609375], [97, 829, 147, 945, 0.58837890625], [97, 828, 146, 944, 0.59130859375], [96, 828, 146, 944, 0.59033203125], [96, 829, 146, 945, 0.58984375], [96, 829, 146, 945, 0.59228515625], [96, 830, 146, 945, 0.59130859375], [97, 830, 146, 945, 0.59033203125], [97, 831, 146, 946, 0.5888671875], [97, 831, 146, 946, 0.5908203125], [97, 831, 146, 947, 0.59033203125], [97, 832, 147, 948, 0.59716796875], [97, 833, 147, 949, 0.59912109375], [97, 833, 147, 949, 0.599609375], [97, 833, 147, 950, 0.60302734375], [97, 834, 147, 950, 0.6015625], [98, 834, 147, 949, 0.607421875], [98, 836, 148, 953, 0.62060546875], [101, 837, 155, 961, 0.59423828125]]\n",
      "Key: 7h, vector len: 9, Card Detections: [[106, 836, 165, 984, 0.64208984375], [107, 836, 157, 953, 0.67529296875], [106, 836, 157, 954, 0.6708984375], [107, 836, 157, 954, 0.6689453125], [107, 836, 157, 954, 0.671875], [107, 837, 158, 955, 0.673828125], [108, 837, 158, 955, 0.6787109375], [108, 836, 159, 955, 0.6865234375], [108, 836, 159, 954, 0.68115234375]]\n",
      "Key: 7s, vector len: 15, Card Detections: [[95, 832, 146, 953, 0.64404296875], [95, 833, 145, 954, 0.6484375], [94, 833, 145, 954, 0.64794921875], [95, 834, 146, 955, 0.6474609375], [95, 834, 146, 955, 0.64990234375], [95, 834, 146, 956, 0.65087890625], [95, 835, 146, 956, 0.65087890625], [95, 835, 146, 956, 0.65087890625], [95, 835, 146, 957, 0.6474609375], [95, 835, 146, 957, 0.65087890625], [95, 835, 146, 957, 0.64892578125], [95, 836, 146, 957, 0.6484375], [95, 836, 146, 958, 0.6484375], [95, 837, 146, 959, 0.64794921875], [95, 839, 147, 960, 0.65234375]]\n",
      "Key: 8c, vector len: 7, Card Detections: [[120, 881, 171, 989, 0.658203125], [122, 883, 172, 993, 0.654296875], [121, 883, 172, 993, 0.65966796875], [121, 883, 172, 993, 0.66357421875], [121, 883, 173, 993, 0.66552734375], [121, 883, 173, 993, 0.66845703125], [122, 883, 174, 993, 0.6640625]]\n",
      "Key: 8d, vector len: 9, Card Detections: [[473, 873, 524, 985, 0.7080078125], [474, 873, 522, 980, 0.69384765625], [475, 873, 522, 981, 0.6904296875], [475, 872, 522, 981, 0.69970703125], [475, 871, 523, 982, 0.7001953125], [475, 871, 524, 980, 0.69873046875], [474, 872, 522, 976, 0.6826171875], [475, 872, 523, 978, 0.68994140625], [475, 872, 523, 979, 0.69873046875]]\n",
      "Key: 8h, vector len: 9, Card Detections: [[104, 831, 155, 945, 0.6689453125], [104, 831, 155, 946, 0.671875], [104, 832, 154, 946, 0.6796875], [104, 832, 155, 946, 0.68310546875], [104, 832, 155, 947, 0.67822265625], [105, 833, 155, 948, 0.6708984375], [105, 834, 155, 948, 0.66943359375], [105, 834, 155, 948, 0.66845703125], [108, 835, 164, 960, 0.642578125]]\n",
      "Key: 8s, vector len: 7, Card Detections: [[115, 851, 167, 969, 0.64990234375], [116, 851, 166, 968, 0.6494140625], [115, 849, 166, 968, 0.6484375], [115, 849, 167, 967, 0.6552734375], [115, 850, 167, 968, 0.65478515625], [115, 851, 167, 968, 0.65283203125], [118, 852, 168, 968, 0.64990234375]]\n",
      "Key: 9c, vector len: 7, Card Detections: [[120, 848, 173, 965, 0.68359375], [120, 849, 172, 965, 0.66552734375], [120, 849, 172, 966, 0.666015625], [120, 849, 172, 966, 0.6767578125], [119, 849, 171, 966, 0.6669921875], [119, 850, 171, 967, 0.65966796875], [120, 851, 171, 967, 0.65576171875]]\n",
      "Key: 9d, vector len: 11, Card Detections: [[471, 880, 520, 990, 0.634765625], [472, 879, 520, 989, 0.6376953125], [471, 880, 520, 991, 0.63623046875], [471, 880, 520, 992, 0.63330078125], [471, 880, 520, 992, 0.63623046875], [471, 880, 519, 992, 0.6328125], [471, 880, 519, 992, 0.63232421875], [471, 881, 519, 992, 0.63232421875], [471, 881, 519, 992, 0.630859375], [470, 881, 519, 993, 0.6298828125], [469, 883, 517, 993, 0.63037109375]]\n",
      "Key: 9h, vector len: 16, Card Detections: [[470, 878, 521, 990, 0.65966796875], [470, 878, 521, 989, 0.6630859375], [470, 878, 520, 991, 0.66162109375], [470, 878, 520, 991, 0.6611328125], [470, 879, 520, 991, 0.650390625], [470, 880, 520, 992, 0.66064453125], [470, 879, 520, 992, 0.65478515625], [470, 879, 520, 992, 0.65478515625], [470, 879, 520, 991, 0.65283203125], [469, 879, 520, 992, 0.65380859375], [469, 879, 520, 992, 0.6513671875], [469, 880, 519, 992, 0.65185546875], [469, 880, 519, 992, 0.64599609375], [468, 880, 519, 992, 0.64306640625], [468, 881, 518, 992, 0.6318359375], [467, 883, 517, 993, 0.63134765625]]\n",
      "Key: 9s, vector len: 12, Card Detections: [[106, 833, 158, 951, 0.69140625], [107, 833, 157, 952, 0.66650390625], [107, 833, 157, 951, 0.67626953125], [107, 833, 157, 951, 0.66845703125], [107, 833, 158, 952, 0.6728515625], [107, 834, 158, 952, 0.673828125], [107, 833, 158, 952, 0.673828125], [107, 834, 158, 953, 0.67333984375], [107, 834, 158, 953, 0.6728515625], [107, 834, 158, 953, 0.6708984375], [107, 834, 159, 954, 0.662109375], [108, 834, 159, 955, 0.65234375]]\n",
      "Key: Ac, vector len: 4, Card Detections: [[108, 841, 166, 962, 0.65576171875], [109, 841, 166, 961, 0.66064453125], [109, 840, 166, 960, 0.66015625], [109, 841, 167, 962, 0.6689453125]]\n",
      "Key: Ad, vector len: 9, Card Detections: [[473, 882, 522, 987, 0.650390625], [474, 883, 521, 988, 0.64794921875], [474, 882, 521, 988, 0.64794921875], [474, 883, 521, 989, 0.642578125], [473, 882, 521, 989, 0.64794921875], [473, 882, 521, 989, 0.6494140625], [473, 882, 521, 990, 0.65087890625], [472, 882, 521, 990, 0.64453125], [471, 885, 519, 990, 0.64404296875]]\n",
      "Key: Ah, vector len: 2, Card Detections: [[472, 882, 521, 986, 0.65869140625], [471, 882, 521, 987, 0.65478515625]]\n",
      "Key: As, vector len: 7, Card Detections: [[477, 873, 528, 985, 0.650390625], [477, 874, 528, 985, 0.64892578125], [477, 874, 528, 986, 0.65234375], [477, 874, 527, 986, 0.6494140625], [477, 874, 527, 987, 0.6494140625], [476, 875, 527, 987, 0.64697265625], [473, 879, 526, 988, 0.57861328125]]\n",
      "Key: Jc, vector len: 15, Card Detections: [[470, 878, 521, 990, 0.68408203125], [470, 878, 522, 989, 0.6845703125], [469, 878, 521, 990, 0.68798828125], [469, 879, 521, 991, 0.68505859375], [469, 879, 521, 992, 0.677734375], [469, 879, 521, 991, 0.67822265625], [469, 879, 521, 992, 0.6640625], [469, 880, 521, 992, 0.66650390625], [468, 880, 520, 992, 0.66943359375], [468, 881, 520, 993, 0.66162109375], [468, 881, 520, 993, 0.66455078125], [467, 881, 519, 993, 0.66259765625], [467, 881, 519, 993, 0.65966796875], [467, 882, 519, 994, 0.6533203125], [466, 884, 517, 995, 0.658203125]]\n",
      "Key: Jd, vector len: 17, Card Detections: [[93, 836, 148, 951, 0.67431640625], [92, 837, 145, 953, 0.640625], [92, 839, 144, 955, 0.63134765625], [91, 839, 144, 956, 0.626953125], [91, 840, 144, 956, 0.626953125], [90, 843, 143, 958, 0.63330078125], [90, 844, 143, 959, 0.63818359375], [90, 844, 143, 959, 0.64453125], [91, 845, 143, 961, 0.640625], [91, 845, 143, 961, 0.64208984375], [91, 846, 143, 962, 0.64453125], [91, 846, 143, 962, 0.64453125], [91, 847, 143, 963, 0.64501953125], [91, 848, 143, 965, 0.64306640625], [91, 849, 143, 965, 0.64599609375], [91, 850, 144, 966, 0.6416015625], [94, 857, 147, 969, 0.62890625]]\n",
      "Key: Jh, vector len: 111, Card Detections: [[88, 860, 141, 976, 0.6474609375], [88, 861, 140, 977, 0.630859375], [88, 861, 139, 977, 0.63232421875], [87, 862, 140, 978, 0.63232421875], [87, 863, 139, 979, 0.6337890625], [87, 863, 139, 980, 0.6279296875], [87, 864, 139, 980, 0.626953125], [87, 864, 139, 980, 0.626953125], [87, 864, 139, 980, 0.62646484375], [87, 864, 139, 980, 0.62548828125], [87, 864, 139, 980, 0.6259765625], [88, 864, 139, 980, 0.62890625], [88, 864, 140, 980, 0.6279296875], [87, 864, 140, 980, 0.6298828125], [87, 863, 139, 978, 0.62744140625], [87, 864, 138, 979, 0.62109375], [86, 864, 138, 979, 0.623046875], [86, 864, 138, 979, 0.62158203125], [86, 864, 139, 979, 0.62109375], [87, 864, 138, 979, 0.61962890625], [86, 865, 138, 980, 0.62060546875], [86, 865, 138, 980, 0.625], [87, 865, 138, 980, 0.62109375], [87, 865, 138, 980, 0.623046875], [87, 865, 138, 980, 0.62353515625], [87, 865, 138, 981, 0.62255859375], [87, 865, 138, 980, 0.623046875], [87, 865, 139, 980, 0.6240234375], [87, 865, 139, 980, 0.6240234375], [87, 865, 139, 980, 0.62353515625], [87, 865, 139, 980, 0.6240234375], [87, 865, 139, 980, 0.6328125], [87, 865, 139, 980, 0.63037109375], [87, 865, 139, 980, 0.6337890625], [87, 865, 139, 980, 0.62744140625], [88, 864, 139, 980, 0.623046875], [87, 864, 139, 979, 0.62255859375], [88, 863, 139, 979, 0.62109375], [87, 863, 139, 979, 0.623046875], [87, 863, 140, 979, 0.62548828125], [87, 862, 140, 979, 0.6240234375], [88, 861, 140, 978, 0.623046875], [88, 861, 140, 978, 0.6240234375], [88, 862, 140, 977, 0.626953125], [88, 861, 140, 976, 0.63525390625], [88, 861, 140, 976, 0.630859375], [88, 861, 140, 976, 0.63134765625], [88, 861, 140, 976, 0.6298828125], [88, 860, 140, 975, 0.6259765625], [88, 860, 140, 975, 0.62646484375], [88, 860, 140, 975, 0.62548828125], [88, 861, 140, 975, 0.62451171875], [88, 860, 140, 975, 0.62255859375], [88, 860, 140, 975, 0.62353515625], [88, 860, 140, 975, 0.62255859375], [88, 859, 140, 975, 0.6220703125], [88, 859, 140, 975, 0.62158203125], [88, 859, 141, 974, 0.6220703125], [88, 859, 141, 974, 0.623046875], [88, 859, 141, 973, 0.62451171875], [88, 859, 141, 973, 0.6259765625], [88, 859, 141, 973, 0.625], [88, 858, 141, 973, 0.6240234375], [88, 858, 141, 973, 0.62451171875], [88, 856, 140, 972, 0.6201171875], [88, 857, 140, 972, 0.6220703125], [88, 856, 141, 971, 0.62353515625], [88, 856, 141, 971, 0.623046875], [88, 855, 140, 971, 0.6259765625], [88, 855, 141, 971, 0.623046875], [88, 855, 141, 971, 0.62255859375], [88, 855, 141, 971, 0.62158203125], [88, 855, 141, 971, 0.62158203125], [88, 855, 141, 971, 0.62109375], [88, 855, 141, 971, 0.6240234375], [88, 855, 141, 971, 0.62548828125], [88, 855, 140, 970, 0.6259765625], [88, 855, 140, 970, 0.62451171875], [88, 854, 141, 970, 0.62353515625], [88, 854, 141, 970, 0.623046875], [88, 854, 141, 970, 0.62255859375], [88, 855, 141, 970, 0.62255859375], [88, 855, 141, 971, 0.62255859375], [88, 855, 141, 971, 0.6220703125], [88, 855, 141, 971, 0.62109375], [88, 855, 141, 971, 0.6220703125], [88, 855, 141, 971, 0.62353515625], [88, 855, 141, 971, 0.625], [88, 855, 141, 971, 0.62646484375], [88, 856, 142, 971, 0.6240234375], [88, 856, 142, 971, 0.62451171875], [89, 856, 141, 972, 0.62353515625], [89, 856, 141, 972, 0.6240234375], [89, 857, 142, 972, 0.626953125], [89, 857, 142, 973, 0.62841796875], [89, 858, 142, 973, 0.63134765625], [89, 858, 142, 973, 0.6318359375], [89, 859, 142, 973, 0.63134765625], [89, 859, 142, 973, 0.630859375], [89, 860, 142, 974, 0.6328125], [89, 860, 143, 974, 0.63134765625], [90, 860, 143, 974, 0.63330078125], [90, 860, 143, 974, 0.6337890625], [90, 861, 143, 975, 0.63427734375], [90, 861, 143, 974, 0.6328125], [91, 861, 143, 974, 0.6337890625], [91, 861, 143, 974, 0.634765625], [91, 862, 144, 975, 0.63623046875], [91, 862, 144, 975, 0.6337890625], [91, 863, 144, 975, 0.6337890625], [91, 864, 144, 976, 0.63134765625]]\n",
      "Key: Js, vector len: 15, Card Detections: [[474, 876, 525, 989, 0.6904296875], [474, 876, 524, 991, 0.68603515625], [474, 876, 524, 991, 0.68994140625], [474, 876, 524, 991, 0.6904296875], [474, 876, 524, 991, 0.693359375], [474, 876, 524, 991, 0.69287109375], [473, 876, 524, 992, 0.69287109375], [473, 877, 523, 992, 0.69189453125], [473, 877, 523, 992, 0.6923828125], [472, 876, 523, 992, 0.689453125], [472, 878, 523, 992, 0.689453125], [471, 877, 523, 992, 0.68212890625], [471, 878, 522, 993, 0.68603515625], [471, 879, 522, 992, 0.68115234375], [470, 880, 521, 993, 0.67431640625]]\n",
      "Key: Kc, vector len: 11, Card Detections: [[475, 868, 530, 982, 0.69873046875], [475, 869, 529, 985, 0.70263671875], [475, 869, 529, 986, 0.697265625], [475, 869, 530, 986, 0.6982421875], [474, 869, 529, 986, 0.69384765625], [474, 870, 529, 987, 0.70751953125], [474, 870, 528, 986, 0.697265625], [473, 871, 527, 986, 0.6953125], [473, 873, 527, 987, 0.705078125], [473, 872, 527, 987, 0.7021484375], [472, 873, 526, 987, 0.7099609375]]\n",
      "Key: Kd, vector len: 10, Card Detections: [[467, 880, 518, 979, 0.5234375], [109, 836, 163, 951, 0.646484375], [109, 836, 162, 951, 0.6435546875], [108, 836, 163, 953, 0.64404296875], [109, 837, 163, 952, 0.64697265625], [109, 838, 163, 952, 0.65966796875], [109, 838, 163, 953, 0.6640625], [109, 838, 163, 953, 0.666015625], [109, 840, 163, 954, 0.67333984375], [110, 840, 164, 955, 0.67138671875]]\n",
      "Key: Kh, vector len: 41, Card Detections: [[83, 855, 138, 969, 0.66357421875], [83, 855, 137, 969, 0.66357421875], [83, 855, 137, 969, 0.66650390625], [83, 855, 137, 970, 0.66650390625], [83, 856, 137, 970, 0.66552734375], [83, 857, 137, 971, 0.6650390625], [83, 857, 137, 972, 0.65966796875], [83, 857, 137, 972, 0.6591796875], [83, 857, 137, 971, 0.6572265625], [84, 857, 137, 971, 0.65673828125], [84, 857, 137, 970, 0.6611328125], [84, 857, 137, 970, 0.66259765625], [84, 856, 137, 969, 0.66455078125], [84, 856, 138, 969, 0.6640625], [85, 856, 138, 969, 0.66552734375], [85, 856, 138, 969, 0.66552734375], [85, 856, 138, 969, 0.6640625], [85, 856, 139, 969, 0.6650390625], [85, 856, 139, 969, 0.66357421875], [85, 856, 139, 969, 0.66162109375], [86, 855, 140, 969, 0.66015625], [86, 856, 140, 969, 0.66064453125], [86, 856, 140, 969, 0.65576171875], [87, 856, 141, 969, 0.65234375], [87, 857, 141, 970, 0.65478515625], [88, 858, 141, 970, 0.65478515625], [88, 858, 141, 971, 0.6513671875], [88, 858, 141, 971, 0.6513671875], [88, 860, 142, 972, 0.64990234375], [89, 860, 142, 972, 0.6513671875], [89, 861, 142, 973, 0.6494140625], [89, 862, 142, 973, 0.646484375], [89, 863, 143, 973, 0.6474609375], [89, 863, 143, 974, 0.64794921875], [89, 862, 143, 974, 0.64599609375], [89, 863, 143, 974, 0.6455078125], [90, 863, 143, 974, 0.64208984375], [90, 863, 143, 974, 0.6435546875], [90, 863, 143, 974, 0.64404296875], [90, 865, 143, 974, 0.634765625], [93, 873, 146, 977, 0.609375]]\n",
      "Key: Ks, vector len: 9, Card Detections: [[467, 881, 520, 989, 0.68798828125], [467, 881, 520, 991, 0.6884765625], [467, 881, 521, 991, 0.68359375], [467, 881, 520, 991, 0.6796875], [467, 881, 520, 991, 0.68310546875], [467, 881, 520, 991, 0.67822265625], [467, 882, 520, 990, 0.6845703125], [467, 883, 519, 990, 0.67626953125], [466, 886, 519, 991, 0.67236328125]]\n",
      "Key: Qc, vector len: 15, Card Detections: [[475, 875, 527, 988, 0.62841796875], [475, 876, 527, 989, 0.64013671875], [475, 876, 527, 989, 0.6240234375], [475, 876, 527, 989, 0.6318359375], [475, 876, 527, 989, 0.62451171875], [474, 876, 527, 990, 0.62890625], [474, 876, 526, 990, 0.62939453125], [474, 876, 527, 989, 0.63720703125], [474, 877, 526, 990, 0.63037109375], [474, 877, 526, 990, 0.6337890625], [474, 877, 526, 990, 0.63720703125], [473, 877, 526, 990, 0.650390625], [473, 877, 526, 990, 0.64892578125], [473, 878, 526, 990, 0.6494140625], [472, 880, 525, 990, 0.66357421875]]\n",
      "Key: Qd, vector len: 5, Card Detections: [[115, 843, 167, 958, 0.6015625], [115, 844, 167, 956, 0.60205078125], [115, 844, 167, 957, 0.60693359375], [115, 843, 167, 958, 0.61328125], [118, 839, 176, 972, 0.5576171875]]\n",
      "Key: Qh, vector len: 73, Card Detections: [[463, 889, 514, 985, 0.55029296875], [465, 889, 512, 998, 0.64501953125], [464, 890, 512, 1000, 0.62890625], [464, 890, 511, 999, 0.6220703125], [464, 890, 511, 999, 0.6318359375], [464, 890, 512, 999, 0.63525390625], [464, 890, 511, 999, 0.6318359375], [465, 890, 512, 999, 0.63623046875], [465, 890, 512, 999, 0.64111328125], [465, 889, 512, 999, 0.6396484375], [465, 889, 513, 999, 0.64306640625], [465, 889, 513, 999, 0.64794921875], [465, 889, 513, 998, 0.64306640625], [466, 889, 513, 998, 0.63916015625], [466, 889, 513, 998, 0.6435546875], [466, 889, 513, 998, 0.64208984375], [466, 889, 513, 998, 0.64404296875], [466, 889, 513, 998, 0.64404296875], [466, 889, 513, 998, 0.6455078125], [466, 889, 513, 998, 0.64501953125], [466, 889, 514, 998, 0.64404296875], [466, 889, 514, 998, 0.64501953125], [467, 890, 514, 998, 0.6435546875], [467, 890, 513, 998, 0.6435546875], [467, 890, 513, 998, 0.64404296875], [467, 890, 513, 998, 0.64404296875], [466, 889, 514, 998, 0.64453125], [466, 889, 513, 999, 0.64501953125], [466, 889, 513, 998, 0.64501953125], [466, 889, 513, 998, 0.642578125], [466, 889, 513, 999, 0.640625], [466, 889, 513, 999, 0.642578125], [466, 890, 513, 999, 0.640625], [466, 890, 513, 999, 0.64013671875], [465, 890, 513, 999, 0.64111328125], [465, 890, 513, 999, 0.64208984375], [466, 890, 513, 999, 0.6416015625], [466, 890, 513, 999, 0.6416015625], [466, 890, 513, 999, 0.64111328125], [465, 890, 513, 999, 0.64404296875], [465, 890, 513, 999, 0.64794921875], [465, 891, 512, 999, 0.6455078125], [465, 891, 512, 999, 0.64404296875], [465, 891, 512, 999, 0.6455078125], [465, 891, 512, 999, 0.6416015625], [465, 891, 512, 999, 0.63818359375], [465, 891, 512, 999, 0.640625], [465, 890, 512, 1000, 0.63623046875], [465, 890, 513, 999, 0.6455078125], [465, 891, 513, 1000, 0.64306640625], [465, 891, 513, 1000, 0.6435546875], [464, 891, 513, 1001, 0.6416015625], [464, 891, 513, 1000, 0.6396484375], [464, 891, 512, 1001, 0.6376953125], [464, 891, 512, 1000, 0.6376953125], [464, 890, 512, 1000, 0.63916015625], [464, 890, 512, 1000, 0.63916015625], [464, 891, 512, 1001, 0.59326171875], [464, 891, 512, 1001, 0.60595703125], [464, 891, 512, 1001, 0.6044921875], [463, 891, 512, 1001, 0.6171875], [463, 891, 512, 1001, 0.61669921875], [463, 891, 512, 1001, 0.611328125], [463, 891, 512, 1001, 0.6318359375], [463, 891, 511, 1001, 0.6376953125], [463, 891, 511, 1001, 0.6376953125], [462, 892, 511, 1001, 0.64697265625], [462, 892, 511, 1001, 0.64599609375], [462, 893, 511, 1001, 0.64599609375], [462, 893, 511, 1001, 0.63818359375], [461, 894, 511, 1001, 0.64453125], [458, 898, 508, 1005, 0.658203125], [456, 900, 507, 1007, 0.658203125]]\n",
      "Key: Qs, vector len: 11, Card Detections: [[110, 836, 163, 954, 0.60009765625], [110, 837, 163, 954, 0.61083984375], [110, 837, 163, 954, 0.59716796875], [110, 837, 164, 956, 0.60498046875], [110, 837, 163, 955, 0.60205078125], [111, 838, 163, 956, 0.61328125], [111, 838, 164, 957, 0.60693359375], [111, 839, 164, 958, 0.61669921875], [111, 839, 165, 958, 0.6181640625], [112, 839, 165, 958, 0.6298828125], [115, 844, 167, 961, 0.666015625]]\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 0, Card Detections: []\n",
      "X shape: (39, 3, 10)\n",
      "y shape: (39, 10)\n",
      "X_test : [[[    0.61876     0.35517         0.6     0.35756      0.6093     0.35647     0.19269           0     0.42857     0.60167]\n",
      "  [    0.62076     0.35172     0.60196     0.35756     0.61128     0.35489     0.19856           0     0.42857     0.54875]\n",
      "  [    0.62076     0.35172     0.60196     0.35756     0.61128     0.35489     0.19856           0     0.42857     0.54318]]\n",
      "\n",
      " [[     0.1976     0.25517     0.21373     0.35174     0.20574     0.30757     0.59116           0     0.42857     0.81058]\n",
      "  [     0.1976     0.25172     0.21373     0.34593     0.20574     0.30284     0.58318           0     0.42857      0.7883]\n",
      "  [     0.2016     0.24828     0.21765     0.34593     0.20969     0.30126     0.59116           0     0.42857      0.8468]]\n",
      "\n",
      " [[    0.26747           0     0.24118           0      0.2542           0   0.0048135           0     0.42857     0.98886]\n",
      "  [    0.26747   0.0034483     0.24118    0.002907      0.2542   0.0031546   0.0048135    0.067963     0.71429     0.96379]\n",
      "  [    0.26747   0.0034483     0.24118    0.002907      0.2542   0.0031546   0.0048135           0     0.42857     0.98607]]\n",
      "\n",
      " [[     0.2994     0.16897     0.31765      0.2907     0.30861     0.23502     0.65854    0.096114     0.28571     0.87187]\n",
      "  [     0.2994     0.16552     0.31765     0.28779     0.30861     0.23186     0.65854    0.067963     0.14286     0.82451]\n",
      "  [     0.3014     0.16207     0.31765     0.28779     0.30959     0.23028     0.64892    0.048057     0.28571     0.83565]]\n",
      "\n",
      " [[    0.18363    0.082759     0.19412     0.21221     0.18892       0.153     0.55475           0     0.42857     0.93315]\n",
      "  [    0.18363    0.082759     0.19412     0.21802     0.18892     0.15615      0.5698           0     0.42857     0.91086]\n",
      "  [    0.18164    0.082759     0.19608     0.21512     0.18892     0.15457     0.59747           0     0.42857     0.93872]]\n",
      "\n",
      " [[    0.99601           1           1     0.99709     0.99802     0.99842     0.65704    0.067963     0.71429     0.77159]\n",
      "  [      0.998           1     0.99804           1     0.99802           1     0.62876    0.033981     0.71429     0.77437]\n",
      "  [          1           1           1           1           1           1     0.62876    0.067963     0.42857     0.79109]]\n",
      "\n",
      " [[    0.95808     0.28276     0.96078     0.35174     0.95945     0.32019     0.52738           0     0.42857     0.83844]\n",
      "  [    0.95808     0.27931     0.95882     0.34593     0.95846     0.31546     0.50361           0     0.42857     0.84401]\n",
      "  [    0.95808     0.27931     0.95882     0.34884     0.95846     0.31703     0.51143           0     0.42857     0.83565]]\n",
      "\n",
      " [[    0.23353      0.8931     0.26471      0.9186     0.24926     0.90694      0.8201           0     0.42857     0.70474]\n",
      "  [    0.23752      0.9069     0.26078     0.92733     0.24926     0.91798     0.73691           0     0.42857     0.73259]\n",
      "  [    0.23752     0.91379     0.25882     0.92733     0.24827     0.92114     0.70156           0     0.42857     0.76323]]], y_test: [[    0.61323     0.36678     0.59136     0.36152     0.60218     0.36392     0.21588      0.8177     0.86925     0.25641]\n",
      " [     0.1984     0.24221     0.21807     0.34111     0.20833     0.29589     0.84514     0.17201     0.22719     0.58974]\n",
      " [    0.26453   0.0034602     0.23969           0     0.25198   0.0015823           0    0.076923     0.71429     0.97436]\n",
      " [    0.29659     0.15571     0.31631     0.29155     0.30655     0.22943     0.96092     0.10879     0.85714     0.58974]\n",
      " [    0.17836    0.079585     0.19646     0.21283      0.1875      0.1519     0.85455    0.076923     0.42857     0.84615]\n",
      " [          1           1     0.99804           1     0.99901           1     0.84828    0.076923           1      0.4188]\n",
      " [    0.95792     0.27682     0.95874     0.34694     0.95833     0.31487     0.71055           0     0.42857      0.5812]\n",
      " [    0.23246     0.92042     0.25737     0.93294     0.24504     0.92722           1     0.31716     0.75885     0.33333]]\n",
      "Original X_train shape: (31, 3, 10), num_samples: 31, sequence_length: 3, num_features: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'attention_3' (of type Attention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">546,816</span> │ masking_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ any_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │ any_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ any_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_10… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │ any_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ any_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_11… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_3 (\u001b[38;5;33mMasking\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_9 (\u001b[38;5;33mAny\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │    \u001b[38;5;34m546,816\u001b[0m │ masking_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ any_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ bidirectional_9[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,048\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │ any_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m656,384\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ any_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ bidirectional_10… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,024\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │ any_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m164,352\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ any_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ bidirectional_11… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m131\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m4,128\u001b[0m │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m330\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,213</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,375,213\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,373,677</span> (5.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,373,677\u001b[0m (5.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.1935 - loss: 0.2456\n",
      "Epoch 1: val_loss improved from inf to 0.33383, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.1935 - loss: 0.2456 - val_accuracy: 0.6250 - val_loss: 0.3338 - learning_rate: 5.0000e-04\n",
      "Epoch 2/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1613 - loss: 0.2245\n",
      "Epoch 2: val_loss improved from 0.33383 to 0.33095, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1613 - loss: 0.2245 - val_accuracy: 0.6250 - val_loss: 0.3310 - learning_rate: 5.0000e-04\n",
      "Epoch 3/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4194 - loss: 0.2086\n",
      "Epoch 3: val_loss improved from 0.33095 to 0.32833, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4194 - loss: 0.2086 - val_accuracy: 0.6250 - val_loss: 0.3283 - learning_rate: 5.0000e-04\n",
      "Epoch 4/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2903 - loss: 0.1886\n",
      "Epoch 4: val_loss improved from 0.32833 to 0.32562, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2903 - loss: 0.1886 - val_accuracy: 0.5000 - val_loss: 0.3256 - learning_rate: 5.0000e-04\n",
      "Epoch 5/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3548 - loss: 0.1690\n",
      "Epoch 5: val_loss improved from 0.32562 to 0.32299, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3548 - loss: 0.1690 - val_accuracy: 0.5000 - val_loss: 0.3230 - learning_rate: 5.0000e-04\n",
      "Epoch 6/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3871 - loss: 0.1513\n",
      "Epoch 6: val_loss improved from 0.32299 to 0.32027, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3871 - loss: 0.1513 - val_accuracy: 0.5000 - val_loss: 0.3203 - learning_rate: 5.0000e-04\n",
      "Epoch 7/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5484 - loss: 0.1397\n",
      "Epoch 7: val_loss improved from 0.32027 to 0.31755, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5484 - loss: 0.1397 - val_accuracy: 0.5000 - val_loss: 0.3176 - learning_rate: 5.0000e-04\n",
      "Epoch 8/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4839 - loss: 0.1374\n",
      "Epoch 8: val_loss improved from 0.31755 to 0.31489, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4839 - loss: 0.1374 - val_accuracy: 0.5000 - val_loss: 0.3149 - learning_rate: 5.0000e-04\n",
      "Epoch 9/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4516 - loss: 0.1346\n",
      "Epoch 9: val_loss improved from 0.31489 to 0.31215, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4516 - loss: 0.1346 - val_accuracy: 0.5000 - val_loss: 0.3122 - learning_rate: 5.0000e-04\n",
      "Epoch 10/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4839 - loss: 0.1157\n",
      "Epoch 10: val_loss improved from 0.31215 to 0.30939, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4839 - loss: 0.1157 - val_accuracy: 0.5000 - val_loss: 0.3094 - learning_rate: 5.0000e-04\n",
      "Epoch 11/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4839 - loss: 0.1133\n",
      "Epoch 11: val_loss improved from 0.30939 to 0.30660, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4839 - loss: 0.1133 - val_accuracy: 0.5000 - val_loss: 0.3066 - learning_rate: 5.0000e-04\n",
      "Epoch 12/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5161 - loss: 0.1033\n",
      "Epoch 12: val_loss improved from 0.30660 to 0.30393, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5161 - loss: 0.1033 - val_accuracy: 0.5000 - val_loss: 0.3039 - learning_rate: 5.0000e-04\n",
      "Epoch 13/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4194 - loss: 0.1001\n",
      "Epoch 13: val_loss improved from 0.30393 to 0.30134, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4194 - loss: 0.1001 - val_accuracy: 0.5000 - val_loss: 0.3013 - learning_rate: 5.0000e-04\n",
      "Epoch 14/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3548 - loss: 0.0885\n",
      "Epoch 14: val_loss improved from 0.30134 to 0.29881, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3548 - loss: 0.0885 - val_accuracy: 0.5000 - val_loss: 0.2988 - learning_rate: 5.0000e-04\n",
      "Epoch 15/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4839 - loss: 0.0817\n",
      "Epoch 15: val_loss improved from 0.29881 to 0.29636, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4839 - loss: 0.0817 - val_accuracy: 0.5000 - val_loss: 0.2964 - learning_rate: 5.0000e-04\n",
      "Epoch 16/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5161 - loss: 0.0806\n",
      "Epoch 16: val_loss improved from 0.29636 to 0.29407, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5161 - loss: 0.0806 - val_accuracy: 0.5000 - val_loss: 0.2941 - learning_rate: 5.0000e-04\n",
      "Epoch 17/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4839 - loss: 0.0776\n",
      "Epoch 17: val_loss improved from 0.29407 to 0.29186, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4839 - loss: 0.0776 - val_accuracy: 0.5000 - val_loss: 0.2919 - learning_rate: 5.0000e-04\n",
      "Epoch 18/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5806 - loss: 0.0708\n",
      "Epoch 18: val_loss improved from 0.29186 to 0.28967, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5806 - loss: 0.0708 - val_accuracy: 0.5000 - val_loss: 0.2897 - learning_rate: 5.0000e-04\n",
      "Epoch 19/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5161 - loss: 0.0642\n",
      "Epoch 19: val_loss improved from 0.28967 to 0.28764, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5161 - loss: 0.0642 - val_accuracy: 0.5000 - val_loss: 0.2876 - learning_rate: 5.0000e-04\n",
      "Epoch 20/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6452 - loss: 0.0655\n",
      "Epoch 20: val_loss improved from 0.28764 to 0.28569, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6452 - loss: 0.0655 - val_accuracy: 0.5000 - val_loss: 0.2857 - learning_rate: 5.0000e-04\n",
      "Epoch 21/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4839 - loss: 0.0606\n",
      "Epoch 21: val_loss improved from 0.28569 to 0.28384, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4839 - loss: 0.0606 - val_accuracy: 0.5000 - val_loss: 0.2838 - learning_rate: 5.0000e-04\n",
      "Epoch 22/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5484 - loss: 0.0542\n",
      "Epoch 22: val_loss improved from 0.28384 to 0.28202, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5484 - loss: 0.0542 - val_accuracy: 0.5000 - val_loss: 0.2820 - learning_rate: 5.0000e-04\n",
      "Epoch 23/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4839 - loss: 0.0576\n",
      "Epoch 23: val_loss improved from 0.28202 to 0.28031, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4839 - loss: 0.0576 - val_accuracy: 0.5000 - val_loss: 0.2803 - learning_rate: 5.0000e-04\n",
      "Epoch 24/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6129 - loss: 0.0570\n",
      "Epoch 24: val_loss improved from 0.28031 to 0.27867, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6129 - loss: 0.0570 - val_accuracy: 0.5000 - val_loss: 0.2787 - learning_rate: 5.0000e-04\n",
      "Epoch 25/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5161 - loss: 0.0557\n",
      "Epoch 25: val_loss improved from 0.27867 to 0.27711, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5161 - loss: 0.0557 - val_accuracy: 0.5000 - val_loss: 0.2771 - learning_rate: 5.0000e-04\n",
      "Epoch 26/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5161 - loss: 0.0512\n",
      "Epoch 26: val_loss improved from 0.27711 to 0.27556, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5161 - loss: 0.0512 - val_accuracy: 0.5000 - val_loss: 0.2756 - learning_rate: 5.0000e-04\n",
      "Epoch 27/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5484 - loss: 0.0456\n",
      "Epoch 27: val_loss improved from 0.27556 to 0.27423, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5484 - loss: 0.0456 - val_accuracy: 0.5000 - val_loss: 0.2742 - learning_rate: 5.0000e-04\n",
      "Epoch 28/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5806 - loss: 0.0471\n",
      "Epoch 28: val_loss improved from 0.27423 to 0.27298, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5806 - loss: 0.0471 - val_accuracy: 0.5000 - val_loss: 0.2730 - learning_rate: 5.0000e-04\n",
      "Epoch 29/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4516 - loss: 0.0520\n",
      "Epoch 29: val_loss improved from 0.27298 to 0.27196, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4516 - loss: 0.0520 - val_accuracy: 0.5000 - val_loss: 0.2720 - learning_rate: 5.0000e-04\n",
      "Epoch 30/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5806 - loss: 0.0398\n",
      "Epoch 30: val_loss improved from 0.27196 to 0.27101, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5806 - loss: 0.0398 - val_accuracy: 0.5000 - val_loss: 0.2710 - learning_rate: 5.0000e-04\n",
      "Epoch 31/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7097 - loss: 0.0405\n",
      "Epoch 31: val_loss improved from 0.27101 to 0.27027, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7097 - loss: 0.0405 - val_accuracy: 0.5000 - val_loss: 0.2703 - learning_rate: 5.0000e-04\n",
      "Epoch 32/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5484 - loss: 0.0439\n",
      "Epoch 32: val_loss improved from 0.27027 to 0.26963, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5484 - loss: 0.0439 - val_accuracy: 0.5000 - val_loss: 0.2696 - learning_rate: 5.0000e-04\n",
      "Epoch 33/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4516 - loss: 0.0382\n",
      "Epoch 33: val_loss improved from 0.26963 to 0.26912, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4516 - loss: 0.0382 - val_accuracy: 0.5000 - val_loss: 0.2691 - learning_rate: 5.0000e-04\n",
      "Epoch 34/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5484 - loss: 0.0364\n",
      "Epoch 34: val_loss improved from 0.26912 to 0.26868, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5484 - loss: 0.0364 - val_accuracy: 0.6250 - val_loss: 0.2687 - learning_rate: 5.0000e-04\n",
      "Epoch 35/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5161 - loss: 0.0396\n",
      "Epoch 35: val_loss improved from 0.26868 to 0.26827, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5161 - loss: 0.0396 - val_accuracy: 0.6250 - val_loss: 0.2683 - learning_rate: 5.0000e-04\n",
      "Epoch 36/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5806 - loss: 0.0336\n",
      "Epoch 36: val_loss improved from 0.26827 to 0.26773, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5806 - loss: 0.0336 - val_accuracy: 0.6250 - val_loss: 0.2677 - learning_rate: 5.0000e-04\n",
      "Epoch 37/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5484 - loss: 0.0361\n",
      "Epoch 37: val_loss improved from 0.26773 to 0.26721, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5484 - loss: 0.0361 - val_accuracy: 0.6250 - val_loss: 0.2672 - learning_rate: 5.0000e-04\n",
      "Epoch 38/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5161 - loss: 0.0347\n",
      "Epoch 38: val_loss improved from 0.26721 to 0.26670, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5161 - loss: 0.0347 - val_accuracy: 0.6250 - val_loss: 0.2667 - learning_rate: 5.0000e-04\n",
      "Epoch 39/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5806 - loss: 0.0290\n",
      "Epoch 39: val_loss improved from 0.26670 to 0.26624, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5806 - loss: 0.0290 - val_accuracy: 0.6250 - val_loss: 0.2662 - learning_rate: 5.0000e-04\n",
      "Epoch 40/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6452 - loss: 0.0388\n",
      "Epoch 40: val_loss improved from 0.26624 to 0.26584, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6452 - loss: 0.0388 - val_accuracy: 0.6250 - val_loss: 0.2658 - learning_rate: 5.0000e-04\n",
      "Epoch 41/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6774 - loss: 0.0336\n",
      "Epoch 41: val_loss improved from 0.26584 to 0.26542, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0336 - val_accuracy: 0.6250 - val_loss: 0.2654 - learning_rate: 5.0000e-04\n",
      "Epoch 42/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4839 - loss: 0.0318\n",
      "Epoch 42: val_loss improved from 0.26542 to 0.26502, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4839 - loss: 0.0318 - val_accuracy: 0.6250 - val_loss: 0.2650 - learning_rate: 5.0000e-04\n",
      "Epoch 43/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6452 - loss: 0.0299\n",
      "Epoch 43: val_loss improved from 0.26502 to 0.26466, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0299 - val_accuracy: 0.6250 - val_loss: 0.2647 - learning_rate: 5.0000e-04\n",
      "Epoch 44/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5484 - loss: 0.0296\n",
      "Epoch 44: val_loss improved from 0.26466 to 0.26414, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5484 - loss: 0.0296 - val_accuracy: 0.6250 - val_loss: 0.2641 - learning_rate: 5.0000e-04\n",
      "Epoch 45/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4839 - loss: 0.0313\n",
      "Epoch 45: val_loss improved from 0.26414 to 0.26351, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4839 - loss: 0.0313 - val_accuracy: 0.6250 - val_loss: 0.2635 - learning_rate: 5.0000e-04\n",
      "Epoch 46/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5161 - loss: 0.0288\n",
      "Epoch 46: val_loss improved from 0.26351 to 0.26284, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5161 - loss: 0.0288 - val_accuracy: 0.6250 - val_loss: 0.2628 - learning_rate: 5.0000e-04\n",
      "Epoch 47/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6129 - loss: 0.0259\n",
      "Epoch 47: val_loss improved from 0.26284 to 0.26207, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.6129 - loss: 0.0259 - val_accuracy: 0.6250 - val_loss: 0.2621 - learning_rate: 5.0000e-04\n",
      "Epoch 48/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4839 - loss: 0.0287\n",
      "Epoch 48: val_loss improved from 0.26207 to 0.26120, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4839 - loss: 0.0287 - val_accuracy: 0.6250 - val_loss: 0.2612 - learning_rate: 5.0000e-04\n",
      "Epoch 49/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6129 - loss: 0.0233\n",
      "Epoch 49: val_loss improved from 0.26120 to 0.26016, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6129 - loss: 0.0233 - val_accuracy: 0.6250 - val_loss: 0.2602 - learning_rate: 5.0000e-04\n",
      "Epoch 50/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6452 - loss: 0.0264\n",
      "Epoch 50: val_loss improved from 0.26016 to 0.25910, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0264 - val_accuracy: 0.6250 - val_loss: 0.2591 - learning_rate: 5.0000e-04\n",
      "Epoch 51/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5161 - loss: 0.0287\n",
      "Epoch 51: val_loss improved from 0.25910 to 0.25806, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5161 - loss: 0.0287 - val_accuracy: 0.6250 - val_loss: 0.2581 - learning_rate: 5.0000e-04\n",
      "Epoch 52/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3548 - loss: 0.0324\n",
      "Epoch 52: val_loss improved from 0.25806 to 0.25724, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3548 - loss: 0.0324 - val_accuracy: 0.6250 - val_loss: 0.2572 - learning_rate: 5.0000e-04\n",
      "Epoch 53/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0240\n",
      "Epoch 53: val_loss improved from 0.25724 to 0.25642, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6129 - loss: 0.0240 - val_accuracy: 0.6250 - val_loss: 0.2564 - learning_rate: 5.0000e-04\n",
      "Epoch 54/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5806 - loss: 0.0293\n",
      "Epoch 54: val_loss improved from 0.25642 to 0.25578, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5806 - loss: 0.0293 - val_accuracy: 0.6250 - val_loss: 0.2558 - learning_rate: 5.0000e-04\n",
      "Epoch 55/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4839 - loss: 0.0229\n",
      "Epoch 55: val_loss improved from 0.25578 to 0.25537, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4839 - loss: 0.0229 - val_accuracy: 0.6250 - val_loss: 0.2554 - learning_rate: 5.0000e-04\n",
      "Epoch 56/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5484 - loss: 0.0287\n",
      "Epoch 56: val_loss improved from 0.25537 to 0.25488, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5484 - loss: 0.0287 - val_accuracy: 0.6250 - val_loss: 0.2549 - learning_rate: 5.0000e-04\n",
      "Epoch 57/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5484 - loss: 0.0252\n",
      "Epoch 57: val_loss improved from 0.25488 to 0.25446, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5484 - loss: 0.0252 - val_accuracy: 0.6250 - val_loss: 0.2545 - learning_rate: 5.0000e-04\n",
      "Epoch 58/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5484 - loss: 0.0261\n",
      "Epoch 58: val_loss improved from 0.25446 to 0.25403, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5484 - loss: 0.0261 - val_accuracy: 0.6250 - val_loss: 0.2540 - learning_rate: 5.0000e-04\n",
      "Epoch 59/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5484 - loss: 0.0266\n",
      "Epoch 59: val_loss improved from 0.25403 to 0.25350, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5484 - loss: 0.0266 - val_accuracy: 0.6250 - val_loss: 0.2535 - learning_rate: 5.0000e-04\n",
      "Epoch 60/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4839 - loss: 0.0244\n",
      "Epoch 60: val_loss improved from 0.25350 to 0.25297, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.4839 - loss: 0.0244 - val_accuracy: 0.6250 - val_loss: 0.2530 - learning_rate: 5.0000e-04\n",
      "Epoch 61/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5161 - loss: 0.0251\n",
      "Epoch 61: val_loss improved from 0.25297 to 0.25248, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5161 - loss: 0.0251 - val_accuracy: 0.6250 - val_loss: 0.2525 - learning_rate: 5.0000e-04\n",
      "Epoch 62/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5161 - loss: 0.0245\n",
      "Epoch 62: val_loss improved from 0.25248 to 0.25212, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5161 - loss: 0.0245 - val_accuracy: 0.6250 - val_loss: 0.2521 - learning_rate: 5.0000e-04\n",
      "Epoch 63/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6129 - loss: 0.0238\n",
      "Epoch 63: val_loss improved from 0.25212 to 0.25180, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6129 - loss: 0.0238 - val_accuracy: 0.6250 - val_loss: 0.2518 - learning_rate: 5.0000e-04\n",
      "Epoch 64/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5484 - loss: 0.0245\n",
      "Epoch 64: val_loss improved from 0.25180 to 0.25148, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5484 - loss: 0.0245 - val_accuracy: 0.6250 - val_loss: 0.2515 - learning_rate: 5.0000e-04\n",
      "Epoch 65/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6452 - loss: 0.0269\n",
      "Epoch 65: val_loss improved from 0.25148 to 0.25125, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6452 - loss: 0.0269 - val_accuracy: 0.6250 - val_loss: 0.2513 - learning_rate: 5.0000e-04\n",
      "Epoch 66/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6452 - loss: 0.0239\n",
      "Epoch 66: val_loss improved from 0.25125 to 0.25111, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6452 - loss: 0.0239 - val_accuracy: 0.6250 - val_loss: 0.2511 - learning_rate: 5.0000e-04\n",
      "Epoch 67/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5806 - loss: 0.0228\n",
      "Epoch 67: val_loss improved from 0.25111 to 0.25104, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5806 - loss: 0.0228 - val_accuracy: 0.6250 - val_loss: 0.2510 - learning_rate: 5.0000e-04\n",
      "Epoch 68/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5161 - loss: 0.0228\n",
      "Epoch 68: val_loss did not improve from 0.25104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5161 - loss: 0.0228 - val_accuracy: 0.6250 - val_loss: 0.2511 - learning_rate: 5.0000e-04\n",
      "Epoch 69/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5161 - loss: 0.0222\n",
      "Epoch 69: val_loss improved from 0.25104 to 0.25096, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5161 - loss: 0.0222 - val_accuracy: 0.6250 - val_loss: 0.2510 - learning_rate: 5.0000e-04\n",
      "Epoch 70/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6129 - loss: 0.0234\n",
      "Epoch 70: val_loss improved from 0.25096 to 0.25071, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0234 - val_accuracy: 0.6250 - val_loss: 0.2507 - learning_rate: 5.0000e-04\n",
      "Epoch 71/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5161 - loss: 0.0221\n",
      "Epoch 71: val_loss improved from 0.25071 to 0.25038, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5161 - loss: 0.0221 - val_accuracy: 0.6250 - val_loss: 0.2504 - learning_rate: 5.0000e-04\n",
      "Epoch 72/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5806 - loss: 0.0223\n",
      "Epoch 72: val_loss improved from 0.25038 to 0.24991, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5806 - loss: 0.0223 - val_accuracy: 0.6250 - val_loss: 0.2499 - learning_rate: 5.0000e-04\n",
      "Epoch 73/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5484 - loss: 0.0205\n",
      "Epoch 73: val_loss improved from 0.24991 to 0.24943, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5484 - loss: 0.0205 - val_accuracy: 0.6250 - val_loss: 0.2494 - learning_rate: 5.0000e-04\n",
      "Epoch 74/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6129 - loss: 0.0187\n",
      "Epoch 74: val_loss improved from 0.24943 to 0.24902, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6129 - loss: 0.0187 - val_accuracy: 0.6250 - val_loss: 0.2490 - learning_rate: 5.0000e-04\n",
      "Epoch 75/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6129 - loss: 0.0193\n",
      "Epoch 75: val_loss improved from 0.24902 to 0.24866, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6129 - loss: 0.0193 - val_accuracy: 0.6250 - val_loss: 0.2487 - learning_rate: 5.0000e-04\n",
      "Epoch 76/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4516 - loss: 0.0239\n",
      "Epoch 76: val_loss improved from 0.24866 to 0.24813, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4516 - loss: 0.0239 - val_accuracy: 0.6250 - val_loss: 0.2481 - learning_rate: 5.0000e-04\n",
      "Epoch 77/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5484 - loss: 0.0194\n",
      "Epoch 77: val_loss improved from 0.24813 to 0.24771, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5484 - loss: 0.0194 - val_accuracy: 0.6250 - val_loss: 0.2477 - learning_rate: 5.0000e-04\n",
      "Epoch 78/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4839 - loss: 0.0224\n",
      "Epoch 78: val_loss improved from 0.24771 to 0.24737, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4839 - loss: 0.0224 - val_accuracy: 0.6250 - val_loss: 0.2474 - learning_rate: 5.0000e-04\n",
      "Epoch 79/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6129 - loss: 0.0212\n",
      "Epoch 79: val_loss improved from 0.24737 to 0.24702, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6129 - loss: 0.0212 - val_accuracy: 0.6250 - val_loss: 0.2470 - learning_rate: 5.0000e-04\n",
      "Epoch 80/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6452 - loss: 0.0250\n",
      "Epoch 80: val_loss improved from 0.24702 to 0.24673, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6452 - loss: 0.0250 - val_accuracy: 0.6250 - val_loss: 0.2467 - learning_rate: 5.0000e-04\n",
      "Epoch 81/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5161 - loss: 0.0199\n",
      "Epoch 81: val_loss improved from 0.24673 to 0.24644, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5161 - loss: 0.0199 - val_accuracy: 0.6250 - val_loss: 0.2464 - learning_rate: 5.0000e-04\n",
      "Epoch 82/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4516 - loss: 0.0218\n",
      "Epoch 82: val_loss improved from 0.24644 to 0.24625, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4516 - loss: 0.0218 - val_accuracy: 0.6250 - val_loss: 0.2463 - learning_rate: 5.0000e-04\n",
      "Epoch 83/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5806 - loss: 0.0200\n",
      "Epoch 83: val_loss improved from 0.24625 to 0.24606, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5806 - loss: 0.0200 - val_accuracy: 0.6250 - val_loss: 0.2461 - learning_rate: 5.0000e-04\n",
      "Epoch 84/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6129 - loss: 0.0182\n",
      "Epoch 84: val_loss improved from 0.24606 to 0.24593, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6129 - loss: 0.0182 - val_accuracy: 0.6250 - val_loss: 0.2459 - learning_rate: 5.0000e-04\n",
      "Epoch 85/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5161 - loss: 0.0200\n",
      "Epoch 85: val_loss improved from 0.24593 to 0.24579, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5161 - loss: 0.0200 - val_accuracy: 0.6250 - val_loss: 0.2458 - learning_rate: 5.0000e-04\n",
      "Epoch 86/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5484 - loss: 0.0203\n",
      "Epoch 86: val_loss improved from 0.24579 to 0.24534, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5484 - loss: 0.0203 - val_accuracy: 0.6250 - val_loss: 0.2453 - learning_rate: 5.0000e-04\n",
      "Epoch 87/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7097 - loss: 0.0183\n",
      "Epoch 87: val_loss improved from 0.24534 to 0.24487, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7097 - loss: 0.0183 - val_accuracy: 0.6250 - val_loss: 0.2449 - learning_rate: 5.0000e-04\n",
      "Epoch 88/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5161 - loss: 0.0198\n",
      "Epoch 88: val_loss improved from 0.24487 to 0.24412, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5161 - loss: 0.0198 - val_accuracy: 0.6250 - val_loss: 0.2441 - learning_rate: 5.0000e-04\n",
      "Epoch 89/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6452 - loss: 0.0192\n",
      "Epoch 89: val_loss improved from 0.24412 to 0.24341, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6452 - loss: 0.0192 - val_accuracy: 0.6250 - val_loss: 0.2434 - learning_rate: 5.0000e-04\n",
      "Epoch 90/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6452 - loss: 0.0195\n",
      "Epoch 90: val_loss improved from 0.24341 to 0.24270, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6452 - loss: 0.0195 - val_accuracy: 0.5000 - val_loss: 0.2427 - learning_rate: 5.0000e-04\n",
      "Epoch 91/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6452 - loss: 0.0206\n",
      "Epoch 91: val_loss improved from 0.24270 to 0.24202, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6452 - loss: 0.0206 - val_accuracy: 0.5000 - val_loss: 0.2420 - learning_rate: 5.0000e-04\n",
      "Epoch 92/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5806 - loss: 0.0240\n",
      "Epoch 92: val_loss improved from 0.24202 to 0.24133, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5806 - loss: 0.0240 - val_accuracy: 0.5000 - val_loss: 0.2413 - learning_rate: 5.0000e-04\n",
      "Epoch 93/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5484 - loss: 0.0181\n",
      "Epoch 93: val_loss improved from 0.24133 to 0.24047, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5484 - loss: 0.0181 - val_accuracy: 0.5000 - val_loss: 0.2405 - learning_rate: 5.0000e-04\n",
      "Epoch 94/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6452 - loss: 0.0178\n",
      "Epoch 94: val_loss improved from 0.24047 to 0.23969, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0178 - val_accuracy: 0.5000 - val_loss: 0.2397 - learning_rate: 5.0000e-04\n",
      "Epoch 95/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5806 - loss: 0.0197\n",
      "Epoch 95: val_loss improved from 0.23969 to 0.23919, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5806 - loss: 0.0197 - val_accuracy: 0.5000 - val_loss: 0.2392 - learning_rate: 5.0000e-04\n",
      "Epoch 96/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0220\n",
      "Epoch 96: val_loss improved from 0.23919 to 0.23871, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5484 - loss: 0.0220 - val_accuracy: 0.5000 - val_loss: 0.2387 - learning_rate: 5.0000e-04\n",
      "Epoch 97/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5806 - loss: 0.0171\n",
      "Epoch 97: val_loss improved from 0.23871 to 0.23844, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5806 - loss: 0.0171 - val_accuracy: 0.5000 - val_loss: 0.2384 - learning_rate: 5.0000e-04\n",
      "Epoch 98/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5484 - loss: 0.0183\n",
      "Epoch 98: val_loss improved from 0.23844 to 0.23818, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5484 - loss: 0.0183 - val_accuracy: 0.5000 - val_loss: 0.2382 - learning_rate: 5.0000e-04\n",
      "Epoch 99/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6129 - loss: 0.0169\n",
      "Epoch 99: val_loss improved from 0.23818 to 0.23801, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0169 - val_accuracy: 0.5000 - val_loss: 0.2380 - learning_rate: 5.0000e-04\n",
      "Epoch 100/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0186\n",
      "Epoch 100: val_loss improved from 0.23801 to 0.23794, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6129 - loss: 0.0186 - val_accuracy: 0.5000 - val_loss: 0.2379 - learning_rate: 5.0000e-04\n",
      "Epoch 101/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0165\n",
      "Epoch 101: val_loss improved from 0.23794 to 0.23771, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6452 - loss: 0.0165 - val_accuracy: 0.5000 - val_loss: 0.2377 - learning_rate: 5.0000e-04\n",
      "Epoch 102/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0171\n",
      "Epoch 102: val_loss improved from 0.23771 to 0.23741, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5806 - loss: 0.0171 - val_accuracy: 0.5000 - val_loss: 0.2374 - learning_rate: 5.0000e-04\n",
      "Epoch 103/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0164\n",
      "Epoch 103: val_loss improved from 0.23741 to 0.23723, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0164 - val_accuracy: 0.5000 - val_loss: 0.2372 - learning_rate: 5.0000e-04\n",
      "Epoch 104/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4839 - loss: 0.0174\n",
      "Epoch 104: val_loss improved from 0.23723 to 0.23695, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.4839 - loss: 0.0174 - val_accuracy: 0.5000 - val_loss: 0.2369 - learning_rate: 5.0000e-04\n",
      "Epoch 105/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5484 - loss: 0.0182\n",
      "Epoch 105: val_loss improved from 0.23695 to 0.23654, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5484 - loss: 0.0182 - val_accuracy: 0.5000 - val_loss: 0.2365 - learning_rate: 5.0000e-04\n",
      "Epoch 106/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0172\n",
      "Epoch 106: val_loss improved from 0.23654 to 0.23597, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5484 - loss: 0.0172 - val_accuracy: 0.5000 - val_loss: 0.2360 - learning_rate: 5.0000e-04\n",
      "Epoch 107/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0175\n",
      "Epoch 107: val_loss improved from 0.23597 to 0.23526, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5484 - loss: 0.0175 - val_accuracy: 0.5000 - val_loss: 0.2353 - learning_rate: 5.0000e-04\n",
      "Epoch 108/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0170\n",
      "Epoch 108: val_loss improved from 0.23526 to 0.23452, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7097 - loss: 0.0170 - val_accuracy: 0.5000 - val_loss: 0.2345 - learning_rate: 5.0000e-04\n",
      "Epoch 109/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0198\n",
      "Epoch 109: val_loss improved from 0.23452 to 0.23376, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5806 - loss: 0.0198 - val_accuracy: 0.5000 - val_loss: 0.2338 - learning_rate: 5.0000e-04\n",
      "Epoch 110/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0154\n",
      "Epoch 110: val_loss improved from 0.23376 to 0.23293, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6129 - loss: 0.0154 - val_accuracy: 0.5000 - val_loss: 0.2329 - learning_rate: 5.0000e-04\n",
      "Epoch 111/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0166\n",
      "Epoch 111: val_loss improved from 0.23293 to 0.23214, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6452 - loss: 0.0166 - val_accuracy: 0.5000 - val_loss: 0.2321 - learning_rate: 5.0000e-04\n",
      "Epoch 112/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0183\n",
      "Epoch 112: val_loss improved from 0.23214 to 0.23149, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5806 - loss: 0.0183 - val_accuracy: 0.5000 - val_loss: 0.2315 - learning_rate: 5.0000e-04\n",
      "Epoch 113/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5806 - loss: 0.0181\n",
      "Epoch 113: val_loss improved from 0.23149 to 0.23094, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5806 - loss: 0.0181 - val_accuracy: 0.5000 - val_loss: 0.2309 - learning_rate: 5.0000e-04\n",
      "Epoch 114/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5806 - loss: 0.0144\n",
      "Epoch 114: val_loss improved from 0.23094 to 0.23029, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5806 - loss: 0.0144 - val_accuracy: 0.5000 - val_loss: 0.2303 - learning_rate: 5.0000e-04\n",
      "Epoch 115/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4839 - loss: 0.0175\n",
      "Epoch 115: val_loss improved from 0.23029 to 0.22977, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4839 - loss: 0.0175 - val_accuracy: 0.5000 - val_loss: 0.2298 - learning_rate: 5.0000e-04\n",
      "Epoch 116/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0164\n",
      "Epoch 116: val_loss improved from 0.22977 to 0.22910, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6129 - loss: 0.0164 - val_accuracy: 0.5000 - val_loss: 0.2291 - learning_rate: 5.0000e-04\n",
      "Epoch 117/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5161 - loss: 0.0173\n",
      "Epoch 117: val_loss improved from 0.22910 to 0.22856, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5161 - loss: 0.0173 - val_accuracy: 0.5000 - val_loss: 0.2286 - learning_rate: 5.0000e-04\n",
      "Epoch 118/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5484 - loss: 0.0149\n",
      "Epoch 118: val_loss improved from 0.22856 to 0.22807, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5484 - loss: 0.0149 - val_accuracy: 0.5000 - val_loss: 0.2281 - learning_rate: 5.0000e-04\n",
      "Epoch 119/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0166\n",
      "Epoch 119: val_loss improved from 0.22807 to 0.22726, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6774 - loss: 0.0166 - val_accuracy: 0.5000 - val_loss: 0.2273 - learning_rate: 5.0000e-04\n",
      "Epoch 120/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5484 - loss: 0.0163\n",
      "Epoch 120: val_loss improved from 0.22726 to 0.22658, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5484 - loss: 0.0163 - val_accuracy: 0.5000 - val_loss: 0.2266 - learning_rate: 5.0000e-04\n",
      "Epoch 121/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0142\n",
      "Epoch 121: val_loss improved from 0.22658 to 0.22584, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6129 - loss: 0.0142 - val_accuracy: 0.5000 - val_loss: 0.2258 - learning_rate: 5.0000e-04\n",
      "Epoch 122/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6129 - loss: 0.0168\n",
      "Epoch 122: val_loss improved from 0.22584 to 0.22497, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6129 - loss: 0.0168 - val_accuracy: 0.5000 - val_loss: 0.2250 - learning_rate: 5.0000e-04\n",
      "Epoch 123/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0157\n",
      "Epoch 123: val_loss improved from 0.22497 to 0.22397, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6452 - loss: 0.0157 - val_accuracy: 0.5000 - val_loss: 0.2240 - learning_rate: 5.0000e-04\n",
      "Epoch 124/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0154\n",
      "Epoch 124: val_loss improved from 0.22397 to 0.22316, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6129 - loss: 0.0154 - val_accuracy: 0.5000 - val_loss: 0.2232 - learning_rate: 5.0000e-04\n",
      "Epoch 125/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0165\n",
      "Epoch 125: val_loss improved from 0.22316 to 0.22261, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6452 - loss: 0.0165 - val_accuracy: 0.5000 - val_loss: 0.2226 - learning_rate: 5.0000e-04\n",
      "Epoch 126/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0155\n",
      "Epoch 126: val_loss improved from 0.22261 to 0.22201, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6774 - loss: 0.0155 - val_accuracy: 0.5000 - val_loss: 0.2220 - learning_rate: 5.0000e-04\n",
      "Epoch 127/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0188\n",
      "Epoch 127: val_loss improved from 0.22201 to 0.22144, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6129 - loss: 0.0188 - val_accuracy: 0.5000 - val_loss: 0.2214 - learning_rate: 5.0000e-04\n",
      "Epoch 128/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5484 - loss: 0.0150\n",
      "Epoch 128: val_loss improved from 0.22144 to 0.22117, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5484 - loss: 0.0150 - val_accuracy: 0.5000 - val_loss: 0.2212 - learning_rate: 5.0000e-04\n",
      "Epoch 129/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0150\n",
      "Epoch 129: val_loss improved from 0.22117 to 0.22090, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6774 - loss: 0.0150 - val_accuracy: 0.5000 - val_loss: 0.2209 - learning_rate: 5.0000e-04\n",
      "Epoch 130/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0173\n",
      "Epoch 130: val_loss improved from 0.22090 to 0.22039, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6129 - loss: 0.0173 - val_accuracy: 0.5000 - val_loss: 0.2204 - learning_rate: 5.0000e-04\n",
      "Epoch 131/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0161\n",
      "Epoch 131: val_loss improved from 0.22039 to 0.21991, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5806 - loss: 0.0161 - val_accuracy: 0.5000 - val_loss: 0.2199 - learning_rate: 5.0000e-04\n",
      "Epoch 132/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7097 - loss: 0.0165\n",
      "Epoch 132: val_loss improved from 0.21991 to 0.21947, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7097 - loss: 0.0165 - val_accuracy: 0.5000 - val_loss: 0.2195 - learning_rate: 5.0000e-04\n",
      "Epoch 133/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0120\n",
      "Epoch 133: val_loss improved from 0.21947 to 0.21915, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6129 - loss: 0.0120 - val_accuracy: 0.5000 - val_loss: 0.2192 - learning_rate: 5.0000e-04\n",
      "Epoch 134/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7097 - loss: 0.0151\n",
      "Epoch 134: val_loss improved from 0.21915 to 0.21896, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7097 - loss: 0.0151 - val_accuracy: 0.5000 - val_loss: 0.2190 - learning_rate: 5.0000e-04\n",
      "Epoch 135/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0162\n",
      "Epoch 135: val_loss improved from 0.21896 to 0.21871, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6452 - loss: 0.0162 - val_accuracy: 0.5000 - val_loss: 0.2187 - learning_rate: 5.0000e-04\n",
      "Epoch 136/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0166\n",
      "Epoch 136: val_loss improved from 0.21871 to 0.21847, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5484 - loss: 0.0166 - val_accuracy: 0.5000 - val_loss: 0.2185 - learning_rate: 5.0000e-04\n",
      "Epoch 137/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0138\n",
      "Epoch 137: val_loss improved from 0.21847 to 0.21809, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6452 - loss: 0.0138 - val_accuracy: 0.5000 - val_loss: 0.2181 - learning_rate: 5.0000e-04\n",
      "Epoch 138/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0160\n",
      "Epoch 138: val_loss improved from 0.21809 to 0.21757, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6129 - loss: 0.0160 - val_accuracy: 0.5000 - val_loss: 0.2176 - learning_rate: 5.0000e-04\n",
      "Epoch 139/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0165\n",
      "Epoch 139: val_loss improved from 0.21757 to 0.21668, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6452 - loss: 0.0165 - val_accuracy: 0.5000 - val_loss: 0.2167 - learning_rate: 5.0000e-04\n",
      "Epoch 140/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0158\n",
      "Epoch 140: val_loss improved from 0.21668 to 0.21565, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5806 - loss: 0.0158 - val_accuracy: 0.5000 - val_loss: 0.2157 - learning_rate: 5.0000e-04\n",
      "Epoch 141/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0153\n",
      "Epoch 141: val_loss improved from 0.21565 to 0.21474, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5484 - loss: 0.0153 - val_accuracy: 0.5000 - val_loss: 0.2147 - learning_rate: 5.0000e-04\n",
      "Epoch 142/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0175\n",
      "Epoch 142: val_loss improved from 0.21474 to 0.21389, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5806 - loss: 0.0175 - val_accuracy: 0.5000 - val_loss: 0.2139 - learning_rate: 5.0000e-04\n",
      "Epoch 143/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0182\n",
      "Epoch 143: val_loss improved from 0.21389 to 0.21317, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0182 - val_accuracy: 0.5000 - val_loss: 0.2132 - learning_rate: 5.0000e-04\n",
      "Epoch 144/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6774 - loss: 0.0157\n",
      "Epoch 144: val_loss improved from 0.21317 to 0.21238, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6774 - loss: 0.0157 - val_accuracy: 0.5000 - val_loss: 0.2124 - learning_rate: 5.0000e-04\n",
      "Epoch 145/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0176\n",
      "Epoch 145: val_loss improved from 0.21238 to 0.21161, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6452 - loss: 0.0176 - val_accuracy: 0.5000 - val_loss: 0.2116 - learning_rate: 5.0000e-04\n",
      "Epoch 146/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0144\n",
      "Epoch 146: val_loss improved from 0.21161 to 0.21085, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0144 - val_accuracy: 0.5000 - val_loss: 0.2109 - learning_rate: 5.0000e-04\n",
      "Epoch 147/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5484 - loss: 0.0138\n",
      "Epoch 147: val_loss improved from 0.21085 to 0.21007, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5484 - loss: 0.0138 - val_accuracy: 0.5000 - val_loss: 0.2101 - learning_rate: 5.0000e-04\n",
      "Epoch 148/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0162\n",
      "Epoch 148: val_loss improved from 0.21007 to 0.20924, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5484 - loss: 0.0162 - val_accuracy: 0.5000 - val_loss: 0.2092 - learning_rate: 5.0000e-04\n",
      "Epoch 149/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0144\n",
      "Epoch 149: val_loss improved from 0.20924 to 0.20839, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5806 - loss: 0.0144 - val_accuracy: 0.5000 - val_loss: 0.2084 - learning_rate: 5.0000e-04\n",
      "Epoch 150/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5484 - loss: 0.0167\n",
      "Epoch 150: val_loss improved from 0.20839 to 0.20749, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5484 - loss: 0.0167 - val_accuracy: 0.5000 - val_loss: 0.2075 - learning_rate: 5.0000e-04\n",
      "Epoch 151/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6774 - loss: 0.0141\n",
      "Epoch 151: val_loss improved from 0.20749 to 0.20671, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6774 - loss: 0.0141 - val_accuracy: 0.5000 - val_loss: 0.2067 - learning_rate: 5.0000e-04\n",
      "Epoch 152/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6774 - loss: 0.0157\n",
      "Epoch 152: val_loss improved from 0.20671 to 0.20613, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6774 - loss: 0.0157 - val_accuracy: 0.5000 - val_loss: 0.2061 - learning_rate: 5.0000e-04\n",
      "Epoch 153/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0149\n",
      "Epoch 153: val_loss improved from 0.20613 to 0.20569, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6452 - loss: 0.0149 - val_accuracy: 0.5000 - val_loss: 0.2057 - learning_rate: 5.0000e-04\n",
      "Epoch 154/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0168\n",
      "Epoch 154: val_loss improved from 0.20569 to 0.20568, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0168 - val_accuracy: 0.5000 - val_loss: 0.2057 - learning_rate: 5.0000e-04\n",
      "Epoch 155/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0141\n",
      "Epoch 155: val_loss improved from 0.20568 to 0.20557, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0141 - val_accuracy: 0.5000 - val_loss: 0.2056 - learning_rate: 5.0000e-04\n",
      "Epoch 156/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0134\n",
      "Epoch 156: val_loss improved from 0.20557 to 0.20538, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5484 - loss: 0.0134 - val_accuracy: 0.5000 - val_loss: 0.2054 - learning_rate: 5.0000e-04\n",
      "Epoch 157/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5161 - loss: 0.0135\n",
      "Epoch 157: val_loss improved from 0.20538 to 0.20503, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5161 - loss: 0.0135 - val_accuracy: 0.5000 - val_loss: 0.2050 - learning_rate: 5.0000e-04\n",
      "Epoch 158/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0125\n",
      "Epoch 158: val_loss improved from 0.20503 to 0.20470, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6452 - loss: 0.0125 - val_accuracy: 0.5000 - val_loss: 0.2047 - learning_rate: 5.0000e-04\n",
      "Epoch 159/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0111\n",
      "Epoch 159: val_loss improved from 0.20470 to 0.20429, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5806 - loss: 0.0111 - val_accuracy: 0.5000 - val_loss: 0.2043 - learning_rate: 5.0000e-04\n",
      "Epoch 160/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5161 - loss: 0.0150\n",
      "Epoch 160: val_loss improved from 0.20429 to 0.20355, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5161 - loss: 0.0150 - val_accuracy: 0.5000 - val_loss: 0.2035 - learning_rate: 5.0000e-04\n",
      "Epoch 161/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0130\n",
      "Epoch 161: val_loss improved from 0.20355 to 0.20269, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6452 - loss: 0.0130 - val_accuracy: 0.5000 - val_loss: 0.2027 - learning_rate: 5.0000e-04\n",
      "Epoch 162/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0145\n",
      "Epoch 162: val_loss improved from 0.20269 to 0.20190, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5484 - loss: 0.0145 - val_accuracy: 0.5000 - val_loss: 0.2019 - learning_rate: 5.0000e-04\n",
      "Epoch 163/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0135\n",
      "Epoch 163: val_loss improved from 0.20190 to 0.20094, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0135 - val_accuracy: 0.5000 - val_loss: 0.2009 - learning_rate: 5.0000e-04\n",
      "Epoch 164/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6774 - loss: 0.0144\n",
      "Epoch 164: val_loss improved from 0.20094 to 0.19995, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6774 - loss: 0.0144 - val_accuracy: 0.5000 - val_loss: 0.1999 - learning_rate: 5.0000e-04\n",
      "Epoch 165/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0138\n",
      "Epoch 165: val_loss improved from 0.19995 to 0.19894, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6774 - loss: 0.0138 - val_accuracy: 0.5000 - val_loss: 0.1989 - learning_rate: 5.0000e-04\n",
      "Epoch 166/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0143\n",
      "Epoch 166: val_loss improved from 0.19894 to 0.19797, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7742 - loss: 0.0143 - val_accuracy: 0.5000 - val_loss: 0.1980 - learning_rate: 5.0000e-04\n",
      "Epoch 167/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5806 - loss: 0.0119\n",
      "Epoch 167: val_loss improved from 0.19797 to 0.19705, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5806 - loss: 0.0119 - val_accuracy: 0.5000 - val_loss: 0.1971 - learning_rate: 5.0000e-04\n",
      "Epoch 168/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0123\n",
      "Epoch 168: val_loss improved from 0.19705 to 0.19615, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6129 - loss: 0.0123 - val_accuracy: 0.5000 - val_loss: 0.1962 - learning_rate: 5.0000e-04\n",
      "Epoch 169/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6774 - loss: 0.0142\n",
      "Epoch 169: val_loss improved from 0.19615 to 0.19541, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6774 - loss: 0.0142 - val_accuracy: 0.5000 - val_loss: 0.1954 - learning_rate: 5.0000e-04\n",
      "Epoch 170/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0133\n",
      "Epoch 170: val_loss improved from 0.19541 to 0.19512, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6129 - loss: 0.0133 - val_accuracy: 0.5000 - val_loss: 0.1951 - learning_rate: 5.0000e-04\n",
      "Epoch 171/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0134\n",
      "Epoch 171: val_loss improved from 0.19512 to 0.19483, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6129 - loss: 0.0134 - val_accuracy: 0.5000 - val_loss: 0.1948 - learning_rate: 5.0000e-04\n",
      "Epoch 172/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0147\n",
      "Epoch 172: val_loss improved from 0.19483 to 0.19454, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5484 - loss: 0.0147 - val_accuracy: 0.5000 - val_loss: 0.1945 - learning_rate: 5.0000e-04\n",
      "Epoch 173/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0117\n",
      "Epoch 173: val_loss improved from 0.19454 to 0.19413, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7097 - loss: 0.0117 - val_accuracy: 0.5000 - val_loss: 0.1941 - learning_rate: 5.0000e-04\n",
      "Epoch 174/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0158\n",
      "Epoch 174: val_loss improved from 0.19413 to 0.19364, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6452 - loss: 0.0158 - val_accuracy: 0.5000 - val_loss: 0.1936 - learning_rate: 5.0000e-04\n",
      "Epoch 175/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6129 - loss: 0.0124\n",
      "Epoch 175: val_loss improved from 0.19364 to 0.19311, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.6129 - loss: 0.0124 - val_accuracy: 0.5000 - val_loss: 0.1931 - learning_rate: 5.0000e-04\n",
      "Epoch 176/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5806 - loss: 0.0146\n",
      "Epoch 176: val_loss improved from 0.19311 to 0.19292, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5806 - loss: 0.0146 - val_accuracy: 0.5000 - val_loss: 0.1929 - learning_rate: 5.0000e-04\n",
      "Epoch 177/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0132\n",
      "Epoch 177: val_loss improved from 0.19292 to 0.19273, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7097 - loss: 0.0132 - val_accuracy: 0.5000 - val_loss: 0.1927 - learning_rate: 5.0000e-04\n",
      "Epoch 178/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0154\n",
      "Epoch 178: val_loss improved from 0.19273 to 0.19245, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6774 - loss: 0.0154 - val_accuracy: 0.5000 - val_loss: 0.1924 - learning_rate: 5.0000e-04\n",
      "Epoch 179/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0135\n",
      "Epoch 179: val_loss improved from 0.19245 to 0.19226, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0135 - val_accuracy: 0.5000 - val_loss: 0.1923 - learning_rate: 5.0000e-04\n",
      "Epoch 180/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4839 - loss: 0.0119\n",
      "Epoch 180: val_loss improved from 0.19226 to 0.19208, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4839 - loss: 0.0119 - val_accuracy: 0.5000 - val_loss: 0.1921 - learning_rate: 5.0000e-04\n",
      "Epoch 181/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0128\n",
      "Epoch 181: val_loss improved from 0.19208 to 0.19207, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6129 - loss: 0.0128 - val_accuracy: 0.5000 - val_loss: 0.1921 - learning_rate: 5.0000e-04\n",
      "Epoch 182/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5161 - loss: 0.0139\n",
      "Epoch 182: val_loss improved from 0.19207 to 0.19191, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5161 - loss: 0.0139 - val_accuracy: 0.5000 - val_loss: 0.1919 - learning_rate: 5.0000e-04\n",
      "Epoch 183/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0147\n",
      "Epoch 183: val_loss improved from 0.19191 to 0.19147, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0147 - val_accuracy: 0.5000 - val_loss: 0.1915 - learning_rate: 5.0000e-04\n",
      "Epoch 184/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5806 - loss: 0.0120\n",
      "Epoch 184: val_loss improved from 0.19147 to 0.19090, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5806 - loss: 0.0120 - val_accuracy: 0.5000 - val_loss: 0.1909 - learning_rate: 5.0000e-04\n",
      "Epoch 185/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0127\n",
      "Epoch 185: val_loss improved from 0.19090 to 0.19008, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5806 - loss: 0.0127 - val_accuracy: 0.5000 - val_loss: 0.1901 - learning_rate: 5.0000e-04\n",
      "Epoch 186/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0121\n",
      "Epoch 186: val_loss improved from 0.19008 to 0.18904, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6129 - loss: 0.0121 - val_accuracy: 0.5000 - val_loss: 0.1890 - learning_rate: 5.0000e-04\n",
      "Epoch 187/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0140\n",
      "Epoch 187: val_loss improved from 0.18904 to 0.18807, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6452 - loss: 0.0140 - val_accuracy: 0.5000 - val_loss: 0.1881 - learning_rate: 5.0000e-04\n",
      "Epoch 188/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0125\n",
      "Epoch 188: val_loss improved from 0.18807 to 0.18715, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6452 - loss: 0.0125 - val_accuracy: 0.5000 - val_loss: 0.1872 - learning_rate: 5.0000e-04\n",
      "Epoch 189/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0124\n",
      "Epoch 189: val_loss improved from 0.18715 to 0.18611, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0124 - val_accuracy: 0.5000 - val_loss: 0.1861 - learning_rate: 5.0000e-04\n",
      "Epoch 190/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0129\n",
      "Epoch 190: val_loss improved from 0.18611 to 0.18503, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5806 - loss: 0.0129 - val_accuracy: 0.5000 - val_loss: 0.1850 - learning_rate: 5.0000e-04\n",
      "Epoch 191/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5806 - loss: 0.0119\n",
      "Epoch 191: val_loss improved from 0.18503 to 0.18390, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5806 - loss: 0.0119 - val_accuracy: 0.5000 - val_loss: 0.1839 - learning_rate: 5.0000e-04\n",
      "Epoch 192/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0155\n",
      "Epoch 192: val_loss improved from 0.18390 to 0.18288, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6452 - loss: 0.0155 - val_accuracy: 0.5000 - val_loss: 0.1829 - learning_rate: 5.0000e-04\n",
      "Epoch 193/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7097 - loss: 0.0120\n",
      "Epoch 193: val_loss improved from 0.18288 to 0.18203, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7097 - loss: 0.0120 - val_accuracy: 0.5000 - val_loss: 0.1820 - learning_rate: 5.0000e-04\n",
      "Epoch 194/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0144\n",
      "Epoch 194: val_loss improved from 0.18203 to 0.18120, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6452 - loss: 0.0144 - val_accuracy: 0.5000 - val_loss: 0.1812 - learning_rate: 5.0000e-04\n",
      "Epoch 195/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5161 - loss: 0.0122\n",
      "Epoch 195: val_loss improved from 0.18120 to 0.18024, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5161 - loss: 0.0122 - val_accuracy: 0.5000 - val_loss: 0.1802 - learning_rate: 5.0000e-04\n",
      "Epoch 196/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0122\n",
      "Epoch 196: val_loss improved from 0.18024 to 0.17926, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6452 - loss: 0.0122 - val_accuracy: 0.5000 - val_loss: 0.1793 - learning_rate: 5.0000e-04\n",
      "Epoch 197/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5484 - loss: 0.0148\n",
      "Epoch 197: val_loss improved from 0.17926 to 0.17835, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5484 - loss: 0.0148 - val_accuracy: 0.5000 - val_loss: 0.1783 - learning_rate: 5.0000e-04\n",
      "Epoch 198/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0134\n",
      "Epoch 198: val_loss improved from 0.17835 to 0.17740, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6129 - loss: 0.0134 - val_accuracy: 0.5000 - val_loss: 0.1774 - learning_rate: 5.0000e-04\n",
      "Epoch 199/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0135\n",
      "Epoch 199: val_loss improved from 0.17740 to 0.17658, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0135 - val_accuracy: 0.5000 - val_loss: 0.1766 - learning_rate: 5.0000e-04\n",
      "Epoch 200/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6129 - loss: 0.0123\n",
      "Epoch 200: val_loss improved from 0.17658 to 0.17587, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6129 - loss: 0.0123 - val_accuracy: 0.5000 - val_loss: 0.1759 - learning_rate: 5.0000e-04\n",
      "Epoch 201/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0117\n",
      "Epoch 201: val_loss improved from 0.17587 to 0.17552, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0117 - val_accuracy: 0.5000 - val_loss: 0.1755 - learning_rate: 5.0000e-04\n",
      "Epoch 202/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0125\n",
      "Epoch 202: val_loss improved from 0.17552 to 0.17522, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5806 - loss: 0.0125 - val_accuracy: 0.5000 - val_loss: 0.1752 - learning_rate: 5.0000e-04\n",
      "Epoch 203/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0124\n",
      "Epoch 203: val_loss improved from 0.17522 to 0.17493, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6774 - loss: 0.0124 - val_accuracy: 0.5000 - val_loss: 0.1749 - learning_rate: 5.0000e-04\n",
      "Epoch 204/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0123\n",
      "Epoch 204: val_loss improved from 0.17493 to 0.17437, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6774 - loss: 0.0123 - val_accuracy: 0.5000 - val_loss: 0.1744 - learning_rate: 5.0000e-04\n",
      "Epoch 205/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0136\n",
      "Epoch 205: val_loss improved from 0.17437 to 0.17398, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6452 - loss: 0.0136 - val_accuracy: 0.5000 - val_loss: 0.1740 - learning_rate: 5.0000e-04\n",
      "Epoch 206/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7419 - loss: 0.0126\n",
      "Epoch 206: val_loss improved from 0.17398 to 0.17368, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7419 - loss: 0.0126 - val_accuracy: 0.5000 - val_loss: 0.1737 - learning_rate: 5.0000e-04\n",
      "Epoch 207/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5484 - loss: 0.0115\n",
      "Epoch 207: val_loss did not improve from 0.17368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5484 - loss: 0.0115 - val_accuracy: 0.5000 - val_loss: 0.1737 - learning_rate: 5.0000e-04\n",
      "Epoch 208/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0108\n",
      "Epoch 208: val_loss did not improve from 0.17368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6129 - loss: 0.0108 - val_accuracy: 0.5000 - val_loss: 0.1737 - learning_rate: 5.0000e-04\n",
      "Epoch 209/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6129 - loss: 0.0137\n",
      "Epoch 209: val_loss improved from 0.17368 to 0.17366, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6129 - loss: 0.0137 - val_accuracy: 0.5000 - val_loss: 0.1737 - learning_rate: 5.0000e-04\n",
      "Epoch 210/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0128\n",
      "Epoch 210: val_loss improved from 0.17366 to 0.17365, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0128 - val_accuracy: 0.5000 - val_loss: 0.1737 - learning_rate: 5.0000e-04\n",
      "Epoch 211/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0113\n",
      "Epoch 211: val_loss improved from 0.17365 to 0.17345, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0113 - val_accuracy: 0.5000 - val_loss: 0.1734 - learning_rate: 5.0000e-04\n",
      "Epoch 212/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6129 - loss: 0.0128\n",
      "Epoch 212: val_loss improved from 0.17345 to 0.17322, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6129 - loss: 0.0128 - val_accuracy: 0.5000 - val_loss: 0.1732 - learning_rate: 5.0000e-04\n",
      "Epoch 213/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0117\n",
      "Epoch 213: val_loss improved from 0.17322 to 0.17250, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0117 - val_accuracy: 0.5000 - val_loss: 0.1725 - learning_rate: 5.0000e-04\n",
      "Epoch 214/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5484 - loss: 0.0118\n",
      "Epoch 214: val_loss improved from 0.17250 to 0.17139, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5484 - loss: 0.0118 - val_accuracy: 0.5000 - val_loss: 0.1714 - learning_rate: 5.0000e-04\n",
      "Epoch 215/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0117\n",
      "Epoch 215: val_loss improved from 0.17139 to 0.17061, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0117 - val_accuracy: 0.5000 - val_loss: 0.1706 - learning_rate: 5.0000e-04\n",
      "Epoch 216/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5484 - loss: 0.0132\n",
      "Epoch 216: val_loss improved from 0.17061 to 0.16934, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5484 - loss: 0.0132 - val_accuracy: 0.5000 - val_loss: 0.1693 - learning_rate: 5.0000e-04\n",
      "Epoch 217/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0105\n",
      "Epoch 217: val_loss improved from 0.16934 to 0.16810, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5806 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 0.1681 - learning_rate: 5.0000e-04\n",
      "Epoch 218/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0136\n",
      "Epoch 218: val_loss improved from 0.16810 to 0.16664, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0136 - val_accuracy: 0.5000 - val_loss: 0.1666 - learning_rate: 5.0000e-04\n",
      "Epoch 219/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0124\n",
      "Epoch 219: val_loss improved from 0.16664 to 0.16530, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5806 - loss: 0.0124 - val_accuracy: 0.5000 - val_loss: 0.1653 - learning_rate: 5.0000e-04\n",
      "Epoch 220/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0102\n",
      "Epoch 220: val_loss improved from 0.16530 to 0.16412, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6129 - loss: 0.0102 - val_accuracy: 0.5000 - val_loss: 0.1641 - learning_rate: 5.0000e-04\n",
      "Epoch 221/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0117\n",
      "Epoch 221: val_loss improved from 0.16412 to 0.16338, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0117 - val_accuracy: 0.5000 - val_loss: 0.1634 - learning_rate: 5.0000e-04\n",
      "Epoch 222/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5806 - loss: 0.0108\n",
      "Epoch 222: val_loss improved from 0.16338 to 0.16267, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5806 - loss: 0.0108 - val_accuracy: 0.5000 - val_loss: 0.1627 - learning_rate: 5.0000e-04\n",
      "Epoch 223/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0120\n",
      "Epoch 223: val_loss improved from 0.16267 to 0.16209, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5484 - loss: 0.0120 - val_accuracy: 0.5000 - val_loss: 0.1621 - learning_rate: 5.0000e-04\n",
      "Epoch 224/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0133\n",
      "Epoch 224: val_loss improved from 0.16209 to 0.16112, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7097 - loss: 0.0133 - val_accuracy: 0.5000 - val_loss: 0.1611 - learning_rate: 5.0000e-04\n",
      "Epoch 225/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0109\n",
      "Epoch 225: val_loss improved from 0.16112 to 0.16061, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0109 - val_accuracy: 0.5000 - val_loss: 0.1606 - learning_rate: 5.0000e-04\n",
      "Epoch 226/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0123\n",
      "Epoch 226: val_loss improved from 0.16061 to 0.16000, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0123 - val_accuracy: 0.5000 - val_loss: 0.1600 - learning_rate: 5.0000e-04\n",
      "Epoch 227/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0109\n",
      "Epoch 227: val_loss improved from 0.16000 to 0.15938, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0109 - val_accuracy: 0.5000 - val_loss: 0.1594 - learning_rate: 5.0000e-04\n",
      "Epoch 228/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0121\n",
      "Epoch 228: val_loss improved from 0.15938 to 0.15860, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0121 - val_accuracy: 0.5000 - val_loss: 0.1586 - learning_rate: 5.0000e-04\n",
      "Epoch 229/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6129 - loss: 0.0115\n",
      "Epoch 229: val_loss improved from 0.15860 to 0.15777, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6129 - loss: 0.0115 - val_accuracy: 0.5000 - val_loss: 0.1578 - learning_rate: 5.0000e-04\n",
      "Epoch 230/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0111\n",
      "Epoch 230: val_loss improved from 0.15777 to 0.15656, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6129 - loss: 0.0111 - val_accuracy: 0.5000 - val_loss: 0.1566 - learning_rate: 5.0000e-04\n",
      "Epoch 231/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6452 - loss: 0.0114\n",
      "Epoch 231: val_loss improved from 0.15656 to 0.15555, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6452 - loss: 0.0114 - val_accuracy: 0.5000 - val_loss: 0.1556 - learning_rate: 5.0000e-04\n",
      "Epoch 232/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0102\n",
      "Epoch 232: val_loss improved from 0.15555 to 0.15489, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6774 - loss: 0.0102 - val_accuracy: 0.5000 - val_loss: 0.1549 - learning_rate: 5.0000e-04\n",
      "Epoch 233/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6129 - loss: 0.0115\n",
      "Epoch 233: val_loss improved from 0.15489 to 0.15398, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6129 - loss: 0.0115 - val_accuracy: 0.5000 - val_loss: 0.1540 - learning_rate: 5.0000e-04\n",
      "Epoch 234/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5806 - loss: 0.0107\n",
      "Epoch 234: val_loss improved from 0.15398 to 0.15291, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5806 - loss: 0.0107 - val_accuracy: 0.5000 - val_loss: 0.1529 - learning_rate: 5.0000e-04\n",
      "Epoch 235/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0089\n",
      "Epoch 235: val_loss improved from 0.15291 to 0.15198, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0089 - val_accuracy: 0.5000 - val_loss: 0.1520 - learning_rate: 5.0000e-04\n",
      "Epoch 236/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0106\n",
      "Epoch 236: val_loss improved from 0.15198 to 0.15099, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7419 - loss: 0.0106 - val_accuracy: 0.5000 - val_loss: 0.1510 - learning_rate: 5.0000e-04\n",
      "Epoch 237/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0107\n",
      "Epoch 237: val_loss improved from 0.15099 to 0.15001, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0107 - val_accuracy: 0.5000 - val_loss: 0.1500 - learning_rate: 5.0000e-04\n",
      "Epoch 238/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6774 - loss: 0.0108\n",
      "Epoch 238: val_loss improved from 0.15001 to 0.14916, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0108 - val_accuracy: 0.5000 - val_loss: 0.1492 - learning_rate: 5.0000e-04\n",
      "Epoch 239/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0109\n",
      "Epoch 239: val_loss improved from 0.14916 to 0.14792, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0109 - val_accuracy: 0.5000 - val_loss: 0.1479 - learning_rate: 5.0000e-04\n",
      "Epoch 240/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0089\n",
      "Epoch 240: val_loss improved from 0.14792 to 0.14680, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0089 - val_accuracy: 0.5000 - val_loss: 0.1468 - learning_rate: 5.0000e-04\n",
      "Epoch 241/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0125\n",
      "Epoch 241: val_loss improved from 0.14680 to 0.14602, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6129 - loss: 0.0125 - val_accuracy: 0.5000 - val_loss: 0.1460 - learning_rate: 5.0000e-04\n",
      "Epoch 242/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0117\n",
      "Epoch 242: val_loss improved from 0.14602 to 0.14521, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5806 - loss: 0.0117 - val_accuracy: 0.5000 - val_loss: 0.1452 - learning_rate: 5.0000e-04\n",
      "Epoch 243/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0097\n",
      "Epoch 243: val_loss improved from 0.14521 to 0.14426, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0097 - val_accuracy: 0.5000 - val_loss: 0.1443 - learning_rate: 5.0000e-04\n",
      "Epoch 244/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0105\n",
      "Epoch 244: val_loss improved from 0.14426 to 0.14360, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7097 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 0.1436 - learning_rate: 5.0000e-04\n",
      "Epoch 245/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6452 - loss: 0.0099\n",
      "Epoch 245: val_loss improved from 0.14360 to 0.14295, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6452 - loss: 0.0099 - val_accuracy: 0.5000 - val_loss: 0.1429 - learning_rate: 5.0000e-04\n",
      "Epoch 246/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0098\n",
      "Epoch 246: val_loss improved from 0.14295 to 0.14260, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5806 - loss: 0.0098 - val_accuracy: 0.5000 - val_loss: 0.1426 - learning_rate: 5.0000e-04\n",
      "Epoch 247/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6774 - loss: 0.0098\n",
      "Epoch 247: val_loss improved from 0.14260 to 0.14228, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6774 - loss: 0.0098 - val_accuracy: 0.5000 - val_loss: 0.1423 - learning_rate: 5.0000e-04\n",
      "Epoch 248/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0104\n",
      "Epoch 248: val_loss improved from 0.14228 to 0.14226, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0104 - val_accuracy: 0.5000 - val_loss: 0.1423 - learning_rate: 5.0000e-04\n",
      "Epoch 249/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0110\n",
      "Epoch 249: val_loss improved from 0.14226 to 0.14201, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0110 - val_accuracy: 0.5000 - val_loss: 0.1420 - learning_rate: 5.0000e-04\n",
      "Epoch 250/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0103\n",
      "Epoch 250: val_loss improved from 0.14201 to 0.14148, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7097 - loss: 0.0103 - val_accuracy: 0.5000 - val_loss: 0.1415 - learning_rate: 5.0000e-04\n",
      "Epoch 251/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6774 - loss: 0.0081\n",
      "Epoch 251: val_loss improved from 0.14148 to 0.14115, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.1412 - learning_rate: 5.0000e-04\n",
      "Epoch 252/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0111\n",
      "Epoch 252: val_loss improved from 0.14115 to 0.14076, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6452 - loss: 0.0111 - val_accuracy: 0.5000 - val_loss: 0.1408 - learning_rate: 5.0000e-04\n",
      "Epoch 253/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0105\n",
      "Epoch 253: val_loss improved from 0.14076 to 0.14030, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6774 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 0.1403 - learning_rate: 5.0000e-04\n",
      "Epoch 254/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6129 - loss: 0.0092\n",
      "Epoch 254: val_loss improved from 0.14030 to 0.13977, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6129 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.1398 - learning_rate: 5.0000e-04\n",
      "Epoch 255/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6774 - loss: 0.0094\n",
      "Epoch 255: val_loss improved from 0.13977 to 0.13936, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6774 - loss: 0.0094 - val_accuracy: 0.5000 - val_loss: 0.1394 - learning_rate: 5.0000e-04\n",
      "Epoch 256/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0102\n",
      "Epoch 256: val_loss improved from 0.13936 to 0.13890, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0102 - val_accuracy: 0.5000 - val_loss: 0.1389 - learning_rate: 5.0000e-04\n",
      "Epoch 257/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0105\n",
      "Epoch 257: val_loss improved from 0.13890 to 0.13847, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 0.1385 - learning_rate: 5.0000e-04\n",
      "Epoch 258/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0090\n",
      "Epoch 258: val_loss improved from 0.13847 to 0.13800, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0090 - val_accuracy: 0.5000 - val_loss: 0.1380 - learning_rate: 5.0000e-04\n",
      "Epoch 259/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5484 - loss: 0.0110\n",
      "Epoch 259: val_loss improved from 0.13800 to 0.13730, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5484 - loss: 0.0110 - val_accuracy: 0.5000 - val_loss: 0.1373 - learning_rate: 5.0000e-04\n",
      "Epoch 260/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0101\n",
      "Epoch 260: val_loss improved from 0.13730 to 0.13666, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6774 - loss: 0.0101 - val_accuracy: 0.5000 - val_loss: 0.1367 - learning_rate: 5.0000e-04\n",
      "Epoch 261/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0097\n",
      "Epoch 261: val_loss improved from 0.13666 to 0.13568, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5484 - loss: 0.0097 - val_accuracy: 0.5000 - val_loss: 0.1357 - learning_rate: 5.0000e-04\n",
      "Epoch 262/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0096\n",
      "Epoch 262: val_loss improved from 0.13568 to 0.13474, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6129 - loss: 0.0096 - val_accuracy: 0.5000 - val_loss: 0.1347 - learning_rate: 5.0000e-04\n",
      "Epoch 263/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6774 - loss: 0.0095\n",
      "Epoch 263: val_loss improved from 0.13474 to 0.13380, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6774 - loss: 0.0095 - val_accuracy: 0.5000 - val_loss: 0.1338 - learning_rate: 5.0000e-04\n",
      "Epoch 264/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0110\n",
      "Epoch 264: val_loss improved from 0.13380 to 0.13260, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7097 - loss: 0.0110 - val_accuracy: 0.5000 - val_loss: 0.1326 - learning_rate: 5.0000e-04\n",
      "Epoch 265/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0081\n",
      "Epoch 265: val_loss improved from 0.13260 to 0.13177, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.1318 - learning_rate: 5.0000e-04\n",
      "Epoch 266/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0099\n",
      "Epoch 266: val_loss improved from 0.13177 to 0.13090, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0099 - val_accuracy: 0.5000 - val_loss: 0.1309 - learning_rate: 5.0000e-04\n",
      "Epoch 267/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6452 - loss: 0.0101\n",
      "Epoch 267: val_loss improved from 0.13090 to 0.12989, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6452 - loss: 0.0101 - val_accuracy: 0.5000 - val_loss: 0.1299 - learning_rate: 5.0000e-04\n",
      "Epoch 268/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5806 - loss: 0.0114\n",
      "Epoch 268: val_loss improved from 0.12989 to 0.12892, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5806 - loss: 0.0114 - val_accuracy: 0.5000 - val_loss: 0.1289 - learning_rate: 5.0000e-04\n",
      "Epoch 269/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.0098\n",
      "Epoch 269: val_loss improved from 0.12892 to 0.12785, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5484 - loss: 0.0098 - val_accuracy: 0.5000 - val_loss: 0.1278 - learning_rate: 5.0000e-04\n",
      "Epoch 270/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0098\n",
      "Epoch 270: val_loss improved from 0.12785 to 0.12660, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0098 - val_accuracy: 0.5000 - val_loss: 0.1266 - learning_rate: 5.0000e-04\n",
      "Epoch 271/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5806 - loss: 0.0107\n",
      "Epoch 271: val_loss improved from 0.12660 to 0.12524, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5806 - loss: 0.0107 - val_accuracy: 0.5000 - val_loss: 0.1252 - learning_rate: 5.0000e-04\n",
      "Epoch 272/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0092\n",
      "Epoch 272: val_loss improved from 0.12524 to 0.12425, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.1242 - learning_rate: 5.0000e-04\n",
      "Epoch 273/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0082\n",
      "Epoch 273: val_loss improved from 0.12425 to 0.12354, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6774 - loss: 0.0082 - val_accuracy: 0.5000 - val_loss: 0.1235 - learning_rate: 5.0000e-04\n",
      "Epoch 274/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0086\n",
      "Epoch 274: val_loss improved from 0.12354 to 0.12297, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6452 - loss: 0.0086 - val_accuracy: 0.5000 - val_loss: 0.1230 - learning_rate: 5.0000e-04\n",
      "Epoch 275/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7419 - loss: 0.0090\n",
      "Epoch 275: val_loss improved from 0.12297 to 0.12262, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7419 - loss: 0.0090 - val_accuracy: 0.5000 - val_loss: 0.1226 - learning_rate: 5.0000e-04\n",
      "Epoch 276/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0084\n",
      "Epoch 276: val_loss did not improve from 0.12262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7419 - loss: 0.0084 - val_accuracy: 0.5000 - val_loss: 0.1227 - learning_rate: 5.0000e-04\n",
      "Epoch 277/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0097\n",
      "Epoch 277: val_loss did not improve from 0.12262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6452 - loss: 0.0097 - val_accuracy: 0.5000 - val_loss: 0.1228 - learning_rate: 5.0000e-04\n",
      "Epoch 278/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0105\n",
      "Epoch 278: val_loss did not improve from 0.12262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0105 - val_accuracy: 0.5000 - val_loss: 0.1231 - learning_rate: 5.0000e-04\n",
      "Epoch 279/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0095\n",
      "Epoch 279: val_loss did not improve from 0.12262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0095 - val_accuracy: 0.5000 - val_loss: 0.1235 - learning_rate: 5.0000e-04\n",
      "Epoch 280/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7097 - loss: 0.0093\n",
      "Epoch 280: val_loss did not improve from 0.12262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7097 - loss: 0.0093 - val_accuracy: 0.5000 - val_loss: 0.1236 - learning_rate: 5.0000e-04\n",
      "Epoch 281/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0078\n",
      "Epoch 281: val_loss did not improve from 0.12262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6452 - loss: 0.0078 - val_accuracy: 0.5000 - val_loss: 0.1233 - learning_rate: 5.0000e-04\n",
      "Epoch 282/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0104\n",
      "Epoch 282: val_loss improved from 0.12262 to 0.12258, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0104 - val_accuracy: 0.5000 - val_loss: 0.1226 - learning_rate: 5.0000e-04\n",
      "Epoch 283/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6774 - loss: 0.0110\n",
      "Epoch 283: val_loss improved from 0.12258 to 0.12141, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6774 - loss: 0.0110 - val_accuracy: 0.5000 - val_loss: 0.1214 - learning_rate: 5.0000e-04\n",
      "Epoch 284/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6129 - loss: 0.0080\n",
      "Epoch 284: val_loss improved from 0.12141 to 0.11996, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6129 - loss: 0.0080 - val_accuracy: 0.5000 - val_loss: 0.1200 - learning_rate: 5.0000e-04\n",
      "Epoch 285/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0087\n",
      "Epoch 285: val_loss improved from 0.11996 to 0.11861, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0087 - val_accuracy: 0.5000 - val_loss: 0.1186 - learning_rate: 5.0000e-04\n",
      "Epoch 286/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0081\n",
      "Epoch 286: val_loss improved from 0.11861 to 0.11736, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.1174 - learning_rate: 5.0000e-04\n",
      "Epoch 287/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8065 - loss: 0.0088\n",
      "Epoch 287: val_loss improved from 0.11736 to 0.11624, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8065 - loss: 0.0088 - val_accuracy: 0.5000 - val_loss: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 288/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0101\n",
      "Epoch 288: val_loss improved from 0.11624 to 0.11525, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6452 - loss: 0.0101 - val_accuracy: 0.5000 - val_loss: 0.1152 - learning_rate: 5.0000e-04\n",
      "Epoch 289/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0087\n",
      "Epoch 289: val_loss improved from 0.11525 to 0.11437, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5806 - loss: 0.0087 - val_accuracy: 0.5000 - val_loss: 0.1144 - learning_rate: 5.0000e-04\n",
      "Epoch 290/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0082\n",
      "Epoch 290: val_loss improved from 0.11437 to 0.11339, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0082 - val_accuracy: 0.5000 - val_loss: 0.1134 - learning_rate: 5.0000e-04\n",
      "Epoch 291/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0091\n",
      "Epoch 291: val_loss improved from 0.11339 to 0.11266, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0091 - val_accuracy: 0.5000 - val_loss: 0.1127 - learning_rate: 5.0000e-04\n",
      "Epoch 292/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0094\n",
      "Epoch 292: val_loss improved from 0.11266 to 0.11187, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6452 - loss: 0.0094 - val_accuracy: 0.5000 - val_loss: 0.1119 - learning_rate: 5.0000e-04\n",
      "Epoch 293/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5806 - loss: 0.0106\n",
      "Epoch 293: val_loss improved from 0.11187 to 0.11102, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5806 - loss: 0.0106 - val_accuracy: 0.5000 - val_loss: 0.1110 - learning_rate: 5.0000e-04\n",
      "Epoch 294/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0095\n",
      "Epoch 294: val_loss improved from 0.11102 to 0.11030, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6774 - loss: 0.0095 - val_accuracy: 0.5000 - val_loss: 0.1103 - learning_rate: 5.0000e-04\n",
      "Epoch 295/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6452 - loss: 0.0092\n",
      "Epoch 295: val_loss improved from 0.11030 to 0.10968, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.1097 - learning_rate: 5.0000e-04\n",
      "Epoch 296/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0092\n",
      "Epoch 296: val_loss improved from 0.10968 to 0.10899, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7097 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.1090 - learning_rate: 5.0000e-04\n",
      "Epoch 297/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0080\n",
      "Epoch 297: val_loss improved from 0.10899 to 0.10830, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0080 - val_accuracy: 0.5000 - val_loss: 0.1083 - learning_rate: 5.0000e-04\n",
      "Epoch 298/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0089\n",
      "Epoch 298: val_loss improved from 0.10830 to 0.10748, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6452 - loss: 0.0089 - val_accuracy: 0.5000 - val_loss: 0.1075 - learning_rate: 5.0000e-04\n",
      "Epoch 299/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0087\n",
      "Epoch 299: val_loss improved from 0.10748 to 0.10674, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0087 - val_accuracy: 0.5000 - val_loss: 0.1067 - learning_rate: 5.0000e-04\n",
      "Epoch 300/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7097 - loss: 0.0088\n",
      "Epoch 300: val_loss improved from 0.10674 to 0.10639, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7097 - loss: 0.0088 - val_accuracy: 0.5000 - val_loss: 0.1064 - learning_rate: 5.0000e-04\n",
      "Epoch 301/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0089\n",
      "Epoch 301: val_loss improved from 0.10639 to 0.10631, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0089 - val_accuracy: 0.5000 - val_loss: 0.1063 - learning_rate: 5.0000e-04\n",
      "Epoch 302/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0083\n",
      "Epoch 302: val_loss improved from 0.10631 to 0.10624, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7097 - loss: 0.0083 - val_accuracy: 0.5000 - val_loss: 0.1062 - learning_rate: 5.0000e-04\n",
      "Epoch 303/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7097 - loss: 0.0090\n",
      "Epoch 303: val_loss improved from 0.10624 to 0.10601, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7097 - loss: 0.0090 - val_accuracy: 0.5000 - val_loss: 0.1060 - learning_rate: 5.0000e-04\n",
      "Epoch 304/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0084\n",
      "Epoch 304: val_loss improved from 0.10601 to 0.10565, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7742 - loss: 0.0084 - val_accuracy: 0.5000 - val_loss: 0.1056 - learning_rate: 5.0000e-04\n",
      "Epoch 305/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6452 - loss: 0.0092\n",
      "Epoch 305: val_loss improved from 0.10565 to 0.10529, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6452 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.1053 - learning_rate: 5.0000e-04\n",
      "Epoch 306/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6452 - loss: 0.0086\n",
      "Epoch 306: val_loss improved from 0.10529 to 0.10502, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6452 - loss: 0.0086 - val_accuracy: 0.5000 - val_loss: 0.1050 - learning_rate: 5.0000e-04\n",
      "Epoch 307/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6774 - loss: 0.0086\n",
      "Epoch 307: val_loss improved from 0.10502 to 0.10439, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6774 - loss: 0.0086 - val_accuracy: 0.5000 - val_loss: 0.1044 - learning_rate: 5.0000e-04\n",
      "Epoch 308/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0076\n",
      "Epoch 308: val_loss improved from 0.10439 to 0.10343, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6452 - loss: 0.0076 - val_accuracy: 0.5000 - val_loss: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 309/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0074\n",
      "Epoch 309: val_loss improved from 0.10343 to 0.10270, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0074 - val_accuracy: 0.5000 - val_loss: 0.1027 - learning_rate: 5.0000e-04\n",
      "Epoch 310/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0092\n",
      "Epoch 310: val_loss improved from 0.10270 to 0.10160, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6774 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.1016 - learning_rate: 5.0000e-04\n",
      "Epoch 311/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0091\n",
      "Epoch 311: val_loss improved from 0.10160 to 0.10087, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7097 - loss: 0.0091 - val_accuracy: 0.5000 - val_loss: 0.1009 - learning_rate: 5.0000e-04\n",
      "Epoch 312/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0092\n",
      "Epoch 312: val_loss improved from 0.10087 to 0.09971, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6452 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.0997 - learning_rate: 5.0000e-04\n",
      "Epoch 313/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0096\n",
      "Epoch 313: val_loss improved from 0.09971 to 0.09841, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0096 - val_accuracy: 0.5000 - val_loss: 0.0984 - learning_rate: 5.0000e-04\n",
      "Epoch 314/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6774 - loss: 0.0070\n",
      "Epoch 314: val_loss improved from 0.09841 to 0.09736, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6774 - loss: 0.0070 - val_accuracy: 0.5000 - val_loss: 0.0974 - learning_rate: 5.0000e-04\n",
      "Epoch 315/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0095\n",
      "Epoch 315: val_loss improved from 0.09736 to 0.09606, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7097 - loss: 0.0095 - val_accuracy: 0.5000 - val_loss: 0.0961 - learning_rate: 5.0000e-04\n",
      "Epoch 316/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0090\n",
      "Epoch 316: val_loss improved from 0.09606 to 0.09499, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0090 - val_accuracy: 0.5000 - val_loss: 0.0950 - learning_rate: 5.0000e-04\n",
      "Epoch 317/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0083\n",
      "Epoch 317: val_loss improved from 0.09499 to 0.09428, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6452 - loss: 0.0083 - val_accuracy: 0.5000 - val_loss: 0.0943 - learning_rate: 5.0000e-04\n",
      "Epoch 318/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0088\n",
      "Epoch 318: val_loss improved from 0.09428 to 0.09375, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7097 - loss: 0.0088 - val_accuracy: 0.5000 - val_loss: 0.0937 - learning_rate: 5.0000e-04\n",
      "Epoch 319/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0077\n",
      "Epoch 319: val_loss improved from 0.09375 to 0.09337, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0077 - val_accuracy: 0.5000 - val_loss: 0.0934 - learning_rate: 5.0000e-04\n",
      "Epoch 320/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0077\n",
      "Epoch 320: val_loss improved from 0.09337 to 0.09290, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6452 - loss: 0.0077 - val_accuracy: 0.5000 - val_loss: 0.0929 - learning_rate: 5.0000e-04\n",
      "Epoch 321/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6452 - loss: 0.0081\n",
      "Epoch 321: val_loss improved from 0.09290 to 0.09238, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6452 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.0924 - learning_rate: 5.0000e-04\n",
      "Epoch 322/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8065 - loss: 0.0084\n",
      "Epoch 322: val_loss improved from 0.09238 to 0.09181, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8065 - loss: 0.0084 - val_accuracy: 0.5000 - val_loss: 0.0918 - learning_rate: 5.0000e-04\n",
      "Epoch 323/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0085\n",
      "Epoch 323: val_loss improved from 0.09181 to 0.09116, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7419 - loss: 0.0085 - val_accuracy: 0.5000 - val_loss: 0.0912 - learning_rate: 5.0000e-04\n",
      "Epoch 324/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6452 - loss: 0.0092\n",
      "Epoch 324: val_loss improved from 0.09116 to 0.09054, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6452 - loss: 0.0092 - val_accuracy: 0.5000 - val_loss: 0.0905 - learning_rate: 5.0000e-04\n",
      "Epoch 325/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0085\n",
      "Epoch 325: val_loss improved from 0.09054 to 0.09022, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6774 - loss: 0.0085 - val_accuracy: 0.5000 - val_loss: 0.0902 - learning_rate: 5.0000e-04\n",
      "Epoch 326/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0072\n",
      "Epoch 326: val_loss improved from 0.09022 to 0.08977, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7097 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0898 - learning_rate: 5.0000e-04\n",
      "Epoch 327/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0073\n",
      "Epoch 327: val_loss improved from 0.08977 to 0.08932, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7097 - loss: 0.0073 - val_accuracy: 0.5000 - val_loss: 0.0893 - learning_rate: 5.0000e-04\n",
      "Epoch 328/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8387 - loss: 0.0078\n",
      "Epoch 328: val_loss improved from 0.08932 to 0.08871, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8387 - loss: 0.0078 - val_accuracy: 0.5000 - val_loss: 0.0887 - learning_rate: 5.0000e-04\n",
      "Epoch 329/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0074\n",
      "Epoch 329: val_loss improved from 0.08871 to 0.08818, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6774 - loss: 0.0074 - val_accuracy: 0.5000 - val_loss: 0.0882 - learning_rate: 5.0000e-04\n",
      "Epoch 330/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0085\n",
      "Epoch 330: val_loss improved from 0.08818 to 0.08790, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7419 - loss: 0.0085 - val_accuracy: 0.5000 - val_loss: 0.0879 - learning_rate: 5.0000e-04\n",
      "Epoch 331/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0076\n",
      "Epoch 331: val_loss improved from 0.08790 to 0.08738, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6129 - loss: 0.0076 - val_accuracy: 0.5000 - val_loss: 0.0874 - learning_rate: 5.0000e-04\n",
      "Epoch 332/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0081\n",
      "Epoch 332: val_loss improved from 0.08738 to 0.08738, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7742 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.0874 - learning_rate: 5.0000e-04\n",
      "Epoch 333/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0075\n",
      "Epoch 333: val_loss improved from 0.08738 to 0.08708, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7419 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0871 - learning_rate: 5.0000e-04\n",
      "Epoch 334/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7419 - loss: 0.0072\n",
      "Epoch 334: val_loss improved from 0.08708 to 0.08670, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7419 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0867 - learning_rate: 5.0000e-04\n",
      "Epoch 335/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0080\n",
      "Epoch 335: val_loss improved from 0.08670 to 0.08637, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0080 - val_accuracy: 0.5000 - val_loss: 0.0864 - learning_rate: 5.0000e-04\n",
      "Epoch 336/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0098\n",
      "Epoch 336: val_loss improved from 0.08637 to 0.08570, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0098 - val_accuracy: 0.5000 - val_loss: 0.0857 - learning_rate: 5.0000e-04\n",
      "Epoch 337/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0075\n",
      "Epoch 337: val_loss improved from 0.08570 to 0.08499, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6452 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0850 - learning_rate: 5.0000e-04\n",
      "Epoch 338/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6452 - loss: 0.0088\n",
      "Epoch 338: val_loss improved from 0.08499 to 0.08430, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.6452 - loss: 0.0088 - val_accuracy: 0.5000 - val_loss: 0.0843 - learning_rate: 5.0000e-04\n",
      "Epoch 339/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0079\n",
      "Epoch 339: val_loss improved from 0.08430 to 0.08344, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6774 - loss: 0.0079 - val_accuracy: 0.5000 - val_loss: 0.0834 - learning_rate: 5.0000e-04\n",
      "Epoch 340/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0076\n",
      "Epoch 340: val_loss improved from 0.08344 to 0.08264, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0076 - val_accuracy: 0.5000 - val_loss: 0.0826 - learning_rate: 5.0000e-04\n",
      "Epoch 341/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0086\n",
      "Epoch 341: val_loss improved from 0.08264 to 0.08208, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0086 - val_accuracy: 0.5000 - val_loss: 0.0821 - learning_rate: 5.0000e-04\n",
      "Epoch 342/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0071\n",
      "Epoch 342: val_loss improved from 0.08208 to 0.08162, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6452 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0816 - learning_rate: 5.0000e-04\n",
      "Epoch 343/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0093\n",
      "Epoch 343: val_loss improved from 0.08162 to 0.08100, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6774 - loss: 0.0093 - val_accuracy: 0.5000 - val_loss: 0.0810 - learning_rate: 5.0000e-04\n",
      "Epoch 344/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0078\n",
      "Epoch 344: val_loss improved from 0.08100 to 0.08012, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6774 - loss: 0.0078 - val_accuracy: 0.5000 - val_loss: 0.0801 - learning_rate: 5.0000e-04\n",
      "Epoch 345/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0097\n",
      "Epoch 345: val_loss improved from 0.08012 to 0.07946, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7419 - loss: 0.0097 - val_accuracy: 0.5000 - val_loss: 0.0795 - learning_rate: 5.0000e-04\n",
      "Epoch 346/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0083\n",
      "Epoch 346: val_loss improved from 0.07946 to 0.07867, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7419 - loss: 0.0083 - val_accuracy: 0.5000 - val_loss: 0.0787 - learning_rate: 5.0000e-04\n",
      "Epoch 347/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0077\n",
      "Epoch 347: val_loss improved from 0.07867 to 0.07795, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7419 - loss: 0.0077 - val_accuracy: 0.5000 - val_loss: 0.0780 - learning_rate: 5.0000e-04\n",
      "Epoch 348/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0062\n",
      "Epoch 348: val_loss improved from 0.07795 to 0.07708, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7419 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0771 - learning_rate: 5.0000e-04\n",
      "Epoch 349/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0077\n",
      "Epoch 349: val_loss improved from 0.07708 to 0.07630, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6774 - loss: 0.0077 - val_accuracy: 0.5000 - val_loss: 0.0763 - learning_rate: 5.0000e-04\n",
      "Epoch 350/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6774 - loss: 0.0080\n",
      "Epoch 350: val_loss improved from 0.07630 to 0.07576, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6774 - loss: 0.0080 - val_accuracy: 0.5000 - val_loss: 0.0758 - learning_rate: 5.0000e-04\n",
      "Epoch 351/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0069\n",
      "Epoch 351: val_loss improved from 0.07576 to 0.07534, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7419 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0753 - learning_rate: 5.0000e-04\n",
      "Epoch 352/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0061\n",
      "Epoch 352: val_loss improved from 0.07534 to 0.07487, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0061 - val_accuracy: 0.5000 - val_loss: 0.0749 - learning_rate: 5.0000e-04\n",
      "Epoch 353/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0076\n",
      "Epoch 353: val_loss improved from 0.07487 to 0.07459, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6452 - loss: 0.0076 - val_accuracy: 0.5000 - val_loss: 0.0746 - learning_rate: 5.0000e-04\n",
      "Epoch 354/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0080\n",
      "Epoch 354: val_loss did not improve from 0.07459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6774 - loss: 0.0080 - val_accuracy: 0.5000 - val_loss: 0.0747 - learning_rate: 5.0000e-04\n",
      "Epoch 355/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6452 - loss: 0.0091\n",
      "Epoch 355: val_loss did not improve from 0.07459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6452 - loss: 0.0091 - val_accuracy: 0.5000 - val_loss: 0.0753 - learning_rate: 5.0000e-04\n",
      "Epoch 356/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0095\n",
      "Epoch 356: val_loss did not improve from 0.07459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6452 - loss: 0.0095 - val_accuracy: 0.5000 - val_loss: 0.0755 - learning_rate: 5.0000e-04\n",
      "Epoch 357/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7097 - loss: 0.0088\n",
      "Epoch 357: val_loss did not improve from 0.07459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7097 - loss: 0.0088 - val_accuracy: 0.5000 - val_loss: 0.0754 - learning_rate: 5.0000e-04\n",
      "Epoch 358/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6129 - loss: 0.0066\n",
      "Epoch 358: val_loss did not improve from 0.07459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6129 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.0751 - learning_rate: 5.0000e-04\n",
      "Epoch 359/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0081\n",
      "Epoch 359: val_loss improved from 0.07459 to 0.07450, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6452 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.0745 - learning_rate: 5.0000e-04\n",
      "Epoch 360/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0075\n",
      "Epoch 360: val_loss improved from 0.07450 to 0.07360, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0736 - learning_rate: 5.0000e-04\n",
      "Epoch 361/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0084\n",
      "Epoch 361: val_loss improved from 0.07360 to 0.07275, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0084 - val_accuracy: 0.5000 - val_loss: 0.0727 - learning_rate: 5.0000e-04\n",
      "Epoch 362/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0072\n",
      "Epoch 362: val_loss improved from 0.07275 to 0.07188, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0719 - learning_rate: 5.0000e-04\n",
      "Epoch 363/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5806 - loss: 0.0072\n",
      "Epoch 363: val_loss improved from 0.07188 to 0.07107, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5806 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0711 - learning_rate: 5.0000e-04\n",
      "Epoch 364/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0068\n",
      "Epoch 364: val_loss improved from 0.07107 to 0.07059, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6452 - loss: 0.0068 - val_accuracy: 0.5000 - val_loss: 0.0706 - learning_rate: 5.0000e-04\n",
      "Epoch 365/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0079\n",
      "Epoch 365: val_loss improved from 0.07059 to 0.07015, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6774 - loss: 0.0079 - val_accuracy: 0.5000 - val_loss: 0.0702 - learning_rate: 5.0000e-04\n",
      "Epoch 366/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0075\n",
      "Epoch 366: val_loss improved from 0.07015 to 0.06956, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0696 - learning_rate: 5.0000e-04\n",
      "Epoch 367/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0080\n",
      "Epoch 367: val_loss improved from 0.06956 to 0.06885, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0080 - val_accuracy: 0.5000 - val_loss: 0.0689 - learning_rate: 5.0000e-04\n",
      "Epoch 368/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0077\n",
      "Epoch 368: val_loss improved from 0.06885 to 0.06847, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7419 - loss: 0.0077 - val_accuracy: 0.5000 - val_loss: 0.0685 - learning_rate: 5.0000e-04\n",
      "Epoch 369/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0084\n",
      "Epoch 369: val_loss improved from 0.06847 to 0.06798, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6129 - loss: 0.0084 - val_accuracy: 0.5000 - val_loss: 0.0680 - learning_rate: 5.0000e-04\n",
      "Epoch 370/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0071\n",
      "Epoch 370: val_loss improved from 0.06798 to 0.06732, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7097 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0673 - learning_rate: 5.0000e-04\n",
      "Epoch 371/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0069\n",
      "Epoch 371: val_loss improved from 0.06732 to 0.06644, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7097 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0664 - learning_rate: 5.0000e-04\n",
      "Epoch 372/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0078\n",
      "Epoch 372: val_loss improved from 0.06644 to 0.06583, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0078 - val_accuracy: 0.5000 - val_loss: 0.0658 - learning_rate: 5.0000e-04\n",
      "Epoch 373/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0072\n",
      "Epoch 373: val_loss improved from 0.06583 to 0.06511, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0651 - learning_rate: 5.0000e-04\n",
      "Epoch 374/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0067\n",
      "Epoch 374: val_loss improved from 0.06511 to 0.06441, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7742 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 0.0644 - learning_rate: 5.0000e-04\n",
      "Epoch 375/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0081\n",
      "Epoch 375: val_loss improved from 0.06441 to 0.06409, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6452 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.0641 - learning_rate: 5.0000e-04\n",
      "Epoch 376/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0071\n",
      "Epoch 376: val_loss improved from 0.06409 to 0.06365, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0636 - learning_rate: 5.0000e-04\n",
      "Epoch 377/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7742 - loss: 0.0068\n",
      "Epoch 377: val_loss improved from 0.06365 to 0.06324, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7742 - loss: 0.0068 - val_accuracy: 0.5000 - val_loss: 0.0632 - learning_rate: 5.0000e-04\n",
      "Epoch 378/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0071\n",
      "Epoch 378: val_loss improved from 0.06324 to 0.06266, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6774 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0627 - learning_rate: 5.0000e-04\n",
      "Epoch 379/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7097 - loss: 0.0072\n",
      "Epoch 379: val_loss improved from 0.06266 to 0.06261, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7097 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0626 - learning_rate: 5.0000e-04\n",
      "Epoch 380/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0056\n",
      "Epoch 380: val_loss improved from 0.06261 to 0.06248, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0056 - val_accuracy: 0.5000 - val_loss: 0.0625 - learning_rate: 5.0000e-04\n",
      "Epoch 381/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0062\n",
      "Epoch 381: val_loss improved from 0.06248 to 0.06230, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6774 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0623 - learning_rate: 5.0000e-04\n",
      "Epoch 382/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0060\n",
      "Epoch 382: val_loss improved from 0.06230 to 0.06192, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0619 - learning_rate: 5.0000e-04\n",
      "Epoch 383/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6452 - loss: 0.0065\n",
      "Epoch 383: val_loss improved from 0.06192 to 0.06161, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6452 - loss: 0.0065 - val_accuracy: 0.5000 - val_loss: 0.0616 - learning_rate: 5.0000e-04\n",
      "Epoch 384/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0066\n",
      "Epoch 384: val_loss improved from 0.06161 to 0.06122, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.0612 - learning_rate: 5.0000e-04\n",
      "Epoch 385/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6774 - loss: 0.0070\n",
      "Epoch 385: val_loss improved from 0.06122 to 0.06075, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6774 - loss: 0.0070 - val_accuracy: 0.5000 - val_loss: 0.0608 - learning_rate: 5.0000e-04\n",
      "Epoch 386/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0069\n",
      "Epoch 386: val_loss improved from 0.06075 to 0.06003, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6129 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0600 - learning_rate: 5.0000e-04\n",
      "Epoch 387/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7097 - loss: 0.0064\n",
      "Epoch 387: val_loss improved from 0.06003 to 0.05932, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7097 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0593 - learning_rate: 5.0000e-04\n",
      "Epoch 388/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0066\n",
      "Epoch 388: val_loss improved from 0.05932 to 0.05861, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7097 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.0586 - learning_rate: 5.0000e-04\n",
      "Epoch 389/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0069\n",
      "Epoch 389: val_loss improved from 0.05861 to 0.05782, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0578 - learning_rate: 5.0000e-04\n",
      "Epoch 390/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0067\n",
      "Epoch 390: val_loss improved from 0.05782 to 0.05734, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 391/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0063\n",
      "Epoch 391: val_loss improved from 0.05734 to 0.05696, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7097 - loss: 0.0063 - val_accuracy: 0.5000 - val_loss: 0.0570 - learning_rate: 5.0000e-04\n",
      "Epoch 392/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0075\n",
      "Epoch 392: val_loss improved from 0.05696 to 0.05664, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7419 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0566 - learning_rate: 5.0000e-04\n",
      "Epoch 393/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6452 - loss: 0.0078\n",
      "Epoch 393: val_loss improved from 0.05664 to 0.05609, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6452 - loss: 0.0078 - val_accuracy: 0.5000 - val_loss: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 394/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0071\n",
      "Epoch 394: val_loss improved from 0.05609 to 0.05569, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.6452 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0557 - learning_rate: 5.0000e-04\n",
      "Epoch 395/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0062\n",
      "Epoch 395: val_loss improved from 0.05569 to 0.05553, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7742 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0555 - learning_rate: 5.0000e-04\n",
      "Epoch 396/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0075\n",
      "Epoch 396: val_loss improved from 0.05553 to 0.05551, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7097 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0555 - learning_rate: 5.0000e-04\n",
      "Epoch 397/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7419 - loss: 0.0086\n",
      "Epoch 397: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7419 - loss: 0.0086 - val_accuracy: 0.5000 - val_loss: 0.0557 - learning_rate: 5.0000e-04\n",
      "Epoch 398/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7742 - loss: 0.0073\n",
      "Epoch 398: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7742 - loss: 0.0073 - val_accuracy: 0.5000 - val_loss: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 399/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7419 - loss: 0.0069\n",
      "Epoch 399: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7419 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0567 - learning_rate: 5.0000e-04\n",
      "Epoch 400/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0060\n",
      "Epoch 400: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7742 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 401/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0067\n",
      "Epoch 401: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7419 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 0.0574 - learning_rate: 5.0000e-04\n",
      "Epoch 402/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7097 - loss: 0.0071\n",
      "Epoch 402: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7097 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 403/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6774 - loss: 0.0064\n",
      "Epoch 403: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6774 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0567 - learning_rate: 5.0000e-04\n",
      "Epoch 404/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7419 - loss: 0.0056\n",
      "Epoch 404: val_loss did not improve from 0.05551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7419 - loss: 0.0056 - val_accuracy: 0.5000 - val_loss: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 405/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0075\n",
      "Epoch 405: val_loss improved from 0.05551 to 0.05526, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7419 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0553 - learning_rate: 5.0000e-04\n",
      "Epoch 406/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8065 - loss: 0.0064\n",
      "Epoch 406: val_loss improved from 0.05526 to 0.05444, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8065 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0544 - learning_rate: 5.0000e-04\n",
      "Epoch 407/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0075\n",
      "Epoch 407: val_loss improved from 0.05444 to 0.05367, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0075 - val_accuracy: 0.5000 - val_loss: 0.0537 - learning_rate: 5.0000e-04\n",
      "Epoch 408/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0062\n",
      "Epoch 408: val_loss improved from 0.05367 to 0.05304, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0530 - learning_rate: 5.0000e-04\n",
      "Epoch 409/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0062\n",
      "Epoch 409: val_loss improved from 0.05304 to 0.05249, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7419 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0525 - learning_rate: 5.0000e-04\n",
      "Epoch 410/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0076\n",
      "Epoch 410: val_loss improved from 0.05249 to 0.05199, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7742 - loss: 0.0076 - val_accuracy: 0.5000 - val_loss: 0.0520 - learning_rate: 5.0000e-04\n",
      "Epoch 411/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0064\n",
      "Epoch 411: val_loss improved from 0.05199 to 0.05157, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6452 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0516 - learning_rate: 5.0000e-04\n",
      "Epoch 412/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6774 - loss: 0.0067\n",
      "Epoch 412: val_loss improved from 0.05157 to 0.05114, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6774 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 0.0511 - learning_rate: 5.0000e-04\n",
      "Epoch 413/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0073\n",
      "Epoch 413: val_loss improved from 0.05114 to 0.05090, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6774 - loss: 0.0073 - val_accuracy: 0.5000 - val_loss: 0.0509 - learning_rate: 5.0000e-04\n",
      "Epoch 414/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0070\n",
      "Epoch 414: val_loss improved from 0.05090 to 0.05073, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7097 - loss: 0.0070 - val_accuracy: 0.5000 - val_loss: 0.0507 - learning_rate: 5.0000e-04\n",
      "Epoch 415/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0069\n",
      "Epoch 415: val_loss improved from 0.05073 to 0.05029, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6452 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0503 - learning_rate: 5.0000e-04\n",
      "Epoch 416/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0062\n",
      "Epoch 416: val_loss improved from 0.05029 to 0.05003, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0500 - learning_rate: 5.0000e-04\n",
      "Epoch 417/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6774 - loss: 0.0073\n",
      "Epoch 417: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6774 - loss: 0.0073 - val_accuracy: 0.5000 - val_loss: 0.0501 - learning_rate: 5.0000e-04\n",
      "Epoch 418/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0074\n",
      "Epoch 418: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7097 - loss: 0.0074 - val_accuracy: 0.5000 - val_loss: 0.0503 - learning_rate: 5.0000e-04\n",
      "Epoch 419/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7097 - loss: 0.0066\n",
      "Epoch 419: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7097 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.0504 - learning_rate: 5.0000e-04\n",
      "Epoch 420/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0063\n",
      "Epoch 420: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7097 - loss: 0.0063 - val_accuracy: 0.5000 - val_loss: 0.0507 - learning_rate: 5.0000e-04\n",
      "Epoch 421/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0061\n",
      "Epoch 421: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7419 - loss: 0.0061 - val_accuracy: 0.5000 - val_loss: 0.0511 - learning_rate: 5.0000e-04\n",
      "Epoch 422/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7419 - loss: 0.0064\n",
      "Epoch 422: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7419 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0514 - learning_rate: 5.0000e-04\n",
      "Epoch 423/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6452 - loss: 0.0069\n",
      "Epoch 423: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6452 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0516 - learning_rate: 5.0000e-04\n",
      "Epoch 424/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0072\n",
      "Epoch 424: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7419 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0516 - learning_rate: 5.0000e-04\n",
      "Epoch 425/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7419 - loss: 0.0065\n",
      "Epoch 425: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7419 - loss: 0.0065 - val_accuracy: 0.5000 - val_loss: 0.0515 - learning_rate: 5.0000e-04\n",
      "Epoch 426/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 426: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.5000 - val_loss: 0.0513 - learning_rate: 5.0000e-04\n",
      "Epoch 427/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0068\n",
      "Epoch 427: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0068 - val_accuracy: 0.5000 - val_loss: 0.0512 - learning_rate: 2.5000e-04\n",
      "Epoch 428/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6774 - loss: 0.0071\n",
      "Epoch 428: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6774 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0509 - learning_rate: 2.5000e-04\n",
      "Epoch 429/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0081\n",
      "Epoch 429: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7097 - loss: 0.0081 - val_accuracy: 0.5000 - val_loss: 0.0506 - learning_rate: 2.5000e-04\n",
      "Epoch 430/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7419 - loss: 0.0067\n",
      "Epoch 430: val_loss did not improve from 0.05003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7419 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 0.0502 - learning_rate: 2.5000e-04\n",
      "Epoch 431/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0060\n",
      "Epoch 431: val_loss improved from 0.05003 to 0.04982, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6774 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0498 - learning_rate: 2.5000e-04\n",
      "Epoch 432/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0070\n",
      "Epoch 432: val_loss improved from 0.04982 to 0.04947, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7097 - loss: 0.0070 - val_accuracy: 0.5000 - val_loss: 0.0495 - learning_rate: 2.5000e-04\n",
      "Epoch 433/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0064\n",
      "Epoch 433: val_loss improved from 0.04947 to 0.04907, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0491 - learning_rate: 2.5000e-04\n",
      "Epoch 434/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7419 - loss: 0.0072\n",
      "Epoch 434: val_loss improved from 0.04907 to 0.04859, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7419 - loss: 0.0072 - val_accuracy: 0.5000 - val_loss: 0.0486 - learning_rate: 2.5000e-04\n",
      "Epoch 435/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0053\n",
      "Epoch 435: val_loss improved from 0.04859 to 0.04816, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7742 - loss: 0.0053 - val_accuracy: 0.5000 - val_loss: 0.0482 - learning_rate: 2.5000e-04\n",
      "Epoch 436/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 436: val_loss improved from 0.04816 to 0.04775, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.5000 - val_loss: 0.0477 - learning_rate: 2.5000e-04\n",
      "Epoch 437/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8065 - loss: 0.0071\n",
      "Epoch 437: val_loss improved from 0.04775 to 0.04714, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8065 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0471 - learning_rate: 2.5000e-04\n",
      "Epoch 438/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0053\n",
      "Epoch 438: val_loss improved from 0.04714 to 0.04646, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0053 - val_accuracy: 0.5000 - val_loss: 0.0465 - learning_rate: 2.5000e-04\n",
      "Epoch 439/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6774 - loss: 0.0050\n",
      "Epoch 439: val_loss improved from 0.04646 to 0.04590, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6774 - loss: 0.0050 - val_accuracy: 0.5000 - val_loss: 0.0459 - learning_rate: 2.5000e-04\n",
      "Epoch 440/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0060\n",
      "Epoch 440: val_loss improved from 0.04590 to 0.04537, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6452 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0454 - learning_rate: 2.5000e-04\n",
      "Epoch 441/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0051\n",
      "Epoch 441: val_loss improved from 0.04537 to 0.04493, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7419 - loss: 0.0051 - val_accuracy: 0.5000 - val_loss: 0.0449 - learning_rate: 2.5000e-04\n",
      "Epoch 442/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6129 - loss: 0.0066\n",
      "Epoch 442: val_loss improved from 0.04493 to 0.04452, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6129 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.0445 - learning_rate: 2.5000e-04\n",
      "Epoch 443/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0074\n",
      "Epoch 443: val_loss improved from 0.04452 to 0.04420, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0074 - val_accuracy: 0.5000 - val_loss: 0.0442 - learning_rate: 2.5000e-04\n",
      "Epoch 444/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7097 - loss: 0.0062\n",
      "Epoch 444: val_loss improved from 0.04420 to 0.04390, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7097 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0439 - learning_rate: 2.5000e-04\n",
      "Epoch 445/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0059\n",
      "Epoch 445: val_loss improved from 0.04390 to 0.04368, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0059 - val_accuracy: 0.5000 - val_loss: 0.0437 - learning_rate: 2.5000e-04\n",
      "Epoch 446/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0069\n",
      "Epoch 446: val_loss improved from 0.04368 to 0.04349, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7097 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0435 - learning_rate: 2.5000e-04\n",
      "Epoch 447/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8065 - loss: 0.0064\n",
      "Epoch 447: val_loss improved from 0.04349 to 0.04331, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8065 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0433 - learning_rate: 2.5000e-04\n",
      "Epoch 448/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0065\n",
      "Epoch 448: val_loss improved from 0.04331 to 0.04321, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0065 - val_accuracy: 0.5000 - val_loss: 0.0432 - learning_rate: 2.5000e-04\n",
      "Epoch 449/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7419 - loss: 0.0063\n",
      "Epoch 449: val_loss improved from 0.04321 to 0.04306, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7419 - loss: 0.0063 - val_accuracy: 0.5000 - val_loss: 0.0431 - learning_rate: 2.5000e-04\n",
      "Epoch 450/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0061\n",
      "Epoch 450: val_loss improved from 0.04306 to 0.04296, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6129 - loss: 0.0061 - val_accuracy: 0.5000 - val_loss: 0.0430 - learning_rate: 2.5000e-04\n",
      "Epoch 451/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0061\n",
      "Epoch 451: val_loss improved from 0.04296 to 0.04285, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6774 - loss: 0.0061 - val_accuracy: 0.5000 - val_loss: 0.0429 - learning_rate: 2.5000e-04\n",
      "Epoch 452/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0073\n",
      "Epoch 452: val_loss improved from 0.04285 to 0.04276, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7097 - loss: 0.0073 - val_accuracy: 0.5000 - val_loss: 0.0428 - learning_rate: 2.5000e-04\n",
      "Epoch 453/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8065 - loss: 0.0066\n",
      "Epoch 453: val_loss improved from 0.04276 to 0.04271, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8065 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.0427 - learning_rate: 2.5000e-04\n",
      "Epoch 454/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6774 - loss: 0.0067\n",
      "Epoch 454: val_loss improved from 0.04271 to 0.04256, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6774 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 0.0426 - learning_rate: 2.5000e-04\n",
      "Epoch 455/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 455: val_loss improved from 0.04256 to 0.04250, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.5000 - val_loss: 0.0425 - learning_rate: 2.5000e-04\n",
      "Epoch 456/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0054\n",
      "Epoch 456: val_loss did not improve from 0.04250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6452 - loss: 0.0054 - val_accuracy: 0.5000 - val_loss: 0.0425 - learning_rate: 2.5000e-04\n",
      "Epoch 457/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6774 - loss: 0.0058\n",
      "Epoch 457: val_loss did not improve from 0.04250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6774 - loss: 0.0058 - val_accuracy: 0.5000 - val_loss: 0.0426 - learning_rate: 2.5000e-04\n",
      "Epoch 458/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0069\n",
      "Epoch 458: val_loss improved from 0.04250 to 0.04249, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7742 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0425 - learning_rate: 2.5000e-04\n",
      "Epoch 459/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0060\n",
      "Epoch 459: val_loss improved from 0.04249 to 0.04242, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7742 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0424 - learning_rate: 2.5000e-04\n",
      "Epoch 460/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0061\n",
      "Epoch 460: val_loss improved from 0.04242 to 0.04222, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7097 - loss: 0.0061 - val_accuracy: 0.5000 - val_loss: 0.0422 - learning_rate: 2.5000e-04\n",
      "Epoch 461/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6774 - loss: 0.0063\n",
      "Epoch 461: val_loss improved from 0.04222 to 0.04201, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6774 - loss: 0.0063 - val_accuracy: 0.5000 - val_loss: 0.0420 - learning_rate: 2.5000e-04\n",
      "Epoch 462/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7097 - loss: 0.0051\n",
      "Epoch 462: val_loss improved from 0.04201 to 0.04184, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7097 - loss: 0.0051 - val_accuracy: 0.5000 - val_loss: 0.0418 - learning_rate: 2.5000e-04\n",
      "Epoch 463/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0069\n",
      "Epoch 463: val_loss improved from 0.04184 to 0.04161, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7097 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0416 - learning_rate: 2.5000e-04\n",
      "Epoch 464/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5806 - loss: 0.0053\n",
      "Epoch 464: val_loss improved from 0.04161 to 0.04142, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5806 - loss: 0.0053 - val_accuracy: 0.5000 - val_loss: 0.0414 - learning_rate: 2.5000e-04\n",
      "Epoch 465/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0056\n",
      "Epoch 465: val_loss improved from 0.04142 to 0.04124, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6452 - loss: 0.0056 - val_accuracy: 0.5000 - val_loss: 0.0412 - learning_rate: 2.5000e-04\n",
      "Epoch 466/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0052\n",
      "Epoch 466: val_loss improved from 0.04124 to 0.04110, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7097 - loss: 0.0052 - val_accuracy: 0.5000 - val_loss: 0.0411 - learning_rate: 2.5000e-04\n",
      "Epoch 467/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7097 - loss: 0.0060\n",
      "Epoch 467: val_loss improved from 0.04110 to 0.04099, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7097 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0410 - learning_rate: 2.5000e-04\n",
      "Epoch 468/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0059\n",
      "Epoch 468: val_loss improved from 0.04099 to 0.04095, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6774 - loss: 0.0059 - val_accuracy: 0.5000 - val_loss: 0.0410 - learning_rate: 2.5000e-04\n",
      "Epoch 469/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0060\n",
      "Epoch 469: val_loss did not improve from 0.04095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7742 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0410 - learning_rate: 2.5000e-04\n",
      "Epoch 470/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6774 - loss: 0.0063\n",
      "Epoch 470: val_loss did not improve from 0.04095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6774 - loss: 0.0063 - val_accuracy: 0.5000 - val_loss: 0.0410 - learning_rate: 2.5000e-04\n",
      "Epoch 471/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 471: val_loss improved from 0.04095 to 0.04086, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.5000 - val_loss: 0.0409 - learning_rate: 2.5000e-04\n",
      "Epoch 472/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0061\n",
      "Epoch 472: val_loss improved from 0.04086 to 0.04064, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0061 - val_accuracy: 0.5000 - val_loss: 0.0406 - learning_rate: 2.5000e-04\n",
      "Epoch 473/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0068\n",
      "Epoch 473: val_loss improved from 0.04064 to 0.04038, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.6774 - loss: 0.0068 - val_accuracy: 0.5000 - val_loss: 0.0404 - learning_rate: 2.5000e-04\n",
      "Epoch 474/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0055\n",
      "Epoch 474: val_loss improved from 0.04038 to 0.04005, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6452 - loss: 0.0055 - val_accuracy: 0.5000 - val_loss: 0.0400 - learning_rate: 2.5000e-04\n",
      "Epoch 475/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6774 - loss: 0.0076\n",
      "Epoch 475: val_loss improved from 0.04005 to 0.03951, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0076 - val_accuracy: 0.5000 - val_loss: 0.0395 - learning_rate: 2.5000e-04\n",
      "Epoch 476/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0062\n",
      "Epoch 476: val_loss improved from 0.03951 to 0.03898, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0062 - val_accuracy: 0.5000 - val_loss: 0.0390 - learning_rate: 2.5000e-04\n",
      "Epoch 477/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0063\n",
      "Epoch 477: val_loss improved from 0.03898 to 0.03854, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6774 - loss: 0.0063 - val_accuracy: 0.5000 - val_loss: 0.0385 - learning_rate: 2.5000e-04\n",
      "Epoch 478/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0069\n",
      "Epoch 478: val_loss improved from 0.03854 to 0.03823, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7419 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.0382 - learning_rate: 2.5000e-04\n",
      "Epoch 479/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8065 - loss: 0.0055\n",
      "Epoch 479: val_loss improved from 0.03823 to 0.03799, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8065 - loss: 0.0055 - val_accuracy: 0.5000 - val_loss: 0.0380 - learning_rate: 2.5000e-04\n",
      "Epoch 480/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8065 - loss: 0.0074\n",
      "Epoch 480: val_loss improved from 0.03799 to 0.03789, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8065 - loss: 0.0074 - val_accuracy: 0.5000 - val_loss: 0.0379 - learning_rate: 2.5000e-04\n",
      "Epoch 481/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6129 - loss: 0.0065\n",
      "Epoch 481: val_loss improved from 0.03789 to 0.03768, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6129 - loss: 0.0065 - val_accuracy: 0.5000 - val_loss: 0.0377 - learning_rate: 2.5000e-04\n",
      "Epoch 482/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0052\n",
      "Epoch 482: val_loss improved from 0.03768 to 0.03761, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6774 - loss: 0.0052 - val_accuracy: 0.5000 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 483/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0073\n",
      "Epoch 483: val_loss did not improve from 0.03761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6774 - loss: 0.0073 - val_accuracy: 0.5000 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 484/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7742 - loss: 0.0063\n",
      "Epoch 484: val_loss did not improve from 0.03761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7742 - loss: 0.0063 - val_accuracy: 0.5000 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 485/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6129 - loss: 0.0066\n",
      "Epoch 485: val_loss improved from 0.03761 to 0.03760, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6129 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 486/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0059\n",
      "Epoch 486: val_loss improved from 0.03760 to 0.03748, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6774 - loss: 0.0059 - val_accuracy: 0.5000 - val_loss: 0.0375 - learning_rate: 2.5000e-04\n",
      "Epoch 487/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0053\n",
      "Epoch 487: val_loss improved from 0.03748 to 0.03725, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6774 - loss: 0.0053 - val_accuracy: 0.5000 - val_loss: 0.0372 - learning_rate: 2.5000e-04\n",
      "Epoch 488/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6774 - loss: 0.0060\n",
      "Epoch 488: val_loss improved from 0.03725 to 0.03706, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6774 - loss: 0.0060 - val_accuracy: 0.5000 - val_loss: 0.0371 - learning_rate: 2.5000e-04\n",
      "Epoch 489/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6129 - loss: 0.0057\n",
      "Epoch 489: val_loss improved from 0.03706 to 0.03686, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6129 - loss: 0.0057 - val_accuracy: 0.5000 - val_loss: 0.0369 - learning_rate: 2.5000e-04\n",
      "Epoch 490/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0045\n",
      "Epoch 490: val_loss improved from 0.03686 to 0.03667, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7742 - loss: 0.0045 - val_accuracy: 0.5000 - val_loss: 0.0367 - learning_rate: 2.5000e-04\n",
      "Epoch 491/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0049\n",
      "Epoch 491: val_loss improved from 0.03667 to 0.03654, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0049 - val_accuracy: 0.5000 - val_loss: 0.0365 - learning_rate: 2.5000e-04\n",
      "Epoch 492/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7419 - loss: 0.0064\n",
      "Epoch 492: val_loss improved from 0.03654 to 0.03641, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7419 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0364 - learning_rate: 2.5000e-04\n",
      "Epoch 493/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6774 - loss: 0.0067\n",
      "Epoch 493: val_loss improved from 0.03641 to 0.03632, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6774 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 0.0363 - learning_rate: 2.5000e-04\n",
      "Epoch 494/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0071\n",
      "Epoch 494: val_loss improved from 0.03632 to 0.03621, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6774 - loss: 0.0071 - val_accuracy: 0.5000 - val_loss: 0.0362 - learning_rate: 2.5000e-04\n",
      "Epoch 495/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 495: val_loss improved from 0.03621 to 0.03616, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.5000 - val_loss: 0.0362 - learning_rate: 2.5000e-04\n",
      "Epoch 496/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5806 - loss: 0.0064\n",
      "Epoch 496: val_loss improved from 0.03616 to 0.03614, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5806 - loss: 0.0064 - val_accuracy: 0.5000 - val_loss: 0.0361 - learning_rate: 2.5000e-04\n",
      "Epoch 497/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0072\n",
      "Epoch 497: val_loss improved from 0.03614 to 0.03607, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7097 - loss: 0.0072 - val_accuracy: 0.3750 - val_loss: 0.0361 - learning_rate: 2.5000e-04\n",
      "Epoch 498/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8065 - loss: 0.0058\n",
      "Epoch 498: val_loss improved from 0.03607 to 0.03595, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8065 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0359 - learning_rate: 2.5000e-04\n",
      "Epoch 499/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0060\n",
      "Epoch 499: val_loss improved from 0.03595 to 0.03590, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7097 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0359 - learning_rate: 2.5000e-04\n",
      "Epoch 500/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0051\n",
      "Epoch 500: val_loss improved from 0.03590 to 0.03576, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6452 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0358 - learning_rate: 2.5000e-04\n",
      "Epoch 501/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0064\n",
      "Epoch 501: val_loss improved from 0.03576 to 0.03574, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0357 - learning_rate: 2.5000e-04\n",
      "Epoch 502/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7419 - loss: 0.0071\n",
      "Epoch 502: val_loss improved from 0.03574 to 0.03569, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7419 - loss: 0.0071 - val_accuracy: 0.3750 - val_loss: 0.0357 - learning_rate: 2.5000e-04\n",
      "Epoch 503/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7742 - loss: 0.0059\n",
      "Epoch 503: val_loss improved from 0.03569 to 0.03565, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7742 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0357 - learning_rate: 2.5000e-04\n",
      "Epoch 504/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0068\n",
      "Epoch 504: val_loss improved from 0.03565 to 0.03559, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6774 - loss: 0.0068 - val_accuracy: 0.3750 - val_loss: 0.0356 - learning_rate: 2.5000e-04\n",
      "Epoch 505/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6774 - loss: 0.0068\n",
      "Epoch 505: val_loss improved from 0.03559 to 0.03553, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6774 - loss: 0.0068 - val_accuracy: 0.3750 - val_loss: 0.0355 - learning_rate: 2.5000e-04\n",
      "Epoch 506/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7742 - loss: 0.0049\n",
      "Epoch 506: val_loss improved from 0.03553 to 0.03545, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7742 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 507/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0055\n",
      "Epoch 507: val_loss improved from 0.03545 to 0.03539, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7742 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 508/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0064\n",
      "Epoch 508: val_loss did not improve from 0.03539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7097 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 509/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 509: val_loss did not improve from 0.03539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0355 - learning_rate: 2.5000e-04\n",
      "Epoch 510/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0070\n",
      "Epoch 510: val_loss did not improve from 0.03539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7419 - loss: 0.0070 - val_accuracy: 0.3750 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 511/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6774 - loss: 0.0063\n",
      "Epoch 511: val_loss improved from 0.03539 to 0.03535, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6774 - loss: 0.0063 - val_accuracy: 0.3750 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 512/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6774 - loss: 0.0055\n",
      "Epoch 512: val_loss improved from 0.03535 to 0.03520, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6774 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0352 - learning_rate: 2.5000e-04\n",
      "Epoch 513/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8065 - loss: 0.0049\n",
      "Epoch 513: val_loss improved from 0.03520 to 0.03501, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8065 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0350 - learning_rate: 2.5000e-04\n",
      "Epoch 514/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0051\n",
      "Epoch 514: val_loss improved from 0.03501 to 0.03485, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6774 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0348 - learning_rate: 2.5000e-04\n",
      "Epoch 515/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0070\n",
      "Epoch 515: val_loss improved from 0.03485 to 0.03473, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7097 - loss: 0.0070 - val_accuracy: 0.3750 - val_loss: 0.0347 - learning_rate: 2.5000e-04\n",
      "Epoch 516/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9032 - loss: 0.0058\n",
      "Epoch 516: val_loss improved from 0.03473 to 0.03468, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9032 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0347 - learning_rate: 2.5000e-04\n",
      "Epoch 517/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6129 - loss: 0.0051\n",
      "Epoch 517: val_loss improved from 0.03468 to 0.03459, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6129 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0346 - learning_rate: 2.5000e-04\n",
      "Epoch 518/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6452 - loss: 0.0057\n",
      "Epoch 518: val_loss improved from 0.03459 to 0.03444, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6452 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 519/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0056\n",
      "Epoch 519: val_loss improved from 0.03444 to 0.03427, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0343 - learning_rate: 2.5000e-04\n",
      "Epoch 520/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6452 - loss: 0.0054\n",
      "Epoch 520: val_loss improved from 0.03427 to 0.03405, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6452 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0341 - learning_rate: 2.5000e-04\n",
      "Epoch 521/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6452 - loss: 0.0050\n",
      "Epoch 521: val_loss improved from 0.03405 to 0.03383, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6452 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0338 - learning_rate: 2.5000e-04\n",
      "Epoch 522/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6129 - loss: 0.0060\n",
      "Epoch 522: val_loss improved from 0.03383 to 0.03365, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6129 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0337 - learning_rate: 2.5000e-04\n",
      "Epoch 523/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8065 - loss: 0.0064\n",
      "Epoch 523: val_loss improved from 0.03365 to 0.03351, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8065 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0335 - learning_rate: 2.5000e-04\n",
      "Epoch 524/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7742 - loss: 0.0052\n",
      "Epoch 524: val_loss improved from 0.03351 to 0.03334, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7742 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0333 - learning_rate: 2.5000e-04\n",
      "Epoch 525/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8065 - loss: 0.0054\n",
      "Epoch 525: val_loss improved from 0.03334 to 0.03319, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8065 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0332 - learning_rate: 2.5000e-04\n",
      "Epoch 526/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6774 - loss: 0.0057\n",
      "Epoch 526: val_loss improved from 0.03319 to 0.03312, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0331 - learning_rate: 2.5000e-04\n",
      "Epoch 527/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0046\n",
      "Epoch 527: val_loss improved from 0.03312 to 0.03304, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 528/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7419 - loss: 0.0060\n",
      "Epoch 528: val_loss improved from 0.03304 to 0.03297, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7419 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 529/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8710 - loss: 0.0058\n",
      "Epoch 529: val_loss improved from 0.03297 to 0.03291, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8710 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 530/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7097 - loss: 0.0051\n",
      "Epoch 530: val_loss improved from 0.03291 to 0.03291, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7097 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 531/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0064\n",
      "Epoch 531: val_loss did not improve from 0.03291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7742 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 532/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6774 - loss: 0.0050\n",
      "Epoch 532: val_loss did not improve from 0.03291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6774 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 533/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 533: val_loss did not improve from 0.03291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 534/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0052\n",
      "Epoch 534: val_loss did not improve from 0.03291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 535/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7097 - loss: 0.0052\n",
      "Epoch 535: val_loss did not improve from 0.03291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7097 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 536/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7097 - loss: 0.0060\n",
      "Epoch 536: val_loss improved from 0.03291 to 0.03290, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7097 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 537/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 537: val_loss improved from 0.03290 to 0.03281, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 538/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0060\n",
      "Epoch 538: val_loss improved from 0.03281 to 0.03272, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7097 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0327 - learning_rate: 2.5000e-04\n",
      "Epoch 539/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0056\n",
      "Epoch 539: val_loss improved from 0.03272 to 0.03255, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7419 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0326 - learning_rate: 2.5000e-04\n",
      "Epoch 540/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7742 - loss: 0.0044\n",
      "Epoch 540: val_loss improved from 0.03255 to 0.03243, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7742 - loss: 0.0044 - val_accuracy: 0.3750 - val_loss: 0.0324 - learning_rate: 2.5000e-04\n",
      "Epoch 541/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6774 - loss: 0.0047\n",
      "Epoch 541: val_loss improved from 0.03243 to 0.03230, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6774 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0323 - learning_rate: 2.5000e-04\n",
      "Epoch 542/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0064\n",
      "Epoch 542: val_loss improved from 0.03230 to 0.03212, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7419 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0321 - learning_rate: 2.5000e-04\n",
      "Epoch 543/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6452 - loss: 0.0047\n",
      "Epoch 543: val_loss improved from 0.03212 to 0.03191, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6452 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0319 - learning_rate: 2.5000e-04\n",
      "Epoch 544/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7742 - loss: 0.0061\n",
      "Epoch 544: val_loss improved from 0.03191 to 0.03170, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7742 - loss: 0.0061 - val_accuracy: 0.3750 - val_loss: 0.0317 - learning_rate: 2.5000e-04\n",
      "Epoch 545/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0059\n",
      "Epoch 545: val_loss improved from 0.03170 to 0.03153, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7419 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0315 - learning_rate: 2.5000e-04\n",
      "Epoch 546/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0057\n",
      "Epoch 546: val_loss improved from 0.03153 to 0.03139, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0314 - learning_rate: 2.5000e-04\n",
      "Epoch 547/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7097 - loss: 0.0053\n",
      "Epoch 547: val_loss improved from 0.03139 to 0.03131, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7097 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0313 - learning_rate: 2.5000e-04\n",
      "Epoch 548/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7419 - loss: 0.0062\n",
      "Epoch 548: val_loss improved from 0.03131 to 0.03130, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7419 - loss: 0.0062 - val_accuracy: 0.3750 - val_loss: 0.0313 - learning_rate: 2.5000e-04\n",
      "Epoch 549/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7742 - loss: 0.0055\n",
      "Epoch 549: val_loss improved from 0.03130 to 0.03125, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7742 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0312 - learning_rate: 2.5000e-04\n",
      "Epoch 550/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 550: val_loss improved from 0.03125 to 0.03124, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0312 - learning_rate: 2.5000e-04\n",
      "Epoch 551/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0053\n",
      "Epoch 551: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7097 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0313 - learning_rate: 2.5000e-04\n",
      "Epoch 552/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6774 - loss: 0.0057\n",
      "Epoch 552: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6774 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0314 - learning_rate: 2.5000e-04\n",
      "Epoch 553/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0062\n",
      "Epoch 553: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6774 - loss: 0.0062 - val_accuracy: 0.3750 - val_loss: 0.0315 - learning_rate: 2.5000e-04\n",
      "Epoch 554/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0057\n",
      "Epoch 554: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7419 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0316 - learning_rate: 2.5000e-04\n",
      "Epoch 555/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 555: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0317 - learning_rate: 2.5000e-04\n",
      "Epoch 556/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6774 - loss: 0.0046\n",
      "Epoch 556: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6774 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0317 - learning_rate: 2.5000e-04\n",
      "Epoch 557/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0062\n",
      "Epoch 557: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7419 - loss: 0.0062 - val_accuracy: 0.3750 - val_loss: 0.0318 - learning_rate: 2.5000e-04\n",
      "Epoch 558/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6774 - loss: 0.0051\n",
      "Epoch 558: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6774 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0318 - learning_rate: 2.5000e-04\n",
      "Epoch 559/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8065 - loss: 0.0052\n",
      "Epoch 559: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8065 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0319 - learning_rate: 2.5000e-04\n",
      "Epoch 560/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6774 - loss: 0.0064\n",
      "Epoch 560: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6774 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0319 - learning_rate: 1.2500e-04\n",
      "Epoch 561/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7419 - loss: 0.0057\n",
      "Epoch 561: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7419 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0319 - learning_rate: 1.2500e-04\n",
      "Epoch 562/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 562: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0318 - learning_rate: 1.2500e-04\n",
      "Epoch 563/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6129 - loss: 0.0052\n",
      "Epoch 563: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6129 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0318 - learning_rate: 1.2500e-04\n",
      "Epoch 564/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 564: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0317 - learning_rate: 1.2500e-04\n",
      "Epoch 565/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7742 - loss: 0.0057\n",
      "Epoch 565: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7742 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0316 - learning_rate: 1.2500e-04\n",
      "Epoch 566/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6452 - loss: 0.0050\n",
      "Epoch 566: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6452 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0315 - learning_rate: 1.2500e-04\n",
      "Epoch 567/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6774 - loss: 0.0061\n",
      "Epoch 567: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6774 - loss: 0.0061 - val_accuracy: 0.3750 - val_loss: 0.0314 - learning_rate: 1.2500e-04\n",
      "Epoch 568/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6774 - loss: 0.0051\n",
      "Epoch 568: val_loss did not improve from 0.03124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6774 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0313 - learning_rate: 1.2500e-04\n",
      "Epoch 569/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7097 - loss: 0.0050\n",
      "Epoch 569: val_loss improved from 0.03124 to 0.03121, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7097 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0312 - learning_rate: 1.2500e-04\n",
      "Epoch 570/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5806 - loss: 0.0054\n",
      "Epoch 570: val_loss improved from 0.03121 to 0.03112, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5806 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0311 - learning_rate: 6.2500e-05\n",
      "Epoch 571/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0051\n",
      "Epoch 571: val_loss improved from 0.03112 to 0.03105, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6774 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0310 - learning_rate: 6.2500e-05\n",
      "Epoch 572/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0062\n",
      "Epoch 572: val_loss improved from 0.03105 to 0.03098, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7097 - loss: 0.0062 - val_accuracy: 0.3750 - val_loss: 0.0310 - learning_rate: 6.2500e-05\n",
      "Epoch 573/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0052\n",
      "Epoch 573: val_loss improved from 0.03098 to 0.03091, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6774 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0309 - learning_rate: 6.2500e-05\n",
      "Epoch 574/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8065 - loss: 0.0051\n",
      "Epoch 574: val_loss improved from 0.03091 to 0.03087, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8065 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0309 - learning_rate: 6.2500e-05\n",
      "Epoch 575/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8387 - loss: 0.0056\n",
      "Epoch 575: val_loss improved from 0.03087 to 0.03083, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8387 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0308 - learning_rate: 6.2500e-05\n",
      "Epoch 576/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6452 - loss: 0.0049\n",
      "Epoch 576: val_loss improved from 0.03083 to 0.03077, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.6452 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0308 - learning_rate: 6.2500e-05\n",
      "Epoch 577/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6129 - loss: 0.0050\n",
      "Epoch 577: val_loss improved from 0.03077 to 0.03069, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6129 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0307 - learning_rate: 6.2500e-05\n",
      "Epoch 578/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7097 - loss: 0.0053\n",
      "Epoch 578: val_loss improved from 0.03069 to 0.03063, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0306 - learning_rate: 6.2500e-05\n",
      "Epoch 579/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0061\n",
      "Epoch 579: val_loss improved from 0.03063 to 0.03057, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7097 - loss: 0.0061 - val_accuracy: 0.3750 - val_loss: 0.0306 - learning_rate: 6.2500e-05\n",
      "Epoch 580/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6129 - loss: 0.0057\n",
      "Epoch 580: val_loss improved from 0.03057 to 0.03049, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6129 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0305 - learning_rate: 6.2500e-05\n",
      "Epoch 581/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0051\n",
      "Epoch 581: val_loss improved from 0.03049 to 0.03043, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7742 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0304 - learning_rate: 6.2500e-05\n",
      "Epoch 582/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7097 - loss: 0.0059\n",
      "Epoch 582: val_loss improved from 0.03043 to 0.03037, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0304 - learning_rate: 6.2500e-05\n",
      "Epoch 583/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0063\n",
      "Epoch 583: val_loss improved from 0.03037 to 0.03030, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7742 - loss: 0.0063 - val_accuracy: 0.3750 - val_loss: 0.0303 - learning_rate: 6.2500e-05\n",
      "Epoch 584/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7742 - loss: 0.0048\n",
      "Epoch 584: val_loss improved from 0.03030 to 0.03025, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7742 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0302 - learning_rate: 6.2500e-05\n",
      "Epoch 585/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0043\n",
      "Epoch 585: val_loss improved from 0.03025 to 0.03018, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7097 - loss: 0.0043 - val_accuracy: 0.3750 - val_loss: 0.0302 - learning_rate: 6.2500e-05\n",
      "Epoch 586/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7742 - loss: 0.0060\n",
      "Epoch 586: val_loss improved from 0.03018 to 0.03010, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7742 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0301 - learning_rate: 6.2500e-05\n",
      "Epoch 587/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6129 - loss: 0.0048\n",
      "Epoch 587: val_loss improved from 0.03010 to 0.03003, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6129 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0300 - learning_rate: 6.2500e-05\n",
      "Epoch 588/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7742 - loss: 0.0065\n",
      "Epoch 588: val_loss improved from 0.03003 to 0.02995, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7742 - loss: 0.0065 - val_accuracy: 0.3750 - val_loss: 0.0300 - learning_rate: 6.2500e-05\n",
      "Epoch 589/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0049\n",
      "Epoch 589: val_loss improved from 0.02995 to 0.02989, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7742 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0299 - learning_rate: 6.2500e-05\n",
      "Epoch 590/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7097 - loss: 0.0051\n",
      "Epoch 590: val_loss improved from 0.02989 to 0.02982, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7097 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0298 - learning_rate: 6.2500e-05\n",
      "Epoch 591/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0054\n",
      "Epoch 591: val_loss improved from 0.02982 to 0.02976, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6774 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0298 - learning_rate: 6.2500e-05\n",
      "Epoch 592/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6452 - loss: 0.0053\n",
      "Epoch 592: val_loss improved from 0.02976 to 0.02971, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6452 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0297 - learning_rate: 6.2500e-05\n",
      "Epoch 593/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0049\n",
      "Epoch 593: val_loss improved from 0.02971 to 0.02968, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7097 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0297 - learning_rate: 6.2500e-05\n",
      "Epoch 594/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8387 - loss: 0.0049\n",
      "Epoch 594: val_loss improved from 0.02968 to 0.02965, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8387 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0296 - learning_rate: 6.2500e-05\n",
      "Epoch 595/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7742 - loss: 0.0040\n",
      "Epoch 595: val_loss improved from 0.02965 to 0.02962, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7742 - loss: 0.0040 - val_accuracy: 0.3750 - val_loss: 0.0296 - learning_rate: 6.2500e-05\n",
      "Epoch 596/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7742 - loss: 0.0054\n",
      "Epoch 596: val_loss improved from 0.02962 to 0.02958, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7742 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0296 - learning_rate: 6.2500e-05\n",
      "Epoch 597/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0048\n",
      "Epoch 597: val_loss improved from 0.02958 to 0.02952, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6452 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0295 - learning_rate: 6.2500e-05\n",
      "Epoch 598/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6452 - loss: 0.0046\n",
      "Epoch 598: val_loss improved from 0.02952 to 0.02947, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6452 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0295 - learning_rate: 6.2500e-05\n",
      "Epoch 599/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6774 - loss: 0.0048\n",
      "Epoch 599: val_loss improved from 0.02947 to 0.02943, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0294 - learning_rate: 6.2500e-05\n",
      "Epoch 600/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0071\n",
      "Epoch 600: val_loss improved from 0.02943 to 0.02940, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7097 - loss: 0.0071 - val_accuracy: 0.3750 - val_loss: 0.0294 - learning_rate: 6.2500e-05\n",
      "Epoch 601/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7097 - loss: 0.0048\n",
      "Epoch 601: val_loss improved from 0.02940 to 0.02936, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7097 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0294 - learning_rate: 6.2500e-05\n",
      "Epoch 602/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6129 - loss: 0.0052\n",
      "Epoch 602: val_loss improved from 0.02936 to 0.02933, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.6129 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0293 - learning_rate: 6.2500e-05\n",
      "Epoch 603/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0059\n",
      "Epoch 603: val_loss improved from 0.02933 to 0.02930, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0293 - learning_rate: 6.2500e-05\n",
      "Epoch 604/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8387 - loss: 0.0053\n",
      "Epoch 604: val_loss improved from 0.02930 to 0.02926, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8387 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0293 - learning_rate: 6.2500e-05\n",
      "Epoch 605/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0049\n",
      "Epoch 605: val_loss improved from 0.02926 to 0.02924, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7742 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0292 - learning_rate: 6.2500e-05\n",
      "Epoch 606/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0043\n",
      "Epoch 606: val_loss improved from 0.02924 to 0.02921, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7419 - loss: 0.0043 - val_accuracy: 0.3750 - val_loss: 0.0292 - learning_rate: 6.2500e-05\n",
      "Epoch 607/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0049\n",
      "Epoch 607: val_loss improved from 0.02921 to 0.02917, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6774 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0292 - learning_rate: 6.2500e-05\n",
      "Epoch 608/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7742 - loss: 0.0051\n",
      "Epoch 608: val_loss improved from 0.02917 to 0.02914, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7742 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0291 - learning_rate: 6.2500e-05\n",
      "Epoch 609/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7419 - loss: 0.0053\n",
      "Epoch 609: val_loss improved from 0.02914 to 0.02911, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7419 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0291 - learning_rate: 6.2500e-05\n",
      "Epoch 610/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7742 - loss: 0.0059\n",
      "Epoch 610: val_loss improved from 0.02911 to 0.02909, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7742 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0291 - learning_rate: 6.2500e-05\n",
      "Epoch 611/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0054\n",
      "Epoch 611: val_loss improved from 0.02909 to 0.02906, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7419 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0291 - learning_rate: 6.2500e-05\n",
      "Epoch 612/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 612: val_loss improved from 0.02906 to 0.02905, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 613/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0065\n",
      "Epoch 613: val_loss improved from 0.02905 to 0.02902, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6774 - loss: 0.0065 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 614/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6774 - loss: 0.0050\n",
      "Epoch 614: val_loss improved from 0.02902 to 0.02900, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6774 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 615/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0055\n",
      "Epoch 615: val_loss improved from 0.02900 to 0.02898, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6774 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 616/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0066\n",
      "Epoch 616: val_loss improved from 0.02898 to 0.02897, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7097 - loss: 0.0066 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 617/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0062\n",
      "Epoch 617: val_loss improved from 0.02897 to 0.02896, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7097 - loss: 0.0062 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 618/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6452 - loss: 0.0052\n",
      "Epoch 618: val_loss improved from 0.02896 to 0.02894, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6452 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 6.2500e-05\n",
      "Epoch 619/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0047\n",
      "Epoch 619: val_loss improved from 0.02894 to 0.02893, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6774 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 6.2500e-05\n",
      "Epoch 620/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0057\n",
      "Epoch 620: val_loss improved from 0.02893 to 0.02892, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7419 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 6.2500e-05\n",
      "Epoch 621/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8065 - loss: 0.0054\n",
      "Epoch 621: val_loss improved from 0.02892 to 0.02889, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8065 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 6.2500e-05\n",
      "Epoch 622/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0050\n",
      "Epoch 622: val_loss improved from 0.02889 to 0.02886, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7419 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 6.2500e-05\n",
      "Epoch 623/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0059\n",
      "Epoch 623: val_loss improved from 0.02886 to 0.02884, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7097 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 624/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6774 - loss: 0.0052\n",
      "Epoch 624: val_loss improved from 0.02884 to 0.02882, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6774 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 625/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0045\n",
      "Epoch 625: val_loss improved from 0.02882 to 0.02880, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7419 - loss: 0.0045 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 626/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7097 - loss: 0.0047\n",
      "Epoch 626: val_loss improved from 0.02880 to 0.02880, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7097 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 627/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0069\n",
      "Epoch 627: val_loss improved from 0.02880 to 0.02880, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7419 - loss: 0.0069 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 628/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6452 - loss: 0.0053\n",
      "Epoch 628: val_loss improved from 0.02880 to 0.02880, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.6452 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 629/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7419 - loss: 0.0050\n",
      "Epoch 629: val_loss improved from 0.02880 to 0.02879, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7419 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 630/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7742 - loss: 0.0056\n",
      "Epoch 630: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7742 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 631/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7742 - loss: 0.0057\n",
      "Epoch 631: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7742 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 632/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7742 - loss: 0.0046\n",
      "Epoch 632: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7742 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 633/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6452 - loss: 0.0056\n",
      "Epoch 633: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6452 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 634/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 634: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 635/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7097 - loss: 0.0056\n",
      "Epoch 635: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7097 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 636/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 636: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 637/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7742 - loss: 0.0048\n",
      "Epoch 637: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7742 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 638/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0051\n",
      "Epoch 638: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7097 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 639/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0051\n",
      "Epoch 639: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7097 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 640/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8387 - loss: 0.0050\n",
      "Epoch 640: val_loss did not improve from 0.02879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8387 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 641/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8065 - loss: 0.0053\n",
      "Epoch 641: val_loss improved from 0.02879 to 0.02879, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8065 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 642/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7097 - loss: 0.0050\n",
      "Epoch 642: val_loss improved from 0.02879 to 0.02878, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7097 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 643/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 643: val_loss improved from 0.02878 to 0.02877, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 644/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8065 - loss: 0.0052\n",
      "Epoch 644: val_loss improved from 0.02877 to 0.02877, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.8065 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 645/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8065 - loss: 0.0054\n",
      "Epoch 645: val_loss did not improve from 0.02877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8065 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 646/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0048\n",
      "Epoch 646: val_loss improved from 0.02877 to 0.02875, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7097 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.5625e-05\n",
      "Epoch 647/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7419 - loss: 0.0056\n",
      "Epoch 647: val_loss improved from 0.02875 to 0.02875, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7419 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 648/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 648: val_loss improved from 0.02875 to 0.02873, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 649/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0043\n",
      "Epoch 649: val_loss improved from 0.02873 to 0.02872, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7097 - loss: 0.0043 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 650/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0064\n",
      "Epoch 650: val_loss improved from 0.02872 to 0.02870, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7742 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 651/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6129 - loss: 0.0047\n",
      "Epoch 651: val_loss improved from 0.02870 to 0.02869, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6129 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 652/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7419 - loss: 0.0053\n",
      "Epoch 652: val_loss improved from 0.02869 to 0.02868, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7419 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 653/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7419 - loss: 0.0051\n",
      "Epoch 653: val_loss did not improve from 0.02868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7419 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 654/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7097 - loss: 0.0062\n",
      "Epoch 654: val_loss did not improve from 0.02868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7097 - loss: 0.0062 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 655/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7742 - loss: 0.0048\n",
      "Epoch 655: val_loss improved from 0.02868 to 0.02868, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7742 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 656/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7097 - loss: 0.0055\n",
      "Epoch 656: val_loss did not improve from 0.02868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7097 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 657/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7742 - loss: 0.0063\n",
      "Epoch 657: val_loss improved from 0.02868 to 0.02867, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7742 - loss: 0.0063 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 658/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6129 - loss: 0.0066\n",
      "Epoch 658: val_loss improved from 0.02867 to 0.02867, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6129 - loss: 0.0066 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 659/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7097 - loss: 0.0050\n",
      "Epoch 659: val_loss improved from 0.02867 to 0.02866, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7097 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 660/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7742 - loss: 0.0053\n",
      "Epoch 660: val_loss improved from 0.02866 to 0.02866, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7742 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 661/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7419 - loss: 0.0048\n",
      "Epoch 661: val_loss improved from 0.02866 to 0.02865, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7419 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 662/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6774 - loss: 0.0050\n",
      "Epoch 662: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6774 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 663/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0054\n",
      "Epoch 663: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7097 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 664/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7419 - loss: 0.0049\n",
      "Epoch 664: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7419 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 665/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7097 - loss: 0.0060\n",
      "Epoch 665: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7097 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 666/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0053\n",
      "Epoch 666: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7097 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 667/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7419 - loss: 0.0064\n",
      "Epoch 667: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7419 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 668/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7419 - loss: 0.0060\n",
      "Epoch 668: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7419 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 669/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7419 - loss: 0.0054\n",
      "Epoch 669: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7419 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 670/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7097 - loss: 0.0055\n",
      "Epoch 670: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7097 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 671/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7419 - loss: 0.0057\n",
      "Epoch 671: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7419 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 672/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6774 - loss: 0.0049\n",
      "Epoch 672: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6774 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 673/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 673: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 674/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0054\n",
      "Epoch 674: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6774 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 675/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7419 - loss: 0.0045\n",
      "Epoch 675: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7419 - loss: 0.0045 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 676/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7419 - loss: 0.0047\n",
      "Epoch 676: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7419 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 677/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6774 - loss: 0.0058\n",
      "Epoch 677: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6774 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 678/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7419 - loss: 0.0053\n",
      "Epoch 678: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7419 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 679/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7419 - loss: 0.0057\n",
      "Epoch 679: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7419 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 680/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7097 - loss: 0.0042\n",
      "Epoch 680: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7097 - loss: 0.0042 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 681/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6129 - loss: 0.0053\n",
      "Epoch 681: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6129 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 3.9063e-06\n",
      "Epoch 682/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7097 - loss: 0.0060\n",
      "Epoch 682: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7097 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 683/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7419 - loss: 0.0049\n",
      "Epoch 683: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7419 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 684/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6129 - loss: 0.0048\n",
      "Epoch 684: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6129 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 685/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8065 - loss: 0.0064\n",
      "Epoch 685: val_loss improved from 0.02865 to 0.02865, saving model to best_lstm_yolo_model_20240902_1930.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8065 - loss: 0.0064 - val_accuracy: 0.3750 - val_loss: 0.0286 - learning_rate: 1.9531e-06\n",
      "Epoch 686/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7419 - loss: 0.0044\n",
      "Epoch 686: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7419 - loss: 0.0044 - val_accuracy: 0.3750 - val_loss: 0.0286 - learning_rate: 1.9531e-06\n",
      "Epoch 687/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8065 - loss: 0.0054\n",
      "Epoch 687: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8065 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 688/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7097 - loss: 0.0045\n",
      "Epoch 688: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7097 - loss: 0.0045 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 689/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7742 - loss: 0.0049\n",
      "Epoch 689: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7742 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 690/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7419 - loss: 0.0048\n",
      "Epoch 690: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7419 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 691/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6774 - loss: 0.0050\n",
      "Epoch 691: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.6774 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.9531e-06\n",
      "Epoch 692/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7742 - loss: 0.0045\n",
      "Epoch 692: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7742 - loss: 0.0045 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 693/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6774 - loss: 0.0053\n",
      "Epoch 693: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6774 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 694/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8065 - loss: 0.0052\n",
      "Epoch 694: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8065 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 695/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7742 - loss: 0.0051\n",
      "Epoch 695: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7742 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 696/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7742 - loss: 0.0044\n",
      "Epoch 696: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7742 - loss: 0.0044 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 697/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7742 - loss: 0.0055\n",
      "Epoch 697: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7742 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 698/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6452 - loss: 0.0051\n",
      "Epoch 698: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6452 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 699/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7419 - loss: 0.0047\n",
      "Epoch 699: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7419 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 700/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8065 - loss: 0.0054\n",
      "Epoch 700: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8065 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 701/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7419 - loss: 0.0047\n",
      "Epoch 701: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7419 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 702/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0048\n",
      "Epoch 702: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 703/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7097 - loss: 0.0058\n",
      "Epoch 703: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7097 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 704/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6774 - loss: 0.0056\n",
      "Epoch 704: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6774 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 705/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6774 - loss: 0.0043\n",
      "Epoch 705: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6774 - loss: 0.0043 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 706/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7419 - loss: 0.0054\n",
      "Epoch 706: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7419 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 707/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6452 - loss: 0.0053\n",
      "Epoch 707: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6452 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 708/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7097 - loss: 0.0046\n",
      "Epoch 708: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7097 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 709/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7742 - loss: 0.0057\n",
      "Epoch 709: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7742 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 710/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8065 - loss: 0.0059\n",
      "Epoch 710: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8065 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 711/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7419 - loss: 0.0053\n",
      "Epoch 711: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7419 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 712/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6452 - loss: 0.0060\n",
      "Epoch 712: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6452 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 713/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6129 - loss: 0.0055\n",
      "Epoch 713: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6129 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 714/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7419 - loss: 0.0051\n",
      "Epoch 714: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7419 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 715/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 715: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 716/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7097 - loss: 0.0055\n",
      "Epoch 716: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7097 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 717/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8387 - loss: 0.0051\n",
      "Epoch 717: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8387 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 718/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6129 - loss: 0.0055\n",
      "Epoch 718: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6129 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 719/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6452 - loss: 0.0054\n",
      "Epoch 719: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6452 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 720/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6774 - loss: 0.0058\n",
      "Epoch 720: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6774 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0287 - learning_rate: 1.0000e-06\n",
      "Epoch 721/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7097 - loss: 0.0061\n",
      "Epoch 721: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7097 - loss: 0.0061 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 722/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8065 - loss: 0.0058\n",
      "Epoch 722: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8065 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 723/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 723: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 724/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0041\n",
      "Epoch 724: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0041 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 725/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7419 - loss: 0.0056\n",
      "Epoch 725: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7419 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 726/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7742 - loss: 0.0060\n",
      "Epoch 726: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7742 - loss: 0.0060 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 727/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7097 - loss: 0.0054\n",
      "Epoch 727: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 728/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6774 - loss: 0.0052\n",
      "Epoch 728: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.6774 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 729/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6774 - loss: 0.0053\n",
      "Epoch 729: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6774 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 730/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7419 - loss: 0.0051\n",
      "Epoch 730: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7419 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 731/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 731: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 732/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6774 - loss: 0.0055\n",
      "Epoch 732: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6774 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 733/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7742 - loss: 0.0061\n",
      "Epoch 733: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7742 - loss: 0.0061 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 734/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6774 - loss: 0.0040\n",
      "Epoch 734: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6774 - loss: 0.0040 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 735/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6774 - loss: 0.0048\n",
      "Epoch 735: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6774 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 736/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0059\n",
      "Epoch 736: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6774 - loss: 0.0059 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 737/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8065 - loss: 0.0048\n",
      "Epoch 737: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8065 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 738/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7419 - loss: 0.0055\n",
      "Epoch 738: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7419 - loss: 0.0055 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 739/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6452 - loss: 0.0056\n",
      "Epoch 739: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6452 - loss: 0.0056 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 740/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6452 - loss: 0.0057\n",
      "Epoch 740: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.6452 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 741/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7097 - loss: 0.0044\n",
      "Epoch 741: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7097 - loss: 0.0044 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 742/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0053\n",
      "Epoch 742: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7097 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0288 - learning_rate: 1.0000e-06\n",
      "Epoch 743/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7097 - loss: 0.0044\n",
      "Epoch 743: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7097 - loss: 0.0044 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 744/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 744: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 745/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6774 - loss: 0.0053\n",
      "Epoch 745: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6774 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 746/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7419 - loss: 0.0051\n",
      "Epoch 746: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7419 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 747/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7419 - loss: 0.0049\n",
      "Epoch 747: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7419 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 748/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7419 - loss: 0.0047\n",
      "Epoch 748: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7419 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 749/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7419 - loss: 0.0054\n",
      "Epoch 749: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7419 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 750/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8065 - loss: 0.0049\n",
      "Epoch 750: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8065 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 751/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7097 - loss: 0.0046\n",
      "Epoch 751: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 752/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7097 - loss: 0.0050\n",
      "Epoch 752: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7097 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 753/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7097 - loss: 0.0057\n",
      "Epoch 753: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 754/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7742 - loss: 0.0052\n",
      "Epoch 754: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7742 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 755/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6774 - loss: 0.0047\n",
      "Epoch 755: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.6774 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 756/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8065 - loss: 0.0051\n",
      "Epoch 756: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8065 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 757/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7097 - loss: 0.0051\n",
      "Epoch 757: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7097 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 758/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7097 - loss: 0.0052\n",
      "Epoch 758: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7097 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 759/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6774 - loss: 0.0058\n",
      "Epoch 759: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6774 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 760/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7097 - loss: 0.0053\n",
      "Epoch 760: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7097 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 761/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6774 - loss: 0.0053\n",
      "Epoch 761: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6774 - loss: 0.0053 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 762/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7419 - loss: 0.0050\n",
      "Epoch 762: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7419 - loss: 0.0050 - val_accuracy: 0.3750 - val_loss: 0.0289 - learning_rate: 1.0000e-06\n",
      "Epoch 763/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8065 - loss: 0.0062\n",
      "Epoch 763: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8065 - loss: 0.0062 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 764/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7419 - loss: 0.0065\n",
      "Epoch 764: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7419 - loss: 0.0065 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 765/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7419 - loss: 0.0066\n",
      "Epoch 765: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7419 - loss: 0.0066 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 766/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6452 - loss: 0.0058\n",
      "Epoch 766: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6452 - loss: 0.0058 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 767/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8065 - loss: 0.0054\n",
      "Epoch 767: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8065 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 768/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8387 - loss: 0.0068\n",
      "Epoch 768: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8387 - loss: 0.0068 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 769/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7419 - loss: 0.0057\n",
      "Epoch 769: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7419 - loss: 0.0057 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 770/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6129 - loss: 0.0054\n",
      "Epoch 770: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6129 - loss: 0.0054 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 771/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7742 - loss: 0.0049\n",
      "Epoch 771: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7742 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 772/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6774 - loss: 0.0047\n",
      "Epoch 772: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6774 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 773/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7742 - loss: 0.0048\n",
      "Epoch 773: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7742 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 774/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0049\n",
      "Epoch 774: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0049 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 775/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7742 - loss: 0.0051\n",
      "Epoch 775: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7742 - loss: 0.0051 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 776/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6452 - loss: 0.0046\n",
      "Epoch 776: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6452 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 777/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7097 - loss: 0.0052\n",
      "Epoch 777: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7097 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 778/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7097 - loss: 0.0043\n",
      "Epoch 778: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7097 - loss: 0.0043 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 779/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7419 - loss: 0.0048\n",
      "Epoch 779: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7419 - loss: 0.0048 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 780/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6774 - loss: 0.0046\n",
      "Epoch 780: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6774 - loss: 0.0046 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 781/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7419 - loss: 0.0067\n",
      "Epoch 781: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7419 - loss: 0.0067 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 782/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7742 - loss: 0.0067\n",
      "Epoch 782: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7742 - loss: 0.0067 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 783/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7742 - loss: 0.0047\n",
      "Epoch 783: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7742 - loss: 0.0047 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 784/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7419 - loss: 0.0052\n",
      "Epoch 784: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7419 - loss: 0.0052 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "Epoch 785/12000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8065 - loss: 0.0043\n",
      "Epoch 785: val_loss did not improve from 0.02865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8065 - loss: 0.0043 - val_accuracy: 0.3750 - val_loss: 0.0290 - learning_rate: 1.0000e-06\n",
      "训练损失: 0.0023, 测试损失: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725276926.593463  622688 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "I0000 00:00:1725276927.332278  622688 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型成功保存为 ONNX 格式，路径为: best_lstm_yolo_model_20240902_1930.onnx\n",
      "最佳模型储存在第685轮训练后，验证集损失为0.0286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "RMSE Error: 199.30694533307985, Mean Squared Error: 39723.258458003285, Mean Absolute Error: 60.73111725761548, R2 Score: 0.560386959953734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es/miniconda3/envs/ultralytics/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'attention_3' (of type Attention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step\n",
      "预测结果：[[     365.15      885.77      388.16      944.36      385.44      933.62      3528.9     0.12141     0.67295     0.65271]\n",
      " [     108.65      862.38      133.06      959.43      123.94      911.83      5442.5     0.49596     -1.8026     0.65126]\n",
      " [     167.06      809.73      179.57       866.2      189.13      838.26      2325.2    -0.23988     0.94372     0.68372]\n",
      " [     174.21         862      191.59       969.1      185.19      902.56        5290     0.53383     -1.4003      0.6564]\n",
      " [     118.08      845.02      166.15      935.68      154.79      888.94      5755.6      0.9966     0.81211     0.67183]\n",
      " [     538.12      1110.1      597.77      1219.7      570.77      1167.1      6411.2     0.79626     0.89431     0.64634]\n",
      " [     534.94      892.65       577.9      999.73      534.39      928.56      5567.1      1.5394      2.0102     0.65799]\n",
      " [     212.43      1080.5      302.46      1231.2       216.1      1141.6        6492     0.48834     0.49503     0.62238]]\n",
      "真实数据：[[        332         909         369         994       350.5       951.5        3145      5.3151      2.4228     0.63721]\n",
      " [        125         873         179         987         152         930        6156       1.118     -1.1071     0.65625]\n",
      " [        158         804         190         870         174         837        2112         0.5      1.5708     0.67822]\n",
      " [        174         848         229         970       201.5         909        6710     0.70711      2.3562     0.65625]\n",
      " [        115         826         168         943       141.5       884.5        6201         0.5           0      0.6709]\n",
      " [        525        1092         576        1213       550.5      1152.5        6171         0.5      3.1416     0.64648]\n",
      " [        504         883         556         989         530         936        5512           0           0     0.65576]\n",
      " [        142        1069         199        1190       170.5      1129.5        6897      2.0616      1.8158      0.6416]]\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "import onnx\n",
    "import tf2onnx\n",
    "import joblib\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# 获取 videos 文件夹中的所有视频文件路径\n",
    "video_folder = 'videos'\n",
    "video_extensions = ['.mov', '.mp4', '.avi', '.mkv', '.flv', '.wmv']  # 支持的所有视频格式（小写）\n",
    "video_paths = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if os.path.splitext(f)[1].lower() in video_extensions]\n",
    "\n",
    "print(\"视频文件路径列表:\", video_paths)\n",
    "\n",
    "all_detected_objects_list = []\n",
    "for video_path in video_paths:\n",
    "    detected_objects_list = load_video_frames(video_path)\n",
    "    all_detected_objects_list.append(detected_objects_list)\n",
    "\n",
    "# 时序数据的一般格式 time、x 和 y 列\n",
    "# 使用检测到的数据来训练,  X 是输入序列，y 是对应的目标输出\n",
    "# 定义不同的时间步长度\n",
    "time_steps = 3\n",
    "num_features = 10  # 每个时间步的10 values，输出10个值，对应类目标的未来位置(x1, y1, x2, y2, cx, cy, card_area, card_velocity, angles, card_conf)\n",
    "dropout_rate = 0.3  # dropout比例\n",
    "\n",
    "X_all, y_all = [], []\n",
    "for detected_objects_list in all_detected_objects_list:\n",
    "    X, y = prepare_complex_sequence_data(detected_objects_list, time_steps)\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "\n",
    "# 填充序列，使所有样本具有相同的时间步长\n",
    "X_all = pad_sequences(X_all, maxlen=time_steps, dtype='float64', padding='post', truncating='post')\n",
    "y_all = pad_sequences(y_all, maxlen=time_steps, dtype='float64', padding='post', truncating='post')\n",
    "\n",
    "# 合并所有视频样本的数据\n",
    "X_all = np.concatenate(X_all, axis=0)\n",
    "y_all = np.concatenate(y_all, axis=0)\n",
    "\n",
    "# 归一化数据\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_all = scaler_X.fit_transform(X_all.reshape(-1, X_all.shape[-1])).reshape(X_all.shape)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_all = scaler_y.fit_transform(y_all)\n",
    "\n",
    "\n",
    "print(\"X shape:\", X_all.shape)  # 输出 (num_samples 54, sequence_length 10, num_features 10)\n",
    "print(\"y shape:\", y_all.shape)  # 输出 (num_samples, num_features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_test : {X_test}, y_test: {y_test}\")\n",
    "\n",
    "# 检查 X_train 的形状\n",
    "print(f\"Original X_train shape: {X_train.shape}, num_samples: {X_train.shape[0]}, sequence_length: {X_train.shape[1]}, num_features: {X_train.shape[2]}\")\n",
    "\n",
    "# 模型訓練\n",
    "# LSTM模型的輸入形狀: X_train.shape[1] 是sequence_length，X_train.shape[2] num_features是指定目标的7个特征值(x1, y1, x2, y2, card_area, card_velocity, card_conf)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "lstm_model = create_bilstm_attention_model(input_shape)\n",
    "\n",
    "# 定义回调函数\n",
    "# EarlyStopping：监控val_loss，如果50个epoch内没有改善，则停止训练，并恢复至最佳模型权重。\n",
    "# ReduceLROnPlateau：当val_loss停止改善时，将学习率降低一半。\n",
    "# ModelCheckpoint：在每个epoch后保存最佳模型\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'best_lstm_yolo_model_{current_time}.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "# 训练模型: 整个数据集上训练12000次，每次训练32个样本，validation_data 在每个 epoch结束后计算验证集的损失\n",
    "history = lstm_model.fit(X_train, y_train, \n",
    "                epochs=12000, \n",
    "                batch_size=32, \n",
    "                validation_data=(X_test, y_test), \n",
    "                callbacks=[early_stopping, reduce_lr, model_checkpoint])\n",
    "\n",
    "# 保存 scaler\n",
    "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
    "\n",
    "# 评估模型\n",
    "train_loss = lstm_model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"训练损失: {train_loss[0]:.4f}, 测试损失: {test_loss[0]:.4f}\")\n",
    "\n",
    "# 选择最佳模型\n",
    "# 训练过程中每个 epoch 的验证损失值\n",
    "val_loss = history.history['val_loss']\n",
    "# 验证损失最小的 epoch 对应就是最佳模型, 保存为lstm_weights_xx.h5文件\n",
    "best_epoch = np.argmin(val_loss)\n",
    "best_model = load_model(f'best_lstm_yolo_model_{current_time}.keras', custom_objects={'Attention': Attention})\n",
    "best_model.save(f'best_lstm_yolo_model_{current_time}.h5')  # 保存整个模型\n",
    "\n",
    "# 将 Keras 模型转换为 ONNX 格式\n",
    "spec = (tf.TensorSpec((None, X_train.shape[1], X_train.shape[2]), tf.float32, name=\"input\"),)\n",
    "output_path = f'best_lstm_yolo_model_{current_time}.onnx'\n",
    "model_proto, _ = tf2onnx.convert.from_keras(best_model, input_signature=spec, opset=13)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "print(f\"模型成功保存为 ONNX 格式，路径为: {output_path}\")\n",
    "# onnx_model = keras2onnx.convert_keras(lstm_model, lstm_model.name)\n",
    "# onnx.save_model(onnx_model, 'best_lstm_yolo_model.onnx')\n",
    "\n",
    "# # Load the ONNX model\n",
    "# onnx_model = onnx.load(\"best_lstm_yolo_model.onnx\")\n",
    "# # Convert the ONNX model to Core ML format\n",
    "# coreml_model = ct.convert(\n",
    "#     onnx_model,\n",
    "#     source=\"tensorflow\",\n",
    "#     minimum_deployment_target=ct.target.iOS13,  # You can specify other deployment targets if needed\n",
    "# )\n",
    "# # Save the Core ML model\n",
    "# coreml_model.save('best_lstm_yolo_model.mlmodel')\n",
    "# print(\"模型成功转换并保存为 Core ML 格式\")\n",
    "\n",
    "print(f\"最佳模型储存在第{best_epoch+1}轮训练后，验证集损失为{val_loss[best_epoch]:.4f}\")\n",
    "\n",
    "# 评估模型性能\n",
    "rmse, mse, mae, r2 = evaluate_performance(lstm_model, X_test, y_test)\n",
    "print(f\"RMSE Error: {rmse}, Mean Squared Error: {mse}, Mean Absolute Error: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# 预测未来行为 如根据最近 3 frame序列, LSTM 模型进行预测下一个时间步的目标位置\n",
    "predictions = best_model.predict(X_test)\n",
    "# inverse 转回去原来的coordinate system\n",
    "predictions = scaler_y.inverse_transform(predictions)\n",
    "print(f\"预测结果：{predictions}\")\n",
    "\n",
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "# 真实数据\n",
    "print(f\"真实数据：{y_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/es/poker-vision/best_lstm_yolo_model.mlmodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcoremltools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mct\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 加载 CoreML 模型\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m coreml_model \u001b[38;5;241m=\u001b[39m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMLModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_lstm_yolo_model.mlmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 加载保存的 MinMaxScaler\u001b[39;00m\n\u001b[1;32m      9\u001b[0m scaler_X \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler_X.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ultralytics/lib/python3.10/site-packages/coremltools/models/model.py:341\u001b[0m, in \u001b[0;36mMLModel.__init__\u001b[0;34m(self, model, is_temp_package, mil_program, skip_model_load, compute_units, weights_dir)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_temp_package \u001b[38;5;241m=\u001b[39m is_temp_package\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights_dir \u001b[38;5;241m=\u001b[39m _try_get_weights_dir_path(model)\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__proxy__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_framework_error \u001b[38;5;241m=\u001b[39m \u001b[43m_get_proxy_and_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_model_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_model_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, _Model_pb2\u001b[38;5;241m.\u001b[39mModel):\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mWhichOneof(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlProgram\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ultralytics/lib/python3.10/site-packages/coremltools/models/model.py:132\u001b[0m, in \u001b[0;36m_get_proxy_and_spec\u001b[0;34m(filename, compute_units, skip_model_load)\u001b[0m\n\u001b[1;32m    129\u001b[0m     _MLModelProxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m filename \u001b[38;5;241m=\u001b[39m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(filename)\n\u001b[0;32m--> 132\u001b[0m specification \u001b[38;5;241m=\u001b[39m \u001b[43m_load_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _MLModelProxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_model_load:\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# check if the version is supported\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     engine_version \u001b[38;5;241m=\u001b[39m _MLModelProxy\u001b[38;5;241m.\u001b[39mmaximum_supported_specification_version()\n",
      "File \u001b[0;32m~/miniconda3/envs/ultralytics/lib/python3.10/site-packages/coremltools/models/utils.py:222\u001b[0m, in \u001b[0;36mload_spec\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m    219\u001b[0m     specfile \u001b[38;5;241m=\u001b[39m model_path\n\u001b[1;32m    221\u001b[0m spec \u001b[38;5;241m=\u001b[39m _Model_pb2\u001b[38;5;241m.\u001b[39mModel()\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mspecfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    223\u001b[0m     spec\u001b[38;5;241m.\u001b[39mParseFromString(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spec\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/es/poker-vision/best_lstm_yolo_model.mlmodel'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import coremltools as ct\n",
    "\n",
    "# 加载 CoreML 模型\n",
    "coreml_model = ct.models.MLModel('best_lstm_yolo_model.mlmodel')\n",
    "\n",
    "# 加载保存的 MinMaxScaler\n",
    "scaler_X = joblib.load('scaler_X.pkl')\n",
    "scaler_y = joblib.load('scaler_y.pkl')\n",
    "\n",
    "# 假设 X_test 是你的测试数据\n",
    "X_test = np.random.rand(1, 3, 10)  # 示例数据\n",
    "\n",
    "# 数据归一化\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "\n",
    "# 准备输入数据\n",
    "input_data = {'input_1': X_test_scaled}\n",
    "\n",
    "# 执行预测\n",
    "outputs = coreml_model.predict(input_data)\n",
    "y_pred_scaled = outputs['Identity']\n",
    "\n",
    "# 反归一化预测结果\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "print(f\"预测结果（反归一化）：{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测转换后的ONNX模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx预测结果: [array([[    0.78174,     0.41031,     0.70578,     0.54379,     0.60865,     0.71896,     0.59345,     0.28221,     0.60143,      0.2476]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_model = onnx.load(f'best_lstm_yolo_model_{current_time}.onnx')\n",
    "\n",
    "# 检查模型是否有效\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# 创建 ONNX Runtime 会话\n",
    "ort_session = ort.InferenceSession(f'best_lstm_yolo_model_{current_time}.onnx')\n",
    "\n",
    "# 准备输入数据（根据实际情况调整）\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "input_data = np.random.random((1, 3, 10)).astype(np.float32)\n",
    "\n",
    "# 执行预测\n",
    "outputs = ort_session.run(None, {input_name: input_data})\n",
    "print(\"onnx预测结果:\", outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果和真实结果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test shape: (8, 10)\n",
      "predictions shape: (8, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAutCAYAAADJQAlaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3yN9/vH8dfJkBARhNgjNWtvYo8QhC7aUmr8OlSpTt1Vo60Obfm2SidtabVKB2Lvvffe1J6Jhsg6vz8+ciQEkZzk3Enez8fjPOTc933u+zrH5c5x3Z/7+tjsdrsdEREREREREREREbEEN1cHICIiIiIiIiIiIiLXqWgrIiIiIiIiIiIiYiEq2oqIiIiIiIiIiIhYiIq2IiIiIiIiIiIiIhaioq2IiIiIiIiIiIiIhahoKyIiIiIiIiIiImIhKtqKiIiIiIiIiIiIWIiKtiIiIiIiIiIiIiIWoqKtiIiIiIiIiIiIiIWoaCsiIiIit1W6dGlKly7t6jAkk2revDk2my3JsvHjx2Oz2Rg/frxrgroLgwcPxmazsWjRIleHIiIiItmIirYiIiIiYimLFi3CZrOl+NG8eXNXh2wJCcXRhIebmxv58uWjSZMmjB8/Hrvd7uoQnSYhRwYPHuzqUERERETShYerAxARERERa5s/f36GHq906dK8++67SZZdvHiRUaNGUapUKXr16nXT9nLdyy+/TO7cuYmLi+PAgQNMnTqVZcuWsX79er744gtXhwfAgw8+SIMGDShSpIirQxERERGxJBVtRUREROS2ypQpk6HHK1269E0jKA8dOsSoUaOSXSdJvfLKKxQuXNjxfOvWrdSvX5/Ro0fz0ksvERgY6MLoDD8/P/z8/FwdhoiIiIhlqT2CiIiIiIvY7Xbat2+PzWbjt99+u2ldu3btkl2XEgl9aMPDw+nbty9FihTBx8eHpk2bsmHDBgCOHz9O9+7dCQgIIGfOnLRp04a9e/fecl+JJe7z+csvv1CjRg1y5sxJkSJFeP7557ly5cpdx5waiXujTps2jUaNGuHr6+uI93a9U293i/3Bgwd58sknKVmyJF5eXhQpUoRevXpx+PDhFMXVqlUr3Nzcbrn9gAEDsNlszJ0717FsypQpNGvWjICAALy9vSlatCjBwcFMmTIlRce8lapVq9KsWTPsdjvr1q0DoFevXthsNg4cOMCnn35KpUqV8PLySjKK+fTp07z44ouULVsWLy8vChQoQKdOndi2bVuyx1m2bBnNmjXDx8cHf39/Hn30UY4ePZrstrf7ezlw4ABPP/00gYGBeHl5ERAQQPPmzR3bDh48mBYtWgAwZMiQJC0hDh065NhPdHQ0n332GbVq1cLHxwdfX1+aNGnCP//8k2xMR48epWvXruTPn5/cuXPTrFkzlixZcodPV0RERCR9aKStiIiIiIvYbDbGjRtHtWrV6NOnDw0aNKBUqVIAjBw5klmzZtGrVy8effTRVO0/Ojqa1q1bExUVxaOPPsqpU6f4/fffCQ4OZsWKFYSEhFCkSBG6d+/Ovn37mDZtGqGhoezcuRN3d/cUHePLL79k1qxZ3H///bRs2ZJZs2bxv//9j7NnzzJx4sQk2zZv3pzFixezcOFCp/ehnTx5MnPmzKFDhw48++yzREREpHpfq1evJiQkhMjISDp06EC5cuU4dOgQEydOZObMmaxcuZJ77rnntvt4/PHHWbBgARMnTuTNN99Msi42NpZJkyZRtGhRWrVqBcCYMWN49tlnKVKkCA8++CD+/v6cPHmSNWvW8Oeff9KpU6dUv5/EbpwQ7LnnnmPVqlWEhobSsWNHAgICANi/fz/Nmzfn33//pU2bNjzwwAOcPn2aKVOmMHv2bObPn0/9+vUd+5k/fz7t2rXDzc2NRx99lKJFizJ//nwaNWpEvnz5UhzfsmXLCA0N5dKlS4SEhNClSxcuXLjAxo0bGTVqFL169aJ58+YcOnSIH3/8kWbNmiXJpbx58wJw9epV2rZty6JFi6hRowZPPPEEMTExzJgxg/vvv58vvviC/v37O1534sQJgoKCOHbsGCEhIdSqVYudO3fSunVrR4FYREREJEPZRURERMSlZs6cabfZbPaGDRvaY2Nj7Rs3brTnyJHDXq5cOfulS5dStc9SpUrZAfvDDz9sj4mJcSz/6KOP7IA9b9689hdffNEeHx/vWNe3b187YJ8yZcpN+ypVqlSSZe+++64dsPv5+dl37drlWH758mV7+fLl7W5ubvZjx44leU2zZs3sgH3hwoV3/X4OHjxoB+zNmjVLsnzcuHF2wO7m5mafO3fuTa9LWD9u3Lib1i1cuNAO2N99913HsujoaHvp0qXtvr6+9g0bNiTZfunSpXZ3d3d7hw4d7hhvRESEPWfOnPZKlSrdtG7atGl2wP7KK684ltWqVcueI0cO+6lTp27a/uzZs3c8nt1+/fM9ceJEkuXbtm2z58yZ026z2ewHDx602+12e8+ePe2AvXjx4vbDhw/ftK+GDRva3d3d7bNmzUqyfPfu3XZfX1971apVHcvi4uLs99xzj91ms9mXLl3qWB4fH29/7LHH7ID9xv92JPf3EhUVZS9WrJjdzc3NPnPmzJtiOnr0qOPn5P7uEnvzzTftgP2dd95JkuMRERH2OnXq2HPkyJEkPxM+j/feey/Jfr7++mtH/KnJWxEREZHUUnsEERERERdr27Ytzz//PCtWrOD111+na9eu2O12fv31V3Lnzp2mfY8YMQIPj+s3V3Xt2hUwoz3fe++9JCMvE9Zt3rw5xft//vnnqVChguN5zpw56dq1K/Hx8axfvz7Jtj/99BM7d+6kXr16qXovt3P//fcTHByc5v1Mnz6dQ4cOMXDgQGrWrJlkXePGjbn//vsJCwu740heX19fHnjgAXbs2OFoR5Hg559/BqB79+5Jlnt6euLp6XnTvvz9/e/qPYwYMYLBgwfzzjvv0L17d+rWrcuVK1d47rnnbmpzMXDgQEqWLJlk2caNG1mxYgU9e/YkJCQkybry5cvz1FNPsXXrVkebhGXLlnHgwAE6dOhA48aNHdvabDY++OCDFI/a/vvvvzl27Bjdu3enbdu2N60vXrx4ivYTHx/PmDFjKFOmjKN9QgJfX18GDRpEdHQ0U6dOBcyI9N9++42AgABefvnlJPt68sknKVeuXIqOKyIiIuJMao8gIiIiYgEffvghixYtYsSIEQB89NFH1K5dO037zJcv300FuSJFigBQrlw5cuXKley648ePp/gYycWYUFy7ePFikuU3xuJMzioEr1q1CoDdu3cn2+v25MmTxMfHs2fPHurUqXPbfT3++OP8+uuv/Pzzz9SqVQuAiIgIpk2bRtWqValevbpj2y5duvDqq69SpUoVHnvsMVq0aEHjxo3JkyfPXb+HTz/9FDBF0zx58lCnTh2eeOIJevTocdO2yX1uCZ/BqVOnkv0Mdu3a5fizSpUqjiJ/kyZNbtq2VKlSlChRIkmv2VtZs2YNAG3atLnjtreze/duLly4QNGiRRkyZMhN68+cOQNcfx+7d+8mKiqKli1b4u3tnWRbNzc3GjVqlGyvZxEREZH0pKKtiIiIiAV4eXnRrl07Nm3ahLe3N08++WSa95lcwS9h1O3t1sXExDjlGHFxcSneT1oVKlTIKfs5f/48wE39eG8UGRl5x321adOGQoUKMWnSJEaMGIG7uzt//PEHV65c4fHHH0+y7SuvvIK/vz9jxozh008/dYyQDg0N5fPPPycwMDDF7+HEiRMULlw4Rdsm97klfAYzZsxgxowZt3xtwmcQHh4O4OiHm9wxUlK0TdhPsWLF7rjt7STEv337drZv337L7e4mfhEREZGMpvYIIiIiIhawevVqPvnkE/z9/YmKiqJv376uDilTuXGCrQRububrbmxs7E3rEop1iSUUoadNm4bdbr/lo1mzZneMyd3dna5du3Ly5EnmzZsHmNYIbm5uPPbYYzfF/3//93+sXbuWM2fO8Oeff/LQQw/x999/06FDh3QrgCf3uSV8Bl988cVtP4OePXsC4OfnB8Dp06eTPcapU6dSFEvCJGLHjh2727eRbPydOnW6bfzjxo1zavwiIiIizqSirYiIiIiLXbp0icceewwPDw8WLVpEp06d+P333/nhhx9cHVqmly9fPiD5QuDGjRtvWla/fn0AVq5c6ZTjJ4yonTBhAkePHmXx4sW0aNHitqNJ/f39eeCBB/jtt99o2bIlO3bsYN++fU6JJyXu9jNIaPOwdOnSm9YdPnyYo0ePpmg/Ca0a5syZc8dtE/rkJlfMvvfee8mTJw/r1q1L0ajx8uXL4+3tzbp164iKikqyLj4+nhUrVqQkfBERERGnUtFWRERExMWeffZZDhw4wIgRI6hSpQrffvstJUqUYMCAAezZs8fV4TnNkSNH2LVrF5cvX86wY9auXRubzcakSZOSFOT27t3LqFGjbtr+/vvvp2TJknz22WcsWbLkpvUxMTEsW7YsxcevVasWlSpV4s8//+Trr7/Gbrff1BoBYNGiRdjt9puOlXCr/429VtNTvXr1qF+/Pr/++iu//fbbTevj4+NZvHix43njxo0JDAxk+vTpST4bu93Om2++meJRwvfddx/FixdnwoQJzJ49+6b1iQvv+fPnB0i2IOzh4UHfvn05fPgwr7zySrKF223btjlG1np5efHII49w+vRpRz/gBN99912W+jcoIiIimYd62oqIiIi40IQJE5gwYQIdO3akX79+gBkdOmHCBFq0aMFjjz3GypUr8fT0dHGkadejRw8WL17MwoULad68eYYcs2jRonTt2pVffvmF2rVr07ZtW06fPs2ff/5J27ZtmTJlSpLtvby8+OOPP2jXrh3NmjWjZcuWVK1aFZvNxuHDh1m6dCn+/v6OSaxS4vHHH+eNN97g448/JleuXHTq1OmmbR544AHy5MlDgwYNKFWqFDExMcydO5cdO3bQuXNnSpUqlebP4m78+uuvtGjRgi5dujBy5Ehq1apFzpw5OXLkCCtXruTMmTOOIribmxvffPMN7du3Jzg4mEcffZSiRYuyYMECTpw4QbVq1diyZcsdj+nl5cXvv/9O27ZtadeuHW3btqV69epERESwadMmLl++7BgdXbFiRYoWLcqkSZPw8vKiePHi2Gw2nnvuOfz8/BgyZAgbNmzgf//7HzNmzKBp06YEBARw7Ngxtm7dyubNm1m5cqWjj+2HH37I/Pnzefvtt1m2bBk1a9Zk586dhIWF0aZNmxSN/hURERFxJo20FREREXGRgwcP0q9fP4oUKXJTK4SmTZvyxhtvsH79et58800XRZg1fPfddwwYMIBz584xevRotmzZwjfffEP//v2T3b5u3bps3ryZ559/nqNHjzJ27Fh++OEHdu3axQMPPMBXX311V8fv1q0bbm5uxMTEcP/995M7d+6bthk+fDg1a9ZkzZo1fPnll0yYMIHcuXMzZswYfvnll1S977QIDAxk48aNvP322/z333+MGzeOr7/+mk2bNtG0aVN+/fXXJNsHBwczf/586tevz+TJk/nmm28oVaoUy5Ytc7SoSImgoCA2bNjA//3f/7F161Y+/fRT/vjjD3LkyMFLL73k2M7d3Z2pU6fSoEEDfv31VwYNGsQ777zDhQsXAFMAnjlzJl9//TWFCxdmypQpjBw5kiVLllCkSBHGjBlD1apVHfsrUqQIK1as4NFHH2XVqlWMGjWKc+fOMXfuXIKCgtL4aYqIiIjcPZv9xvuwRERERERERERERMRlNNJWRERERERERERExEJUtBURERERERERERGxEE1EJiIiIpIJ/PXXX2zatOmO2zVv3jzDJvkSEREREZH0oaKtiIiISCbw119/8eOPP6ZoWxVtRUREREQyN01EJiIiIiIiIiIiImIhGmmbSvHx8Rw/fhxfX19sNpurwxERERERERERERGLs9vtXLp0iaJFi+LmduvpxlS0TaXjx49TokQJV4chIiIiIiIiIiIimczRo0cpXrz4LderaJtKvr6+gPmA8+TJ4+Jo0t/MmTNp166dq8MQuSXlqFidclSsTjkqVqccFatTjorVKUfF6rJLjkZERFCiRAlHbfFW1NM2lSIiIvDz8yM8PDxbFG3PnTuHv7+/q8MQuSXlqFidclSsTjkqVqccFatTjorVKUfF6rJLjqa0pnjrxgkiidyux4aIFShHxeqUo2J1ylGxOuWoWJ1yVKxOOSpWpxxNSp+GpMiyZctcHYLIbSlHxeqUo2J1ylGxOuWoWJ1yVKxOOSpWpxxNSkVbEREREREREREREQtR0VZERERERETkbg0eDMOGJb9u2DCzXkREJJVUtJUUqVatmqtDELkt5ahYnXJUrE45KlanHBXLcXeHQYMchVtHjg4bZpa7u7swOBFuurCQ5DyqCwtiQfpdn5SHqwOQzKFo0aKuDkHktpSjYnXKUbE65ahYnXJULOedd8yfgwYBUPT112HoUHj3XRgy5Pp6EVdJuLAA8M4718+jCRcWhg51XWxZQFxcHDExMa4OI0vJnz8/UVFRrg4j1Tw8PHB3d8dmszllfza73W53yp6ymYiICPz8/AgPDydPnjyuDifdTZs2jY4dO7o6DJFbUo6K1SlHxeqUo2J1ylGxrGsFsDgPD9xjY68vt9nAzS3p4/HH4euvzfrISChd+uZt3N3Nn6Gh8MUXZlu7HapVu/W2jRrBJ59cP3aHDhATk/z2VaokLdY9+6yJJbltAwNh4MDr277/PoSHXz9u4kehQvDMM9e3HTcOLlxIfls/P+jS5fq2M2eabRO/p4SHtzeEhFzfdv16E0Ny23p4QO3a17c9fDjpe7tx+xIlrm8bEQGxsbfe1sPD/J1mNokKtNNq1KDjpk3XC7a6sJAqdrudkydPcvHiRVeHkuVcvnyZXLlyuTqMNHF3dycgIAA/P79bFm9TWlPUSFsRERERERGR1DhwwBTzcuTAPToacuSA6Gizzm6HuDjzSJC4qBsfD2fP3nrfZ84k3Xbbtltv6++f9Pm8eXD1avLb3lho+u03OH8++W3r109atP36azh6NPltq1RJWrT9+GPYtSv5bQMDkxZt334bNmxIftuAADh16vrzF1+EpUuT39bHB/777/rzZ56BWbOS39ZmM59rgt69YerU5LcFuHwZcua8vu3EickX0N3cYM+e638nb74JEybcetu5cyFhBOzIkfDLL7fe9ocfoFQps+3Eiebv7laF/GHD4J57TGF2zx4YNIhQd3eTjyrYpklCwTYgIIBcuXI5bVSlmGJmZh0YabfbiY2NJSIighMnTnDlyhWKFCmSpn2qaCsiIiIiIiJyt86cMSNA9+0DMCNto6Ph9dfhpZdMQTAuzvyZ8PDxuf76XLlMITbx+sTb589/fVubzRRiE2+b+BEQkDS2ceNMgTi5bW8sIgwdagqSyW17Y1uSp582Rd8b31dy++3Y0Yx6Te693RhvvXqQL1/yn0XizwFMwff8+ZuPHxdnPtPEfH1N8TS593aj5JYl5pZoSqCYGPO4lcRFvHPnbl3ohqRF/SNHYO3aW2+b+LbxnTth2rRbb/vyy9d/rlQJALe4OFPUffvtW79ObisuLs5RsPW/8WKJpFlUVBTe3t6uDiNNfH198fLy4uzZswQEBOCehv7mao+QStmtPcKOHTuodO1EL2JFylGxOuWoWJ1yVKxOOSqWEhkJLVvCmjXm+cCB7OjVi0pTpujW88wqPt6Mjk6u2B4fb1o6JBRjL1y4XuhObtty5a5PRHfkiCnwJ1e8jo+HoCDw8jLb7tgBBw/eetv27SGh/rB+PWzadOui/2OPXS+OP/UUfPfd9fdaowasXm1GhstdiYqK4uDBg5QuXZqcCSOvxWmuXLmSJT7XK1eucOjQIQIDA5MtQqe0pqiibSplt6KtiIiIiIiIYEawPvAAzJgBwL72A+j07yj27IHy5eHXSsOoNEmFW7GIxJOOFSxoehjb7aaf8oYNZoSzpFhC0fZWxTgRuHOepLSm6HbLNSKJzJkzx9UhiNyWclSsTjkqVqccFatTjool2O2mT+qMGeDuzsHgpygXNoqtW82d61u3QuVJ77Cjy9Ckt72LuELigu077zDnnnsgLMyMsD10yIwI/vdfV0cp4hAeHu7qECxFPW0lRa7eqom9iEUoR8XqlKNidcpRsTrlqFjC4MHw/femv+nUqTzwzn3YbKaWC9f/rDb5HUqXhjz/mLvq8+Qxj7v52dPTVW9SsowbJh27evWq6TW8di00aWImVitQwMVBilynZgBJqWgrIiIiIiIikhJly4KHB3z5Jdx3H7sevl6oTSwuDvbvT9uhvL1TX/BN+NnX14Qr2dTgwckvr1bNTGTm6WkSTUQsSadvSZFChQq5OgSR21KOitUpR8XqlKNidcpRsYTHH4eGDaFMGfbsSb4Dgs1mett+/z1ERJhHeHjKf7582ewnKso8Tp1KW8i5cqW9+Js79/V5tSTzSnIeLVo06co33zR/4a+9dn3CNck2bCn8O1+4cCHNmzdPtzg8dYtBEpqILJU0EZmIiIiIiEg2sH49FCsGhQs7Fh0/bmq3hw+b5wktEhL+nDoVHnwwdYeLjb1eyL3bgm/in6OinPDeE8mdO+3FXx8f01lCLGblSpPQAE88AWPGqD/HLWTVicgmTJiQ5PlPP/3E3Llz+fnnn5Msb926tS6ipoCzJiLTSFtJkRUrVtAw4SQuYkHKUbE65ahYnXJUrE45Ki6xeze0aWOqjgsWQGAgFy5ASIgp2JYtawYojhoFO3fGc++9brz7buoLtmDaGeTPbx5pER19d8XfWy2LiTH7++8/8zh2LPUx2WymZUNai7+5cmkwaGrc8jwaFARffAHPP2+GiB8+DH/8YT5syRa6d++e5PmqVauYO3fuTctvdPnyZXLlyuW0OP777z9y587ttP1ldiraSoqcO3fO1SGI3JZyVKxOOSpWpxwVq1OOSoY7ccJUZ8+fN9XZgAAuXzbzOG3bBkWKwJw5EBgIvXvDtGkz6Nixo6ujdsiRw8wxldZ5pqKi0j7qNzzctJKw26+vSws3t9QXfBP/7O2dvYq/tz2P9u8PpUtDly4wb54ZeRsWBqVKZVh8Ym3Nmzfn7Nmz/Pjjj7z44ousW7eOp59+mpEjR2Kz2Xj33XcZfEMf5dKlS9O8eXPGjx/vWHbx4kUGDx7MlClTOH36NCVKlOCpp55i4MCBxMbGZuybsjgVbUVEREREREQSi4iAdu3MiMNy5WD6dGJy+PDIg7B8OeTNC7Nnm4JtVuftbR4BAanfh90OV67cucibkgJwfLx5XLxoHmnh4XH3Bd/klnl5pS0Oy+jQAZYuNX/u2AH168O0aVC3rqsjy/KmToUhQ2DPHtMT+9134aGHXB3Vzc6dO0e7du3o0qUL3bt3v+tWCZcvX6ZZs2YcO3aMPn36ULJkSVasWMEbb7zBiRMnbir6Zncq2kqK+Pj4uDoEkdtSjorVKUfF6pSjYnXKUckw0dGmWrJ5s6lUzppFvH9BnugFM2aYAua0aVC1atKXKUdvzWYzLQ1y5UrSGviu2e1morbUjvhN+PnSJbOv2FgzkPr8+bS9vxw50j7qN0+e9Gsjm1AQ3LmzPffee4eCYM2asHq1Kdxu3gz796toewcJeZlaf/8N3bpd74m9dSt06gQTJ8L996dun+nVQuTkyZOMHTuWPn36pOr1n332Gfv372fjxo2UK1cOgD59+lC0aFE++eQTnn76afLmzevEiDM3FW0lRVq2bOnqEERuSzkqVqccFatTjorVKUclQ8THm14H8+ebmbfCwrAH3sPAV+Dnn8HdHSZPhsaNb36pcjT92WxmMjMfHyhaNPX7iY+HyMjb9/NNyc///Wf2Fx0NZ86YR1p4e6e9+Ovra0YQJ5g61RQATUHQ3VEQnDLlNoXb4sXNiNuZM+GRR9L2prKBy5fN6SKt7Pakf3brlvp9/fef+XfibF5eXvTu3TvVr588eTJNmjQhX758nD171rE8ODiYDz/8kI0bN1KpUiVnhJolZLqi7eDBgxkyZEiSZRUqVGDXrl2AmaHt5ZdfZtKkSVy9epWQkBC++uqrJEO2jxw5Qt++fVm4cCG5c+emZ8+eDB8+HA+PTPdxZJjNmzdTvXp1V4chckvKUbE65ahYnXJUrE45Khni/HnYsMFUvaZMgdq1+eRj+Owzs/qHH8wAxOQoRzMPNzdT3PT1Tdt+4uLMqN3UtnpI+DlhlGZUlHmcOpW2uHLlul7MPXLELEtcELTZYOjQO9x+7+ubtGB7/DiMHm2G7Kp2km0VK1aMHDlypPr1e/fuZcuWLRQsWDDZ9f/++2+q950VZcp/aZUrV2bevHmO54mLrS+++CIzZsxg8uTJ+Pn50b9/fx566CGWL18OQFxcHKGhoRQuXJgVK1Zw4sQJevTogaenJx988EGGv5fM4siRI/oCIpamHBWrU46K1SlHxeqUo5IhChQwTWtXrYI2bfjhB3jtNbNqxAjo0ePWL1WOZj/u7qa/cVrv5o6NNcXftLZ9iIoy+7t82TxOnEj+eHY77N59FwHGxZn79NetMxc1fvvNVIQFMEXyhFHXqdGgAWzffr2wDqawXqUKrFyZ+pjSQ86cOe9q+7i4uCTP4+Pjad26Na+++mqy299tj9ysLlMWbT08PCicTCOc8PBwvv/+e3755RfHrSnjxo3j3nvvZdWqVTRo0IA5c+awY8cO5s2bR6FChahRowbDhg3jtddeY/Dgwbe8YnD16lWuXr3qeB6R1ukuRURERERExBpOnrzebDV/fmjfnr/+gqeeMotefRVeftll0UkW5+EB+fKZR1pER99c/O3Z08ynd2NBsEKFu9ixuzu89RY89hjMmgVNmsD06VCiRNoCziIS2nak1pAhiVtYXP9zyJD0aXGQHvLly8fFG2YGjI6O5sQNVw7KlCnDf//9R3BwcLL7uXEf2V2mLNru3buXokWL4u3tTVBQEMOHD6dkyZKsX7+emJiYJH/5FStWpGTJkqxcuZIGDRqwcuVKqlatmqR6HxISQt++fdm+fTs1a9ZM9pjDhw+/qS0DwMyZM8l17RJG69atOXfuHBs2bHCsDwoKwsPDg6VLlzqWVatWjWLFijFz5kzHsnvuuYfKlSszd+5coq5dHgsICKB+/fqsXLnS0esjV65ctGrViq1bt3Lo0CHH60NDQzl06BDbt293LGvWrBlRUVGsXr3asaxOnTr4+fkxf/78JJ9RuXLlmDFjBvHx8QCUKFGCGjVqsGjRIi5dukR8fDzLli2jcePGrFu3zvEPz9PTk7Zt27Jr1y727t3r2GebNm04c+YMGzdudCxr2LAhbm5uLFu2LMlnUbRoUWbNmuVYVqZMGSpVqsScOXMchfJChQpRr149VqxYwblz5wDT6L9ly5Zs3ryZIwn3fAAdO3Zk//797Nixw7GsRYsWREZGsmbNGseyunXr4uvry4IFCxzL7r33XsqWLcv06dOxX/utVrJkSapXr+74LADy589Po0aNWLt2LSdPngQgR44chISEsHPnTvbt2+fYZ0hICKdOnWLTpk2OZY0aNQJwjAAHqFGjBoUKFWL27NmOZWXLluXee+9l9uzZREdHA1C4cGHq1q3L8uXLOX+tY76vry/NmzdP8lnYbDY6dOjAvn372Llzp2OfLVu25NKlS6xdu9axrF69evj4+LBw4ULHskqVKlGmTBmmTZvmWJbwWSxYsIDIyEgA/P39adiwIWvWrOHUtft4vLy8aNOmDTt27GD//v2O17dt25bjx4+zZcsWx7LGjRsTHx/PihUrHMtq1qxJwYIFmTNnjmNZuXLlqFixIrNmzSImJgaAIkWKUKdOHZYtW0Z8fDzTpk1zfBabNm3i6NGjALi5uREaGsrevXsdrVQAWrVqRXh4OOvWrXMsq1+/Pt7e3ixevNixrHLlypQuXZoZM2Y4lpUuXZqqVasyf/58Ll+7n6lAgQIEBQWxevVqTp8+DYC3tzetW7dm+/btHDhwwPH6du3acezYsSSfRZMmTYiNjWVlosuptWrVwt/fn7lz5zqWlS9fngoVKjBz5kxiY2MBKFq0KLVr12bp0qWOX3R+fn40bdqUDRs2cOzYMQDc3d1p3749e/bsYXeiy+vBwcFcuHCB9evXO5Y1aNAALy+vJJ9FlSpVKFmyJGFhYY5lgYGBVKlShXnz5nHlyhUAChYsSIMGDVi1ahVnrjX3ypkzJ8HBwWzbto2DBw86Xt++fXuOHDnCtm3bHMuaNWvG1atXWbVqlWNZ7dq1yZcvX5I7LSpUqED58uUJCwtzXMUtVqwYtWrVYsmSJYSHhwOQN29emjRpwvr16zl+/DhgLgC2a9eO3bt3s2fPHsc+0+tcnpCj4LpzOZgvVDqX61ye3LkccPm5/MKFC0k+C53LdS5PfC5POLe58lxuhe/loHO5s8/lHsuW4fPww2z/v//jcPv21KhRgz17CvPII27Ex7vTqtURevaMBG5/Lo+Pj2fRokXZ/nu5zuWuP5dv3Hj9XN6nT3neeKMCNpsdu93MTGW3Q7lysHXrNg4dSuG53N0dv/feo9577+G9ZQv2+vVZ+uqrhJcpA2Su7+VpOZdfunSJy5cvExERQVRUFLly5cLd3d1xTgKTa97e3kkKkDly5CBXrlxcunTJ8fm4u7vj6+tLSEgkP/0EH3/sxd697lSsaOP116/SosUVEnaRJ08eYmNjHTkOkPtaI93/Eg3zzZkzJ56enkkGGnp5eZEzZ07Cw8Md51NPT098fHz477//HLnr5uZGnjx5uHz5suOcf/HiRfLmzUtUVBSxsbHExcVx8eJFfH19iY+Pd5x/SpcuzeLFi4mLi3N8Ft98843jvSZ8Fvfddx8ffvghs2fPpmHDho71Hh4exMbGEhsb69jWZrPh5+fHlStXkgyiTOlnkStXLjw8PFL1WST83Vy+fNlxzgccn0VCTgE3fRYJr4+Pj2fhwoWOfSY+l19O4cx1Nrs98fUW65s5cyb//fcfFSpU4MSJEwwZMoRjx46xbds2pk2bRu/evZP8ZYL5xdeiRQs++ugjnn76aQ4fPpzkP1OXL1/Gx8eHsLAw2rVrl+xxkxtpW6JECcLDw8mj2wJEREREREQyn61bzajB8HDT4POPP9i8xUbTpmaU4n33mda2auEpmdnUqaaH7e7dZjRvwuDHl1+GTz4xIztT7PBh09h52zYzDPTXX6Fjx3SJ24qioqI4ePAggYGBeHt7uzqcdNO/f39Gjx5N4pJh8+bNOXv2bJKifoKvv/6aZ555hoceeojWrVuzefNmZs+ezaVLlwgNDWX8+PGAqb81adKELVu20KtXL2rXrk1kZCRbt27ljz/+4NChQxQoUCCj3ma6uVOeRERE4Ofnd8eaolt6Bpke2rVrx8MPP0y1atUICQkhLCyMixcv8vvvv6frcb28vMiTJ0+SR3aS+KqsiBUpR8XqlKNidcpRsTrlqDjdkSPQtq0p2DZuDBMmcOCgjZAQU7Bt0gQmTUp5wVY5Klb10EOwaRNs27af48fhf/8zyz/9FJ57Dq4N7E+ZUqVg2TJo3RoiI+Htt01TXsnWnnrqKV577TWWLFnCyy+/zMGDB5k7dy4+N/R3yJUrF4sXL2bgwIEsWrSI559/ng8//JC9e/cyZMgQvLy8XPQOrCnTFW1vlDdvXsqXL8++ffsoXLgw0dHRN/XAOHXqlKMHbuHChR23iiRen7BOkpf4liYRK1KOitUpR8XqlKNidcpRcarz56FdOzh+HCpVgn/+4WR4Tlq3hlOnoFo1+OcfuJs5d5SjYnUJOfrcc/DNN2aE7ejR8PTTZq6xFPPzgxkzYOBA8w9FQ9GznC+//JIbb8xftGhRsqNswbRW+PDDDzlz5gyRkZHMmjWLMmXKcOjQIcco2wS5c+fmgw8+YO/evVy9epUzZ86wfPlyXn755ZsmLsvuMn3R9r///mP//v0UKVKE2rVr4+npmaQv1O7duzly5AhBQUGA6X+ydetWR18bgLlz55InTx4qVaqU4fGLiIiIiIhIBrpyBe6/H3bsgGLFYOZMwt3y0bYtHDgAgYFmrqW8eV0dqEj6eeop+PFHcHOD7783E5bd1YBZT0/4+GMz8jbB339Dop6iIpI2ma5o+8orr7B48WIOHTrEihUrePDBB3F3d6dr1674+fnxxBNP8NJLL7Fw4ULWr19P7969CQoKokGDBoBpxF+pUiUef/xxR4+Nt99+m379+mkYtoiIiIiISFb322/m9u48eWDmTKICSnLffbB5MxQqBHPmQJEirg5SJP09/rhpSevhARMnQpcukGjOpbvz11/w4IPQtKkZwS4iaZbpxrD/+++/dO3alXPnzlGwYEEaN27MqlWrKFiwIACff/45bm5udOrUiatXrxISEsJXX33leL27uzvTp0+nb9++BAUF4ePjQ8+ePRk6dKir3lKm0KJFC1eHIHJbylGxOuWoWJ1yVKxOOSpO07MnnD0LdeoQe29Vuj4MS5Y4ariULZu63SpHxeqSy9FHHgEvL/PnlCnQqRNMngx3PcdWkSJQsCBs3Aj168P06VC9unMCl2zD19fX1SFYis1+Y5MKSZGUzvSWVZw6dYpChQq5OgyRW1KOitUpR8XqlKNidcpRSbP4eHMv+DV2u7lF/PvvTdFq1ixo3jz1u1eOitXdLkdnz4YHHoCoKDPH2F9/Qa5cd3mAgwchNBR27oTcueH3303v6CwkKiqKgwcPEhgYiPddV7blTmJiYvD09HR1GGl2pzxJaU0x07VHENdYs2aNq0MQuS3lqFidclSsTjkqVqcclTT58Udo2xYiIhyL3nzTFGzd3Mwt4mkp2IJyVKzvdjkaEgJhYeDjA3PnQvv2cOnSXR4gMBCWL4eWLU1v244dYcyYtAUt2UpkZKSrQ7AUFW1FREREREQk65o1C5580lSifvgBgM8+gw8/NKu//tq04hTJ7lq0MCNufX1h8WJo0wYuXrzLneTLZ/qM9OoFcXHw7LOwdGk6RCuS9WW6nrYiIiIiIiIiKbJ+PXTuDLGx0K0bDBjAzz/Dyy+b1R98YOq5ImI0agTz55uRt6tWQatWZnI+f/+72EmOHOYCSblycPo0NGmSbvGKZGUaaSspUrduXVeHIHJbylGxOuWoWJ1yVKxOOSp3bf9+c493ZCQEB8MPPzBjphu9e5vVL74Ir7/uvMMpR8XqUpqjdevCwoVmXrENG8wI3FOn7vJgNpvpQfL559eXXbwIJ0/e5Y4kO/Hx8XF1CJaioq2kiGbwE6tTjorVKUfF6pSjYnXKUbkrZ86YHranT0ONGjBlCivW5eDhh80d2927w4gRpq7kLMpRsbq7ydHq1WHRIihSBLZuNT2fjx1LxUET/pFFR0OnTlC/PmzbloodSXbg5qYyZWL6NCRFFixY4OoQRG5LOSpWpxwVq1OOitUpR+WudOsG+/ZB6dIQFsa2I3kIDYUrV8xk9j/8YCYgcyblqFjd3eZopUqmt22JErBrFzRtCocPp/LgZ87Av//CkSOmB8OcOanckWRll+569rusTUVbERERERERyVo++QSqVoVZszh0tQghIebO7KAgmDwZPD1dHaBI5lCuHCxZAoGBcOCAKdzu25eKHRUrBitWmB1ERJjWJd9+6/R4RbISFW1FREREREQka6leHTZt4nS+CrRpA8ePQ+XKMH06qGWiyN0pXRqWLoXy5c1A2aZNzcjbu+bvb0bYdu9u+pQ8/bRpLB0f7+yQRbIEFW0lRe69915XhyByW8pRsTrlqFidclSsTjkqd/TRR7BsmePppUg32reHvXuhZEmYPRvy50+/wytHxerSkqPFiplWCZUrw4kTpnC7ZUsqduTlBT/9BO++a55/9JGZFVAEqF69Or169XI8X7RoETabjUWLFrksphuVLl06SYzpSUVbSZGyZcu6OgSR21KOitUpR8XqlKNidcpRua2vvzYj9lq3hsOHuXoVHnwQ1q+HAgXM4L5ixdI3BOWoWF1ac7RwYTM5Wc2apkVtixbm39hds9lg8GBTvC1YEJ56Kk1xifOMHz8em83meHh7e1O+fHn69+/PqVOn0v34NifNDhkWFsbgwYOdsi9XUtFWUmT69OmuDkHktpSjYnXKUbE65ahYnXJUbunvv+HZZ83Pr75KXPFSdO8O8+dD7twwcyZUqJD+YShHxeqckaMFCph/W/Xrw/nz0LIlrFyZyp09/rhplFulyvVlly+nOUZJu6FDh/Lzzz/z5Zdf0rBhQ8aMGUNQUBCX0/nvJ/6GVhlNmzblypUrNG3a9K72ExYWxpAhQ5wZmkuoaCspYrfbXR2CyG0pR8XqlKNidcpRsTrlqCRrxQro0sX0xHziCezvDqZfP/jjDzPZ2J9/Qp06GROKclSszlk5mi8fzJ0LTZqYOcVatzatE1Ild+7rPy9ZAvfcAwsXOiXOTGHwYBg2LPl1w4aZ9S7Qrl07unfvzpNPPsn48eN54YUXOHjwIH///Xey20dGRqZLHG5ubnh7e+Pmlj3Ll9nzXYuIiIiIiEjmtmsXdOwIUVEQGgpjxzJ4iI2vvzZ3X0+YAMHBrg5SJGvy9TWj2IODITIS2rUzbUjSZMQIOHUK2rSB8eOdEab1ubvDoEE3F26HDTPL3d1dE9cNWrZsCcDBgwfp1asXuXPnZv/+/bRv3x5fX1+6desGmJGyI0eOpHLlynh7e1OoUCH69OnDhQsXkuzPbrfz3nvvUbx4cXLlykWLFi3Yvn37Tce9VU/b1atX0759e/Lly4ePjw/VqlVj1KhRAPTq1YvRo0cDJGn1kMDZMaYnjww9mmRaJUuWdHUIIrelHBWrU46K1SlHxeqUo5LEyZPQtq25P7tePfjtN74c68HQoWb16NHwyCMZG5JyVKzO2Tnq4wPTpkGnThAWZq6h/PGH+TNVfv8devWC336D3r1h/34YOtRchckMbjfa1N0dvL1v3vallyA62hRoo6NNb+6PPjJF26FD4Z13br9fNzfImfP688uXIVeutL2PZOzfvx8Af39/AGJjYwkJCaFx48aMGDGCXNeO2adPH8aPH0/v3r0ZMGAABw8e5Msvv2Tjxo0sX74cT09PAAYNGsR7771H+/btad++PRs2bKBNmzZER0ffMZa5c+fSoUMHihQpwvPPP0/hwoXZuXMn06dP5/nnn6dPnz4cP36cuXPn8vPPP9/0+oyI0Wnskirh4eF2wB4eHu7qUERERERERLKXK1fs9s6d7fZy5ez206ftv/5qt9tsdjvY7UOGuDo4kezl6lW7/aGHzL8/Dw+7ffLkNOwsLs5uf+stszOw27t2Nf/eLeLKlSv2HTt22K8kF1NCzMk92rdPum2uXLfffujQ69sWKHDr7erUSbrfUqXS9P7GjRtnB+zz5s2znzlzxn706FH7pEmT7P7+/vacOXPa//33X3vPnj3tgP31119P8tqlS5faAfvEiROTLJ81a1aS5adPn7bnyJHDHhoaao+Pj3ds9+abb9oBe8+ePR3LFi5caAfsCxcutNvtdntsbKw9MDDQXqpUKfuFCxeSHCfxvvr162dPruSZHjEm57Z5Yk95TVHtESRFbhyKLmI1ylGxOuWoWJ1yVKxOOSpJeHvDpEmwdClzNhakRw9TwejXzwxMcwXlqFhdeuVojhxmcGzXrhAbC48+ChMnpnJnbm7w3nvwww/g4QG//mp6MFy65NSYLc1mc92J7Jrg4GAKFixIiRIl6NKlC7lz5+bPP/+kWLFijm369u2b5DWTJ0/Gz8+P1q1bc/bsWcejdu3a5M6dm4XXehXPmzeP6OhonnvuuSRtC1544YU7xrVx40YOHjzICy+8QN68eZOss6VgRHZGxOhMao8gKXIpO50gJVNSjorVKUfF6pSjYnXKUSE+3lSGHn3UFHbc3Vl9qBAPPQQxMWbx//7nujuplaNidemZox4e8PPP5nrKuHHw+OOm3fQTT6Ryh717Q8mSpvdCyZJJJyyzqv/+u/W6G3vTnj6d9PmHH5pidY4cpk3CsGHXC7eHDt16vzdO0LVjR4rDvZ3Ro0dTvnx5PDw8KFSoEBUqVEgyGZiHhwfFixdP8pq9e/cSHh5OQEBAsvs8fe09Hz58GIBy5colWV+wYMGbCrE3SmjTUKVKlbt6P86MMV++fKk6dmqoaCsiIiIiIiLW99prZqKiOXNg3Dh27jTzj0VGmtnrf/rp5vqFiGQcd3f47jtTuB0zBp580hRu+/VL5Q5btYK1a6FEiczR19bHJ3XbDhtmCrYJPWwTJiED8/xu9uukfrb16tWjTp06t1zv5eWVpIgLZoKvgIAAJt5imHXBggWdEltaZIYYE1PRVlIkf/78rg5B5LaUo2J1ylGxOuWoWJ1yNJsbOdIUbAFatuToUQgJgXPnoG5dmDrVDFBzJeWoWF1G5Kibm5kI0NsbPv8c+veHK1fglVdSucPEIx3j46FHD2jXDrp1c0q8LpdQoE0o2ML1PxMXbjOBMmXKMG/ePBo1akTOxJOj3aBUqVKAGfV6zz33OJafOXOGixcv3vEYANu2bSM4OPiW292qVYIzYrxw4cJtY3QmXYeUFGnUqJGrQxC5LeWoWJ1yVKxOOSpWpxzNxn7/3cywDvDhh5xr/zghIXD0KFSoYGatt8Kd08pRsbqMylGbDT79FN56yzwfONAMJE2zX34xzXK7dzdFTrvdCTt1sbi4pAXbBO+8Y5bHxbkmrlR45JFHiIuLY9iwYTeti42NdRRkg4OD8fT05IsvvsCe6O9w5MiRdzxGrVq1CAwMZOTIkTcVeBPvy+fa6OQbt8mIGJ1JI20lRdauXUvdunVdHYbILSlHxeqUo2J1ylGxOuVoNrVokWmOabdD//5E9nuV0GDYuROKFTOdEgoUcHWQhnJUrC4jc9RmM4Vab29Tf3znHTPi9r330tDp4LHHYOtW+PhjePdd2LcPvv0WvLycGnuGGjz41usyyQjbBM2aNaNPnz4MHz6cTZs20aZNGzw9Pdm7dy+TJ09m1KhRdO7cmYIFC/LKK68wfPhwOnToQPv27dm4cSMzZ87E39//tsdwc3NjzJgxdOzYkRo1atC7d2+KFCnCrl272L59O7Nnzwagdu3aAAwYMICQkBDc3d3p0qWLU2IskIG/dFS0lRQ5efKkq0MQuS3lqFidclSsTjkqVqcczYa2boUHHjCT8nTuTPTHI+n0oI3VqyFfPlOwLVnS1UFepxwVq3NFjr79NuTMadojfPABXL4Mn32WysKtmxt89BGUKQPPPmtmPjtyxPRHUXsSSxg7diy1a9fm66+/5s0338TDw4PSpUvTvXv3JCO933vvPby9vRk7diwLFy6kfv36zJkzh3bt2t3xGCEhISxcuJAhQ4bw6aefEh8fT5kyZXjqqacc2zz00EM899xzTJo0iQkTJmC32+nSpYtTYgwNDXXiJ3Z7Nrs9K4wnz3gRERH4+fkRHh5Onjx5XB1Oups2bRodO3Z0dRgit6QcFatTjorVKUfF6pSj2dCff0KXLlC/PvGz5tD9SW9+/dXMszNvHgQFuTrApJSjYnWuzNHRo01/W4BnnjHP0zRx4Jw50LkzXLoE5cubPinX+p2mp6ioKA4ePEhgYCDe3t7pfrzs5uLFi+TNm9fVYaTZnfIkpTVF9bSVFMnh6q7+InegHBWrU46K1SlHxeqUo9nQgw/C/PnY//qbF143BVsPD5gyxXoFW1COivW5Mkf79YPvvzcjbMeOhSeeSGO71jZtYPlyKFECDh8GjXTPEm41gVh2pZG2qZTdRtqKiIiIiIikuytX4MIFKFrUsej9980t1mDmIHrsMRfFJiJpNnEi9OxpCrZdusBPP4GnZxp2eOIEbNoEKbit3hk00lZSQiNtJUPt3LnT1SGI3JZyVKxOOSpWpxwVq1OOZgNxcdCtGzRoANu3A/DNN9cLtqNGWbtgqxwVq7NCjnbrBr/9ZkbNT5oEjz4KV6+mYYdFiiQt2G7ZYiYq0/jETOnKlSuuDsFSVLSVFNm3b5+rQxC5LeWoWJ1yVKxOOSpWpxzN4ux2GDDA9LE9dQrOnmXKFOjb16x+6y2z2sqUo2J1VsnRTp3MP/UcOcyfDz0EUVFO2HFEBISGwmuvwZNPQkyME3YqGelqmir4WY+KtiIiIiIiIuJaH34IX31lGl5OmMCCuGY89hjEx8NTT8GwYa4OUEScqUMHmD4dcuY0c4h16ACRkWncaZ488PrrZoazH34wI3AvXnRGuCIuoaKtiIiIiIiIuM6PP8Kbb5qfR45k/T0Pc//9EB1tRuCNGWNquSKStbRuDTNnQu7cMH++qbFGRKRxp/36wbRp13fasCEcPOiUeBPT9FByO87KD01ElkrZbSKy6OhozYYqlqYcFatTjorVKUfF6pSjWdSsWWaIXVwcvPoqe5/8iEaN4MwZaNHCjMDLLHP9KEfF6qyaoytXQtu2pmBbr545LeTLl8adbtpkzi3HjkFAAPzzD9Svn+ZY4+Li2LNnDwEBAfj7+6d5f5JUfHw8bm6Zf3zp2bNnOXv2LOXKlcPd3f2m9SmtKXqkZ5CSdZw6dYoSJUq4OgyRW1KOitUpR8XqlKNidcrRLMhuh6FDHROQHX9uOG2amIJtzZrw11+Zp2ALylGxPqvmaFAQLFgAbdrAmjXQsiXMnQsFCqRhpzVqwKpV0LGjKeAOH25OKmnk7u5O3rx5OX36NAC5cuXCplsBnMaqFxZSwm63ExsbS0REBBEREeTNmzfZgu3dUNFWUmTTpk2WPLmLJFCOitUpR8XqlKNidcrRLMhmM0NpP/qICy8MISTYjUOHoGxZc8t0ZruhUTkqVmflHK1dGxYtguBgU2Nt3hzmzYPChdOw0+LFYckSePttc4HISQpfCyqhcCvOc/nyZXLlyuXqMNLE3d2dIkWK4Ofnl+Z9qWgrIiIiIiIiGSc2Fjyu/Vc0b14uvzOcjm1g2zZToJkzBwoVcm2IIpLxqlaFxYuhVSvYvh2aNTNtaYsXT8NOfX1h1Kjrz+12+O036Nz5+nnoLtlsNooUKUJAQAAxMTFpCE5utHDhQlq0aOHqMFLNw8MDd3d3p42+VtFWREREREREMkZkpBlK16ULPP88MTHwyCOwfDn4+cHs2RAY6OogRcRVKlY0g2NbtoQ9e6BpU9M6oXRpJx3g88/h5Zdh/Hj4/fc0Del3d3dP8+3vklRsbCzemakvTjrL1N19P/zwQ2w2Gy+88IJjWVRUFP369cPf35/cuXPTqVMnTp06leR1R44cITQ0lFy5chEQEMDAgQOJjY3N4Ogzl0aNGrk6BJHbUo6K1SlHxeqUo2J1ytEsIKFCu2oVDBtG/KkzPPkkzJhhetdOnw7Vqrk6yNRTjorVZZYcLVPGFG7LlIGDB6FJE9i714k7z5XLXCFq3BiOHHHSjsUZMkuOZpRMW7Rdu3YtX3/9NdVu+K3+4osvMm3aNCZPnszixYs5fvw4Dz30kGN9XFwcoaGhREdHs2LFCn788UfGjx/PoEGDMvotiIiIiIiIZA92OzzzjOlhmzMnTJ/OayMK8tNP4O5uBrw1buzqIEXEKkqVMoXbihXh33/NiNsdO5yw4/vvNzsuXBi2boX69WH9eifsWMT5MmXR9r///qNbt258++235MuXz7E8PDyc77//ns8++4yWLVtSu3Ztxo0bx4oVK1i1ahUAc+bMYceOHUyYMIEaNWrQrl07hg0bxujRo4mOjr7lMa9eveqYAS7hkZ0sX77c1SGI3JZyVKxOOSpWpxwVq1OOZnLvvgs//ABubvDbb3y8pAEjRphV339vJnjP7JSjYnWZLUeLFjU9bqtWhZMnTY/bTZucsOPatWH1aqhSxey4aVP4+28n7FjSKrPlaHrLlD1t+/XrR2hoKMHBwbz33nuO5evXrycmJobg4GDHsooVK1KyZElWrlxJgwYNWLlyJVWrVqVQos72ISEh9O3bl+3bt1OzZs1kjzl8+HCGDBly0/KZM2c6ZrZr3bo1586dY8OGDY71QUFBeHh4sHTpUseyatWqUaxYMWbOnOlYds8991C5cmXmzp1LVFQUAAEBAdSvX5+VK1dy9uxZAHLlykWrVq3YunUrhw4dcrw+NDSUQ4cOsX37dseyZs2aERUVxerVqx3L6tSpg5+fH/Pnz0/yGZUrV44ZM2YQHx8PQIkSJahRowaLFi3i0qVLxMfHs2zZMho3bsy6des4ceIEAJ6enrRt25Zdu3axN9H9Cm3atOHMmTNs3LjRsaxhw4a4ubmxbNmyJJ9F0aJFmTVrlmNZmTJlqFSpEnPmzOHq1asAFCpUiHr16rFixQrOnTsHgI+PDy1btmTz5s0cSXRLQ8eOHdm/fz87El2Ga9GiBZGRkaxZs8axrG7duvj6+rJgwQLHsnvvvZeyZcsyffp07HY7ACVLlqR69eqOzwIgf/78NGrUiLVr13Ly5EkAcuTIQUhICDt37mTfvn2OfYaEhHDq1Ck2JfrtkjDkP/EJqUaNGhQqVIjZs2c7lpUtW5Z7772X2bNnOy4qFC5cmLp167J8+XLOnz8PgK+vL82bN0/yWdhsNjp06MC+ffvYuXOnY58tW7bk0qVLrF271rGsXr16+Pj4sHDhQseySpUqUaZMGaZNm+ZYlvBZLFiwgMjISAD8/f1p2LAha9ascbQi8fLyok2bNuzYsYP9+/c7Xt+2bVuOHz/Oli1bHMsaN25MfHw8K1ascCyrWbMmBQsWZM6cOY5l5cqVo2LFisyaNcvR7L1IkSLUqVOHZcuWER8fz7Rp0xyfxaZNmzh69CgAbm5uhIaGsnfvXnbt2uXYZ6tWrQgPD2fdunWOZfXr18fb25vFixc7llWuXJnSpUszY8YMx7LSpUtTtWpV5s+fz+XLlwEoUKAAQUFBrF692jGTqLe3N61bt2b79u0cOHDA8fp27dpx7NixJJ9FkyZNiI2NZeXKlY5ltWrVwt/fn7lz5zqWlS9fngoVKjBz5kxHa5eiRYtSu3Ztli5dysWLFwHw8/OjadOmbNiwgWPHjgGm71L79u3Zs2cPu3fvduwzODiYCxcusD7RVeYGDRrg5eWV5LOoUqUKJUuWJCwszLEsMDCQKlWqMG/ePK5cuQJAwYIFadCgAatWreLMmTMA5MyZk+DgYLZt28bBgwcdr2/fvj1Hjhxh27ZtjmXNmjXj6tWrjgtuALVr1yZfvnzMmzfPsaxChQqUL1+esLAw4uLiAChWrBi1atViyZIlhIeHA5A3b16aNGnC+vXrOX78OGCaxLdr147du3ezZ88exz7T61yekKPgunM5QL58+XQu17k82XM54PJz+YULF5J8FjqX61ye+FyecG5z5bncCt/LIfOdyyM/+4xqX30FQNTIkYzZ15TXXjPb9O69nZAQfyIjM/+5PD4+nkWLFmX77+U6l1v3XJ7wfTQzfS+PiTnHa69tZfDgBuzbl5fmzeOZOjWSyMhFju1Sey73ePtt6n3yCf7r12Pv3Jn5Y8dyJSAA0LncVd/LE/+fKSt/L084V92JzZ7wqWUSkyZN4v3332ft2rV4e3vTvHlzatSowciRI/nll1/o3bu3IwkT1KtXjxYtWvDRRx/x9NNPc/jw4SR/aZcvX8bHx4ewsDDatWuX7HGvXr2aZL8RERGUKFGC8PBw8qShcXVmMW3aNDpmhcvfkmUpR8XqlKNidcpRsTrlaCa1fbtpVBsfD+++yz+1BvPgg+bpwIHw8ceuDtB5lKNidZk5Ry9ehPbtYeVK8PWFmTPBKe1PY2Kgf38znLd/fyfsUNIiM+fo3YiIiMDPz++ONcVMNdL26NGjPP/888ydOzfDZ5Pz8vLCy8srQ49pJTVq1HB1CCK3pRwVq1OOitUpR8XqlKOZVOXKMGIE7NrFkhbv8mhbU7Dt3Rs++sjVwTmXclSsLjPnaN68Zu6wjh1Ny4SQEJg2DVq0SOOOPT1h7Fiw2a4vO3rUHNDXN407l7uVmXM0PWSqnrbr16/n9OnT1KpVCw8PDzw8PFi8eDH/+9//8PDwoFChQkRHRztuQUhw6tQpChcuDJhhzwm3iiRen7BOkpe4nYSIFSlHxeqUo2J1ylGxOuVoJvbii2zuO5b77rcRFQX33QfffJO0RpIVKEfF6jJ7jvr6mrkM27SByEgz8jZRF4DUS3wyunDBHKBJEzMDmmSozJ6jzpapirYJPaM2bdrkeNSpU4du3bo5fvb09EzSS2T37t0cOXKEoKAgwPSy2rp1q6OvDcDcuXPJkycPlSpVyvD3lFkkbichYkXKUbE65ahYnXJUrE45mokcPw6PP27uZwYOHIC27WyEh0PjxjBpEnhkqns+U0Y5KlaXFXI0Vy4zZ1jHjjguAjl1DrGjR+H8edi8GerXd9LMZ5JSWSFHnSlT/ar09fWlSpUqSZb5+Pjg7+/vWP7EE0/w0ksvkT9/fvLkycNzzz1HUFAQDRo0AEzz5kqVKvH444/z8ccfc/LkSd5++2369euXrdsfiIiIiIiIpFl4uBn+tnkzREZy8quptGljJmivWtXczpwzp6uDFJHMzNsb/vgDunUzf3buDBMnwiOPOGHn1arB6tUQGgo7dpgrTb/9Zp6LZLBMNdI2JT7//HM6dOhAp06daNq0KYULF2bq1KmO9e7u7kyfPh13d3eCgoLo3r07PXr0YOjQoS6MWkREREREJJO7ehUeesgUbAsVIuLdT2nXDvbvh8BA048yb15XBykiWUGOHPDrr9C9O8TGQteu8NNPTtp56dKwfDm0amX6MNx3H4we7aSdi6Rcphppm5xFixYlee7t7c3o0aMZfZt/UKVKlSIsLCydI8taypYt6+oQRG5LOSpWpxwVq1OOitUpRy0uYXaxBQsgd26u/hnGfc8HsmkTBATAnDlQpIirg0xfylGxuqyWox4eMH68GXn73XfQq5dpmfD0007Yed68MHMm9O0L338P/fub89xzzzlh53IrWS1H08pmt9vtrg4iM4qIiMDPz4/w8HDy5Mnj6nBERERERERc55VX4NNPwcODuGlhdP66NX/9ZSYOWrwYatZ0dYAiklXFx8OAAdcHw44aZZ47hd0OH30EX38NK1eCJrAXJ0hpTTHLtUeQ9KFm0GJ1ylGxOuWoWJ1yVKxOOWphX35pCraA/Ydx9PnDFGxz5IB//sk+BVvlqFhdVs1RNzf44gtz7Qjg+edNndUpbDZ4/XXYujVpwTYy0kkHkMSyao6mloq2kiLR0dGuDkHktpSjYnXKUbE65ahYnXLUwlq0gOLF4aOPeGtnd77/3hRRfv0Vmjd3dXAZRzkqVpeVc9Rmg48/hkGDzPPXX4chQ8xAWafInfv6zz/9BJUqmUKuOFVWztHUUNFWREREREREUq9yZdiyhc89BjJ8uFk0dqyZk0xEJKPYbKZQ+8EH5vngwfDGG04s3IKZ9WzECDhyBBo1MjMsiqQTFW0leYMHw7BhjqeFE98GMGyYWS9iIYXVW0gsTjkqVqccFatTjlrMli2QaFLoCTPy8dLLNsAUTJ56ykVxuZByVKwuu+ToG2/A55+bnz/6CF54wYmFWw8Pc+5r1gwuXYLQUPjmGyftXLJLjqaUJiJLpSw/EdmwYea+gqFD4Z137rxcRERERESyhyNHICgIzp6F6dMJi2nN/febAWgvvACffWZGvImIuNLYsdC3r/n56adhzBjTusUpoqPN1amffjLPBw6EDz904gEkK9NEZJI277xjCrODBsGwYSxfvlwFW7G05cuXuzoEkdtSjorVKUfF6pSjFnH+PLRtC8ePQ7lyrI6rQ+fOpmDbrZuZjyy7FmyVo2J12S1Hn3kGxo0zddRvvoFevcy5yily5IDx4019BOCTT+CRRyAuzkkHyJ6yW47eiYerAxALSyjMDhpEw3ffNfcTqGArFnX+/HlXhyByW8pRsTrlqFidctQCrlyB++6DnTuhWDF2j5xJ24fzceUKtGt3vTiSXSlHxeqyY4726gXe3tC9O/z8M0RFwcSJ4OnphJ3bbKY+cs898H//B/feC+7uTthx9pUdc/R20vVXalxcHJMmTaJPnz48+OCDbL02s154eDhTp07l1KlT6Xl4cYZ33gE3N2wJXTSKFXNyF28REREREbG8uDgzlHb5cvDz4/gPs2jZswQXL5pOCZMnO6kIIiLiZF26XD9HTZ4MDz8MV6868QDdusHGjddH3Yo4SboVbS9evEijRo147LHH+PXXX/nnn384c+YMALlz52bAgAGMGjUqvQ4vzjJsGMTHY0+4x+mJJ8zV9ZMnXRuXyA18fX1dHYLIbSlHxeqUo2J1ylEXstthwAD480/IkYOLP/5Ni+eqcPw4VKoE06eDj4+rg3Q95ahYXXbO0QcfhL/+Ai8v+PtveOABc/OA01SqdL03zJUrpo3M/PlOPED2kJ1zNDnpVrR9/fXX2b59O7Nnz+bAgQMknu/M3d2dzp07ExYWll6HF2dI1MPWFhMDrVub5dOnQ5Uq8Mcfro1PJJHmzZu7OgSR21KOitUpR8XqlKMuFBcH4eFgs3Hl2wm0fq8Ze/ZAyZIwezbkz+/qAK1BOSpWl91ztH17mDEDcuWCWbMgNBT++y8dDvTxx+bk2LYt/PBDOhwg68ruOXqjdCva/vXXXzz33HO0bt0aWzKd6MuXL8+hQ4fS6/CSVjdMOrZ52zaYMwf69TPrz50z9xR8/71r4xS5ZvPmza4OQeS2lKNidcpRsTrlqAt5eMBPPxE9bwkdf3qYdeugQAHz34PixV0dnHUoR8XqlKPQqpUp2Pr6wsKFEBJirkk51WuvQdeuZtazJ56AN9+E+HgnHyRrUo4mlW5F2/DwcAIDA2+5PiYmhlinTdsnThcXl2TSsSNHjpjlX34J774LTZpAuXJmdkQRC3DkqIhFKUfF6pSjYnXKURfYvt1RaIizu9FtTGPmzzetEMLCoEIFF8dnMcpRsTrlqNGkCcydC3nzwooVEBwMTp3/ytvbzHaWMIn78OHw2GNmFjS5LeVoUulWtC1TpgwbNmy45fo5c+ZQqVKl9Dq8pNXgwddPMMmtW7IEtmwxl6fAfJkbOTKd7i0QEREREZEMtXYt1K8PXbtij7pK//6mO5qnp+kLWbeuqwMUEUm9+vVhwQLw94d166BlS7g2DZNz2GxmINy4ceZuhd9+M8N8nXoQyerSrWj75JNP8sMPP/Dbb785+tnabDauXr3KW2+9xaxZs+jTp096HV6cLLkWF3h7X/95zBh48UWoVg2WLs24wESuSTZHRSxEOSpWpxwVq1OOZqD9+02zx8hIuHCB9963MXasqUFMmGBGpcnNlKNidcrRpGrWhMWLoVAh2LwZmjWDEyecfJBevUx/27x5Yc8eiIhw8gGyFuVoUjZ74hnCnMhut/P000/z/fffkzdvXi5evEihQoU4d+4csbGx9OnThzFjxqTHoTNEREQEfn5+hIeHkydPHleH43oLF5qT0ZEj5tvcyy+bvriJC7siIiIiImJtp09Dw4amcFuzJt90W0yfV8zddV99BX37ujg+EREn27PHjLQ9dgzKloX5881Ei061a5dpnlu/vpN3LJlRSmuK6TbS1maz8e2337JkyRJ69OhBu3btqFGjBk8//TSLFi3K1AXb7Gjfvn2336BFC9MuoXdvsNthxAioXRvWr8+YACXbu2OOiriYclSsTjkqVqcczQD//WdG2O7fD6VL89fTYTwz0BRsBw9WwfZOlKNidcrR5JUvbzpAli4N+/ZB06Zw4ICTD1KxYtKCbVgY/PSTkw+S+SlHk0q3om2Cxo0bM3LkSGbMmMHMmTP58ssvadq0aXofVpxs586dd97Izw9++AH+/tvcX7BjBzRoAF9/nf4BSraXohwVcSHlqFidclSsTjmazmJizCTD69aBvz/L3pnNIwMKY7fDs8/CoEGuDtD6lKNidcrRW7vnHlO4LVsWDh82hdvdu9PpYPv3w6OPQs+e5opY+twAnykpR5NK96KtZEP33QfbtkHnzubkU6uWqyMSEREREZHb2bTJzMqTMyfbP5pO2wHliYkxdYX//c90QBMRycpKlDCF20qVTKuEZs1MacPpAgOhf3/z85Ah0KMHXL2aDgeSzM4jvXYcGBh4xwbCNpuN/fv3p1cI4koFCsDvv5szXNWq15evX2+6fbvpeoGIiIiIiGXUrQvz5nF0WzjNXmtAZCS0bm3u3nV3d3VwIiIZo0gRWLTInP82b4bmzWHOHCePRXNzg+HDoUwZeOYZM8Pj4cPw55/g7+/EA0lml24TkfXq1eumom1cXByHDx9m+fLlVKlShZo1azJu3Lj0OHy6yy4TkU2dai787N5tp0IFG+++Cw89lMqdbdtm+twGBcH48aZhjIiTREZG4uPj4+owRG5JOSpWpxwVq1OOppMrVyBnTgD+/dfMQXb0qKnhzp8Pvr4uji8TUY6K1SlHU+78eWjbFtauNZ0gZ89OpznE5s41dylHREC5cqbXbdmy6XCgzCG75GhKa4rpNtJ2/Pjxt1y3efNmQkJC6NatW3odXpxg6lTo1MncCmW329i61TyfMiWVhds9e8DTExYvNqNvR46E//s/3WslTnHp0qVscXKXzEs5KlanHBWrU46mg7/+ggEDYPp0zhWrRps2pmBboQLMmKGC7d1SjorVKUdTLn9+U08NDYXlyyE42NRTmzRx8oFat4YVK8yB9u6FsWPNxO7ZlHI0KZfco169enX69OnDa6+95orDSwoNGZJQsDXP7XbzfOjQVO7woYfM/QWNG5uZaZ98Ejp2hBMnnBazZF9r1651dQgit6UcFatTjorVKUedbPly6NoVjh4lZuz3hIbCzp1QrJgZUVawoKsDzHyUo2J1ytG74+cHs2ZBixamhNG2Lcyblw4HqlwZVq2Cl182bROyMeVoUi5rLFqoUCF27NjhqsNLCuzZc/Mkhna7+TKXamXKmAYxn3wCOXKYS/hVqsAff6QlVBERERERSamdO83giago4tt34P59n7J6NeTLZwq2pUq5OkAREWvInduULdq2hcuXoUMH89zpChc2I2w9Pc3z2Fj45ZebizKSrbikaHvu3Dm+//57ihcv7orDSwqVL59854LoaOje3fTJThV3d3jlFdiwwXTzPn8eDhxIU6wiIiIiIpICx4+b6sOFC9jr1+fJ3JOYOdeDXLlMIaJyZVcHKCJiLTlzmm4y998PV6/Cgw+aOcPS1YAB0K2baSkZHZ3OBxOrSreJyFq2bJns8osXL7Jr1y6io6P5+eef6dq1a3ocPt1lh4nIkva0TdoqAcDLC55/Ht54A/LmTeVBYmJg3Dh44onr09L+95+5nCVyF06dOkWhQoVcHYbILSlHxeqUo2J1ylEnCA+Hpk1hyxbs5crxVrPlDP+uIB4e8M8/0K6dqwPM3JSjYnXK0bSJiTED2H7/3ZQvfv7ZdJlJF2PGQP/+EB9v+jNMmWJuh8jiskuOprSmmG4jbePj47Hb7UkeAIGBgfTv359t27Zl2oJtdvHQQ+a8UK0aeHnZqVbNFHLXrTPnjKtX4eOPzcSGo0al8uKPpyc8/fT1gu2VK2ZKxqefhkuXnPp+JGtTs3KxOuWoWJ1yVKxOOeoEb70FW7ZAoUKM7jib4d+ZxrXjx6tg6wzKUbE65WjaeHqajgU9ekBcnBkIO25cOh2sb1+YPt0MaFu4EBo2zBZ3KCtHk0q3kbZZXXYYaZvYtGnT6Nixo+O53W5mThw48HqP2zJl4MMPr4/OTZV//oEHHjAHCAw03yCbNk1r+JIN3JijIlajHBWrU46K1SlHnSAiAnr2ZErld+j8fi0ARo40d89J2ilHxeqUo84RH29qqt98Y55/9ZV5ni42bzaNdP/918wQ+c8/0KBBOh3M9bJLjrp8pK1kbTYbhIaaC/Vjx0KhQrB/Pzz8MDRqBCtWpHLH990HCxaY2Q8OHoTmzc0MilFRzgxfRERERCT7yZOHKd3/5JHhpmD75psq2IqI3C03N1MHGTDAPH/2Wfj883Q6WPXqsHo11KwJZ86YSST/+y+dDiZW4+GsHf3000+pel2PHj2cFYK4gIcH9OkDjz1mJjocMQJWrjSF206dzMjbsmXvcqfNm5tq8Esvwfffw2efwcyZ8NNPUKdOerwNEREREZGsaeRI08ds4EAWLrLx2GNmlNhTT8F777k6OBGRzMlmM6fXnDnho49M+eLKFXMxzOmKFoUlS+Dxx+HJJzUHUDbitPYIbm53P2jXZrMRFxfnjMNnuOzWHmH//v2UKVPmjtsdPw7vvgs//GC+DHp4mKtO77wDBQqk4sAzZpiT0smTZpbbmTNTsRPJDlKaoyKuohwVq1OOitUpR1Nh0iTHLDl7v5pL7deCuXTJzF2RMJGOOI9yVKxOOep8djsMG2bqIABvvw1Dh6ahZeSdDpZ4x3v2mLaSnp7pcDDXyC45mtKaotOKtocPH07V60qVKuWMw2e47Fa0vVvbtsGrr16vsebJY644DRhgrkTdlXPn4JVXYMgQKFnS6bGKiIiIiGQ5CxeaQQ/R0Vx8/DnKzxzFmbM2mjc339G9vV0doIhI1vHxx/Daa+bnl1+GTz5Jp8JtggMHTG/bGjVg8mTw80vHg4mzZXhP21KlSqXqIZnDtGnT7mr7KlXMRGXz5plzSEQEvP46VKgAEyaYUbgp5u9vpmRMXLB94QX49FMzZaMId5+jIhlNOSpWpxwVq1OO3oUtW8zkvtHRXAntTO0ln3PmrI2aNeHvv1WwTS/KUbE65Wj6efVVGDXK/Pzpp/Dcc3dZ97hbBw7A5cswd67pT5nKgZRWoxxNShORSbpq1QrWr4cff4TixeHoUdOGpW5dM99Yqqxebc6Gr7wCLVqYk5WIiIiIiMCRI9CuHUREENOwKY0P/syBw+6ULWtG2OomQRGR9DFgAHz9tRlhO3o0PP10Oo4zCw42fW6LFIHt26F+fVi7Np0OJq6SrkXbkydP8v7779OpUyeCg4Np2bJlkkerVq3uep9jxoyhWrVq5MmThzx58hAUFMTMRH1Oo6Ki6NevH/7+/uTOnZtOnTpx6tSpJPs4cuQIoaGh5MqVi4CAAAYOHEhsbGya368kz80NevQw7VaGDwdfX9iwwRR0Q0PN+eWu1KtnzoQ+PrB0KVSrBt98Y/q7iIiIiIhkV1FRpiXC8ePE31uZ++L+YsMObwoXhjlzoFAhVwcoIpK1Pf20GbTm5mbmVe/ZE9Kt3FSrlhnUVq0anDoFzZrBn3+m08HEFdKtaLtlyxYqVarEe++9x/79+1m4cCFnzpxh7969LFq0iKNHj5KadrrFixfnww8/ZP369axbt46WLVty//33s/1a5e/FF19k2rRpTJ48mcWLF3P8+HEeeughx+vj4uIIDQ0lOjqaFStW8OOPPzJ+/HgGDRrktPeeFZV0Qi/ZnDlNi4T9+6F/fzNJWViYOb88/TScOJHCHdls5gVbtkDTphAZCX36mArw8eNpjlMyJ2fkqEh6Uo6K1SlHxeqUoyng7Q39+mEvVYr/KzqLWavz4ecHs2ebuWokfSlHxeqUoxnj8cfh119NzWPiROjSBaKj0+lgJUrAsmXmgt2VK9CpE2TiFgPK0aScNhHZjdq3b8+2bdtYtmyZY0TrvHnzaNmyJZMnT6Zv376EhYVRr169NB8rf/78fPLJJ3Tu3JmCBQvyyy+/0LlzZwB27drFvffey8qVK2nQoAEzZ86kQ4cOHD9+nELXLjWPHTuW1157jTNnzpAjR45kj3H16lWuXr3qeB4REUGJEiU0EVka7NljirgJF4J8fGDgQNO0O3fuFO4kPh5GjjSznF29CuXLw44dmgpXRERERLKl+Hh4psdlvp2YC29vM8K2SRNXRyUikv38/Tc88ogp2HboYOYLS7ee4rGxppHuhg1mIspcudLpQOIMKZ2IzCO9Ali+fDmvvvoqJUuW5Pz58wDEX+vC/PDDD7Ns2TIGDhzI4sWLU32MuLg4Jk+eTGRkJEFBQaxfv56YmBiCg4Md21SsWJGSJUs6irYrV66katWqjoItQEhICH379mX79u3UrFkz2WMNHz6cIUOG3LR85syZ5Lr2j6F169acO3eODRs2ONYHBQXh4eHB0qVLHcuqVatGsWLFkrR1uOeee6hcuTJz584lKioKgICAAOrXr8/KlSs5e/YsALly5aJVq1Zs3bqVQ4cOOV4fGhrKoUOHHCOOAZo1a0ZUVBSrV692LKtTpw5+fn7Mnz8/yWdUrlw5ZsyY4fg7KlGiBDVq1GDRokVcunSJ+Ph4/P39ady4MevWrePEtWGxnp6etG3bll27drF3717HPtu0acOZM2fYuHGjY1nDhg1xc3Nj2bJljmWff16NAQOK0afPJfbsycfgwfDllzF88IEnxYvPJTbWfBaFChWiXr16rFixgnPnzgHg4+NDy5Yt2dyqFec//ZSaI0ey78EHqePuzv79+9mxY4fjOC1atCAyMpI1a9Y4ltWtWxdfX18WJGque++991K2bFmmT5/uGAlesmRJqlev7vgswFwoaNSoEWvXruXkyZMA5MiRg5CQEHbu3Mm+ffsc+wwJCeHUqVNs2rTJsaxRo0aA+XeSoEaNGhQqVIjZs2c7lpUtW5Z7772X2bNnE33t0lzhwoWpW7cuy5cvd/zb8vX1pXnz5mzevJkjR44AYLPZ6NChA/v27WPnzp2OfbZs2ZJLly6xNlG/m3r16uHj48PChQsdyypVqkSZMmWSNAJP+CwWLFhAZGQkAP7+/jRs2JA1a9Y4WpF4eXnRpk0bduzYwf79+x2vb9u2LcePH2fLli2OZY0bNyY+Pp4VK1Y4ltWsWZOCBQsyZ84cx7Jy5cpRsWJFZs2aRUxMDABFihShTp06LFu2jHPnzuHm5ub4LDZt2sTRo0cBcHNzIzQ0lL1797Jr1y7HPlu1akV4eDjr1q1zLKtfvz7e3t5Jzk2VK1emdOnSzJgxw7GsdOnSVK1alfnz53P58mUAChQoQFBQEKtXr+b06dMAeHt707p1a7Zv386BRP2X27Vrx7Fjx5J8Fk2aNCE2NpaVK1c6ltWqVQt/f3/mzp3rWFa+fHkqVKjAzJkzHa1dihYtSu3atVm6dCkXL14EwM/Pj6ZNm7JhwwaOHTsGgLu7O+3bt2fPnj3s3r3bsc/g4GAuXLjA+vXrHcsaNGiAl5dXks+iSpUqlCxZkrCwMMeywMBAqlSpwrx587hy5QoABQsWpEGDBqxatYozZ84AkDNnToKDg9m2bRsHDx50vL59+/YcOXKEbdu2OZY1a9aMq1evsmrVKsey2rVrky9fPubNm+dYVqFCBcqXL09YWBhx1xpGFStWjFq1arFkyRLCw8MByJs3L02aNGH9+vUcvzYi38PDg3bt2rF792727Nnj2Gd6ncsTn1dcdS4HyJcvn9PP5dWqVaNo0aLMmjXLsaxMmTJUqlSJOXPmOC563vZcnuj8BdCxY0edy8nYc3lUVBS5c+d26bn8woULST4Lnct1Lk98LgdzbnDludwK38vhhnP58eME/vMPp0JCaPXwwzz11Dl+mOiPm1s8r7yyjnr1qvPvvzqXQ/qfy+Pj4/Hz88v238t1LrfuufzUqVO4ubll++/lGXUu9/CYwRtv+DN8eF2mT3fnvvvgpZeWEBNjPgunfy9v147qAwZQxNOTWdOmgd2Oe3Q0pStVyjTn8sS//7Ly9/KEc9Ud2dNJ7ty57d9++63dbrfb4+Li7B4eHvbffvvNsf7bb7+1+/j4pGrfW7Zssfv4+Njd3d3tfn5+9hkzZtjtdrt94sSJ9hw5cty0fd26de2vvvqq3W6325966il7mzZtkqyPjIy0A/awsLBbHjMqKsoeHh7ueBw9etQO2MPDw1P1HjKbf/75J133Hx9vt//+u91+zz12u2lOa7dXrmy3z5hh1qVIbGzS59Om2e3Tpzs9VrGm9M5RkbRSjorVKUfF6pSjt/Dee44vz59+EOX4Lj1unKsDy36Uo2J1ylHXWLDAbvfxMefmZs3s9oiIDDrwoEF2e7VqdvvRoxl0wLTLLjkaHh6eoppiuvW0DQwMdFyxcXNzIzAwMMlVmBUrVpA3b95U7btChQps2rSJ1atX07dvX3r27Jmk4p8evLy8HJOfJTzEeWw2ePhh09ng888hf34zQVloqJkUMdGFtVtL3BLh1Cno3dvcg/DkkxARkW6xi4iIiIi4xPjx8PbbAKyq8Qwvv+kFwCefQK9ergtLRESua9HC9Bb39YXFi6FNG7g2CDv9XLhgJmzfsgXq14dEI3Ql83Bq0TbhNggwQ7cnT57seN63b1++++47goODadWqFT/++COPPfZYqo6TI0cOypYtS+3atRk+fDjVq1dn1KhRFC5cmOjoaMctCAlOnTpF4cKFATPsOeFWkcTrE9ZJ8vz9/TPkOF5e8MILsG+f6W+bIwcsWAC1a5tm3olG6N9enjzQo4epBn//PVSvDosWpWPk4moZlaMiqaUcFatTjorVKUdvMHOmGZwA7H3oNRpP6g+Y79CvvOLKwLIv5ahYnXLUdRo1gvnzIV8+WLUKWrWCa10J0kfCgSpXNhO2N2kC06en4wGdQzmalFMnIvPy8qJ9+/Z069aNRo0acfz4capVq4anpyd2u53333+fKVOm4O7uTocOHXjzzTdvOfHX3WjZsiUlS5Zk1KhRFCxYkF9//ZVOnToBsHv3bipWrHjTRGQnTpwgICAAgG+++YaBAwdy+vRpvLy8UnTMlDYNlrQ5dAjeegt++cU8TyjqvvEG+PmlYAeLF5thBgm9aV54AT74AHLmTI9wRURERETS39q10Lw5XL7MqTaPU3rxj0RdtdGrF/zwgxm3ICIi1rN5s7mb+OxZqFoV5s6FRFMuOV94uLmtee5ccHMzE7k/91w6HlBSIqU1RaeOtO3cuTPz5s3j0Ucf5d5772X06NEsWbIEu92OzWbj7bffZuPGjaxbt47BgwenqmD7xhtvsGTJEg4dOsTWrVt54403WLRoEd26dcPPz48nnniCl156iYULF7J+/Xp69+5NUFAQDRo0AMwI4EqVKvH444+zefNmZs+ezdtvv02/fv1SXLDNjhI3l85IpUvDxInme2mzZnD1Knz0EZQpA198YWZhvK1mzcztAE89ZZ6PHGmG7f73XzpHLhnNVTkqklLKUbE65ahYnXL0mn37TA+xy5e5FNSGKqu+I+qqjQ4d4NtvVbB1JeWoWJ1y1PWqVzdjy4oUga1bzfW3a3PTpQ8/P5gxw9yZER8PAwaYWzIsSjmalFOLthMnTuT06dNMmDCBJk2aMHHiRNq0aUOxYsV4+eWXk8z4l1qnT5+mR48eVKhQgVatWrF27Vpmz55N69atAfj888/p0KEDnTp1omnTphQuXJipU6c6Xu/u7s706dNxd3cnKCiI7t2706NHD4YOHZrm2LKyG1tKZLQ6dWDhQvjnH6hY0dxGMGCAGek/ZYqZbuGWfH1NL5cZM8yZsXFjyJ07w2KXjOHqHBW5E+WoWJ1yVKxOOXpNfDz4+HC1ck1q7v+DsxE5aNwYfv8dPDxcHVz2phwVq1OOWkOlSqZwW6IE7NoFTZvC4cPpeEBPT1MT+fBDc2WvSpV0PFjaKEeTcvqv9Zw5c9K1a1e6du3KhQsX+P333/nll18YOXIkI0eOpFy5cnTv3p3HHnuMe+655673//333992vbe3N6NHj2b06NG33KZUqVKEhYXd9bHFtWw26NgR2rWD776Dd981Aw06d4aGDWHECAgKus0O2rc3l7ISj/D+919zu0Dlyukev4iIiIhImpUvz5l/VtKxI+w/7UvVqjBtmrp/iYhkJuXKwZIl0LIlHDhgCrfz50PZsul0QJsNXnvNFFUqVbq+3G7XLRoW5tSRtjfKly8fffr0YfHixRw5coQPP/yQXLlyMWjQIMqVK0fDhg3T8/DiRFZqHeHhAc88Ywq277xjvqCuWGEKtw8/bJbfkr+/GXkLZpRC796mXcKIERAXlyHxS/qwUo6KJEc5KlanHBWry9Y5GhNj+oVhxhu06VGY1YcLU7q0mZE8b16XRifXZOsclUxBOWotpUubwm358mbS9aZNzcjbdJW4YHvq1PWWkhahHE3KqRORpcTWrVsZNGgQf//9NzabjbhMWijTRGTWcewYDBoE48aZi0SenvDss6age9uJBy9dgi5dIGHUdePG8OOPkIoR4CIiIiIi6cJuhyeegJ9/JvrbH2kz/jEWL4aAAFi2zIzWEhGRzOvkSTM52fbtULAgzJsH1aplwIEffxwmTDAD237/Hdq2zYCDCrhoIrJbSRhlW716dWrUqMHff/9Nw4YN+fLLLzPi8OIEO3bscHUIt1SsGHz/vZmFsW1bMxBh1CgzWdnHH0NU1C1e6OsL06ebGRty5zbfeqtVg6+/vkOTXLEiK+eoCChHxfqUo2J12TZHr41OsNvtfPJ1HhYvNl9jZ85UwdZqsm2OSqahHLWmwoVh0SKoWRPOnIEWLWD9+gw48P/+Zw526RJ06ABjx2bAQW9POZpUuhVtz549y1dffUXjxo0JDAzkzTffJCYmhqFDh3LgwAGWLVtG37590+vw4mT79+93dQh3VLWq+fI6Z46ZkTE83LRsqVABJk403RBuYrOZWRS3bDH3IkRGmt4L7drB2bMZ/h4k9TJDjkr2phwVq1OOitVlyxwdOxbeew+An4LG8vaqDuTIAX//DbVquTg2uUm2zFHJVJSj1lWggOlpW78+nD9vet2uXJnOB82XD2bNgl69TLvIvn3hlVduUTzJGMrRpJxatI2MjGTChAm0b9+eYsWK0b9/fw4ePMgLL7zAunXr2LFjB2+99RalS5d25mFFkmjd2lyVGj/ejMI9cgS6d4e6dWHhwlu8KDDQrPz0U/DyMi/y8cnIsEVERERErvvrL+jXD4D5TQbTa9mTuLnBr7+agVEiIpK15MtnBqE1aQIREaa2sXhxOh80Rw744QfHBUI+/dTM9n75cjofWFLCqUXbgIAAevbsyfLly3nssceYM2cOR48e5dNPP6WWLgVLBnJ3h549Yc8eeP99cwvZhg3malXHjpDsiHs3N3jpJdi40XwbTpiCNy4Ozp3L0PhFREREJBtbvhy6doX4eLY2eIrgpYMAM/D2oYdcHJuIiKSbPHnMHcTBweZG4HbtTCE3Xdls8NZb8Msvpoi7YwdcvZrOB5WUcOpEZPfffz/dunXjvvvuw9vb21m7taTsNhFZTEwMnp6erg4j1U6fhqFDzRfduDhTn33ySRgyxPSPua1PPjFXm7791lR8xZIye45K1qccFatTjorVZascfeEFGDWKf2t2pPTGqcThwfvvw5tvujowuZ1slaOSKSlHM4+oKOjUycybniMH/PFHBpUjli2DIkXMJEEukF1y1CUTkf3999888sgjWb5gmx0dP37c1SGkSUAAfPmlmY3xgQdMi5ZvvoGyZU0xNzLyFi+Mi4NJk+DUKbjvPvi//zP3KYjlZPYclaxPOSpWpxwVq8tWOfr552zrN4ZKWyYRhwfPPw9vvOHqoOROslWOSqakHM08vL3hzz/hwQchOtrcZfHHHxlw4MaNkxZsv/0W5s3LgAMbytGk0m0iMslatmzZ4uoQnKJCBXPiW7IE6tUzxdp33zUz7373nanRJuHubm5Pe+UVc8vAuHFmxrNbNscVV8kqOSpZl3JUrE45KlaX5XP0v/8cX0ZXrrJR74dnuBSXi27d4LPPzFdRsbYsn6OS6SlHM5ccOeC330y3nNhYePRRM8l6hlm69PpE7d9/nyGHVI4mpaKtZEtNmsCqVWYQbWAgnDgBTz0FNWqY/jFJmoZ4e5sWCYsXwz33mEnKWraE559Xc24RERERSburV81dXZ07s2P9FUJD4coV8//kceNMay8REcl+PD3h55+hd29zx/Djj2dY/dSMdEuoGD/5pLnlIz4+gw4uoKKtZGM2m7lStXOnGb2QLx9s2wbt25tZGjduvOEFTZrA5s3Qp495PnYsHDiQ4XGLiIiISBYSHw+9esHChcTPnUf/9ge4cAEaNIDJk81/2EVEJPtydzd3BvftawaYPfkkjB6dAQf28jIV43ffNc8//BC6dDFXFSVDOHUisuwku01EduHCBfLly+fqMNLVhQvw/vvwxRemZ4zNZq5ivfcelChxw8azZsHhw9cLuGDOnrpvzWWyQ45K5qYcFatTjorVZdkcffll+Owz7B4e/F+hMMYfa02lSuau1Pz5XR2c3I0sm6OSZShHMze73fzK+Pxz8/yTT0wnxwzx00+mWhwTY64q/v23mTzIybJLjrpkIjLJuuKzwRD4fPlgxAjYtctcPLLbzXmpfHkzU294eKKN27ZNWrBdtw7q1zdDdcUlskOOSuamHBWrU46K1WXJHP3sM/MABpUYz/hjrSlRAmbPVsE2M8qSOSpZinI0c7PZ4NNPTX0CYOBAM8gsQ/ToAXPmQN68ptfk1KnpchjlaFIq2kqKrFixwtUhZJjAQPj1V1izBpo2hagoGD4cypaFL780F5Zu8tJLsHYt1K4NH3+czIxmkt6yU45K5qQcFatTjorVZbkcnTTJDJkCvin7Me8d7Ia/v/k/cfHiLo5NUiXL5ahkOcrRzM9mM3cIDxtmnr/zDrz11g3z8qSX5s1h5UoYPDjpIDYnUo4mpaKtyC3UrQuLFplR/xUqwNmz8NxzULky/PnnDSfF33+HDh1MX4XXXoNmzWD/fleFLiIiIiJWFh5umhMCYWUH0GffK/j4mAlxK1Z0cWwiImJ5b79t7hQG+OADM44sQwq3FSuaHrcJrSEjItJt1K2oaCtyWzabmch361b46ivTsmXvXnjoITMv2apV1zYsXBj++cdM4+jrC8uXQ7VqMGZMBp05RURERCTT8PPDHjaTpZX60GHf53h62vjzTzNoQEREJCVeftncDQwwciQ8+6yZ2zLDxMbCI49Ap04waJBqH+lARVtJkZo1a7o6BJfy9DSDIfbtM1e0cuY0ddmgIHOO2r8fU+H9v/+DLVvMbQOXL5uz5p9/ujr8bCG756hYn3JUrE45KlaX1XJ0yOwGNN0xFmxuTJgArVu7OiJJq6yWo5L1KEeznn794LvvTDli7Fh44okM7Nbo5mZaRILp19C9O1y9mqZdKkeTstntKoWnRkpnessqrl69ipeXl6vDsIxjx0zvmPHjzcUkT09zsnz7bfD3x1ze+uILmD8f/vrLnMwkXSlHxeqUo2J1ylGxukyfo+fPQ+fO8OmnjF5Rk/79zeLRo811fsn8Mn2OSpanHM26Jk6Enj1NwbZLFzOpuqdnBh38hx9Mj9vYWGjc2AxcK1AgVbvKLjma0pqiKkmSInPmzHF1CJZSrJg5L23cCG3amMnJRo6EMmVMX5moaDd4/nnTEDehYHvpEvTvD2fOuDT2rEo5KlanHBWrU46K1WXqHL1yBTp2hIULCb+vO8/3N8Og3n1XBdusJFPnqGQLytGsq1s3+O038PAw81w++miaB72m3P/9n2nKnicPLFtmbkneuzdVu1KOJqWirUgaVK8Os2ebR7VqZk6JgQNNb+5ffoF4u+36xq+9ZoZSVKliirkiIiIikvXFxcFjj8GKFcTkzkuzk78ThzvPPmuKtiIiIs7QqZOZEyxHDjPY9aGHICoqgw4eHAwrVkCpUqavZOfOGdxgN2tS0VbECdq0gQ0bYNw4KFoUDh82V7rq14fFi69t9OSTULkynD4NDzwAvXqZKq+IiIiIZE12Ozz3HPz1F/E5vOgQ+zebYyvzyCPwv/9dn3xbRETEGTp2hOnTzTw8YWHQoQNERmbQwStXhtWroVUr+PFHtYl0An2CkiLlypVzdQiW5+5u6rB798J770Hu3LBunZmT7L77YGfOWmbBwIHmG/qPP0LVqrBggatDzxKUo2J1ylGxOuWoWF2mzNEPPoAxY7DbbDyRYwJzopoSHGx6Dbq7uzo4cbZMmaOSrShHs4fWrU23gty5zTQ77dpBREQGHbxQIZg3D2rUuL5s+3ZzETMFlKNJaSKyVMpuE5HJ3Tt9GoYMga+/NnfFubvDU0/B4MFQaO8y0yX8wAGz8fffmz4wIiIiIpI1/PUXPPggAIPy/o9hF5+jTh1zvd7X17WhiYhI1rdyJbRtawq29erBrFmQL18GB7FiBbRsaWZH++Yb07tBNBGZONesWbNcHUKmExBgWthu2wb3328Kt2PHQtmyMGxhYyJXbIZnnjGzKrZv7+pwMz3lqFidclSsTjkqVpfpcjQ4mOhWbfnW/zWGXXyOChXMraoq2GZdmS5HJdtRjmYvQUHmQmH+/LBmjamdnj2bwUHs3QuxseZO45AQuHDhtpsrR5NS0VZSJCYmxtUhZFoVK5qBFosXQ9268N9/MGgQlK+Vm+/rjCFu204oXPj6CyZPhuhol8WbWSlHxeqUo2J1ylGxusyWo5G23LS89A99zn1AsWJm4tqCBV0dlaSnzJajkv0oR7Of2rVh4UIzqGzTJtO+8eTJDAygZ0+YMcNcsVy0yFSSE+44ToZyNCkVbUUySNOmsGoV/PorlC4Nx4+buclqti7A7NnXNpoyBR55xMxgtnWrK8MVERERkbu1bx98+ikx0XY6d4blazzJm8+N2bPNhNoiIiIZrVo1M4isaFHTXrZZM/j33wwMICQEli+HEiVg925T71ixIgMDyLxUtJUUKVKkiKtDyBLc3Ewrl127YMQIyJvX1GbbtoU2beDgv57g728ugdWuDR99ZPoqyB0pR8XqlKNidcpRsTrL5+ipU+Y/pq+8wuT6I5g1y8zePWOGmVBbsj7L56hke8rR7KtiRViyBEqWhD17zKCyQ4cyMICqVc0otlq1TI+Gli1h48abNlOOJqWJyFJJE5GJM5w/D++/D19+aToi2GzQ/+FTfHThaXLO/cds1LCh6f9StqxrgxURERGR5P33H7RoAevWcTZPIFUiVnDOozD//GNm7RYREbGCw4ehVSvYvx+KFzc9b8uVy8AAIiPhscfA0xN+/92MbMuGNBGZONWyZctcHUKWlD8/fPop7NwJjz4Kdjt88Xsh8i/5iz86jMPu62tuG6heHX76ydXhWppyVKxOOSpWpxwVq7NsjsbEwMMPw7p1XM5VgKCI2ZyiMOPHq2Cb3Vg2R0WuUY5KqVKmVULFiqZFQtOmsGNHBgbg4wNTp8KECaZgO3gwvPuu+V3KDTk6bJhZn42paCspcuEOM/xJ2txzD0yaBKtXQ5MmEHXVxsPTe1Hbcyv/lm8Bly9r5oo7UI6K1SlHxeqUo2J1lsxRux2eegpmzSImRy5aXJ7OPsoxciR06+bq4CSjWTJHRRJRjgpAsWKmcFu1qpmUrFkz06Exw7i7g7e3+dnNDYYONVXk8PDrOTpsmJnB3d09AwOzHhVtRSykXj1z8vzrLyhfHjaeL0XJPfPoWXw+f11th6OZyaFDoM4mIiIiIq71zjvw44/Eu7nzUMzvrKE+b74Jzz/v6sBERERuLSAAFi40U+mcPWs6/Kxd64JAHn3UtEo4cADKlSPnqVPXC7ZDh5rfs9mYiraSIr6+vq4OIduw2eD++2HbNhg9GgoUdOOnf1vy4IPm1oWN/xyFGjWgUyc4c8bV4VqGclSsTjkqVqccFauzZI6WKkW8mzvP2sYy3R7Kk0/Ce++5OihxFUvmqEgiylFJzN8f5s2DoCC4eNH0ul2+PIODqFAB1qwBX184c4aWffuqYJuIJiJLJU1EJhklIgI+/tj0vo2Kgkf4jYluj+MRH2NaJnzzDTzwgKvDFBEREcl2NmyAJ5ruZVNkOR580Myp4uHh6qhERERS7tIl6NjR3PXr4wPTppmRtxnq2DEIDDS9bXPkgKtXMziAjKWJyMSpNmVogxNJLE8eM2Jj717o1Qsm2x6lTvwatlHFjLR98EHo2dNcGsvGlKNidcpRsTrlqFidZXJ03To4c4a9e6FtW9gUWY7mzeGXX1Swze4sk6Mit6AcleT4+kJYGLRpA5GR0L49zJqVwUH88APExBDv6QnR0aZFgmS+ou3w4cOpW7cuvr6+BAQE8MADD7B79+4k20RFRdGvXz/8/f3JnTs3nTp14tSpU0m2OXLkCKGhoeTKlYuAgAAGDhxIbGxsRr6VTOXo0aOuDiHbK14cxo2DjRshoHUNarOOD3mNONzgp5+wV6lq7m3IppSjYnXKUbE65ahYnSVydMcOaNOG2PqN6NnyKGfOQM2a8Pff1+dUkezLEjkqchvKUbmVXLnM77KOHc0dvvfdZ55niEQ9bGdMmWJaIwwapMItmbBou3jxYvr168eqVauYO3cuMTExtGnThsjISMc2L774ItOmTWPy5MksXryY48eP89BDDznWx8XFERoaSnR0NCtWrODHH39k/PjxDBo0yBVvSeSuVK8Oc+bAP7O8+KXqhzRhKfsog+3Yv+z6bAbx8a6OUERERCQLOnbMDK29cIEdJ/Oz6V9/ypSBmTPNnVEiIiKZmbc3/PGHmT4nJgY6dzZtf9JVcpOOvfOOCrfXZLobeGbdMEZ7/PjxBAQEsH79epo2bUp4eDjff/89v/zyCy1btgRg3Lhx3HvvvaxatYoGDRowZ84cduzYwbx58yhUqBA1atRg2LBhvPbaawwePJgcOXLcdNyrV69yNVFPjYiIiPR9oxbj5pbp6vtZXkgIBAfDjz82pO1bm+l2cgQfz3yVqg1gxAho2jA2W92jpxwVq1OOitUpR8XqXJqj4eHmftGjRzmSszwtr0zHr3Au5syBQoVcF5ZYi86jYnXKUbmTHDlg0iTTmnHiROja1Yy87dEjnQ4YF5ekYOvI0YQCblxcOh04c8j0FZ3w8HAA8ufPD8D69euJiYkhODjYsU3FihUpWbIkK1eupEGDBqxcuZKqVatSKNE3rJCQEPr27cv27dupWbPmTccZPnw4Q4YMuWn5zJkzyZUrFwCtW7fm3LlzbNiwwbE+KCgIDw8Pli5d6lhWrVo1ihUrxsyZMx3L7rnnHipXrszcuXOJiooCICAggPr167Ny5UrOnj0LQK5cuWjVqhVbt27l0KFDjteHhoZy6NAhtm/f7ljWrFkzoqKiWL16tWNZnTp18PPzY/78+Uk+n3LlyjFjxgzirw3TLFGiBDVq1GDRokVcunQJgGXLltG4cWPWrVvHiRMnAPD09KRt27bs2rWLvXv3OvbZpk0bzpw5w8aNGx3LGjZsiJubG8uWLUvyWRQtWjRJMb5MmTJUqlSJOXPmOArlhQoVol69eqxYsYJz584B4OPjQ8uWLdm8eTNHjhxxvL5jx47s37+fHTt2OJa1aNGCyMhI1qxZ41iW0GZjwYIFjmX33nsvZcuWZfr06STM0VeyZEmqV6+e5LPInz8/jRo1Yu3atZw8eRKAHDlyEBISws6dO9m3b59jnyEhIZw6dSpJ/6BGjRoBsDzR1Iw1atSgUKFCzJ4927GsbNmy3HvvvcyePZvo6GgAChcuTN26dVm+fDnnz5+nYEH44gc/1q9/F7fhcaxdCy2axbHWtwmlujTnwvPd2XnggGOfLVu25NKlS6xdu9axrF69evj4+LBw4ULHskqVKlGmTBmmTZvmWJbwWSxYsMAxut3f35+GDRuyZs0aRxsSLy8v2rRpw44dO9i/f7/j9W3btuX48eNs2bLFsaxx48bEx8ezYsUKx7KaNWtSsGBB5syZ41hWrlw5KlasyKxZs4iJiQGgSJEi1KlTh2XLlhEfH8+0adPw9fWlefPmbNq0yXH7j5ubG6Ghoezdu5ddu3Y59tmqVSvCw8NZt26dY1n9+vXx9vZm8eLFjmWVK1emdOnSzJgxw7GsdOnSVK1alfnz53P58mUAChQoQFBQEKtXr+b06dMAeHt707p1a7Zv386BRH8P7dq149ixY0k+iyZNmhAbG8vKlSsdy2rVqoW/vz9z5851LCtfvjwVKlRg5syZjrYuRYsWpXbt2ixdupSL1/ob+/n50bRpUzZs2MCxY8cAcHd3p3379uzZsydJa5ng4GAuXLjA+vXrHcsaNGiAl5dXks+iSpUqlCxZkrCwMMeywMBAqlSpwrx587hy5QoABQsWpEGDBqxatYozZ84AkDNnToKDg9m2bRsHDx50vL59+/YcOXKEbdu2OZY1a9aMq1evsmrVKsey2rVrky9fPuYlagNSoUIFypcvT1hYGHHXfqEXK1aMWrVqsWTJEsfviLx589KkSRPWr1/P8ePHAfDw8KBdu3bs3r2bPXv2OPaZXufy/PnzO/49ufJcni9fPp3LLXguBxznr8Sfhc1mo0OHDuzbt4+dO3c69pke5/LQ0FCXn8svXLiQ5LPQuVzn8hvP5UCGn8vdYmJo8v775NmyhbOehWh2ZRZRPn4MH7qae+6pr3M5OpcnPpcvWrTIpedyK3wv17ncuufyhP8zufpc7urv5VapsVj1XL59+2Y6dz7CmTPVmDOnFL16wdGjp6lW7fr7dtq5vHZtAPIvX06jRo0ICAhwnOty1KuXZb+XJ5yr7sRmT/jUMqH4+Hjuu+8+Ll686EjSX375hd69eycZFQvmA2vRogUfffQRTz/9NIcPH07yF3f58mV8fHwICwujXbt2Nx0ruZG2JUqUuONMb1nF3r17KVeunKvDkDs4dQoGD4bj30zn7/iOAPzrX41ck38if4vqrg0unSlHxeqUo2J1ylGxOpfkaHy8GWb0++9c8fSlYcxidnnXZM4caNIkY0MR69N5VKxOOSp3Iz4eBgyA0aPN81GjzPP0lF1yNCIiAj8/vzvWFDP12Ph+/fqxbds2Jk2alO7H8vLyIk+ePEke2Uniq6BiXYUKwZgx8NH2DgyvM4UzFKD4uS3kblmXhW2Gczki6062pxwVq1OOitUpR8XqXJKjZ87A+vXEuXnQMWYqW91r8vvvKthK8nQeFatTjsrdcHODL76AV14xz59/Hj76KH2PqRxNKtMWbfv378/06dNZuHAhxYsXdywvXLgw0dHRjtsQEpw6dYrChQs7tkm4XSTx+oR1IpldxYrwxtqH2Dt1G4vy3k8OYmgx9012FmjClOF7sntbGBEREZGUKVSI0d1WcF/8X8wnmO++MzNri4iIZAc2G3z88fUWs6+/DkOGQOa9Zz9zyXRFW7vdTv/+/fnzzz9ZsGABgYGBSdbXrl0bT0/PJP1Edu/ezZEjRwgKCgJMD5StW7c6etsAzJ07lzx58lCpUqWMeSMiGaDhg4VoevZPVj7zIxG2PNSOWUXhN3tTq6adRG2pRERERCSxa/9PGD8e+g8NIIxQPv7YTMwiIiKSndhsZq6wDz4wzwcPhjfeUOE2I2S6nrbPPvssv/zyC3///TcVKlRwLPfz8yNnzpwA9O3bl7CwMMaPH0+ePHl47rnnABwN1ePi4qhRowZFixbl448/5uTJkzz++OM8+eSTfJCQhXeQ0v4TWcXly5cdE65J5hS19yjH7u9Lj3+Hs+JSVQDatIFPPoFq1VwcnBMoR8XqlKNidcpRsboMy9EFC6BjRzY+8SV1v+pNXJy5NfSTT9L/0JK56TwqVqcclbQaORJefNH8PGCAeW6zOW//2SVHs2xP2zFjxhAeHk7z5s0pUqSI4/Hbb785tvn888/p0KEDnTp1omnTphQuXJipU6c61ru7uzN9+nTc3d0JCgqie/fu9OjRg6FDh7riLWUKCTM9SublXa4EZXZM55+DVXnxRfD0hGpzPuGz6j/Su5edf/91dYRpoxwVq1OOitUpR8XqMiRHN2+GBx6Ay5fZP3oWcXF2evY0t4aK3InOo2J1ylFJqxdegK++Mj//73/wzDNmwjJnUY4mlemKtna7PdlHr0T3Knl7ezN69GjOnz9PZGQkU6dOvalXbalSpQgLC+Py5cucOXOGESNG4OHhkcHvJvNYt26dq0MQJ/H3h88+g/1/buFD2xuMpxf3/fgQjcqd5u23ISLC1RGmjnJUrE45KlanHBWrS/ccPXwY2rWDS5dY5t6M7vE/0qGDje++c+4oIsm6dB4Vq1OOijP07QvjxpmJyr75Bnr3hlgnzXmuHE0q0xVtRcQ5SoRUwv39YcR7ePIgf7E2qgrb3/+TsmVhzBiIiXF1hCIikq4GD4Zhw5JfN2yYWS+SXZw7B23bwokT7PSoQoe4v6jb2JvffgON6xAREUmqVy+YOBHc3eGnn6BbN9UQ0oOKtiLZlYcHvPEGbuvWYq9WjQDO8CcPMeJMD9549iJVq8Lff6u5uIhIluXuDoMGsaPrMKpXh06d2lO9OuzoOgwGDTLrRbKDK1fgvvtg1y5OeBSndexMSlbNyz//QDZoqyciIpIqXbrA5Mmm9eLvv8PDD8PVq66OKmtR0VZSpH79+q4OQdJL9erY1qyBN97A7uZGD35mnXt99u+O4YEHoHlzWLvW1UHemXJUrE45KpbzzjvseHQIlSYNotOWQcTEuHH/lmFUmjSIHV2GwjvvuDpCkSTS7Tz600+wYgUR7nkJjp2FZ+nizJoF+fKlz+Ek69LverE65ag424MPwl9/gZeXGfT1wAPmWmhqKUeTstntGkeXGimd6S2riIiIyBbvM9tbuRJ69ODK088z7EJ/Pv8coqLMqi5d4IMPIDDQtSHeinJULGfwYDNS8VrhK0mODhsGcXG6/Twziosz937FxpphBV5eZvmVK/Dvv2ZdwiM29vrPZcpAqVJm27NnYc6cpNsm3r5RI2jc2Gx7/LiZAenaNvboGOKuxhJ7JYa4qBguNL2fY616EBkJcUeOUfODh7E79hkLsTG4xcZgi4thSeme/FjuPSIjwevCSaauK4En1xuQ2QEbsJmqjMs/kK5hj1OxIvj5ZegnLHJL6fW7PuqKnYmV3mf8oWbsCWjCsmVQrpzTDyPZgL6PitUpRyW9zJ9vblq5fBlatIB//oHcue9+P9klR1NaU1SHJkmRxYsX07FjR1eHIektKAg2byantzcfuJkG4+OfWcWssHgmTWrI1Knw3HPw1lvWG32iHBXLuXbrOQDvvHM9R4ddu/V86FDXxpcREq4LJ8zgc/kyhIcnLWYmLlhWqAAJX1oOHYItW25d2AwNhdKlzbYbN8LUqTdvm/Do1w/q1TPbLlkC779/620/+MAMGQCYOxceeSTp+sTXur/80uwbYNUqaNnylh/FwWc+Ys8DrxIZCd5bDtB+SLdbbvtLuUF8W6wxkZFQ+NwF/jkwyrHOhvnylvAFbszsQAa+ZX4uRQyHWHnL/Z7Yfo6/tpuf/fFIUrBN2DdAdbZS4fwKGjR4HIB7CkWy6mIFzvuXJ7p0eXJUKU/+oAoUaFgeW2BpU7wWyQBO/11vtxMXb+Oxbjb+PPQ2vr6waKYKtpJ6+j4qVqcclfTSqhXMmmW+oi9caNrEz5hx9xf/laNJqWgrIkklat5WIu8l3tn5GG+7HWZSyVfpdWgwn37qxQ8/wNtvm1pFwiAzEblBwq3lCYXbGjWSFmxvdet5TIxpBpXcaM2YGChf/nqv0T174NixWxcgH3kEcuY02y5YYHqd3GrbIUOgQAGz7S+/wJQpt97211+hbFmz7f/+B598knyssbGmmJlwm9NXX8HAgbf+zObPv174nDkTnn321tuWLHm9aLt1K7z33q23bdfuetH2zBkzyvUWNi84x65oU1/2XxfPfRcv3nLbUZ/GMv47iIyEihe8mUAeYvAgBs8kj1g8+Hxsfr4fa15XlnzkoFWy28XgyT97a7Bor9m2AAEM5/Wbto3BE5unJ3ty1aBUXvDxgfzeAf/P3l2HR3G1fRz/bpwECBoguAV3t+IEKXWBlhbq7vZUcN5SoS20pbQ8fQp1Woq0uAZ3LZbgUiR4AglE5/3jkE2WCIFCdkJ+n+vaK9kzs7NnN3dONvecuQ/94ybjlc8bb39vvPJ54xNgvvfJ741nsSDGlDb7BuQrwqK4f3jzXW/uODCSdxhOPN74kMBcOjPb706Ci5iJvgUjd1KcwxQ/chiOhMEKYKzpXyJezKz1Bn/3ep/q1aFm5TiqnFiJT51qULJkasJexG6++w5ryhReKjaBKVMC8PExl3U2bOjujomIiORObdqYOQ9du8Ly5dCpE8yZA0WKuLtnuZeStiKSOcuCNm1w7NtH7/0fcGuFGfTz/JHJe+rx2mtmktnw4SYvpP/LRS65eBEOHjTJ1TSJ21tTtgcGwtdfwxdfpCY2z5xJXZ784YdhwoTMj3/2bOop648+gv/9L/N9O3dOTdr+9ReMGpX5vi+9lJq03bbNzFzNzLlzqd+fP2/KAmQm7TKy3t5msPD2Nq/X29v1lmaJ9qSgUliNmpLk4U2ShzeJjku3SwnLLRtLcPCoSZgWjKhBjYbPE5fszcUkby4keXMh0ZsLCebrvP712PqO2bfwuSY05QfiM0iCJuDNzi9DOPal6UMArShNuEtCNe0tfp8PSZf6u4sWBBLl8tI9PS8lSC/d6jm/r8rogPnOdn9/1/1uDYD7nfeLExAw3GV7QID5sXqkW5nAH7gz85+FCw+gNOOnD6XmgeEMYAhD6U9/hjKEAZS5ow01f+1CdDREbKrOjAWridkQgWPXTvIf2UnwuQiqshN/LrB0W2FGXAr1WuxiK+0BiPXMz+liIcRVqIZPrRAKNw8hf8fmUKlSNvsocoPMnAlPPokjKYlkvsfD41l+/dVczikiIiLXrlkzM1ekc2dYt87Mx5g3D4oXd3fPcifVtL1Gea2m7d69e6mkf7LyrqlT4ckn4cQJLG9v1t86iDtXvsk/x0yCpWlTGDHCnFlzF8Wo5LiTJ2HHDggPd73t22cSkDExqUlIT09ITs78WLGxqcnVhx6Cn35K3ebp6ZrY3LUr9XT1oEGpS7ZmdPv+ewgKMvv++quZYZrZvs8/n/ppavVq2LDBNZmadt82bbAKBnLxIlzYc4S4/UeJTfAmNt6LC4nexMR7cz7em5g4b85QmHMXvYmJgZjzFjGxDvN9mltsLOna4uOv608rU35+pEuIZpZMzc4t7WN8fGx+QuvSzO/tvYbwwI7+7NiRTI0aHvxSwyxGltWM8IQE2Ls7mX3LjxBxwI+Nh4oRHg4Ftyznq9i+VGQfnqSP+WEBw5nX6D9Urw7NgvbRed37BDSoRqGmIXjUqGYSuiq3IJm4Ln/r16wx2dnYWL7nYfoxnm++cfDkk9enj5K36fOo2J1iVHLK1q1mpm1kJNSoYS6oK1Xqyo/LKzGa3ZyikrbXKK8lbZOTk/FIP6VH8pLjx+Hpp2HKFACSmjbnk06zGTIqkJgYs8sdd8AHH5iylDlNMSo3REKCScKGh0NEBLz2Wur0xvvuMwnTjAQGmk8qZcqwvbdJgKVcer6385NU+vBp14RoxYqpx71wwcxyT0mU/ousX1LSlZOjV7pl9pjY2Kzz0NeLh8e/T6Zmtr+/f2qliTzpssXyXMbRa1wsz7Lg2DGI+DuOo8v3cn7DTtgZQf4jOykds5PhvM1sugFwG3/yJ3e4PD7J4cnZwpWIKx/CxadeotTDnc35jKQkEwy2zoLLjfav/9bv3m3q9588yWxC6ck0Bg3z5t13r18fJW/T51GxO8Wo5KSdO81M28OHTWW1BQtMhbOs5JUYVdL2BstrSdtp06apGLSY/8Z/+smsRnbLLfDnnxyLdDBoEPz3vyaB4+kJTz0FAwemTvDLCYpRuS7Cwsxs1JRZs7t3m/IFKfbvh/LlzfeDBsEPP5izFNWru96CgsDhcCZsL7/0fHuvIdT8tT+WZcrXXu+EasotLi5n3jZf338/KzWzm6+v8nQ55UaPo+fPm3MfKb9e51Zvo9qm3yh6aidVkncSwk7yE+Pc/z5+4w/HfVSoAA8XncHbm+/nXMkQrKohBDQIwb9BNVOGJCTk6le5kFzpX8VoZCS0bAl797KeRrQjjMdeKsBnn2mMketHn0fF7hSjktP27jWLlKX8G7VwYdaVsvJKjGY3p6iatiKSfQ6HuXS7XTvndb8lS8LXH5zltXuieHVUeaZPN2sN/fgj/Oc/8PLLLmubibhPcrKpNXt5OYNff029VmfuXDNdPC1//9TEbFJSavvAgc5ZiPHxZn2ryEg4vtF8rfTzUNrMG0B/hjAMM5NxKP2xgKETBjBsMgxK6u9yyBvF4bi6pOrV7uulTxOSDfnzQ6NG5mbUAoaQmGg+yIdtt/hnzRHObdgJETvZcaoFVpSZ7B61bye+xOB7aCMc2ggLXY897aHf8bj/XqpXhwrJe/HcvsUkcytV0oqZYk469+oFe/eyz1GR7tYMbnugAJ9+qoStiIjIjVSpEixZYmbc7t5t5n4tWOCeq3NzI/2bJSJXr2xZ1/svvEDVP/9k2qhRLHq1H6+/4WD9enj3XZPAHTbM5Hrz9GXIknNiYsxJhZS6mD/9ZIouR0SYRcIut2NHatK2fXuIjsaqVp0L5atzvEh1jjhKE3nCg+PHIfInUykkMhKOH3dc+mrWEbvcQJKYmyZhmyLlvmd8Emnztd7e1zeZmvYx+fIpMSH25eVlLpmrUsUBt5UGSgPtecMyJ0PCwyFi6/O8v7o78Vt34r1vJ8XPRBCCmZ0bzFEG/ViJDT+a473iOZ1Pk14CINnhQUxQRZKrhOBfLwTvWiGmlk9wsLterriDw8Gepz8mfkk/bkueQsOuJRg3LqPF/EREROR6K1vWJG47dYLt26FtW5g/H2rXdnfP7E/lEa5RXiuPsGXLFurUqePubogdxcaapSFXrDD3b7uN5DHfMGFRSd5+20xsBKhXDz7+2Ox6IyhG8xjLgqNHU2vNpp05e/Cg+VSQsjLet9/CE0+Yh/n4EFeuKtGlqnO8aHX+yV+dDUU6szemhDMBm/L1woWr65Knp1nHq0QJcwsKgtmzzXplaTkcULUqTJvmmlzV2kvibrlpHI2NNXXSwsNh7+ZzbNmdj+07vYiIgN5x43ieLwlhJwU4n+6xLzdbCc2bU706tIn8g8obJuJbJwRHtRAz7SMkBAoVyvkXJVd0rTF64AC0agVHDifTtJkHCxaYcVfkestN46jkTYpRcacTJ0w+YPNmKFoU5s2DBg1c98krMaqatjdYXkvaimQpKcnMZBwwwFwnXrQofP01F2+9hy++gP/7P4iKMruGhsJHH0Hduu7tsuQScXHmOprwcGjaNHWW9zffmIXxMvFrl++YXuwRjh8HDh2iZORmVkdVZ69VgaSruMjE3z81AXulr0WKpJ+1NXky3H23SdRaVurXyZPhzjuv4f0QkSwlJZnzNjt2QPgOi6Mbj3FxcwTe+3cSfN7MzO3L95ylMACf8TIvMyrdceICi5NUpRo+P43Dq3oV0xgVBX5+KreQm3z4IWfqt6f5i03ZudOsXr10qfmYIiIiIjnv9Gno2hXWrjVLEsyZA82aubtXOU9J2xssryVtFyxYQMeOHd3dDbG7LVtMHYTNm839Bx6A0aM5lVSIYcNg9GhISDCJq0cegSFDoHTp6/PUitGbwOHDWDNnEf93OAnbIvDcFY7fkb04kpMB+KH9OP4s3I/jx6HCvjDGHe7MXioRTnXnLYJqRFCNUxTL9GmKFs1eErZEieszE2vyZBPr27cnUbOmJwMHKmEr9nSzj6MnT5qJ+Tt2pE7M99m0hopHllHVMgndakRQmiPOxwR7HadwSHGqV4dX/nmNlmtHklCqPJ41QvCqlWYhtJAQc1JJ19vfUFcVo2PGwLPPEusRQNXkCDzLlmbFCihT5sb2UfK2m30cldxPMSp2EBUF3bubi3Xz54eZM1MvkswrMaqFyOS6io2NdXcXJDeoUwfWrDEZquHDISwMkpMpWhQ++wyefx7efhsmToTvvjPrP732Grz5JhQo8O+eWjFqX4mJcOoURB5O5Nzf+0jYGoHHznDyHQhnUcn7WeTVmchIqHZwGz+feAJfIO08tigKEk51ZoTlY/KltlW05jdiScAHb2+TZE1JtPbIIhFbvHjOlyG46y5zmzZtZp5YCVVyr5t9HC1WzNxatUrb2pSLF5uya5dJ4v5vB+zbcp6LW3bhsW83R+OLcXS7qb/Wi4N4kIzvkX1wZB8smONy/KW/HaFy61KUKgWOuXPg2LHUhK6mdl4X2Y7RKVOwnnsOBzA8+S3iipZm2VwlbOXGu9nHUcn9FKNiBykzbG+7zaQMunaFv/6Cjh0Vo5dT0lZEri8fH7PyWM+epuhgkSKm3bKoHHyR33/Px8qV8Prr5szasGEwdiwMHgyPP65V6HOLCxdIVwM25evxY8lEnvAgMhLyH9nJG2fevjQPdhc+JLgcZ/bfpZiJKXR8lFrMJpRwqnPAtxonilYnOrg6nqVLUqKkg2pB8KUzCevtTMYWKqRFtkTk2vn5mXOOqeXT8gMNSE5uwPuHUmflLtzxO7/8fZzk8J0UO2Nm5aYshhbEcW65vyRgTkL+5fk17c5OdT5HYqGieFQPwSOlbu6rr6rMwo2ybBlW7944LItveJLP/N9j4UyoXt3dHRMREZEU+fPDjBlmcsvs2SZxW6YMHD7cnRo1YOBAsy2vU3pEsqVYscwvNRbJ0OWFaX76yWRmx4+nRevWLFsGU6bAW2+ZkqXPPAOjRsGHH5p879Um4RSj/45lwdmzmSdi036NjISY88mU5RDViHAWJ2hOONWI4Bue4lcGAFAJT+52zo+FC458/BNQjRNFqhFdqjrl63bi22YpidjSBAXN5pYgU0v2ZqMYFbtTjLry8IDy5c0tNBTAAZQASnDmTBtnqYXvwyFiRzJVwx3s3QvnzsF8GpFENCHspCz/4HX2FKxaCatWctHTn8Fn36J6TZNIrP+/F/A9sDN1Vm7KYmhly5oVDsXpijG6fTvWbbfhiIvjT27jZa/R/DXVQdOmOdM/EY2jYneKUbGTfPlg6lRTGmHtWti/H8CTLVvMuiCTJilxq5q21yiv1bQV+VeSk82ykH//bbKxr79uSij4+REfb9aUGjzYXEIP0LatWdescWP3dju3S0gwNRxTEq1ZJWOPHzf7X86PC4Swk3h8CKcGABXYxzZq4c+FDJ83vEFv1r/2iylJUDSJCjO+JKBhdTxrVVfNRxG5qcXFwZ49ZmZuSu3c/dtiSArfRZkLZlauP7G8y/vOx2ymLnXZku5Ylq8v1KmDY82a1DOZO3eaK1iKFtUlBpc7cgSaN4dDh1hBCzozn+8m+HP//e7umIiIiGSlbl2zPE5aDodp37TJLV264bQQ2Q2W15K2q1evplleXNJPrp+oKHj5ZRg/3tyvVQt+/NEkcy9t/uADGDkSLl40u/TuDe+/DxUqXPnweSVGY2KyNxv2+PHUJHh2eJFAK5bTwC+cen7h1CCcCvERFI89gAcWEc0eZusb35tEbOEEqtb3B4cDR5UqZqpYyq1aNfM1MPDGvQm5VF6JUcm9FKM3jmXB4cOppRbSJnXLHllFTbY7F0ILYSdV2I0v8Wx31OKhBlupUcMMrc9915DC+zZiFS6MI2VGbsqtRg2oXdvdL/WGyjJGY2PZ17wXcVt20orlDB1dlGefzdn+iWgcFbtTjIod5cuXmgNIy8/PlOW7GWkhMrmujh8/7u4uSG4XGAjjxsGdd8ITT8C2bdC0qSlW85//EBjoxfDhpkzCe++Zagq//mouiXjxRXjnHShcOPPD59YYTU6GM2cyL0NwedvV1mX38DCLb5UoAcHF4qnjv4cajnAqJkTgVSqI6HseNaUJApMoU60DjosWXP4Hs3BhqtXxodrdKQ3esGuXKTqkIsTZlltjVPIOxeiN43CYIbNMGejUyXVbdHRzwsObEx4Oa8Phx3CI2J5E/O6D5E86y6YNsGGD2fdO4igMOM6cgVWrzO2S2PLVubhhh7OUPB9+aP7bSSm5UL58ri+3kFWM/j7dnwe3TKYoJ3lhoBK24h4aR8XuFKNiRyEhZqZt2imlDof5+JLX6b9tEclZt90GLVqY7OykSdC/v/kPtnlzAMqVgx9+gFdegTfegAULTKmE//0PBgyAZ581a53ZWXx8asmBK82GPXECEhOv7vh+fiYJW8K5KFcmX4Msin3yNo7wS9O5Fu+BpKTUA7VqBd0fTTkqtG9vTnNePmu2WLH0l+FmZ/qziIhcUcGC5hyma91VTxISKrJ3r+us3MfCt7F/eyxB53a7LIQWwk52HahK36Jm/K9ezWL2qvfJlxDtPKLl44OjcmUztrduDa+9luOv9bpLToY//mB+4Xvp08dBIl7c9UxJBg50d8dEREQkuwYONDVsHQ6TuE35qr/nStpKNvn5+bm7C3IzKV4cJk6EX34x9fkuJWzTatAA5s0zK0m+8YaZmPvKK/DFFzB8ONx7r2se8UbGqGXB+fPZL0tw5szVP0fhwtlIwl76mj8/OJKTTKX2iIjUa22XhZsd/vjj0lEd8OsvcOhQ6hPlz5+akL28aPCCBdf6Fkk2aBwVu1OM2ou3txmqq1WD229Pbbcsf44dq0t4eF3Cw2H9Dvj50p8BDl36O3Q8gZE860zoVmUXfvFxJvu7Ywc7t8Wzscxr1KgBVatCvrpVTa3ctAuhhYSYjQEBbnsPLpcuRl9/HT77jP1eYSQkjuHee83nBJX7FXfROCp2pxgVO7rrLjOfa8gQ2L49iZo1PRk40Fykm9eppu01yms1bUVyxO7dpu7tl1+6zORMTDSlcPv3h2PHTFuzZmYG7vHjZhGznZcW3h44MHsrTCYlwenT2VukKzIy4xo7WfH0zF4CtkQJk8POdPbw+fNw9Kj5xzlFp06wbJlZ8eZyJUua/VOMHm2+psyeDQ7Wf7MiIjep8+ddz+WlzNLdszOJEgmHnHVzjxDMZEzNm6Kc4iRZrCbeu7c5yZpi7lyoVMn8nXZniZxPPjFJW+ABfuZEpweYPh18fd3XJREREZHs0EJkN1heS9pu27aNWrVqubsbcrMLDTX/DBYoAJ99Bo8+6pJgPH/e/I/28cdmQa4Ul19G8eGHZp2zK5UlSE6+uu4FBGR/NmzhwqaebLYdPpx6/WvKLSIC/vkHypaFgwdT923fHhYtMv+ZhoSkXwisUaOre2GSIzSOit0pRm9eiYnm4ozL/8zs2AHRZxKpTrhzVm7asgvFOckfpZ5ndvcvzDpnZc4S2utSgXlvb6hcOXVWbrVqpsZD3bo37HU4Y/TXX+GBBwB4nY9Z3Ph1Fi40Hx9E3EnjqNidYlTsLq/EqBYik+tq7969eeIXR9xs9Gjo2xdWrIDHH4epU+G//zWzRzFX9g8cCE8+CYMGwdix5mEpp55Svr71VvafsmjR7Cdi//UVohcvmgW8wsPNbNgXX0zd1quXmT2bkfh4M6s2ZfrQl1+Cv78pAJzLF5XJSzSOit0pRm9eXl5QpYq59eyZ2m5ZcOKEF+HhtQkPr82OHfD7pYTu/v1QmNN4H03g+P/M/pU4xRTqUJVd5Eu4mJr9vSTh8Wfw/u9X5s758/D0065J3apVzR/z7Bo0yPyd698fuBSjx45h9e2LA1hJM6ZVfY1lM5WwFXvQOCp2pxgVu1OMulLSVkTso0oVWLLETKft3x+mT4fatWHMGFPE9pJSpeCbb0zJhPj4jA/VsOGVk7DFi9/gKzv//BMWL069VnXfvtTMssNhss8pdaVq1zbTf9POmk2ZOVu4sOtx9UdMRESuA4fD/D0MCoJbbnHdFhsLO3cWcZmVGx5emaYRfxMfl0wZ/nGZlVuNCCZ825SwuVCjBnQssos3fv05/ZMGB5u/bY8+Cn36mLbkZFO3yNvbdV9PT7MKKUD//hTctw/rvfdwJCQAsCx/d+bOc1C8+HV+Y0RERERsQElbEbEXT094803o1g0efhg2bYL77oMJE+D++112rV4dtmxJzYOC+Qe0bl1Yv/4G9zMhAfbudS0euHMnLFyYWqB28mT44QfXxwUGmv9mq1Uzs5BSkrZffaVasyIiYhv+/lC/vrmllZQEBw96sGNHOcLDyxEe3plJl5K6J08CB01Fn60U5yQfOBO61Rw7KW6dgCNH4MgRtpXvjndTUx7Xa8c2c7a1UiXXxdDatDGrkV5K3OY7e57kczF4Ah/6DeDWVQMoXz6H3xgRERGRHKKattcor9W0TUxMxMudi01I3hQfD0OHwuzZsHx5utW6Jk+Gu+9OX9N28uTruNLk2bNQsGBqgdrPPjN1GXbvNkUCL7djh8kmA/z+O6xaZf75TJk5GxSk5GwepXFU7E4xKv/WyZPmXObltXP37TOTaQtxhqrsohoRrKMx4dTA2xueLTGJkf/ck+lxI+t1ocTmucThgy/xfODxDrcs/T9atszBFyeSDRpHxe4Uo2J3eSVGtRDZDZbXkrYHDhygvKYyiLskJKReMpmQAB99BC+9BPnzM3kyDBkC4eEW1as7GDjwGhK2yclw4ED6JbcjIuDYMZOgrVzZ7DtkiCmsC2YaUkoJg5SkbJcuUKjQ9XrlchPROCp2pxiVGyVtSffUUgvmz2xsLDhIJpgj6RZCq+UZQdmkfdzDH0ygF77EE4cPfsQxaRLcdZe7X5mIK42jYneKUbG7vBKjWohMrqu///47T/ziiE2lrXE3bJhJnI4YAXffzV3ffstdd8G0adPpmbK6ytCh5vrNQYNcjxMTY0oYhIdDaCgUKWLaBw82x8zMnj2pSdvevaFFC5OgLV06dQauyBVoHBW7U4zKjeLnB3XqmFtaycnwzz+wY4cH4eFlCA8vw44dHZgSDpGRQBJ4E887/J8zYetLPP0ZypAh/ZW0FdvROCp2pxgVu1OMulLSVkRyl3btzApkBw/C//5nErDz56duHzrU1L576SVTJzbtrNmDB1P3mzPHzIoFUzfPx8esan35QmAhIaY8QoqqVc1NRERE/hUPDyhXztxCQ123nTlj/nTPavUhg5KH0J8hDKM/7zGUoQzAcxtAf3d0W0RERCRHKGkrIrlL+/Zm9bFXXoHvvjO1bsuVo0GtWjBjBnzzjZk1W64c9OuX/vHFiplkbNoZsvfeC716mUXQRERExO0KF4bm84bSPHkAAy4lbAGG0R8HMCRxAAwF+itxKyIiIjcn1bS9Rnmtpu3Zs2cppDqdYjfTpplyBTExqW1Dhph/4DZvNl9TZsxWq2ZuxYq5r7+Sp2kcFbtTjIrtDBrE9ghPak3on27R0W29hlKzWgalkETcSOOo2J1iVOwur8RodnOKua4Y45IlS+jZsyfBwcE4HA6mTp3qst2yLAYMGECpUqXIly8fnTp1YteuXS77nD59mgcffJCCBQtSqFAhHnvsMc6fP5+DryL3SUxMdHcXRNLr2RP270+dIevtnTrjpl49+Osvs2jZo49Cq1ZK2IpbaRwVu1OMiu0MGkTNX/szaRLUrQu+vhZ168LkyVDz1/5K2IrtaBwVu1OMit0pRl3luqRtTEwM9erVY/To0Rlu/+ijj/j888/5+uuvWb16NQEBAYSGhnLx4kXnPg8++CDbtm1j3rx5TJ8+nSVLlvDkk0/m1EvIlVauXOnuLohkbMwYSEoiycsLEhJMTVsRG9I4KnanGBW7uusu2LQJJk6czqZNcOed7u6RSMY0jordKUbF7hSjrnJdTdtu3brRrVu3DLdZlsXIkSN57733uP322wH44YcfKFGiBFOnTqVXr17s2LGD2bNns3btWho3bgzAF198Qffu3RkxYgTBwcEZHjsuLo64uDjn/ejo6Ov8ykTkqqUsOjZkCDPr16fnpk3mPqjGnYiIiIiIiIjkWrkuaZuVffv2cezYMTp16uRsCwwMpFmzZqxcuZJevXqxcuVKChUq5EzYAnTq1AkPDw9Wr17NnZmcuh8+fDiDBw9O1z5r1iz8/f0B6Ny5M6dOnWLDhg3O7S1atMDLy4ulS5c62+rWrUvp0qWZNWuWs61SpUrUqlWLefPmOWcFBwUFOft+8uRJAPz9/enYsSNbtmxh//79zsf36NGD/fv3s23bNmdb27ZtuXjxIqtXr3a2NW7cmMDAQBYsWOBsq169OlWrVmXGjBkkJycDULZsWerXr8+iRYs4d+4cycnJLFu2jNatW7Nu3TqOHj0KgLe3N127diU8PNylDEWXLl04ceIEGzdudLa1bNkSDw8Pli1b5vJeBAcHM3v2bGdb5cqVqVmzJnPnznUmykuUKEHTpk1ZsWIFp06dAiAgIIAOHTqwefNmDh486Hx8z5492bNnD9u3b3e2tW/fnpiYGNasWeNsa9KkCQUKFGDhwoXOtho1alClShWmT59OSrnncuXKUa9ePed7AVCkSBFatWrF2rVrOXbsGAA+Pj6EhoayY8cOdu/e7TxmaGgokZGRbNq0ydnWqlUrAJYvX+5sq1+/PiVKlGDOnDnOtipVqlCjRg3mzJlDfHw8ACVLlqRJkyYsX76c06dPA1CgQAHatWvn8l44HA5uvfVWdu/ezY4dO5zH7NChA+fOnWPt2rXOtqZNmxIQEEBYWJizrWbNmlSuXJlp06Y521Lei4ULFxJzqY5s0aJFadmyJWvWrCEyMhIAX19funTpwvbt29mzZ4/z8V27duXIkSP8/fffzrbWrVuTnJzMihUrnG0NGjSgePHizJ0719lWtWpVqlevzuzZs0lISKDqhAlU/+UXGDKEZe3bk3zqFNPq16f2I49QccAAjh49yrpLJ3g8PDzo0aMHu3btIjw83HnMjh07EhUVxbp165xtzZo1w8/Pj8WLFzvbatWqRYUKFZgxY4azrUKFCtSpU4cFCxYQGxsLQLFixWjRogWrV6/m+PHjAPj5+dG5c2e2bdvG3r17nY/v1q0bhw8fdnkv2rRpQ2JiosvZxYYNG1K0aFHmzZvnbAsJCaFatWrMmjXLeflIcHAwjRo1YunSpZw9exYw498tt9zChg0bOHz4MACenp50796dnTt3EhER4Txmp06dOHPmDOvXr3e2NW/eHF9fX5f3onbt2pQrV46ZM2c62ypWrEjt2rWZP38+Fy5cAKB48eI0b96cVatWceLECQBnyZqtW7eyb98+5+O7d+/OwYMH2bp1q7Otbdu2xMXFsWrVKmdbo0aNKFy4MPPnz3e2VatWjZCQEGbOnElSUhIApUuXpmHDhixZsoSoqCgAChUqRJs2bVi/fj1HjhwBwMvLi27duhEREcHOnTudx7xRY3lycrLz98ldYzlA4cKFNZZrLM9wLAdyfCwHKFWqFI0bN2bZsmWcOXPG5b3YtGkThw4dAjSWayzHOba5cyy3w+dy0Fhu17E8OTmZRYsW5bnP5aCxPLeM5SmfR/P653KN5fYdy9P+z3Qzfy5PGauuJFcvROZwOJgyZQp33HEHACtWrKBVq1YcOXKEUqVKOfe77777cDgc/Pbbb7z//vt8//33LoMimF/ewYMH88wzz2T4XBnNtC1btmyeWYjs8OHDlC5d2t3dEEk1aJCpZXtpRq1LjA4dCklanETsReOo2J1iVOxOMSp2pxgVu1OMit3llRjN7kJkN9VM2xvJ19cXX19fd3fDbVJm4IjYxmUJWZcYVWkEsSGNo2J3ilGxO8Wo2J1iVOxOMSp2pxh1lesWIstKyZIlAZyXgqSIjIx0bitZsqTz8ogUiYmJnD592rmPpJf2EhARO1KMit0pRsXuFKNid4pRsTvFqNidYlTsTjHq6qZK2lasWJGSJUu61BKJjo5m9erVtGjRAjD1T86ePetSH2bhwoUkJyfTrFmzHO+ziIiIiIiIiIiISFq5rjzC+fPnXQoQ79u3j02bNlGkSBHKlSvHyy+/zLBhw6hatSoVK1akf//+BAcHO+ve1qhRg65du/LEE0/w9ddfk5CQwPPPP0+vXr0IDg7Odj9SSgFHR0df19dnV7GxsXnmtUrupBgVu1OMit0pRsXuFKNid4pRsTvFqNhdXonRlNd4xWXGrFwmLCzMAtLd+vbta1mWZSUnJ1v9+/e3SpQoYfn6+lodO3a0IiIiXI5x6tQpq3fv3lb+/PmtggULWo888oh17ty5q+rHoUOHMuyHbrrppptuuummm2666aabbrrppptuuummW1a3Q4cOZZl7dFjWldK6kpHk5GSOHDlCgQIFcDgc7u7ODRUdHU3ZsmU5dOhQlqvaibiLYlTsTjEqdqcYFbtTjIrdKUbF7hSjYnd5KUYty+LcuXMEBwfj4ZF55dpcVx7BLjw8PChTpoy7u5GjChYseNP/4kjuphgVu1OMit0pRsXuFKNid4pRsTvFqNhdXonRwMDAK+5zUy1EJiIiIiIiIiIiIpLbKWkrIiIiIiIiIiIiYiNK2soV+fr6MnDgQHx9fd3dFZEMKUbF7hSjYneKUbE7xajYnWJU7E4xKnanGE1PC5GJiIiIiIiIiIiI2Ihm2oqIiIiIiIiIiIjYiJK2IiIiIiIiIiIiIjaipK2IiIiIiIiIiIiIjShpKyIiIiIiIiIiImIjStqKiIiIiIiIiIiI2IiStpKl0aNHU6FCBfz8/GjWrBlr1qxxd5dEnJYsWULPnj0JDg7G4XAwdepUd3dJxGn48OE0adKEAgUKEBQUxB133EFERIS7uyXiNGbMGOrWrUvBggUpWLAgLVq0YNasWe7ulkimPvjgAxwOBy+//LK7uyICwKBBg3A4HC636tWru7tbIi4OHz5Mnz59KFq0KPny5aNOnTqsW7fO3d0ScapQoUK6sdThcPDcc8+5u2tup6StZOq3337j1VdfZeDAgWzYsIF69eoRGhrK8ePH3d01EQBiYmKoV68eo0ePdndXRNJZvHgxzz33HKtWrWLevHkkJCTQpUsXYmJi3N01EQDKlCnDBx98wPr161m3bh0dOnTg9ttvZ9u2be7umkg6a9eu5ZtvvqFu3bru7oqIi1q1anH06FHnbdmyZe7ukojTmTNnaNWqFd7e3syaNYvt27fzySefULhwYXd3TcRp7dq1LuPovHnzALj33nvd3DP3c1iWZbm7E2JPzZo1o0mTJnz55ZcAJCcnU7ZsWV544QX+85//uLl3Iq4cDgdTpkzhjjvucHdXRDJ04sQJgoKCWLx4Mbfccou7uyOSoSJFivDxxx/z2GOPubsrIk7nz5+nYcOGfPXVVwwbNoz69eszcuRId3dLhEGDBjF16lQ2bdrk7q6IZOg///kPy5cvZ+nSpe7uiki2vfzyy0yfPp1du3bhcDjc3R230kxbyVB8fDzr16+nU6dOzjYPDw86derEypUr3dgzEZHcKSoqCjBJMRG7SUpKYsKECcTExNCiRQt3d0fExXPPPUePHj1cPpeK2MWuXbsIDg6mUqVKPPjggxw8eNDdXRJx+uuvv2jcuDH33nsvQUFBNGjQgP/+97/u7pZIpuLj4/npp5949NFH83zCFpS0lUycPHmSpKQkSpQo4dJeokQJjh075qZeiYjkTsnJybz88su0atWK2rVru7s7Ik5btmwhf/78+Pr68vTTTzNlyhRq1qzp7m6JOE2YMIENGzYwfPhwd3dFJJ1mzZoxfvx4Zs+ezZgxY9i3bx9t2rTh3Llz7u6aCAB79+5lzJgxVK1alTlz5vDMM8/w4osv8v3337u7ayIZmjp1KmfPnqVfv37u7ooteLm7AyIiIje75557jq1bt6rOndhOtWrV2LRpE1FRUfzxxx/07duXxYsXK3ErtnDo0CFeeukl5s2bh5+fn7u7I5JOt27dnN/XrVuXZs2aUb58eX7//XeVmRFbSE5OpnHjxrz//vsANGjQgK1bt/L111/Tt29fN/dOJL3//e9/dOvWjeDgYHd3xRY001YyVKxYMTw9PYmMjHRpj4yMpGTJkm7qlYhI7vP8888zffp0wsLCKFOmjLu7I+LCx8eHKlWq0KhRI4YPH069evUYNWqUu7slAsD69es5fvw4DRs2xMvLCy8vLxYvXsznn3+Ol5cXSUlJ7u6iiItChQoREhLC7t273d0VEQBKlSqV7kRsjRo1VMZDbOnAgQPMnz+fxx9/3N1dsQ0lbSVDPj4+NGrUiAULFjjbkpOTWbBggWrdiYhkg2VZPP/880yZMoWFCxdSsWJFd3dJ5IqSk5OJi4tzdzdEAOjYsSNbtmxh06ZNzlvjxo158MEH2bRpE56enu7uooiL8+fPs2fPHkqVKuXurogA0KpVKyIiIlzadu7cSfny5d3UI5HMjRs3jqCgIHr06OHurtiGyiNIpl599VX69u1L48aNadq0KSNHjiQmJoZHHnnE3V0TAcwH47QzGfbt28emTZsoUqQI5cqVc2PPRExJhF9++YU///yTAgUKOOuBBwYGki9fPjf3TgTefvttunXrRrly5Th37hy//PILixYtYs6cOe7umggABQoUSFcHPCAggKJFi6o+uNjC66+/Ts+ePSlfvjxHjhxh4MCBeHp60rt3b3d3TQSAV155hZYtW/L+++9z3333sWbNGsaOHcvYsWPd3TURF8nJyYwbN46+ffvi5aVUZQq9E5Kp+++/nxMnTjBgwACOHTtG/fr1mT17drrFyUTcZd26dbRv3955/9VXXwWgb9++jB8/3k29EjHGjBkDQLt27Vzax40bp8L6YgvHjx/n4Ycf5ujRowQGBlK3bl3mzJlD586d3d01EZFc4Z9//qF3796cOnWK4sWL07p1a1atWkXx4sXd3TURAJo0acKUKVN4++23GTJkCBUrVmTkyJE8+OCD7u6aiIv58+dz8OBBHn30UXd3xVYclmVZ7u6EiIiIiIiIiIiIiBiqaSsiIiIiIiIiIiJiI0raioiIiIiIiIiIiNiIkrYiIiIiIiIiIiIiNqKkrYiIiIiIiIiIiIiNKGkrIiIiIiIiIiIiYiNK2oqIiIiIiIiIiIjYiJK2IiIiIiIiIiIiIjaipK2IiIiIiIiIiIiIjShpKyIiIiJyDRwOB4MGDXJ3N7LUr18/KlSo4O5uiIiIiMhVUtJWRERERNxmy5Yt3HPPPZQvXx4/Pz9Kly5N586d+eKLL9zdtRxXoUIFbr31Vnd3Q0RERERsQElbEREREXGLFStW0LhxYzZv3swTTzzBl19+yeOPP46HhwejRo1yd/dERERERNzGy90dEBEREZG86f/+7/8IDAxk7dq1FCpUyGXb8ePH3dMpEREREREb0ExbEREREXGLPXv2UKtWrXQJW4CgoCCX++PGjaNDhw4EBQXh6+tLzZo1GTNmTLrHpZQYWLRoEY0bNyZfvnzUqVOHRYsWATB58mTq1KmDn58fjRo1YuPGjS6P79evH/nz52fv3r2EhoYSEBBAcHAwQ4YMwbKsK76mw4cP8+ijj1KiRAl8fX2pVasW3333XfbflDT279+Pw+FgxIgRjB07lsqVK+Pr60uTJk1Yu3Ztuv2nTp1K7dq18fPzo3bt2kyZMiXD4yYnJzNy5Ehq1aqFn58fJUqU4KmnnuLMmTPOfQYOHIiHhwcLFixweeyTTz6Jj48PmzdvvqbXJCIiIiLZo5m2IiIiIuIW5cuXZ+XKlWzdupXatWtnue+YMWOoVasWt912G15eXkybNo1nn32W5ORknnvuOZd9d+/ezQMPPMBTTz1Fnz59GDFiBD179uTrr7/mnXfe4dlnnwVg+PDh3HfffURERODhkTqXISkpia5du9K8eXM++ugjZs+ezcCBA0lMTGTIkCGZ9jEyMpLmzZvjcDh4/vnnKV68OLNmzeKxxx4jOjqal19++Zrep19++YVz587x1FNP4XA4+Oijj7jrrrvYu3cv3t7eAMydO5e7776bmjVrMnz4cE6dOsUjjzxCmTJl0h3vqaeeYvz48TzyyCO8+OKL7Nu3jy+//JKNGzeyfPlyvL29ee+995g2bRqPPfYYW7ZsoUCBAsyZM4f//ve/DB06lHr16l3TaxERERGRbLJERERERNxg7ty5lqenp+Xp6Wm1aNHCevPNN605c+ZY8fHx6faNjY1N1xYaGmpVqlTJpa18+fIWYK1YscLZNmfOHAuw8uXLZx04cMDZ/s0331iAFRYW5mzr27evBVgvvPCCsy05Odnq0aOH5ePjY504ccLZDlgDBw503n/sscesUqVKWSdPnnTpU69evazAwMAMX8Plfe/Ro4fz/r59+yzAKlq0qHX69Gln+59//mkB1rRp05xt9evXt0qVKmWdPXvW2TZ37lwLsMqXL+9sW7p0qQVYP//8s8tzz549O137li1bLB8fH+vxxx+3zpw5Y5UuXdpq3LixlZCQkOXrEBEREZF/T+URRERERMQtOnfuzMqVK7ntttvYvHkzH330EaGhoZQuXZq//vrLZd98+fI5v4+KiuLkyZO0bduWvXv3EhUV5bJvzZo1adGihfN+s2bNAOjQoQPlypVL17537950fXv++eed36fMnI2Pj2f+/PkZvhbLspg0aRI9e/bEsixOnjzpvIWGhhIVFcWGDRuy+9a4uP/++ylcuLDzfps2bVz6ffToUTZt2kTfvn0JDAx07te5c2dq1qzpcqyJEycSGBhI586dXfrYqFEj8ufPT1hYmHPf2rVrM3jwYL799ltCQ0M5efIk33//PV5eulhPRERE5EbTJy4RERERcZsmTZowefJk4uPj2bx5M1OmTOGzzz7jnnvuYdOmTc6k4/Llyxk4cCArV64kNjbW5RhRUVEuycq0iVnAua1s2bIZtqet5Qrg4eFBpUqVXNpCQkIAU2c2IydOnODs2bOMHTuWsWPHZrjPtS6udvnrSUngpvT7wIEDAFStWjXdY6tVq+aSLN61axdRUVHpagZn1sc33niDCRMmsGbNGt5///10SWARERERuTGUtBURERERt/Px8aFJkyY0adKEkJAQHnnkESZOnMjAgQPZs2cPHTt2pHr16nz66aeULVsWHx8fZs6cyWeffUZycrLLsTw9PTN8jszarWwsMHYlKX3o06cPffv2zXCfunXrXtOxr2e/k5OTCQoK4ueff85we/HixV3u7927l127dgGwZcuWq34+EREREbk2StqKiIiIiK00btwYMJf9A0ybNo24uDj++usvl1mnaS/lv56Sk5PZu3evc3YtwM6dOwGoUKFCho8pXrw4BQoUICkpiU6dOt2QfmWmfPnyAM7kaloREREu9ytXrsz8+fNp1aqVS8mJjCQnJ9OvXz8KFizIyy+/zPvvv88999zDXXfddf06LyIiIiIZUk1bEREREXGLsLCwDGeLzpw5EzCX9kPqTNO0+0ZFRTFu3Lgb1rcvv/zS+b1lWXz55Zd4e3vTsWPHDPf39PTk7rvvZtKkSWzdujXd9hMnTtywvpYqVYr69evz/fffu9T3nTdvHtu3b3fZ97777iMpKYmhQ4emO05iYiJnz5513v/0009ZsWIFY8eOZejQobRs2ZJnnnmGkydP3rDXIiIiIiKGZtqKiIiIiFu88MILxMbGcuedd1K9enXi4+NZsWIFv/32GxUqVOCRRx4BoEuXLvj4+NCzZ0+eeuopzp8/z3//+1+CgoKcs3GvJz8/P2bPnk3fvn1p1qwZs2bNYsaMGbzzzjvpygek9cEHHxAWFkazZs144oknqFmzJqdPn2bDhg3Mnz+f06dPX/e+phg+fDg9evSgdevWPProo5w+fZovvviCWrVqcf78eed+bdu25amnnmL48OFs2rSJLl264O3tza5du5g4cSKjRo3innvuYceOHfTv359+/frRs2dPAMaPH0/9+vV59tln+f3332/YaxERERERzbQVERERETcZMWIE7du3Z+bMmbz66qu8+uqrrFmzhmeffZbVq1dTqFAhwMy4/eOPP3A4HLz++ut8/fXXPPnkk7z00ks3pF+enp7Mnj2bY8eO8cYbb7B27VoGDhyY4ezUtEqUKMGaNWt45JFHmDx5Ms8//zyjRo3i9OnTfPjhhzekrym6du3KxIkTSUpK4u2332by5MmMGzfOWWoira+//pqxY8dy/Phx3nnnHd5++20WLlxInz59aNWqFUlJSfTt25dixYoxcuRI5+OqVq3K8OHDmThxopK2IiIiIjeYw7oeKy+IiIiIiNwE+vXrxx9//OEyO1VEREREJKdppq2IiIiIiIiIiIiIjShpKyIiIiIiIiIiImIjStqKiIiIiIiIiIiI2Ihq2oqIiIiIiIiIiIjYiGbaioiIiIiIiIiIiNiIkrYiIiIiIiIiIiIiNqKkrYiIiIiIiIiIiIiNKGkrIiIiIiIiIiIiYiNK2oqIiIiIiIiIiIjYiJK2IiIiIiIiIiIiIjaipK2IiIiIiIiIiIiIjShpKyIiIiIiIiIiImIjStqKiIiIiIiIiIiI2IiStiIiIiIiIiIiIiI2oqStiIiIiIiIiIiIiI0oaSsiIiIiIiIiIiJiI0raioiIiIiIiIiIiNiIkrYiIiIikqUKFSpQoUIFd3dDcql27drhcDhc2saPH4/D4WD8+PHu6dRVGDRoEA6Hg0WLFrm7KyIiIpKHKGkrIiIiIrayaNEiHA5Htm/t2rVzd5dtISU5mnLz8PCgcOHCtGnThvHjx2NZlru7eN2kxMigQYPc3RURERGRG8LL3R0QEREREXtbsGBBjj5fhQoVGDhwoEvb2bNnGTVqFOXLl6dfv37p9pdUr732Gvnz5ycpKYm9e/cyefJkli1bxvr16/niiy/c3T0A7rzzTpo3b06pUqXc3RURERERW1LSVkRERESyVLly5Rx9vgoVKqSbQbl//35GjRqV4TZx9frrr1OyZEnn/S1bttCsWTNGjx7Nq6++SsWKFd3YOyMwMJDAwEB3d0NERETEtlQeQURERMRN5s+fj8Ph4Nlnn81w+549e/Dw8CA0NPSqj51ShzYqKopnnnmGUqVKERAQwC233MKGDRsAOHLkCH369CEoKIh8+fLRpUsXdu3alemx0kpb5/OXX36hfv365MuXj1KlSvHSSy9x4cKFq+7ztUhbG3XatGm0atWKAgUKOPubVe3UrC6x37dvH48//jjlypXD19eXUqVK0a9fPw4cOJCtfnXs2BEPD49M93/xxRdxOBzMmzfP2TZp0iTatm1LUFAQfn5+BAcH06lTJyZNmpSt58xMnTp1aNu2LZZlsW7dOgD69euHw+Fg7969fPLJJ9SsWRNfX1+XWczHjx/nlVdeoUqVKvj6+lKsWDHuvvtutm7dmuHzLFu2jLZt2xIQEEDRokW5//77OXToUIb7ZvVz2bt3L08++SQVK1bE19eXoKAg2rVr59x30KBBtG/fHoDBgwe7lITYv3+/8zjx8fF8+umnNGzYkICAAAoUKECbNm3466+/MuzToUOH6N27N0WKFCF//vy0bduWJUuWXOHdFREREbkxNNNWRERExE06duxI5cqV+eWXXxgxYgT+/v4u27/99lssy+KJJ564puPHx8fTuXNnLl68yP33309kZCS///47nTp1YsWKFYSGhlKqVCn69OnD7t27mTZtGj169GDHjh14enpm6zm+/PJLZs+eze23306HDh2YPXs2n3/+OSdPnuTnn3922bddu3YsXryYsLCw616HduLEicydO5dbb72VZ599lujo6Gs+1urVqwkNDSUmJoZbb72VqlWrsn//fn7++WdmzZrFypUrqVSpUpbHeOihh1i4cCE///wz77zzjsu2xMREJkyYQHBwMB07dgRgzJgxPPvss5QqVYo777yTokWLcuzYMdasWcOUKVO4++67r/n1pHX5gmAvvPACq1atokePHvTs2ZOgoCDAnDBo164d//zzD126dOGOO+7g+PHjTJo0iTlz5rBgwQKaNWvmPM6CBQvo1q0bHh4e3H///QQHB7NgwQJatWpF4cKFs92/ZcuW0aNHD86dO0doaCi9evXizJkzbNy4kVGjRtGvXz/atWvH/v37+f7772nbtq1LLBUqVAiAuLg4unbtyqJFi6hfvz6PPfYYCQkJzJgxg9tvv50vvviC559/3vm4o0eP0qJFCw4fPkxoaCgNGzZkx44ddO7c2ZkgFhEREclRloiIiIi4zYcffmgB1vjx413aExISrFKlSllBQUFWfHz8VR+3fPnyFmDde++9VkJCQrrnK1SokPXKK69YycnJzm3PPPOMBViTJk1Kd6zy5cu7tA0cONACrMDAQCs8PNzZHhsba4WEhFgeHh7W4cOHXR7Ttm1bC7DCwsKu+vXs27fPAqy2bdu6tI8bN84CLA8PD2vevHnpHpeyfdy4cem2hYWFWYA1cOBAZ1t8fLxVoUIFq0CBAtaGDRtc9l+6dKnl6elp3XrrrVfsb3R0tJUvXz6rZs2a6bZNmzbNAqzXX3/d2dawYUPLx8fHioyMTLf/yZMnr/h8lpX6/h49etSlfevWrVa+fPksh8Nh7du3z7Isy+rbt68FWGXKlLEOHDiQ7lgtW7a0PD09rdmzZ7u0R0REWAUKFLDq1KnjbEtKSrIqVapkORwOa+nSpc725ORk64EHHrAA6/J/OzL6uVy8eNEqXbq05eHhYc2aNStdnw4dOuT8PqOfXVrvvPOOBVj9+/d3ifHo6GircePGlo+Pj0t8prwfw4YNcznON9984+z/tcStiIiIyLVSeQQRERERN3rkkUfw8fHh22+/dWmfMWMGR48epW/fvnh7e1/z8UeMGIGXV+rFVb179wbMbM9hw4a5zLxM2bZ58+ZsH/+ll16iWrVqzvv58uWjd+/eJCcns379epd9f/jhB3bs2EHTpk2v6bVk5fbbb6dTp07/+jjTp09n//79vPHGGzRo0MBlW+vWrbn99tuZOXPmFWfyFihQgDvuuIPt27c7y1Gk+PHHHwHo06ePS7u3t3eGP+uiRYte1WsYMWIEgwYNon///vTp04cmTZpw4cIFXnjhhXRlLt544w3KlSvn0rZx40ZWrFhB375905XmCAkJ4YknnmDLli3OMgnLli1j79693HrrrbRu3dq5r8Ph4P3338/2rO0///yTw4cP06dPH7p27Zpue5kyZbJ1nOTkZMaMGUPlypWd5RNSFChQgAEDBhAfH8/kyZMBMyP9t99+IygoiNdee83lWI8//jhVq1bN1vOKiIiIXE8qjyAiIiLiRsWLF+euu+5iwoQJhIeHU716dQBnEvfxxx+/5mMXLlw4XUKuVKlSAFStWjVdOYaUbUeOHMn2czRq1ChdW0py7ezZsy7tl/flerpeieBVq1YBEBERkWGt22PHjpGcnMzOnTtp3Lhxlsd66KGH+PXXX/nxxx9p2LAhANHR0UybNo06depQr1495769evXizTffpHbt2jzwwAO0b9+e1q1bU7Bgwat+DZ988glgkqYFCxakcePGPPbYYzz88MPp9s3ofUt5DyIjIzN8D8LDw51fa9eu7Uzyt2nTJt2+5cuXp2zZsi61ZjOzZs0aALp06XLFfbMSERHBmTNnCA4OZvDgwem2nzhxAkh9HREREVy8eJEOHTrg5+fnsq+HhwetWrXKsNaziIiIyI2kpK2IiIiImz311FNMmDCBb7/9lhEjRnDkyBFmzZpF27ZtCQkJuebjZpTwS5l1m9W2hISE6/IcSUlJ2T7Ov1WiRInrcpzTp08DpKvHe7mYmJgrHqtLly6UKFGCCRMmMGLECDw9Pfnjjz+4cOECDz30kMu+r7/+OkWLFmXMmDF88sknzhnSPXr04LPPPqNixYrZfg1Hjx6lZMmS2do3o/ct5T2YMWMGM2bMyPSxKe9BVFQUgLMebkbPkZ2kbcpxSpcufcV9s5LS/23btrFt27ZM97ua/ouIiIjkNJVHEBEREXGzdu3aUb16dX744Qfi4+MZN24cSUlJ17wAWV50+QJbKTw8zMfdxMTEdNtSknVppSShp02bhmVZmd7atm17xT55enrSu3dvjh07xvz58wFTGsHDw4MHHnggXf8fffRR1q5dy4kTJ5gyZQp33XUXf/75J7feeusNS4Bn9L6lvAdffPFFlu9B3759AQgMDATg+PHjGT5HZGRktvqSsojY4cOHr/ZlZNj/u+++O8v+jxs37rr2X0REROR6UtJWRERExAaefPJJTpw4wdSpU/nuu+8oXLgwd999t7u7lesVLlwYyDgRuHHjxnRtzZo1A2DlypXX5flTZtT+9NNPHDp0iMWLF9O+ffssZ5MWLVqUO+64g99++40OHTqwfft2du/efV36kx1X+x6klHlYunRpum0HDhzg0KFD2TpOSqmGuXPnXnHflDq5GSWza9SoQcGCBVm3bl22Zo2HhITg5+fHunXruHjxosu25ORkVqxYkZ3ui4iIiFxXStqKiIiI2EDfvn3x8/PjlVdeYe/evTz00EPp6mvmdgcPHiQ8PJzY2Ngce85GjRrhcDiYMGGCS0Ju165djBo1Kt3+t99+O+XKlePTTz9lyZIl6bYnJCSwbNmybD9/w4YNqVmzJlOmTOGbb77Bsqx0pREAFi1ahGVZ6Z4r5VL/nIyFpk2b0qxZM3799Vd+++23dNuTk5NZvHix837r1q2pWLEi06dPd3lvLMvinXfeyfYs4dtuu40yZcrw008/MWfOnHTb0ybeixQpApBhQtjLy4tnnnmGAwcO8Prrr2eYuN26datzZq2vry/33Xcfx48fd9YDTvHtt9+yc+fObPVfRERE5HpSTVsRERERGyhSpAj33nsvP/74I8BNWRrh4YcfZvHixYSFhdGuXbscec7g4GB69+7NL7/8QqNGjejatSvHjx9nypQpdO3alUmTJrns7+vryx9//EG3bt1o27YtHTp0oE6dOjgcDg4cOMDSpUspWrSocxGr7HjooYd4++23+eijj/D3989wBvUdd9xBwYIFad68OeXLlychIYF58+axfft27rnnHsqXL/+v34ur8euvv9K+fXt69erFyJEjadiwIfny5ePgwYOsXLmSEydOOJPgHh4ejB07lu7du9OpUyfuv/9+goODWbhwIUePHqVu3br8/fffV3xOX19ffv/9d7p27Uq3bt3o2rUr9erVIzo6mk2bNhEbG+ucHV29enWCg4OZMGECvr6+lClTBofDwQsvvEBgYCCDBw9mw4YNfP7558yYMYNbbrmFoKAgDh8+zJYtW9i8eTMrV6501rH94IMPWLBgAe+99x7Lli2jQYMG7Nixg5kzZ9KlS5dszf4VERERuZ6UtBURERGxib59+/Ljjz/SvHlzateu7e7u3DS+/fZbihUrxm+//cbo0aOpVq0aY8eOJTg4OF3SFqBJkyZs3ryZjz/+mJkzZ7J8+XJ8fX0pXbo0d9xxB717976q53/wwQd59913SUhI4J577iF//vzp9hk+fDizZ89mzZo1TJs2jYCAACpXrsyYMWN47LHHrvm1X6uKFSuyceNGPv30U6ZOncq4cePw9PSkVKlS3HLLLdxzzz0u+3fq1MmZ9Jw4cSL58uWjY8eOTJw4kYcffjjbz9uiRQs2bNjA8OHDmTNnDvPnz6dw4cLUrFmTp59+2rmfp6cnkydP5q233uLXX3/l3LlzAPTp04fAwEB8fX2ZNWsW//vf//jhhx+YNGkScXFxlChRwnmsOnXqOI9XqlQpVqxYwZtvvsmcOXNYsmQJjRo1Yt68eSxcuFBJWxEREclxDuvy67BERERExC1GjBjBG2+8wf/+9z8effRRd3dHRERERETcRElbERERERu4ePEi1atXJzo6mn/++Qd/f393d0lERERERNxE5RFERERE3GjZsmUsXryYOXPmcODAAYYPH66ErYiIiIhIHqekrYiIiIgbzZ8/n8GDB1OsWDFeeeUVXn/99Qz3mzp1Kps2bbri8dq1a5dji3yJiIiIiMiNofIIIiIiIrlAv379+P7776+438CBAxk0aNCN75CIiIiIiNwwStqKiIiIiIiIiIiI2IiHuzsgIiIiIiIiIiIiIqlU0/YaJScnc+TIEQoUKIDD4XB3d0RERERERERERMTmLMvi3LlzBAcH4+GR+XxaJW2v0ZEjRyhbtqy7uyEiIiIiIiIiIiK5zKFDhyhTpkym25W0vUYFChQAzBtcsGBBN/fmxps1axbdunVzdzdEMqUYFbtTjIrdKUbF7hSjYneKUbE7xajYXV6J0ejoaMqWLevMLWZGC5Fdo+joaAIDA4mKisoTSdtTp05RtGhRd3dDJFOKUbE7xajYnWJU7E4xKnanGBW7U4yK3eWVGM1uTlELkUm2ZFVjQ8QOFKNid4pRsTvFqNidYlTsTjEqdqcYFbtTjLrSuyHZsmzZMnd3QSRLilGxO8Wo2J1iVOxOMSp2pxgVu1OMit0pRl0paSsiIiIiIiIiIiJiI0raioiIiIiIiFytQYNg6NCMtw0daraLiIhcIy93dyAvSEpKIiEhwd3d+Fdq1qzJxYsX3d2Nm4q3tzeenp7u7sZNo27duu7ugkiWFKNid4pRsTvFqNiOpycMGGC+798/NUaHDjXtQ4a4r28iGdA4KnanGHXlsCzLcncncqPsrPRmWRbHjh0jKiqK3P42W5aFw+FwdzduKg6Hg8DAQEqWLKn39jpISEjA29vb3d0QyZRiVOxOMSp2pxgVW0pJ0N52G4mvvYbX4sWpCdv+/d3dOxEXGkfF7vJKjGYnpwhK2l6z7LzBZ8+e5ejRoxQvXpyAgIBcnZiLjo7OMpDk6liWRUxMDCdOnKBUqVIUKlTI3V3K9aZNm0bPnj3d3Q2RTClGxe4Uo2J3ilGxpYQEaNAAtm3DAhwAgwenzsAVsRGNo2J3eSVGs5u0VXmEG8SyLI4fP07BggUpVqyYu7vzr128eBE/Pz93d+Omki9fPuLi4jh+/DiBgYG5OqkvIiIiIpLnJCTAAw/Atm3ApYQtQPv2buuSiIjcPLQQ2Q2SlJREUlKSZqdKlgoWLOiMFRERERERySUSEqBXL/jjD1PbFkj2uPTv9aJF7uuXiIjcNGyVtF2yZAk9e/YkODgYh8PB1KlTXbZPnjyZLl26ULRoURwOB5s2bUp3jIsXL/Lcc89RtGhR8ufPz913301kZKTLPgcPHqRHjx74+/sTFBTEG2+8QWJi4nV9LSnH8/K6OSYz+/r6ursLN6WU+Lje8ZcXVa5c2d1dEMmSYlTsTjEqdqcYFVuZNw8mTzYJ26QkGDKE8C1bTC3bAQNMrdvISFi1yt09FXHSOCp2pxh1ZaukbUxMDPXq1WP06NGZbm/dujUffvhhpsd45ZVXmDZtGhMnTmTx4sUcOXKEu+66y7k9KSmJHj16EB8fz4oVK/j+++8ZP348A25QzaGb5ZL3fPnyubsLN6WbJT7soGbNmu7ugkiWFKNid4pRsTvFqNhK9+7Qo4czYUv//iZG+/dPTdw2bQpt28J337m7tyKAxlGxP8WoK1slbbt168awYcO48847M9z+0EMPMWDAADp16pTh9qioKP73v//x6aef0qFDBxo1asS4ceNYsWIFqy6d4Zw7dy7bt2/np59+on79+nTr1o2hQ4cyevRo4uPjb9hry+2ioqLc3QWRLM2dO9fdXRDJkmJU7E4xKnanGBW3i4uDM2dS7zdu7EzYQpoY7d8f3nsP/P0hPh4eewxeesmUVBBxI42jYneKUVe2Str+W+vXrychIcElqVu9enXKlSvHypUrAVi5ciV16tShRIkSzn1CQ0OJjo5m26UC8hmJi4sjOjra5ZaXWJbl7i6IZCkuLs7dXRDJkmJU7E4xKnanGBW3iouDu++Gjh3h9GnTNmiQM2FrdkkTo0OHmgXKhgwx9z//HLp2hVOncq7PIpfROCp2pxh1dXMUXL3k2LFj+Pj4UKhQIZf2EiVKcOzYMec+aRO2KdtTtmVm+PDhDB48OF37rFmz8Pf3B6Bz586cOnWKDRs24OXlRVBQEAkJCXh5eXH+/HnnY/Lly4ePj4/L7FVfX1/y5ctHdHQ0ycnJgKl3mj9/fs6fP++seerh4UHBggWJjY11mRkcGBhIfHw8Fy5ccLYVKFCA5ORkYmJinG3+/v54enpy7tw5Z5ufnx9+fn6cPXvW2ebj44O/vz/nzp1zLpJ17tw5ChQoQExMDAmXzhI7HA4CAwO5cOGCyy9XwYIFSUxMJDY21tmWP39+gHTvhbe3t0sSPOW9iIqKciaLvb29CQgIyNZ7UahQIS5evMjFixezfC8CAgLw8PC4pvci5Wfzb9+L6OhoYmNjCQsLo3bt2pQoUYI5c+Y496tSpQo1atRgzpw5ztdYsmRJmjRpwvLlyzl96QNjgQIFaNeuHZs3b+bgwYPO/tx6663s3r2bHTt2OI/ZoUMHzp07x9q1a51tTZs2JSAggLCwMGdbzZo1qVy5MtOmTXO2lStXjnr16rFw4ULne1m0aFFatmzJmjVrnPWjfX196dKlC9u3b2fPnj3Ox3ft2pUjR47w999/O9tat25NcnIyK1ascLY1aNCA4sWLu5xlq1q1KtWrV2f27NnO97xUqVI0btyYZcuWkZyczLRp05zvxaZNmzh06BBgYqVHjx7s2rWL8PBw5zE7duxIVFQU69atc7Y1a9YMPz8/Fi9e7GyrVasWFSpUYMaMGc62ChUqUKdOHRYsWOD82RYrVowWLVqwevVqjh8/DpiY6ty5M9u2bWPv3r3Ox3fr1o3Dhw+7vBdt2rQhMTHReZIJoGHDhhQtWpR58+Y520JCQqhWrRqzZs1y/j4EBwfTqFEjli5d6ozfwMBAbrnlFjZs2MDhw4cB8PT0pHv37uzcuZOIiAjnMTt16sSZM2dYv369s6158+b4+vq6vBe1a9emXLlyzJw509lWsWJFateuzfz5851jUPHixWnevDmrVq3ixIkTgPl979SpE1u3bmXfvn3Ox3fv3p2DBw+ydetWZ1vbtm2Ji4tzXiUB0KhRIwoXLsz8+fOdbdWqVSMkJISZM2c6fz9Lly5Nw4YNWbJkiXOcLVSoEG3atGH9+vUcOXIEML/H3bp1IyIigp07dzqPmXYsT9GiRQu8vLxYunSps61u3bqULl2aWbNmOdsqVapErVq1mDdvnnMMCgoKolmzZs4YBTMWd+zYkS1btrB//37n43v06MH+/ftdTiK2bduWixcvsnr1amdb48aNCQwMZMGCBc626tWrU7VqVWbMmOH8O1K2bFnq16/PokWLnGNd4cKFad26NevWrePo0aOAGWO7du1KeHg4u3btch6zS5cunDhxgo0bNzrbWrZsiYeHB8uWLXN5L4KDg5k9e7azrXLlytSsWZO5c+c6x8QSJUrQtGlTVqxYwalL/7QGBATQoUMHl/ELoGfPnuzZs4ft27c729q3b09MTAxr1qxxtjVp0oQCBQqwcOFCZ1uNGjWoUqUK06dPd/4dSRm/0r4XRYoUoVWrVqxdu9b5GcDHx4fQ0FB27NjB7t27nccMDQ0lMjLSpZ5+q1atAFi+fLmzrX79+rl2LAfcPpafuTSDTWO5xvKMxvKUsc2dY/nKlSs5efIkoLE8L43lHvHxtP38c/IvWUKSjw+r/vtfTtesmW4sT05OZtGiRa5jef36lHznHZp8/jksXEhMrVqsffddzlWocNN+LtdYbt+xPOXzaF7/XK6x3L5jedr/mW7mz+Vp80NZcVg2nULpcDiYMmUKd9xxR7pt+/fvp2LFimzcuJH69es723/55RceeeSRdJn5pk2b0r59ez788EOefPJJDhw44PJDi42NJSAggJkzZ9KtW7cM+xMXF+dy3OjoaMqWLUtUVBQFCxZMt//FixfZt28fFStWxM/P7ypfvf3ExMQQEBCQ7RqsYWFhtGvX7sZ26iZws8WJO61Zs4amTZu6uxsimVKMit0pRsXuFKPiFhcvwp13wuzZkC8fTJtmZttmIMsY3boVbr8d9u41ZRXWrAGtbyE5TOOo2F1eidHo6GgCAwMzzSmmuKlm2pYsWZL4+HjOnj3rMts2MjKSkiVLOvdJeyYgZXvKtsz4+vri6+t7/TudSwQEBADw448/urT/8MMPzJs3L117jRo1cqxvIkCeGNgld1OMit0pRsXuFKOS4y5cgDvugLlzTcJ2xgxo3z7dbpMnw+DBsHNnU0JCYOBASLMWtlG7NqxdC08+Cf/3f0rYiltoHBW7U4y6uqlq2jZq1Ahvb2+XaekREREcPHiQFi1aAGYq/ZYtW5yXSADMmzePggULapW6LKSUNOjTp4/LLSQkJMP2y0tQZHfqt8i1SnsZl4gdKUbF7hSjYneKUclRFy6YmbFz55oFxWbOzDRhe/fdsGWLmZS7ZYu5P3lyBscsUgT++AOqVUttmz4d0pRrE7mRNI6K3SlGXdkqaXv+/Hk2bdrkrEuxb98+Nm3a5Kwfcfr0aTZt2uSsoxEREcGmTZuctYsCAwN57LHHePXVVwkLC2P9+vU88sgjtGjRgubNmwOmDkjNmjV56KGH2Lx5M3PmzOG9997jueeeyxUzaSdPhnr1zIneevUy+TBwA6TU58mOdu3aUbt2bdavX88tt9yCv78/77zzDmDKXgwaNCjdYypUqEC/fv1c2s6ePcvLL79M2bJl8fX1pUqVKnz44YfOmjAiaZ3Sog5ic4pRsTvFqNidYlRyVGQkbN8OAQEwaxZkUvpt8GAzaTal6KBlmfsp649lacECM5O3ZUtTNkHkBtM4KnanGHVlq/II69ato32as5evvvoqAH379mX8+PH89ddfPPLII87tvXr1AmDgwIHOROBnn32Gh4cHd999N3FxcYSGhvLVV185H+Pp6cn06dN55plnaNGiBQEBAfTt25ch2fqr+u9ZFlzrpNM//4QHH0z9UJByFvfnn81J4Gvh739jrsw5deoU3bp1o1evXhnOvL2S2NhY2rZty+HDh3nqqacoV64cK1as4O233+bo0aOMHDny+ndaREREREQEoEIFCAszydvWrTPdbceO1IRtCsuCNOtKZS5/fggKMvVumzSB33/PtF6uiIjkPbZK2rZr146s1kXr169futmYl/Pz82P06NGMHj06033Kly/vssJiToqNNX+b/420Z3HBJHKv1fnz5uTxlXh4XN2k7GPHjvH111/z1FNPXVO/Pv30U/bs2cPGjRupWrUqAE899RTBwcF8/PHHvPbaa5QtW/aaji03p4DsBLKIGylGxe4Uo2J3ilG54WJiYNMmuLQKOVWrmlsmZs+GzC5ILFQIkpMhy3+jmjWDdevMQmdr1kBoKHzyCbz4omreyg2hcVTsTjHqylblEcS+slrNLiO+vr4us6Kv1sSJE2nTpg2FCxfm5MmTzlunTp1ISkpiyZIl13xsuTl16NDB3V0QyZJiVOxOMSp2pxiVG+r8eejeHTp0MNnYK5g1y1ztmDKR5vIc67FjZvvZs1c4UHAwLF4MfftCUhK8/DI8+qgpkCtynWkcFbtTjLpS0jaH+fubzwPXcqtdO/2HAYcD6tS59mP6+2ev31e7kFjp0qXx8fG5qsektWvXLmbPnk3x4sVdbp06dQJwWUhOBGDz5s3u7oJIlhSjYneKUbE7xajcMCkJ2yVLwM/PTJPNwsyZphRtfLyZJPvbb1C3Lvj4JFOvHjz3HPj6mjXGGjeGv/++wvP7+cG4cfDZZ2Zq7vjxMGnSdXpxIqk0jortDBoEQ4c677rE6NChZnseZqvyCHmBw5G9cgQZGTzY1LBNqWmb8nXw4Gs/ZnbFx8fjn90ML5AvX76rOn5SUpLL/eTkZDp37sybb76Z4f4hISFXdXy5+R08eJB69eq5uxsimVKMit0pRsXuFKNyQ5w7ZxK2y5ZBYCDMnQtNm2a6+/Tp5n+y+Hi46y6YMAG8veG++2DatBn07NkTgEceMfvt2QPNm8PYsdCnTxb9cDjMLNtatWDGDHjggev7OkXQOCo25OkJAwaY7/v3T43RoUNNew6tP2VXStrmInfdZU64DhliCttXqwYDB5qzu7lF4cKFOXvZNULx8fEcPXrUpa1y5cqcP3/eObNWRERERETkuoqOhm7dYMUKk7CdN88sCJaJ6dPN/2QJCSYh++uvJmGbkUaNYP16s/7InDnw0EOwerUpWZvlBYmdO5tb2j7OnQv33HNtr1FExM769zdfUxK39eu7JmxTtudRKo+Qy9x1l6mNf+GC+ZqbErZgkrGX16MdO3Zsupm29913HytXrmTOnDnpjnH27FkSM6v4LyIiIiIiciXnz0PXriZhW6gQzJ+fZcJ22rTUhO0992SdsE1RtKiZNJuSc/jyS2jXDg4fzmYfk5JM1vfee+G11zJf9UxEJDfr398kaAcMoPtddylhm4aStpItha5Q1ym7Hn/8cTZu3Mjdd9/N119/zTPPPMOnn35KsWLFXPZ74403aNiwIbfeeitPPPEEX3/9NZ988gn9+vWjTJky6WbriqRciiZiV4pRsTvFqNidYlSuq3z5oFIlKFwYFiwwxWcz8ddfZmZtQoLJn/7yS8YJ24xi1NPT5B7++stM5l25Eho2hEWLstFHh8PsDPDpp6aMw+nT2Xt9IhnQOCq2Y1mwf79J0Pr44JmYaC5HUMIWUNJWsunidVq99IknnuCtt95iyZIlvPbaa+zbt4958+YRcFlRXn9/fxYvXswbb7zBokWLeOmll/jggw/YtWsXgwcPJjAw8Lr0R24ee/bscXcXRLKkGBW7U4yK3SlG5bry9ITvv4c1a1IToxn4808zszYhwdStzSxhC1nHaM+esG6dWbDs+HHo1MmUSrCsLPro4WEWMPnjD7OC9Lx5pt7utm3ZfJEirjSOiq0cPWpK1DRvDv/5D8THY3l7m6LhaRYny8sclpXlnwnJRHR0NIGBgURFRVGwYMF02y9evMi+ffuoWLEifn5+bujh9XX27NnrNttWUt1sceJO06ZN05ljsTXFqNidYlTsTjEq/9qZM6ZGwTvvmKTtFUydambWJibC/ffDTz+BVxarwmQnRmNj4amnzLHAJIS/+w4KFLhCZ/7+G26/3cxIy5/fHOD226/4GkTS0jgqtjFlCjzxBJw6ZQbWxEQYMoRp9evTc9Omm75EwpVyiik001ZERERERERubmfOmAW+Bgww9WGvYMqU1IRtr15XTthml78//PCDyR17eZlJtE2bQnj4FR5Yty6sXWuK4p4/Dy+8YBY6ERHJTc6dg8ceM0XCT52CUqWcCVtngjZNjdu8PuP2OvzZEREREREREbGp06dNwnbDBihWzCQMsjB5splZm5gIDzxgqihcj4RtCocDnnsOGjQwieHwcLMG2vjxpnZupooVg7lz4a23TMfy5bt+nRIRudFWroQ+fWDvXjMQvvWWGVx9fJhcqz+D68GOHd2pUQMGDuzPXUMwCzLmYSqPcI3yWnmEpKQkPLNxCZFcnZstTtzp/Pnz5M+f393dEMmUYlTsTjEqdqcYlWty6pQpILtpExQvDgsXQu3ame4+aZJJ2CYlXX3C9lpiNDLSPN/ixeb+G2/A++9fZZJ42jTzmipWvKrnlrxH46i41SOPmLNT5crBjz/CLbcA5kTZ3XebPK5lpX6dNMlMyL0ZqTyCXFfJycnu7oJIlmJiYtzdBZEsKUbF7hSjYneKUblqJ09Cx44mYVuiBCxalGXC9o8/UhO2Dz5oyhhcTfL0WmK0RAmYPz+1YsPHH5tJwcePZ/MA69aZFdKaNIGwsKt+fslbNI6KW40aBa+8Ymp0X0rYgllvMSVRC6mJ2yFD3NRPG1HSVrJFg7vY3Zo1a9zdBZEsKUbF7hSjYneKUbkqycnQvTts3mwyo2FhULNmprtPnGhq1yYlwUMPmRm2V3uh4bXGqJcXjBgBv/8OAQEmt9ywIaxalY0HlyxpEtGnTpls75dfpmY+RC6jcVRyjGXB2LHmTFjKmFSwIHz6KQQGuuwaHp5+2LIsiIjIob7amJK2IiIiIiIicnPx8ICBA6F8eZMFrVEj011//x169zYJ24cfhnHjrj5hez3ce69Za6xaNTh82ExE++qrK+Rgy5SBJUvM1OCkJLNA2RNPQFxcjvVbRMTF8eNw++3w1FNmgJ0yJcPdkpLgo48gPj79NofDjIV5nZK2IiIiIiIicvPp0cNM1apePdNdfvvN1K5NSoK+feG779yTsE1RowasWWPqOyYkmAXL+vWD2NgsHpQvn6kP+fHHJln9v/9B+/Zw7FhOdVtExJgxA+rUMbW2fXzMZQR33JFut/37zTD11lupbQ5H6lfLMufd8jolbSVbAgIC3N0FkSw1adLE3V0QyZJiVOxOMSp2pxiVK4qMhNBQ2L07tc3XN9PdJ0xITdj262dynf8mYXu9YrRgQVOuISUH+8MP0LIl7NmTxYMcDnj9dZMwCQw0q7SPH39d+iM3D42jcsPExsKzz8Ktt5qZtrVqmTNQr71mBrJLLMsMTXXrwtKlkD+/GXv/+MO0+fpa1K1rFie78073vRy7uJo1KSUP8/BQfl/srUCBAu7ugkiWFKNid4pRsTvFqGTp6FHo0MEUR3z4YVi+PHXaVgZ+/RX69DGlbx95BP77338/w/Z6xmhKDrZRI1MScvNmaNwYfvrJTCDOVNeuJlHy1Vfw5pvXrT9yc9A4KjfMffeZk0ZgFht7/33w83PZ5cQJUzEhpVpCq1bmpFSlSub+3XdDTEysJg2moUycZMu5c+fc3QWRLC1cuNDdXRDJkmJU7E4xKnanGJVMHT1qrrMND4eyZU2pgCwStr/8kpqwffRR+Pbb61MS4UbEaPv2sGEDNG8OZ8+aSWwDB5rZwZkKCYGRI1Nnt128CJ9/foUHSV6gcVRumHffhXLlYN48s9jYZQnblKoJU6aAtzcMHw6LF6cmbFMoRl0paSsiIiIiIiK505Ej0K6dqV1brpxZdKxy5Ux3/+kneOghk7B97DEzw9buFxWWKWNe1rPPmvtDhpjk7enT2TzA00/DSy+ZB505c6O6KSJ5yb59MGlS6v0WLWDXLujUyWW3mBh45hkz/ERGQs2asHo1/Oc/7q0fnlvY/M+TSMYqVKhAv379nPcXLVqEw+Fg0aJFbuvT5S7vo4iIiIiIXEeHD5uE7c6dUL68yWxePm0rjZ9+MouNJSfD44/D2LH2T9im8PWF0aPh++/NBLbZs03phI0bs/Hgbt3MYmWzZ0OzZrBjxw3vr4jcpCzLDET16plLFrZvT93m4+Oy6+rVUL8+fP21uf/yy7BuHTRokGO9zfVyyZ8ocTe/y6a2jx8/HofD4bz5+fkREhLC888/T2RkpJt6efVmzpzJoEGD3N0NuQ5q1Kjh7i6IZEkxKnanGBW7U4xKOi+/bGZ2pSRsK1bMdNcffzSlbpOT4ckn4Ztvrn/CNidi9OGHzRpjlSqZ1ddbtszGemP3329q/JYrZ96vZs1g+vQb3lexH42j8q+cOmVq1/brB+fOmTNH/v7pdktIMGVcWrUy60KWKQPz58Nnn5nzR1lRjLqyVdJ2yZIl9OzZk+DgYBwOB1OnTnXZblkWAwYMoFSpUuTLl49OnTqxa9cul30qVKjgkkx0OBx88MEHLvv8/ffftGnTBj8/P8qWLctHH310o19arnd50jbFkCFD+PHHH/nyyy9p2bIlY8aMoUWLFsTGxuZo/2655RYuXLjALbfcclWPmzlzJoMHD75BvZKcVKVKFXd3QSRLilGxO8Wo2J1iVNL5+mu44w5TGLFChUx3+/57M8PWsswiOGPG3JgZtjkVo/Xrm9lqPXqYcrWPPGIqIMTFZfGgBg1g7Vpo08YkW267zSwUZFk50mexB42jcs3mzYO6deGPP8DLy4wfGYy9ERHmZNKQIaaM9gMPwN9/Q8eO2XsaxagrWyVtY2JiqFevHqNHj85w+0cffcTnn3/O119/zerVqwkICCA0NJSLFy+67DdkyBCOHj3qvL3wwgvObdHR0XTp0oXy5cuzfv16Pv74YwYNGsTYsWNv6Gv71wYNgqFDM942dKjZfgOdPXs2w/Zu3brRp08fHn/8ccaPH8/LL7/Mvn37+PPPPzPcPyYm5ob0z8PDAz8/Pzxyy/VNct1N12wBsTnFqNidYlTsTjEqAKSdHFK0qFnVpnz5THcfP94kNS3LJDa/+urGlUTIyRgtXBj++gsGDzZrrn3zDdxyCxw6lMWDgoLMdLennzZvyCefwLFjOdZncT+No3JN3nwTunQxNcSrVYNVq+Dtt12K0lqWKeHSoIE5qVSoEPz6K/z8sxmvsksx6spWGa5u3boxbNgw7rzzznTbLMti5MiRvPfee9x+++3UrVuXH374gSNHjqSbkVugQAFKlizpvAUEBDi3/fzzz8THx/Pdd99Rq1YtevXqxYsvvsinn36aZd/i4uKIjo52ueUoT08YMCB94nboUNNukwrOHTp0AGDfvn3069eP/Pnzs2fPHrp3706BAgV48MEHAUhOTmbkyJHUqlULPz8/SpQowVNPPcWZywrjW5bFsGHDKFOmDP7+/rRv355t27ale97MatquXr2a7t27U7hwYQICAqhbty6jRo0CoF+/fs4TBGlnZqe43n2UG8vSLAGxOcWo2J1iVOxOMSocOGCWH//qq2ztPm4cPPqoSSY884xJKNzIOR45HaMeHuZfwRkzTFJkzRpo2BAWLMjiQT4+Zqrx11/D779DqVI51l9xP42jck0KFjRfn30WNmwwZRHSOHLElM5+/nm4cMGsRbZlC/TqdfVPpRh15eXuDmTXvn37OHbsGJ3SrEQXGBhIs2bNWLlyJb3SRMMHH3zA0KFDKVeuHA888ACvvPIKXl7mpa5cuZJbbrkFnzQFkkNDQ/nwww85c+YMhTM5BTB8+PAML6OfNWsW/pdqeHTu3JlTp06xYcMGvLy8CAoKIiEhAS8vL86fP+98TL58+fBJSCAqKsrZ5uvrS758+YiOjibZ4QA/P7y8vMifPz/nIyNJfPRRfKOjyTdgAMTHE/viizg++oh8I0Zw4Z138HvvPeLj4rhw8qTzmAUKFCA5OTl1dquHB/5Fi+Lp6cm5c+ec+/n5+eHn5+cym9bHxwd/f3/OnTtHUlISAOfOnaNAgQLExMQ4yx+kvK4LFy4QFxfH1q1bAShcuDDJyckkJibSuXNnmjdvzocffoi/vz9nz57lpZde4pdffuHhhx/m+eefJyIigm+//ZZ169YRFhZGwYIFiYqKYtiwYYwYMYLQ0FB69uzJ6tWr6dy5M/Hx8SQkJAAQGxvr7EfK14sXLzJr1ix69epFiRIleOGFFyhRogRbtmxh6tSp9O3bl8cee4zDhw8zf/58vr5UGTslLtL28aGHHuLFF18kIiKCsWPHsm7dOubPn0/hwoWJiYlh0KBBjBgxgi5dunDbbbexZs0aZx/j4+Od70PakhH58+cHzMzv2NhYwsLCqF27NiVKlGDOnDnO/apUqUKNGjWYM2cO8fHxAJQsWZImTZqwfPlyTl9aMrZAgQK0a9eOzZs3c/DgQcAkom+99VZ2797NjjSLDXTo0IFz586xdu1aZ1vTpk0JCAggLCzM2VazZk0qV67MtGnTnG3lypWjXr16LFy40BlXRYsWpWXLlqxZs8ZZz9jX15cuXbqwfft29uzZ43x8165dOXLkCH///bezrXXr1iQnJ7NixQpnW4MGDShevDhz5851tlWtWpXq1asze/Zs58++VKlSNG7cmGXLlpGcnMy0adOc78WmTZs4dGmqgYeHBz169GDXrl2Eh4c7j9mxY0eioqJYt26ds61Zs2b4+fmxePFiZ1utWrWoUKECM2bMcLZVqFCBOnXqsGDBAufPtlixYrRo0YLVq1dz/PhxwPx+de7cmW3btrF3717n47t168bhw4dd3os2bdqQmJjIypUrnW0NGzakaNGizJs3z9kWEhJCtWrVmDVrFomJiQAEBwfTqFEjli5d6vxdDgwM5JZbbmHDhg0cPnwYAE9PT7p3787OnTuJiIhwHrNTp06cOXOG9evXO9uaN2+Or6+vy3tRu3ZtypUrx8yZM51tFStWpHbt2syfP58LFy4AULx4cZo3b86qVas4ceIEgLOszdatW9m3b5/z8d27d+fgwYPO8QOgbdu2xMXFsWrVKmdbo0aNKFy4MPPnz3e2VatWjZCQEGbOnOkcq0qXLk3Dhg1ZsmSJc5wtVKgQbdq0Yf369Rw5cgQALy8vunXrRkREBDt37nQeM+1YnqJFixZ4eXmxdOlSZ1vdunUpXbo0s2bNcrZVqlSJWrVqMW/ePOdVIEFBQTRr1swZowD+/v507NiRLVu2sH//fufje/Towf79+11O/LRt25aLFy+yevVqZ1vjxo0JDAxkQZr/yqpXr07VqlWZMWMGycnJAJQtW5b69euzaNEi57hfuHBhWrduzbp16zh69CgA3t7edO3alfDwcJeyQ126dOHEiRNsTLPKScuWLfHw8GDZsmUu70VwcDCzZ892tlWuXJmaNWsyd+5c4i5dr1miRAmaNm3KihUrOHXqFAABAQF06NDBZfwC6NmzJ3v27GF7msUN2rdvT0xMDGvWrHG2NWnShAIFCrBw4UJnW40aNahSpQrTp093fvBLGb/SvhdFihShVatWrF27lmOXZhr5+PgQGhrKjh072L17t/OYoaGhREZGsmnTJmdbq1atAFi+fLmzrX79+rl2LAfcPpannBjVWK6xPKOxPGVsc+dYvnLlSk5e+rytsTxnx/J8kZG0GTgQ3yNHiB0+nLCgIJJ9fTMdyw8fDuXxxy0sy0H37vvo2nUriYk3dixPTk5m0aJFOT6WJybG8OGH+Rgxojk7d+anSxeLhx7awV137cHPL5Ox/NFHzVh+6ZjFN26kVqNGxDdvrrGcm3csT/k8mtc/l2ssv8JYvnEjx7ZsIf5Sfqznf/7D4cqV2ZA/v/OsUMpY/tlnh/jqq7qcO+eDn5/F0KHxVK06l40bzUKJV/u5PO3/TDfz5/JslxS1bAqwpkyZ4ry/fPlyC7COHDnist+9995r3Xfffc77n3zyiRUWFmZt3rzZGjNmjFWoUCHrlVdecW7v3Lmz9eSTT7ocY9u2bRZgbd++PdP+XLx40YqKinLeDh06ZAFWVFRUhvtfuHDB2r59u3XhwoXMXmDmt+7dXff198983woVXPctVizzfRs3zvT1XUlMTIzL/XHjxlmANX/+fOvEiRPWoUOHrAkTJlhFixa18uXLZ/3zzz9W3759LcD6z3/+4/LYpUuXWoD1888/u7TPnj3bpf348eOWj4+P1aNHDys5Odm53zvvvGMBVt++fZ1tYWFhFmCFhYVZlmVZiYmJVsWKFa3y5ctbZ86ccXmetMd67rnnrIx+DW5EHzNyxTiRbNu0aZO7uyCSJcWo2J1iVOxOMZqH7d1rWeXKmf9pqla1rH/+yXL3b7+1LIfD7P7cc5aV5mP6DeXuGI2Ntax+/VL//bvzTsvK5N9VVzt3WlZgoGV5eVnWmDE3upviRu6OUckFDh60rPbtLatOHcvKIk9x9qxlPfRQ6njTsKFlbdv2758+r8RoVFRUljnFFLYqj3A9vPrqq7Rr1466devy9NNP88knn/DFF184zyZcK19fXwoWLOhys4Us6jddT/4ZrAgI5ixg8eLFKVu2LL169SJ//vxMmTKF0qVLO/d55plnXB4zceJEAgMD6dy5MydPnnTeGjVqRP78+Z1nIubPn098fDwvvPCCS9mCl19++Yr93bhxI/v27ePll1+mUKFCLtvSHiszOdFHub7q1avn7i6IZEkxKnanGBW7U4zmUXv2QNu2cPAghITAokWQ5n+Ny337LTz+uEkjPP88fPGFqfmaE9wdo/nywXffmfq2Pj6m3G+TJnDFym2lS5trmxMTTR2Jp5+GSzPQ5Obi7hgVm5swwSw2FhZmxt40s3rTWrTI7Pbjj6ZMy7vvwsqVULPmv++CYtRVrknalixZEsB5yV6KyMhI57aMNGvWjMTEROc095IlS2Z4jLTPkSPOn8/8NmmS677Hj6due+8905ZS3uGWW1z33b8/8+MuWXLN3U1bTiGt0aNHM2/ePMLCwti+fTt79+4lNDTUud3Ly4syZcq4PGbXrl1ERUURFBRE8eLFXW7nz593Xr5y4MABwFx+k1bx4sUzLWORIuXSn9q1a1/dC83BPsr1dXk9YxG7UYyK3SlGxe4Uo3nQ7t3Qrp1ZXataNZMpCA7OdPf//heeeMJ8/+KL8PnnOZewBXvEqMMBTz4JS5dCmTKwcyc0bQq//ZbFg/z94Zdf4IMPUlc169jR/B8qNxU7xKjY0Nmz0KcP9O5tvm/aFDZtghYtXHa7eBFefx06dDDn0SpVMmPNsGGpKap/SzHqKtfUtK1YsSIlS5ZkwYIF1K9fHzD1QFevXp1uJmdamzZtwsPDg6CgIMDUP3n33XdJSEjA29sbgHnz5lGtWrWcTbKlWRwt2/sOHWp+G4YMgf79Uxch8/Y296/2uFchpSbN5Zo2bUrjxo0zfZyvry8el1X7T05OJigoiJ9//jnDxxQvXvzaO3qd5IY+iqvMTiyI2IViVOxOMSp2pxjNg6ZPh3/+gerVzcyvLCbZjB0LTz1lvn/pJfjss5xN2IK9YrRpU7NeUK9esHCh+bp6NXz4ofn3MR2HA956C2rXhgcegGXLoHFj+PNPsxy83BTsFKNiE4sXw8MPmyysh4eZKPjee+kGir//NnndLVvM/SeegE8/hUvL9Vw3ilFXtkranj9/3qW48L59+9i0aRNFihShXLlyvPzyywwbNoyqVatSsWJF+vfvT3BwMHfccQdgFhlbvXo17du3p0CBAqxcuZJXXnmFPn36OBOyDzzwAIMHD+axxx7jrbfeYuvWrYwaNYrPPvvMHS85+1IStCkJW0j9OmCA632bq1y5MvPnz6dVq1bky5cv0/3KXyr9sGvXLipVquRsP3HihLO4fVbPAbB161aXxesul1mphJzoo4iIiIiIZOHll03i4J57oESJTHf75htzRX/KQz79NOcTtnZUvDjMmWP+TfzgA5PIXrcOfv89i/x3jx4mu3v77Waa7nffmRoTInLzsSwYNCh12uxPP6WbXZuUZMbU994zVVOCgkwZmp493dPlvMZW5RHWrVtHgwYNaHDpTN6rr75KgwYNGHApKfnmm2/ywgsv8OSTT9KkSRPOnz/P7Nmz8fPzA8yszgkTJtC2bVtq1arF//3f//HKK68wduxY53MEBgYyd+5c9u3bR6NGjXjttdcYMGAATz75ZM6/4KuRlOSasE3Rv79pz2Qm7PXi5XX98vv33XcfSUlJDB06NN22xMRE5wqbnTp1wtvbmy+++MK5yiDAyJEjr/gcDRs2pGLFiowcOdJ5vBRpjxVwaWby5fvkRB/l+ipSpIi7uyCSJcWo2J1iVOxOMZpH7NljSruleO65LBO2Y8akJmxfecW9CVs7xqiXFwwfDpMnQ4EC5lLmhg0hzQLr6VWvbhK3b78Nn3ySY32VG8+OMSpu5HDA+PFmnM2gHML+/aYUwptvmoTtbbeZmbY3MmGrGHXlsNJmmiTboqOjCQwMJCoqKsNFyS5evMi+ffuoWLGiM6l8Mxk/fjyPPPIIa9euzbQ8Qr9+/fjjjz84n/ZD1yVPP/0033zzDd26daNLly54e3uza9cuJk6cyKhRo7jnnnsAeOeddxg+fDjdu3ene/fubNy4kVmzZhEfH0+PHj0YP348YOqetG/fnrCwMNq1awfAnDlz6NmzJ8HBwTzyyCOUKlWK8PBwtm3bxpw5cwCz4Nh9993HQw89RGhoKJ6envTq1euG9DEjN3uciIiIiIhk244dJkNQrRrMmHHF0m9ffWVyDQCvvgojRmiGbVZ27oQ774Tt200y95NP4IUXsvmeJSbC//2fmcocGHijuyoiN4JlwejRZmbtRx9ludsPP5jx4dw5MxSPGgWPPqox9nq5Uk4xha1m2op9xcTEXNfjff3114wdO5bjx4/zzjvv8Pbbb7Nw4UL69OlDq1atnPsNGzaMwYMHs3HjRt544w327NnD3LlznTNksxIaGkpYWBghISF88sknvPrqqyxYsICeaU4L3XXXpNqJRQABAABJREFUXbzwwgvMnj2bhx56iN69e+doH+X6Wbt2rbu7IJIlxajYnWJU7E4xepPbvh3at4djx+DMGbhwIcvdR49OTdi+/ro9ErZ2j9GQEDOB9v77TQ72pZdMjcps/av33nvmMupmzSAi4kZ3VW4Qu8eo3EBHj0L37iYT+/HHZjDIwMmTpiJNv34mYduyJWzeDI89ljNjrGLUlWbaXqO8NtP27NmzFCpUyN3duOncbHHiTtOmTXNJyIvYjWJU7E4xKnanGL2JbdtmZtgePw716sH8+VCsWKa7f/mlyTsAvPGGWVzL3QlbyD0xallm1tzrr5sqe7Vrm/IJVatm8aD16+GOO8zCcIGB8Ouv0K1bTnVZrpPcEqNynU2ZYlYOO3UK/PxM0va559INnDNnmtm0kZFmNv6QIaY0gqdnznU1r8SoZtqKiIiIiIiIvW3dambYHj8O9evDggVZJmy/+CI1Yfvmm/ZJ2OYmDoepchAWZhYk27oVGjeGP//M4kGNGplVzFq1gqgos2DZRx+ZDLCI2NP58/D443DXXSZhW7++OQHz/PMuA2dMDDz7rPm1joyEGjVSy1rnZMJW0lPSVrLFoU9CYnM+Pj7u7oJIlhSjYneKUbE7xehNaMsWk7A9cQIaNDAJ26JFM93988/hxRfN92+9BR98YK+EbW6L0TZtYMMGk4eNjjYTad99N4s1rkuUMD+jxx83ydq33oIHH4TY2JzstvwLuS1G5V+wLDO+/u9/ZqD8z39MJrZmTZfdVq82w++YMeb+Sy+ZvG7Dhm7oM4rRy6k8wjXKa+UR5MZQnIiIiIhInrV5symLULEizJ0LWawaPnIkvPKK+f7tt82aWHZK2OZmCQmmVMLnn5v7nTvDL79kMeHZskyG56WXwMcH1qyBWrVyrL8ikk2//WYuSfjxR7jlFpdNCQlmHB02zJyoKV0axo+HTp3c09W8RuUR5Lq6cIWFAETcbceOHe7ugkiWFKNid4pRsTvF6E2oXj1YvBjmzcsyYfvZZ6kJ23fesW/CNrfGqLe3qXH7yy/g729+HI0aQabrATkc5lrqefPg55+VsM1FcmuMSjbt2mXG1BT33w87dqRL2EZEmBn2gwebhG3v3ubCBzskbBWjrpS0lWyJi4tzdxdEsrR79253d0EkS4pRsTvFqNidYvQmsWEDLF+eer92bShcONPdP/0UXn3VfP/uu2ZWmB0TtpD7Y7R3b1i1CqpUgYMHoXVr+PbbLB7Qrp2pqZBi5Ur4739vcC/l38jtMSqZsCzzu1e/Ptx3n6kRnsLf32W3r74y5RDWroVChczJml9+yXIYzlGKUVdK2oqIiIiIiMiNt369mcrVtav5/go++QRee818/957MHSofRO2N4s6dcx6Y7ffDvHxZsH5xx+Hixev8MATJ+DOO+HJJ80iRwkJOdJfkTzvxAlz8uTJJ0196Zo1ITEx3W5Hj0L37vDcc3DhAnTsaGbX9u6d812W7FPS9gZTyWDJiuJDRERERPKEdetMwvbMGZMZrFo1y91HjDB1VgEGDIAhQ5SwzSmBgTB5Mrz/Pnh4mHWMWreG/fuzeFCxYiZZCzB6NHTpYpJJInLjzJxpxtO//jL1pUeMMIsFBge77DZpkrmoYfZs8PMz5VDmzoUyZdzUb8k2LUR2ja5UNDgpKYmdO3cSFBRE0SxWQM0tkpOT8fBQjv96O3XqFMePHyckJARPT093dydXi4+P10qTYmuKUbE7xajYnWI0F1u71qxuFRUFLVvCrFmQxcIrH30Eb71lvh84EAYNyplu/ls3Y4zOm2dm4p06ZcoO//ILhIZm8YA//4Q+feD8eShf3tyvVy/H+itZuxljNE9KSoIXXzS1DsDUlf7553S/a1FRZrcffjD3GzSAn34yk3HtKq/EaHYXIvPKwT7lKZ6enhQqVIjjl2qJ+Pv748jFp4bzyi9OTrEsi9jYWI4fP06hQoWUsL0OIiMjKVu2rLu7IZIpxajYnWJU7E4xmkutXm1mXUZHm+maM2dCgQKZ7v7hh/Cf/5jvc1PCFm7OGO3c2ZQhvvtuM1m6Wzcz6/mdd8ws3HRuv90Uxr39dtizxyTpv/8e7rknx/su6d2MMZoneXqaGgcAL78Mw4ebKbRpLF4MDz9s6lN7eJhxdeBAMyHXzhSjrpS0vYFKliwJ4Ezc5maxsbH4pylgLddHoUKFnHEi/86mTZs0uIutKUbF7hSjYneK0Vxo27bUhG2bNiZhmz9/prt/8AG8/bb5ftAgk2DITW7WGC1XDpYuhZdegrFjoX9/WLPGzN4rVCiDB9SqZXbo1ctM1f3tN5P1zcWTmG4WN2uM5glJSWYGe2CguT9qlJnV3qGDy25xcaYG+CefmIXHKlUyv6utWrmhz9dAMepKSdsbyOFwUKpUKYKCgkjI5YXYw8LCaN++vbu7cVPx9vbWDFsRERERuXlVqWKStefPw/TpWSZshw83szfBzOTs3z+H+ijZ4ucH33wDzZrBs8/CtGnQuLGpfVu3bgYPKFLEJOlHjoSnn1bCVuTf2L8fHnrIjKEzZ5rfpwIF0iVs//7b5HG3bDH3H38cPv00y4sbxOaUtM0Bnp6euT45l5iYiN9l0+1FREREREQy5etrVsBJTISAgEx3+7//MzPDAIYOTf1e7OfRR03ZzLvvNtUPmjc3s2/79MlgZy+v1NXkwEz7e+cdc5ArLEQnIpjfmR9/NIv8nTtnsq8REVC9ustuSUnw2Wfw7rsQHw/Fi8O338Jtt7mp33LdaGUpyZZWuWUuveRZilGxO8Wo2J1iVOxOMZpLLF1qiiemrHft65tlwnbYsNQkbdrvc6O8EqONGsH69WZBsgsXzATAF14wyaIsff65qYHRtKlZul5yXF6J0ZvC6dNw//3Qt69J2LZqBZs3p0vYHjgAHTvCG2+Y38GePc1M29yasFWMulLSVkRERERERP69JUvMSlUffmimX17B0KGpZRDef9/MEpPcoWhRmDEj9ef35ZfQvj0cOZLFg+67D1q0gLNnTZx89llqcl9EUs2fD3XqwMSJZsb6sGGwaBFUrOjcxbJMrdq6dc2iYwEB8N//wp9/QokS7uu6XF9K2kq2LF++3N1dEMmSYlTsTjEqdqcYFbtTjNrc4sUmERcTA507m2XLszBkCAwYYL4fPjx1AbLcLK/FqKen+Tn+9ZdZG2nFCmjY0IRChkqVgrAwUx4hORlefRX69YOLF3Oy23laXovRXCkxEZ57zpwBCQkxv1jvvmuSt5ecPAn33msm4UZHm3MhmzebGra5vXy0YtSVkrYiIiIiIiJy7cLCoHt3iI0118z/+Sfky5fp7oMGwcCB5vsPPjDVFCT36tkT1q0zM/4iI82l2p9+mskkWl9fU2zz889N1veHH+CWW+Dw4Rzvt4gteXmZ34tnnoENG6BJE5fNs2ebSbiTJpld/+//zEUOlSu7qb9yQylpKyIiIiIiItdm4ULo0cMkbLt2halTr5iwHTzYfP/hh/DWWznSS7nBqlSBlSvNgmRJSfDaa6Yc57lzGezscJgiuHPnQpEisGkT7NuX010WsYfkZHOWY/To1LZmzeCrr1zqgcfEmAm43brBsWNQowasXm3W9kszCVduMkraSrbUr1/f3V0QyZJiVOxOMSp2pxgVu1OM2tDJk3D77WY1qu7dYcoU8PPLcFfLMrNrUxK2H38Mb76Zg33NAXk9Rv39zQTBL780SaSJE03uKTw8kwd06ABr18LPP0Pr1jna17wqr8eo7fzzjykn89pr5rZ3b4a7rVljSo989ZW5/9JLZjHAhg1zsK85RDHqSklbyZYSqmQtNqcYFbtTjIrdKUbF7hSjNlSsGHz9tUncTp58xYTtkCHm/ogR8PrrOdjPHKIYNZNon3vO1LUNDoYdO8zV3ZMmZfKASpVMcc4UW7eabH5iYo70N69RjNrI77+bOgcLF5ozHp9/7rLQGEBCgjnR1bIl7NwJpUvDvHkwcmSWFzTkaopRV7ZK2i5ZsoSePXsSHByMw+Fg6tSpLtsty2LAgAGUKlWKfPny0alTJ3bt2uWyz+nTp3nwwQcpWLAghQoV4rHHHuP8+fMu+/z999+0adMGPz8/ypYty0cffXSjX1quN2fOHHd3QSRLilGxO8Wo2J1iVOxOMWojSUmp3z/4oJlh6+ub4a6WBf37w9Ch5v4nn5gJZTcjxWiqli3NTMC2beH8ebjnnmzkYuPi4M47zTTs0FA4dSrH+ptXKEZtICrKLNR4//1w9iw0bQobN8KTT7qsIrZzp5mAPmiQGXJ79YItW6BTJ7f1PEcoRl3ZKmkbExNDvXr1GJ22lkcaH330EZ9//jlff/01q1evJiAggNDQUC6mWW3ywQcfZNu2bcybN4/p06ezZMkSnnzySef26OhounTpQvny5Vm/fj0ff/wxgwYNYuzYsTf89YmIiIiIiORqs2aZa3KPHElty2S5csuC994zC+WAKdv46qs50EexhZIlYf781CT9xx9Dly5w/HgmD/D1hY8+MnU8Fy40U3S3bMmx/orccHFxJq5//BE8PGDAAFi2DEJCnLtYFowZA/Xrm7IIgYHwyy/w669QuLD7ui7uYaukbbdu3Rg2bBh33nlnum2WZTFy5Ejee+89br/9durWrcsPP/zAkSNHnDNyd+zYwezZs/n2229p1qwZrVu35osvvmDChAkcufSh4ueffyY+Pp7vvvuOWrVq0atXL1588UU+/fTTLPsWFxdHdHS0y01ERERERCTPmDkT7rgD/v7b1DjIgmXBu+/C+++b+599Bq+8cuO7KPbi5WVC5fffTS42LMzk/FetyuQBd95pVjSrWNEsTtaihZnJLXIz8PWFfv1MWZBly0ztA29v5+ajR826js8+a0qFd+hgzlv07u2+Lot7OSzLstzdiYw4HA6mTJnCHXfcAcDevXupXLkyGzdudClM3LZtW+rXr8+oUaP47rvveO211zhz5oxze2JiIn5+fkycOJE777yThx9+mOjoaJfSC2FhYXTo0IHTp09TOJNTF4MGDWJwStX8NCZMmIC/vz8AnTt35tSpU2zYsMG5vUWLFnh5ebF06VJnW926dSldujSzZs1ytlWqVIlatWoxb94858zhoKAgmjVrxsqVKzl58iQA/v7+dOzYkS1btrB//37n43v06MH+/fvZtm2by3tz8eJFVq9e7Wxr3LgxgYGBLFiwwNlWvXp1qlatyowZM0hOTgagbNmy1K9fn0WLFnHu3Dksy6JIkSK0bt2adevWcfToUQC8vb3p2rUr4eHhLqUqunTpwokTJ9i4caOzrWXLlnh4eLBs2TKX9yI4OJjZs2c72ypXrkzNmjWZO3cucXFxgKlr0rRpU1asWMGpS5fJBAQE0KFDBzZv3szBgwedj+/Zsyd79uxh+/btzrb27dsTExPDmjVrnG1NmjShQIECLFy40NlWo0YNqlSpwvTp00n51ShXrhz16tVzvhcARYoUoVWrVqxdu5Zjx44B4OPjQ2hoKDt27GD37t3OY4aGhhIZGcmmTZucba1atQJg+fLlzrb69etTokQJl8sBqlSpQo0aNZgzZw7x8fEAlCxZkiZNmrB8+XJOnz4NQIECBWjXrp3Le+FwOLj11lvZvXs3O3bscB6zQ4cOnDt3jrVr1zrbmjZtSkBAAGFhYc62mjVrUrlyZaZNm+ZsS3kvFi5cSExMDABFixalZcuWrFmzhsjISAB8fX3p0qUL27dvZ8+ePc7Hd+3alSNHjvD3338721q3bk1ycjIrVqxwtjVo0IDixYszd+5cZ1vVqlWpXr06s2fPJiEhAYBSpUrRuHFjli1bxunTp3E4HM73YtOmTRw6dAgADw8PevTowa5duwhPsxJCx44diYqKYt26dc62Zs2a4efnx+LFi51ttWrVokKFCsyYMcPZVqFCBerUqcOCBQuIjY0FoFixYrRo0YLVq1dz/NIUAj8/Pzp37sy2bdvYm6awfLdu3Th8+LDLe9GmTRsSExNZuXKls61hw4YULVqUefPmOdtCQkKoVq0as2bNIvHSNWbBwcE0atSIpUuXcvbsWQACAwO55ZZb2LBhA4cPHwbA09OT7t27s3PnTiIiIpzH7NSpE2fOnGH9+vXOtubNm+Pr6+vyXtSuXZty5coxc+ZMZ1vFihWpXbs28+fP58KFCwAUL16c5s2bs2rVKk6cOAHgLGuzdetW9qVZIbh79+4cPHiQrVu3Otvatm1LXFwcq9J8om/UqBGFCxdm/vz5zrZq1aoREhLCzJkzSbp0qWbp0qVp2LAhS5YsISoqCoBChQrRpk0b1q9f7zyJ5+XlRbdu3YiIiGDnzp3OY96osTxtm7vGcoDChQtrLNdYnuFYXrhwYc6dO+fWsTzlM5zGco3lGY3lKb+f7hzL7fC5HNwzlgcuW0bj4cPxTEyEu+9m5YsvcvLSz+bysdyy4IcfqjNpUlUAHn98K7fdZuLlZh7LLcuiYMGCef5zeWZj+aFD+Rk+vAn//JMfb2+Lxx7bQrduB3A40o/l3tHRdPjmG3wu/b5G9O7Nzvvvp1adOhrLL7mWsfz48eM4HI48/7k8J8dy/wMHwLIo3KqVGcsXLCD25EmS/P1dxvJJkyxGj67HuXM++PrCK69E0rz5GjwuTbXMK5/L0/4e38yfy2NjY+nVqxdRUVEULFiQzOSapO2KFSto1aoVR44coVSpUs797rvvPhwOB7/99hvvv/8+33//vcuAB+YXc/DgwTzzzDN06dKFihUr8s033zi3b9++nVq1arF9+3Zq1KiRYX/i4uKcwQ2mzELZsmWv+AaLiIiIiIjkan/9ZYqSJiSYRaN+/tlldlhalgX/+Y+5yh1g1Ch48cUc7KvYWnQ0PPpo6sJkDz9sLgW/NA/KVWIivPGGWXWpQweYM8dM3RXJDSwLvvrKrLpYuTKsW5fhYo1RUfDSS/D99+Z+/frw009Qq1bOdldyVnR0NIGBgVfMKdqqPIKd+fr6UrBgQZdbXqJi0GJ3ilGxO8Wo2J1iVOxOMeomU6emJmzvv98UV8wiYfvWW6kJ2y++yFsJW8XolRUsCBMnmvq2Hh7www9m0bI0E19TeXmZuhq//GLqKyhh+68pRnPI0aPQvTs8/zxcvAilS5sV+S6zZAnUq2cSth4e8PbbsHp13k7YKkZd5ZqkbcmSJQGcl3mkiIyMdG4rWbKk89KHFImJiZw+fdpln4yOkfY5JL2UaeMidqUYFbtTjIrdKUbF7hSjbpCYaFYSS0gwS5f/9FOmiTPLgjffNMk4gC+/NPmKvEQxmj0Oh5l8OH8+FC8OmzdDo0amZHKGeveGokVT77/7LqS5FF2yTzGaA6ZMgTp1YPZsM7P288/NAo7Fijl3iYsz42W7dnDgwP+zd9/hUVVrG4d/k4QUAiTUQKihE3roTXoXRbGgqICoiKJy9ODRo3QUUD+P7Vg4NhTB3pDepffQQg29l0ASAoQkM98fi5lkSCG0zA557uuai8yePZM1w5udzDNrv8u0cF682PQA9/X13NCtQDXqLteEtmFhYZQsWdKtT0hcXByrVq2iWbNmgOltcvbsWbfeLwsWLMBut9OkSRPXPn///ber9w7A3LlzqVatWqb9bEVERERERPIcHx9zSvrLL5vVzrMIbIcOTV2b7L//hWefzcFxSq7Uti2sXw9Nm8LZs2YBppEj4XI754z98otJtjp3NmGYNbs9Sl508SI88QTcey+cPm36HKxdC889h6sxLWZhscaNzQdcDgcMGGA+uGjZ0nNDF+uyVGh77tw5IiMjXc2E9+7dS2RkJAcOHMBmszFkyBDGjh3Ln3/+yebNm3nssccIDQ119b2tUaMGXbp04cknn2T16tUsW7aMwYMH07t3b0JDQwF4+OGH8fX1ZcCAAWzdupUffviB999/nxdffNFDzzp30CxksTrVqFidalSsTjUqVqcazUGXF0oCzGm9EyZkGdi+9BL83/+Z6x9/bFY+z4tUo9euTBlYtCi1ZkaNgjvvhMtrAaXXvbtphJuSYhqBDhhgpi1KtqhGb6F8+SA62kwlf/llWLnSrc+B3W6Okw0bwqZNZpb577/D559DwYKeG7bVqEbdWWohskWLFtG2bdt02/v27cvXX3+Nw+FgxIgRTJw4kbNnz9KyZUs+/vhjqlat6to3JiaGwYMHM23aNLy8vOjVqxcffPABBQoUcO2zadMmnn32WdasWUOxYsV47rnn+Ne//nVNY81u02AREREREZFc44cfTCj29dfmtPQsOBzw4otmnSgwC0o9/fQtH6Hcpr75BgYONBMWw8LMpNr69TPY0eEwRffPf5okrGlT+PVXSLNguUiOSEoyHyA4Fxg7eNAEt23auO22fz/062c+oADzwcTnn0NISE4OVqwku5mipULb3CSvhbbLli2jRYsWnh6GSKZUo2J1qlGxOtWoWJ1qNAdMnQqPPGKCsAEDTKqQCYcD/vEPeP99c/2zz+Cpp3JonBalGr1xkZHQq5dZmMzfHz79FPr2zWTnuXPN4nhnzkBoqOkl2rhxTg4311GN3kS7dsGjj5qGzP/9b4a7OBymFfjgwRAXB4GB5vOGAQPMhFxJL6/UaHYzxetuj5CSksL333/PwIEDueeee9i8eTMAsbGx/Prrr+kW+5LcLSbT81NErEE1KlanGhWrU42K1alGb7EpU1ID2/79TQqbCYcDhgxRYHsl1eiNc7YB7d7dzLjt1w8GDcqkA0LHjrB6NdSoAUePgjKIq1KN3gQOh/lAq359WLXKHDtPnEi32+nT8MAD5sSFuDho1sx8KPHEEwpss6IadXddoe3Zs2dp0aIFDz/8MFOnTuXPP//k5MmTABQoUIDnn3+e952/wUVERERERMS6Jk82M8bsdpMofP45eHtnuKvDYVqJfvCBuT5xogJbubkKF4Y//zT9bW02M9v2jjvMmefpVK5seof++CP06JHjY5U85uRJ6NkTnnwSEhLManqbNkGJEm67zZoFtWvDzz+bduBjx8Lff5tyFbkW1xXavvLKK2zdupXZs2ezZ88e0nZY8Pb25r777mPGjBk3bZDieQXVGVssTjUqVqcaFatTjYrVqUZvkUmTzFQwu90EEZ995rbSeVoOBzz/PHz4oQnTPv/c3EUM1ejN4+UFw4fD9OkmxF29GiIiYMGCDHYuVAjuuy/1+r59ph+zZuyloxq9ATNmmCT2zz/NomNvvw3z5kHZsq5dzp+HZ5+Frl3N5O/q1c1nCq+9lulajnIF1ai76wptf//9d5577jk6duyILYN53VWrVmXfvn03OjaxkDZXNNIWsRrVqFidalSsTjUqVqcavUUiI00aO3CgmdKYRWD73HPw0Uepge2AATk7VKtTjd58XbvCunXmTPRTp0xHhLfeMvWYIYcD+vSB7783/W23bs3R8VqdavQ6xcWZsxGOH4eaNWHNGrMQXprj5Zo1pk4//thcf+45U7sNGnhozLmUatTddYW2sbGxhIWFZXp7UlISycnJ1z0osZ6NGzd6eggiWVKNitWpRsXqVKNidarRW+Tdd82p5R9/nGlga7eb2WP//a8JbL/4Ah5/PIfHmQuoRm+NsDBYtsz0t7Xb4V//MouVxcVlsLPNZmq5fHmIjoamTc3MSAFUo9etUCFzFsKQIabpct26rpuSk2H0aNOzdudOsybe7NmmhUz+/J4bcm6lGnV3XaFtpUqVWL9+faa3z5kzh/Dw8OselFjPgQMHPD0EkSypRsXqVKNidapRsTrV6E00a1bqyk42G9x//1UD208+Mbt++aVZp0zSU43eOgEBpvY+/RR8feG336BRo0wm0tata6Y9tmkD587B3XebpqKZTs/NO1Sj2ZSSAuPGwbRpqdvuuw/+8x/w93dt2rULWraEESPMXR54ADZvhk6dPDDm24Rq1N11hbZPPPEEX375JT/88IOrn63NZiMxMZHXXnuNWbNmMXDgwJs6UBEREREREblBEyeac87vvx+SkrLc1W6HZ54xQZnNBl99ZWY7iniCzWa6eCxZAmXKmFmNTZrADz9ksHPx4jBnDgwebK4PGwYPPmgWjxLJyr59JvD/97/NKQVnzqTbxeEwE2/r1YNVqyAoCL77znTlKFIkpwcst7PraoX8wgsvsHXrVh566CGCg4MBePjhhzl9+jTJyckMHDiQAWpwdFvJqHexiJWoRsXqVKNidapRsTrV6E3w6acwaJD5umLFLFfGsdvNrhMnmrDs66/NemWSOdVozmjcGNavh969zcJkvXub4GzCBLM+lEu+fGbVvLp1zacPe/ZkOqM8r1CNZsHhgMmTzakF8fFQoAC88w5czrycjh0z/bxnzDDX27Uzx8c065HJDVCNurM5HNd/jsDSpUv5+eef2bVrF3a7nUqVKvHAAw9wxx133MwxWlJcXBxBQUHExsZSqFAhTw9HREREREQkcx9/bMIIgH/8A/7v/0wamwG73cxo/Pxzs8ukSWYNHhErSU42E2jHjzfXW7Uy7ZlLlsxg5+XLTaqmZE0yEhNjPqX68UdzvUUL+OYb8+FWGr/+Ck89BadPg5+fqb3nn8/znwXIdchupnhDoW1eltdC2927d1O5cmVPD0MkU6pRsTrVqFidalSsTjV6Az76yCxlDvDSS/D229kKbL28TGD7yCM5ONZcTDXqGb/9Bn37msmRpUrBTz+ZzC1LY8dC4cJmBm4emtmnGs1ATAzUqQOHD5uzD0aONKvdpTkTIS4OXnjBzKgF0xZh8mSoWdMTA7695ZUazW6mqM8DJFu2bdvm6SGIZEk1KlanGhWrU42K1alGr9PHH6cGti+/fNXA9qmnUgPbb79VYHstVKOecc89sHYthIfD0aOmHemHH2ax7tiqVWaK7uDBpuAvXcrJ4XqUajQDRYpAly5QtaqZkf3aa26B7d9/m0z366/NofOVV0wJKbC9NVSj7q6rp21YWNhV+0zYbDaio6Ova1AiIiIiIiJyE9SpA4GBJrh9880sA9snnjCLjTkD24cfzuGxilynqlVNkPbEE2Zhsuefh5UrTU/mwMArdm7cGN56y8ym/Pxz2LYNfvkFQkI8MnbxgE2boFgxCA011997zxwb0xRLYiIMH24+53I4oEIFc1xs2dIjI5Y86rpC29atW6cLbVNSUti/fz/Lli2jVq1a1K9f/6YMUERERERERK5Ty5awebNJHDIJbFNSTNj19dcmsJ08GR56KEdHKXLDChSAqVOhaVP45z9hyhSTzf36K1SpkmZHmw2GDoVatUyhL1sGDRuaPgsNG3ps/JID7HYT0L76qpmSPXOmOegVKOC22+bN5iyDTZvM9ccfh//8B/JAZ0yxmJve03bjxo107tyZyZMn06FDh5v50JaS13raJiQkEJjuI0oR61CNitWpRsXqVKNidarRa/Df/5qwtm7dq+6akmJWQp80Cby94bvv4MEHc2CMtyHVqHUsWQL33w/Hj5ug7dtv4a67Mthx505zw44d4O8PX355W39ikadr9NAh0/x4wQJzvUcPk+ynCWzTZrqXLpnJuP/7H/Ts6ZER50l5pUY91tO2bt26DBw4kH/96183+6HFg+Lj4z09BJEsqUbF6lSjYnWqUbE61Wg2vf226dXZvj0cO5blrikpZgaZM7CdMkWB7Y1QjVpHq1awfr1ZkCwuDu6+G15/3dS8G2dfhe7d4eLF276/bZ6t0R9/hNq1TWCbPz989hn88YdbYHvgAHToYNZqvHTJlMSWLQpsc1qerdFM3JKFyEJCQoiKiroVDy0esmbNGk8PQSRLqlGxOtWoWJ1qVKxONZoN48ebxcbA9LAtWTLTXVNSoH9/+OYbE9hOnQoPPJBD47xNqUatJTQUFi40/W0B3ngDunaFU6eu2DEoyAR4f/1lZmLexvJcjcbHw2OPmU+jzp6FRo1gwwazAN3ldjEOh2kJU7u2qRdnpjttmtoce0Keq9GruOmh7enTp/niiy8oU6bMzX5oERERERERycibb5pzegFGj4YRIzLdNSUF+vUzp4w7A9v778+ZYYrkpHz54P33zSzy/Plh7lxo0ADWrr1iR29vM7XS6cQJ6NQJtm/P0fHKTeblZWZSe3nBsGGmf3HVqq6bY2JMnvvoo2ZGdtOmsHGjW6Yr4lHXtRBZu3btMtx+9uxZtm/fzqVLl/j2229vaGAiIiIiIiKSDWPHmkDC+fVrr2W6a0qKmUz43Xfg4wPffw+9euXQOEU85KGHzLpj994Lu3ebtgn//a9ZgC9DQ4aYhLdJE5P4pg10xdouXTIHNy8vCAw0n0pdvAjNm7vtNnu2Odvg6FGz+4gR8Mor5msRq7iumbZ2ux2Hw+F2AQgLC2Pw4MFs2bKFh27j5t15UePGjT09BJEsqUbF6lSjYnWqUbE61WgmJk1KDWzffDPLwDY52Zwp7Axsf/hBge3NpBq1ttq1zQzbu+82ud6TT5rQ9uLFDHZ+7z3TGDcuzixYNX68OY8+l7vta3TbNjNd9r33UrdFRLgFtufPm+4xXbqYwLZaNVixwvQ8VmDrebd9jV4jm8NxGxx5PCC7K73dLs6dO0eBNE26RaxGNSpWpxoVq1ONitWpRjNx7hx062ZmAmaxGLQzsJ061QQTP/4I99yTg+PMA1SjuYPdDhMmmJDObjftEn75BcqXv2LHS5dMQ9zPPjPXH3wQvvzS9FnIpW7bGnU44OOP4Z//NCl8aKiZUh0Q4Lbb2rXwyCOwY4e5/txzJo/Pxf+lt53btkavkN1M8ZYsRHYrxcfHM2TIEMqXL09AQADNmzd3a1Tcr18/bDab26VLly5ujxETE0OfPn0oVKgQwcHBDBgwgHPnzuX0U8lVFi5c6OkhiGRJNSpWpxoVq1ONitWpRjNRoADMn3/VwPbRRxXY3mqq0dzBy8u0f541C4oWhXXrzGTMOXOu2NHXFz79FD75JHVqesuWcOiQR8Z9M9yWNXrsmPnQavBgE9h26gRr1rgFtsnJMGYMNGtmAtvQUNMe4YMPFNhazW1ZozcgW5O/v/nmm+t68Mcee+y67peVJ554gi1btvDtt98SGhrK5MmT6dChA1FRUZQuXRqALl268NVXX7nu4+fn5/YYffr04ejRo8ydO5ekpCT69+/PU089xZQpU276eEVERERERG4ah8O0Q/DzS22LkC9fprsnJ5uZZT/8YHb76SdzerhIXtexowls77vPzMDs0sUEe6++aoJdl6efhvBws+O5c6ZPqljD77+bPhenTplj4ttvw7PPuv0H7tplPrRatcpcv/9+k8UXKeKZIYtci2yFtv369bvmB7bZbDc9tL1w4QK//PILf/zxB3fccQcAI0eOZNq0aXzyySeMHTsWMCFtyZIlM3yMbdu2MWvWLNasWUPDhg0B+PDDD+nWrRvvvPMOoaGhN3XMIiIiIiIiN4XDYXrWjhtnrnfuDFn0/0tOhj59zMzafPng55/hrrtyaKwiuUD58rBkiemC8L//mZYJq1bBN99AcHCaHe+4w8zevHgRChc22xwOsNk8MWwBOHgQHngAkpKgXj2YPBlq1nTd7HDAxInw4oumj21QkFl87uGH9d8muUe2Qtu9e/fe6nFkS3JyMikpKfj7+7ttDwgIYOnSpa7rixYtokSJEhQuXJh27doxduxYihYtCsCKFSsIDg52BbYAHTp0wMvLi1WrVnFPJucJJSYmkpiY6LoeFxd3M5+a5YWHh3t6CCJZUo2K1alGxepUo2J1eb5GHQ4zBXDCBHP9vfeyDGyTkkxg+9NPJrD95ReznpLcOnm+RnMpf38T7jVpYiZpTpsGjRrBr7+axctcrmx6+9//wpYt5hx7X98cHfP1uq1qtGxZeOMNM8t29Ggz0/ayY8dgwACYMcNcb9sWvv4aypXzzFAl+26rGr0JshXalk/XkdszChYsSLNmzRgzZgw1atQgJCSEqVOnsmLFCipXrgyY1gj33nsvYWFhREdH8+9//5uuXbuyYsUKvL29OXbsGCVKlHB7XB8fH4oUKcKxY8cy/d7jxo1j1KhR6bbPnDmT/JeboHTs2JHTp0+zfv161+3NmjXDx8eHJUuWuLbVqVOH0qVLM3PmTNe2ihUrUrNmTebOncvFy8tXlihRgiZNmrBixQpOnToFQP78+Wnfvj2bN29m3759rvt3796dffv2sXXrVte21q1bc/HiRVY5zwMAGjZsSFBQEPPnz3dtq169OlWqVGH69OnY7XYAypYtS7169Vi0aBHx8fEAHD16lJYtW7J27VqOHj0KQL58+ejSpQvbt29n165drsfs1KkTJ0+eZMOGDa5tzZs3x8vLyy1gr1OnDqGhocyaNcu1rVKlSoSHhzNnzhxXUB4SEkLjxo1Zvnw5p0+fBiAwMJB27dqxceNGDhw44Lp/jx49iI6OJioqyrWtbdu2JCQksHr1ate2Ro0aUbBgQRYsWODaVqNGDSpXrsxff/2Fc42+cuXKUbduXbfXokiRIrRo0YI1a9a46sbX15fOnTuzbds2du/e7XrMzp07c/z4cSIjI13bWrRoAcCyZctc2+rVq0dISAizZ892batcuTI1atRg9uzZXLp0CYCSJUvSqFEjli1bRkxMDGB+Ntq0aeP2WthsNu688052797Ntm3bXI/Zrl074uPj3XpBN27cmMDAQLf+MeHh4VSqVIlp06a5tjlfiwULFpCQkABA0aJFad68OatXr+b48eOAme3eqVMnoqKiiI6Odt2/S5cuHDlyhE2bNrm2tWzZErvdzvLly13b6tevT/HixZmTprFUlSpVqF69OrNmzSIpKQmAUqVK0bBhQ5YuXcqZM2eIiopyvRaRkZEcPHgQAC8vL7p3786uXbvYvn276zHbt29PbGwsa9eudW1r0qQJ/v7+LF682LWtZs2aVKhQgenTp7u2VahQgdq1azN//nzOnz8PQLFixWjWrBmrVq3ixIkTAPj7+9OxY0e2bt3Knj17XPfv2rUrhw8fdnstWrVqRXJyMitWrHBti4iIoGjRosydO9e1rWrVqlSrVo2ZM2eSnJwMQGhoKA0aNGDJkiWcPXsWgKCgIO644w7Wr1/P4cOHAfD29qZbt27s3LmTHc4O/JgPr86cOcO6detc25o2bYqfn5/ba1GrVi3KlSvHDOdfQEBYWBi1atVi3rx5XLhwAYDixYvTtGlTVq5cycmTJwHzAVuHDh3YsmWL24eB3bp148CBA2zZssW1rXXr1iQmJrJy5UrXtgYNGlC4cGHmzZvn2latWjWqVq3KjBkzSElJAaB06dJERETw999/ExsbC0BwcDCtWrVi3bp1HDlyBDDH/q5du7Jjxw527tzpesxbdSw/ceKE67jkyWN54cKFdSzXsdzSx/K0r4WO5TqWX3ksr1SpkkeP5R77u7xuXQ489BDlfvgBgOgXXqDSCy9keizftm0377wTwfLloeTL5+Czz04DK3AeCnQsj3Rtu9nH8oMHD+pYnkuP5SVKbGLcuCDGj2/I7t35adLEwaBBG2jTxhx70x7L/U+dot0//oF3cjJERTF/0CDOX148yerH8qioKI8fy6/n73JbSgqVf/qJkAEDsEVEmGN59eoA1Dl2zHUsX7myJB99VIe4OD/8/KBfvx107bqTjRvh6FFrZSz6uzz9sTwmJsb1fW7nv8udx6qrsTmcr1ouER0dzeOPP87ff/+Nt7c3ERERVK1alXXr1rm9aE579uyhUqVKzJs3j/bt2/Pmm28yadIkt4MimD/ERo0axaBBgzL8vhnNtC1btuxVV3q7XUybNo0e+mheLEw1KlanGhWrU42K1eXZGnU4zIro775rrn/0kZkOmImkJHjoITOz1tfX/HvnnTk01jwuz9bobeb0aTNL3ZnzPPccvPNOBpNp//rLnGsfH29mff7xB9Svn+PjvRa5tkZ37zbNuVetgho1IDIy3X9IXBwMGQLO5Y3q1jUdE2rVyvHRyg3ItTV6jeLi4ggKCrpqppitmbYZOXbsGF988QXr168nNjbW9emBk81mc/uk4WapVKkSixcvJiEhgbi4OEqVKsWDDz5IxYoVM9y/YsWKFCtWjN27d9O+fXtKlizp+qTNKTk5mZiYmEz74IL5hPLKBc1ERERERERuqeXLUwPbjz+GTCaZgAlse/c2p3X7+sJvv0G3bjk0TpHbRNGiMH06jBplFib78EOzYNlPP4HbEjh33mlCxLvvNqtdtWhhEsMHH/TY2G87Dgd88YVJYxMSTGPa119PF9guWQKPPQb79pl+tS+/bP7/FOFIbud19V3S27RpE+Hh4YwdO5bo6GgWLlzIyZMn2bVrF4sWLeLgwYPc6gm8gYGBlCpVijNnzjB79mzuzmQJ1EOHDnH69GlKlSoFmNOizp4963aqwYIFC7Db7TRp0uSWjllEREREROSatGhhUqNPP80ysL10yWRFCmxFbpy3t2mT+uefJidcvhwiIiBNdwKjRg1YvRq6dIELF8ynJsOGeWTMt52TJ+Gee+DJJ01g27o1bNpkZjdfdumSafXdurUJbCtUMP9H48crsJXbw3WFtq+88goFChRgx44dzJs3D4fDwfvvv8/Bgwf54YcfOHPmDOPHj7/ZYwVg9uzZzJo1i7179zJ37lzatm1L9erV6d+/P+fOnWPo0KGsXLmSffv2MX/+fO6++24qV65M586dAdNPo0uXLjz55JOsXr2aZcuWMXjwYHr37k2o28dmklY5dewWi1ONitWpRsXqVKNidXmqRh0Oc8q10+DBMHBgprtfumQWUf/tNxNU/P67AltPyFM1mkf06AFr10KdOnD8OLRvD//5j/kRdQkONq0Shg5NvW5RuaZG9+wxq8D98YdZSfGtt2D+fLeVxLZsMWsxjh9v/j/694eNG6FVKw+OW25YrqnRHHJdPW2DgoJ4+eWXee2114iJiaFYsWLMmTOHDh06APDCCy8QGRnp1iT7Zvnxxx959dVXOXToEEWKFKFXr1688cYbBAUFceHCBXr27MmGDRs4e/YsoaGhdOrUiTFjxhASEuJ6jJiYGAYPHsy0adPw8vKiV69efPDBBxS43Dg8O7Lbf0JERERERCTbHA4T0q5YAfPmQZEiWe7uDGz/+CM1sO3SJWeGKpJXnD8PTz0F331nrj/wgDlrP12EsHSpmR1vs5nrDkfq15J9djt07AjHjpkXvV49t5vef9/MsE1MhGLFYOJEMylXJLfIbqZ4XTNt7Xa7KwQNDg7G29vbtcIaQO3atd3aD9xMDzzwANHR0SQmJnL06FE++ugjgoKCALOa7ezZszlx4gSXLl1i3759TJw40S2wBbMq3ZQpU4iPjyc2NpYvv/zymgLbvCjt6n8iVqQaFatTjYrVqUbF6vJEjdrtZpGxjz82C+1cZRLMpUtw//2pge0ffyiw9aQ8UaN5VP788O23Zh1AHx/48Uczy/OK9c2hZcvUkDYuzlyfNSvHx5sZS9doZKRpgwDg5QXff2+mOacJbA8cgA4d4MUXTWDbvTts3qzA9nZi6Rr1gOsKbcPCwti7d695AC8vwsLCmDdvnuv25cuXE2zhUwLk2iU4D54iFqUaFatTjYrVqUbF6m77GrXb4Zln4JNPTOjz1VdZJhGJiXDffabnpr+/+fdyRzjxkNu+RvM4m818prJ4sVmQbNs2aNTI9JHO0FtvmWa43bvDO+9c0VPBMyxZoykppsdBo0bwz3+mbi9eHAICAPPSffedaVOxcKEJ0T/9FKZNgyzWk5dcyJI16kHZDm3PnDnj+rpTp0789NNPruuDBg3i888/p0OHDrRv355JkybxcJrm0CIiIiIiIpIJux2efho++8zMMJs0Cfr2zXT3xETo1csEFs7AtlOnHByvSB7WvDmsW2cWv4qPNz+L//oXJCdfseOwYTBggPn5HjoUHn3ULFYmqfbtg7ZtTa+D5GSz+NgVL2RMjFnf7ZFHIDYWmjQxk3IHDlTnCbn9ZTu0LVmyJPfccw8///wzL730ElOnTiUpKQmAIUOGMHr0aE6fPk1sbCzDhg1j7Nixt2zQkvOKFi3q6SGIZEk1KlanGhWrU42K1d22NWq3m2aZ//ufCWy/+caEO5lwBrbTp5vAdto00/pRPO+2rVFJp2RJ03L6pZfM9bfeMh+cnDiRZic/P/Nz/dFH4O1tpoq2agWHDnlkzGChGnU4YPJkqFsXliwxzYG/+gp++sn0n7hszhyzHtmPP5qXcPRo0za4ShUPjl1uKcvUqEVkeyGyPn368Oeff3L+/HkKFizIvffeS58+fWjXrh22PPjxhhYiExERERGRG3b0qDkt+OhRE2I89FCmu168aALbGTPMWcPTppnV7EXEc376Cfr3N+1Yy5SBn382s0HdLFpk+pmcPg0hIeZTlwYNPDFczztzBgYNgh9+MNebNzcNgytWdO1y/ryZvfzRR+Z6tWpml0aNPDBekVvgpi9E9t1333HixAkmT55Mq1at+O677+jUqROlS5fmpZdeYv369Tdl4GJNq1ev9vQQRLKkGhWrU42K1alGxepu2xotVco0afzpp6sGtvfemxrY/vWXAluruW1rVLJ0//2wZo0JFg8dMpNpP/30iha2bdqYRbXq1DFTRkNDPTJWS9TohQtmmrK3N4wZY5oEpwls160zebYzsB08GNavV2CbV1iiRi3kmhYiCwgI4KGHHmLatGkcO3aMjz/+mCpVqvDee+/RqFEjqlevztixY9mzZ8+tGq94yPHjxz09BJEsqUbF6lSjYnWqUbG626pGU1JMCuFUpYpJZDNx8aJZk2zmTBPYTp8O7drlwDjlmtxWNSrXpEYNWL3azIRPSjITSfv3v6KFbYUKZmGyefPMhzVOdnuOjdNjNZq2T21oqGkVsXw5vP66qx1CcjKMHQtNm8L27eYlmjULPvzQLDwmeYOOo+6uKbRNq3DhwgwcOJDFixdz4MABxo8fT/78+Rk+fDhVqlShefPmN3OcIiIiIiIiuV9yMjz2GDRrZlLYq7h4EXr2NOFF/vxmpm3btrd+mCJybQoVMhPm33ordT3B5s3BbU5bYKBJeJ2mTjVNqU+dyvHx5pjNmyEiAn7/PXVb587QuLHr6u7dcMcdZu225GQze3nzZrObSF523aFtWqVLl2bo0KFMmjSJu+++G4fDwapVq27GQ4tF+Pn5eXoIIllSjYrVqUbF6lSjYnW3RY06A9spU8zsuqusJH/hAtx9N8yenRrYtmmTM0OVa3db1KjcEJsNhg41k2mLF4fISGjY0PzspnP+PAwZAgsWmHP/N2265ePL0Rq12+E//zEvwObN8Npr6WYVOxxmrbZ69WDFChN8f/utaXer9ajyJh1H3WV7IbLMHDhwgClTpjB16lS2bNmCw+GgefPm9OnTh0GDBt2scVqOFiITEREREZFsS06GRx4xaYSPj1kO/Z57Mt3dGdjOnZsa2LZunYPjFZEbcuiQWXts1SoT5g4fbi5eaafObd1qftCjo80P+jffmB4Lud2hQ9CvH8yfb67feSd8/rlZhO2y48fhiSdMf24wH0hNmgTlyuX4aEVy3E1fiCytU6dO8fHHH9OyZUvCwsL497//TVJSEqNHj2bPnj0sXbr0tg5s86KoqChPD0EkS6pRsTrVqFidalSsLlfXaFISPPywCWzz5TPLy2cR2J4/D3fdZQLbwEDTRUGBrfXl6hqVm65MGbPG1jPPmBmlo0ZBjx4QE5Nmp5o1TTPcjh3ND/5995lk9xb1uc2RGv3xR6hd2wS2AQFmVbY//3QLbH//HWrVMoGtry/83/+Z3RXYio6j7rId2iYkJDB58mS6detG6dKlGTx4MHv37mXIkCGsXbuWqKgoXnvtNSpUqHALhyueEh0d7ekhiGRJNSpWpxoVq1ONitXl2hp1BrY//WQC219+MTPrMuEMbOfNSw1s77gjB8cr1y3X1qjcMn5+8N//mhmk/v5mxnzDhrBhQ5qdihQxN7z4ork+ZoxZmDAl5aaP55bX6Pr18OCDcPZs6hMdONBMNQbi42HAAPOZ1alTUKcOrF1rnrrXTWneKbmdjqPufLK7Y4kSJbh48SIFChTg4Ycfpk+fPrRr1w4v/WSJiIiIiIhkzMvLJDe+viawvfPOTHc9f97MxFuwAAoUMIFty5Y5OFYRuSUee8wElL16mYXJmjc3E1D79r28g4+PmW5aty489RRUrw7e3h4d83WJiIBBg6BYMbOqWL58rpuWLjWvw969qb1/R482h0cRyVi2Q9sOHTrQp08f7rrrLvz9/W/lmERERERERG4P3t5mmt0//gENGmS6W0KCCWwXLjSB7axZ0KJFDo5TRG6pevXMrNJHH4Xp003L11WrzFpdruDyscfMcaJ69dQ7pqRYN8C9dAnefBOefBJKlzbb/vtf18xa5y4jRsCECaZNRPnypnWvziAQubobXogsr8prC5ElJSWRL82nZCJWoxoVq1ONitWpRsXqclWNXrpkptE9+2y2wpaEBDMBd9EiKFjQBLbNm9/6YcrNlatqVDzGboexY2HkSBNiNmli2lyXKZPBzomJ0L69maI7ZIhbGHo9bmqNbt8OffqYlgjt25sm3FeMb+tWs/5iZKS53q8fvP8+5IEIRa5TXjmO3tKFyCTvOXLkiKeHIJIl1ahYnWpUrE41KlaXa2o0MdEsJvTCC+Y04au4MrCdPVuBbW6Va2pUPMrLy6w1Nn06FC5sZttGRJi2KOlMnQrLlpmmr/36wcWLN/S9b0qNOhzw8cdm0OvXm568Tz/tFtja7WYGcYMGJrAtWtR0h/nqKwW2kjUdR90ptJVs2bRpk6eHIJIl1ahYnWpUrE41KlaXK2o0MdHMiJs2zaw6dP/9We5+7hx06+Ye2DZrljNDlZsvV9SoWEbXrrBuHdSvDydPQseO8NZbJhN16dvXTE319jY9BVq3hsOHr/t73nCNHjsG3bubswguXDCD3rzZfFB12cGDZvOLL5pDYrdusGWLWVtN5Gp0HHWn0Fay9Ouvphd6r17dqFvXXBcRERERkStcvGiWRJ8+HQIC4K+/THKRCWdg+/ffZubZnDkKbEXymrAwM5G2Xz8zO/Vf/zL5Z1zc5R1sNnj+efOJTpEisHo1NGoEK1fm/GA3bIDatc0KiX5+JkyeNQtCQ127TJlidlmwAPLnN11i/voLSpbM+eGK3A4U2kqmfv3VTBTYvBmSkrzZvNlcV3ArIiIiIpLGxYvQs6cJM5yBbfv2me7uDGyXLEkNbJs2zbnhioh1BATAl1+agNPX17zfbtQIoqLS7NS+PaxZAzVrwtGjZsZtTr8xr1YNihUzs7rWrTNhspeJlGJi4KGHTIvb2FjTpzcyEgYOvOE2vCJ5mhYiu055YSGyunVNYHtlheTLZ/psVaoEFSuai/ProkV1UBbPOHPmDIULF/b0MEQypRoVq1ONitVZtkYdDhPY/vmnmVo2fTq0aZPp7vHxJrBduhSCgkxg27hxjo1WbiHL1qjkGqtXm4lShw5BYKAJcx94IM0O8fGmZcKiRSbErVTpmh7/mmt082YTFF8OZ9m3D0qVMjNtL5s7F/r3N10bvL1hxAh49VXw8bmmoYkAeec4mt1MUT9GkqmdO9MHtgBJSbB4sblcqVAh9xA37b9ly5rAV+RWsNvtnh6CSJZUo2J1qlGxOsvWqM1mppMtXWpmvrVunemu8fGmj+WyZSawnTvXzKiT24Nla1RyjcaNzdpevXubFgMPPmgWKhs//vJ76YIF4eefITraPbBNSsrWm+1s12hyMrzxBowZY775P/9ptleo4NrlwgV45RX44ANzvWpVmDxZxzS5MTqOulN7BMlU1arpZ83abFClCnz3HYwebXrvtGoFpUub2+PizGkQv/wCb79tFpHs1Mn8PgkIMP927Gi2v/WW2W/DhjQ9e0Su0/Llyz09BJEsqUbF6lSjYnWWrtFu3WDv3iwD27g46NJFge3tzNI1KrlG8eKmhe0rr5jr774LHTqYNcAAM+u1SpXUO8yebWbDbtly1cfOVo3u3g0tW8LIkZCSYh73itlc69ZBRERqYPvss+Z9vY5pcqN0HHWX60Lb+Ph4hgwZQvny5QkICKB58+asWbPGdbvD4WD48OGUKlWKgIAAOnTowK5du9weIyYmhj59+lCoUCGCg4MZMGAA586dy+mnYnkjRphjszO4tdnM9QkT4OGHYdgw+Oors3jCoUPmk7aoKNPC6/334YUX4M47ITzcLJ6bkgJ79sC8efDZZ6lN1iMizB+uxYqZTxYfeghee82cCrJokVl9Uh+2iIiIiIhlJCTAI4+YcMMpi9MbnYHt8uUQHGz+Hla4ISKZ8fGBcePM5P2CBc177ogI86GPG4cD/v1v2LXLNMb+7bfr/6YOB3zxBdSrZ6b3BgWZ2Vpff+0KBZwTcJs2he3bzQJjM2fCRx+Z7jAicnPluvYITzzxBFu2bOHbb78lNDSUyZMn06FDB6KioihdujRvvfUWH3zwAZMmTSIsLIxhw4bRuXNnoqKi8Pf3B6BPnz4cPXqUuXPnkpSURP/+/XnqqaeYMmWKh5+dtdx7r5kJO3o0REWlEB7uzYgRZlHcjPj7Q40a5nIlu918MhgdbYLbK/89cQJOnzaXNBm8i6+vWVkzo9YLFSvqF4SIiIiI5JCEBDMzYdEicx7z5s2mkWMmnIHtihVQuLCZYdugQc4NV0Ryr3vuMZNo77nHTJBq08bMvB08+HKOarOZxtgPPGD6Kdx7L4waBa+/ntqHNjtOnoSnnoLffzfXW7eGb76BcuVcu0RHw6OPmmMZmN67n31m1rURkVsjVy1EduHCBQoWLMgff/xB9+7dXdsbNGhA165dGTNmDKGhobz00kv883LPldjYWEJCQvj666/p3bs327ZtIzw8nDVr1tCwYUMAZs2aRbdu3Th06BChoaEZfu/ExEQSExNd1+Pi4ihbtuxtvRBZWocOHaJMmTK37PHj480ZZRmFuvv2mU/0slKyZOa9dENCtDhaXnCra1TkRqlGxepUo2J1lqjRc+ege3cz7a1gQZg1y6zQm4nYWBPYrlxpAtt588xsObk9WaJG5bZ07hw88QT88IO53qePCUwDAy/vkJRk+s46+xXcey9MmgQFCrg9TqY1unGjOe3V4TBTaV980fVhlMMBn38O//iH+cyqUCEzs/aRR/Q+W26+vHIcvS0XIktOTiYlJcU1Y9YpICCApUuXsnfvXo4dO0aHDh1ctwUFBdGkSRNWrFhB7969WbFiBcHBwa7AFqBDhw54eXmxatUq7slkGum4ceMYNWpUuu0zZ84k/+Vpnh07duT06dOsX7/edXuzZs3w8fFhyZIlrm116tShdOnSzJw507WtYsWK1KxZk7lz53Lx4kUASpQo4Rr7qVOnAMifPz/t27dn8+bN7Nu3z3X/7t27s2/fPrZu3era1rp1ay5evMiqVatc2xo2bEhQUBDz5893batevTpVqlRh+vTprqbPZcuWpV69eixatIj4+HgA9u3bR8uWLVm7di1Hjx4FIF++fHTp0oXt27e7taHo1KkTJ0+eZMOGDa5tzZs3x8vLi6VLl7q9FqGhoSxaNAswp4F07VqJ8PBw5syZQ2JiIikpAGUpVKgec+bsZvduB8eP5+fEiYKcPFmIM2fMLN5jx8wpZ1fy80umUiUbZcsm4e9/mJCQ85QqdZ4OHSoSHp6fZcsWuPatUaMGlStX5q+//sL5eUa5cuWoW7eu22tRpEgRWrRowZo1azh2ubmQr68vnTt3Ztu2bexOc6pc586dOX78OJGRka5tLVq0AGBZmvNb6tWrR0hICLNnz3Ztq1y5MjVq1GD27NlcunQJgJIlS9KoUSOWLVtGTEwMAAULFqRNmzZs3LiRAwcOAGCz2bjzzjvZvXs327Ztcz1mu3btiI+Pd2sr0rhxYwIDA1m4cKFrW3h4OJUqVWLatGmubc7XYsGCBSQkJABQtGhRmjdvzurVqzl+/Pjl19yPTp06ERUVRXR0tOv+Xbp04ciRI2zatMm1rWXLltjtdrfeNfXr16d48eLMmTPHta1KlSpUr16dWbNmkZSUBECpUqVo2LAhS5cu5cyZM2zYsMH1WkRGRnLw4EEAvLy86N69O7t27WL79u2ux2zfvj2xsbGsXbvWta1Jkyb4+/uzOM1KezVr1qRChQpMnz7dta1ChQrUrl2b+fPnc/78eQCKFStGs2bNWLVqFSdOnADA39+fjh07snXrVvbs2eO6f9euXTl8+LDba9GqVSuSk5NZ4fz4GoiIiKBo0aLMnTvXta1q1apUq1aNmTNnknz5E43Q0FAaNGjAkiVLOHv2LGCOf3fccQfr16/n8OHDAHh7e9OtWzd27tzJjh07XI/ZoUMHzpw5w7p161zbmjZtip+fn9trUatWLcqVK8eMGTNc28LCwqhVqxbz5s3jwoULABQvXpymTZuycuVKTp48CeBqWbNlyxb27t3run+3bt04cOAAW9L04WrdujWJiYmsXLnSta1BgwYULlyYefPmubZVq1aNqlWrMmPGDFLMwYLSpUsTERHB33//TWxsLADBwcG0atWKdevWceTIEQB8fHzo2rUrO3bsYOfOna7HvFXH8v3797uOiZ48lhcuXPiWHctnzZrl2lapkvuxHCAkJITGjRuzfPlyTp8+DUBgYCDt2rVzO34B9OjRg+joaKKiolzb2rZtS0JCAqtXr3Zta9SoEQULFmTBAh3Lb/RY3qBBA0scy9O+FjqW61ie9lheqFAhypQp47ljeXg4ca1aUWjjRpLy5yfyjTdo1Lx5psfy1at3MGJEU3buLExwsIMffzzD4cPLuPzfqGP5bXos3717t/4u17H8lhzLP/vMjwIFDvDVV+F8950Xa9de4o8/vNm5c4bzjtQvVowyY8fCr78St24dy8aPp3CFCm7H8g0bNphjebt2bImKch3LyzzzDHUeeYQDRYqw5fLvhzNnfJk6tR2zZplFzmrVOsWQIZG0bx/OxYu59+9yq2QsOpanP5YfPnzY9Rxv57/Lnceqq8lVM23BFKWvry9TpkwhJCSEqVOn0rdvXypXrsxXX31FixYtOHLkCKVKlXLd54EHHsBms/HDDz/w5ptvMmnSJLeDIpgf3lGjRjFo0KAMv29en2k7bdo0evTo4elhZOjMmYxbLkRHX70frs0GZcpk3HKhUiUoUkSfHuYWVq5REVCNivWpRsXqPFqj8fHQtWvqKmJz5phZaZk4exY6d4bVq83fk/PmQf36OTdc8QwdRyUnLFkC998Px4+bw9G334Jb2a1YYfop9OgBoaFmZtSwYUCaGl2/3iygeNddMHFiht/njz/gySdN5wRfX3jzTTPb9lq6Lohcq7xyHL0tZ9oCfPvttzz++OOULl0ab29vIiIieOihh9w+hboV/Pz88PPzu6XfQ65P4cKmL1hGvcEuXYL9+zMPdRMSTLB78KBpS3alQoUybrlQsaJp7+OT636CREREROSaDR2aGtjOnZvlKmJnz0KnTmadhiJFYP58s66PiMjN0KqVyVwfeMAclu66yyzkPWrU5Y4GzZqZHYoWhbfeguHDTb/BkSPN6uATJpjFy+x284nSFeLjTTj7xRfmep06MHky1K6do09TRMiFoW2lSpVYvHgxCQkJxMXFUapUKR588EEqVqxIyZIlATh+/LjbTNvjx49T7/JfSiVLlnSdHuGUnJxMTEyM6/5y+/D1hSpVzOVKDof51PDKMNf59ZEjZuGIDRvM5Ure3lC+fOazdPPABGwRERGRvOHNN83q7BMmQJo2a1c6c8YEtmvXmrxk/nyoWzcHxykieUJoKCxcmNrG9o03zAdFU6ZcXhjMuVbPsGEmnB05Ev78k+ZJSeA83b9GDTNtN41ly+Cxx8x7YpvNfF41ejRo/pqIZ+S60NYpMDCQwMBAzpw5w+zZs3nrrbcICwujZMmSzJ8/3xXSxsXFsWrVKlfbg2bNmnH27FnWrVtHg8tTMxcsWIDdbqdJkyaeejqWVyWj1DOXs9mgRAlzadYs/e0XLpjF0TKapbtnDyQmpn6dkaJFM5+lW7q0Tiu52W7HGpXbi2pUrE41KlaX4zWalAT5TB9HV4+DLPpmnTkDHTvCunVQrJgJbOvUyaGxiiXoOCo5KV8+eP99aNrULFI2Z445+/Tnn6/4bKltWzMNNzKSos5t99wDv/ziOqZdumR2GT/eZLzly8M338Add+T0s5K8TsdRd7mup+3s2bNxOBxUq1aN3bt3M3ToUPz9/VmyZAn58uVjwoQJjB8/nkmTJhEWFsawYcPYtGkTUVFRrgXMunbtyvHjx/n0009JSkqif//+NGzYkClTpmR7HNntP5FrjRxpppJe7n3jZswYc1rFyJE5PSrLsNvh6NGMWy7s2WNm8GbF1xfCwjIOdcPC4PLadiIiIiLiCc6mtI89Bs8+e9XdrwxsFyzQqcQiknM2b4Z774Xdu82s2P/+FwYMSLPDnDnmmAYm7b28ABNAVBQ88kjq2aV9+5rZu7djzCFiFbdtT9vY2FheffVVDh06RJEiRejVqxdvvPEG+S5/Cv7yyy+TkJDAU089xdmzZ2nZsiWzZs1yBbYA3333HYMHD6Z9+/Z4eXnRq1cvPvjgA089JWvy9ja9bwCGDWPWrFl06dLFBLbDh5tzJPIwLy8zW7Z06Yw/fYyLy3yW7r595nfkjh3mkpFSpdxbLaT9NyREi6NlxFWjIhalGhWrU42K1eVYjabtcbBnDzz8sFlEIRMxMSawXb9egW1ep+OoeErt2uaQ9dhj8OefZubtypXw4Yfg7w+sWgWA3ccHr6QkGDMG+2vD+PBD+Ne/zFmkRYvCZ59Br16efS6St+k46i7XhbYPPPAADzzwQKa322w2Ro8ezegsQsUiRYpc06zaPMk5w/ZycJtUr557YJvRDFxxKVTI9C/LqIdZcjIcOpTxLN3oaIiNNbN4jx41PYWulD9/xmFupUrmNJa82m8oKSnJ00MQyZJqVKxONSpWlyM1emUCO3/+VQPbDh3MDLXixU1gW6vWrR+mWJOOo+JJQUHw22+m9fbrr8Pnn5tj07zWYwh+17yPn16vHj0iI2H4cCZ9DUP2mPf1XbuahcfSLA0k4hE6jrrLdaGt5KA0we2dNptZuatjRyhbFmbMMM1gQ0LMxdfXs2PNRXx8oEIFc2nfPv3tMTEZz9CNjoaDB+H8ediyxVyuZLOZ/56MQt2KFU07Ns3SFREREcnAlQns/PlZTpk9fdrsHhlp/ixesABq1sy54YqIXMnLC1591fS0fegh6LpuDMHrhrOgzWj+8fMwto1JoVSpHgzIB8P3DOegD5T4cBgDB+p9oogVKbSVrA0bBqNHY0tONtfnzjWXtD7+GC4v9EZkpJmRGxKSGuqm/bdMGTVsvYoiRcwlo4WJL10y7RWuXBTN+XVCAhw4YC6LFqW/f1BQ5rN0y5Y1gXJuVUofC4vFqUbF6lSjYnW3tEavMYG9cveFCyE8/NYNT3IHHUfFKpw9tmc3S2HY0dGMXeQ8U9abAwdgBMMoWBie7ZNC0ac9OlQRNzqOust1C5FZxW2/EJmTsyWCt7dZfKxuXShZEo4fhxMnzOWHH0zXc4Aff4QHH8z88T79FAYONF+vW2fO28gs4A0LMymjZIvDYf47Mpule/Ro1vf38THtFTKbpXs7l7mIiIjkcRMnmr9RQ0JMYJtFAnvqlAlsN27M1u4iIh5z8aJZhyUmJv1tdeqY45iI5LzbdiEyyUFpetgubduWlgsXmuu9eqW2TnA4wG5PvU9EBHz0kUkPncFu2oC3RInUfXfvhlmzMv/+n30GTz1lvl692nRIL1Ei44C3alXTOT0Ps9lSu1U0a5b+9vPnM18cbe9e03ze2Vf3ysnUYNq6ZTZLNzTUnIrjSUuXLqVly5aeHYRIFlSjYnWqUbG6W1qjTz0F8fHQrRvUqJHpbqdOmfZWmzaZv7kWLsxyd8ljdBwVq/H3N+8DM7JzZ86ORSQ7dBx1p9BWMnbFomNnpk1LtzgZw4aZpNDbO/V+lSubS2bSTuxu3Nh0O88s4C1ZMnXfPXsyPt/faeJEePJJ8/WKFTBkSOYBb61a5us8Jn9+c5ZfRmf62e1w5EjGM3T37DFvUJyX1avT39/Pz0yMzijUDQvLmY4YZ86cufXfROQGqEbF6lSjYnU3vUZPnoSAAChQwFx/6aWr7t6+PWzebP5MXbgQqle/uUOS3E3HUbGiqlXNcSvtW3GbDapV89yYRDKj46g7hbaSsZQUV2Drxnk9JeX6Hjdtd/OwMHPJjhYtYOrUzAPe0NDUfffvzzhZdEob8C5dCs88k3nAW7++OZ/kNuflZdoNlykDrVunvz0uLn3/XOe/+/ebWbrbt5tLRkqVcm+1kDbYLVFCTe9FREQkh504Ae3amTO1ZsyAwMAsd1dgKyK51YgR5mRZ59rizn9HjPD0yETkahTaSsZGjnS7WrBgwdQrVwa5OaFsWejdO3v7tm4Nf/yRPtx1/luuXOq+Bw+av74z87//wRNPmK8XL4YBAzIPeJs0MU1hb0OFCkG9euZypeRk8zJmNEs3OtoEvkePmsvSpenvHxiYcZhbsSJUqAC+vlmP7ddfYdQo2LatGzVqmD8+nC2WRazE7TgqYkGqUbG6m1ajx4+bwDYqynzwf+JElhMJTpwwge2WLeaD6IULNUNNMqbjqFjRvffCL7+YOVnbtqVQo4Y3I0bAPfd4emQi6ek46k4LkV2nPLMQ2e3uxAnTfT2zGbzjxpmVJgCmTIE+fTJ/rM8/N6EumBUpHn0084C3ZUuTTN7mHA7T9D5tmJv264MH3U/TuZLNZvL6zGbpLlwI992X/lPjX35RcCsiIiIZOHrUBLbbt5tTjBYuzLK1l3NC7tatCmxFRETk5tBCZHJTRUZGUi+jaZa5XYkS0LFj9vbt0sVMFc0s4E0bwh49aprEHjmS8WN98UXq/nPnwgMPZB7wtmuX+u7AbjfJZC7pJ2CzmbMOixaFRo3S356YaNorZNZL9/x5OHDAXBYuTH9/5+JnzuDXGdyOHq3QVqzntj2Oym1DNSpWd8M1evQotG0LO3aYT4UXLszyQ/QrJ+QuXGh6Q4pkRsdRsTrVqFidatSdQlvJloMHD+oHp0gR01s3O3r0gHXrMg94q1RJ3ffYMTh71lwyWsLzyy9TQ9u5c+HuuzMPeDt3Tl1pLDnZ/Otj3R9zPz/z5iejN0AOh3nJMgpzo6PNy2a3Z3y/zZvhww/NG63w8FyTccttTsdRsTrVqFjdDdXokSMmsN2507TKWrjQnLqTibSBbenSZve0f76JZETHUbE61ahYnWrUnXXTHJHcrFAhiIjI3r733mumoWYW8KZd5eL4cTM99eBBc7lSkSKpoe28edC1q5nmmlHA26MH1K1r9r10yVwCAy2TcNpsZqGPkiWhefP0tyckmJd41670LRbsdnj+efN1SIh5j9aunblUrGiZpygiIiI55fRpOHXKrD+wcGGWPWyPHTN/M2zbZgLbRYuy7KAgIiIicksotJVs8XKehy43X2CgCWazswTxgw+ahdYyC3hr1Ejd98QJ8+/p0+aybZv7Y5Utmxrazp8P3bpBQEDGAW+vXtCggdn3wgU4d84ExN7eN/78r1NgoGk5nNFKqH36mJdl6VLz7/ffmwuYyTXt25s3Y23bmjdjIjlBx1GxOtWoWN0N1Wjt2mbNgaAgs9JpJq6x5a2IGx1HxepUo2J1qlF3WojsOmkhMrG8lBSzClhmAe/TT6cGsd98A337Zv5YkybBY4+Zr2fONAGvlxcUK5Y+4O3dG5o0MfsmJJhZLSVKmED4Zho5Ery9+bXmMEaPNu3pqlXDrIS6ZQykpJD46khWrjTv0RYsgJUrU7tGOFWrljoLt00b85RERPKEy8dRhg1Lf9sYcxxl5MicHpXIzXPwIBw6BM2aZWv3a2x5KyIiInJdtBCZ3FS7du2iihp55S7e3lC8uLk4WyZk5tFHTZuGtKFu2q/r1End98wZ86/dnnp7WhERqaHtokVw553m6wIF0ge8jz2W2ic4Ph4OHzbbCxe+eg8Db28YPpx7R8O9kcNSa3TMGBg+HEaPxs/PTExu3RpGjTIThJctSw1x160zb8x27IBPPjEPW7duaoh7xx2m04XIzaDjqFjO5eMoAMMyPo6KWMk1HUf37zcJ7MmTZk2Apk2z3P3KwHbRoixb3opkSL/rxepUo2J1qlF3Cm0lW7Zv364fnNuZzWZC1QIFrj6l5OGH4YEHzJugjALetE3D4+PB19f0yz13zlyio1Nvb9UqNbRdvNj02QWzeNqVi6098YRJUcEs2ta9O8TGugKH7fXqUeX771ODhgxmjhUoYNZq69zZXD9zBv7+OzXE3bIFNm40l//8x+QZjRqlhrjNm9/8CcOSd+g4KpbjPE5ew3FUxJOyfRzdt88ksPv2mb9rrtIL6RrXKBPJlH7Xi9WpRsXqVKPuFNqKyLXz8YFSpcwlK717mz68sbEZB7xpF2u7eBGCg00gm5xs3kEdOZJ6uzNpBdOs1hnwAgwfzp3OhrY9e0K/ftl6GoULw913mwuYoS1cmBriRkeblgorV8Kbb5r8uXnz1BC3USOzTUQkV4qNNR+edenifhx1Bra7dpl+6MHB5lK4sPm3QAGt6CjWtXevSWD37zfNaBcuNM1pM3H4sNl91y4T2C5alOUaZSIiIiI5RqGtiNxaNlvqG/6qVTPf7777zCUxMXUWb9qAt2HD1H2TkkxgfOKE6bkI2JztuX//He65J7UH765d5h1YRATUqgV+fpkOISTE5My9e5vr+/enhrjz55sMedEicxk+3CyG1qpVaohbr55H12YTEbm6OXPgiy9Mf5i0Zz5w+TiaL1/qDNs//oChQ9M/hre3Wczpt99Sz4BYsACmTk093qcNeYODTZueoKBb97xEAPbsMQnsgQNQpYr5JZ7FLNu0gW358mZ3BbYiIiJiFVqI7DrltYXIzp8/T/78+T09DBF3dju89hqMH4/DxwdbcrJ5tzV9OtSoYfZ5/30YMsR8nS+fCW4jIswibBERpomtv/9Vv5XDYd7UOWfhLlgAp0+771O4sFnMzBni1qihyWiSSsdRyTFHj8L69amXESNSW9d8/jk8+WTqvhUqmL4v27bh8PbGlpKSOtP266/h009NL5mzZ82/SUmp9121Cho3Nl+/807GAa/TrFmpZ0xMmgQvv+we6qYNeh97LPUYfvy4+QQt7T46xSHPyvI4evCgabl08KBZZXTBAggNzfSxDh0yge3u3ebHYOFC86/IjdDverE61ahYXV6pUS1EJjdVbGxsnvjBkVzmjTdg/HgYPZpjTzxBqc8/N1Ngf/45daZYqVLQoYMJLmJiYMMGc/niC3P70qWpfXW3bTP71KtnptGmYbOZicJVq8LTT5u8ePPm1AB38WKTZ/z2m7mAmbnrDHDbtTN5skLcvEvHUblldu2Cb75JDWmPHXO/vVOn1NC2bVuYMMF8aFW/Pnz8sauHrdtxFMxxNG27GYfDtLJxhrhppyS2bAljx5rtzoDX+fXZs2ZRTKe0PdEz0qZNamj711+mp3la+fOnBrjvv2+O8QCRkfDLL5nP9i1VSo3Jc7ksj6MlSpgPYgMDzS/mLFo4HTxofhSio01Qu2iRmWkrcqP0u16sTjUqVqcadafQVrJl7dq19EjbQ1TE09Kubj5sGGunTaPHFYvqMGyYWTTtgQdM2HDggDkl2BlsREaaN3hOn3wCH35oktXq1d1n5NavD2k+AfPyMnetWxf+8Q/ThnfdutQQd+lSM0Fs6lRzAfOG0Bngtm171XVR5Daj46jcELvdJEzO41fnzuZgAuYc77FjU/f18jLHMOfxq23b1NsqVTKzXCH7x1Enm82EngEB6WcwNm1qLtkxYIAJktOGumlD3sqVU/f18TEHzzNnIC7ObDt/3lyOHHG1yAHMQTjt63Cl7783fdbBzPz917/Sz/Z1Xu/SxczWBLOI5pkz6udrAVkeR/38zIe2cXHuHxJc4eBB87nAnj3mc4eFCxXYys2j3/VidapRsTrVqLtcFdqmpKQwcuRIJk+ezLFjxwgNDaVfv368/vrr2C7/Ad2vXz8mTZrkdr/OnTsza9Ys1/WYmBiee+45pk2bhpeXF7169eL999+nQIECOfp8ROQGpD2FNy3n9bRv5MG8yS5f3lzuvTfjx8yf3wQRR46YWbfbtsF336XefvIkFCtmvt67N/UNPiZXaNLEXF591bTmXbkyNcRdudKc4fvVV+YCJg9o1w7atzdvIIsWvaFXRERuJ7GxMG1aaki7YUNqaAnmGOcMbevVg8cfNwFtRATUqZPubIEMXetx9GYpXNh17Lyqvn3NxTmeuDj3kNc5gxhMUD14sHsAnLa1Q3Bw6r6HD8OmTZl/3++/Tw1t58yBXr3M197e6Vs6vPyyCaEB9u2DGTMyn+3r76/Q92bauROmTDEtQGw2E9xmEdgeOGA+w3AGtosWmcXHRERERKwoV4W2EyZM4JNPPmHSpEnUrFmTtWvX0r9/f4KCgnj++edd+3Xp0oWvnKkI4HfFwkN9+vTh6NGjzJ07l6SkJPr3789TTz3FlClTcuy5iMgNGjky89uuDCCya/x4czl2zIQkzlm569aZsMAZ2AI884yZqRUWljqbzflvsWL4+UHr1uYyapSZqLV0aWqIu3497NhhLp98Yh6yXr3UmbitWrlN7BWR29WlSxAVZQ4KpUpB165me1wcPPqo+75+fmZ6f4MGqYEtmDDQ2fLlWtyK4+it5O2dGvhmtFpUixap7W4yknYZh65dzTE8s9m+lSql7nvhgumJnpRkfhecPu3e1Dxt+4b16+HZZzMfw6efwsCB5uu1a+H11zOf7duoUerzTE4248+XL/PHzmt27DAJ7NGj5kOKrHoqYwLbNm3MZ64VK5rAtmzZHBmpiIiIyHXJVQuR3XnnnYSEhPBFmjcmvXr1IiAggMmTJwNmpu3Zs2f5/fffM3yMbdu2ER4ezpo1a2h4eTX6WbNm0a1bNw4dOkRoFgsWpJXXFiI7ceIEJUqU8PQwRDJ1y2v03DlzWqxTs2Zm+mxGatUyM7ics6ni46FgQbddzpwxfXCdIe7Wre4P4e1t3q87Q9zmzdWKMbfTcVRISXFv0bJ+vWmOfemSuf3uu8H594vDAT16mPDQOYO2evVbEtr9+qv5cGnHDgfVqtkYMSLzExLyLIfDhLcZhbwtW6aeX790Kbz3XsZ9fe120y+nd2+z76+/ps7gzUjagHfBAnNaRv78GYe8jz0GHTuafU+dgr//Th8CFypkfrnkYq7j6LZt5pfjsWNQuzbMn5/lDNv9+02+u3ev+ZFauFCBrdwa+l0vVqcaFavLKzV6Wy5E1rx5cyZOnMjOnTupWrUqGzduZOnSpbz77rtu+y1atIgSJUpQuHBh2rVrx9ixYyl6+bzjFStWEBwc7ApsATp06ICXlxerVq3innvuyfB7JyYmkpiY6Loel/YUxTzA39/f00MQydItr9Er26esWGHekG/Y4D4jd9cu0+cg7emvDRqY0DfNjNzCERH0vLs0PXua/Y4dM7N+nCFudLTJhFeuhDffNIulN2+eGuI2bqwJV7mNjqN5zLlzsHEjJCSknjrvcJipfhcuuO8bFGSODU2apG6z2cwiXLeYMze02cDhsLF5s7n+yy8Kbt3YbCYwdbbRyUzLluZyJYfDfIDn65u6rUED+PrrzBdvq1Ahdd+zZ82/zn6+hw+7P36LFqmh7aZNmYfBhQqZXyrO2cDR0aa3cWazfStXzvr53mojR5qg+fLMb39/fzMzvV070zi+RAnzSzPtmTBX2LfPBLb79pnAdtEiKFMmJwYveZF+14vVqUbF6lSj7nJVaPvKK68QFxdH9erV8fb2JiUlhTfeeIM+ffq49unSpQv33nsvYWFhREdH8+9//5uuXbuyYsUKvL29OXbsWLrU3sfHhyJFinDsytWW0xg3bhyjRo1Kt33mzJmule06duzI6dOnWb9+vev2Zs2a4ePjw5IlS1zb6tSpQ+nSpZk5c6ZrW8WKFalZsyZz587l4sWLAJQoUYImTZqwYsUKTp06BUD+/Plp3749mzdvZt++fa77d+/enX379rE1zXS91q1bc/HiRVatWuXa1rBhQ4KCgpg/f75rW/Xq1alSpQrTp0/HbrcDULZsWerVq8eiRYuIj4/HbrdTtGhRWrZsydq1azl69CgA+fLlo0uXLmzfvp1du3a5HrNTp06cPHmSDRs2uLY1b94cLy8vli5d6vZahIaGuvUcrlSpEuHh4cyZM8cVlIeEhNC4cWOWL1/O6cunJAYGBtKuXTs2btzIgQMHXPfv0aMH0dHRREVFuba1bduWhIQEVq9e7drWqFEjChYsyIIFC1zbatSoQeXKlfnrr79wTkIvV64cdevWdb0WAEWKFKFFixasWbPGVTe+vr507tyZbdu2sXv3btdjdu7cmePHjxMZGena1uLy6ZvLli1zbatXrx4hISHMnj3bta1y5crUqFGD2bNnc+nyTKySJUvSqFEjli1bRkxMDAAFCxakTZs2bq+FzWbjzjvvZPfu3Wzbts31mO3atSM+Pp41a9a4tjVu3JjAwEAWLlzo2hYeHk6lSpWYNm2aa5vztViwYAEJCQkAFC1alObNm7N69WqOHz8OmJYknTp1IioqiujoaNf9u3TpwpEjR9iUpo9gy5YtsdvtLF++3LWtfv36FC9enDlz5ri2ValSherVqzNr1iySkpIAKFWqFA0bNmTp0qWcPn0aLy8v12sRGRnJwYMHAfDy8qJ79+7s2rWL7du3ux6zffv2xMbGsnbtWte2Jk2a4O/vz+LFi13batasSYUKFZg+fbprW4UKFahduzbzHQ7OV68O1atT7PnnaVazJpHz5nHw8uuW3+Gg/Z49ZobdX3+5hTApxYqxv2lTtj711OXXpxUdOiSzYsUKTpwIYNOmYhw6VJUVKwI4etTGokXmzebw4eZM0Bo1TlC79knq1DlN8+aBNG7cgCVLlnD28pv7oKAg7rjjDtavX8/hy2/wvb296datGzt37mTHjh2usXTo0IEzZ86wbt0617amTZvi5+fn9lrUqlWLcuXKMWPGDNe2sLAwatWqxbx587hwOYwqXrw4TZs2ZeXKlZw8eRKAgIAAOnTowJYtW9i7d6/r/t26dePAgQNs2bLFta1169YkJiayMs1s5gYNGlC4cGHmzZvn2latWjWqVq3KjBkzSLncf7N06dJERETw999/ExsbC0BwcDCtWrVi3bp1HDlyBDDH/q5du7Jjxw527tzpesxbdSxfuHAhXl5epi48dCwHKFy4sI7lN/lYvmr2bIL27CEoOpoKZ86Qf9s22LkTm8NBXLlyHJ41yxzL58+nbu3aeCUlkVy3LqHdu7PWbufo5T6nBQsWpA3c8mN56dLlCAqqy9SpG3n33WqAHw6H+QDJvFwOHn88kblz99GqVXXOn99PQsI+goISKVToEj16dL5lx/IzZ84A5PyxfP58zp8/D0CxYsVo1qwZq1at4sSJE4B5A9GxY0e2bt3Knj17XPfv2rUrhw8fdnstWrVqRXKyOZY7RUREULRoUebOnevaVrVqVar17cvMmTNJTk4GIDQ0lAYN0hzLp00zx/K772bjwoWc2rWLfAkJ+F24QJNq1Ti2bRuno6M5eekS8dOm0aFDB87Fx+Ndowb5zp3DJyEB/4sXsV1+bsTFsWnrVgru3Uu5cuVYNXUqza9YCyKtA4MGUe7jj1m5ciWJq1fT7PXXSS5YkPyhoZzz8SHOy4ukAgVICgwk7JlnOFCpElu2bME7MZFCe/dSr00bEgMCWLljB/bLgfU1Hcu9vWH4cHNs6t2bwH37aDd2LFz+f9nVqhW716zJ9FgeGXmWu+8uxIkT+SlV6hy//XaJAgW8mDYtd/9dDjqWW/XvcrvdTlBQUJ7/uzzPHcurVcv6WI51/i4/fvw4Xl5eef7vch3LrXssT/ue6XbOWJzHqqvJVe0Rvv/+e4YOHcrbb79NzZo1iYyMZMiQIbz77rv0dS5ScYU9e/ZQqVIl5s2bR/v27XnzzTeZNGmS20ERzA/vqFGjGDRoUIaPk9FM27Jly+aZ9gjTpk3TCn5iaZauUeeMO+fp0OvWmZlCKSlm8SBny5dLl0z/wvBwt1m5jrCK7Nxlc83CXbjQvZ0imElRbdqkzsStUUNr3ViNpWtUsu/kSdi927RIcapVK32PE4DSpU2fk19+gct/fOak5GSz4FJUlPtl+/b0k32vRVCQORM9uxe1drGAxESzuN2ZM2ZWqnPly7174YcfMp/t+9prpvUCpLZoyMy4cfDKK+brDRvM77C0/PxSZ/I+91zqbN+TJ+HddzOf7TtpErzxBrz+Ohc//hj/y2+meOUV8z0zsW+f+b24fz9UqWJ+d5Yunb2XS+R66Xe9WJ1qVKwur9TobdkeYejQobzyyiv0vtwLrHbt2uzfv59x48ZlGtpWrFiRYsWKsXv3btq3b0/JkiVdn7Q5JScnExMTQ8mSJTP93n5+fukWNBMRyZYCBdIvkHPhgulleXmmPmDSlCNHzCXNp9a2oCCq1a9PtccfZ9BPj2K3m7s6Q9zFi8377N9+MxeAkJDUALddO7PoiohcA4fD/Cym7T+7fj0cOmRSyPj41P6gERHmlHVn79mICKhf3/wg5oCkJJMjpw1mt2416zQ52+Veyc/PtMjdvz/1zPu0ihY1+dzJk6mXU6fMZ02xseaSZsJDlgoUuLaQNzBQHzrddH5+ppXAlT3iwsJSg9aradoUtmxxD3XTBr1Nm6bum5xsfvGk7eebmGhaGhw/bn5+nA4dMouAZuZf/4LRo2H4cHydP3OvvmraPGRi714T2B44oMBWREREcq9cFdqeP3/eNU3aydvb2zXdPCOHDh3i9OnTlCpVCjBT6c+ePcu6deto0KABAAsWLMBut9MkbS85cVOzZk1PD0EkS7muRgMCTGPatMLDzWriztm469eb3oSxsaYvwuW+mF5eULfQXur++hj/aNCAlHsj2OrfgBnR1Zi3yIdly8x74qlTzQVMa0RngNu2rWdbFOZVua5G8xKHw6SX5cunpoWPPQaXFzlNp2xZ80Pm/EH68kvwufV/UiUmmrbZaYPZqCjYudNkZBkJCDAz78PD3S8VK5rM2b2nbeq///sfXNnm3243+dvJk+bs9LSBbmaXpCRzssG5cyZIyw5//9QAt0SJq4e8hQop5M0R+fNDdo9jjRqZfrlgCufcOfeQt1y51H0LF4YXXsh8tm9wsAmWx47F69Il0xc4i8B2zx4T2B48CFWrmsBWv/Mkp+h3vVidalSsTjXqLle1R+jXrx/z5s3js88+o2bNmmzYsIGnnnqKxx9/nAkTJnDu3DlGjRpFr169KFmyJNHR0bz88svEx8ezefNm10zZrl27cvz4cT799FOSkpLo378/DRs2ZMqUKdkeS3anMt8u7HZ7usBcxEpu2xpNSjKpzPr1ZpGi8HCz/aef4IEH3PcNCIC6dUmu24CN9fryx5FGLFgAq1alD3SqV08Ncdu0ST1TVm6d27ZGcxu73UwRvXIG7ZkzJuVxrlA0apRZoCk83Myadc6grVvXpIS30MWLZpZs2mA2KsoM+3KLuHQCA9MHszVrmhz6amX3669mIuOOHQ6qVbMxYkT6wPZ6OBwQF5c+yM0q8L3ccu6a+PqaM/6vDHMzC3yDgz3SrUKul8MBY8fC8OE4fH2xXbpkCvby4mRpRUebDyYPHoRq1Uxge3nehkiO0O96sTrVqFhdXqnR7GaKuSq0jY+PZ9iwYfz222+cOHGC0NBQHnroIYYPH46vry8XLlygZ8+ebNiwgbNnzxIaGkqnTp0YM2YMIWlOUYyJiWHw4MFMmzYNLy8vevXqxQcffECBK1eHz0JeC23zSl8Ryb3yXI0eOQLz56fOyN2wwcxkcvrxR7j/fgDOL1zFqXe+Yk1yBL8daMDP22uRSGq7F5vN5FDOELdVq1ueSeVJea5GrcD5aYVzFuxHH5nTqtP+rDjlywezZ5vEB8wMd1/fW9qQ9fx50182bTAbFWVmCmZ2ElGhQhmHs2XK3HgQ6ekadTggISHrmbtXBr6X1965Jt7eGYe8mYW9RYqkdsIQDxgzxqzAOXo00+rVo0dkpOt62uA2Otp8CHnokPlgcsECBbaS8zx9HBW5GtWoWF1eqdHbsqdtwYIFee+993jvvfcyvD0gIMBtVbjMFClS5Jpm1YqIWE5oKDz6qLmASXh27UqdNZimt2D+VQspN+MzygG9gG99fIgtW4ttAQ2YdyaCj472IjIyhMhIsxaMt7fp3OAMcZs100JCkgtcumTST+cHGevXmwUAZ840SQ6Y07DPnTPn39er596DtmZNE9I6BQXdtKHFx8O2bekXBNu3zwSVGQkONkNyhrLOgDY09PZtBWCzmf63BQqYVqvZceFC9to0OAPfuDgzW9nZWjW74ypa9OptGpxhb7FiOdItI29IE9gybBhMm5Ya1A4fbv4dNozdu83nLc7AduFCyGKpChEREZFcQX9SiojcDry8zLmg1arBQw+539a6tVnI5XKvXFtMDMF7I2lGJM34gkFzmjH3VAgLFsCF6QsocnQL61Y04L0VdXnjjQL4+UHz5qkhbqNGZlKiiCUsWgQvvWRW50tKSn/7hg2poW23bma/6tVvSap29mzG4eyBA5nfp2hRE8qmDWbDw80aZrdrOHszBQSY9qhpW6RmJTHRLKiW3aA3JsYE66dOmcu2bdn7PoULX9via1rrNhMpKRm3QnBeT0lh1y4T2B4+bPo3L1igwFZERERuDwptJVsqVKjg6SGIZEk1moVmzcwFTPpw4EDqbMTISIq1rslDvpez3iemwBdfAGDHxm6f6qxOjGDdwgbMXRjB6GHN8A305Y47UkPcunV16nB2qEavU3w8REa695998UXo39/cHhBgtoFJytLOno2IgMqVUx+rcGFzuUExMemD2a1bTdeSzISEpA9mw8NNYGcVeaFG/fygdGlzyY6kJDh9Ovsh7+nT5sSHM2fMZefO7H2fQoWuLeTNn//6X4NcZeRIt6tuNTpsGLt2mc9kjhwxP08LFpifNRFPyQvHUcndVKNidapRd7mqp62V5LWetiKSR/zvf/DnnyYEyyCBCit8ln1nzGnjbViIF3b2BEVQv11h2rWD9u3NJEbNEJQbcuBA6uzwXbvS9xAYNAg+/th8feGCaYEQEWFW3bqJxXfyZPpgNioq69PqS5dOH8zWqKHF/vKKlBQT1mZ34bVTp9IvFJkd+fNnvdjalZcCBW6/4/LOnWaGrQJbERERyW1uy4XIrCSvhbbz58+nffv2nh6GSKZUo7fAsWOpMxvXrYOzZ7HPX8imTebNcYc32lInZhEAewhjHQ1YTwT7CkdQqG0DGncrRrt22e9NebtTjV7hxAn32bPNmpk2B2CSrLRTUMuUcZ8926jRTTv/2eEwIWzaUNZ5OXUq8/uVK5dxOBscfFOG5RGq0ZzncJi2GtldeO3kSdO++Vr5+WVv0TXnJSjImiGvs0Z37DCB7dGjZgb7ggXmuYh4mo6jYnWqUbG6vFKjt+VCZOI558+f9/QQRLKkGr0FSpY0PUC7dXNt8sKs31SvHrC1Io5FB7Dt2UNF9lKRvdzPz3AGTvxanJBfjwM2KlSA/nXWUrNTGZrdU5LQUI88G4/L8zWamAjjxqWGtIcPu98eH58a2hYrBu+/b3o0169/U9IYh8PMyLsymI2KMjMjMxMW5h7M1qxpZpMXLHjDQ7KcPF+jHmCzpXbtqFr16vs7HOZHJbsLr508aSajJyaaRboOHcreuPLlMz+GV1t0zXkpXNi0Vr/Vzp8/7xbY1qoF8+crsBXr0HFUrE41KlanGnWn0FZERK7PF19gA5N4bdgA69eTsnodiSvXc9avEi1CbKxaBfv2weP7elLmz8McGVyKhYENuFAjguD2DajRJ4LCtUpbc0qXXDuHA/buTQ1mAwPhtdfMbb6+Jog9e9Zct9lMKOucPevsu+z0/PPXNQS7HQ4eTB/MRkVBXFzG97HZoFIl92A2PNwMLzDwuoYhckvYbKb/baFCpmazIyEh+z15T540oXBSkglFjx7N3vfw9jYtQLLTqqFECbPvtfRC//VXGDUKoqLMh4jJyVC7tglsrdQXWkRERORmUmgr2VKsWDFPD0EkS6pRDypc2LUqmTeQH6iaksJSb/Pmf8W8BHyeDCLl9FFCOUpowl+w9i9YC0yAJYW68ceT02nXDlq1goJxhyE09LYLcm/bGv35Z1i5MjWojY1Nva1ixdTQ1maDV14xzTgjIswKdgUKXPe3tdvNBwIZhbMJCRnfx9vbrEt25YJgVaua9czyutu2RvO4wEBzye66HhcvXlvIe/as6eV74oS5ZIfNBkWKZC/kXbMGnnzS3MfhSE16//EPBbZiPTqOitWpRsXqVKPu1NP2OuW1nrYiIjcsIYG4JRvZ+8t6LixdR+G966mUuJVPGMTzfAhAQa8EztoLcjGgMBdrRFCwTQT5mjQwIV/Fijlz/q2kl5wM27aZUPboURO+OjVqBGvXpl739TVT4JwzaAcOvKEAPiUF9uxJvyDY9u3mtO+M5Mtngtgre85WqWJ6e4rIzZOUZPo/Z2fhtZMnISYm/dqC18pmgzp1IDLypjwFERERkRylhchusbwW2q5atYomTZp4ehgimVKN5k7H9l5g2dzzzFpTlAULoOCeSFbTGF+S0u2bHFgI27/+hfewf5sNdrt5538t59h6UK6q0a1bYfny1NmzmzaZ6XcAPj5w7lxq+vn227B/f2pIGx5ugttrlJQE0dHuwWxUFOzYYfpxZsTX1/SXvTKcrVzZBLdybXJVjUqulZxsgtvsLr6W2exdf//MP7gR8RQdR8XqVKNidXmlRrUQmdxUJ7J7vpuIh6hGc6eSYQH0eiqAXk+Z6/v21WPqnHh2/b6Vi8vXUSl2PQ1YRx024Z8Qx8tjA9m60nRj6FZ+G9X7NcFWv74JCxtcnpFbvboJFi3GkjV6/jxs3Gh6Ej/9dOpM5rFj4fvv3fctVMgsChYRYe7nDG2HDr2mb3npEuza5R7MRkXBzp0muM2Ivz/UqJE+nK1Y0ZL/1bmWJWtUbjs+PqavbXYXD6tbFzZvdp+d62yJLWI1Oo6K1alGxepUo+70VkdERCyjQgWo8JQfPBWBwxHBjh2wYAH837wkjs6PYldcCY7NgBkzIJL1fEsCLF1qLk4BAeZd/vDh0LWrx56L5cTFmXOJ16+HdevMv9u3mxnLAB06pC5f37q1Od85bRh+je0pLl40s2Sv7De7a5dpeZCRwMD04WzNmlC+fK6ZUC0iN9mIEdCrl7Onbeq/I0Z4emQiIiIit5ZCW8kWf39/Tw9BJEuq0duPzWYmzVavDs88kw+7vS6bNpkQd8ECmLboIWomRBCBmY0bwXoibBsocOEcrFzJscMplHQ+2IwZ5h1+2hCydu0cbXCaozV6+rSZPduoEQQFmW1vv21m0F4pJMS8Jml7EDz9tLlkw/nzJvu9MpyNjk7Ng69UsKB7KOv8umxZtS32JB1HxYruvRd++QVGj4aoqBTCw70ZMQLuucfTIxNJT8dRsTrVqFidatSdetpep7zW01ZExGqSksyEUWeIu2wZJF60U4VdRLCe2XQmOKwI7drBCzHDqf3bGPcH8PGBWrVMYPmvf5lVqnKjY8dSe886L/v3m9umT4du3czXv/0GQ4ak9p51XkqVyta3OXfOrEV2ZTi7d2/miwoFB6cPZsPDoXTpG1qbTEREREREJNfSQmS3WF4Lbbdu3UrNmjU9PQyRTKlG5eJFWLEiNcRdvdoseANQmkM0YwWdiq6jZf71VDyzDr9zMal33r49tUHi5Mkwb17qrNy6daFAgRse3w3XqMMBBw+aHgJFi5ptU6fCww9nvH/lyjB+vDmv2Hn/bCSlsbHpw9mtW+HAgczvU7Ro+mA2PBxKllQ4m5voOCpWpxoVq1ONitWpRsXq8kqNaiEyuan27NmTJ35wJPdSjYq/P7Rtay5jxkB8vGl1a0LcMvyy4X5+Pn0/nAZwUJ4D9ApbT+eQSJJ3VaFVqDltn5kzYcoUmDTJPLCzT4NzZuqTT17e8SpGjjSNWIcNA66o0TFjTGPXkSMzvq/DAXv2pM6cdfagPX0aPvgAnnvO7FezZvrxNWgA9eqltkVwuiI9PXMmfTAbFQWHD2f+lEJC0gez4eHZX1BIrE3HUbE61ahYnWpUrE41KlanGnWn0FZERG5LBQuadcica5HFxMDixc4Q10ZUVHne3Vued/feAz1Mt4TGjeHxik/S7rEqlDu9Hu8N6+DIETP1dNs2+P57GDQo9Zt88YUJUhs0gPr1oUiR1Nu8vc1iaOAKbgET2A4fbho0gglvL1xInc27eTO0amWmvF7JxweOH0+9XrOmSacDAzN9HU6dSh/MRkWZrgqZCQ3NOJx1TvAVERERERGRW0uhrYiI5AlFipiFa5yL1xw9CgsXprZT2LsXli+H5cvbAG3w84MWLaDHo8foXGIDVePX4X3mFAQEpD7oxImmD4NTWFjqjNfGjWHUqNTgtl49M7N21Cjo2RNOnDDfIDISnngC3n8/9THi4swiaXXquPefrVXLTCl28vaGwEAcDvNwaUNZ5+Xkycxfk7JlMw5ng4Nv8MUWERERERGRG6Kettcpr/W0TU5OxsdHGb9Yl2pUbtTeve4h7tGj7rcXKAB33AHt2plL3brg9f5/TCPddetMO4O0ypeHfftcM2sdNhu2zH7ltmsH8+enXt+2zfSkzZfPbTeHw0z8vTKYjYoyM4kzU6FCaiDr7D1bvTrkgV9fcg10HBWrU42K1alGxepUo2J1eaVGtRDZLZbXQtv9+/dTvnx5Tw9DJFOqUbmZHA7YsSM1wF24MH0oWqQItGkD7dubzLVaiTPYIjek9qAtUSJ19qyfH1y6ZL4uVMh99mxEBFStambNpvn+Bw9mHM5m1DUBTMvaihXdg1lnOJtF9wQRFx1HxepUo2J1qlGxOtWoWF1eqVEtRCY31aZNm/LED47kXqpRuZmca3tVrw7PPAN2O2zcmBri/v23CXF//dVcAEqVKky7du3MZZyZ3QoQ9dAYwi9d4hL58CWJqK4vEf69aZlgt8P+/RA1K304e+5cxmPz8jKTcNMGs+HhUK2ae+cGkWul46hYnWpUrE41KlanGhWrU426U2grIiJyFV5eZp2x+vXhpZcgKQnWrk0NcZctM+0UvvvOXMC0ph1mG0P/PcMZzmjGMIxhjGH0D8P5YqWNj4sOY9s2swZZRnx8zATcK/vNVq1qJu6KiIiIiIjI7cvL0wO4FikpKQwbNoywsDACAgKoVKkSY8aMIW2HB4fDwfDhwylVqhQBAQF06NCBXbt2uT1OTEwMffr0oVChQgQHBzNgwADOZTalSURE5Ar58kGzZvDaa6YV7dmzJrx9/XVo3tx0Ouiz1wS2wy4HtsDl4HY0A/YPp9v6MVy4AL6+ULs2PPigWaPsp5/MgmLnz5t/f/rJbH/wQbOfAlsREREREZHbX67qafvmm2/y7rvvMmnSJGrWrMnatWvp378/b7zxBs8//zwAEyZMYNy4cUyaNImwsDCGDRvG5s2biYqKwv/yittdu3bl6NGjfPbZZyQlJdG/f38aNWrElClTsj2WvNbT9uzZswRrOXGxMNWoWEl8PBx7eiSTp3oz2jEs3e3DvcbQ+74UvMeMpGJFM6tWxNN0HBWrU42K1alGxepUo2J1eaVGb8uFyO68805CQkL44osvXNt69epFQEAAkydPxuFwEBoayksvvcQ///lPAGJjYwkJCeHrr7+md+/ebNu2jfDwcNasWUPDhg0BmDVrFt26dePQoUOEhoZmayx5LbQ9deoUxYoV8/QwRDKlGhUrqlsXNm82C4s52WxQpw5ERnpsWCIZ0nFUrE41KlanGhWrU42K1eWVGs1uppir2iM0b96c+fPns3PnTgA2btzI0qVL6dq1KwB79+7l2LFjdOjQwXWfoKAgmjRpwooVKwBYsWIFwcHBrsAWoEOHDnh5ebFq1apMv3diYiJxcXFul7zE+fqJWJVqVKxoxAgT2Nps5rrNZq6PGOHZcYlkRMdRsTrVqFidalSsTjUqVqcadZerTsh85ZVXiIuLo3r16nh7e5OSksIbb7xBnz59ADh27BgAISEhbvcLCQlx3Xbs2DFKlCjhdruPjw9FihRx7ZORcePGMWrUqHTbZ86cSf78+QHo2LEjp0+fZv369a7bmzVrho+PD0uWLHFtq1OnDqVLl2bmzJmubRUrVqRmzZrMnTuXixcvAlCiRAlX4Hzq1CkA8ufPT/v27dm8eTP79u1z3b979+7s27ePrVu3ura1bt2aixcvuoXRDRs2JCgoiPnz57u2Va9enSpVqjB9+nTsdjsAZcuWpV69eixatIj4+HjsdjtLly6lZcuWrF27lqNHjwKQL18+unTpwvbt2916B3fq1ImTJ0+yYcMG17bmzZvj5eXF0qVL3V6L0NBQZs2a5dpWqVIlwsPDmTNnDomJiYD5P2zcuDHLly/n9OnTAAQGBtKuXTs2btzIgQMHXPfv0aMH0dHRREVFuba1bduWhIQEVq9e7drWqFEjChYsyIIFC1zbatSoQeXKlfnrr79cvZLLlStH3bp1Xa8FQJEiRWjRogVr1qxx1Y2vry+dO3dm27Zt7N692/WYnTt35vjx40SmmVbXokULAJYtW+baVq9ePUJCQpg9e7ZrW+XKlalRowazZ8/m0qVLAJQsWZJGjRqxbNkyYmJiAChYsCBt2rRxey1sNht33nknu3fvZtu2ba7HbNeuHfHx8axZs8a1rXHjxgQGBrJw4ULXtvDwcCpVqsS0adNc25yvxYIFC0hISACgaNGiNG/enNWrV3P8+HEA/Pz86NSpE1FRUURHR7vu36VLF44cOcKmTZtc21q2bIndbmf58uWubfXr16d48eLMmTPHta1KlSpUr16dWbNmkZSUBECpUqVo2LAhS5cuxW63M23aNNdrERkZycGDBwHw8vKie/fu7Nq1i+3bt7ses3379sTGxrJ27VrXtiZNmuDv78/ixYtd22rWrEmFChWYPn26a1uFChWoXbs28+fP5/z58wAUK1aMZs2asWrVKk6cOAGAv78/HTt2ZOvWrezZs8d1/65du3L48GG316JVq1YkJye7/aKKiIigaNGizJ0717WtatWqVKtWjZkzZ5KcnAxAaGgoDRo0YMmSJZw9exYwH1rdcccdrF+/nsOHDwPg7e1Nt27d2LlzJzt27HA9ZocOHThz5gzr1q1zbWvatCl+fn5ur0WtWrUoV64cM2bMcG0LCwujVq1azJs3jwuXV9UqXrw4TZs2ZeXKlZw8eRLA1Wd8y5Yt7N2713X/bt26ceDAAbZs2eLa1rp1axITE1m5cqVrW4MGDShcuDDz5s1zbatWrRpVq1ZlxowZpKSkAFC6dGkiIiL4+++/iY2NBSA4OJhWrVqxbt06jhw5Aphjf9euXdmxY4frw0C4ucfyfPlg3LhqfP99VaKiUihT5hy9e++kUKE4IOeP5QCFCxfWsVzH8gyP5YDHj+Vnzpxxey10LNexPO2x3Hlsy+ljOVjr73LQsdyqx3K73c6iRYvy/N/lOpZb91jufM+UF/8uBx3Lc8Ox3FmjcHv/Xe48Vl1NrmqP8P333zN06FDefvttatasSWRkJEOGDOHdd9+lb9++LF++nBYtWnDkyBFKlSrlut8DDzyAzWbjhx9+4M0332TSpEluB0UwP7yjRo1i0KBBGX7vxMREV3GDmcpctmzZPNMeYdq0afTo0cPTwxDJlGpUrE41KlanGhWrU42K1alGxepUo2J1eaVGs9seIVfNtB06dCivvPIKvXv3BqB27drs37+fcePG0bdvX0qWLAnA8ePH3ULb48ePU69ePcAk6M5P2pySk5OJiYlx3T8jfn5++OXhJbsjIiI8PQSRLKlGxepUo2J1qlGxOtWoWJ1qVKxONSpWpxp1l6t62p4/fx4vL/che3t7u6abh4WFUbJkSbdp6XFxcaxatYpmzZoBZir92bNn3U41WLBgAXa7nSZNmuTAs8idnKdNiliValSsTjUqVqcaFatTjYrVqUbF6lSjYnWqUXe5KrTt0aMHb7zxBtOnT2ffvn389ttvvPvuu9xzzz2A6S8xZMgQxo4dy59//snmzZt57LHHCA0NpWfPnoDpp9GlSxeefPJJVq9ezbJlyxg8eDC9e/cmNDTUg8/O2tL27RGxItWoWJ1qVKxONSpWpxoVq1ONitWpRsXqVKPuclV7hA8//JBhw4bxzDPPcOLECUJDQxk4cCDDhw937fPyyy+TkJDAU089xdmzZ2nZsiWzZs3C39/ftc93333H4MGDad++PV5eXvTq1YsPPvjAE09JRERERERERERExE2uCm0LFizIe++9x3vvvZfpPjabjdGjRzN69OhM9ylSpAhTpky5obE412+Li4u7ocfJLc6fP59nnqvkTqpRsTrVqFidalSsTjUqVqcaFatTjYrV5ZUadT5HZ7aYmVwV2lpJfHw8AGXLlvXwSERERERERERERCQ3iY+PJygoKNPbbY6rxbqSIbvdzpEjRyhYsCA2m83Tw7ml4uLiKFu2LAcPHqRQoUKeHo5IOqpRsTrVqFidalSsTjUqVqcaFatTjYrV5aUadTgcxMfHExoaipdX5suNaabtdfLy8qJMmTKeHkaOKlSo0G3/gyO5m2pUrE41KlanGhWrU42K1alGxepUo2J1eaVGs5ph65R5nCsiIiIiIiIiIiIiOU6hrYiIiIiIiIiIiIiFKLSVq/Lz82PEiBH4+fl5eigiGVKNitWpRsXqVKNidapRsTrVqFidalSsTjWanhYiExEREREREREREbEQzbQVERERERERERERsRCFtiIiIiIiIiIiIiIWotBWRERERERERERExEIU2oqIiIiIiIiIiIhYiEJbydJ///tfKlSogL+/P02aNGH16tWeHpKIy99//02PHj0IDQ3FZrPx+++/e3pIIi7jxo2jUaNGFCxYkBIlStCzZ0927Njh6WGJuHzyySfUqVOHQoUKUahQIZo1a8bMmTM9PSyRTI0fPx6bzcaQIUM8PRQRAEaOHInNZnO7VK9e3dPDEnFz+PBhHnnkEYoWLUpAQAC1a9dm7dq1nh6WiEuFChXSHUttNhvPPvusp4fmcQptJVM//PADL774IiNGjGD9+vXUrVuXzp07c+LECU8PTQSAhIQE6taty3//+19PD0UkncWLF/Pss8+ycuVK5s6dS1JSEp06dSIhIcHTQxMBoEyZMowfP55169axdu1a2rVrx913383WrVs9PTSRdNasWcNnn31GnTp1PD0UETc1a9bk6NGjrsvSpUs9PSQRlzNnztCiRQvy5cvHzJkziYqK4v/+7/8oXLiwp4cm4rJmzRq34+jcuXMBuP/++z08Ms+zORwOh6cHIdbUpEkTGjVqxEcffQSA3W6nbNmyPPfcc7zyyiseHp2IO5vNxm+//UbPnj09PRSRDJ08eZISJUqwePFi7rjjDk8PRyRDRYoU4e2332bAgAGeHoqIy7lz54iIiODjjz9m7Nix1KtXj/fee8/TwxJh5MiR/P7770RGRnp6KCIZeuWVV1i2bBlLlizx9FBEsm3IkCH89ddf7Nq1C5vN5unheJRm2kqGLl26xLp16+jQoYNrm5eXFx06dGDFihUeHJmISO4UGxsLmFBMxGpSUlL4/vvvSUhIoFmzZp4ejoibZ599lu7du7v9XSpiFbt27SI0NJSKFSvSp08fDhw44Okhibj8+eefNGzYkPvvv58SJUpQv359/ve//3l6WCKZunTpEpMnT+bxxx/P84EtKLSVTJw6dYqUlBRCQkLctoeEhHDs2DEPjUpEJHey2+0MGTKEFi1aUKtWLU8PR8Rl8+bNFChQAD8/P55++ml+++03wsPDPT0sEZfvv/+e9evXM27cOE8PRSSdJk2a8PXXXzNr1iw++eQT9u7dS6tWrYiPj/f00EQA2LNnD5988glVqlRh9uzZDBo0iOeff55JkyZ5emgiGfr99985e/Ys/fr18/RQLMHH0wMQERG53T377LNs2bJFfe7EcqpVq0ZkZCSxsbH8/PPP9O3bl8WLFyu4FUs4ePAgL7zwAnPnzsXf39/TwxFJp2vXrq6v69SpQ5MmTShfvjw//vij2syIJdjtdho2bMibb74JQP369dmyZQuffvopffv29fDoRNL74osv6Nq1K6GhoZ4eiiVopq1kqFixYnh7e3P8+HG37cePH6dkyZIeGpWISO4zePBg/vrrLxYuXEiZMmU8PRwRN76+vlSuXJkGDRowbtw46taty/vvv+/pYYkAsG7dOk6cOEFERAQ+Pj74+PiwePFiPvjgA3x8fEhJSfH0EEXcBAcHU7VqVXbv3u3poYgAUKpUqXQfxNaoUUNtPMSS9u/fz7x583jiiSc8PRTLUGgrGfL19aVBgwbMnz/ftc1utzN//nz1uhMRyQaHw8HgwYP57bffWLBgAWFhYZ4ekshV2e12EhMTPT0MEQDat2/P5s2biYyMdF0aNmxInz59iIyMxNvb29NDFHFz7tw5oqOjKVWqlKeHIgJAixYt2LFjh9u2nTt3Ur58eQ+NSCRzX331FSVKlKB79+6eHoplqD2CZOrFF1+kb9++NGzYkMaNG/Pee++RkJBA//79PT00EcD8YZx2JsPevXuJjIykSJEilCtXzoMjEzEtEaZMmcIff/xBwYIFXf3Ag4KCCAgI8PDoRODVV1+la9eulCtXjvj4eKZMmcKiRYuYPXu2p4cmAkDBggXT9QEPDAykaNGi6g8ulvDPf/6THj16UL58eY4cOcKIESPw9vbmoYce8vTQRAD4xz/+QfPmzXnzzTd54IEHWL16NRMnTmTixImeHpqIG7vdzldffUXfvn3x8VFU6aRXQjL14IMPcvLkSYYPH86xY8eoV68es2bNSrc4mYinrF27lrZt27quv/jiiwD07duXr7/+2kOjEjE++eQTANq0aeO2/auvvlJjfbGEEydO8Nhjj3H06FGCgoKoU6cOs2fPpmPHjp4emohIrnDo0CEeeughTp8+TfHixWnZsiUrV66kePHinh6aCACNGjXit99+49VXX2X06NGEhYXx3nvv0adPH08PTcTNvHnzOHDgAI8//rinh2IpNofD4fD0IERERERERERERETEUE9bEREREREREREREQtRaCsiIiIiIiIiIiJiIQptRURERERERERERCxEoa2IiIiIiIiIiIiIhSi0FREREREREREREbEQhbYiIiIiIiIiIiIiFqLQVkRERERERERERMRCFNqKiIiIiIiIiIiIWIhCWxERERGR62Cz2Rg5cqSnh5Glfv36UaFCBU8PQ0RERESukUJbEREREfGYzZs3c99991G+fHn8/f0pXbo0HTt25MMPP/T00HJchQoVuPPOOz09DBERERGxAIW2IiIiIuIRy5cvp2HDhmzcuJEnn3ySjz76iCeeeAIvLy/ef/99Tw9PRERERMRjfDw9ABERERHJm9544w2CgoJYs2YNwcHBbredOHHCM4MSEREREbEAzbQVEREREY+Ijo6mZs2a6QJbgBIlSrhd/+qrr2jXrh0lSpTAz8+P8PBwPvnkk3T3c7YYWLRoEQ0bNiQgIIDatWuzaNEiAH799Vdq166Nv78/DRo0YMOGDW7379evHwUKFGDPnj107tyZwMBAQkNDGT16NA6H46rP6fDhwzz++OOEhITg5+dHzZo1+fLLL7P/oqSxb98+bDYb77zzDhMnTqRSpUr4+fnRqFEj1qxZk27/33//nVq1auHv70+tWrX47bffMnxcu93Oe++9R82aNfH39yckJISBAwdy5swZ1z4jRozAy8uL+fPnu933qaeewtfXl40bN17XcxIRERGR7NFMWxERERHxiPLly7NixQq2bNlCrVq1stz3k08+oWbNmtx11134+Pgwbdo0nnnmGex2O88++6zbvrt37+bhhx9m4MCBPPLII7zzzjv06NGDTz/9lH//+98888wzAIwbN44HHniAHTt24OWVOpchJSWFLl260LRpU9566y1mzZrFiBEjSE5OZvTo0ZmO8fjx4zRt2hSbzcbgwYMpXrw4M2fOZMCAAcTFxTFkyJDrep2mTJlCfHw8AwcOxGaz8dZbb3HvvfeyZ88e8uXLB8CcOXPo1asX4eHhjBs3jtOnT9O/f3/KlCmT7vEGDhzI119/Tf/+/Xn++efZu3cvH330ERs2bGDZsmXky5eP119/nWnTpjFgwAA2b95MwYIFmT17Nv/73/8YM2YMdevWva7nIiIiIiLZ5BARERER8YA5c+Y4vL29Hd7e3o5mzZo5Xn75Zcfs2bMdly5dSrfv+fPn023r3Lmzo2LFim7bypcv7wAcy5cvd22bPXu2A3AEBAQ49u/f79r+2WefOQDHwoULXdv69u3rABzPPfeca5vdbnd0797d4evr6zh58qRrO+AYMWKE6/qAAQMcpUqVcpw6dcptTL1793YEBQVl+ByuHHv37t1d1/fu3esAHEWLFnXExMS4tv/xxx8OwDFt2jTXtnr16jlKlSrlOHv2rGvbnDlzHICjfPnyrm1LlixxAI7vvvvO7XvPmjUr3fbNmzc7fH19HU888YTjzJkzjtKlSzsaNmzoSEpKyvJ5iIiIiMiNU3sEEREREfGIjh07smLFCu666y42btzIW2+9RefOnSldujR//vmn274BAQGur2NjYzl16hStW7dmz549xMbGuu0bHh5Os2bNXNebNGkCQLt27ShXrly67Xv27Ek3tsGDB7u+ds6cvXTpEvPmzcvwuTgcDn755Rd69OiBw+Hg1KlTrkvnzp2JjY1l/fr12X1p3Dz44IMULlzYdb1Vq1Zu4z569CiRkZH07duXoKAg134dO3YkPDzc7bF++ukngoKC6Nixo9sYGzRoQIECBVi4cKFr31q1ajFq1Cg+//xzOnfuzKlTp5g0aRI+PjpZT0RERORW019cIiIiIuIxjRo14tdff+XSpUts3LiR3377jf/85z/cd999REZGukLHZcuWMWLECFasWMH58+fdHiM2NtYtrEwbzAKu28qWLZvh9rS9XAG8vLyoWLGi27aqVasCps9sRk6ePMnZs2eZOHEiEydOzHCf611c7crn4wxwnePev38/AFWqVEl332rVqrmFxbt27SI2NjZdz+DMxjh06FC+//57Vq9ezZtvvpkuBBYRERGRW0OhrYiIiIh4nK+vL40aNaJRo0ZUrVqV/v3789NPPzFixAiio6Np37491atX591336Vs2bL4+voyY8YM/vOf/2C3290ey9vbO8Pvkdl2RzYWGLsa5xgeeeQR+vbtm+E+derUua7HvpnjttvtlChRgu+++y7D24sXL+52fc+ePezatQuAzZs3X/P3ExEREZHro9BWRERERCylYcOGgDntH2DatGkkJiby559/us06TXsq/81kt9vZs2ePa3YtwM6dOwGoUKFChvcpXrw4BQsWJCUlhQ4dOtyScWWmfPnyAK5wNa0dO3a4Xa9UqRLz5s2jRYsWbi0nMmK32+nXrx+FChViyJAhvPnmm9x3333ce++9N2/wIiIiIpIh9bQVEREREY9YuHBhhrNFZ8yYAZhT+yF1pmnafWNjY/nqq69u2dg++ugj19cOh4OPPvqIfPny0b59+wz39/b2plevXvzyyy9s2bIl3e0nT568ZWMtVaoU9erVY9KkSW79fefOnUtUVJTbvg888AApKSmMGTMm3eMkJydz9uxZ1/V3332X5cuXM3HiRMaMGUPz5s0ZNGgQp06dumXPRUREREQMzbQVEREREY947rnnOH/+PPfccw/Vq1fn0qVLLF++nB9++IEKFSrQv39/ADp16oSvry89evRg4MCBnDt3jv/973+UKFHCNRv3ZvL392fWrFn07duXJk2aMHPmTKZPn86///3vdO0D0ho/fjwLFy6kSZMmPPnkk4SHhxMTE8P69euZN28eMTExN32sTuPGjaN79+60bNmSxx9/nJiYGD788ENq1qzJuXPnXPu1bt2agQMHMm7cOCIjI+nUqRP58uVj165d/PTTT7z//vvcd999bNu2jWHDhtGvXz969OgBwNdff029evV45pln+PHHH2/ZcxERERERzbQVEREREQ955513aNu2LTNmzODFF1/kxRdfZPXq1TzzzDOsWrWK4OBgwMy4/fnnn7HZbPzzn//k008/5amnnuKFF164JePy9vZm1qxZHDt2jKFDh7JmzRpGjBiR4ezUtEJCQli9ejX9+/fn119/ZfDgwbz//vvExMQwYcKEWzJWpy5duvDTTz+RkpLCq6++yq+//spXX33lajWR1qeffsrEiRM5ceIE//73v3n11VdZsGABjzzyCC1atCAlJYW+fftSrFgx3nvvPdf9qlSpwrhx4/jpp58U2oqIiIjcYjbHzVh5QURERETkNtCvXz9+/vlnt9mpIiIiIiI5TTNtRURERERERERERCxEoa2IiIiIiIiIiIiIhSi0FREREREREREREbEQ9bQVERERERERERERsRDNtBURERERERERERGxEIW2IiIiIiIiIiIiIhai0FZERERERERERETEQhTaioiIiIiIiIiIiFiIQlsRERERERERERERC1FoKyIiIiIiIiIiImIhCm1FRERERERERERELEShrYiIiIiIiIiIiIiFKLQVERERERERERERsRCFtiIiIiIiIiIiIiIWotBWRERERERERERExEIU2oqIiIiIiIiIiIhYiEJbEREREREREREREQtRaCsiIiIiIiIiIiJiIQptRURERETkltu3bx82m41+/fq5bW/Tpg02m80zg7pGFSpUoEKFCp4ehoiIiOQBCm1FRERExLL69euHzWbL9uXrr7/29JA9zhmOpr34+vpStmxZHn74YTZt2uTpId5UzhrZt2+fp4ciIiIictP4eHoAIiIiIiKZ6dmzZ7qZjYsWLWLx4sXcfffd1KtXz+22K6/nZZUqVeKRRx4B4Ny5c6xcuZKpU6fy66+/Mn/+fFq0aOHhERrffPMN58+f9/QwRERERCxFoa2IiIiIWFbPnj3p2bOn27aRI0eyePFievbsme5Ue0lVuXJlRo4c6bbt9ddf54033uC1115j0aJFHhnXlcqVK+fpIYiIiIhYjtojiIiIiOQgh8NBt27dsNls/PDDD+lu69q1a4a3ZYez32ZsbCyDBg2iVKlSBAYGcscdd7B+/XoAjhw5wiOPPEKJEiUICAigU6dO7Nq1K91j/fbbbzz00ENUrlyZ/PnzExQURKtWrfjll1/S7fv0009js9kYP358prdNmDDhmp/PtXL2Rr148SKvv/46lSpVIl++fK7gMqveqVmdYv/HH3/Qvn17ChcujL+/P7Vq1eKdd94hJSXlqmPav38/Xl5etGvXLsPbk5KSKFasGGXLlsVutwMQGxvL8OHDCQ8Pp0CBAhQqVIjKlSvTt29f9u/fn70XIxPPPfccAGvWrHFts9lstGnThsOHD/PYY49RsmRJvLy83ELdv//+mx49elCsWDH8/PyoUqUKr7/+eoYzZFNSUpgwYQKVK1fG39+fypUrM27cONfzu1JW/y9//PEHnTp1omjRovj7+1OhQgUeffRRtmzZApianzRpEgBhYWGudhBt2rRxe5y9e/fyxBNPUK5cOfz8/ChVqhT9+vXL9PX8448/aNSoEQEBAYSEhPDkk09y5syZjF9UERERkVtAM21FREREcpDNZuOrr76iTp06DBw4kKZNm1K+fHkA3nvvPWbNmkW/fv148MEHr+vxL126RMeOHbl48SIPPvggx48f58cff6RDhw4sX76czp07U6pUKR555BF2797NtGnT6N69O9u2bcPb29v1OK+++iq+vr60bNmSUqVKcfLkSf7880/uu+8+PvjgA1f4B/Cf//yHv//+m+HDh9O+fXsaNWoEmOD3s88+o127dgwdOtS1/759+wgLC6N8+fK3pA9pr1692LhxI126dCE4OJiwsLDrfqxXX32V8ePHU7p0ae69916CgoJYsmQJQ4cOZdWqVfz0009Z3r98+fLccccdLF68mEOHDlGmTBm322fMmMHp06f517/+hZeXFw6Hg86dO7Nq1SpatGhBly5d8PLyYv/+/fz55588+uijrnq5EVeGpKdPn6ZZs2YUKVKE3r17c/HiRQoVKgTAJ598wrPPPktwcDA9evSgRIkSrF27ljfeeIOFCxeycOFCfH19XY/11FNP8eWXXxIWFsazzz7LxYsXeffdd1m+fPk1jfGll17i3XffpUiRIvTs2ZMSJUpw8OBB5s2bR4MGDahVqxZDhgzh66+/ZuPGjbzwwgsEBwcDuLXUWLVqFZ07dyYhIYE777yTKlWqsG/fPr777jtmzpzJihUrqFixomv/b775hr59+1KoUCEeffRRgoOD+euvv+jQoQOXLl1ye64iIiIit4xDRERERHLczJkzHTabzdG8eXNHcnKyY8OGDQ5fX19HlSpVHPHx8df1mOXLl3cAjvvvv9+RlJTk2j5hwgQH4AgODnb84x//cNjtdtdtgwYNcgCOX375xe2xoqOj0z1+fHy8o3bt2o6goCBHQkKC222RkZEOPz8/R6VKlRzx8fGOgwcPOooUKeIoWrSo4/Dhw2777t271wE4ypcvf13Pc8SIEQ7A8dVXX7ltb926tQNw1KtXz3H69Ol093PenpG+ffs6AMfevXtd2+bMmeMAHJ07d3acO3fOtd1utzuefvppB+D4+eefrzrezz//3AE4JkyYkO62Xr16OQDHli1bHA6Hw7Fp0yYH4OjZs2e6fS9evJit2nC+vp07d0532/Dhwx2Ao23btq5tgANw9O/f35GcnOy2/9atWx0+Pj6OunXrOk6dOuV227hx4xyA45133nFtW7hwoQNw1K1b1+01O3TokKNYsWIOwNG3b1+3x8no/2XatGkOwFG7du103zcpKclx7Ngx1/WM/u+cLl265KhQoYKjYMGCjvXr17vdtmTJEoe3t7fjzjvvdG2LjY11FCpUyBEYGOjYsWOH2+PccccdN1S3IiIiItdC7RFEREREPKBLly688MILLF++nFdeeYWHHnoIh8PB1KlTKVCgwA099jvvvIOPT+oJVQ899BAAycnJjB071m2WpfO2jRs3uj1G2pmHTgUKFKBfv37Exsa6nV4PULduXSZMmEB0dDSDBg3i0UcfJSYmhi+//JLQ0FC3fUuXLs22bduYP3/+DT3PzIwaNYoiRYrc8ON89NFHAEycOJHAwEDXdmcrCJvNxtSpU6/6OPfddx/+/v5MnjzZbfvZs2f566+/qFevHjVr1nS7LSAgIN3j+Pn5XVNt7N69m5EjRzJy5EiGDh3KHXfcwejRo/H39+eNN95w29fX15e33nrLbbY1wGeffUZycjIffvghRYsWdbvt5Zdfpnjx4m6vwTfffAPA8OHD3V6z0qVL88ILL2R77B9//DEA77//frrv6+PjQ0hISLYe56+//mLfvn0MHTqU+vXru93WsmVL7r77bmbMmEFcXBwAv//+O3FxcTz++ONUrVrVtW++fPnSvWYiIiIit5LaI4iIiIh4yPjx41m0aBHvvPMOABMmTKBBgwY39JiFCxdOt7BTqVKlAKhSpQr58+fP8LYjR464bT9x4gTjx49n5syZ7N+/nwsXLrjdfuX+AM8//zyzZ892hZODBg3irrvuSrdfvnz5qF69+jU+s+xr3LjxTXmclStXEhgYyJdffpnh7QEBAWzfvv2qjxMUFMRdd93Fjz/+yMaNG6lbty4AP/30E4mJiTz66KOufWvUqEGdOnWYOnUqhw4domfPnrRp04Z69erh5XVt8y2io6MZNWoUYF7zkJAQHn74YV555RVq167ttm9YWBjFihVL9xgrV64EYPbs2RmG7Pny5XN7DZzhf6tWrdLtm9G2zKxevRo/Pz9at26d7ftkxDn+HTt2pFuUDeDYsWPY7XZ27txJw4YNsxx/s2bN3D4MEREREbmV9FeHiIiIiIf4+fnRtWtXIiMj8ff354knnrjhx3T2IU3LGTRldVtSUpJrW0xMDI0aNeLAgQO0aNGCDh06EBwcjLe3N5GRkfzxxx8kJiameyybzUbPnj2ZOXMmgFvf25yU3VmYVxMTE0NycrIr+MxIQkJCth7r0Ucf5ccff2Ty5Mmu0Pbbb7/F29ubhx9+2LWfj48PCxYsYOTIkfzyyy+89NJLABQvXpzBgwfz2muvpZsNm5nOnTsza9asbO2b2WsWExMDkO1ZprGxsXh5eWUYAF/L/0tsbCylS5e+5qD6Ss7xf/fdd1nu5/x/jI2NBaBEiRLp9vH29k4361dERETkVlF7BBEREREPWbVqFW+//TZFixbl4sWLDBo0yNNDAuCLL77gwIEDjBkzhqVLl/Lhhx8yZswYRo4cSdOmTTO93969exk6dChFihTBZrPxxBNPkJKSkoMjN65cZMvJGQAmJyenu80Z1qVVqFAhihYtisPhyPSyd+/ebI2pS5curlYCdrudffv2sXTpUjp06EDJkiXd9i1atCgffvghhw8fJioqio8++ogiRYowYsQI3nrrrWx9v2uV2WvmDPrj4uKyfB2cgoKCsNvtnDp1Kt1jHT9+PNvjCQ4Ods2CvRHO8U+bNi3L8Ttn9AYFBQFmpvmVUlJSOH369A2NR0RERCS7FNqKiIiIeEB8fDz/z959h0VxfQ0c/y69SBMFK/aCvSv2AiKoMVGT10SjMUVjjDXNNHs0Mc1UTdUkxpif0RQUC9gL9hJRsSvGiijFQt15/7iysAqKCOwA5/M8+8je2Z05rIdhOXvn3KeeegobGxvWr19Pv379+N///pfjpfiF6cSJEwD06dPnrm2bNm3K9jlpaWkMHDiQxMREfv/9d8aPH8/WrVvvOUu1sHl4eABw7tw5s3Gj0XhXT1+A1q1bExsby7Fjxx762DY2NgwYMIBz586xbt06fv31VzRNY9CgQTk+x2Aw4Ovry8iRIwkLCwPgn3/+eehYHkTr1q2BzDYD95Mxizi7PMkpd7LTqlUrkpOT2bBhw30fmzHzOLsPCDLij4iIyNVx7xV/REREtgV/IYQQQoiCIEVbIYQQQggLeOmllzh58iQfffQRDRo04LvvvqNy5cqMHj2ao0ePWjS2KlWqALB582az8YULFxIaGprtc6ZMmUJERASvvPIK/v7+zJgxg2bNmjFjxoy7CmCpqalERUWZisOFpWXLlgDMnz/fbPyTTz7Jdsbs6NGjAXj22WeznWF58eJFDh8+nOvjZ/Su/eWXX/jll19wdnbmscceM3vM6dOnOX369F3PzZil6uDgkOvj5YeXXnoJGxsbRo0aRXR09F3b4+Li2Lt3r+l+xvc4depUs9YR586d47PPPsv1cUeOHAnAmDFjTC0OMqSlpZnN2s1YdO7s2bN37adPnz74+PjwySefsHHjxru2p6ammuV5nz59cHV15ccffzT7OUxNTeWdd97JdfxCCCGEEA9LetoKIYQQQhSyBQsWsGDBAnr37m0qTnl4eLBgwQK6dOnCU089RUREBLa2thaJ7+mnn+aDDz5g1KhRrFu3jipVqrB//37WrFlD3759Wbp0qdnjN27caCrSZvQ+tbOzY+HChTRv3pxBgwaxf/9+3N3dAVXA8/X1pUqVKtkWKAvK0KFDmTVrFpMnT2bfvn3UqFGDXbt2ERkZSadOne6a1dmjRw/effddpk2bRs2aNenRowdVqlQhNjaW48ePs2nTJqZPn46vr2+ujt+yZUvq1KnDwoULSU1N5emnn8bZ2dnsMfv27aNv3760atWKevXqUa5cOc6dO8dff/2FlZUV48aNy7fXIzcaNGjA119/zYgRI6hTpw7BwcHUqFGDxMRETp48yYYNG3jmmWeYO3cuAF26dGHo0KHMmzePhg0b8thjj5GcnMzvv/9OmzZtWLZsWa6OGxwczKuvvspHH31ErVq1eOyxx/Dy8uLcuXOsWbOGV199lbFjxwLQtWtXPvroI4YNG0a/fv1wdnamSpUqPP3009jb2/PHH38QFBREp06d6Nq1Kw0bNsRgMHDmzBk2bdqEp6enaTE1Nzc3Pv/8c5555hlatmzJgAEDcHNzY9myZTg6OpoW7hNCCCGEKHCaEEIIIYQoNCdPntRcXV218uXLazExMXdtf/vttzVAe/XVVx9431WqVNGqVKmS7TZA69Sp013jp06d0gBtyJAhZuP79u3Tunfvrnl4eGguLi5ap06dtPDwcG3evHkaoM2bN0/TNE27evWqVrlyZc3Z2Vk7cuTIXfv/7rvvNEDr37//XcfMKdb7mTRpklkMGTp16qTd7+3tvn37tG7dumlOTk6aq6ur1qdPH+3YsWPakCFDNEA7derUXc8JCwvTevfurZUtW1aztbXVypUrp/n5+WnTpk3ToqOjHyj26dOna4AGaKtWrbpr+9mzZ7UJEyZobdq00by8vDQ7OzvNx8dH69u3rxYREZGrY2S8voGBgbl6fE65kdWOHTu0AQMGaBUqVNBsbW21MmXKaM2aNdMmTJigHT582OyxaWlp2syZM7Xq1atrdnZ2WvXq1bUZM2Zox48fzzbX7vX/tmTJEq1Lly6am5ubZm9vr1WtWlV7+umntcjISLPHzZo1S6tVq5Zma2ub7ffz33//aWPGjNFq1aql2dvba66urpqvr6/2/PPPa2vWrLnruH/++afWvHlzzd7eXvPy8tKef/557erVq/f8GRNCCCGEyE8GTcuycoAQQgghhBBCCCGEEEIIi5KetkIIIYQQQgghhBBCCKEjUrQVQgghhBBCCCGEEEIIHZGFyIQQQgghdOqvv/5i3759931c586d6dy5c4HHI4QQQgghhCgcUrQVQgghhNCpv/76i59++ilXj5WirRBCCCGEEMWHLEQmhBBCCCGEEEIIIYQQOiIzbfPIaDRy/vx5XFxcMBgMlg5HCCGEEEIIIYQQQgihc5qmkZiYSIUKFbCyynm5MSna5tH58+epXLmypcMQQgghhBBCCCGEEEIUMWfPnqVSpUo5bpeibR65uLgA6gV2dXW1cDQFb8WKFQQFBVk6DCFyJDkq9E5yVOid5KjQO8lRoXeSo0LvJEeF3pWUHE1ISKBy5cqm2mJOpKdtHiUkJODm5kZ8fHyJKNrGxsbi6elp6TCEyJHkqNA7yVGhd5KjQu8kR4XeSY4KvZMcFXpXUnI0tzXFnBsnCJHFvXpsCKEHkqNC7yRHhd5Jjgq9kxwVeic5KvROclToneSoOXk1RK5s3rzZ0iEIcU+So0LvJEeF3kmOCr2THBV6Jzkq9E5yVOid5Kg5KdoKIYQQQgghhBBCCCGEjhS5ou25c+cYNGgQnp6eODo60rBhQ3bt2mXarmkaEydOpHz58jg6OuLv78+xY8fM9nH16lUGDhyIq6sr7u7uPPfcc1y/fr2wvxUhhBBCCCGEEEXV5MkwbVr226ZNU9uFEEKIPCpSRdtr167Rrl07bG1tWbFiBYcOHeLjjz/Gw8PD9JhZs2bx+eefM3fuXLZv346zszOBgYEkJSWZHjNw4EAOHjxIWFgYy5YtY+PGjQwbNswS31KR0ahRI0uHIMQ9SY4KvZMcFXonOSr0TnJU6I61NUycaCrcmnJ02jQ1bm1tweCEuJucR4XeSY6aM2iaplk6iNyaMGECW7ZsYdOmTdlu1zSNChUq8Morr/Dqq68CEB8fj7e3N/Pnz2fAgAEcPnyYevXqsXPnTlq0aAHAypUrCQ4O5r///qNChQrZ7js5OZnk5GTT/YSEBCpXrnzfld6Ki9TUVGxtbS0dhhA5khwVeic5KvROclToneSo0KWMAu2UKaS+8Qa2s2ap+1OnwrvvWjo6IczIeTR/paenk5qaaukwipWinqM2NjZYW1tjMBju+biEhATc3NzuW1O0ye8AC9I///xDYGAgjz/+OBs2bKBixYq89NJLvPDCCwCcOnWKixcv4u/vb3qOm5sbrVu3JiIiggEDBhAREYG7u7upYAvg7++PlZUV27dv57HHHsv22DNnzmTKlCl3ja9YsQInJycAAgICiI2NZc+ePabtfn5+2NjYmBWaGzVqRMWKFVmxYoVprHr16tSvX5+wsDDTrGAvLy9T7FeuXAHAycmJbt26ceDAAU6fPm16fs+ePTl9+jQHDx40jXXq1ImkpCS2b99uGmvRogVubm6sWbPGNFa3bl1q1arF8uXLMRqNAFSuXJkmTZqwfv16EhMTMRqNeHp60r59e3bt2sWFCxcAsLW1pUePHkRFRZm1oejevTsxMTHs3bvXNNa2bVusrKzMGks3atSIChUqsHLlStNYjRo1qFevHqtXrzYVyr29vWnVqhVbt24lNjYWAGdnZ7p27cr+/fuJjo42Pb93796cOHGCQ4cOmca6dOnCjRs32LFjh2msZcuWuLi4sHbtWtOYr68vNWvWZNmyZWR8nuHj40Pjxo1NrwVA6dKladeuHTt37uTixYsA2NnZERgYyOHDhzl+/Lhpn4GBgVy6dIl9+/aZxtq1awfAli1bTGNNmjTB29ubVatWmcZq1qyJr68vq1atIiUlBYBy5crRsmVLtmzZwtWrVwFwcXGhc+fOZq+FwWCgV69eHD9+nMOHD5v22bVrVxITE9m5c6dprFWrVjg7O7Nu3TrTWL169ahRowYhISGmsYzXYu3atdy4cQMAT09P2rZty44dO7h06RIA9vb2dO/enUOHDnHixAnT83v06MH58+f5999/TWPt27fHaDSydetW01jTpk0pW7Ysq1evNo3VqlWLunXrsnLlStMvxvLly9OiRQs2b95MbGwsVlZWptdi3759nD17FlArUPbs2ZNjx44RFRVl2me3bt2Ij483a7HSunVrHBwc2LBhg2msfv36VK1aleXLl5vGqlatSsOGDVmzZg03b94EoEyZMvj5+bF9+3YuX74MgIODAwEBARw8eJCTJ0+anh8UFMS5c+fMXosOHTqQlpZGRESEaaxZs2Z4enoSFhZmGqtduzZ16tRhxYoVpKWlAVChQgWaN2/Opk2biIuLA9T5r2PHjuzZs4dz584BYG1tTXBwMEePHuXIkSOmffr7+3Pt2jV2795tGmvTpg329vZmr0WDBg3w8fEhNDTUNFatWjUaNGhAeHg4t27dAqBs2bK0adOGbdu2ERMTA2BqWRMZGcmpU6dMzw8ODiY6OprIyEjTWKdOnUhOTmbbtm2msebNm+Ph4UF4eLhprE6dOtSuXZvQ0FDS09MBqFixIs2aNWPjxo3Ex8cD4O7uTocOHdi9ezfnz58H1C/UoKAgjhw5wtGjR037LKhzeWhoqGk1VEudywE8PDzkXC7n8mzP5bGxsXh7e1v0XH7t2jWz10LO5XIuz3ouNxqN9OnTx6Lncj28Lwc5l+vqXP7uu1zYtYvykyZhO2mSevCYMex/5BGiQ0KoHBZG+YgIvKtXJ17TiE1KIs3RkTRHR2o0bkxc9+7suH1esb96lWZVquDo5cWmfftIc3BAs7Utcu/L5Vyu33P5pUuXsLKyKvHvy/PjXF6qVClKlSqFo6MjBoPB7OpuW1tbbG1tuXXrlun8ZWNjg52dHUlJSabzu5WVFQ4ODiQnJ5teM4PBgKOjI6mpqWYFYUdHR9LT003nH1A/33ce287ODmtra9P/f07xWFtbY29vb3bsjHhSUlJM+ZzxGt0Zj4ODA5qmmU1uzC6e3L4WGfFk/Aw/6Gvh4OAAUKCvRU7xZH0tNE0jLS2NcuXK4enpyfr1602Py3ouz/p93kuRmmmb8Z8wfvx4Hn/8cXbu3MmYMWOYO3cuQ4YMYevWrbRr147z589Tvnx50/OeeOIJDAYDv//+OzNmzOCnn34yOymC+uGdMmUKI0aMyPbYJX2mbUhICL1797Z0GELkSHJU6J3kqNA7yVGhd5KjQpciI6FjR7hdqATg7FmoVEl9PX48fPppzs8/eBDq1VNfT5qkZuhmZWcHpUqBiwv88w9kXDocEgJ//JG57c5/u3SBsmXVYxMT4eZNtc3JCe4zA0wUX3IezR8XLlwgLi4OLy8vnJyc7jurUuReQkJCka2xZRRsExISSEhIwN3d3aw2mVWxnGlrNBpp0aIFM2bMANSnfpGRkaaibUGyt7fH3t6+QI8hhBBCCCGEEKKIOH4cAgJMBVujjQ1WaWnwww+qAAvw1FPQsKEqnF6/fve/Zcpk7s/WVt1PTISMCUMpKXD1qrpl7ZG7dy/8/HPOsW3Zklm0/f57VTwGVbAtVcq8yDtnDrRqpbZv3gxLl5oXgLN+3bgxeHqqx6amqv3ZFKmyghAPJT093VSw9cz4WRD5JikpyTRhs6hycXHB3t6eK1eu4OXlhfVD9DcvUmfX8uXLUy/jU8jbfH19WbJkCaAuTwG4dOmSWTX70qVLNGnSxPSYjMsjMqSlpXH16lXT88XdatSoYekQhLgnyVGhd5KjQu8kR4XeSY4KXfnvP/D3h9stGXjzTaIGDaLekiWqp62Vlepp26KFuuXGO++oG6iC6J1F3urVMx8bEACOjpnb7iwGZxRsIbMADKBpmY+/3VqDrD05d+++98zg0FAIClJfL1gAzz4LDg7Zz/idOBFut58gMlLNFM5uVnCpUlC1Kri55e51Enkm59GHl3FZfEabTJG/istkSWdnZ2JiYkhNTS05Rdt27drd1dbg6NGjVKlSBVD9W8qVK8eaNWtMRdqEhAS2b99uanvg5+dHXFwcu3fvpnnz5gCsXbsWo9FI69atC++bKWLuLJYLoTeSo0LvJEeF3kmOCr2THBW6smsXZPTvfe01mDGDepDZ6mDiRPVvXhcjs7UFDw91y46fn7rlxoQJ8PrrqkVCdrN9s/5sNW+uHpvd4xITzWcGX7+u/k1KUrfbPUJNRo/O/Hr3bnj77ZxjXLgQnnxSff333zBkyN2F3YyvX3wROnRQjz1zBlatyrlNhKenKioLQM6j+UlaIhQMR0dHS4eQL/IrP4pU0XbcuHG0bduWGTNm8MQTT7Bjxw6+/fZbvv32W0C9KGPHjmX69OnUqlWLatWq8e6771KhQgUeffRRQM3M7dGjBy+88AJz584lNTWVl19+mQEDBlChQgULfnf6tnr1arp3727pMITIkeSo0DvJUaF3kqNC7yRHha48+igMGADly8OsWUCWHM0o1N5e0EYXrKwyC5/3usK0fXt1y40XX1TtH7IWdrN+3bRp5mOrV4fnnst+VnBionlxOj4+85adnj0zv967F4YPzznGOXNUnKBaRgwefHfLh4x/+/fPLAZfuQIbNuTcJsLOrmj0Bp48WbXVuJ2TZufRadNUjk6ebLHwhLhTfHw8bjLr3qRIFW1btmzJn3/+yZtvvsnUqVOpVq0as2fPZuDAgabHvP7669y4cYNhw4YRFxdH+/btWblypVlPjF9//ZWXX36Zbt26YWVlRb9+/fj8888t8S0VGVkXYRNCjyRHhd5Jjgq9kxwVeic5Kizu5k1ISMgsei5caLbZLEfzOsO2KLG1VTNZc9PXs0OHzILo/fTtC23aZF/cTUxUs4EzlCkDjzySfeE4MVEVWDPExsLJkzkft06dzBgjI1URNyfvvw9vvKG+PnRItYnIabZv166ZbSJu3FCztO98nLOzKqznN2trs1nfphydNk2N37nwnRAWpmmapUPQlSJVtAXo1asXvXr1ynG7wWBg6tSpTL3Hyad06dIsvOMXrBBCCCGEEEIIka2UFOjXD44ehfBwqFbNtGnpUpgyBQ4fDsbXV61B1revBWMt6kqVgtq1c/fYe80M1jR1y9Chg5ptm9OicFl7Dzs6qkLrnY+5dSszxgwxMbB9e84x2thkFm2PHYPOnbN/nLOzamWR0df43DkYNiz7QrCLCzRrBhktHlNTVW5m3W5rm/nhQUbhtkkT84JtSfhwQYgirMgVbYVleHt7WzoEIe5JclToneSo0DvJUaF3kqPCYtLTYeBAWLkSnJzU4mO3i7ZLl6parsEAmmbNgQPq/pIlUri1OIPBvIWBhwe0bZu757ZuDZs33z2elqaKt3Z2mWP166s+vNnNCr5+XRVXM2iamtGbdVaw0ai23bhhHu+VK2rht5y8/npm0fa//6BBA/PtdnaZhd6uXWHiRHra2qoCrxRsxR1y24N13bp1dM7pg4d8YGtrW2D7LoqkaCtypVWrVpYOQYh7khwVeic5KvROclToneSosAijUc12/OMPVQT76y+zBcCmTMko2Kr7Gf8OGqQeltMkyXuNubio2nBBXC0vHpKNDbi7m49ltGjIjaZNISoq876mqdm7GYXerL08K1aEH37IeVG4xo0zH5ucrOJITFRfg5odHhurbk88AZs3Y5WSovK4X788ffui+Prll1/M7v/888+EhYXdNe7r61ugcTg7Oxfo/osaKdqKXNm6dSttc/uppBAWIDkq9E5yVOid5KjQO8lRUeg0DV55BX78UVVQFy2CgACzh0RFmV+Bn+HWLVi7Nu+HNhjU1fI5FXXvV/TNrr2qjfz1rz8Gg6rQOzmBl5f5tjJlVK/c3KhbV7VpADWT9s5F4RYtgpQUjLa2qnDbsCFMnw6vvSaJIQAYNGiQ2f1t27YRFhZ21/idbt68iZOTU77Fcf36dUplbT9SwslPp8iV2NhYS4cgxD1Jjgq9kxwVeic5KvROclQUuqlTYfZs9fWPP8Jjj5ltPnBAdU64k8EAVauqmlhOa2ndayyjFWtG3e3ixfz5dhwcHqzQe7/t9vb5E5fIZ7a2qhWEh4e6P20afPopTJ3K8saN6f3mm2rxtLfeUjPHf/pJFX2FuI/OnTtz5coVfvrpJ8aNG8euXbsYNmwYs2fPxmAwMGnSJCZPnmz2nKpVq9K5c2fmz59vGouLi2Py5MksWbKEy5cvU7lyZV544QVee+010tLSCveb0jkp2gohhBBCCCGEEFnduKFmJwJ8/jkMGWK2OTJStQnNKNpmtEjI+Pfjj++q8eaKpsHNmw9e6M1pe2KiasMKkJSkbhkTMh+Wre2DF3rvtd3Jybylq8gHdy46FhKikrd/f9WQeccO1bJhxgwYM0Z6clhQxoKGR4+qdfj0uqBhbGwsQUFBDBgwgEGDBj1wv/mbN2/SqVMnzp07x/Dhw/Hx8WHr1q28+eabXLhw4a6ib0knRVuRK9JXROid5KjQO8lRoXeSo0LvJEdFoXJ2ho0b1QJTzz9vtungQVWwvXIFmjeH0aPhk0/g0KF06tWzZtKkvBVsIbMtgrMz5Nfae8nJeZvxm9P2pCS139RUuHZN3fKDlZUq3uZXIdjZGayt8ye2Iis93WzRMWdnZ5VkS5bAq6+qmbYnTsD48ZmzbqtWtWTERVLGhy159fffaq3DjA99MhY0/PVX6NMnb/ssqA9BLl68yNy5cxk+fHienv/JJ59w4sQJ9u7dS61atQAYPnw4FSpU4MMPP2TYsGG439k3ugSToq3Ila5du1o6BCHuSXJU6J3kqNA7yVGhd5KjolCcPw8VKqivy5a9q2B76JAq2MbEQLNmEBamrkIfPBhAnxVCe3t1K1Mmf/aXlmbeMvVBCsE5jYFa8y0hQd3yi5PTgxV971cILnIL298xa9HsPPrRR/Dhh/Ddd6pou2tX5rRs8UBu3lQ58rDuXNBw4MC87+v6dfXBRX6zt7dn6NCheX7+4sWL6dChAx4eHly5csU07u/vz/vvv8/evXupV69efoRaLEjRVuTK/v37aZx1dUohdEZyVOid5KjQO8lRoXeSo6LAhYaq65G//PKuYi2ogm2XLnD5srqiPKNgm6Gk5KiNDbi7q1t+MBpV0Ss/ZgFnfJ3RtuLmTXW7dCl/YrWze/DZv/cqBDs4FE5LiIxL76OijNSta5V56b3BAMOGqQX2/v0XatbMfFJiogpUiCwqVqyInZ1dnp9/7Ngx/v33X8qWLZvt9v/++y/P+y6OpGgrciU6OrpEvAERRZfkqNA7yVGhd5KjQu8kR0WB2rhRXY+cnAxr1sBzz5lV0w4fVjNsL1+GJk0gPBxKlzbfheRo3mRti5AfNC2zJUR+FYKTk9W+U1IgNlbd8oO1dd7aQOT0HCenu9vSLl2qUltdem9luvR+yZIsPVOrVVO3DBs2qB4fs2fD009Ls+H7cHLKnDGeF23aqLYrGTNsQb3kDRpARETeYyoIjo6OD/T49DtWazQajQQEBPD6669n+/gH7ZFb3EnRVgghhBBCCCFEybV7N/TqpZq19uwJP/9sVqSKilIzbC9dgsaNsy/YCv0wGNQMVgcH1eEiP6Sm5l87iMTEzP6n6ekQH69u+SGjJ3LWQu6RI2pb1kvvDQbV6jbHha7mzFHNiocMUVXfb77JvybLxVDG655XU6ZkLaxn/jtlSsG0OCgIHh4exMXFmY2lpKRw4cIFs7EaNWpw/fp1/P39s93Pnfso6aRoK4QQQgghhBCiZDp0CAIDVSWtc2dYvNiscemRI5kF20aNVMHW09Ny4QrLsLVVrTCytsN4GOnpcONG/rWDuH5dtZnQtMx+wxcv5nx8Tcss5mZrwQI1pXziRLVK1ubNqpD7+OP58wIIM337qpnPU6eq/5c6dXioBQ0toUaNGmzcuNFs7Ntvv71rpu0TTzzB5MmTWbVqFYGBgWbb4uLiSJO+ymYMmpZ1ArbIrYSEBNzc3IiPj8fV1dXS4QghhBBCCCGEeBCnTkH79mrxsZYtVVuELD08Mwq2Fy6ogu2aNfm3mJcQ+UnT4Nat7Iu6L74IZ8+aX3oPKqf377/Pjg8cUKvs7dun7g8YoHo+l+BPLpKSkjh16hTVqlXDwcHB0uEUmJdffpmvvvqKrCXDzp07c+XKFSIjI+96/DfffMOLL75I3759CQgIYP/+/axatYrExER69uzJ/PnzAbh58yYdOnTg33//5ZlnnqF58+bcuHGDAwcO8Mcff3D69GnKFIMT7f3yJLc1RasctwiRxYkTJywdghD3JDkq9E5yVOid5KjQO8lRke9+/10VbBs0gBUrzAq2R49mFmwbNsxdwVZyVFiKwaB6mHp7Q40aapJshw4QFASffpp5yf2dz0lIuM+OGzaE7dvVjFtra1i0CFauLKhvQxRhL7zwAm+88QYbN27klVde4dSpU4SFheF8R38HJycnNmzYwGuvvcb69esZM2YM77//PseOHWPKlCnY29tb6DvQJ5lpm0clbaZtSEgIvXv3tnQYQuRIclToneSo0DvJUaF3kqMi32kafPGFuuS7fHnT8LFjqlNCRj137drc9UaVHBV6tXSpuvT+0KF0KlWy5vx5tbha48awfDlUrJiLnezaBb/9Bh99lFkBzq4aXMyVlJm2lhIXF4e7u7ulw3hoMtNWCCGEEEIIIYR4EImJqloFqtg0erRZwfb4cTXD9vx5qF9fzbDNr8WshLCUvn1Vh4MlS0I5eRK2bFGzcvfvBz8/OHgwFztp0QI+/jizSHv1qnpyeHhBhi5EiSZFWyGEEEIIIYQQxd+tW9C7t7rduHHX5uPH1Qzbc+egXj01w9bLq/DDFKKgNW8OERFqwauzZ6FdO1i37gF38t57qnVCQACMHKka6Aoh8pUUbUWudOnSxdIhCHFPkqNC7yRHhd5Jjgq9kxwVDyUlRbVB2LABtm2DkyfNNp84oWbYPkzBVnJU6F3WHK1WDbZuVWvxxcdDYCAsXPgAO5s6VRVrAb7+WjXS3bw5X+MVJY9Llt7iQoq2IpduZPNJtBB6Ijkq9E5yVOid5KjQO8lRkWfp6TB4sGre6eCg/m3Y0LT55ElVsP3vP/D1VQVbb+8HP4zkqNC7O3O0dGkIC1OfZ6SmwsCB8P77qlXtfTk7w5dfqvYIlSurTz46doRXX1Wz2oXIA6PRaOkQdEWKtiJXduzYYekQhLgnyVGhd5KjQu8kR4XeSY6KPNE0ePFF+P13sLVVKzJ16GDafPKkaolw9izUrZv3gi1Ijgr9yy5HHRxg0SIYP17df/NNNYE2LS2XO+3WDQ4cgGefVT9vH38MkyfnW8yiZJEPv8xJ0VYIIYQQQgghRPGjafDaa/D992BlBb/+CkFBps2nTqkZtmfPqt6ea9dCuXIWjFcIC7GyUrXWzz5T64zNmaMWL8t1/czNDX74AUJCVMPcCRMKNF4hSgop2gohhBBCCCGEKH7OnoXvvlNff/edugb8ttOnVcE2OloVbNetg/LlLROmEHoxejT88YeafRsSon5GLl9+gB306gU7d4KHh7qvafD66/DvvwUSrxDFnRRtRa60bNnS0iEIcU+So0LvJEeF3kmOCr2THBUPzMdHVWO//lpdun3b6dOqJcKZM1C7dv4VbCVHhd7lJkf79oU1a8DTU9Vf/fzg6NEHOIjBkPn1ggXw4YfQogXMnPkAPRdESeXs7GzpEHRFirYiV2QFP6F3kqNC7yRHhd5Jjgq9kxwVuZaQkPl1s2YwYoTp7pkzavbgmTNQq1b+zrCVHBV6l9scbdsWtm6F6tVV3+eM+w+se3d45BG1ytlbb0G7dhAVlYcdiZLCykrKlFnJqyFyZe3atZYOQYh7khwVeic5KvROclToneSoyJWlS6FGDYiIuGtTdLQq2J4+nVmwrVAh/w4tOSr07kFytHZt9WPUsiXExqr1xv788wEP6O0Nf/0FP/2k+t7u2AFNm8Ls2WA0PuDOREmQmJho6RB0RYq2QgghhBBCCCGKvtWrYcAAuHJFLTqWRXS0aolw6hTUrKkKthUrWiZMIYoKLy/1s9K7NyQlQb9+8PnnD7gTgwEGD4bISDXzNikJxo2DoUMLJGYhihMp2gohhBBCCCGEKNq2bIFHH1WXYT/+OHz2mWnT2bNqhu2pU2oSrhRshcg9Z2c1gX3ECLWu2Jgx8MoreZgoW6kSrFwJc+eCiws891yBxCtEcSJFW5Ervr6+lg5BiHuSHBV6Jzkq9E5yVOid5KjI0d69EBwMt25Bjx5q8SNrawD++08VbE+eVP05161TtaOCIDkq9C6vOWpjA199pdYSA/jkEzWpPSnpAXdkMMDw4Wrqe8eOmeMhIeqHVZR4jRs35plnnjHdX79+PQaDgfXr11sspjtVrVrVLMaCJEVbkSs1a9a0dAhC3JPkqNA7yVGhd5KjQu8kR0W2oqIgMFAtPtahAyxZAnZ2AJw7p1oinDihCrbr10PlygUXiuSo0LuHyVGDASZMUJ1HbG1h8WIICICrV/OwM3f3zK+PHVMV4AYN4Oef1XReYTHz58/HYDCYbg4ODtSuXZuXX36ZS5cuFfjxDQZDvuwnNDSUyZMn58u+LEmKtiJXli1bZukQhLgnyVGhd5KjQu8kR4XeSY6KbM2YATEx0KyZmq3n5ASYF2yrVVMzbAuyYAuSo0L/8iNHn3oKVq1S64pt3gzt2qnF/fLMYICGDSE+HoYMgcceg0IoDop7mzp1Kr/88gtffvklbdu2Zc6cOfj5+XHz5s0CPa7xjr4bHTt25NatW3TMOjM7F0JDQ5kyZUp+hmYRUrQVuaLJp11C5yRHhd5Jjgq9kxwVeic5KrL17bcwdqzqlenmBqiCbZcucPw4VK2qCrY+PgUfiuSo0Lv8ytEuXVTBtnJlNdm9TRvYvTuPO6tZU+1sxgw1hffvv6F+fTWVtySYPBmmTct+27RparsFBAUFMWjQIJ5//nnmz5/P2LFjOXXqFH///Xe2j79x40aBxGFlZYWDgwNWViWzfFnkvuvJkyebTdU2GAzUrVvXtD0pKYmRI0fi6elJqVKl6Nev311TuKOjo+nZsydOTk54eXnx2muvkZaWVtjfihBCCCGEEEKIB3XrVuYl1A4O8OmnULYsAOfPQ9eu6orrqlVVS4QqVSwWqRDFVoMGEBEBjRqpibGdOkFoaB53ZmMDb74Ju3ZB48YQGwtPPAFPP1382yVYW8PEiXcXbqdNU+O3+3NbWteuXQE4deoUzzzzDKVKleLEiRMEBwfj4uLCwIEDATVTdvbs2dSvXx8HBwe8vb0ZPnw4165dM9ufpmlMnz6dSpUq4eTkRJcuXTh48OBdx82pp+327dsJDg7Gw8MDZ2dnGjVqxGe3F6B85pln+OqrrwDMaocZ8jvGgmRTqEfLJ/Xr1yc8PNx038Ym89sYN24cy5cvZ/Hixbi5ufHyyy/Tt29ftmzZAkB6ejo9e/akXLlybN26lQsXLjB48GBsbW2ZMWNGoX8vRYVPYXw0LcRDkBwVeic5KvROclToneSoACAxEfz91SJGs2apS6tvu3BBzQA8elQVatetK9yCreSo0Lv8ztGKFWHTJujfH8LC4JFHYM4ceOGFPO6wUSPYsUMVLGfOVM2o86nHaaG412xTa2v1IdOdjx0/HlJSVIE2JUU1Dv7gA/UaTJ0K77577/1aWYGjY+b9mzdNbWLy04kTJwDw9PQEIC0tjcDAQNq3b89HH32E0+1jDh8+nPnz5zN06FBGjx7NqVOn+PLLL9m7dy9btmzB1tYWgIkTJzJ9+nSCg4MJDg5mz549dO/enZSUlPvGEhYWRq9evShfvjxjxoyhXLlyHD58mGXLljFmzBiGDx/O+fPnCQsL45dffrnr+YURY77RiphJkyZpjRs3znZbXFycZmtrqy1evNg0dvjwYQ3QIiIiNE3TtNDQUM3Kykq7ePGi6TFz5szRXF1dteTk5FzHER8frwFafHx83r4RIYQQQgghhBC5d+uWpnXtqmmgaaVLa9rZs6ZN589rWp06apOPj6adOmW5MIUoaVJSNG3IEPXzB5r2zjuaZjQ+5E737tW0rDWaEyc0LS7uIXf68G7duqUdOnRIu3Xr1t0bM16A7G7BweaPdXK69+OnTs18bJkyOT+uRQvz/Vap8lDf37x58zRACw8P12JiYrSzZ89qixYt0jw9PTVHR0ftv//+04YMGaIB2oQJE8yeu2nTJg3Qfv31V7PxlStXmo1fvnxZs7Oz03r27KkZsyTKW2+9pQHakCFDTGPr1q3TAG3dunWapmlaWlqaVq1aNa1KlSratWvXzI6TdV8jR47Usit5FkSM2blnnmi5rykWufYIAMeOHaNChQpUr16dgQMHEh0dDcDu3btJTU3F39/f9Ni6devi4+NDREQEABERETRs2BBvb2/TYwIDA0lISLjnNOfk5GQSEhLMbiXJnVPRhdAbyVGhd5KjQu8kR4XeSY6WcKmp8H//B2vXgouL6mFbqRIAFy+qlghHjqgem+vXq9YIhU1yVOhdQeWorS3Mm6cmiwJMnw7PPKMmjuZZkyZgZ6e+TkmBfv3UgmVZrroutgwGNcPWgvz9/SlbtiyVK1dmwIABlCpVij///JOKFSuaHjNixAiz52Rc8R4QEMCVK1dMt+bNm1OqVCnWrVsHQHh4OCkpKYwaNcqsbcHYsWPvG9fevXs5deoUY8eOxd3d3WybIRezsgsjxvxU5NojtG7dmvnz51OnTh0uXLjAlClT6NChA5GRkVy8eBE7O7u7/uO8vb25ePEiABcvXjQr2GZsz9iWk5kzZ2a78tyKFStM08ADAgKIjY1lz549pu1+fn7Y2NiwadMm01ijRo2oWLEiK1asMI1Vr16d+vXrExYWRlJSEgBeXl60bt2aiIgIrly5AoCTkxPdunXjwIEDnM6yRGPPnj05ffq0WeG5U6dOJCUlsX37dtNYixYtcHNzY82aNaaxunXrUqtWLZYvX25aqa9y5co0adKE9evXk5iYiNFoZPPmzbRv355du3Zx4cIFAGxtbenRowdRUVEcO3bMtM/u3bsTExPD3r17TWNt27bFysqKzZs3m70WFSpUYOXKlaaxGjVqUK9ePVavXk1ycjKg/o9atWrF1q1biY2NBcDZ2ZmuXbuyf/9+U+EeoHfv3pw4cYJDhw6Zxrp06cKNGzfYsWOHaaxly5a4uLiwdu1a05ivry81a9Zk2bJlpibtPj4+NG7c2PRaAJQuXZp27dqxc+dOU97Y2dkRGBjI4cOHOX78uGmfgYGBXLp0iX379pnG2rVrB2Bq2wHQpEkTvL29WbVqlWmsZs2a+Pr6smrVKtMU/HLlytGyZUu2bNnC1atXAXBxcaFz585mr4XBYKBXr14cP36cw4cPm/bZtWtXEhMT2blzp2msVatWODs7m05QAPXq1aNGjRqEhISYxjJei7Vr15oajXt6etK2bVt27Nhh6h9tb29P9+7dOXTokOkyCoAePXpw/vx5/v33X9NY+/btMRqNbN261TTWtGlTypYty+rVq01jtWrVom7duqxcuZLU1FQAypcvT4sWLdi8eTPx8fGEhISYXot9+/Zx9uxZQDUv79mzJ8eOHSMqKsq0z27duhEfH8+uXbtMY61bt8bBwYENGzaYxurXr0/VqlVZvny5aaxq1ao0bNiQNWvWmFbQLFOmDH5+fmzfvp3Lly8D4ODgQEBAAAcPHuTkyZOm5wcFBXHu3Dmz16JDhw6kpaWZPmQCaNasGZ6enoSFhZnGateuTZ06dVixYoWpH3eFChVo3rw5mzZtIi4uDgA3Nzc6duzInj17OHfuHADW1tYEBwdz9OhRjhw5Ytqnv78/165dY3eWFQTatGmDvb292WvRoEEDfHx8CM3SsKpatWo0aNCA8PBwbt26BUDZsmVp06YN27ZtIyYmBgBHR0f8/f2JjIzk1KlTpucHBwcTHR1NZGSkaaxTp04kJyezbds201jz5s3x8PAwa49Tp04dateuTWhoKOnp6QBUrFiRZs2asXHjRuLj4wFwd3enQ4cO7N69m/PnzwOqtU5QUBBHjhzh6NGjpn0W1Lk8I0fBcudyAA8PDzmXy7k823N5YmKixc/lGb3E5Fwu5/LszuUZ5zZLnsv18L4cSuC5PD2dpp9+SqUNG8DBgb1Tp/LfxYsQEgJ488YbrYiKgjJlbvHuu1s5ejSNatUK/1xuNBpZv359iX9fLudy/Z7LM96PFtS5fMqU2sTF/cuXXzbg55+tOHIkgVWrXNm//+Hel0eFhtLm4kWcL16EgACSn3uONYGBpN9uN1CY5/LExERu3rxJQkICSUlJODk5YW1trc7P//0HqFxzcHAw/f8D2Dk64gQkJiaq33VHj2JtbY2Liws3btzA6sMPcfzoIzQ7OwwpKaROnMiN8ePVk/ftw9XVlbS0NFOOA5QqVQqsrLie5TiOe/diazSaTTS0t7fH0dGR+Ph403tjW1tbnJ2duX79uil3sy729eGHH1KzZk1sbGyoUaMGVapUISUlhbi4OFJSUrCxscHb29vsezx69Cjx8fF4eXmRnXPnzhEXF2f6HVW+fHnT821sbChbtizu7u6m42Qtll6/fp24uDjTz2mdOnXMjl2qVCnT4wDT7yzjHa9FVFRUrmLMyMNKlSqZHads2bJ4eHiYYgR1rjMajWaLsVlbW2M0Glm3bp3p9c16Ls/6/3hP95yHWwRcu3ZNc3V11b7//nvt119/1ezs7O56TMuWLbXXX39d0zRNe+GFF7Tu3bubbb9x44YGaKGhoTkeJykpSYuPjzfdzp49W6LaI/zzzz+WDkGIe5IcFXonOSr0TnJU6J3kaAllNGraiBHqMmAbG01btsy06eJFTfP1VZsqVdK048ctGKcmOSr0r7ByNDRU05yd1c9mw4ZmnUzyLjFR0156KbMtQI0amrZpUz7s+MHc77L3PJk61bwlwp33C1FGe4SdO3fm+JghQ4Zozs7Od40HBgZqXl5eWlhYWLa3ffv2aZqmaTNnztQA7cSJE3ftw93d/Z7tERYtWqQBWlhY2D2/j5zaI+RHjB4eHoXWHqHIzbS9k7u7O7Vr1+b48eMEBASYqt1ZZ9teunSJcuXKAerT0Kyf6mZsz9iWE3t7e+zt7fP/GygiSpcubekQhLgnyVGhd5KjQu8kR4XeSY6WUDt2wNy56nLhBQugZ08ALl9WLREOH1aLIa1fDzVqWDZUyVGhd4WVo0FBsHGj+nE9cADatIEVK1R3gzwrVQq++goefRSefRZOnFALEo4fDzNmZLZSKGqmTVN9JTIWHYPMfzP6TVi4VUJu1ahRg/DwcNq1a4dj1sXR7lDl9gqRx44do3r16qbxmJgYs1mtOR0DIDIy0qw16p1yapWQHzFmXE1QGIpkT9usrl+/zokTJyhfvjzNmzfH1tbW7BKjI0eOEB0djZ+fH6Auizpw4IDpEglQK8+5urpSr169Qo+/qMi4bEgIvZIcFXonOSr0TnJU6J3kaAnVujX8+it8843qaUtmwfbQIf0UbEFyVOhfYeZos2YQEQG+vnDuHLRvD1lKNXkXEACRkTB0qJpzGxEB1tb5sGMLSU83L9hmePddNX67bVBR8MQTT5Cens60adPu2paWlmYqyPr7+2Nra8sXX3xhatcAMHv27Pseo1mzZlSrVo3Zs2ffVeDNui9nZ2eAux5TGDHmpyI30/bVV1+ld+/eVKlShfPnzzNp0iSsra158skncXNz47nnnmP8+PGULl0aV1dXRo0ahZ+fH23atAFUT6d69erx9NNPM2vWLC5evMg777zDyJEjS/RM2vvZuXMnLVu2tHQYQuRIclToneSo0DvJUaF3kqMlTEpK5sy5J580DcfEQLducPAgVKgA69ZBzZoWivEOkqNC7wo7R6tWhS1b1OTYjRvVDNwffoCnn37IHbu5wY8/wmOPQd26mUXbpCSwsipas24nT855WxGZYZuhU6dODB8+nJkzZ7Jv3z66d++Ora0tx44dY/HixXz22Wf079+fsmXL8uqrrzJz5kx69epFcHAwe/fuZcWKFXh6et7zGFZWVsyZM4fevXvTpEkThg4dSvny5YmKiuLgwYOmXuTNmzcHYPTo0QQGBmJtbc2AAQPyJcYyZcoU+GuZocgVbf/77z+efPJJYmNjKVu2LO3bt2fbtm2ULVsWgE8//RQrKyv69etHcnIygYGBfP3116bnW1tbs2zZMkaMGIGfnx/Ozs4MGTKEqVOnWupbKhLutUibEHogOSr0TnJU6J3kqNA7ydESZMECeP99WLVKTaW9LaNgGxkJ5curGba1alkuzDtJjgq9s0SOenioH+UhQ+B//4PBg+HsWXjzTdX15KH07m1+/6231Cc5P//8kL0YRF7NnTuX5s2b88033/DWW29hY2ND1apVGTRokNlM7+nTp+Pg4MDcuXNZt24drVu3ZvXq1QQFBd33GIGBgaxbt44pU6bw8ccfYzQaqVGjBi+88ILpMX379mXUqFEsWrSIBQsWoGkaAwYMyJcYe95u01MYDFrWeb4i1xISEnBzcyM+Ph5XV1dLh1PgQkJC6H3nCVEIHZEcFXonOSr0TnJU6J3kaAnx11/Qv7+6JHjKFFNPxytXVEuEAwcyC7a1a1s00rtIjgq9s2SOGo3wxhvw0Ufq/rBhqkWtTX5NJYyLUyeFmBiwtVXnj9dey8cDKElJSZw6dYpq1arh4OCQr/sW3LVGVVF1vzzJbU2xyPe0FYXDrihdXiBKJMlRoXeSo0LvJEeF3kmOlgBr1qi+tenpalreO+8AqmDbrZsq2JYrpybS6a1gC5KjQv8smaNWVvDhh/DFF2qG7bffqrYJ16/n0wHc3eHff+GRRyA1Vc26bd8ejhzJpwOIwpDTAmIllcy0zaOSNtNWCCGEEEIIIQpMRIRaYOjGDdWn8n//AxsbYmNVwXb//syCbd26lg5WCPEw/vwTnnpKtaBt3hyWLwdv73zauaap9gijR0NCAjg4qHYro0apyvFDkpm2Ijdkpq0oVIcPH7Z0CELck+So0DvJUaF3kqNC7yRHi7H9+yE4WBVsAwLgt99MBVt/f7XZ21v/BVvJUaF3esnRxx6DtWvB0xN27wY/v3ycEGswqJn6kZHqfJKUpNqsSM/pIuHWrVuWDkFXpGgrcuX48eOWDkGIe5IcFXonOSr0TnJU6J3kaDGlafDii6ofZdu2agqevT1Xr6p6y7594OWl/4ItSI4K/dNTjvr5qQn2NWrAqVPqx3/Llnw8QOXKagW0uXNhzhyoUCFzm1xwrlvJycmWDkFXpGgrhBBCCCGEEMIyDAb44w8YMEBdI+3szNWraobt3r2ZBVtfX0sHKoTIb7VqqcJt69Zw9apqhfLHH/l4AIMBhg9XvRgyrFgBQUHw33/5eCAhCoYUbYUQQgghhBBCFK709MyvK1ZULRHc3bl2Tc2w3bsXypZVl1DXq2e5MIUQBSvj57xPH0hOhieegE8/LaCDpaer3rarVkGDBqr3bR5n3cryUOJe8is/ZCGyPCppC5GlpKTIaqhC1yRHhd5Jjgq9kxwVeic5WozExUH37jB+vJphm2XY31/1uMwo5DRoYLEoH5jkqNA7PedoejqMGQNffaXujx0LH3+cL2uHmYuKUj1vd+xQ9/v0gW++yfVKaOnp6Rw9ehQvLy88PT3zOThhNBqxyvf/9MJ35coVrly5Qq1atbC2tr5re25rilK0zaOSVrQ9e/YslStXtnQYQuRIclToneSo0DvJUaF3kqPFxI0bqmC7dSuULw/HjoGzM3Fxaobtrl1QpoxqiVCUCrYgOSr0T+85qmnw0Ufw+uvqfr9+8Msv4OiYzwdKS4NZs2DyZEhNVSuizZ0L/fvn6ukXLlwgLi4OLy8vnJycMBgM+RxgyaXnDxbuR9M00tLSSEhIICEhAXd3d8qXL5/tY3NbU7QpqGBF8bJv3z5dn9yFkBwVeic5KvROclToneRoMZCcrJaN37oV3N1h5UpTwbZ798yCbVGbYZtBclTond5z1GCA115Ta4gNGQJLlsCFC/DPP6qumm9sbOCtt6BnT3Wg/fvh8cdVg902be779HLlygFw+fLlfAxKANy8eRMnJydLh/FQrK2tKV++PG5ubg+9LynaCiGEEEIIIYQoWGlp8OSTEBYGzs5qMaBGjYiPh8BA2LlTFWXWrIGGDS0drBDCkgYMUBPxH31UfcbTtq06ZVSvns8HatxYtUmYNg3Ons1VwRbAYDBQvnx5vLy8SE1NzeegSrZ169bRpUsXS4eRZzY2NlhbW+fb7Gsp2gohhBBCCCGEKDhGIzz3HPz5J9jZwd9/Q5s2poLtjh2ZBdtGjSwdrBBCDzp1gi1bICgIjh4FPz9YtgxatsznA9nZqaJt1s6hly7Be++p8XvMlrS2ts62X6nIu7S0NBwcHCwdhm5IT9s8Kmk9ba9evUrp0qUtHYYQOZIcFXonOSr0TnJU6J3kaBG2aJGaZWttra537tOHhARVsN22DUqXVi0RGje2dKAPR3JU6F1RzNHz51UXg337wMkJfv8devUq4IP27as+ZKpcGebNg27dCviAIkNRzNG8yG1NsegvySaEEEIIIYQQQr/+7//g1Vdh/nxTwbZHD1Ww9fBQM2yLesFWCFEwKlSAjRvVhzw3b0KfPvDNNwV80HHjVC+Gs2fB3x9eflktoihEIZOirciVLVu2WDoEIe5JclToneSo0DvJUaF3kqNFUMZFnQYDfPghDBpEYqK63DkiIrNg26SJRaPMN5KjQu+Kao66uEBICDz7rOq28uKLah2xArtuvEMHtTjZiBHq/ldfqU+WiujrV5QU1RwtKFK0FUIIIYQQQgiRv779Vl1inJRkGkpMVDNst25VBdvwcGja1IIxCiGKDFtb+P57mDxZ3Z85E55+GlJSCuiApUrB11/D6tVQqRKcOKGKuUuXFtABhbibFG2FEEIIIYQQQuSf335TU+H++gt+/RXANMN261Zwd4ewMGjWzKJRCiGKGIMBJk2CH38EGxt1egkKgvj4AjxoQAAcOADPPANVq6r7QhQSKdqKXGlSXK5ZEsWW5KjQO8lRoXeSo0LvJEeLiGXLYPBgdd3ySy/Bs89y/ToEB6srizMKts2bWzrQ/Cc5KvSuuOTo0KGwfLmaDLt2LbRvr9rPFhh3d7Ug2e7dqlcDqD4NP/5YgFN9S6bikqP5RYq2Ile8vb0tHYIQ9yQ5KvROclToneSo0DvJ0SJg/Xp4/HFIS4NBg+CLL7h+w0BwMGzeDG5uqmDbooWlAy0YkqNC74pTjnbvDps2QfnyEBkJfn7w778FfFAPj8yv586F556D1q3VTFyRL4pTjuYHKdqKXFm1apWlQxDiniRHhd5Jjgq9kxwVeic5qnM7d0Lv3qqHbZ8+8OOP3LhlRc+eqrDi6lq8C7YgOSr0r7jlaJMmsG0b1KsH586pGbfh4YV0cG9vKF0a9u1Tlw68/776wEo8lOKWow9LirZCCCGEEEIIIfIuORn69YPr16FbN1i0iBsptvTsCRs3ZhZsW7a0dKBCiOLGx0fN5O/UKbN39s8/F8KB+/WDgwfVh1WpqfDmm2qhsqNHC+HgoqSQoq0QQgghhBBCiLyzt4dFi6BHD/jrL26kO9CrF2zYoAq2q1dDq1aWDlIIUVx5eMCqVfDkk2qy65AhMH26aq1doMqVg7//hvnz1clu2zY1/XfhwgI+sCgppGgrcqVmzZqWDkGIe5IcFXonOSr0TnJU6J3kqA5lrYi0bQsrVnDTqhS9e6v2ti4uqpDSurXFIixUkqNC74pzjtrbw4IF8MYb6v6778KwYWoSbIEyGFSVODISAgLUwmS1ahXwQYuv4pyjeWHQtAL/7KFYSkhIwM3Njfj4eFxdXS0djhBCCCGEEEIUnpgY6N8fZs+Gpk0BuHlTXSm8dm1mwdbPz7JhCiFKnq+/hlGjwGhUFwAsXgylShXCgTUNdu0y7wXz77/QsKEq7gpxW25rijLTVuSKNIMWeic5KvROclToneSo0DvJUR2Jj4fAQNWwdvBgMBq5eRMeeUQVbEuVgpUrS17BVnJU6F1JydGXXoI//wRHR3Uu6tQJLl4shAMbDOYF28hIdT84WK2UJu6rpORobknRVuRKSkqKpUMQ4p4kR4XeSY4KvZMcFXonOaoTN29Cr16wdy+ULQt//MGtZCv69IE1azILtm3bWjrQwic5KvSuJOXoI4/AunXqNLVnD7RpA4cPF3IQBw6oQu7KldCggerfIBe731NJytHckKKtEEIIIYQQQoj7S0lRK6Zv3gxubrBqFbd86tCnD4SHg7MzrFgB7dpZOlAhhFD9tCMioGZNOHNGnZs2bSrEAJ58Un3A1bIlxMXB00+rc+jly4UYhCjKpGgrcqVcuXKWDkGIe5IcFXonOSr0TnJU6J3kqIWlpcHAgWrGmJMTLF9Okm9THn0UwsJUwXblSmjf3tKBWo7kqNC7kpijNWrA1q1qpu21a+DvD//7XyEG4OurAnjvPbC1VX0b6teHpUsLMYiioyTm6L3IQmR5JAuRCSGEEEIIIUqMDz6ACRPAzg5CQkjq2J1HH1WLjWXMsO3QwdJBCiFE9m7eVJ87/fWXuv/RRzB+fCGvD7Z/v+oD/u+/6pz6+uuFeHChJ7IQmchXW7ZssXQIQtyT5KjQO8lRoXeSo0LvJEctbORItQz7b7+R1LE7jz2mCrZOThAaKgVbkBwV+leSc9TJCf74A0aNUvdffRXGjIH09EIMonFj2LkTvv4aXnklczwxsRCD0LeSnKPZkaKtyJWrV69aOgQh7klyVOid5KjQO8lRoXeSoxZWqhSEhpLcsy99+2Z2SQgNhY4dLR2cPkiOCr0r6TlqbQ2ffaZm2QJ88QU8/jjculWIQdjZwYgRKhhQB2/VCp5/HhISCjEQfSrpOXqnAi3apqens2jRIoYPH85jjz3GgQMHAIiPj2fp0qVcunSpIA8vhBBCCCGEECKvZs+GqVNNq50npxjo21e1QnB0hOXLoVMny4YohBAPwmBQk1wXLVL10z//hK5d4coVCwUUHg5HjsAPP0DDhrBmjYUCEXpUYEXbuLg42rVrx1NPPcVvv/3GP//8Q0xMDAClSpVi9OjRfPbZZw91jPfffx+DwcDYsWNNY0lJSYwcORJPT09KlSpFv3797ioOR0dH07NnT5ycnPDy8uK1114jLS3toWIp7lxcXCwdghD3JDkq9E5yVOid5KjQO8nRQvbjjzBuHEyaBGvWkJysFj0PDc0s2HbubOkg9UVyVOid5Gim//s/tYiiuzts2wZt28KJExYIpHdv2LABqleH6Gi1UtqoUXDjhgWCsTzJUXMFVrSdMGECBw8eZNWqVZw8eZKs651ZW1vTv39/QkND87z/nTt38s0339CoUSOz8XHjxhESEsLixYvZsGED58+fp2/fvqbt6enp9OzZk5SUFLZu3cpPP/3E/PnzmThxYp5jKQk6yzsyoXOSo0LvJEeF3kmOCr2THC1EixfDCy+or199leT23ejfXxVqHR1h2TLo0sWyIeqR5KjQO8lRcx07wtatUKUKHDsGfn6wY4cFAunQQS1SNmKEuv/ll9CkiQquhJEcNVdgRdu//vqLUaNGERAQgCGb5fhq167N6dOn87Tv69evM3DgQL777js8PDxM4/Hx8fzwww988skndO3alebNmzNv3jy2bt3Ktm3bAFi9ejWHDh1iwYIFNGnShKCgIKZNm8ZXX31FSkpKjsdMTk4mISHB7FaS7N+/39IhCHFPkqNC7yRHhd5Jjgq9kxwtJCtWqCXWjUZ44QVSps/i8ScMLFsGDg4QEqIuJRZ3kxwVeic5ejdfX4iIgGbNICZGXUHwzz8WCKRUKbVA2apVUKkSHD+u2tOUMJKj5mwKasfx8fFUq1Ytx+2pqal5bkkwcuRIevbsib+/P9OnTzeN7969m9TUVPz9/U1jdevWxcfHh4iICNq0aUNERAQNGzbE29vb9JjAwEBGjBjBwYMHadq0abbHnDlzJlOmTLlrfMWKFTg5OQEQEBBAbGwse/bsMW338/PDxsaGTZs2mcYaNWpExYoVWbFihWmsevXq1K9fn7CwMJKSkgDw8vKidevWREREcOV2gxUnJye6devGgQMHzIrePXv25PTp0xw8eNA01qlTJ5KSkti+fbtprEWLFri5ubEmS5+UunXrUqtWLZYvX47RaASgcuXKNGnShPXr15OYmIjRaCQxMZH27duza9cuLly4AICtrS09evQgKiqKY8eOmfbZvXt3YmJi2Lt3r2msbdu2WFlZsXnzZrPXokKFCqxcudI0VqNGDerVq8fq1atJTk4GwNvbm1atWrF161ZiY2MBcHZ2pmvXruzfv5/o6GjT83v37s2JEyc4dOiQaaxLly7cuHGDHVk+NmvZsiUuLi6sXbvWNObr60vNmjVZtmyZaXa4j48PjRs3Nr0WAKVLl6Zdu3bs3LmTixcvAmBnZ0dgYCCHDx/m+PHjpn0GBgZy6dIl9u3bZxpr164dYL4yYpMmTfD29mbVqlWmsZo1a+Lr68uqVatMHyqUK1eOli1bsmXLFlOTbhcXFzp37mz2WhgMBnr16sXx48c5fPiwaZ9du3YlMTGRnTt3msZatWqFs7Mz69atM43Vq1ePGjVqEBISYhrLeC3Wrl3LjduXa3h6etK2bVt27NhhakVib29P9+7dOXToECeyXGPSo0cPzp8/z7///msaa9++PUajka1ZPkVs2rQpZcuWZfXq1aaxWrVqUbduXVauXElqaioA5cuXp0WLFmzevJnY2Fiio6NNr8W+ffs4e/YsAFZWVvTs2ZNjx44RFRVl2me3bt2Ij49n165dprHWrVvj4ODAhg0bTGP169enatWqLF++3DRWtWpVGjZsyJo1a7h58yYAZcqUwc/Pj+3bt3P58mUAHBwcCAgI4ODBg5w8edL0/KCgIM6dO2f2WnTo0IG0tDQiIiJMY82aNcPT05OwsDDTWO3atalTpw4rVqwwnUcrVKhA8+bN2bRpE3FxcQC4ubnRsWNH9uzZw7lz5wB1pUNwcDBHjx7lyJEjpn36+/tz7do1du/ebRpr06YN9vb2Zq9FgwYN8PHxMbtSolq1ajRo0IDw8HBu3e7iX7ZsWdq0acO2bdtMrXEcHR3x9/cnMjKSU6dOmZ4fHBxMdHQ0kZGRprFOnTqRnJxs+sANoHnz5nh4eBAeHm4aq1OnDrVr1yY0NJT020u/VqxYkWbNmrFx40bi4+MBcHd3p0OHDuzevZvz588DYGNjQ1BQEEeOHOHo0aOmfRbUufz06dOmn09LncsBPDw85Fwu5/Jsz+WxsbEkJydb9Fx+7do1s9dCzuVyLs96LjcajTRu3Nii53I9vC+HgjuXVzxxAsOjj2Kdmsq5Dh2IGT6KSU8YCAkBO7t03nprBy4u1oCcy+Huc7nRaOTatWsl/n25nMv1ey6/dOkS0dHRJf59eXbn8q+/PshLL5Vlzx4vHntM4/PPNYKCLHQuP3CAay++yO7u3bl1++e+e0AAMVeuFPv35Vn/ZirO78szzlX3Y9Cy9i3IRw0aNKBDhw7MmTOH2NhYypYtS3h4OF1vfyzbs2dPYmJizP6Dc2PRokW899577Ny5EwcHBzp37kyTJk2YPXs2CxcuZOjQoaYkzNCqVSu6dOnCBx98wLBhwzhz5ozZf9rNmzdxdnYmNDSUoKCgbI+bnJxstt+EhAQqV65MfHw8rq6uD/Q9FAmTJ6vVDN99F4CQkBB69+6ttk2bBunp6jFC6IRZjgqhQ5KjQu8kR4XeSY4WsJgYqFlTrV7esycpv//JEwNt+ftvNcP2n38gIMDSQeqb5KjQO8nRe0tNVR0KfvhB3X/jDZgxA6wK7Br1BzByJJQpA2+/rVZQK6ZKSo4mJCTg5uZ235pigaXe888/z48//sjvv/9uqqYbDAaSk5N5++23WblyJcOHD3+gfZ49e5YxY8bw66+/4uDgUBBh58je3h5XV1ezW7FmbQ0TJ6oCLWS2uJg2TY1bW1swOCHull0bFiH0RHJU6J3kqNA7ydECVrYsfPQRdOlC6sLFDHhaFWzt7eHvv6VgmxuSo0LvJEfvzdYWvvvOVAbhgw9g0CC4Y15g4du7V7VOmDoV2rSBAwcsHFDBkRw1V2AzbTVNY9iwYfzwww+4u7sTFxeHt7c3sbGxpKWlMXz4cObMmfNA+/zrr7947LHHsM5SMExPT8dgMGBlZcWqVatMlxK4u7ubHlOlShXGjh3LuHHjmDhxIv/884/ZNOpTp05RvXp19uzZk2N7hDvltipepGUUaKdOVTNu77wvhBBCCCGEKFZSk43835NW/PlnZsE2MNDSUQkhROH6+Wd47jlIS1N9bv/8E7KUmQrf77/DSy/B1atqpu3UqfDqqzKhroiy+Exbg8HAd999x8aNGxk8eDBBQUE0adKEYcOGsX79+gcu2AKmnlH79u0z3Vq0aMHAgQNNX9va2pr1Ejly5AjR0dH4+fkBqv/JgQMHTH1tAMLCwnB1daVevXoP/40XJ+++q04EEyei2dhIwVboWtYeN0LokeSo0DvJUaF3kqMF4Px5ePxx1RoBdWnwkwMzC7Z//SUF2wchOSr0TnI09wYPhtBQcHGB9euhXTvI0ua18P3f/8HBg9C7N6SkwIQJ0L49ZOkBXBxIjporsIXIMrRv35727dvny75cXFxo0KCB2ZizszOenp6m8eeee47x48dTunRpXF1dGTVqFH5+frRp0wZQjfjr1avH008/zaxZs7h48SLvvPMOI0eOxN7ePl/iLFbefRemTMGQng4GA/TpY+mIhMjW4cOHqVmzpqXDECJHkqNC7yRHhd5Jjuaz2Fjo3l0VAW7dIvXPZTz1FCxZoiZx/fkn9Ohh6SCLFslRoXeSow8mIAA2bYLgYDh0SHUmCA2FJk0sFFC5curyh59/htGjYds2FeTx46q3QzEgOWpOD+2U89Wnn35Kr1696NevHx07dqRcuXIsXbrUtN3a2pply5ZhbW2Nn58fgwYNYvDgwUydOtWCUevY7UXHNABNg6ZN1Sc6uVzpTgghhBBCCKEzCQmqInvwIFSsSOonXzBwIPzxR2bBNof1mYUQokRp3FjVRhs0gAsXoEMHWL3aggEZDDBkCERGgr8/fPxxsSnYirsV2EzbatWq3beBsMFg4MSJEw91nPXr15vdd3Bw4KuvvuKrr77K8TlVqlQhNDT0oY5bImTpYRteuTIBs2bB4cOqG/fixTBnjvp0XgghhBBCCFE03LoFjzwCu3aBpydpK8IY9G41Fi9WBdulS9WsMiGEEErlymrGbd++sG4d9OypFix75hkLB7V6tSriZvjrL9Xu5vnnzcdFkVVgC5E988wzdxVt09PTOXPmDFu2bKFBgwY0bdqUefPmFcThC1yxX4jsjkXHbty4gbOzMzz1FPz2W+bj3nsP3nrLcnEKcZspR4XQKclRoXeSo0LvJEfzQWoqPPYYLF8Orq6krV7LoE+b8/vvaqLW0qXQq5elgyy6JEeF3kmOPpyUFHj2Wfj1V3V/8mRVNtFFffTKFfD1Vf/26AHffw8VK1o6qgdWUnI0tzXFAptpO3/+/By37d+/n8DAQAYOHFhQhxcPKz3dbNGxxMRE9YOzcCFUrw7h4bBvn/qUXggdMOWoEDolOSr0TnJU6J3kaD545RVVsHV0JO3vZTw9O7Ngu2SJFGwfluSo0DvJ0YdjZwe//AI+PjBzpiraRkfD3Lk66FDg4QFvvqkm1a1cqfo5fPEFDByok6py7kiOmrNIT9vGjRszfPhw3njjDUscXuTG5Mnw7rssXap6uPj4lKVxY/XpO9Onq6Yup0+rE0GG77+HqCgLBSxKup07d1o6BCHuSXJU6J3kqNA7ydF8MHYs1KlD+uKlDP62A4sWqULDH3+oBcnFw5EcFXonOfrwDAaYMUMVaq2s4Mcf1fkzMdHCgVlbw/jxsHcvtGwJcXHw9NPQrx9cvmzh4HJPctScxRYi8/b25tChQ5Y6vMiFpUvVz/eBA5Caas2BA+q+aV23cuUyH7xvH7z4oqrwTp4MyckWiFgIIYQQQgiRo+rVSd93gMELe/Dbb2Bjo5aqkIvnhBDiwQwfDn//DU5OsGoVdOqkFiqzOF9f2LpVTbaztVUrSzZooNomiCLHIkXb2NhYfvjhBypVqmSJw4tcmjJFfYqU0fVY09T9qVOzeXDp0qpvSkqKemLjxrBhQ6HGK4QQQgghhLjD++/DP/8AqgPaMy/YsnBhZsG2Tx8LxyeEEEVUr16wfj14eakJrm3agC7mJtrYwNtvw44d0KiR6mVepoyloxJ5UGALkXXt2jXb8bi4OKKiokhJSeGXX37hySefLIjDF7hivxAZ4OgISUl3j9vbZz+Opql3fmPGwMWLamzoUPjwQ/D0LNBYhbh06RLe3t6WDkOIHEmOCr2THBV6JzmaB59/rt6bW1uTvj+SoR/U5Zdf1N/z//uf+jte5B/JUaF3kqMF4+RJCAqCo0fB3R3++kvNvNWFlBS1CGVGn9joaIiMhOBgy8aVg5KSo7mtKRbYTFuj0YimaWY3gGrVqvHyyy8TGRlZZAu2JUXt2tn3q05Ohueey6Z9rcEATzwBhw+rVgkA8+ZB69aQllbg8YqSTZqVC72THBV6Jzkq9E5y9AH99JMq2ALGt97h2VmqYGttDb//LgXbgiA5KvROcrRgVK+uOhK0batayXbvDosWWTqq2+zsMgu2RqMq5vTsCc8/DwkJlo0tG5Kj5gqsaLt+/XrWrVtndlu7di1Llixh1qxZ1K1bt6AOLfLJpEmZLRHAvID7449Qrx707atm3Jtxd4c5c2DLFqhfXy14YGNTSFGLkmrdunWWDkGIe5IcFXonOSr0TnL0ASxdCs8+C4Bx9FiePTOJn3/OLNj27Wvh+IopyVGhd5KjBcfTE8LD1TpAKSnw5JPqouOCubY9j9LSVLsEgwF++AEaNoS1ay0dlRnJUXMWW4hM6F/fvrBkifqZtrVNp1Ej9f5v61bV+0rTVE/r1q2ha1dYvfqOE1LbtrBnD4wYkTkWHg4zZ6rp+UIIIYQQQoj8tXo1DBgARiPaM0N5IeFjfvrZgLW1mvnVr5+lAxRCiOLJ0VF9MDZ2rLr/+uvw8suqn7gu2NnBxx+rRrzVqqlWCd26wahRcOOGpaMT2ci36Y8///xznp43ePDg/ApBFIC+fdUtJCSU3r17m8b/+ks12J41C379FdatU7emTWHCBPVm0NoadVLIkJSkllg8eRIWLoRvvwU/v0L/noQQQgghhCiWDh2CRx+F1FS0fv15XvuOH3+ywtoafvsN+ve3dIBCCFG8WVvDp5+Cjw+88gp8/TWcO6dKIE5Olo7uto4d4d9/4bXXYO5c+PJLWLkSQkOhVi1LRyeyyLeFyKysHnzSrsFgIF03Hzk8mJKwEFlWJ06coEaNGtlui45WJ6Vvv4WbN9VYjRrq53/IEHBwuP1ATVMV3nHj4MoVNSX/xRfVzFs3t8L5RkSxda8cFUIPJEeF3kmOCr2THM2F9HQYORLt9BleLP833863w9pavQX/v/+zdHDFn+So0DvJ0cL1xx8waJBaF6h1awgJgbJlLR3VHVatUn1uXVzUldKOjhYNp6TkaG5rivlWtD1z5kyenlelSpX8OHyhK2lF29yIjVUf0Hz+OVy9qsa8vVWN9sUXs9RlY2NVRXfePHW/fHn1pH79sl/5TAghhBBCCJErxnSNkS+kMHeePVZWanaXFGyFEMIyNm9W7SWvXlWT21as0OFk1rg4uHQJ6tRR99PT1QLzDRpYNKziLLc1xXzraVulSpU83UTREBISct/HeHqqxcuio2H2bKhcWf3cT5igLg148024ePH2A3/8UTW8rlULLlyAxx9XZzMh8ig3OSqEJUmOCr2THBV6JzmagzNn1CyJ1FSMRnhxhMFUsF2wQAq2hUlyVOid5Gjha99erQtUtSqcOKGW/tm2zdJR3cHdPbNgC6rvbZMmMHlyoa9HJDlqThYiE/nO2RnGjFEnpJ9+gnr1ICEB3n9fnahGjFDb6NJF9VF5913VYKt9e0uHLoQQQgghRNFx8SL4+8Ps2Wivvc6IEfDdd2BlBb/8olYvF0IIYVl16kBEBDRvrjpFdumi1gnSJU2DAwfUbNspU1Rfh8hIS0dVYhVo0fbixYu899579OvXD39/f7p27Wp269atW0EeXliYrS0MHqx+3v/+G9q0Ub1c5s6F2rXVorZ7DzvA1Knwv/9ltka4cgW6d4fduy37DQghhBBCCKFXV6+q98zHj6NVrcqbsa/y7beqYPvzz/DUU5YOUAghRIZy5WD9eggOVmu09+2r2kvqjsGgfon89huULg1796pq8wcfqEKuKFQFVrT9999/qVevHtOnT+fEiROsW7eOmJgYjh07xvr16zl79iz51E5XFAIfH588P9fKCh55RF0SsGEDBAWB0Qi//w7NmkGPHrB+gwFTOrz7LoSFQatW6lKvxMT8+SZEsfYwOSpEYZAcFXonOSr0TnI0i8RE9Zf/gQNo5cszqW04HyyoiMGgrnQbONDSAZZMkqNC7yRHLatUKTWhbdgwNaF11Ci13I/RaOnI7mAwqFl2kZHQqxekpKi+lx06wPHjBXpoyVFz+bYQ2Z2Cg4OJjIxk8+bNODk54eXlRXh4OF27dmXx4sWMGDGC0NBQWrVqVRCHL3CyENnD2b8fZs2CRYsyT1CtW8MbbzHjokYAAQAASURBVECfNpewemWc+mQHVHPcL79UlV8hhBBCCCFKsqQk6NkT1q5FK12a9wI28O7vDUwF26eftnSAQggh7kXTYOZMePttdf///g/mzwcHB4uGlT1NU8GNGaMund61Cxo2tHRURV6hL0R2py1btjB8+HB8fHywslKHMd6uzj3++OMMHDiQ1157raAOL/LZ2rVr83V/jRvDr7/CsWPw0kvq5LR9u7pEoH5Xb+YFLCT1nxVQrRqcPauWW+zXD86dy9c4RPGR3zkqRH6THBV6Jzkq9E5y9LYhQ1TBtlQpPuy60lSwnT9fCraWJjkq9E5yVB8MBnjrLdWFwMZGXYUcGKi63uiOwQBDh6pZtwsWmBdsr1/P98NJjporsKKt0WjE29sbAHd3d6ytrbmaJQMbNmzIbulZWmTcuHGjQPZbvTp89RWcPq1OWm5uEBUFzz4L1Ub04IvhkaSMfR2srWHpUtVHRYhsFFSOCpFfJEeF3kmOCr2THL1t2DC0MmX43D+EN/5oicEA8+aptSSEZUmOCr2THNWXp5+GlSvB1RU2blRrs585Y+mocuDjA48/nnl/50419v33kI8X8EuOmiuwom21atU4deqUOoiVFdWqVSM8PNy0fevWrbi7uxfU4UUR4+0N770H0dHw4YdQvryaVDt6ghPlfvqAr5/fQ3KPR9SiZRl01/hFCCGEEEKIgqV17cbr/U8x9q/OGAzwww9q8q0QQoiip1s32LwZKlaEw4fVAu579lg6qlyYOxeuXYMXXlAte+Sq6AKRr0Xba9eumb7u3r07ixcvNt0fMWIE33//Pf7+/nTr1o2ffvqJp2RJ0yLD09OzUI7j6gqvvgqnTsF330GtWuo8MPKbRnhs+JvRE93VJ0+aphpiT5gAN28WSmxC3worR4XIK8lRoXeSo0LvSnSOfvABHD6Mpql1ej+aWwpQE5yGDrVwbMKkROeoKBIkR/WpYUPYtk39e/EidOyoZuDq2rffwkcfgb09rFgBDRqo9gkPOetWctRcvi5EZm9vT3BwMAMHDqRdu3acP3+eRo0aYWtri6ZpvPfeeyxZsgRra2t69erFW2+9hZ2dXX4dvlDJQmSFIz0d/vwT3n8fMrppWFvDtK7reDOsqxqoVk19ytO9u+UCFUIIIYQQoiC8/z68+SZa2bK80y+KGXNLA6pg+9xzFo5NCCFEvomPV0v5rFmj6h7ffFMEzvOHD6v+PLt2qfuPPabqM15elo1L5yyyEFn//v0JDw/n//7v//D19eWrr75i48aNaJqGwWDgnXfeYe/evezatYvJkycX2YJtSbRjxw6LHNfaGvr3V+1SwsPB318Vct8K60If/iLGoZKalhsYCAMHwuXLFolTWJ6lclSI3JIcFXonOSr0rkTm6Ndfw5tvArDM93VTwfa774rAH/IlUInMUVGkSI7qm5sbhIaqXrfp6fD88zBpUr62jM1/vr4QEQHTpqlV1f78U93ySHLUXL4WbX/99VcuX77MggUL6NChA7/++ivdu3enYsWKvPLKK+wpEo05RHYuXbpk0eMbDKrXS1iYKuD27w8hhj5UTzrEbMaQjhUsXIhWt65q7KXrs5ooCJbOUSHuR3JU6J3kqNC7EpejCxbAyJEAhLV5h0c2vgqomVfPP2/JwEROSlyOiiJHclT/7Ozgp5/g7bfV/alT1ULtqamWjeuebGzgnXdUsWbkSNXnNsMD1mYkR83l+0Jkjo6OPPnkk4SEhHDx4kW+/vpratWqxezZs2nZsiV169Zl+vTpnDx5Mr8PLUqIFi1g8WKIioIBz7vwht1sWrOdvTTBcO0a8RM/Iu1miqXDFEIIIYQQIm/+/hueeQaAzU1H0X2bWox37lwYNsyCcQkhhChwBgNMn64+pLO2hvnz1VpfCQmWjuw+mjSBL78Eq9ulxsRE6NBBTR8WeZLvRdusPDw8GD58OBs2bCA6Opr3338fJycnJk6cSK1atWjbtm1BHl7kI3t7e0uHcJfatdWlYadOQdfXWtDFeSfj+Zhe57+lVgN7vvoKbsanQnKypUMVhUCPOSpEVpKjQu8kR4XelZgc3bIFnngC0tPZ1WAIHffOBgzMmQPDh1s6OHEvJSZHRZElOVq0DBsG//wDTk7qquOOHeHcOUtH9QA+/FD9TuvZU82+zUXVWXLUXL4uRJYbBw4cYOLEifz9998YDAbS09ML8/D5RhYi059r12DOHJg9G2Ji1NgU51m85Pgj9vO+waVXJ4vGJ4QQQgghxH3FxaH16sXBGC+aHP0f6djw9dcwYoSlAxNCCGEJu3ZBr15w6RJUrgwrVkD9+paOKhdu3VJ9HmbPVm0SfHxg3jzo2tXSkVmcRRYiy0nGLNvGjRvTpEkT/v77b9q2bcuXX35ZGIcX+eDQoUOWDuG+PDzgrbfgzBn46iuoWSWVgTe+ocyVI7j07sz2hs9xPvKqpcMUBaQo5Kgo2SRHhd5Jjgq9Kyk5qrm5M6n1Kpof/Y10bPjySynYFhUlJUdF0SU5WjS1aKHW+qpTB86ehXbtYN06S0eVC46O8MknKthq1SA6Wi1WNHo03LyZ7VMkR80VWNH2ypUrfP3117Rv355q1arx1ltvkZqaytSpUzl58iSbN29mhLz7KDJOnDhh6RByzdERXnoJDh+3Ze93u/lf6RcBaB35IzYN6/J95wUciZKFyoqbopSjomSSHBV6Jzkq9K5Y5+ixYzBnDpqm1nKZ9okzKdjz5ZemtchEEVCsc1QUC5KjRVe1arB1K7RvD/HxEBgICxdaOqpc6tQJ9u/P7PHzxRfw+uvZPlRy1Fy+Fm1v3LjBggULCA4OpmLFirz88sucOnWKsWPHsmvXLg4dOsTbb79N1apV8/OwQmTLxgb6P+/O41fmEPHRFk461ceLGJ7f8DRnfAMZ0eMUO3daOkohhBBCCFGiRUeDvz+89BL/BM9lxgw1/PnnUrAVQgiRqXRp1dv28cchNRUGDoT331edB3TPxUWtprlypVqw7N131fjkyTBtWvbPmTZNbS/B8rVo6+XlxZAhQ9iyZQtPPfUUq1ev5uzZs3z88cc0a9YsPw8lRK4ZDOD3SluqX9vDmWHvkWJlT2fWs35VEq1aqdn5YWFF5EQnhBBCCCGKj0uXICAAoqO5Uro2L6zsC8Bnn8GoURaOTQghhO44OMCiRTB+vLr/5pvqA760NMvGlWuBgbBnD3h7q/vW1jBx4t19gKZNU+PW1oUfo47ka9HW39+f3377jUuXLjFv3jz8/f2xssrfDgxz5syhUaNGuLq64urqip+fHytWrDBtT0pKYuTIkXh6elKqVCn69evHpUuXzPYRHR1Nz549cXJywsvLi9dee420IpPhltGjRw9Lh/Dw7Oyo8s1b2B2JJOb9H2k9xBcbG1i7Fp7rHk2LFrB4MRTRtfFKvGKRo6JYkxwVeic5KvSu2OVoXJz64/XoUeLcfGh6NZwYvJg9W7X7E0VPsctRUexIjhYPVlbw8cfqAz6DQS3I3rcv3Lhh6chyyWDI/LphQ/Xv3LnQtSs9unXLLNhOnZo5I7eEyteK6t9//80TTzyBg4NDfu7WTKVKlXj//ffZvXs3u3btomvXrvTp04eDBw8CMG7cOEJCQli8eDEbNmzg/Pnz9O3b1/T89PR0evbsSUpKClu3buWnn35i/vz5TJw4scBiLg7Onz9v6RDyT82aVHxjEPPnw4kT8NGAXZygBs/teYnnn4inbl349ltISrJ0oOJBFKscFcWS5KjQO8lRoXfFKkdv3ICePWH/fq47e9MyPpz/qMwnn8CYMZYOTuRVscpRUSxJjhYvo0fDH3+o2bchIdClC1y+bOmoHlC7dtC/v/p63Tps3NykYJtFgS1EVlB69+5NcHAwtWrVonbt2rz33nuUKlWKbdu2ER8fzw8//MAnn3xC165dad68OfPmzWPr1q1s27YNgNWrV3Po0CEWLFhAkyZNCAoKYtq0aXz11VekpKTkeNzk5GQSEhLMbiXJv//+a+kQCoSPD7zSKAxb0niJORwx+NL4+B8MH65RrRrMmgUl7L+6yCquOSqKD8lRoXeSo0Lvik2OpqfDY4/B1q3ccnCn7Y3VHKcWH38M48ZZOjjxMIpNjopiS3K0+OnbF9asAU9P2LkT/Pzg6FFLR/UAypaF//0PfvsNrK0xpKWBnZ0UbG+zsXQADyM9PZ3Fixdz48YN/Pz82L17N6mpqfj7+5seU7duXXx8fIiIiKBNmzZERETQsGFDvDP6ZwCBgYGMGDGCgwcP0rRp02yPNXPmTKZMmXLX+IoVK3BycgIgICCA2NhY9uzZY9ru5+eHjY0NmzZtMo01atSIihUrmrV1qF69OvXr1ycsLIyk21M8vby8aN26NREREVy5cgUAJycnunXrxoEDBzh9+rTp+T179uT06dOmGccAnTp1Iikpie3bt5vGWrRogZubG2vWrDF7jWrVqsXy5csxGo0AVK5cmSZNmrB+/XoSExMxGo1s3ryZ9u3bs2vXLi5cuACAra0tPXr0ICoqimPHjpn22b17d2JiYti7d69prG3btlhZWbF582az16JChQqsXLnSNFajRg3q1avH6tWrSU5OBsDb25tWrVqxdetWYmNjAXB2dqZr167s37+f6Oho0/N79+7NiRMnOHTokGmsS5cu3Lhxgx07dpjGWrZsiYuLC2sbNMDzvfdo9PXXlDt3jj94nNW2PXjh4lzeeKMK06alM2qUNS1abMHW9ioApUuXpl27duzcuZOLFy8CYGdnR2BgIIcPH+b48eOm4wQGBnLp0iX27dtnGmvXrh0AW7ZsMY01adIEb29vVq1aZRqrWbMmvr6+rFq1yvShQrly5WjZsiVbtmzh6lUVj4uLC507dzZ7LQwGA7169eL48eMcPnzYtM+uXbuSmJjIziyrsLVq1QpnZ2fWrVtnGqtXrx41atQgJCTENObj40Pjxo1Zu3YtN25fe+Hp6Unbtm3ZsWOHqRWJvb093bt359ChQ2arP/bo0YPz58+bvVlo3749RqORrVu3msaaNm1K2bJlWb16tWmsVq1a1K1bl5UrV5KamgpA+fLladGiBZs3b8ZoNBISEmJ6Lfbt28fZs2cBsLKyomfPnhw7doyoqCjTPrt160Z8fDy7du0yjbVu3RoHBwc2bNhgGqtfvz5Vq1Zl+fLlprGqVavSsGFD1qxZw82bNwEoU6YMfn5+bN++ncu3P+J0cHAgICCAgwcPcvLkSdPzg4KCOHfunNlr0aFDB9LS0oiIiDCNNWvWDE9PT8LCwkxjtWvXpk6dOqxYscLU2qVChQo0b96cTZs2ERcXB4CbmxsdO3Zkz549nDt3DgBra2uCg4M5evQoR44cMe3T39+fa9eusXv3btNYmzZtsLe3N3stGjRogI+PD6GhoaaxatWq0aBBA8LDw7l16xYAZcuWpU2bNmzbto2YmBgAHB0d8ff3JzIyklOnTpmeHxwcTHR0NJGRkaaxTp06kZycbPrADaB58+Z4eHgQHh5uGqtTpw61a9cmNDSU9Nu9TSpWrEizZs3YuHEj8fHxALi7u9OhQwd2795tmmFgY2NDUFAQR44c4WiWdzYFdS7PyFGw3LkcwMPDo3iey9euNY35+vpSs2ZNli1bhna7YXnG+SvrayHncvNzOWDxc/m1a9fMXgs5l8u5POu5POPcZslzeX69L6/u40NN21J0SVrBARoxdOhBatU6ybFjci7PUBTP5UajkfXr15f49+VyLtfvuTzj/WhJf1+uhxoL5N+5PDZ2M9OnOzNlSmtOnnSmbVuN11/fgq+v+lksCufyRmvWUCU9nXQbG6xTUogaOJAzgwcX2/flGeeq+zFoWtFbfunAgQP4+fmRlJREqVKlWLhwIcHBwSxcuJChQ4eakjBDq1at6NKlCx988AHDhg3jzJkzZv9pN2/exNnZmdDQUIKCgrI9ZnJystl+ExISqFy5MvHx8bi6uhbMN6ojISEh9O7d29JhFKykJJgxQy2/mJpKqr0z73l8zJSLwwGwt4ehQ+HVV6FGDQvHKu5SInJUFGmSo0LvJEeF3hWnHJ0+Hb589yKXKMeHH6r3l6LoK045KoonydHi7fJl6NVLzbh1cICFC9WFHbqXpYdtSJMm9N63r9i3SEhISMDNze2+NcUi1x4B1Cc4+/btY/v27YwYMYIhQ4aYVfwLgr29vWnxs4xbSdK+fXtLh1DwHBzUSWHfPmjfHtvkG0ycCH/9BW3aQHKy6o1duzY8+aR6mNCPEpGjokiTHBV6Jzkq9K5I56imweefQ1wc772n/ga9RDk++EAKtsVJkc5RUSJIjhZvXl6wbh307q3mpPXrp3716Nodi461b99e/ZKcOlWNT5tm6QgtqkgWbe3s7KhZsybNmzdn5syZNG7cmM8++4xy5cqRkpJiugQhw6VLlyhXrhygpj1nXCqSdXvGNpG9jCn9JUK9erBhAyxZgtXwF+jTB7ZuhZ0/HqBvQCJGIyxaBE2bQlCQemjRm69e/JSoHBVFkuSo0DvJUaF3RTpHJ06EMWO4UL8bk99Rl5O//z68/rqF4xL5qkjnqCgRJEeLP2dnWLoURoxQdYoxY2D8eNDtf316utmMWlOOZhRub7faKKmKZNH2TkajkeTkZJo3b46tra1ZL5EjR44QHR2Nn58foPqfHDhwwNTXBiAsLAxXV1fq1atX6LEXFVn7GpUIVlaqo7eV+hEx3LxBiym9WRJVnxOf/sOTT6pNK1dC587Qtq2akavbE2EJUOJyVBQ5kqNC7yRHhd4V2Rz96CPVDwGYdv450rBl5kx44w0LxyXyXZHNUVFiSI6WDDY28NVXMHOmuv/ppzBggJp9qzuTJ5u1QDDL0XffVdtLsCJXtH3zzTfZuHEjp0+f5sCBA7z55pusX7+egQMH4ubmxnPPPcf48eNZt24du3fvZujQofj5+dGmTRtANW+uV68eTz/9NPv372fVqlW88847jBw5Ent7ewt/d0K3zpxRVdqzZ6k+rg8Lk/txctM5RoxQvW63bVO9YurXh/nz4XY/ayGEEEIIUZJ9+y289hoAE5jJHF7ivfdgwgQLxyWEEKJYMxjU75pffwVbW1i8GAIC4PY6W6KIKHJF28uXLzN48GDq1KlDt27d2LlzJ6tWrSIgIACATz/9lF69etGvXz86duxIuXLlWLp0qen51tbWLFu2DGtra/z8/Bg0aBCDBw9m6tSplvqWRFFQrx5ERqpr2KytYelSqvTw5ev6X3HmZDpvvQVubhAVpRYrq1EDZs+G69ctHbgQQgghhLCI336DF18EYCYT+IAJTJ8Ob71l4biEEEKUGE89BatWqXrF5s3qKuFTpywdlcgtg6ZJN868yO1Kb8XFf//9R6VKlSwdhj7s3w/DhsGOHep+mzYQFkaCsRTffAOffAIXL6pNHh4wapS6lSljuZBLAslRoXeSo0LvJEeF3hWpHA0NhT59IC2NrxnBSL5i2jQD77xj6cBEQSpSOSpKJMnRkisyEoKD4exZ8PaGZcugRQtLR3W3kpKjua0pFrmZtsIyypYta+kQ9KNxY7Uy2ZdfgosLVKwIpUrh6qqufjt1Sl0JV7MmXLumemf7+KgG4GfOWDr44ktyVOid5KjQO8lRoXdFKkerVyfR2ZsFDORlvmTKFCnYlgRFKkdFiSQ5WnI1aAAREdCoEVy6BJ06qc8X9UZy1JwUbUWurF692tIh6Iu1NYwcCYcPq+JthkuXcNi4mhdeUK0S/vc/aNYMbt2Czz9XhdwhQ+DgQcuFXlxJjgq9kxwVeic5KvSuKOXopyvqUid+B0OZx6TJVkycaOmIRGEoSjkqSibJ0ZKtYkXYtEn1tr15Ex55BL77ztJRmZMcNSdFWyEeRsWKUK5c5v1x4yAwEJ56Cusrl3j8cdi1C8LCoFs3SEuDn39Wn3I98oiasCuEEEIIIYqByEhYu5bZs2H8eLhABd6eZMukSZYOTAghhFBcXWH5cjWZLD1ddX585x2Qxqn6JEVbIfKL0QheXmBlpRae8PWF77/HoBnx94fwcNUGt18/tZJjSAi0awcdO6rLEuQkKYQQQghRRJ04AQEBpHUP4p9xawF4912kYCuEEEJ3bG1h3jxMV4G8954q4qakWDYucTcp2opcqVWrlqVD0D8rK5g9G7Zvh6ZNVUPbF16Azp1VGwWgZUv44w919/nn1cly0ybo2VO1yl24UM3GFQ9OclToneSo0DvJUaF3us3R//4Df3+4eJFD6XXYRxPeeQemTFEf1IuSQ7c5KsRtkqMig8Ggfk99/73q/vjLL2qhsvh4y8YlOWrOoGkyvy8vcrvSmyih0tJUE9t331XNYmxt4a+/1Fkwi3PnVJ137ly4fl2NVa0Kr74KQ4eCk1NhBy6EEEIIIXItJkZdNhUVxTFq0oFNPP92OaZNk4KtEEKIomHFCnj8cbhxAxo2VFcCV6pk6aiKt9zWFGWmrciVlStXWjqEosXGRjUzO3RITaP18oL27e96WMWK8OGHEB0N06dD2bJw+jS8/LIq3r73npqwK+5PclToneSo0DvJUaF3usvR+Hjo0QOiojhLJfwJ59k3pWBbkukuR4W4g+SoyE5QEGzcqJbrOXAA2rRR/1qC5Kg5KdqKXElNTbV0CEVTlSqqee3OnarjN6jmtbNmQWys6WEeHvD226pg++WXqmAbE6Magvv4wGuvwfnzFvkOigzJUaF3kqNC7yRHhd7pKkdv3oTevWHPHi5TFn/CeWpCFd57Twq2JZmuclSIbEiOipw0awYREWppnnPn1JyzNWsKPw7JUXNStBWioBkMUL585v358+GNN9TZcMECsxXInJxg5Eg4dgx+/VVdmnD9Onz0EVSrpvrgHjlS+N+CEEIIIYTIwtaWo0mVicONQFbx2Bt1mDFDCrZCCCGKrqpVYcsW1fUnIUHNwP3lF0tHVbJJ0VbkSvmsRUfxcOrWhfr11VTap5+GwEC14nAWNjbw1FOwfz8sXw4dOqiVHH/4QdV6+/dXk3dFJslRoXeSo0LvJEeF3ukpR7/50Za6O3+hFTsIeK0pM2dKwVboK0eFyI7kqLgfDw9YtQqeeAJSU2HwYJgxw2yuWYGSHDUnC5HlkSxEJh5KSoqaPjttGiQlgYMDTJyoViCztc32KVu3wgcfwD//ZI516wYTJqh/5Q8FIYQQQogCZDTCr7/y3Y2nGDbCGlBv3WbNkvdhQgghihejUV0g/NFH6v6wYfDVV2qCmXh4shCZyFebN2+2dAjFi50dvPWW6u7t768Kt2+9BYMG5fiUtm3h778hMlJ92mVjo3rMBARAixaweDGkpxfi96AzkqNC7yRHhd5Jjgq9s2iOahq88goMHozDiGcAjVdekYKtMCfnUaF3kqMit6ys1KLpX3yhfs99+y08+qhq31iQJEfNSdFW5Mq1a9csHULxVLMmrF6tGsV4ecHYsfd9Sv368NNPcPw4jB4Njo6wZ4+6fKFuXfjuO0hOLvjQ9UZyVOid5KjQO8lRoXcWzdEpU2D2bADC8WfcOAMffigFW2FOzqNC7yRHxYN6+WVYskRdHLx8OXTuDJcuFdzxJEfNSdFWCEszGNQM29Onwc8vc/zrr9X02Rw6mFSpAp99BtHRqrOCh4cq5A4bphYt+/BD1TxcCCGEEEI8hE8/VUVbYBSfU3rsED7+WAq2QgghSobHHoO1a8HTE3bvVmULWSC9cEjRVuSKi4uLpUMo/hwdM78+fhzGj1fTZ3v3hjNncnxamTLq74joaPU3RaVKcOECvP46+PiorgsF+UmYXkiOCr2THBV6Jzkq9M4iOfrjj+o9GfAO07AeM4pPPpGCrcienEeF3kmOirzy84OICKhRA06dUu0bt2zJ/+NIjpqThcjySBYiEwUqKQlmzlS31FRwclKLlo0efd/O3ykpsHChWrQsKkqN2dvDs8+qxTKqVy+E+IUQQgghirrFizH+3wCsNCMf8ir/jZrF7M8MUrAVQghRYl2+rOaV7dih6gwLFkD//paOquiRhchEvtq3b5+lQyhZHBzU9Nn9+6FDB7h5Uy1+0bq1uh7hHuzs4Jln4OBB+PNP9ZTkZJgzB2rVgqeeUrstbiRHhd5Jjgq9kxwVelfYObpmiwMpmi3f8gJnX5aCrbg/OY8KvZMcFQ/LywvWrYM+fVSd4Ykn1BW/+UVy1JwUbUWunD171tIhlEy+vrB+vVpdzN1drTjWsSNcvXrfp1pZqdUdIyLULnr0AKMRfvsNmjSBoCDYsCHHlrlFjuSo0DvJUaF3kqNC7wozR3/+GQI+700rdnBgxBw++1wKtuL+5Dwq9E5yVOQHJye1ONnIkaqeMH48jBun6g0PS3LUnBRthdA7Kyt4/nnV6+DJJ2HCBChdOtdPNxigUydYsQL27oUBA9QuV65UKz+2bQt//50/J1ghhBBCiCJt717+/Pgkzzyj/hDt8FIjPv/KWgq2QgghRBbW1vDFFzBrlro/e7aadXvrlkXDKnakaCtyxcpKUsXivL1Vs9p33skc27YNHn8czp3L1S6aNFEzbY8ehRdfVD1otm1TM3IbNICfflI9cYsiyVGhd5KjQq+WLoXGjaFfv2AaN1b3hdCjAj+PHjpEUscAWr3agRraMUaMgC+/lEXHRO7J73qhd5KjIj8ZDPDaa6rGYGenZt/6+0NsbN73KTlqThYiyyNZiExYnKZBixaqZYKLi1q07MUX1UdeuXTxInz+OXz1FSQkqLHKldXlDc8/D6VKFVDsQgghLEbTIDFR/Q74/XeYODFzm8Ggti9ZAn37Wi5GIQrdqVPcbN4ep2vn2UFLfns2nI+/c0X+dhRCCCHub8MGNRksLg5q11ZX+soi6DnLbU1RirZ5VNKKtseOHaNWrVqWDkPcaf9+GDZMLd0IatWxb7+FRo0eaDfx8fDNN6qB+MWLaqx0aRg1Cl5+GcqUyee4C4DkqNA7yVFR0NLTISZGnccvXMj8N+vXGf/evHnvfdnYqPY5deqoN94Z/1avDra2hfP9CHGnAjuPnj9PYtMOuFw+SST1+XHwBj6a5ykFW/HA5He90DvJUVGQDh1Sa+dER6sFy5Ytg5YtH2wfJSVHc1tTtCnEmEQRFhUVVSJ+cIqcxo1h61aYMwfeegu2b4fmzeGVV9TUKSenXO3GzQ1efx1Gj1YLb3z4IRw/DlOmqK9feEHNvvXxKeDv5yFIjgq9kxwVeXXrVvaF1zvHLl16sP7kLi5w/Xr2C1KmpcHGjeqWlbW1KtxmLeRm/Fu+vFxGLgpWgZxHY2OJa90d98snOUF1fnpqtRRsRZ7J73qhd5KjoiDVq6cWQu/ZE/btU2vo/P479OqV+31IjpqToq0QRZ21tZoO+9hjquq6dCl88AE0bAgDBz7Qrhwc1MTd555Tu5k5Uy1e9tlnqoXCU0+p4m79+gX0vQghRAmhaXD1au6KsfHxud+vwaBmNpQrp4qo5ctnfn3nmLOz+uzvwAHzwq3BADVrwqRJqgf6kSPq36NH4cYNOHZM3ZYvNz92qVLZF3Nr11YFYiF0JyGBq616UPq/g5yjAt//Xzgf/FJBCrZCCCFEHlWooD70f/xxWLUK+vRRtYQXX7R0ZEWTFG2FKC4qVlRNCP/5B/73P1VhzWA08iB/gVhbq5Ns//4QHg7vvw9r16pZuD//DI88AhMmgJ9fAXwfQghRhKWkqBmvuSnGpqbmfr8ODtkXXu8cK1tWtTbIrUmToF+/zF62Gf9+8IH6LDArTYPz580LuRn/njqlZu3u2aNudypf/u5ibp06ULWqtFsQlvPX/1KofNKIEU/m9g3jvYXVpGArhBBCPCQXFwgJUYXaH3+EESPgzBl4770HKksIpKdtnpW0nrY3b97EKZeX2gudSUyE9u1Vg9pnn83zWXLHDvVH/J9/Zs7I6thRFW979LD8JbGSo0LvJEeLLk1TizXmplfsg66WW7p07oqxrq4Fd55duhSmToWoKI26dQ1MmnR3wfZ+UlLg5Mm7i7lHjsDlyzk/z8YGatS4e2ZunTrg7W353y1CX/LzPLp4MTz5JDinxzPmsbNM/qOB/CEpHpr8rhd6JzkqCpOmqfeYkyer+wMHqiKunV3OzykpOSoLkRWwkla0vXDhAuXLl7d0GCIvPvhAVVYBOnRQK475+uZ5d0eOqD63P/+cOUusUSN44w144okHm+GVnyRHhd5JjupPeroqKOamGHvrVu73a2OTc0uCrP96e4O9fcF9fw+qoHI0Li6zvULWVgtHj957QTRXV/Mibsa/tWqpVgyi5MmXHE1PZ+PktXSdGUB6OjzzDPzwg8z8EflDftcLvZMcFZYwb55qw5iWBl26qAkD7u7ZP7ak5KgUbQtYSSvahoSE0Lt3b0uHIfIiLQ0+/xzefVf9dWxrC2++qW4ODnne7blz8OmnqgZ8/boaq1YNXn0Vhg4FR8d8ij+XJEeF3kmOFp6bN3PXnuDy5QdbuMvVNXfF2NKli2YBqLBz1GhU7Raym517+vS9/28qVsy+f27Vqpb78FAUvIfOUU3jVPfhVAv/jvF8zNUh4/nhB9UWSoj8IL/rhd5JjgpLWb1ateS6fl2tkbNiBVSufPfjSkqO5ramKG9rhSjubGxg/Hjo2xdGjoTQUHWNwqJFquLauXOedluxInz0Ebz1Fnz9tVqs7NQpdYjJk2HsWHjppZw/QRNCiAehaar1QG6KsQkJud+vlZX5wl05FWMzFu4S+cfKCipVUrdu3cy3JSfDiRPZ98+NiVEfHJ47B+vWmT/P1la1W8iuf27ZstJuoUTTNI4++jq1w78jHSuqd6zMh1KwFUIIIQpF9+6waRMEB8PBg9CmjSpNNG5s6cj0TYq2QpQUVavCsmWqiduYMeov34co2mYoXRreeUfVhefNU60TzpyBt99WC5gNHw7jxqlVJIUQ4k4pKXcXYbMrxl669GALdzk65twfNuvYgy7cJQqHvT3Uq6dud7p2Lfti7tGjkJQEUVHqdic3t+yLuTVrSkG+JDg08D3q/fMRAPP8vmPE2selYCuEEEIUoiZNYNs2CAqCQ4dU98YlSyAgwNKR6VeRa48wc+ZMli5dSlRUFI6OjrRt25YPPviAOnXqmB6TlJTEK6+8wqJFi0hOTiYwMJCvv/4ab29v02Oio6MZMWIE69ato1SpUgwZMoSZM2dik8u/3Epae4TLly/j5eVl6TBEfomLgylTVCPacuXU2M2bqsrxkNOQUlPhf/9TBdvISDVmZweDB8Nrr6k/kguC5KjQu5KUoxkLd+XUHzbr11evPti+PT1zV4wtyIW7iquinqNGI/z3X/btFs6cyVxEMzuVKmVf0K1SRWZi6klec/TfF76g0fejAVjQ/FOe3D5W/l9FgSjq51FR/EmOCj24dk0terthg5o88f33MGSI2lZScrTY9rTt0aMHAwYMoGXLlqSlpfHWW28RGRnJoUOHcL49TWLEiBEsX76c+fPn4+bmxssvv4yVlRVbtmwBID09nSZNmlCuXDk+/PBDLly4wODBg3nhhReYMWNGruIoaUXbhISEEvF9lmiPPw7x8TBnjrq29CFpmrrc4f33YfNmNWYwqD42b7wBLVo89CHMSI4KvSsOOZqWpi5Nv18x9uLFB1u4y9b27iJsdsVYb+97rzYrHk5xyNGcJCWpdgvZFXRjY3N+np2dmombXf/cMmXkg4HClpcc3TPmJ5p9/gwASxpO5tG9k6RgKwpMcT6PiuJBclToRXKyWgvnt9/U/QED1OzbI0c06tQxMGmS6vBYXBXbou2dYmJi8PLyYsOGDXTs2JH4+HjKli3LwoUL6d+/PwBRUVH4+voSERFBmzZtWLFiBb169eL8+fOm2bdz587ljTfeICYmBrtc/EVY0oq2JaUZdIl16pS6BjUpSS1ONnGiWlHM1jZfdr9lC3zwAYSEZI75+6vibbdu+fNHr+So0Ds95+iNG/eeDZvxdUzMgy/cdb9Fu8qXBw+PorlwV3Gj5xwtSLGxme0VshZzjx1Tf1DkxMMj+2JuzZrg5FR48ZckD5qjISGw89H3mGp8h9A64wiM/BhrG6m0i4JTUs+jouiQHBV6YjSqNXI++MB83GBQk8CWLCm+hdsSsxBZfHw8AKVLlwZg9+7dpKam4u/vb3pM3bp18fHxMRVtIyIiaNiwoVm7hMDAQEaMGMHBgwdp2rTpXcdJTk4mOcs794QHWeVECL2rVg0OHIARIyA8XJ05Fy6Eb78FP7+H3n27dvDPP6pdwqxZatfh4erWvDlMmKAuj5CZL0LkH6NRFaPut2jXhQuQmJj7/WYs3HW/Ymy5clK40r3Jk9WJ99137942bRqkp6vHFHOenupX3Z2/7oxGiI7Ovn9udLS6tG/7dnW7k49P9gVdHx/5XVdYQkLU1T2pxrdx6NyK11f7S8FWCCGE0BErK3Vl7oIFaoHZDJqmCrdTpxbfom1uFemirdFoZOzYsbRr144GDRoAcPHiRezs7HC/Y8l6b29vLl68aHpM1oJtxvaMbdmZOXMmU6ZMuWt8xYoVON3+qzQgIIDY2Fj27Nlj2u7n54eNjQ2bNm0yjTVq1IiKFSuyYsUK01j16tWpX78+YWFhJCUlAeDl5UXr1q2JiIjgypUrADg5OdGtWzcOHDjA6dOnTc/v2bMnp0+f5uDBg6axTp06kZSUxPYsf020aNECNzc31qxZYxqrW7cutWrVYvny5RhvT6GqXLkyTZo0Yf369SQmJmI0Gtm8eTPt27dn165dXLhwAQBbW1t69OhBVFQUx44dM+2ze/fuxMTEsHfvXtNY27ZtsbKyYnPGtfK3X4sKFSqwcuVK01iNGjWoV68eq1evNhXKvb29adWqFVu3biX29nWMzs7OdO3alf379xMdHW16fu/evTlx4gSHDh0yjXXp0oUbN26wY8cO01jLli1xcXFh7dq1pjFfX19q1qzJsmXLyJiE7uPjQ+PGjU2vBagPCdq1a8fOnTtNOWNnZ0dgYCCHDx/m+PHjpn0GBgZy6dIl9u3bZxpr164dgKllB0CTJk3w9vZm1apVprGaNWvi6+vLqlWrSElJAaBcuXK0bNmSLVu2cPV2M0gXFxc6d+5s9loYDAZ69erF8ePHOXz4sGmfXbt2JTExkZ07d5rGWrVqhXO5cqwbNYqKDRtS/4cfsI+MhHbtON2jB4eGDCHdycn0Wqxdu5YbN24A4OnpSdu2bdmxYweXLl0CwN7enu7du3Po0CFOnDhhOk6PHj2YNu08nTod46+/qrN6dRV277bm8cehQoXr9O17gi5d/qNVq8aULVuW1atXm55bq1Yt6taty8qVK0m9vRpR+fLladGiBZs3b8ZoNBISEmJ6Lfbt28fZs2cBsLKyomfPnhw7doyoLKvTdOvWjfj4eHbt2mUaa926NQ4ODmzYsME0Vr9+fapWrcry5ctNY1WrVqVhw4asWbOGmzdvAlCmTBn8/PzYvn07ly9fBsDBwYGAgAAOHjzIyZMnTc8PCgri3Llz/Pvvv6axDh06kJaWRkREhGmsWbNmeHp6EhYWZhqrXbs2derUYcWKFaSlpQFQoUIFmjdvzqZNm4iLiwPAzc2Njh07smfPHs7d/i1obW1NcHAwR48e5ciRI6Z9+vv7c+3aNXbv3m0aa9OmDfb29mavRYMGDfDx8SE0NNQ0Vq1aNRo0aEB4eDi3bl8TX7ZsWdq0acO2bduIiYkBwNHREX9/fyIjIzl16pTp+cHBwURHRxOZ0QQZdf5KTk5m27ZtprHmzZvj4eFBeHi4aaxOnTrUrl2b0NBQ0tPTAahYsSLNmjVj48aNpg/23N3d6dChA7t37+b8+fMA2NjYEBQUxJEjRzh69KhpnwV1Ls/IUXi4c3lqqhWVK7fk5k1XVq8+wLVr9ly7Zo/RWI5bt9yIioozjaWn5376qqMjlCmTQqlS1/HwSMLDI5lWrSrj5JTA9evHcHdPonTpZHr0aI6tbc7n8qtXVZ/apCQ5l2co1HO5szPr1q0zjdWrV48aNWqYci/ra3HyzBmqz59PVFQUV0eOBGDHjh24fvYZdRcu5PjgwdSEbM/l58+fNzt/tW/fHqPRyNatW01jTZs2feBz+bVr18xeC0uey3fuzDyX163rwKhRmefy5GQrLlxwxtu7A7t2JbB793XOnXPm3LlSXL9uR3S0KuxmOV0BYGubTvnyN6hY8QYNGtjRtq0nsbERlCsXj6trqpzL73Muz3ifer9z+dmQON6e9yipaS506HCOemOSWbFyWbF5Xw7g4eEh78t1eC43Go2sX7++UM/lD/O+vCScy+V9ufm5POP9aEl/Xy7ncn2dyy9fDgbMP9XWNDh0KB2wLpbvyzPOVfdTpNsjjBgxghUrVrB582YqVaoEwMKFCxk6dKjZrFhQL1iXLl344IMPGDZsGGfOnDH7j7t58ybOzs6EhoYSFBR017Gym2lbuXLlEtMe4eTJk1SvXt3SYYjCEhurVg2bN09NCzp4EEqVyvfDxMTAl1/CF1+oGUugZuiNGwfDh6tLq3NLclTo1dKlat2/qCgjdetaZdufSdNUS+n7Ldp18eKDL9xVpsz9F+0qXx5cXKQ/Z4k0bZpqiTN1KicHDqT6r7+a7mc7A1fc15Ur2c/OPXYMbv9tkK3SpbNfDK1mTdW5SOTud/3mL/bSYHQXDlGP7x4N5bvF7uRynWEhHpq8HxV6Jzkq9KhxY3Xhb9bqpMEAjRpBlrpssVLse9q+/PLL/P3332zcuJFq1aqZxteuXUu3bt24du2a2WzbKlWqMHbsWMaNG8fEiRP5559/zKryp06donr16uzZsyfb9gh3Kmk9bY1GI1bScLDkWb9eXR7brZu6bzSqylHFivl6mOvX4bvv4OOPMy+LcHODkSNh9Gi1+ND9SI4KS9I0tUhXcrL5LSQExozJ7MuU8W9goGodkLUYe3sCQK7Y2ali6/2KsbJwVxGVnq4SKClJ3TK+Ll0684SYmAhr12Zuu/PfVq2ge3f12JgYeOWV7PeZlKT6A6xdi2ZnhyElRVULW7YEd/e7bzVrQpMmmbGmpSEVsdxJT1ezb7NbDO32BLRsGQxQpUr27RYqVy5Z/aDv97t+wzdR+L7YES9iOFymPbVOrMLGVfq0iMIj70eF3kmOCj1aulS1NLrzb6alS1UbxeKo2BZtNU1j1KhR/Pnnn6xfv55atWqZbc9YiOy3336jX79+ABw5coS6devetRDZhQsX8PLyAuDbb7/ltdde4/Lly9jb2983jpJWtJWG5QJQPW7HjVMzs0aPzvc/1FNS4NdfVSPyjCuEHBzg2WfVumhZPp+5i+RoyaFpmTWth7mlpOTv8/Pjt6mbW86LdWUdK11aZsUWCKMx8z/0zuJmhQpQtqx63KVLsHFjzgXTHj2gbVv12KgoNdU6u2JpcrI6lw4frh67d68qtt6+vPIu77yjzr8Z+/X1zfl7GTsWPv1Uff3ff6q6l5Pnn4eff1ZJbWd37+mggwbBL7+or5OT1Una2Tn7Am+HDpnfG6h33q6udz9Oir7cvKlm4t5ZzD1yRM3Cz4mDA9SqlX1B9/ZyD8XKvX7Xr//pDDWeaU9l/uOkezMqH1uLbRm3Qo5QlHTyflToneSo0KulS9WFXocOpVOvnjWTJhXfgi0U44XIRo4cycKFC/n7779xcXEx9S1yc3PD0dERNzc3nnvuOf6fvfuOjqra4jj+nSQkgQAJvTcp0nuV3psoIvpUQEAFHiKiKIqFroKKCE8URAUs2AUUpPfeCR2kV+kQIJB+3x/HTDKkGELC3CS/z1qzyJx7586eyc4l2XPuPgMHDiRnzpxkz56d/v37U69ePerWrQuYXiDly5enW7dufPDBB5w9e5a3336bfv36JalgK5Jh/fmn+cvylVdMdXXKFLOSWArx9oaePaF7d/j9d9OUfNMm+Owz+Pxz+M9/4PXXzWUScu/cPoM0pYudybnZ/eNGDw8Y6TGckAhP3iHuJeZDHaNo3yaSU88NdynGZs5872O1BcuKSYz4iqClSpniHsCRI7BhQ9wiaPS/XbpApUpm37VrYdy4hAumH3wQ89vgH3/Aww8nHOPkyTEFyN274fHHE97X3z+maHv1Kvz4Y8L7xu6l7+0dt2Dr4WEqcz4+kClTzHj27FC3rhmP3u7rG/N17FW1cuSADz+Mu0/013PnQlgYkV5eeIaFQceOpuB69WrcW4UKMceNriYGB5tb7BUkwHyyEP2ehYaaKRTxyZrVbJs+PWbsmWcSLgYXLmwqk+lIlizm0sAqVVzHLctMlI5dzI3++tAhk8q7dpnb7XLnjr+YW6qU+fanJ8t/OEuRni0owilOZStLkT0LVLAVERFJQzp1Mrc5c+bpg4VY0lzRdtKkSQA0adLEZXzatGn06NEDgI8//hgPDw8effRRQkNDad26NZ999plzX09PT+bOnUvfvn2pV68efn5+dO/enZEjR96rlyGSNs2aZfrcDhoE27aZGWH9+5uZX9mypdjTeHiYOkrHjrBypSneLlwI339vbm3bwuDBpqYwa5aZxLZvXzvKlSPefqFpyb/NIHVHwfSf3vm25XCYAsTd3Ly9U/YYXl7AKE8YOhQHMCpW4XYIoxhhDYV6I6lth1yNiIBbtxIumFataipKADt3mp/9+PaLnjVarJjZd/Zs+Oqr+IulISGmkBldWPz0U3MuScjcudC+vfl61Srz6U5CqlWLKdr+/bf52D4hsRsE395HIjqx4iuY5s4NjRrFLZhG/xu78laiBEyYkHDBNPYlBGXKmFmxsfdJaBZqwYIQa3GURPn5mcsV4jNqlGksPnIk86pWpUNgoOlpW726me6QmNy5TQ/0+Iq7V6+6FlZDQqBBA9ftN26YbTdumJNftNBQ839NQtq3NzkRLboPSI4ccQu8VarAs8/G7Ltmjcnn6O3+/uDpuvCFnTgckDevuTVo4LotIgKOH4+/f+6pU6a37sWLEGs9IcD8H1usWPz9cwsVSnvtFpb9epm8XVpSyjrEuSzFybdzCZkK5nF3WCIiIiJ3Lc21R7CLjNYeYdeuXVSK/iNY5Nw5GDjQVFDBXHb79dfQtGmqPeX27aZtwi+/xBQRy5Qxf5ze3vvmt9+SVriNfSW0Oy6nj+8Wu25hRwkVSO+26Hk3j7fzldV7nxxF+R+HMpSRjGIIQxjFSIay94mRlP9hiClk3byZcGGzQYOYF7h2rVkUMKGC6TvvmAIUmFnwv/2W8HHXrYspFg4ebH64ErJjR8z09nfeSXxxqjVr4J+VWxk/3rRTScjChTE9V7/8Enr1itnm7e1auPziC9MIGGDpUvNJTkIF065dTcERzKzchQvjL5b6+Jjryv9pk0RoKFy75lqkTe89KGItQsaQITH/1982nmoiIsxs3atXzfc8uoVDSIhZpTKhYnDz5qYQDjEtGhJye4E3SxbzIUVs0S0bmjQx/5dFGzLEVDDjm+2bJ4+Z8WtTwcGm3UJ8/XOvXUv4cZkzm/9bo2+xC7qxlopwm9t/H128GAY/uJv5Yc3I5ONJ1u2ryVSulBsjlIxOfzOJ3SlHxe4ySo6m2562dpHRirYi8Vq4EPr2hWPHzOXKtWun+lMeOgRjx5qraEND498na1YzuerfCqYJtY20k3sxS/ROHu/llf7rWHdt40ZzrfKJE3DyJDfmrSTr+aNYgAPY9/hQyv00wuzbtatpNZKQixfNIlEA//2v6ROSkGPHYma5vvqqWdkvIbt3x1zmPny4ma4OplB5exF05syYou3PP5sfvviKpb6+0Ls3RK9IvHu3eS8SKpiWKRNTZI4uKEcnZFqb6pdWDR9uZpnGV5gdNcp8ijR8+L2O6s5ERZnifEIF3tKlTc8dMCf9qlVjtgUHux4rKQXeaPXrmw8potWpY/I4ocXbunWL2Xf/fvNzEBBgCsb3MN8tC86fj9tq4a+/4PBhCA9P+LF58sQ/O/e++9zTbmHJEujQwbztzzc/wPgPw8lUreK9D0RERETkDqlom8oyWtF26dKlNG/e3N1hiB3dvGn+cnrooZixzZvNTLdUvOT07FkzySklZ6Ymt/iZWkXTjDDRL80IDTX9Ov8pxDpvJ06YS/C3bIkpvDz+uJkSnpCgIFOoAXPZ9tSp5mclvkLoypUxi199/jnMnx//fj4+ZlZr9MpDmzfHFIbiuyz//vtjZieGhJhKjo+PiqUZXIb7vz4sLGam79Wr5mciemaHZZmF3+IrBF+5YnoW//przLHupMBbqBCcOWO+djhcF2erVs21NcSnn5pic3zF4Bw5Ys4lKSAiwnz2E9/s3Ohw4+PhYSbux9c/t1ChlP1/LDpHly0MZ9BDB9gWVpGHHzafJ93e4UTEHTLceVTSHOWo2F1GydF0uxCZuMfNmzfdHYLYVZYsrgXb/fvNJd3VqplLtFNp1bD8+c1EwV27XBelcjjMFbbjxt1Z0dTbWwXSDCsqynwKEF2EPXnSNIQcOzamiPn006YqkJBz58xqYmAWhwoOhqJFTTJu3QozZxLl6YlHZCR8/LFpvgwwaZIpxialx0OfPjGLOv2bWrXMLSkSu7RcMpQM93+9t7f5UCRPPP1PHQ54992kH2vFioRn+xYv7rpv5szmduuW+Q8sKMjcjh83l4rE9t57CVdMK1QwM9qjde5segzHV+AtVMhsj3b2rIkhWzbnec7Ly0wKLlUqpoV0tOvXTbuF+PrnXr9uZukePmw+V4otS5b4i7mxJ9rfiZs3b7JsSRTn2vdkVeQs3q87m7d/bqmCrdhGhjuPSpqjHBW7U466UtFWRFLWgQOmErpxI9SoAa+8YnojRi9klIKGDTMLjt/e03b8+JgF4SWDsywzKy56ZmzbtjEzwIcPN/0rT52Kv1fGoEExhdgiRUxxs0iRmFt0UbZIEdfqw8CB5gbmEvOZM2HkSP6MvciTh4e5JF2VBpH04U7aAx06ZP4NCXGd6Xv1qimkxvb446bAGl8x+PYms+vXJ1zgLV/etWjbvDns3Wv+4/T3d13ErWRJ00c62i+/kO3WLaoHBFC9YACUD3Dua2XNxtlzjniLuUeOmItxAgPN7Xb58sVfzL3vvlinxn9aeMysMIQRI2Dvnnb8L/IF+jKDSDwYVmwant4tE3u3RURERNIsFW0lSXLnzu3uECStePhh2LfPrCI/c6ZZ4Ojnn82MwuiFhFJIp05mraWRI2HfvijKlfNg2DAVbDOUmzdNkSN6mvSvv5qpXrFbGMTuW3n6NBQsaL6+ccNcCwymiFqokGtRNnargHffhQ8/vLPp2Lct5pR7/fqY3qFDh5p/U3ORJ5E7pP/r77HotiX58iW8z8cfJ7zt9g+bvvnG9MGOr8Ab/QFUtOhZLJYVs0+0c+dc9x0+3BR44+EoXJgCJ09SoAA0bgwMGADep6BBAJHtArgSFcDfIQGcvB7AoSu5mXmrLX/9ZbrKXD0XwqpzPqxa5Xpe9fQ07Rbuvx/6Xfak7fqhbAd2OYbwrvU2fZlEFOBJFFQol/D7I+IGOo+K3SlHxe6Uo67U0zaZMlpPW5Fk+eMP6NfPzGQE07/zyy/dG5OkPfv2wfbtru0Lor++fNm1EJvQAlx58phC7A8/mKlcYKaCXbxoxgsUSFqLgjuRHhZ5EpH0KyQk/gKvj4/rp5/PP296H9ze1zc83Mzg3bMnZt+KFV3vx1awoDlfA9eugUejBmTZtYEQH3+uewRwycrBuZAALkUFcJb89GciAG8zilEMZTUNaEhMb+BP84+k39/64EtERETSHi1ElsoyWtF248aN1KlTx91hSFp0/bopWn3yienN9/rrqfI0ytE0JioKLlxwLcTGLsjOmmUaF0PChdhoGzaYldsBli6FdetcWxcULhz3kmM3UI6K3SlHJcksyxR9b96EXLlixmfPNi0aoou7sds/BATATz/F7JtIgTc0V0Gmv3uaAwdgwgQ4ElWMYpxwbh/CSMb6Dklw7TcRd9F5VOxOOSp2l1FyVAuRSYo6f/68u0OQtCpbNtNktkcPs2hKtG3bTCGtXMpc2qgctZmgoLiF2JdfjvnjfvBg024gIcePxxRtK1c2193GLsRGf120qGs/2ebNzc2GlKNid8pRSTKHI2ZBtdg6dkz6MTZtMv9XXLkSZ7avj6enc93FpUth0c7WPMuXeGARijfvOoZQ+f6UeSkiKUnnUbE75ajYnXLUlYq2InJvVK0a83VoKHTtahZjeeMNc9MK9mlHSIhpeXHyJNSqFbPa+ZdfmgL9iRNmhvXtHnwwpmhbqJD5o79AgbiLehUtapYvj/b00+YmIiLpR5Ys5nZ7v93bDBsG2x8t4izY+hDGW9Yoqg9TawQRERFJ31S0lSTxVUFNUtL162Z56H37zCJNP/4In38OTZok+5DK0RQSGWn+9fQ0/65caRaUiz1jNvann+vXQ9265uubN10vdc2Z07UQG3ul8969oW/fWEuEp3/KUbE75ajYUac9o+jEUD7NP5KXL73Jx7neY9TZobAbeESFW7EXnUfF7pSjYnfKUVfqaZtMGa2nrUiKsyz49Vd48UU4e9aM9expLpmP3R9PUt6pU6Y9RXy9ZE+fhrVrY3rE/u9/ZjXw22XJYoqxn3/+z5LhwLFjcPBgTKHWz++evSQREUmHRo2CoUPNB7yxF3VMaFxEREQkDVBPW0lRe/bsoULsfqQid8vhgMceg5YtTXuEyZNh2jSYM8f0uStR4o4OpxzFzGCOLr5G36ILsh99BFWqmP1mzTLF8oScOBFTtK1Xzywed3sv2Zw5zfcwtuLFzU3ipRwVu1OOiu1ERroUZp05Gl2ojb46RMQmdB4Vu1OOit0pR12paCtJcuTIEf3gSOoICIBJk6BbN3PJfP78ySr8pfscDQszs2Bjz4p9/HEoWdJsnzzZtBtIyF9/xRRty5QxvWijC7G395SNXgAMzH61aqXe68pA0n2OSpqnHBXbGT7c5a5LjmqGrdiQzqNid8pRsTvlqCsVbUXEHh54wFyyf/VqzAzOoCD46ivo3x8yZXJreKkqKsq0iDh50hRhc+c24/PmmT9YT56Ec+dMS4nYSpaMKdpGF1r9/eMvxEbPnAVo3drcRERERERERMSWVLQVEfvw9oa8eWPuv/GGmYU7bRpMmWIu1U9rLMvcPDzM/V274PvvXdsXnD4N4eFm+08/mRm0YGbXbt4ccywfH9dibKFCMdvatDFFbvXYFhEREREREUnztBBZMmW0hcgiIiLw8lKNX+6xGTPgpZfg4kUz+/a//4X33jMtFW7j1hy9fNnMEr59Ua/or6dOjSnEzp4NjzwS9xgeHlCwILz/Pjz1lBk7dw7Wr48p1ObOHbePrKQZOo+K3SlHxe6Uo2J3ylGxO+Wo2F1GyVEtRCYp6vTp0xQrVszdYUhG06WLmUE6aJCZbTtpkllE63//g86dXQqYqZKjERFw5kz8hdgXXjCLqAGsWhV/ITbayZMxX1esaB4be8Zs0aJQoADc/p9TvnzQsWPKviZxG51Hxe6Uo2J3ylGxO+Wo2J1yVOxOOepKRVtJkp07d+oHR9wjVy4zU/Xpp6FPH7Og1uOPQ6tW0KCBcyESlxwdNcqsKH3bAiYuLAsuXHAtyDZqBFWrmu3z58ODD5p+s/Fp2DCmaFuiBJQr59pD9vavo5UqBZ98cldviaRNOo+K3SlHxe6Uo2J3ylGxO+Wo2J1y1JWKtiKSNjRpAjt2wOjR8MUXUK0aDB1qtsVeQXrUKDP+1luwZ48p+kYv0rVtG7z6akyRNjTU9Tk+/DCmaJsvnynYZsoEhQvHnRnbsGHM46pUgb17U+uVi4iIiIiIiEgGo6KtiKQdvr4wYgS8/jpkyQJ+fqZAO38+Vfz84JVX4OBBs2DXu++a29ixZjza8uUxXzscpqAbXYgtWTJmW8WKpjVCvnwxi4iJiIiIiIiIiNwDWogsmTLaQmRXr14lIJ7Fn0Tc7qmn4Icf4t+WIwe89hoMHmzuX78Ov/8eM2O2UCHw9r53sUqGpvOo2J1yVOxOOSp2pxwVu1OOit1llBzVQmSSoiIiItwdgkj8xo+Hn382PWy9vODPP2N6yWbN6rpvtmzQtatbwhTReVTsTjkqdqccFbtTjordKUfF7pSjrnTNryTJ+vXr3R2CSPw+/xwiI4n08oKICNi40SwKdnvBVsTNdB4Vu1OOit0pR8XulKNid8pRsTvlqCvNtBWRtCt60bGRI5lXtSodAgPjX5xMRERERERERCQNUdFWRNKmWAVbhgyBOXNiCrUq3IqIiIiIiIhIGqairSRJ9erV3R2CiKvIyJiCLbFyNLpQGxnppsBE4qfzqNidclTsTjkqdqccFbtTjordKUddOSzLstwdRFqU1JXe0ouQkBB8fX3dHYZIgpSjYnfKUbE75ajYnXJU7E45KnanHBW7yyg5mtSaohYikyRZvHixu0MQSZRyVOxOOSp2pxwVu1OOit0pR8XulKNid8pRVyraioiIiIiIiIiIiNiIetomU3RXiWvXrrk5knvj5s2bGea1StqkHBW7U46K3SlHxe6Uo2J3ylGxO+Wo2F1GydHo1/hvHWtVtE2m69evA1CkSBE3RyIiIiIiIiIiIiJpyfXr1/H3909wuxYiS6aoqCjOnDlDtmzZcDgc7g4nVV27do0iRYpw8uTJDLHomqQ9ylGxO+Wo2J1yVOxOOSp2pxwVu1OOit1lpBy1LIvr169TsGBBPDwS7lyrmbbJ5OHhQeHChd0dxj2VPXv2dP+DI2mbclTsTjkqdqccFbtTjordKUfF7pSjYncZJUcTm2EbTQuRiYiIiIiIiIiIiNiIirYiIiIiIiIiIiIiNqKirfwrHx8fhg0bho+Pj7tDEYmXclTsTjkqdqccFbtTjordKUfF7pSjYnfK0bi0EJmIiIiIiIiIiIiIjWimrYiIiIiIiIiIiIiNqGgrIiIiIiIiIiIiYiMq2oqIiIiIiIiIiIjYiIq2IiIiIiIiIiIiIjaioq2IiIiIiIiIiIiIjahoK4n69NNPKV68OL6+vtSpU4dNmza5OyQRp1WrVtGhQwcKFiyIw+Fg9uzZ7g5JxGn06NHUqlWLbNmykTdvXjp27MiBAwfcHZaI06RJk6hcuTLZs2cne/bs1KtXj/nz57s7LJEEjRkzBofDwUsvveTuUEQAGD58OA6Hw+VWtmxZd4cl4uL06dN07dqVXLlykTlzZipVqsSWLVvcHZaIU/HixeOcSx0OB/369XN3aG6noq0k6KeffmLgwIEMGzaMbdu2UaVKFVq3bs358+fdHZoIAMHBwVSpUoVPP/3U3aGIxLFy5Ur69evHhg0bWLx4MeHh4bRq1Yrg4GB3hyYCQOHChRkzZgxbt25ly5YtNGvWjIcffpg9e/a4OzSRODZv3sznn39O5cqV3R2KiIsKFSrw999/O29r1qxxd0giTleuXKF+/fpkypSJ+fPns3fvXj766CNy5Mjh7tBEnDZv3uxyHl28eDEAjz32mJsjcz+HZVmWu4MQe6pTpw61atVi4sSJAERFRVGkSBH69+/P4MGD3RydiCuHw8GsWbPo2LGju0MRideFCxfImzcvK1eupFGjRu4ORyReOXPm5MMPP+TZZ591dygiTjdu3KB69ep89tlnvPPOO1StWpXx48e7OywRhg8fzuzZswkMDHR3KCLxGjx4MGvXrmX16tXuDkUkyV566SXmzp3LwYMHcTgc7g7HrTTTVuIVFhbG1q1badGihXPMw8ODFi1asH79ejdGJiKSNgUFBQGmKCZiN5GRkfz4448EBwdTr149d4cj4qJfv360b9/e5fdSEbs4ePAgBQsW5L777qNLly6cOHHC3SGJOP3xxx/UrFmTxx57jLx581KtWjW++OILd4clkqCwsDC+++47nnnmmQxfsAUVbSUBFy9eJDIyknz58rmM58uXj7Nnz7opKhGRtCkqKoqXXnqJ+vXrU7FiRXeHI+K0a9cusmbNio+PD//973+ZNWsW5cuXd3dYIk4//vgj27ZtY/To0e4ORSSOOnXqMH36dBYsWMCkSZM4evQoDRs25Pr16+4OTQSAI0eOMGnSJEqXLs3ChQvp27cvL774Il9//bW7QxOJ1+zZs7l69So9evRwdyi24OXuAERERNK7fv36sXv3bvW5E9u5//77CQwMJCgoiF9//ZXu3buzcuVKFW7FFk6ePMmAAQNYvHgxvr6+7g5HJI62bds6v65cuTJ16tShWLFi/Pzzz2ozI7YQFRVFzZo1ee+99wCoVq0au3fvZvLkyXTv3t3N0YnE9dVXX9G2bVsKFizo7lBsQTNtJV65c+fG09OTc+fOuYyfO3eO/PnzuykqEZG054UXXmDu3LksX76cwoULuzscERfe3t6UKlWKGjVqMHr0aKpUqcKECRPcHZYIAFu3buX8+fNUr14dLy8vvLy8WLlyJf/73//w8vIiMjLS3SGKuAgICKBMmTIcOnTI3aGIAFCgQIE4H8SWK1dObTzElo4fP86SJUt47rnn3B2KbahoK/Hy9vamRo0aLF261DkWFRXF0qVL1etORCQJLMvihRdeYNasWSxbtowSJUq4OySRfxUVFUVoaKi7wxABoHnz5uzatYvAwEDnrWbNmnTp0oXAwEA8PT3dHaKIixs3bnD48GEKFCjg7lBEAKhfvz4HDhxwGfvrr78oVqyYmyISSdi0adPImzcv7du3d3cotqH2CJKggQMH0r17d2rWrEnt2rUZP348wcHB9OzZ092hiQDmF+PYMxmOHj1KYGAgOXPmpGjRom6MTMS0RPj+++/5/fffyZYtm7MfuL+/P5kzZ3ZzdCLwxhtv0LZtW4oWLcr169f5/vvvWbFiBQsXLnR3aCIAZMuWLU4fcD8/P3LlyqX+4GILr776Kh06dKBYsWKcOXOGYcOG4enpyZNPPunu0EQAePnll3nggQd47733ePzxx9m0aRNTpkxhypQp7g5NxEVUVBTTpk2je/fueHmpVBlN74Qk6D//+Q8XLlxg6NChnD17lqpVq7JgwYI4i5OJuMuWLVto2rSp8/7AgQMB6N69O9OnT3dTVCLGpEmTAGjSpInL+LRp09RYX2zh/PnzPP300/z999/4+/tTuXJlFi5cSMuWLd0dmohImnDq1CmefPJJLl26RJ48eWjQoAEbNmwgT5487g5NBIBatWoxa9Ys3njjDUaOHEmJEiUYP348Xbp0cXdoIi6WLFnCiRMneOaZZ9wdiq04LMuy3B2EiIiIiIiIiIiIiBjqaSsiIiIiIiIiIiJiIyraioiIiIiIiIiIiNiIirYiIiIiIiIiIiIiNqKirYiIiIiIiIiIiIiNqGgrIiIiIiIiIiIiYiMq2oqIiIiIiIiIiIjYiIq2IiIiIiIiIiIiIjaioq2IiIiISDI4HA6GDx/u7jAS1aNHD4oXL+7uMERERETkDqloKyIiIiJus2vXLjp37kyxYsXw9fWlUKFCtGzZkk8++cTdod1zxYsX58EHH3R3GCIiIiJiAyraioiIiIhbrFu3jpo1a7Jjxw569erFxIkTee655/Dw8GDChAnuDk9ERERExG283B2AiIiIiGRM7777Lv7+/mzevJmAgACXbefPn3dPUCIiIiIiNqCZtiIiIiLiFocPH6ZChQpxCrYAefPmdbk/bdo0mjVrRt68efHx8aF8+fJMmjQpzuOiWwysWLGCmjVrkjlzZipVqsSKFSsAmDlzJpUqVcLX15caNWqwfft2l8f36NGDrFmzcuTIEVq3bo2fnx8FCxZk5MiRWJb1r6/p9OnTPPPMM+TLlw8fHx8qVKjA1KlTk/6mxHLs2DEcDgdjx45lypQplCxZEh8fH2rVqsXmzZvj7D979mwqVqyIr68vFStWZNasWfEeNyoqivHjx1OhQgV8fX3Jly8fffr04cqVK859hg0bhoeHB0uXLnV5bO/evfH29mbHjh3Jek0iIiIikjSaaSsiIiIiblGsWDHWr1/P7t27qVixYqL7Tpo0iQoVKvDQQw/h5eXFnDlzeP7554mKiqJfv34u+x46dIinnnqKPn360LVrV8aOHUuHDh2YPHkyb775Js8//zwAo0eP5vHHH+fAgQN4eMTMZYiMjKRNmzbUrVuXDz74gAULFjBs2DAiIiIYOXJkgjGeO3eOunXr4nA4eOGFF8iTJw/z58/n2Wef5dq1a7z00kvJep++//57rl+/Tp8+fXA4HHzwwQd06tSJI0eOkClTJgAWLVrEo48+Svny5Rk9ejSXLl2iZ8+eFC5cOM7x+vTpw/Tp0+nZsycvvvgiR48eZeLEiWzfvp21a9eSKVMm3n77bebMmcOzzz7Lrl27yJYtGwsXLuSLL75g1KhRVKlSJVmvRURERESSyBIRERERcYNFixZZnp6elqenp1WvXj3rtddesxYuXGiFhYXF2ffmzZtxxlq3bm3dd999LmPFihWzAGvdunXOsYULF1qAlTlzZuv48ePO8c8//9wCrOXLlzvHunfvbgFW//79nWNRUVFW+/btLW9vb+vChQvOccAaNmyY8/6zzz5rFShQwLp48aJLTE888YTl7+8f72u4Pfb27ds77x89etQCrFy5clmXL192jv/+++8WYM2ZM8c5VrVqVatAgQLW1atXnWOLFi2yAKtYsWLOsdWrV1uANWPGDJfnXrBgQZzxXbt2Wd7e3tZzzz1nXblyxSpUqJBVs2ZNKzw8PNHXISIiIiJ3T+0RRERERMQtWrZsyfr163nooYfYsWMHH3zwAa1bt6ZQoUL88ccfLvtmzpzZ+XVQUBAXL16kcePGHDlyhKCgIJd9y5cvT7169Zz369SpA0CzZs0oWrRonPEjR47Eie2FF15wfh09czYsLIwlS5bE+1osy+K3336jQ4cOWJbFxYsXnbfWrVsTFBTEtm3bkvrWuPjPf/5Djhw5nPcbNmzoEvfff/9NYGAg3bt3x9/f37lfy5YtKV++vMuxfvnlF/z9/WnZsqVLjDVq1CBr1qwsX77cuW/FihUZMWIEX375Ja1bt+bixYt8/fXXeHnpYj0RERGR1KbfuERERETEbWrVqsXMmTMJCwtjx44dzJo1i48//pjOnTsTGBjoLDquXbuWYcOGsX79em7evOlyjKCgIJdiZezCLODcVqRIkXjHY/dyBfDw8OC+++5zGStTpgxg+szG58KFC1y9epUpU6YwZcqUePdJ7uJqt7+e6AJudNzHjx8HoHTp0nEee//997sUiw8ePEhQUFCcnsEJxTho0CB+/PFHNm3axHvvvRenCCwiIiIiqUNFWxERERFxO29vb2rVqkWtWrUoU6YMPXv25JdffmHYsGEcPnyY5s2bU7ZsWcaNG0eRIkXw9vZm3rx5fPzxx0RFRbkcy9PTM97nSGjcSsICY/8mOoauXbvSvXv3ePepXLlyso6dknFHRUWRN29eZsyYEe/2PHnyuNw/cuQIBw8eBGDXrl13/HwiIiIikjwq2oqIiIiIrdSsWRMwl/0DzJkzh9DQUP744w+XWaexL+VPSVFRURw5csQ5uxbgr7/+AqB48eLxPiZPnjxky5aNyMhIWrRokSpxJaRYsWIAzuJqbAcOHHC5X7JkSZYsWUL9+vVdWk7EJyoqih49epA9e3Zeeukl3nvvPTp37kynTp1SLngRERERiZd62oqIiIiIWyxfvjze2aLz5s0DzKX9EDPTNPa+QUFBTJs2LdVimzhxovNry7KYOHEimTJlonnz5vHu7+npyaOPPspvv/3G7t2742y/cOFCqsVaoEABqlatytdff+3S33fx4sXs3bvXZd/HH3+cyMhIRo0aFec4ERERXL161Xl/3LhxrFu3jilTpjBq1CgeeOAB+vbty8WLF1PttYiIiIiIoZm2IiIiIuIW/fv35+bNmzzyyCOULVuWsLAw1q1bx08//UTx4sXp2bMnAK1atcLb25sOHTrQp08fbty4wRdffEHevHmds3FTkq+vLwsWLKB79+7UqVOH+fPn8+eff/Lmm2/GaR8Q25gxY1i+fDl16tShV69elC9fnsuXL7Nt2zaWLFnC5cuXUzzWaKNHj6Z9+/Y0aNCAZ555hsuXL/PJJ59QoUIFbty44dyvcePG9OnTh9GjRxMYGEirVq3IlCkTBw8e5JdffmHChAl07tyZffv2MWTIEHr06EGHDh0AmD59OlWrVuX555/n559/TrXXIiIiIiKaaSsiIiIibjJ27FiaNm3KvHnzGDhwIAMHDmTTpk08//zzbNy4kYCAAMDMuP31119xOBy8+uqrTJ48md69ezNgwIBUicvT05MFCxZw9uxZBg0axObNmxk2bFi8s1Njy5cvH5s2baJnz57MnDmTF154gQkTJnD58mXef//9VIk1Wps2bfjll1+IjIzkjTfeYObMmUybNs3ZaiK2yZMnM2XKFM6fP8+bb77JG2+8wbJly+jatSv169cnMjKS7t27kzt3bsaPH+98XOnSpRk9ejS//PKLirYiIiIiqcxhpcTKCyIiIiIi6UCPHj349ddfXWanioiIiIjca5ppKyIiIiIiIiIiImIjKtqKiIiIiIiIiIiI2IiKtiIiIiIiIiIiIiI2op62IiIiIiIiIiIiIjaimbYiIiIiIiIiIiIiNqKirYiIiIiIiIiIiIiNqGgrIiIiIiIiIiIiYiMq2oqIiIiIiIiIiIjYiIq2IiIiIiIiIiIiIjaioq2IiIiIiIiIiIiIjahoKyIiIiIiIiIiImIjKtqKiIiIiIiIiIiI2IiKtiIiIiIiIiIiIiI2oqKtiIiIiIiIiIiIiI2oaCsiIiIiIiIiIiJiIyraioiIiIiIiIiIiNiIirYiIiIiIiIiIiIiNqKirYiIiIiIiIiIiIiNqGgrIiIiIiIiIiIiYiMq2oqIiIiISKo7duwYDoeDHj16uIw3adIEh8PhnqDuUPHixSlevLi7wxAREZEMQEVbEREREbGtHj164HA4knybPn26u0N2u+jiaOybt7c3RYoU4amnnmLnzp3uDjFFRefIsWPH3B2KiIiISIrxcncAIiIiIiIJ6dixY5yZjStWrGDlypU8/PDDVK1a1WXb7fczspIlS9K1a1cAbty4wYYNG/jhhx+YOXMmS5cupX79+m6O0Pjmm2+4efOmu8MQERERsRUVbUVERETEtjp27EjHjh1dxoYPH87KlSvp2LFjnEvtJUapUqUYPny4y9jbb7/Nu+++y1tvvcWKFSvcEtftihYt6u4QRERERGxH7RFERERE7qElS5bgcDh4/vnn491++PBhPDw8aN269R0fO7rfZlBQEH379qVAgQL4+fnRqFEjtm3bBsCZM2fo2rUrefPmJXPmzLRq1YqDBw/GOdasWbN48sknKVWqFFmyZMHf35+GDRvy22+/xdn3v//9Lw6HgzFjxiS47f3337/j13OnonujhoSE8Pbbb1OyZEkyZcrkLFwm1js1sUvsf//9d5o3b06OHDnw9fWlYsWKjB07lsjIyH+N6fjx43h4eNCsWbN4t4eHh5M7d26KFClCVFQUAEFBQQwdOpTy5cuTNWtWsmfPTqlSpejevTvHjx9P2puRgP79+wOwefNm55jD4aBJkyacPn2ap59+mvz58+Ph4eFS1F21ahUdOnQgd+7c+Pj4ULp0ad5+++14Z8hGRkby/vvvU6pUKXx9fSlVqhSjR492vr7bJfZ9+f3332nVqhW5cuXC19eX4sWL061bN3bv3g2YnP/6668BKFGihLMdRJMmTVyOc/ToUZ577jmKFi2Kj48PBQoUoEePHgm+n7///ju1atUic+bM5MuXj169enHlypX431QRERGRVKCZtiIiIiL3UPPmzSlZsiTff/89Y8eOJUuWLC7bv/zySyzLolevXsk6flhYGC1btiQkJIT//Oc/nDt3jp9//pkWLVqwbt06WrduTYECBejatSuHDh1izpw5tG/fnn379uHp6ek8zhtvvIG3tzcNGjSgQIECXLhwgT/++IPOnTvzv//9z1n8A/j4449ZtWoVQ4cOpXnz5tSqVQswhd/PP/+cZs2aMWjQIOf+x44do0SJEhQrVixV+pA++uij7NixgzZt2hAQEECJEiWSfaw33niDMWPGUKhQITp16oS/vz+rV69m0KBBbNy4kV9++SXRxxcrVoxGjRqxcuVKTp06ReHChV22z5s3j0uXLvH666/j4eGBZVm0bt2ajRs3Ur9+fdq0aYOHhwfHjx/njz/+oFu3bhQrVizZryfa7UXSS5cuUa9ePXLmzMkTTzxBSEgI2bNnB2DSpEn069ePgIAAOnToQN68edmyZQvvvvsuy5cvZ/ny5Xh7ezuP1bt3b6ZOnUqJEiXo168fISEhjBs3jnXr1t1RjK+88grjxo0jZ86cdOzYkbx583Ly5EmWLFlCjRo1qFixIi+99BLTp09nx44dDBgwgICAAACXlhobN26kdevWBAcH8+CDD1K6dGmOHTvGjBkzmD9/PuvXr+e+++5z7v/NN9/QvXt3smfPTrdu3QgICGDu3Lm0aNGCsLAwl9cqIiIikmosEREREbmn3n//fQuwpk+f7jIeHh5uFShQwMqbN68VFhZ2x8ctVqyYBViPPfaYFR4eHuf5AgICrJdfftmKiopybuvbt68FWL/99pvLsQ4fPhzn+NevX7cqVapk+fv7W8HBwS7bAgMDLR8fH6tkyZLW9evXrZMnT1o5c+a0cuXKZZ0+fdpl36NHj1qAVaxYsTt+jZZlWcOGDbMAa9q0aS7jjRs3tgCratWq1qVLl+I8Lnp7fLp3724B1tGjR51jixYtsgCrdevW1o0bN5zjUVFR1n//+18LsH799dd/jffLL7+0AOv999+Ps+3RRx+1AGv37t2WZVnWzp07LcDq2LFjnH1DQkKs69ev/+vzRb+/rVu3jrNt6NChFmA1bdrUOQZYgNWzZ08rIiLCZf89e/ZYXl5eVpUqVayLFy+6bBs9erQFWGPHjnWOLV++3AKsKlWquLxnp06dsnLnzm0BVvfu3V2OE9/3Zc6cORZgVapUKc7zhoeHW2fPnnXej+97Fy0sLMwqXry4lS1bNmvbtm0u21avXm15enpaDz74oHMsKCjIyp49u+Xn52cdOHDA5TiNGjW6q7wVERERuRNqjyAiIiJyj/Xs2RNvb2++/PJLl/E///yTv//+m+7du5MpU6ZkH3/s2LF4ecVcUPXkk08CEBERwTvvvOMyyzJ6244dO1yOEXvmYbSsWbPSo0cPgoKCXC6vB6hSpQrvv/8+hw8fpm/fvnTr1o3Lly8zdepUChYs6LJvoUKF2LdvH0uXLk32a0zMiBEjyJkz510fZ+LEiQBMmTIFPz8/53h0KwiHw8EPP/zwr8fp3Lkzvr6+fPfddy7jV69eZe7cuVStWpUKFSq4bMucOXOc4/j4+JA1a9Ykx3/o0CGGDx/O8OHDGTRoEI0aNWLkyJH4+vry7rvvuuzr7e3NBx984DLbGuDzzz8nIiKCTz75hFy5crlse+2118iTJ4/Le/DNN98AMHToUJf3rFChQgwYMCDJsX/22WcATJgwIc7zenl5kS9fviQdZ+7cuRw7doxBgwZRrVo1l20NGjTg4YcfZt68eVy7dg2A2bNnc+3aNZ555hnKlCnj3DdTpkxx3jMRERGR1KT2CCIiIiL3WJ48eejUqRM//vgj+/fvp2zZsgDOIu5zzz2X7GPnyJEjzsJOBQoUAKB06dJx2jFEbztz5ozL+Pnz5xkzZgzz58/n+PHj3Lp1y2X77fsDvPjiiyxcuNBZnOzbty8PPfRQnP0yZcrkfM2poXbt2ilynA0bNuDn58fUqVPj3Z45c2b279//r8fx9/fnoYce4ueff2bHjh1UqVIFgF9++YXQ0FC6devm3LdcuXJUrlyZH374gVOnTtGxY0eaNGlC1apV8fC4s/kWhw8fZsSIEYB5z/Ply8dTTz3F4MGDqVSpksu+JUqUIHfu3HGOsWHDBgAWLlwYb5E9U6ZMLu9BdPG/YcOGcfaNbywhmzZtwsfHh8aNGyf5MfGJjv/AgQNxFmUDOHv2LFFRUfz111/UrFkz0fjr1avn8mGIiIiISGrSbx0iIiIibtCnTx9+/PFHvvzyS8aOHcuZM2eYP38+jRs3dpnhd6ei+5DGFl1oSmxbeHi4c+zy5cvUqlWLEydOUL9+fVq0aEFAQACenp4EBgby+++/ExoaGudYDoeDjh07Mn/+fACXvrf3UlJnYf6by5cvExER4Sx8xic4ODhJx+rWrRs///wz3333nbNo++233+Lp6clTTz3l3M/Ly4tly5YxfPhwfvvtN1555RXAFPpfeOEF3nrrrTizYRPSunVrFixYkKR9E3rPLl++DJDkWaZBQUF4eHjEWwC+k+9LUFAQhQoVuuNC9e2i458xY0ai+0V/H4OCggDImzdvnH08PT3jzPoVERERSS1qjyAiIiLiBk2aNKFs2bJ88803hIWFMW3aNCIjI5O9AFlK+uqrrzhx4gSjRo1izZo1fPLJJ4waNYrhw4dTt27dBB939OhRBg0aRM6cOXE4HDz33HNERkbew8iN2xfZihZdAIyIiIizLbpYF1v27NnJlSsXlmUleDt69GiSYmrTpo2zlUBUVBTHjh1jzZo1tGjRgvz587vsmytXLj755BNOnz7N3r17mThxIjlz5mTYsGF88MEHSXq+O5XQexZd6L927Vqi70M0f39/oqKiuHjxYpxjnTt3LsnxBAQEOGfB3o3o+OfMmZNo/NEzev39/QEz0/x2kZGRXLp06a7iEREREUkqFW1FRERE3KR3795cuHCB2bNnM3XqVHLkyMGjjz7q7rA4fPgwAA8//HCcbatXr473MREREXTp0oXr16/z008/MXDgQNatW5foLNV7LUeOHACcPn3aZTwqKipOT1+AOnXqcOnSJQ4ePHjXz+3l5cUTTzzB6dOnWb58OTNmzMCyLLp27ZrgYxwOB+XKlaNfv34sXrwYgD/++OOuY7kTderUAWLaDPyb6FnE8eVJQrkTn9q1axMaGsrKlSv/dd/omcfxfUAQHf/69euT9LyJxb9+/fp4C/4iIiIiqUFFWxERERE36d69O76+vrz88sscOXKEbt264evr6+6wKFasGABr1qxxGf/++++ZN29evI8ZMWIE69ev55VXXqFFixa89957VK9enffeey9OASw8PJz9+/c7i8P3Sq1atQCYPn26y/i4cePinTH74osvAvDMM8/EO8Py7Nmz7Nu3L8nPH9279ttvv+Xbb7/Fz8+PRx55xGWfY8eOcezYsTiPjZ6leq/z4/nnn8fLy4v+/ftz4sSJONuvXr3K9u3bnfejX+PIkSNdWkecPn2aCRMmJPl5+/XrB8CAAQOcLQ6iRUREuMzajV507uTJk3GO8/DDD1O0aFHGjRvHqlWr4mwPDw93yfOHH36Y7NmzM3XqVP766y+X/d5+++0kxy8iIiJyt9TTVkRERMRNcubMyWOPPca3334LYIvWCGAKb++//z79+/dn+fLlFCtWjB07drB06VI6derEzJkzXfZftWqVs0gb3fvU29ub77//nho1atC1a1d27NhBQEAAYAp45cqVo1ixYvEWKFNLz549+eCDDxg+fDiBgYGULFmSLVu2sHv3bho3bhxnVmebNm0YMmQIo0aNolSpUrRp04ZixYpx6dIlDh06xOrVq3nnnXcoV65ckp6/Vq1a3H///Xz//feEh4fTrVs3/Pz8XPYJDAykU6dO1K5dm/Lly5M/f35Onz7N7Nmz8fDw4OWXX06x9yMpKlasyGeffUbfvn25//77adeuHSVLluT69escOXKElStX0qNHDyZPngxA06ZN6dmzJ9OmTaNSpUo88sgjhIaG8tNPP1G3bl3mzp2bpOdt164dr776KmPHjqV06dI88sgj5M2bl9OnT7N06VJeffVVXnrpJQCaNWvG2LFj6d27N48++ih+fn4UK1aMbt264ePjw6+//krbtm1p3LgxzZo1o1KlSjgcDo4fP87q1avJlSuXczE1f39//ve//9GjRw9q1arFE088gb+/P3PnziVz5szOhftEREREUptm2oqIiIi4Uffu3QGoW7cuFStWdHM0RuHChVm5ciXNmzdnyZIlfP7554SFhbFo0SI6dOjgsu+VK1fo2rUrmTNn5ocffsDb29u57f7772f8+PGcOHHCFgXpfPnysXz5cpo3b86iRYv44osvCAgIYMOGDRQvXjzex4wcOZLFixfTsGFDli5dyrhx45g7dy6hoaEMHz6cLl263FEM3bp1cy76Fl9rhJo1a/L666/jcDj4888/+eijj1ixYgUtWrRg7dq1PPTQQ3f8uu9Wr169WL9+PR07dmTDhg2MHz+eX3/9lYsXL/Lyyy87i6fRvvjiC0aPHo3D4WDixInMnz+fgQMHMn78+Dt63g8//JDffvuNKlWq8OuvvzpnyzZr1oyWLVs692vbtq2z1+9HH33EkCFD+Oqrr5zba9WqxY4dOxgwYAAnT55k8uTJTJ06lf3799OxY0c+++wzl+ft3r07s2bNonTp0nz99dd8/fXX1K9fnyVLlrjkt4iIiEhqclixVw4QERERkXtq7NixDBo0iK+++opnnnnG3eGIiIiIiIgNqGgrIiIi4iYhISGULVuWa9eucerUKbJkyeLukERERERExAbU01ZERETkHluzZg0rV65k4cKFHD9+nNGjR6tgKyIiIiIiTiraioiIiNxjS5YsYcSIEeTOnZuXX36ZV199Nd79Zs+eTWBg4L8er0mTJjRp0iRlgxQREREREbdRewQRERERm+rRowdff/31v+43bNgwhg8fnvoBiYiIiIjIPaGirYiIiIiIiIiIiIiNqD1CMkVFRXHmzBmyZcuGw+FwdzgiIiIiIiIiIiJic5Zlcf36dQoWLIiHh0eC+6lom0xnzpyhSJEi7g5DRERERERERERE0piTJ09SuHDhBLeraJtM2bJlA8wbnD17djdHk/rmz59P27Zt3R2GSIKUo2J3ylGxO+Wo2J1yVOxOOSp2pxwVu8soOXrt2jWKFCnirC0mRD1tk+natWv4+/sTFBSUIYq2ly5dIleuXO4OQyRBylGxO+Wo2J1yVOxOOSp2pxwVu1OOit1llBxNak0x4cYJIrEk1mNDxA6Uo2J3ylGxO+Wo2J1yVOxOOSp2pxwVu1OOutK7IUmyZs0ad4cgkijlqNidclTsTjkqdqccFbtTjordKUfF7pSjrlS0FREREREREREREbERFW1FRERERERERETk3ho+HEaNin/bqFFmewbm5e4AMoLIyEjCw8PdHcZdKV++PCEhIe4OI13JlCkTnp6e7g4j3ahcubK7QxBJlHJU7E45KnanHBW7U46K3SlHxXY8PWHoUPP1kCExOTpqlBkfOdJ9sdmAirapyLIszp49S1BQEJZluTucu2JZFkePHnV3GOmKw+HA39+f/Pnz43A43B1OmlewYEF3hyCSKOWo2J1yVOxOOSp2pxwVu1OOiu0MGWL+/adwW3DwYNeCbfT2DEpF21QUFBTE1atXyZMnD35+fmm6MHft2jWyZ8/u7jDSDcuyCA4O5sKFC2TOnJmAgAB3h5TmLViwgA4dOrg7DJEEKUfF7pSjYnfKUbE75ajYnXJUbOmpp2D2bBg6FI+RIyEiQgXbf6hom0osy+L8+fNkz56d3LlzuzucuxYSEoKvr6+7w0hXMmfOTGhoKOfPn8ff3z9NF/VFRERERERERO7IjBnQty9cvw6ennhGRIC3twq2/9BCZKkkMjKSyMhIzU6VRGXPnt2ZKyIiIiIiIiIi6d7169C9O3Ttar4uWhQiI4n08oKwsIQXJ8tgVLRNJREREQB4eaWPycw+Pj7uDiFdis6P6HyR5CtZsqS7QxBJlHJU7E45KnanHBXbuW3Vc5cc1arnYkM6j4otbN0K1avDN9+Ahwc0bQonTsDIkRzYscO0Rhg6VIVb1B4h1aWXS94zZ87s7hDSpfSSH3ZQvnx5d4cgkijlqNidclTsTjkqtnPbqufOHNWq52JTOo+K2/34Izz9NISHQ5Ei0KoVfPWVs4dteYDoPI11fs2oNNNWkiQoKMjdIYgkatGiRe4OQSRRylGxO+Wo2J1yVGxnyJCYGWFPPMG6yZO16rnYms6j4nZ16kDmzPDoo7BjBxQu7HK+dOZo9Pk1g7eS1ExbSRLLstwdgkiiQkND3R2CSKKUo2J3ylGxO+Wo2NJrr8Evv8BPP1Hvp5/M2LBhKtiKLek8Km5x8CCULm2+LlECtm2D++4DhyNOGxmXHNV5VDNtRURERERERJLl8cdh1y4sILrx2ZXv5sK+fe6MSkTE/cLCYNAgKFsWYs/yLlnSFGzlX6loK0mSKVMmwPRgTcptxYoV7g1YMpx8+fK5OwSRRClHxe6Uo2J3ylGxo7WV+3ITXxxA+D8XsuY4vJXIqtUhMNCtsYncTudRuWcOHoQHHoCxYyEqCtasSdLDlKOu1B5BksTPzw+Ab7/91mX8m2++YfHixXHGy5Urd89iEwGoXbu2u0MQSZRyVOxOOSp2pxwV24iMNIuQAYFfbKY+IQxhJO8whA8YxCDGcoaCFKlc2c2BirjSeVRSnWXBt9/C889DcDDkzAlTp8LDDyfp4cpRV5ppK0ly48YNALp27epyK1OmTLzjt386cvPmzXses2Qs69atc3cIIolSjordKUfF7pSjYgtr1kCFCnDoEIwaRb9zQ50FW4DX+JAhjKBI2BF4913zmBs34OefTTFDxI10HpVUde0adOsG3bubgm3jxmaxsSQWbEE5ejsVbdOYmTOhShWz2F6VKub+vRAREZHkfZs0aULFihXZunUrjRo1IkuWLLz55puAaa8w/LZG0wDFixenR48eLmNXr17lpZdeokiRIvj4+FCqVCnef/99oqKi7ualSDp16dIld4cgkijlqNidclTsTjkqbjdrFrRsCQcOwNChbN4Q6VKwjfYOQ3nfbySRYf+sev7qq/Cf/0DnznDxohsCFzF0HpVUtWgRzJhhrkQYNQqWLoXChe/oEMpRV2qPcI9ZFiR30unvv0OXLqZfs2XBrl3w6KPmZ+IOPrhwkSVL6vR/vnTpEm3btuWJJ56Id+btv7l58yaNGzfm9OnT9OnTh6JFi7Ju3TreeOMN/v77b8aPH5/yQYuIiIiIiMTn00+hf3+wLKwODzEo4Es++iGLc3P032jRBgcP4beF8F1XizJFi4KXl5lxs3YtfPUVtG/vhhchIpKKOneG11+Hhx4y/Wzlrqloe4/dvAlZs97dMaJ/GYj+t0uX5B/rxg34p11tojw87mxS9tmzZ5k8eTJ9+vRJVlzjxo3j8OHDbN++ndKlSwPQp08fChYsyIcffsgrr7xCkSJFknVsSZ/8kpLIIm6kHBW7U46K3SlHxS0sC956C0aPBiCsR28ePfspcyeZP6VHj4bSpc2ksr17Iylf3pMWLUwLx82boVp1B+PGvUnvDW1wPN0N9u6FBx+EXr1g3Li7/+NQ5A7oPCop6u+/YdAg+PhjyJPHjI0Zc1eHVI66slV7hFWrVtGhQwcKFiyIw+Fg9uzZzm3h4eG8/vrrVKpUCT8/PwoWLMjTTz/NmTNnXI5x+fJlunTpQvbs2QkICODZZ5919mONtnPnTho2bIivry9FihThgw8+uBcvL03Lnj37He3v4+NDz549k/18v/zyCw0bNiRHjhxcvHjReWvRogWRkZGsWrUq2ceW9KlZs2buDkEkUcpRsTvlqNidclTuubAw6NHDWbC9+sooamyezNwFXmTODL/+CoMHm6sfAwMhLMyTwECzWPrOndC8uZm089//wkPDq3N+/lYYONBMy/3iC9PvbscOd75CyWB0HpUUM28eVK5sLv3u1y/FDqscdWWrom1wcDBVqlTh008/jbPt5s2bbNu2jSFDhrBt2zZmzpzJgQMHeOihh1z269KlC3v27GHx4sXMnTuXVatW0bt3b+f2a9eu0apVK4oVK8bWrVv58MMPGT58OFOmTEn11wemHcGNG8m7VawYt5WBwwGVKiX/mFmyxB/n7e50IbFChQrh7e19R4+J7eDBgyxYsIA8efK43Fq0aAHA+fPnk31sSZ926BdesTnlqNidclTsTjkq91xEBPz1F3h6cvjtqZT97m1273GQPz+sXGmKtbHFztHChU17x3HjwNsb5s6FSrV8mdv0I1i2DIoWhaAguMM2ciJ3Q+dRuWuhofDyy6bFy8WL5sOnkSNT7PDKUVe2ao/Qtm1b2rZtG+82f39/Fi9e7DI2ceJEateuzYkTJyhatCj79u1jwYIFbN68mZo1awLwySef0K5dO8aOHUvBggWZMWMGYWFhTJ06FW9vbypUqEBgYCDjxo1zKe7eLjQ0lNDQUOf9a9euJes1OhxJa0cQnxEjzC8G0f2Sov8dMSL5x0yqsLAwsiS1wgtkzpz5jo4fGRnpcj8qKoqWLVvy2muvxbt/mTJl7uj4kv6dOHGCKlWquDsMkQQpR8XulKNid8pRueeyZIE5c1gxPpC2Y1sQEmLqE3PmQHyd2m7PUQ8PU9to3hy6djVrknToAH36NOGj9TvxO7kf8uePOcDJk/EfWCSF6Dwqd+XAAXjiCXNpAcCAAaYdgq9vij2FctSVrYq2dyooKAiHw0FAQAAA69evJyAgwFmwBWjRogUeHh5s3LiRRx55hPXr19OoUSOXWaCtW7fm/fff58qVK+TIkSPe5xo9ejQjRoyIMz5//nxnMbNly5ZcunSJbdu24eXlRd68eQkPD8fLy8ulRUPmzJnx9vYmKCjIOebj40PmzJm5du0aUVFRAHh5eZE1a1Zu3LhBREQEzZrBt996M3ZsFvbvtyhdOpLXXw+ladNwLMufsLAwbt265TxmtmzZiIqKIjg42DmWJUsWPD09uX79unPM19cXX19frl696hzz9vYmS5YsXL9+3VlQvX79OtmyZSM4OJjw8HDAFHMBbt265SxqR0REOLfFnqGbNWtWcuTIwblz55zPlTlzZizL4u+//yYsLIyrV6/i4+NDyZIlCQoKcn4vM2XKhJ+fn/O9AFM4z549Ozdv3nTGARAQEEBISAghISGJvhd+fn54eHgk672I/t7Efi8cDgf+/v4u7wWY1hIRERFx3ovo13Dz5k2WL19OxYoVyZcvHwsXLnTuV6pUKcqVK8fChQudrzF//vzUqlWLtWvXcvnyZefra9KkCTt27ODEiRPOeB588EEOHTrEvn37nMds1qwZ169fZ/Pmzc6x2rVr4+fnx/Lly51j5cuXp2TJksyZM8c5VrRoUapUqcKyZcuc72WuXLl44IEH2LRpE+fOnQNMPrdq1Yq9e/dy+PBh5+PbtGnDmTNn2Llzp3OsQYMGREVFsW7dOudYtWrVyJMnD4sWLXKOlS5dmrJly7JgwQLne16gQAFq1qzJmjVriIqKYs6cOc73IjAwkJMnTwKmJ3P79u05ePAg+/fvdx6zefPmBAUFsWXLFudYnTp18PX1ZeXKlc6xChUqULx4cf7880/nWPHixalUqRJLly51fm9z585NvXr12Lhxo3M2uK+vLy1btmTPnj0cOXLE+fi2bdty+vRpl/eiYcOGREREsH79eudY9erVyZUrl8uHVmXKlOH+++9n/vz5zp+HggULUqNGDVavXu3MX39/fxo1asS2bds4ffo0AJ6enrRr146//vqLAwcOOI/ZokULrly5wtatW51jdevWxcfHx+W9qFixIkWLFmXevHnOsRIlSlCxYkWWLFniPAflyZOHunXrsmHDBi5cuACYn/cWLVqwe/dujh496nx8u3btOHHiBLt373aONW7cmNDQUDZs2OAcq1GjBjly5GDJkiXOsfvvv58yZcowb948589noUKFqF69OqtWrXKeZwMCAmjYsCFbt251ttXx8vKibdu2HDhwgL/++st5zNjn8mj16tXDy8uL1atXO8cqV65MoUKFmD9/vnPsvvvuo0KFCixevNh5DsqbNy916tRx5iiYc3Hz5s3ZtWsXx44dcz6+ffv2HDt2jD179ri8FyEhIWzcuNE5VrNmTfz9/Vm6dKlzrGzZspQuXZo///zT+f9IkSJFqFq1KitWrHCe63LkyEGDBg3YsmULf//9N2DOsW3atGH//v0cPHjQecxWrVpx4cIFtm/f7hx74IEH8PDwYM2aNS7vRcGCBVmwYIFzrGTJkpQvX55FixY5z4n58uWjdu3arFu3zrkyrJ+fH82aNXM5fwF06NCBw4cPs3fvXudY06ZNCQ4OZtOmTc6xWrVqkS1bNpYtW+YcK1euHKVKlWLu3LlY/zSAjz5/xX4vcubMSf369dm8eTNnz54FzDm/devW7Nu3j0OHDjmP2bp1a86dO0dg9C+pQP369QFYu3atc6xq1app9lwOuP1cfuXKFZf3Qudynctjn8ujz23uPJevX7+eixcvAjqXp9dzud/p01Q7exa/N99kwYKF/PxzaWbMMFf7PfggPPvsEgIDbxEYGPdcHhUVxYoVK+I9l2/a9CD9+l1h6tQcfP45zJnjyQ8/VKbM2bNs3ryZ/OvXU/3DD7k5eDCOV19leax2cGnt93Kdy+17Lo/+fTSj/16uc/mdn8tPz5hBvmefxSs0lLBs2Yj86iuuNWrEplg/DylxLo/9N1N6/r08yVezWzYFWLNmzUpw+61bt6zq1atbTz31lHPs3XfftcqUKRNn3zx58lifffaZZVmW1bJlS6t3794u2/fs2WMB1t69exN8vpCQECsoKMh5O3nypAVYQUFBCca3d+9e69atW4m9zDTjypUr8Y7369fPuj2NGjdubFWoUCHe/WvWrGlVq1bNZeyTTz6xAKt79+7OseHDh1uAtWDBgnhjCQ8Pv7MXYFPpLU/c6Y8//nB3CCKJUo6K3SlHxe6Uo5Lq1q+3rFy5LAussKnfWl27Wpa5ttGyXn7ZsiIiEn94UnJ0yRLLKlTIHNPLy7JGjbKs8HDLsp55JubJGjSwrMOHU+Y1icSi86gkW1CQZZUoYVlNm1rW6dOp9jQZJUeDgoISrSlGs1VP26QKDw/n8ccfx7IsJk2adE+e08fHh+zZs7vcMpLo2cx367nnnmP79u08+uijTJ48mb59+zJu3Dhy587tst+gQYOoXr06Dz74IL169WLy5Ml89NFH9OjRg8KFC7vMhBUB8+mfiJ0pR8XulKNid8pRSVV//AHNmsGlS4RXq8Ujk1rx3Xfg6QmTJ5vetJ6eiR8iKTnavLlZpOzxx03L3CFDoHFjOPLml/DVV5A1K6xZY/owfPmlKeOKpBCdR+WO7NsXcw7Knt008168GAoWTPGnmjnTnPYef7wDVaqY+2KzhciSIrpge/z4cRYvXuxSPM2fP3+cBaoiIiK4fPky+f/pFZQ/f37npSLRou/nj91PSFzEbjVwN3r16sXrr7/OqlWreOWVVzh69CiLFy/G77amvFmyZGHlypUMGjSIFStWMGDAAMaMGcPBgwcZMWIE/v7+KRKPpB+xL/cSsSPlqNidclTsTjkqqWbKFHjkEbh1ixuN2lHtynL+3JwXf39YsAD69EnaYZKaozlzwo8/wrffmjrIunVQpaqD6R7PYO3YCY0amVWje/WChx6Cf9o+iNwtnUclSSIjYfRos+p97ImSRYr8+6dXyTBzplm/adcuCAkx/z76qAq3kMaKttEF24MHD7JkyRJn/7Vo9erV4+rVqy69X5YtW0ZUVBR16tRx7rNq1Spn7x2AxYsXc//99yfYz1YSLtpOnDjR2Zck2ooVK1x64MTm4eHBmDFjuHDhAsHBwSxYsICSJUty7Ngxpk+f7rJv1qxZee+99zh48CChoaFcuHCBtWvX8sorr5ApU6YUeV2SfsTulSZiR8pRsTvlqNidclRSnGXB0KGmKhsVxenWz1As8Hf2HPPjvvtg/Xpo0SLph7uTHHU4zOJkO3ZAw4amRtuzJzz2Wgku/bIMPvwQvL1h7lyI9fetyN3QeVT+1Zkz0KoVvPmmKd7G6jOdWkaMMOfE6NKSZZn7I0em+lPbnq2Ktjdu3CAwMNDZTPjo0aMEBgZy4sQJwsPD6dy5M1u2bGHGjBlERkZy9uxZzp4962weXK5cOdq0aUOvXr3YtGkTa9eu5YUXXuCJJ56g4D/Tt5966im8vb159tln2bNnDz/99BMTJkxg4MCB7nrZIiIiIiIicq+tXQujRgGwpd1Qii3+ksvXvGjQADZuhHLlUj+E4sVh+XIzqc3LC377DSpV9WRR5VdNsXb0aGjfPuYBapcgIqllzhyoXBmWLQM/P5g2zbRtSUVRUbB3b9xTm2VBrPX5MixbFW23bNlCtWrVqFatGgADBw6kWrVqDB06lNOnT/PHH39w6tQpqlatSoECBZy32Ktbzpgxg7Jly9K8eXPatWtHgwYNmDJlinO7v78/ixYt4ujRo9SoUYNXXnmFoUOH0rt373v+ekVERERERMRNGjQg6t3R/Nz8c2rNG0FklINu3WDJErhtyY1U5ekJgwebQnHZsvD339C6NQz4oiK3BgyO2fHUKahWzRRURERSSkgIvPiiacdy6ZI5z2zbBj16mCmvqWTvXtMNJiIi7jaHA+6/P9WeOs1wWLdf2y5Jcu3aNfz9/QkKCop3UbKQkBCOHj1KiRIl8PX1dUOEKSsyMhLPVOhdktGltzxxpxs3bpA1a1Z3hyGSIOWo2J1yVOxOOSop4vx5M4UrXz6uX4ennjIdCADeecdcEZzcGkVK5OjNm/Daa/Dpp+Z++fIwYwZUrQo8+yxMnWo2vPQSvPceZM58V88nGYvOoxKvLVugbl3TDmHgQHNu8fFJtacLCTFPMWYMhIebpwoNjWmREP3vzJmm3Xh69G81xWi2mmkr9hUVFeXuEEQSFRwc7O4QRBKlHBW7U46K3SlH5a4dOgQPPADt23Nq/w0aNjQFW19f+OkneOutu5tUlhI5miULTJwIf/4J+fKZmWi1a5sWt1EfT4hZFW38eKhRw8yGE0kinUclXjVrwrhx5sTz0UepWrBdsQKqVDGdacLDoUMH+Osv0xqmcmXw8bGoXDl9F2zvhIq2kiQ6uYvdbdq0yd0hiCRKOSp2pxwVu1OOyl3ZvNkUbA8fJvTMJTo1vMCOHaYwumIFPP743T9FSuZou3ZmBfWHHzaFjddeg+YPZ+XEm5NNYSV/fti3D+rUMVOE47u+WOQ2Oo8KAFevQrdusGdPzNiLL5oTTyq5dAmeeQaaNjVF2gIF4Ndf4fffoWhR6NQJAgPhl1/mEhiogm00FW1FREREREQk/Zo3D5o0gQsXuFKiGmWvrGfzxRJUqmT6yNap4+4A45cnD8yaBV9+adYEWrHCzET7Ieifim7nzqZYO2QITJjg7nBFJC1Yt85Mdf3uO3j66VRf3NCyTIuXcuXMumYOB/Ttaz5zevTRVG2Zmy6oaCsiIiIiIiLp09SpZnGdmzc5UroVRY+u5FhIftq3h7VroVgxdweYOIfDtLINDDTF5aAg04e3y4DcXJ3ys6mG1KsHzz/v7lBFxM4iI01PgkaN4MQJKFkSJk9O1arpkSPQpg107QoXLkCFCrBmDXz2Gfj7p9rTpisq2kqS+Pn5uTsEkUTVqlXL3SGIJEo5KnanHBW7U47KHZs82VQ8IyNZe183yh6cww2yMWCAuSQ3W7aUfbrUzNFSpUyxY/hw8PSE77+HylUcrCj4lKk+Ry9IFhkJr78Op0+nWiySduk8mkGdOgXNm8PQoeYc0aWL6YedSvkQHg7vvw8VK8KiRaZF7rvvmqd84IHEH6scdaWirSSJh4dSRewtW0r/1i2SwpSjYnfKUbE75ajcsTZtiMqbn2+LvEGDI18T5enNZ5+ZNbw8PVP+6VI7R728YNgwU7wtWRJOnoRmzeC11x2Ehv6z0/jx8MEHplryww+pGo+kPTqPZkD79pl2CCtXQtas8M03pjVC9uyp8nSbNpl1zQYPhlu3zDlq1y54803w9v73xytHXakSJ0ly/fp1d4cgkqhly5a5OwSRRClHxe6Uo2J3ylFJkqgo55cHQotTJ8sunj75HtmzO/jzT9NLMbXcqxytW9e0S3juOdMv8sMPTeuEPXuABx80s+euXjV9FJ54Ai5fvidxif3pPJoBlS5t+hLUqGGmunbrlipPc+2aWcusbl3YuRNy5YKvv4YlS0wISaUcdaWirYiIiIiIiKR9Fy+afo2//86yZaZ4sOVYbkqUgPXroXVrdweYcrJmhS++gNmzIXdu2LHD1GT+t/B+olavjemj8NNPZtbtggXuDllE7pX9+yEkxHzt5QW//WYWILuT6ukdmD0bypeHTz4xHyQ9/bQJ4emntdDY3VLRVtKk4sWL06NHD+f9FStW4HA4WLFihdtiut3tMYqIiIiISCo5ehTq14e1awnu0Y+HWoVw9arpn7hxoykopEcPP2wuPW7bFkJDYcAAaPtQJs70GgYbNkDZsvD332aHDz5wd7gikposy/TyrlbN9CeIlidP0noT3KHTp6FTJ3jkEfN1yZKweLGZYZs7d4o/XYakoq0kia+vr8v96dOn43A4nDdfX1/KlCnDCy+8wLlz59wU5Z2bN28ew4cPd3cYkgLKlSvn7hBEEqUcFbtTjordKUclQdu3m+rsX39xJVtRal5dTHCkL089BUuXmnrFveCuHM2fH/78Ez79FHx9zcI/lSrBzBM1zeXQL75oVgJq08Yt8Yl96Dyajl2+DJ07mx4wISFw4IBZESwVREaa8025cjBrlpnM++ab5gOkFi3u7tjKUVcq2kqS3F60jTZy5Ei+/fZbJk6cyAMPPMCkSZOoV68eN2/evKfxNWrUiFu3btGoUaM7ety8efMYMWJEKkUl91KpUqXcHYJIopSjYnfKUbE75ajEa/Fi0xLh7FmOZq9Mhevr2U85Rowwa+0k8GdMqnBnjjoc8PzzpkZbvbqp3zz6KDzTLzPX35kAhw5B5coxD1i+HMLC3BavuIfOo+nU6tVQtSrMnAmZMsFHH5lPcjJlSvGn2rnTXNTwwgtw/bppQ7NtG7z7LmTOfPfHV466UtE2rRg+HEaNin/bqFFmeyq6evVqvONt27ala9euPPfcc0yfPp2XXnqJo0eP8vvvv8e7f3BwcKrE5+Hhga+vLx4eSumMau7cue4OQSRRylGxO+Wo2J1yVOL49lto1w5u3GBj1mZUvbaKyz4F+eEHGDr03vdStEOOlitn+ve+8YZ5/dOmmVrOuhOFY3basgVatTLVlj173Bar3Ht2yFFJQRERphbUpAmcPGl61q5fDwMHQgrXRm7dMueVGjVMy5ns2c1s27Vrzcz+lKIcdaUKV1rh6Wl+87i9cDtqlBn39HRPXLdp1qwZAEePHqVHjx5kzZqVw4cP065dO7Jly0aXLl0AiIqKYvz48VSoUAFfX1/y5ctHnz59uHLlisvxLMvinXfeoXDhwmTJkoWmTZuyJ55fLBLqabtx40batWtHjhw58PPzo3LlykyYMAGAHj168OmnnwK4tHqIltIxSuqyLMvdIYgkSjkqdqccFbtTjkocmzZBRASzMj9Jwxvz8c3rz4oV8MQT7gnHLjnq7Q3vvQcrV0KxYnDkCDRsCEOG/HO19MWLpuKyfbupwIwbB1FR7g5b7gG75KikkLNnYfx48/PbvbuZ8lqjRoo/zeLFZj3DMWNMnbhTJ9i718zuT+l5c8pRV17uDiDDSmzGqaen63U8wcHmk5KwMFOgDQszTaXHjIF33oGRI83/wP92XA+PlJmvnojDhw8DkCtXLgAiIiJo3bo1DRo0YOzYsWTJkgWAPn36MH36dHr27MmLL77I0aNHmThxItu3b2ft2rVk+mca/9ChQ3nnnXdo164d7dq1Y9u2bbRq1YqwJFzKs3jxYh588EEKFCjAgAEDyJ8/P/v27WPu3LkMGDCAPn36cObMGRYvXsy3334b5/H3IkYREREREUmemY3GM+/zWky91ZXyFTyYOxeKF3d3VPbRsCHs2AH9+5tJye+8AwsXwnfftaHM7t3w3HMwbx688gr88YdZPahYMXeHLSJJVbgwTJ1qetg+9VSKH/7CBVOK+u67mKf79FN46KEUfypJiCXJEhQUZAFWUFBQvNtv3bpl7d2717p161b8BzDr+sV/a9fOdd8sWRLet3hx131z505435o1k/16g4ODXe5PmzbNAqwlS5ZYFy5csE6ePGn9+OOPVq5cuazMmTNbp06dsrp3724B1uDBg10eu3r1aguwZsyY4TK+YMECl/Hz589b3t7eVvv27a2oqCjnfm+++aYFWN27d3eOLV++3AKs5cuXW5ZlWREREVaJEiWsYsWKWVeuXHF5ntjH6tevnxXfj0FqxBiff80TSbLAwEB3hyCSKOWo2J1yVOxOOSrWrVuW9d57VlRomDVmTMyfOW3aWFYCf5bdU3bO0Z9+sqwcOcz7lSWLZU2ebFlRkVGW9fnnluXnZzZky2ZZ337r7lAlFdk5RyUJgoMtq08fy5o/P1WfJirKsqZNs6ycOc2pweGwrBdftKxr11L1aS3Lyjg5+m81xWhqj5DW3aNPQqNnyN6uRYsW5MmThyJFivDEE0+QNWtWZs2aRaFChZz79O3b1+Uxv/zyC/7+/rRs2ZKLFy86bzVq1CBr1qwsX74cgCVLlhAWFkb//v1d2ha89NJL/xrv9u3bOXr0KC+99BIBAQEu2xxJaG51L2KUlFWlShV3hyCSKOWo2J1yVOxOOZrBXbli+rC++SarKz3P4MFm+IUXYM4cc7W/u9k5Rx9/3Cwg1Lw53LwJ//0vPPSwg/Mde5vpuA88YFYVuq0VnKQvds5R+Rc7d0KtWvD559Czp/lBTgV//WXOEz17mgUNq1SBDRtgwgTIli1VntKFctSVirbucuNGwrfffnPd9/z5mG1vv23GvL3Nv40aue577FjCx121KtnhXr9+Pd7xTz/9lMWLF7N8+XL27t3LkSNHaN26tXO7l5cXhQsXdnnMwYMHCQoKIm/evOTJk8flduPGDc6fPw/A8ePHAShdurTL4/PkyUOOHDkSjTe6TUPFihXv7IXewxglZd3ez1jEbpSjYnfKUbE75WgGduIENGgAq1dzw9OfIX91xcMDPvnE3Lxs0vTP7jlauDAsWmRa2Hp7w9y5ZgGhuftKmr8Vv/sO+vWLeUBQkPuClVRh9xyVeFiW6UlQu7ZpJJs/v+l3ksDEuuQKCzMtVCpXhuXLTWfNDz6AzZvNU98rylFXNvnvLQPy87vzfUeNcu1hG70IWaZMMT1t7+S4dyAyMjLe8dq1a1OzZs0EH+fj44PHbZ2po6KiyJs3LzNmzIj3MXny5El+oCkkLcQorhL6YEHELpSjYnfKUbE75WgGtXMntG0LZ85w1qsQLSIWcCJbReb+ZIbtJC3kqIcHvPwytGgBXbrArl3QoQP06ePJRx91wS/6T7cbN8yCRo0bw8cf22Mqs9y1tJCjEsulS/Dss/D77+Z+u3YwfTqkcD1i7Vro3dvUhAFat4ZJk6BEiRR9miRRjrpS0TatiC7Qxl50LPrfoUNd79tcyZIlWbJkCfXr1ydzIgujFfun9cPBgwe57777nOMXLlzgyr9ctlOyZEkAdu/eTYsWLRLcL6FWCfciRhERERERScTy5dCxI1y7xj6PCrSKmI9nsSKsm2tWMpfkq1QJNm2Ct94yM28//xyWLYMZM8wV2CxaBEeOwOHDZsPXX8e9ylNEUs+FC1CtGpw+babGf/ABvPgiJKHdY1JdvQpvvAGTJ5v7efKYNghPPJGiTyN3Qe0R0orISNeCbbQhQ8x4AjNhU4pXCl5z9PjjjxMZGcmoUaPibIuIiODq1auA6ZebKVMmPvnkEyzLcu4zfvz4f32O6tWrU6JECcaPH+88XrTYx/L7Z2by7fvcixglZeXMmdPdIYgkSjkqdqccFbtTjmYwN26YRqzXrrGKRjwQtZrCdYuwcaN9C7ZpLUd9feGjj2DJEihUCA4eNK1t33kHIh7qBCtXQvHipgVfkyYwaJBZpV7SrLSWoxlanjzQsiXcf79pKjtgQIpVUi0LfvkFypWLKdg++yzs3w9PPunegq1y1JVm2qYVw4cnvO0ezLDNmjVrih2rcePG9OnTh9GjRxMYGEirVq3IlCkTBw8e5JdffmHChAl07tyZPHny8OqrrzJ69GgefPBB2rVrx/bt25k/fz65c+dO9Dk8PDyYNGkSHTp0oGrVqvTs2ZMCBQqwf/9+9uzZw8KFCwGoUaMGAC+++CKtW7fG09OTJ5544p7EKCmrfv367g5BJFHKUbE75ajYnXI0Y4nKkpWvmv1Alp+n8Sxf8cgTvkydavos2lVazdHmzU0Xir594eefzZ+X8+fDt9825L6dO00/ha++grFjYcEC00+zalV3hy3JkFZzNMM4dsz0qs2b19yfONH8m4JtME+cMK2r58419++/38y0b9w4xZ7irihHXWmmrSRJcHBwih5v8uTJTJkyhfPnz/Pmm2/yxhtvsGzZMrp27eryQ/rOO+8wYsQItm/fzqBBgzh8+DCLFi1yzpBNTOvWrVm+fDllypTho48+YuDAgSxdupQOHTo49+nUqRP9+/dnwYIFdOvWjSeffPKexigpZ/Pmze4OQSRRylGxO+Wo2J1yNAOIioLDhwkOhs6doffPLejKDF4f6sv339u7YAtpO0dz5oQffzT12OzZYd06s2r89N+yYX3xJfzxhykk7d5trvSUNCkt52i69/PP5sOQHj3MuRBMsTaF6gqRkTB+PJQvbwq2mTLBsGGwY4d9CragHL2dw4p9Tbck2bVr1/D39ycoKIjs8TRlDwkJ4ejRo5QoUQJfX183RJiyrl69SkBAgLvDSHfSW56405w5c1wK8iJ2oxwVu1OOit0pR9O50FB4+mmiFi3hsYJrmbm3LN7eMHWqWTArLUgvOXrsGDz9NKxebe4/+qiZiZcr6gK8/jq8955ZwV7SnPSSo+lKcDC89BJ8+aW5X7cuzJsHOXKk2FNs3w69esHWreZ+w4bmZ7pcuRR7ihSTUXL032qK0TTTVkRERERERNzn6lVo0wZ+/pmIq9dh7x7y5DHrX6WVgm16Ury4WQNu9Gjw8oLffjMLly3ansdU0WMXbJ9/3jTF1FwwkTu3YwfUrGkKtg6HWRlw1aoUK9gGB8Orr5qn2LoVAgJgyhRYscKeBVuJS0VbSRKHlg4Um/P29nZ3CCKJUo6K3SlHxe6Uo+nUqVNm2teKFVwjG+2Yx/7yj7JxI6S11obpKUc9PWHwYNi4EcqWhb//htatzVpIt279s9Py5TBpkmmG27692UlsLT3laJpmWfDJJ1C7tln9q2BBWLrUrAKYKVOKPMW8eVChgllsMCoK/vMf2LfPzLj1sHElUDnqSu0RkimjtUeQ1KE8EREREZEMa88erDZtcJw6xd/kpy3zydeqKj//DP7+7g5Oot28Ca+9Bp9+au6XLw8zZkDVylHwv/+Z6m5oqGmMO2kSPP64ewMWsbvgYNM0+vBheOghs9BfCi1kfvas6bbw00/mfrFi5seybdsUObykELVHkBR1y/lxqog97du3z90hiCRKOSp2pxwVu1OOpjM7d2I1aIDj1Cn2cz/1WM8Dfavy559pt2CbXnM0SxaziP28eZAvH+zdayYIfviRB1EvvgTbtkH16nD5spnO16ULXLni7rAlHuk1R9McPz/44Qcz23b27BQp2EZFwRdfmLYHP/1kZtO+8grs2ZO2CrbKUVcq2kqShIaGujsEkUQdOnTI3SGIJEo5KnanHBW7U46mL1fylGGXVYm1PEBDx1oGTijOp5+aHqppVXrP0bZtYdcuePhhCA83s2+bN4cTWcvD+vXw9tumUvT999Cqlfrc2lB6z1HbCg+HN9+Mma4OUKsWvPCC6WV7l/btg8aNoXdv0yK8Rg3YvBnGjjX14bREOepKRVsRERERERG5NyyLQ4egXlNfGgX9QUe/JUyfk4sXX0yR2oWksjx5YNYss26Sn59Z0KhyZfjhN28YNQrWroXSpWH4cH1DRQCOHjV9u0ePNlNfT51KsUOHhMCwYabTwpo15mfy449hwwYz+V3SPhVtU5laBktilB8iIiIikiFERcHrr3Oi25vUqQMHDkD2IgEsXZeZ9u3dHZzcCYcDnn0WAgOhTh0ICoKnnjJdEa6WrWuux479TZ0zx0z7E8lofvgBqlY1K/oFBMB330Hhwily6JUrzaFHjjQTeR980LQueemltH3FgrjSQmTJ9G9NgyMjI/nrr7/ImzcvuXLlckOEKSsqKgoPOy8xmEZdunSJ8+fPU6ZMGTw9Pd0dTpoWFhamlSbF1pSjYnfKUbE75WgaFhYGzzxjVq8CarAFr9o1+P13yJ/fzbGloIyYoxER8O67ZpJtZCQUKQLffANNmvyzw8mTUKkS3Lhh2ie89RZkyuTOkDO0jJijbnHjBvTvD9Onm/v165vzX7Fid33oy5dh0CCYOtXcz5/ftMZ99NH0Mbk9o+RoUhciU9E2mZLyBv/9999cvXqVvHnzkiVLFhxp+Ccoo/zg3CuWZXHz5k3Onz9PQEAABQoUcHdIad7JkycpUqSIu8MQSZByVOxOOSp2pxxNo65dw+r0KI6lSwjHi158wc3HevD115A5s7uDS1kZOUc3boSuXeHQIVM4evVVU8j1Cb4M/frBjz+aHWvWhG+/hbJl3RtwBpWRc/SeCQuDatXMtFcPD/NhxZAhdz391bLMxN2XX4bz583Yf/9rui4EBNx92HaRUXI0qUVbTZpORfn/+dj4fPRPVBp28+ZNsmTJ4u4w0p2AgABnnsjdCQwMzBAnd0m7lKNid8pRsTvlaBr0999EtWmHx85AbuBHZ36l1tttGDHC1DLSm4yco3XqwPbtMHCgWcH+ww9h0SKYMSMnFX74waxe1rcvbNliClrvv28WYUqPiWBjGTlH7xlvb/MJxmefmXYIjRvf9SGPHjU/PgsXmvvly8OUKWYCb3qjHHWlom0qcjgcFChQgLx58xIeHu7ucO7K8uXLadq0qbvDSFcyZcqklggiIiIikj4dOEBEyzZ4nTzGOfLysNc8+k2tQbdu7g5MUkvWrKaQ1L49PPcc7NhhVrH/4AN44YUn8GjY0LTJWLQIBgyAuXNh3jw14JS07/x509y5dGlz/7XXzDTYHDnu6rDh4TB+vFls7NYt8PExk3YHDTK1YUn/dHa8Bzw9PdN8cS4iIgJfX193hyEiIiIiImnA8d8DKXbyGH9RmicDFjD+j/to2NDdUcm98PDDZubtM8/A/PmmPvvnnzBtWiEKLlgAkyaZ/gnly6tgK2nf4sXQrRvkzg2bNkGWLODpedcF282boVcv8+EHQNOmMHkylCmTAjFLmqGetsmU1P4T6cXly5fJmTOnu8MQSZByVOxOOSp2pxwVu1OOph1z5sCTT8LDwTM4WqoV3y7IQ8mS7o4q9SlHXVmWqc++8gqEhEDOnKZ1QqdOwMGDULhwTGPjkyfN17lzuzXm9E45moLCwsy01w8+MPcrVDCfTtzlYmPXr5s2uJ98Yn6GcuaEjz6C7t3Tx0Jj/yaj5GhSa4pqICMiIiIiIiJ3zZr+NVOGn+HhhyE4GM4178K8zRmjYCtxORzw/POwbRtUr25WvX/0UTMD93r+0jEF28hIU+WvWNEUvUTs7vBhaNAgpmDbt6+ZGnuXBds//jAT0P/3P1Ow7dYN9u+HHj0yRsFW4lLRVpJk7dq17g5BJFHKUbE75ajYnXJU7E45amOWReQbb+Po2YM6I9ria92kd29zaXx6WtX83yhH41euHKxfD2+8YQpP06ZB1aqwbt0/O5w7B1eumH8ffBD69IEbN9wZcrqlHE0BM2aYBN682bRAmDnTLDoW/SFEMpw+bT7QePhhOHUK7rvPtH7+5hvIkyflQk8LlKOuVLQVERERERGR5AkPJ7TrM3iOeReAWXTinbGZmTwZMmVyc2xiG97e8N57sHKlmYx45Ag0bGiuLg/PUxC2bIGXXzY7T5kCVaqAijdiN1FRpsfHjRsmgXfsgEceuavDffaZ+WBj5kzT4nnwYNi1C1q2TMG4Jc1S0VZERERERETu3I0b3GzeAZ/vpxOBJ/28v6DGH8MY+IpDl/JKvKLrXE8/bQpW77wD9evDXyczw7hxsGwZFC1qqrqNGpnpuWFh7g5bxPDwgO++M59ALF8ORYok+1C7dpnc79fP9LGtUwe2boXRo81aZiKgoq0kUdWqVd0dgkiilKNid8pRsTvlqNidctRmzp3jes0mZFm9kGCy8Gyu3+m18Tk6dHB3YO6jHE0af3/4+mv46SdzdfnmzVCtGnz+OVhNmsLOnWbVpago02NDUoxy9A5FRcHYsWY1vWiFC5sPEzw9k3XIW7fgzTdNn+cNGyBbNpg40Uwsr1w5heJOw5SjrhyWZVnuDiItSupKb+lFWFgY3t7e7g5DJEHKUbE75ajYnXJU7E45ai+nqj9E4e1zuEBuXi37J2OW1aZAAXdH5V7K0Tt36pRZZGnpUnP/wQfhq68gb15g1iwoVQoqVTIbIyJMU9xkFstEOXpHzp41Hx4sWmTub9wItWvf1SGXLjUtmw8fNvcfeQQ++QQKFbrLWNORjJKjSa0p2mqm7apVq+jQoQMFCxbE4XAwe/Zsl+0zZ86kVatW5MqVC4fDQWBgYJxjhISE0K9fP3LlykXWrFl59NFHOXfunMs+J06coH379mTJkoW8efMyaNAgIiIiUvGVpX0LFy50dwgiiVKOit0pR8XulKNid8pRe4iKMn1I623/lJU0YkSrdUzaqoItKEeTo3BhUxMbN870vZ0719Ro587FVLSiC7YA774LTZvC0aNuizetU44m0YIFpq/yokVmgbEpU6BWrWQf7sIF0xKkRQtTsC1UyHwmMXOmCra3U466slXRNjg4mCpVqvDpp58muL1Bgwa8//77CR7j5ZdfZs6cOfzyyy+sXLmSM2fO0KlTJ+f2yMhI2rdvT1hYGOvWrePrr79m+vTpDB06NMVfj4iIiIiISHoR8tcJnnzS9CE9RREWvrGS/80vrf6Lclc8PMwaZFu2mBrt+fPQoQP8978QHPzPTkFBMGECrF5triH/6ivQRcOS0kJDTSuEtm1NIlaqZBKzVy+S06jbskwrkHLl4NtvzSH694e9e6Fjx5QPX9IfL3cHEFvbtm1p27Ztgtu7desGwLFjx+LdHhQUxFdffcX3339Ps2bNAJg2bRrlypVjw4YN1K1bl0WLFrF3716WLFlCvnz5qFq1KqNGjeL1119n+PDhCU7DDg0NJTQ01Hn/2rVryXyVIiIiIiIiaUvQR1+SZdDzRFrfkylTZ6ZMMZe1i6SUSpVg0yZ46y0z8/bzz826ZDNmQK1a/maVpu7dTeH2uefg99/hiy8gXz53hy7pgWVB+/YxvTpeeAE+/BB8fZN1uIMHzQcPy5aZ+5Urmwm7deqkULySIdiqaHu3tm7dSnh4OC1atHCOlS1blqJFi7J+/Xrq1q3L+vXrqVSpEvlindhbt25N37592bNnD9WqVYv32KNHj2bEiBFxxufPn0+Wfz5abtmyJZcuXWLbtm3O7fXq1cPLy4vVq1c7xypXrkyhQoWYH6up+n333UeFChVYvHgxISEhAOTNm5c6deqwfv16Ll68CECWLFlo3rw5u3btcilet2/fnmPHjrFnzx7nWOPGjQkJCWHjxo3OsZo1a+Lv78/S6BPRP+9R6dKl+fPPP4mKigKgSJEiVK1alRUrVnD9+nUsy2LNmjU0aNCALVu28PfffwOQKVMm2rRpw/79+zl48KDzmK1ateLChQts377dOfbAAw/g4eHBmjVrXN6LggULsmDBAudYyZIlKV++PIsWLXIWyvPly0ft2rVZt24dly5dAsDPz49mzZqxY8cOTpw44Xx8hw4dOHz4MHv37nWONW3alODgYDZt2uQcq1WrFtmyZWNZ9FkUKFeuHKVKlWLu3LlEt3suWrQoVapUcb4XADlz5qR+/fps3ryZs2fPAuDt7U3r1q3Zt28fhw4dch6zdevWnDt3zqWdR/369QFYu3atc6xq1arky5fP5XKAUqVKUa5cORYuXEjYP6um5s+fn1q1arF27VouX74MQLZs2WjSpInLe+FwOHjwwQc5dOgQ+/btcx6zWbNmXL9+nc2bNzvHateujZ+fH8uXL3eOlS9fnpIlSzJnzhznWPR7sWzZMoL/+dg7V65cPPDAA2zatMnZisTHx4dWrVqxd+9eDkc37AHatGnDmTNn2Llzp3OsQYMGREVFsW7dOudYtWrVyJMnD4ui+wcBpUuXpmzZsixYsIDw8HAAChQoQM2aNVmzZg2WZTFnzhznexEYGMjJkycB8PDwoH379hw8eJD9+/c7j9m8eXOCgoLYsmWLc6xOnTr4+vqycuVK51iFChUoXrw4f/75p3OsePHiVKpUiaVLl3Lz5k0AcufOTb169di4cSPnz58HwNfXl5YtW7Jnzx6OHDnifHzbtm05ffq0y3vRsGFDIiIiWL9+vXOsevXq5MqVi8WLFzvHypQpw/3338/8+fOdrV0KFixIjRo1WL16NVevXgXA39+fRo0asW3bNk6fPg2Ap6cn7dq146+//uLAgQPOY7Zo0YIrV66wdetW51jdunXx8fFxeS8qVqxI0aJFmTdvnnOsRIkSVKxYkSVLlnDr1i0A8uTJQ926ddmwYQMXLlwAIHPmzLRo0YLdu3dzNNZlbe3atePEiRPs3r3bOda4cWNCQ0PZsGGDc6xGjRrkyJGDJUuWOMfuv/9+ypQpw7x584iMjASgUKFCVK9enVWrVhEUFARAQEAADRs2ZOvWrZw5cwYALy8v2rZty4EDB/jrr7+cx0ytc7mvr6/z58ld53KAHDly6Fyuc3m85/JSpUq5/Vx+5coVl/dC53Kdy2Ofy6MnV7jzXG6H38vhHp/Ly5Vj88O9qDXnKwDaZVpE/8WdyZRpHXPm6Fwe+1xuWRYrVqzI8L+X3+25vEkTyJEjN599VpuDBz2pVy+KJ574i86dD1H5q68oPns21ptv4jlnDqFlynB2+HCKvfyyzuX8+7k8+m+mjP57ebzn8t27Ca1Zk8qbNhHYvz81R41K1rk8PNzBmjV1+eyz3ISGgrd3JE8+eYB+/cKoVUu/l0Pi5/IsWbI4z3Xp+ffy6HPVv7HtQmQOh4NZs2bRMZ4548eOHaNEiRJs377dZWW577//np49e7rMiAXzZjVt2pT333+f3r17c/z4cZdv2s2bN/Hz82PevHkJzvSNb6ZtkSJFMsxCZCIiIiIiksFERHDiwecpuvALACblfIsW60dRusydXyYscqcuX4a+feHnn839Bx4wl5jfdx+waxd06wY7dpieo4cPo8bKcseuXTNTYmvUiBm7ehUCApJ1uHXroHdviK7ztmoFkyb9k7MisaTJhcjszMfHh+zZs7vcMhI1gxa7U46K3SlHxe6Uo2J3ytF7y7oRzNGqj1B04RdE4sH4Mp/xn4PvqGCbCOVoysqZE3780RRqs2c3BbEqVWD6dLAqVoKNG2HwYBg7VgXbJFKOxrJpE1SrZvrX/jPLFUhWwTYoCJ5/Hho0MAXbPHngu+/MemYq2N4Z5airdFW0zZ8/P2FhYc5LEKKdO3eO/PnzO/eJvlQk9vbobRK/6GnjInalHBW7U46K3SlHxe6Uo/dOxPVbHCvVnBJ75nILXyY1/43nd/UlZ053R2ZvytGU53BA165mQm3DhnDjBvTsCY89Bpdu+MDo0aZaFm3tWhg4EP5pDSCulKNAVBS8/z7Urw9HjkCWLGbRsWSwLPjtN7PQ2KRJ5v4zz8C+fdClS7LWLsvwlKOu0lXRtkaNGmTKlMmlL9SBAwc4ceIE9erVA0z/k127djn72gAsXryY7NmzU758+Xses4iIiIiIiF0EBcGDj2Vm1rkHuEROZvVbSr/FHUlgvWaRe6J4cVi+3NRovbxMoaxSJYjVahfCwsxCZR9/DDVrQqw+qCKAmVHburWZoR0RAf/5DwQGmincd+jkSXj4Yejc2Ry2TBmTo199BblypXzokjHZqmh748YNAgMDnc2Ejx49SmBgoLPp7+XLlwkMDHQ2Pz5w4ACBgYHOhvP+/v48++yzDBw4kOXLl7N161Z69uxJvXr1qFu3LmCaN5cvX55u3bqxY8cOFi5cyNtvv02/fv3w8fG59y86jdAsZLE75ajYnXJU7E45KnanHE19R4+avqELF8LQzGPZMmU7T018QLPFkkg5mro8PU2tbeNGKFs2pv42YMA/E2u9vWHCBMiXD/buhTp14J13THFOgAyeo3/+CZUrw5IlZnbtV1/BDz/ccTuEyEiTZuXKwZw5kCkTDBliZoM3aZIqkWcoGTpH42GrhchWrFhB06ZN44x3796d6dOnM336dHr27Bln+7Bhwxg+fDgAISEhvPLKK/zwww+EhobSunVrPvvsM5dv/PHjx+nbty8rVqzAz8+P7t27M2bMGLy8vJIca1KbBouIiIiIiNjd3o8XcnzwZ3QM+5ncBX2YMweqV3d3VCLxu3kTXn8dJk4098uXhxkzoGpV4OJFs4LZr7+ajXXrwjffQOnS7gpX7ODZZ2HqVDOr9scfTeX/Dm3fbhYa27LF3K9fH6ZMMfkncieSWlO0VdE2LcloRdu1a9dSv359d4chkiDlqNidclTsTjkqdqccTT3r+35DzcnPkokIPik4mk6bBlOokLujSnuUo/fe/Pmmx+25c2bG47vvwiuvgIfDMlXcF14wPT+yZIGtW5NVqEtPMlyOWlZMY9ngYNM649VXwdf3jg4THAzDh5uHR0aCvz988AE89xx42Or69bQvo+RoUmuKyU6vyMhIfvzxR/r06cMjjzzCrl27AAgKCmLmzJlxFvuStO3y5cvuDkEkUcpRsTvlqNidclTsTjma8qwoiyXNR1NvcncyEcHKwl14ZvdAFWyTSTl677VtC7t2QceOEB4Or70GzZvDiZP/rGC2a5cZaN4c7r/f3eG6XYbJUcsys2o7dzYLjwH4+cHbb99xwXbBAqhYEcaONQXbxx83C4317q2CbWrIMDmaRMlKsatXr1K/fn2eeuopfvjhB/744w8uXLgAQNasWXnxxReZMGFCigYqIiIiIiIiKSMkOJLFZV+gxbI3AVhR+zUaHv0GvxxacUzSljx5YOZM+PJLU5dbscK0Lv3hB6BIEbNa2fffx8y4vHo1pnWCpD9Xr8KTT5p2CDNnws8/J+sw586Zw7RtC8eOQdGiMHcu/PQTFCiQohGLJChZRdvBgwezZ88eFi5cyJEjR4jdYcHT05POnTszb968FAtS3C9btmzuDkEkUcpRsTvlqNidclTsTjmacs4du8XGIp1pdfAzonCw/okJNNn4Ph5emjZ2N5Sj7uNwmBpdYKBZfywoCJ56Crp0gavXPCBr1pid+/eHxx6DJ56ADDarL93n6Pr1UK2aqax6esLo0WZq7B2IijIfAJQta1rfenjAwIGwZw+0b59KcYtTus/RO5Ss/5Vnz55N//79admyJY54lhItU6YMx44du9vYxEaaaBlEsTnlqNidclTsTjkqdqccTRm7d8OT9U9Q5cpyQvBh77CfqffDi+4OK11QjrpfqVKwZo3pP+rpaSbYVq5sZt8C5rL5UqXMxp9+Mte9L1jgxojvrXSbo5GRpqFxw4ZmWmyJErB2LQwefEc9DPbvh6ZNoVcvM2G3enXYtAk++si17i+pJ93maDIlq2gbFBREiRIlEtweHh5OREREsoMS+9mxY4e7QxBJlHJU7E45KnanHBW7U47evQUL4IEHYPmZ++lX6HcufLeIisM7uzusdEM5ag9eXjBsmKnZlSoFJ09Cs2am321omMNsXL/e9Lj9+29z/fvzz5vVptK5dJujffqYfrWRkaanwfbtZsp1EoWGmkJ/lSqwapVZt27cONi4EWrUSL2wJa50m6PJlKyibcmSJdm2bVuC2xctWkT58uWTHZTYz4kTJ9wdgkiilKNid8pRsTvlqNidcvTu/PjGDka3W83169C4MfxvR2OKdGnk7rDSFeWovdSpY2p3vXqZCbYffmjG9uwBatWCbdvgxX9mmU+aBFWr/rMx/Uq3Odq3L+TIAdOnw4wZ4O+f5IeuWmW+9SNGQFiYaYGwdy+8/LL5AEDurXSbo8mUrKLtc889x9SpU/npp5+c/WwdDgehoaG89dZbLFiwgD59+qRooCIiIiIiInJnIiLgk45LaTemIb9bHXiz414WLYJcudwdmUjqy5oVpkyB2bMhd27YscPMnPzf/yDKNwtMmACLF0Phwmambf787g5ZkiIkJFbPC8w39fhx6N49ZsG5f3HliinoN25s2iLky2c6ZsyZA8WKpU7YIncqWZ8bDBgwgD179vDkk08SEBAAwFNPPcWlS5eIiIigT58+PPvssykZp7hZfL2LRexEOSp2pxwVu1OOit0pR+/ctWswudH3vLSjB96Ec/y+JrwztSAOb3dHlj4pR+3r4YfNLNtnnoH582HAAPjzT5g2DQq2aAG7dsHhwzGfZliW6atQtKh7A09h6SJH9+41i8gdOAAbNpiFxwCSuICVZZni7IABcP68GevTB8aMgX/KW+JG6SJHU5DDip4qmwxr1qzh119/5eDBg0RFRVGyZEkef/xxGjVK/5fZXLt2DX9/f4KCgsiePbu7wxEREREREXE6fszi17pjeeXcawCceuBxCi/7Bnx83ByZiPtYlumE8MorZrJmzpzwxRfQqdNtO373HTz3HIwebap7d7CYlaQSy4IvvzTfj1u3IE8eU31t2jTJhzh61LQvjl57rlw5MxO7QYNUilkkAUmtKd5V0TYjy2hF20OHDlGqVCl3hyGSIOWo2J1yVOxOOSp2pxxNug3rotjZYiC9b00A4OxTL5P/27EqPKUy5WjasW8fdO1q2toC9OxpOiU4J2s+9RT88IP5ukkT0ys1HVwzn2Zz9MoV6N0bfv3V3G/ZEr75JsntLCIiYPx4GDrU1Hu9vc26Za+9ps+x7CbN5ugdSmpNUf9rS5Ls27fP3SGIJEo5KnanHBW7U46K3SlHk+bHH+Gnxp86C7ZXh3xE/hnjVLC9B5SjaUe5crB+PbzxhmmBOm2aWYxq3bp/dpgxAyZPhixZTO/UypXh66/NbM80LE3m6Nq15pvz669mZbAPPzRTZZNYsN282aw7N2iQKdg2aWK6YQwZooKtHaXJHE1FyeppW6JEiX/tM+FwODh8+HCyghIREREREZGksywYNQqGDQNvetM17zwqvN+dgB5PuDs0EVvy9ob33oO2baFbNzhyBBo2hDffhKFDHWTq0weaNzeLW61bBz16wO+/w+efm0vz5d5YuxZOnICSJc3s51q1kvSw69dNYfaTTyAqyrTCGDvWfBvVNlXSimQVbRs3bhynaBsZGcnx48dZu3YtFStWpFp0M2gRERERERFJNSEhMLDreSb/lhvwoP8rPlQdMw9PL1UmRP5Nw4awYwe8+KK54v6dd2DhQtPWtkyZUrBqFXzwgflEZNYs6N//jvqoSjJYVkxl9dVXzdf//W+SFxubMwf69TNryQF06QLjxkHevKkUr0gqSfGetjt27KB169Z89913tGjRIiUPbSsZradtcHAwfn5+7g5DJEHKUbE75ajYnXJU7E45Gr8LF2Bgq92MDmzDL47/kPXzj+jVy91RZUzK0bTv559NbfDKFdMZYdw400rV4QACA2H5cnj55ZgHxC4upgFpIkdnzTJv/MKF5ptwB86cMcX3334z90uUMF0uWrVKhTglVaSJHE0BbutpW6VKFfr06cPrr7+e0ocWN7p+/bq7QxBJlHJU7E45KnanHBW7U47GtXcv9K+8kk8CG1CY0/QuMp9e/7nm7rAyLOVo2vf447Bzp+mKcPOmKeA+9BCcP4/pqxq7YHv4sOl1u2qVu8K9Y7bO0Vu34PnnoVMnWLPGrByWRFFRMGmS6VX822/g6Qmvvw67d6tgm9bYOkfdIFW60efLl4+9e/emxqHFTTZv3uzuEEQSpRwVu1OOit0pR8XulKOuFi+G92v+wtdnWxFAEDer18dv+xrIAFcB2pVyNH0oXBgWLTKTPb29Ye5cqFTJ/Ovi7bdNVbBJE7PKVUiIO8K9I7bN0d27Ta/aSZPM/ddeM20RkvjQhg1NvffaNahdG7ZuhTFj7niirtiAbXPUTVK8aHvp0iW++uorChcunNKHFhERERERyfAmT4Z5rScw7dZ/8CGM0PadyLJmsVlpR0TumoeHmVS7ZYsp2J4/Dx06mJm3wcH/7PT55/Dss6ZFwtixpugYGOjOsNMeyzIntFq1YM8eyJfPtEV4/31TMU/ErVvw1ltQrZpZJy5rVrPo2Lp1UKXKPYpfJJUlayGyZs2axTt+9epV9u/fT1hYGN9+++1dBSYiIiIiIiIxIiPN5LPc49/iY94zY//th8/ECeZ6YBFJUZUqwaZNZlLtRx+ZOu2yZTBjBtSqlR2+/NL0T+jVy0z5rF0bRowwM0X1M/nv3nkHhg41X7dpA19/naTVwpYtgz594NAhc79jR1Ow1dxBSW+SNdM2KioKy7JcbgAlSpTghRdeYPfu3Tz55JMpGqi4V+3atd0dgkiilKNid8pRsTvlqNhdRs/R69fh4YdNm8dAqhLl8MB6bzSen32i4pBNZPQcTa98fc1E2iVLoFAhOHgQHnjA1BsjIjBF2927TeUwPBzefBOmTHF32PGyXY4+8wwULGh6Ufz5578WbC9ehB49TM/hQ4fMQ2fONGuXqWCbPtguR93MYUVXXOWOJHWlt/Tixo0bZM2a1d1hiCRIOSp2pxwVu1OOit1l5Bw9ccJcmr1zpykgffstdK50AO6/392hSSwZOUczisuXoW9f+Plnc/+BB8zP4333YS71/+YbmDbNNMX9l8v73cHtORoRYdoftG8fM3bz5r82n7Us+O4707Li0iVwOKBfP3j3XbXxTm/cnqP3SFJriqmyEJmkP8uXL3d3CCKJUo6K3SlHxe6Uo2J3GTVHN22CDjXO8N7O9lTPc5JVq6BzZ1SwtaGMmqMZSc6c8OOPplCbPXtM/9Tp08HCAd27w/LlMQXb8HB45RX4+2+3xh3NrTl6/LhZtO3BB+H332PG/6Vge+gQtGwJTz9tCraVKpn3/ZNPVLBNj3QedZWknrbffPNNsg7+9NNPJ+txIiIiIiIiGd2vv8I7XfbxR1gbinGC5mV64ltribvDEsnQHA7o2hUaNDCFxNWroWdPmDvX9LzNlcsRs/Po0ebS/+nTzYJbjz3mtrjd6rff4Lnn4OpVyJbNFLP/RXi4aUsxciSEhJirDIYNMzXwTJlSP2QRO0hS0bZHjx53fGCHw6GirYiIiIiIyB2yLFPr+fOttSyjAzm5QlSpMvh++4W7QxORfxQvbibVfvihWUvrt9/MDNDp06FVq392evRRmD0btm+Hxx+HLl1g4kQICHBb3PfUzZump0F0j986deD77//pJ5Gw9euhd2/TKhjMTNtJk6BkyVSOV8RmklS0PXr0aGrHITZXvnx5d4cgkijlqNidclTsTjkqdpdRcjQ01BQrrn0ziyU8RWZCsOrUxWPuHMid293hSSIySo5KDE9PGDzYFGm7dIH9+6F1a3jxRRgzBjJXqAAbNpjpoqNHw4wZsHKl6XvbosU9j/ee5ujOnfDEE7Bvn5mePHgwjBiR6DTZoCCzjtukSebDq9y54eOPzXvrcCT4MElHdB51pYXIkimjLUQmIiIiIiKp6+JF6NQJKq7+jIm8gAeWWZn+hx/+te+jiLjXzZvw+utmIi1A+fKmRlu16j87bNgA3bqZJq0AEyaY6m56NXOmmWlcoIBpAty8eYK7WhbMmgX9+8OZM2asRw/THiFXrnsTrsi9pIXIJEXNmTPH3SGIJEo5KnanHBW7U46K3aX3HN2/H+rWhY2rQ3ne43NTsO3Tx1xzrYJtmpDec1QSlyWLWRxr3jzIlw/27oXatU37hKgozA94YCD07Wt2btPmnseY6jkae05gp06mj++OHYkWbE+ehI4dTX33zBkoXRqWLjWTkVWwzXh0HnWVpPYI8Tl79ixfffUV27ZtIygoiKioKJftDoeDpUuX3nWAIiIiIiIi6dnSpdC5s1mjp0QJH7ynzocdv5hZeLomWCRNadsWdu0ybU5mz4bXXjOF3K+/hqJF/eCzz+Ctt6BQoZgHLVkCjRun7RW2VqyAl14yL7ZgQTPWp0+Cu0dGwqefmrfixg3z0l9/3dz39b0nEYvYXrJm2u7cuZPy5cvzzjvvcPjwYZYvX86FCxc4ePAgK1as4OTJk6jrgoiIiIiISOKmTIFHW12n2dXfqF8fNm6EMk0KwoABKtiKpFF58pjuAF9+CX5+pp5ZubLpdAK4FmxXrzZNcevXN1Pu05rwcHj7bWjWzMyqHTbsXx+yYwfUq2dOczduwAMPmLXaRo1SwVYktmQVbQcPHkzWrFk5cOAAS5YswbIsJkyYwMmTJ/npp5+4cuUKY8aMSelYxY2KFi3q7hBEEqUcFbtTjordKUfF7tJbjkZGwiuvwNA+Z1ka1YTf6Myy3j+SJ4+7I5PkSm85KnfH4YBnnzUdEerUMYtsPfWUWVTr6tVYO165Av7+sHkzVKtmeizcdiVzSknxHD12zMwQfvdd0xrh2Wdh/PgEd79508w8rlHDvFx/f9NBYfVqqFAhZUOTtEnnUVfJWojM39+f1157jbfeeovLly+TO3duFi1aRIt/Vj8cMGAAgYGBrFy5MsUDtgstRCYiIiIiIslx44Yp3Oz74y8W0Ib7OIqVJw+OP/+EWrXcHZ6IpLCICFPXHDXKfGBTpAh88w00afLPDqdPwzPPwKJF5n6LFjB1qtnRrn76yfSAuHYNsmc3lw385z8J7r5woWnne/Souf/YY2YttgIF7lG8IjaSqguRRUVFkS9fPgACAgLw9PTk8uXLzu2VKlVi69atyTm02NSyZcvcHYJIopSjYnfKUbE75ajYXXrJ0VOnoGFDOPfHBtbxAPdxFEqWxLFunQq2aVx6yVFJeV5epmvA2rVQqpRZfKtZMzPrNDQU0y5hwQKYOBEyZzY9bitVgp9/TtE4UixHv/0WnnjCFGzr1TP9DhIo2J4/bz6katPGFGyLFIE5c8xLU8FWbqfzqKtkFW1LlCjB0X8+HvHw8KBEiRIsWbLEuX3dunUEBASkSIBiD8HBwe4OQSRRylGxO+Wo2J1yVOwuPeToli1mNfnCgXNYRjNycwlq1oR160wlR9K09JCjkrrq1DG9W3v1Mt0EPvzQjO3Zg+mn0K+f6adQu7bpp3DjRoo+f4rlaKdOpp/B22/DqlX8n737Do+q2vo4/p30Qgg1QCK99957b6JAFEFQxIYorwXFqyjdgh2Va0G9FAVEpEnvvRdBeu+9BgiQNvP+sckkQxIMEJgT8vs8z3kys8+ZM3uGxc5kzT5rU6BAkkMcDvjlFyhRAsaOBQ8PeOMN2L4dHn44bbohDx6No65SnbS9cOGC83azZs2YMGGC836PHj34+eefadKkCY0bN2bUqFE8+eSTadtTERERERGRdGrSJKhXD7Ke2MYU2hLANbPM/KJFEBLi7u6JyH2SKZOpJDBlCuTIYSapVq4M33xzo5RtsWJmSu7YsdCtW8IDXQrh3mcOB/z5Z0Kt3cBA8y3U4MFmGvFNdu2Chg3h+edNyd6KFWHtWvjyS/P6RSR1Up20zZ07N+3atePPP//kzTffZNy4ccTExADw+uuvM2jQIM6dO0dERAR9+/blgw8+uGedlvsve/bs7u6CyC0pRsXqFKNidYpRsbr0GqMOBwwZAuHhcO0a5G9ZmtjX3jL1K6dOVQbjAZJeY1Tc49FHYcsW891NVBS89pq5ffw4JhHaqZOZfQsm81m2LHTvflezb+8oRs+cgTZtTBHaL75IaPfzS3JoVBQMGgTlysGSJRAQYB6ydq1JTIv8G42jrlK9EFnnzp3566+/uHr1KkFBQbRv357OnTvTqFEjbPEDSQaihchERERERORWoqPhpZfg1xEx+HONZ/4vM19+CV6eN/4Ey4B/R4mIK4cDvv8e3nwTrl+HbNngp59MBQKnsWNNYViAwoXNKma1at37zi1YAF26wMmT4OsLQ4eaQS0Zy5aZdcl27jT3W7WC//432coJIhlemi9ENmbMGE6fPs1vv/1G3bp1GTNmDM2aNSMsLIw333yTjRs3pknHxZrWrl3r7i6I3JJiVKxOMSpWpxgVq0tvMXruHDRtCuNHRDKVtuws/DDffHrdXElssylh+wBKbzEq1mCzwcsvm1q3lSrB+fNmZv6zz8LlyzcOevJJWLjQrOK1b59ZzfDdd803Q7ch1TEaEwPvvGMGsZMnoVQpM102mYTthQsmWVuvnknY5soF48fD9OlK2Mrt0zjq6rYWIvP396dTp05MmzaNkydP8t1331G0aFGGDh1K1apVKVGiBB988AH79++/V/0VNzl16pS7uyByS4pRsTrFqFidYlSsLj3F6O7dUKMG7Fh6mqUeDWnFTEKPrzcLDMkDKz3FqFhPiRKwahX06WMSuSNGQIUKZp1CwBSJ3bIFnn7a1JYdMsQsWLZlS6qfI1Uxun8/1KkDn3xipgF37w7r1pmaB4k4HCY5W7KkmRkMJnm7Ywd06KDvpeTOaBx1dVtJ28SyZs1K9+7dWbJkCYcPH2bIkCEEBATQr18/ihYtSq37MVVfRERERETEQhYtMglb+959rPGqTWX7Osie3VxmXKOGu7snIhbm4wMffmjqwebPb/KndetC375m8ivBwTBqFEycmLCK2aefpm0nLl40036zZDGLj/3wgylOm8jBg9C6NXTsCKdOmcTtsmXw44+QNWvadkckI7vjpG1iYWFh9O7dm1GjRvHoo4/icDhYs2ZNWpxaLMLX19fdXRC5JcWoWJ1iVKxOMSpWlx5i9JdfoFkzKHRhPeu9alIwdq+5PnjFCqhZ093dk3ssPcSopA9165p8bPyk2g8+gNq1zSx+wBS83bIFunWDr79O9XlTjFG7PeF2pUowZozpQHi4y2GxsWZhsdKlYdYsk2QeNMjkeOvUuc0XKZIMjaOuUr0QWUoOHz7M2LFjGTduHFu3bsXhcFCrVi06d+5Mjx490qqflqOFyEREREREBEy+45134LPPoDHzme7VFr/YSKhYEWbOhNy53d1FEUmn/vjDlJK9cMFMeP3yS1OGIEn5AYfDJHHr1jUFcVNbn2DjRuja1czgrVQpxcM2bIAXXjAJWoD69c3M2uLF7+x1iWRkab4QWWJnz57lu+++o06dOhQsWJA+ffoQExPDoEGD2L9/P8uXL3+gE7YZ0fbt293dBZFbUoyK1SlGxeoUo2J1Vo3RyEgzGe2zz8z9tq88hG9mX7OAz5IlSthmIFaNUUnfOnSAf/6Bxo3h6lWTwH3kETh9+qYDZ8wwidfnn4dHHzV1C27iEqN2u8kA16gBW7fC228n+/xXrsAbb5jyuX//bcof/PKLKQWjhK2kNY2jrlKdtI2MjOS3336jVatWhIWF0bNnTw4cOMDrr7/O+vXr2b59O++99x4FtDzgA2nfvn3u7oLILSlGxeoUo2J1ilGxOivG6LFjZsX0KVPA1xfGjoWew0pgW77cLJ0eFOTuLsp9ZMUYlQfDQw/B3Lkmx+rra4aXsmXNT6eWLU19Wx8fmDYNypSBJ56AwYOdhzhj9NQpk3F9801TLLddOzOl9ybTp5tSCEOHmhxv586wc+ftTeQVuR0aR12lOmkbEhJC165dWbFiBU8++SRz587lyJEjfPHFF1S6xRT627F06VLatGlDaGgoNpuNKVOmuOx3OBz069ePPHny4O/vT5MmTdizZ4/LMefPn6dz585kzpyZLFmy8Nxzz3HlyhWXY/755x/q1q2Ln58fefPm5dO0LtwtIiIiIiIPtI0bzcyzTRvj+Mnv/9jw6QI6dbqxs2RJkzgREUkjHh5mxuu6dSZhe/o0tGljZt5GRgKentC7tzmgXDk4e9YkYvv1g/feSzjR3LlQuDDs3QteXmahsYkTIVs25yEnTpgZvm3awOHDULAgzJ4Nv/0GISH3/7WLZFSpTto2adKEcePGcerUKUaMGEGTJk3w8EiTdcycIiMjKV++PP/973+T3f/pp5/yzTff8MMPP7BmzRoCAwNp3rw5169fdx7TuXNntm3bxrx585g+fTpLly7lxRdfdO6/dOkSzZo1I3/+/GzYsIHPPvuMAQMGMHz48DR9LSIiIiIi8mCaMsWUjbxw/Cpzg8J5/vowSvd/zBSdFBG5h8qWhbVrzSRZMHVlK1Y0uVrAJGzXroX//CdhOuxHH8HgwWTfsgWaNzdZ3pAQ2LQJund3Hme3mxxuyZIwYYLJA7/9tqme0Lz5fX+pIhneXS9Edq/YbDYmT55M27ZtATPLNjQ0lDfffJO33noLgIiICHLlysXIkSPp2LEjO3bsoFSpUqxbt44qVaoAMHv2bFq1asXRo0cJDQ3l+++/57333uPkyZP43Pj2+5133mHKlCns3Lkzxf5ERUURFRXlvH/p0iXy5s2bYRYii4mJwdvb293dEEmRYlSsTjEqVqcYFauzQow6HPD55yYXktVxjmVZ2lDq4qqE2gjt27u1f+JeVohRyVgWLDBriB07ZibN9u9vFkX08rpxwPLlCYuTjRiBw8cHW3S0uUxg8WLw93eea9s2s8DZypXmfrVqMHw4lC9/31+WZGAZZRxN7UJkXinusZgDBw5w8uRJmjRp4mwLDg6mevXqrFq1io4dO7Jq1SqyZMniTNgCzhnBa9asoV27dqxatYp69eo5E7YAzZs355NPPuHChQtkzZo12ef/+OOPGThwYJL2WbNmERAQAEDTpk05d+4cGzdudO6vWbMmXl5eLFu2zNlWrlw5wsLCmDVrlrOtUKFClC5dmnnz5jlnDoeEhDhf39mzZwEICAigcePGbNmyhYMHDzof37p1aw4ePMi2bducbfXr1+f69eusWbPG2ValShWCg4NZsGCBs61EiRIULVqUGTNmYLfbAcibNy8VKlRg0KCtjBiRl2PHMpEv3xU+/TQT+fKt58SJEwB4e3vTokULdu7c6VKqolmzZpw5c4a/45eWBGrVqoWHhwfLly93eS9CQ0OZPXu2s61w4cKUKlWKuXPnOhPluXLlolq1aqxcuZJz584BEBgYSKNGjdi8eTOHDx92Pr5Nmzbs27fPpYB1w4YNiYyMZO3atc62qlWrEhQUxMKFC51tJUuWpEiRIkyfPp347zPy5ctH+fLlWbx4MZcvXwYgW7Zs1K5dm3Xr1nHy5EkAfHx8aN68OTt27GDv3r3OczZv3pxTp06xadMmZ1vt2rUBWLFihbOtQoUK5MqVizlz5jjbihQpQsmSJZkzZw7R0dEA5M6dm6pVq7JixQrOnz8PQFBQEA0aNHB5L2w2Gw8//DB79+5lx44dznM2atSIy5cvs875VSxUq1aNwMBAFi1a5GwrVaoUhQsXZtq0ac62+Pdi4cKFREZGApA9e3Zq1arF2rVrOXWj2L2vry/NmjVj+/btLjVpWrRowfHjx/nnn3+cbXXq1MFut7My/tMBULFiRXLmzMncuXOdbUWLFqVEiRLMnj2bmJgYAPLkyUOVKlVYvnw558+fx2azOd+LTZs2ceTIEQA8PDxo3bo1e/bscflypnHjxkRERLB+/XpnW/Xq1fHz82PJkiXOttKlS1OgQAFmzJjhbCtQoABly5ZlwYIFXL16FYAcOXJQs2ZN1qxZw+kbKwP4+fnRtGlTtm3bxv79+52Pb9myJceOHXN5L+rWrUtsbCyrVq1ytlWqVIns2bMzb948Z1uxYsUoXrw4s2bNIjY2FoDQ0FAqV67MsmXLuHjxImDGyHr16rFx40aOHTsGgKenJ61atWL37t3s2rXLec4mTZpw4cIFNmzY4GyrUaMGvr6+Lu9FmTJlyJcvHzNnznS2FSxYkDJlyjB//nyuXbsGQM6cOalRowarV6/mzJkzAM6yNlu3buXAgQPOx7dq1YrDhw+zdetWZ1v9+vWJiopi9erVzrbKlSuTNWtW5s+f72wrXrw4xYoVY+bMmcTFxQEQFhZGpUqVWLp0KREREQBkyZKFunXrsmHDBo4fPw6Al5cXLVu2ZNeuXezevdt5zns1li9btsz5/+Z+j+WJx6+sWbNSp04d1q/XWK6x3HUsDwsL49SpU24dyy/cmKWosVxjeXJjefxzu2ssr1ixOo89dopp03KRn4Msz9SEhy7uIzZzZtb06cN5b2+YNk1jeQYeyx0OB5kzZ87wn8s1lt+/sbxBg3x89tk8vvuuLMuXh9G3L8yaBS+9tIIsWczni5ARI6hepw72337DIzqaOC8vFn34IU38/dm6dSu7dh3ijz+KMmlSEWJjPQgMtNO58zZatjx4ozTCg/e53J05Fo3ltx7LV65cyaVLl4AH+3N5/Fj1b9LNTNuVK1dSu3Ztjh8/Tp48eZzHdejQAZvNxvjx4/noo48YNWqUy4AH5j/mwIED6dGjB82aNaNgwYL8+OOPzv3bt2+ndOnSbN++nZIlSybbn4w403bSJLMSrs1mZhXE/5w4UZMIxHqmTZtGmzZt3N0NkRQpRsXqFKNide6M0QsXzOfiRYugku1vlga1IvDSScib1xR6LFXKLf0Sa9E4Ku7icMCYMfDKK3DpEmTKBN9+a2bh2myYxcj69SPOywvP2FgYNAj69mXRIlMdIT43+Oij5nF587r15UgGllHG0Qdupq27+fr64uvr6+5u3FcDByYkaiHhZ7dupp65jw94e5ufiW8n15ZW+728tEqliIiIiNw/e/bAww/D7t0mETKp3nACZ540dSNnzoSwMHd3UUQyOJsNunSBOnXg6adh2TLzd/v06TC66GAChvSDQYOYWaECbTZtgn79mDQZwv/uC0BoKAwbBu3aufd1iIirdJO0zZ07NwCnTp1ymWl76tQpKlSo4Dwm/tKHeLGxsZw/f975+Ny5czsvFUl8jsTPIcbu3QmJ2sQuXYLx4+9/f+Ld70RxWjwmjdfsExEREZH7YMkSc4XZ+fOQL59JgOQv/jUMzGZW5wkOdncXRUScChQwVwR89hn06wclJw4mgH4sqD+IXn/2ZcfgOHLnbsOLPvD+3/3oC5x/pS8ffqjhTMSK0k3StmDBguTOnZsFCxY4k7SXLl1izZo19OjRAzC1TS5evMiGDRuoXLkyAAsXLsRut1O9enXnMe+9955LceN58+ZRvHjxFOvZZlTFisGWLa6JW5vNTCbo3RtiYiA62mzxt5Nru5v9N0okuYhvv1G6KV3w8LBeIvnf9qeXWc2TJplZ4bt2PUzx4qb4vsp3iBXVqVPH3V0QuSXFqFjd/Y7RkSPNojwxMQ7eLjqFNxY9Qu4wT8AHPvzwvvZF0geNo2IFnp5mMbJmzWBlszj6nhvEB0v6xu/lyBHoS1/8MsOLj8fx0DC3dlfEhcZRV5aqaXvlyhVnceGKFSvy5Zdf0rBhQ7Jly0a+fPn45JNPGDJkCKNGjaJgwYL07duXf/75h+3bt+Pn5weYIuKnTp3ihx9+ICYmhm7dulGlShXGjh0LQEREBMWLF6dZs2b85z//YevWrTz77LN89dVXvPjii6nua2rrT6RnKdW0nTTp/l024XAkJGnTKhF8P/bfqDWe7t2czHV3Ivnm2/Pnw/PPq+6ypA/nzp0je/bs7u6GSIoUo2J19ytG7XZ47z0YMgQ8iGN6kTdoufdb6NkTvvkmfXyrLW6hcVSs5upVc5XAjXWmnGw2KFsWNm92T79EUpJRxtF0WdN2/fr1NGzY0Hm/V69eAHTt2pWRI0fy9ttvExkZyYsvvsjFixepU6cOs2fPdiZsAcaMGUPPnj1p3LgxHh4ehIeH88033zj3BwcHM3fuXF555RUqV65Mjhw56Nev320lbDOK9u1N8mvQINi+PY5SpTzp3//+1rmx2RKSdIGB9+9571Zc3P1PNKfFOW+W0mxnq0lcd9lmMzGrpK1YzcqVKzNEUX1JvxSjYnX3I0avXoWnnjKTFHy5zoYSXSi9c6LZWaiQErZySxpHxWoCApK/QtXhMOUQRaxG46grSyVtGzRowK0m/tpsNgYNGsSgQYNSPCZbtmzOWbUpKVeuHMuWLbvjfmYk7dubbdq0mfqPcxs8Pc2W6PsEy3M4IDbWeonkW+2/fj3517FlC/z2m/mCIT0l+0VERMR9jh+HRx6BDRsgl/d5NhdqS66dy8zsgdGj4Ykn3N1FEZHbllLZw+LF3dcnEUkdSyVtRcR9bDZTcuBGqed0oXz5pB9AwFzW+NRTJmH72GNmBdUGDbQgnIiIiCRv0yZo0waOHoXyWQ+zMnMLAnbtgMyZYcoUSHQ1oIhIetK/f/JlD/v3d3fPROTfKIUhqVKxYkV3d0Ekif79Ez54QMLPjh2hcGFzKdCoUdC4sVlJtU8f2LHDbd2VDE7jqFidYlSs7l7F6LRpUKeOSdiWKR7DusyNCTi0w6y+u3y5EraSahpHxYriyx6WKwe+vg7Klbu/69SI3A6No64stRBZepIRFiJLLCoqCl9fX3d3QySJSZNMDdudOx2UKGFz1l12OGDVKnM14/jxcPFiwmOqVjWzbzt2hBw53NZ1yWA0jorVKUbF6tI6Rh0O+OoreOstc7tJE5gwAbIsngL9+sGMGZA3b5o9nzz4NI6K1SlGxeoySoymNqeombaSKnPnznV3F0SS1b69uaRxwoTpbNqU8I2xzQa1asEPP8CJE+aPsDZtwMsL1q2D//s/yJMH2rY1id+oKDe+CMkQNI6K1SlGxerSMkZjYuCll+DNN03C9tVul5k5E7JkwXw42LhRCVu5bRpHxeoUo2J1ilFXStqKyAPPz8/Utv3rLzh2DL7+GipXNguvTZ1qajzlyQMvvwyrVyetkSsi8kAaMAAGD05+3+DBZr/IA+jCBWjZEoYPN1/yLn70S4bOKYH3sYMJB3lp6Q8RERFxLyVtRSRDCQmBV1+F9eth61b4z39MyboLF+D776FmTbOS6uDBcPCgu3srInIPeXpCv35s7zSY8uUhPLwV5cvD9k6DzaXhnp7u7qFImtu3z1yJs2ABZAqws/eRXtSf+ia248fh99/d3T0RERERJyVtJVWKFi3q7i6I3NKdxGjp0jBkCBw6BPPmwVNPQUAA7Nlj8hUFC0L9+vDLLxARcQ86LRmKxlGxnL592d5xEKV+78ej/wwmJsaTR/8ZTKnf+7G94yDo29fdPRRxcbfj6LJlUL067NwJhcKiOFz3SQpN/crs/PRT802uyF3Q73qxOsWoWJ1i1JUWIrtDGW0hMpGM4soVU+N29GhYuDChVIKfnylx9/TT0LSprpoUkfTvzBmoVNHBe8d68BI/EosnXsQxiqf4OOBDqrTLS0gIzi1nTtfbgYHm0nKR9GD0aHj+eVPLtn6FCOYEtMV35WLw9oYRI6BzZ3d3UURERDKI1OYUlbS9QxktaTt79mxatGjh7m6IpOhexOiRIzBmjPlDb8eOhPZcuczfdk8/DeXLp+lTygNM46hYwYEDMGUKLB9/jLprPqcdk8jP4STHfcB79OUDAPJymF95imOEuWxnfcKIyRlKXK5QsuX2STaxm/i2n999frHywLmTcdRuN1fPfPihuf986xP8eLA5Htu2QFCQ+aa2SZN70FvJiPS7XqxOMSpWl1FiNLU5Rc0Vk1SJiYlxdxdEbulexGjevPDOO+ZqyQ0bTPJ23Dg4dQq+/NJs5cqZ5O2TT5rFzERSonFU3MHhgM2b4a+JMSybdIb520MByI0HE/gaDxxE4Y0vMcThgSd2ThHC+WxF+OxdOH0asvxzkPpzliY9eTRwDAYfe59+mAXN8nCc/gxkL2EsJdQlyRuTKRshuWz/mtwNCYEcOcwESJHEbnccvXYNunaFCRPM/T59YPDbmfBo5A25c8OsWVChQtp3VDIs/a4Xq1OMitUpRl0paSsi6dOAAWaRnORqLg4eDHFxabbyuc0GVaqY7YsvYPZsk8D96y/45x946y14+21o1swkcB991NTGFRFxh9hYWLECpv95nQt/zKPO6Yn05C9qUYlFnvOpVw/ats3DpUMDubR2B/mWj6MfgxhMX/oymEH04/lmRyj11o0Tni4BC8bCsWNw7BiOY8ewHzmO/egxPE8d59HnwwitbMotZNq4l+4Thifbr2tX/Hj/ygd8ue9NAHJymi78xqpEid3jhBKNLwBZs946sZv4frZsWjdNXJ08aX4fr11rvgD46SeTwIUgmDnTZHQLFHBzL0VERERSpqStpEoeTSEUq7mx6jkAffsmxOjgG6ueDxp0T57W2xvatDHbhQvwxx8mgbtypUnmzp5trrZ8/HGTwK1bFzy05KOgcVTurWvXzIKKsyZcIXrqLJpenkg/ZhDEFecxtbLs4NTW62QPu1GnYDBkWT6O7R0H8deOvvjssPNXyb50LAmlfu8HpTBfjIWEQKdOzvPYAM8bGw4H5WJjKRc/K3ZfGJTq70zwcvw4jmPHsJ09iz/X6fFmIHVqmxm8fmt20HXEm0leyxlycJxQPr/wFr9deIpduyCYi9RiJatuzN49S44bPTE8PMzs3H+bwRt/O0sW1eNNj1I7jv7zDzz8sClzlC0bLH1jEqXP7AdufBORK9e966RkaPpdL1anGBWrU4y6Uk3bO5TRatqKuI3DAVevQnS0mXYVb+FCGD4cxo83f5n17m3aBg40Cdv7vOr5nj3w228mgXvwYEJ7/vzw1FNmK1bsvnZJRB5w58/DjBmmRu3s2WaonMbDPMwM5zFXsz+Ed4f2eD/RHurUcZ2Oeh+vWCAqCo4fh+Bgk0UD+Ptv+PTThATvsWPmuBuO9/+B3Q26c+YMeC1fTLtvGjr3Rdt8OO0VyjFHKIdiwxhBN2bTEgB/rhLKcY4RxnX8k+2Ot7dJ3iY3aze521p0Lf2YMQM6djQLixYvDsueGEbOwa+azxPz5ql+rYiIiLidFiK7xzJa0nb58uXUqVPH3d0Qq7PbTXI18Wozy5fD5ctmu3LFdXvoIXj55YRjW7Uy1zMmPjYy0vyhVbOmmc4aL29eOHo0aR9Kl4b33nOZFXY/2e3msuTRo80s3EuXEvbVqGFm3z7xRELOQjIOjaOSFo4cgalTYfEfp8mxfAptHZN4jl84Thj58sGnhX/kkZ2f4vtkOB6Ph0PVqqme7u/2GHU4zCUM8QncUqUgXz6zb/Fi6NXLtJ8+neShEZ/8wKEW3c2uRYto8lEjACJ9s3LWJ4wTHmEcsYdxICqUP6IfZQNVAPAgDgc2HNz6PfLzS32phpw5wT/5XLHcpVvFqMMB33xjwsRuh8YN7Uwv1we/rz8xB7z0Egwbpjoack+5fRwV+ReKUbG6jBKjWohM0tSFCxfc3QVJaw5HwrQhu93MeLo5qXrlikmgFipkVtqKf1yrVq6J1fjbV69Cy5amVly8li3NvuTUru2atN20CU6cSP7Ym89RtaqpRZcpE8yda14DwLZtpnBd4qTtzp1mus19mCbl4WFKItSta/54/Osvk8CdMwdWrzbba6+ZycFdu5q3x8fnnndLLEDjqNwJhwO2bzezaVf+cZTC/0winIn0YDmemHHvxxaTCf2wJxUrgi3uOfB88Y7GO7fHqM1mvtHKlg3KlnXd16ABbNxobkdHm98ViWboBjerS7lSN469EmGypteuERh1gcCoC+RnKzVu7H5jWF5OPlKF06chbv5SKr/XnMigPFwICOW0dxjHbWEcjg1j77Uw5l6pxc6ogly/DocPmy01goJSX6ohZ04tupZaKcVobCy8+ip8/725/9Kz0fz3+nN4fP2bafjgA7MKmaZLyz3m9nFU5F8oRsXqFKOulLQVSU9iY811+MklV69cMdfft25tjr16Fbp0ST4Je+UKtG0L48aZYx0Os8pWSlq1Skja2mywdKk5f3JuTq6WL2+KLWbK5LoFBUGRIq7H/u9/5vw3H5spU9JpS5MmmZ+DB8Ps2cR5eeEZGwv16sHzzyccd/q0ma2VO7d5Ha1bm0sjg4JSfr1pxN/fzKp94gkzgXjcOJPA3bQJJk82W/bs5jLOp582eWj9PSkidrv5gmfKFLN57tnBSJ7hPda6HHe9TGX8ngzn4SdaQaEbjV4Z4KOdj4+pPZM/f/L727Y1V2lcvOhSWzf+tnf1SuTNay7YYMcxiIsh88XDZL54mCRnHD6cyCdf4PRpuDp3Ofk+7M6loDDO+YdxytMsnnYgOoy9V0PZeLko+84GExOTcIHJ/v2pe0lZs6a+VIMWXXN18aL5PTt3rvkd+vXgS/RcHI5t/nzzRv38MzzzjLu7KSIiInLbMsAne0kLQfchwfVAiY01fyAmVxLgyhUoWdIkF8EUJXztNdeEauIEa+fOZsommGvtS5VK+XmffDIhaevlZbKCKUmcXPX0NAlUL6/kE6bly7s+dsQIMy0ouWMzZXI9dvny1L1nAC1apP5YcFl0bFndujRYtszcT1yvbutWCAgws7J++cVs3t7m/W/dGsLDEy6/vYdy54Y33jDbP//Ar7+aGrgnT8J//2u24sVN8rZLl/vSJbnPNI7KrURFmbLcUyY72DlpO7HnLrKS2gDk9M5Dpdi/cWAjpmotfDqGQ/v2+KWUtLxDD1SM2mwmE5o1K5Qpk/JxHTuaWbyJ6+om3ooXJzAQChYEAg7Ake0EsZ2w5M710084nnueiAi4tHA9Ad98TERAKGf9wjjpEcbhuDAORoey60oYh84Hcfo0nD1rkvQXLpht9+5/f2keHuYLv9SUaggJebAWXbs5RvfvN1eu7NhhftWPHQuPRs2G9+ebQsR//nn7ny1E7sIDNY7KA0kxKlanGHWlmrZ3KKPVtH1gxcWZv5KSm4l65Yqpj1qpkjn2+HGzIEtKs1yff94kDAEOHDAlBVLSowd89525ffas+csqJV26mAwfmEtCc+c2s0STS5bWqgWvvJLw2B9/NH+03DzDNVMmsxhMlix3+s65X6KErcsiOsm1R0XBkiWmbMOMGbB3b8LxI0eaOgVg/h29vcHX9768hNhYWLDAzL6dPNlMSAbzx3WDBiaBGx5+XyYFi4gbRETArFkmUXt8+kZaXJ1IOBMpzm42eFTly45radvW5JyCFk8zV0RoRV33OXMGNm92TeommsHL//4HzZubY3/91QziKfnf/6BbN+x2iFi5jbhRv3EhIIzTPmEcxyR4D1zNxcmzXpw5Yy4aOX3afM97u7y8Ul+qISTEfERID0neFSvMpOqzZyEsDKZNg4oVb+z87DNo2PDWVxGJiIiIuIkWIrvHHvik7U0rSm/atIkKFSqYfWm9onRqOBwmo5VSwrRUKShRwhx78CAMHZrysf/3fwmJzY0boXLllJ/33Xfho4/M7b17oWjRlI995RWzwAWYP+zy5k0+WZopk/mj7qWXzLHR0eZxKc1azZHD/BUlru4mRnfvNsnbGTPMtJz49/fzz81jmjQxs3BbtTJ/Cd4Hly6Zig+jRpn1duL5+0P79uZv/8aNdUlseuYSo5JhnThhal1PmQKX5q0hPG487ZlEAQ45j7F7+0DTZnhMnnhfi14rRtPQ7t0wb17ys3cvXzZfIrZsaY4dPTrhy8PEPDwgVy7zJW/btgDE7D5A5OylnPcL45RnKMcI49jlzJw+Y3NJ7sbfTrwYZmr5+aVuBm/87fu56Fp8jI4ZA88+az5CVa4MswauJWf1QuYzk4gbaRwVq1OMitVllBjVQmRydzw9E2aN9u3LkSNHzH+cxLMYU2K3m3qnKSVX46/73rPHzHJMaZZr794Ji0ktXgyNGqX8nEOGJCRtz52Dr79O+djEC13FT2H090+aWM2UyXW2bEiIef0pJVdDQxOOzZkTrl9PuQ+J+fiYpY7l9tyUkHXGKLjOvE1OsWJme+MN1/ZVq0wdxKlTzQamNETr1marXv2eZU0zZzYl9555Bg4dMqUTRo82f/ePGWO20FBTLePpp299ta9Yk0uMSoaye7dJ0k6bHMuKNV7Ef13+B5/zOH8CEOcXgEfrVtjC2+PRurUZFO4zxWgaiv89k5zLl12T8UWLQs+errN2T5wwXz6eOGGyqDd4r1pKlteeIQsJZYwJDDRfMIaFQf/+UL++aT91iqidBzjvH8YJR25OX/BONrGbeLt2zXx8OXLEbKmRKVPqZvCGhJic6p18DzFpEgwcCDt2lCVrVtNXgHbtYOwTU/F7rKOZZjt/vqmTIOImGkfF6hSjYnWKUVdK2kry4pNe/frBmTMUvXDBXGq2bJn5UPzPP2aGyJUr8N57CfXC/voLHn005fP+8AN0725uHz6cMIs1OUePJtxOXCc18eX+8UnW3LkT9oeFwTvvJD/DNVOmG4Xpbihc2FyjnppEXObM8P77/36cpF8TJphVwuJn4a5day6F3bwZvvrKfCEQP6UoJuaeLfedP7/5b9Wnj+nCr7+aRcyOHzf/DT/7zPw3fPpp871Grlz3pBsicoccDli/3iRqZ0yKImznfMKZyBSmUpsVZKlegrZtoWamzrDGD8LD8WzWTMmmjOLmmjc1a5otsbg4k1U9dsx10c7s2aFZs4Tk7sWL5svG3bvN9p//JBw7axa+3bqRB8hjs5msaXxyNywMXnspoWZ9ZCRERxPpnSXFWbvJ3Y6OTviuPbWLrmXJkvpSDdmzm+9Qw8NNyQaHw9OZsG3bFv5s+iMeT75sJgxkywa6gFBEREQeIEraSsoSJW5LJG7/+2+zxUs8FSPxNXI2W9LyAMHBCfsLFoRXX0155mriBbcqVjQzUwICzOWCt5I7N3z8cepe47+dS9INj7T4t/TwMDWMK1Uy8X/mDMyebRK4Xl6u8V21qonp+Fm4ZcqkeRFAm81M7q1eHb780lxNO3o0TJ+e8N/wrbfMdyZPPw1t2tzfy1Tl9qRJjIplxcSY0tlTpsCcSZGUOzGbcCbyH6aTmcvO49b0+YvgD+N/q7aFnm3d0NvkKUYtxNPTfJ5J/KU0mFW3Hn444X5kpOsMXWdR1xvy5TP7Y2Ph1Cmzbdxo9rVrl3DchAnQrRuB/v4UDA2lYOLkblgY9HzU9UtvTH700qXUJXfjf9rtJs988WLqFl2z2RI+qiXOx9pw0HJlPzymfGAann8evv/e/K4WcSONo2J1ilGxOsWoK9W0vUMPfE3bxHx8zF+jnp6mxuvNydXKlaFAAXPs9etmZZWgIJM9Sg8rWYjcrmPH4KGHXNvy5k1I4DZqdE9nzJ07B+PHmwTumjUJ7cHB0KGDSeDWrq3/fiL32pUrMGeOSdROn24SUVVYxxLqE8A153H20DA8wtubAtV16iixJPeX3Z4wazdxgveFF8zvLjA13Xv3Tvkcc+aYGb5giq/37u2a1I3fQkPNN43ZsiXbjQsXUp/kPXcO+jOAODz5gISyR17EMJwX6cZI0zBggLkyTL/0REREJJ3QQmT3WIZJ2t6oYWv39sYjJsbUsv23eqEibrBnzx6K3mqhuLR28KCZ+jpjBixc6FrDuFs3szL4fbBrlymf8OuvpuJIvIIF4amnzJb4ylpxn/seo3JPnDljVqmfPBn+nnuGFtFTicKX33iKnDkhvPV1vh2fE4/cIXg8Fm4StdWqpYsrOxSjGdy1a65J3cTbkCEJdf4//PDW5aLmzoWmTc3tSZPM4rDxCd2bk7wPPZRiqaHYWLjWZzBBn/WjH4MYfCNx+z0v8RI/moMefdR8ayJiERpHxeoUo2J1GSVGtRCZ3L1Ei47NqFCBNps2uSxOJmIlO3fuvL+De4EC8PLLZrt6FRYtSkjixq8IDrBhA3TpkjALt06dNK2FW7w4fPCB+T5l6VIz+3bCBDhwwLQNGgS1apnZtx06QNasafbUcpvue4xKmjlwwOSFJk+GA8uP8ahjMr2YSD2W4omd01mL031qF2rWsuHp6QcDt5kZjOls5p9iNIPz9ze1/gsXvvVxPXua32c3J3jj7+fPn3Ds9u1mPYSUzJsHTZok3P7jD2dC1ys0lKAn27BrTySDppjPn4Ppy3XMwmyH63Um35Tf7uYVi6Q5jaNidYpRsTrFqCslbSV5iRK29O1rphUlXpwMlLgViRcQkJCUHTbMXAMab8YM2LnTbF98YRa0a9bMHNuyZZqtIubhAQ0amG3YMJNgGj3a/A28cqXZXn0VHnnEJHBbtLhn66iJpHsOh1l/MD5R+88/8ALD+YQR1GS167GVKhHSvj0hNWLB88Z/qnz57n+nRe6X4GCoUMFs/6ZjRyhWLPnZu8eOmdm38Vavhp9/TnKK4oDdw5NB9n68xwf4Es2ODv0pOX5AGr0gEREREWtS0laSFxeXfCmE+Ptxcfe/TyLpgc1m6j/He/VVKFHCJG9nzTLXVv/5p9kA1q41i5qloYAAePJJsx0/DmPHmhKEW7cmPHXOnNCpk0ngVqqU7iYEiqS52FhYscIkaqdMAd+DO9lFccCGpye0DVlDzRM3Era1apmyB+3bY7tpcSYRSaRIkZRr9Nxcoa1RI9N28+zd06fxsMeBtze+MdHg46OErYiIiGQIqml7hzJMTdsbrl69SsA9XFhJ5G6lixi122HdOpPAnTED9u83q63ET3kdONDUym3d2szGTcOxJX7m4OjRMGaMedp4pUqZ5G3nzknXV5O0ky5iNIO5ds3MRp8yBf6a6iDf+b9pzyTCmUhJdtK7/lrKdKvKww9D9j2rTbmTdu1cZwc+QBSjYknR0WYh3C+/xOHjgy06WmssiGVpHBWrU4yK1WWUGNVCZPdYRkvanjhxgjx58ri7GyIpSpcxeulSQmLW4TB1BA8cMPe9vKBu3YSyC8WLp9l02NhYs07M6NEwdWrCGmo2GzRubBK47dpBpkxp8nRyQ7qM0QfQ+fPmO5PJk2HubDtlr60hnIm0ZxKFOOA8zuHtje2HH+DZZ93Y2/tLMSqWlKhk14nnnyfPzz+7lvASsRCNo2J1ilGxuowSo6nNKVp/KWOxhPXr17u7CyK3lC5j9ObB+aef4I03TP2/2FizuNlbb0HJkuay0TTi5QWtWsHvv8PJk6aEYL16Jm88f75J2ubODV27woIFqoaSVtJljD4gjhwxtZ4bN4aQEBPjkydDpWvLWUUt3uILCnEAh7+/KXswZgy2M2cyVMIWFKNiQTetsbB+/XqTqB00yLQPHuzuHoq40DgqVqcYFatTjLpSTVsRESuIn+bauDF8+SXs3ZtQRmHJEpO4jRcbC126QMOGJvuaN+8dP21wMDz3nNkOHIDffjMzcPfuNT9HjzYlE7p0gaeeMqUURKzO4TCL1scvJLZlQxSNWUAnJlGfUP4sO4i2baFtm9o4niyCrVo1CA/H1qKFKQotItagNRZEREQkA1PSVkTEiooUgddeM9uVKxAZmbBv1SoYP95sAGXLJpRRqFHDTKW9AwULmr+D33/fLOI9erSZjXv0KAwZYrYqVcwsxY4dzWJmIlZht5u4jU/UHtt7lRbM5nUm0YZpBHMJgNhcofTbNAA8PABP2L1bK/GJWNWAASnvU2kEERERecCppu0dymg1bU+fPk1ISIi7uyGSogwVo0eOmIzqzJkmS2W3J+zLmhWGD4fHHkuTp7p+3Uz2jX+62FjT7uUFLVuaBG6bNuDrmyZP90DLUDF6n0RFwcKFJlE7dSqcOmXav+ZVnudnAriWcHCePKb0Qfv20KDBjaStJKYYFatTjIrVKUbF6hSjYnUZJUZV01bSlJ+fn7u7IHJLGSpG8+aF996DFStMluq336BTJ5OwvXAB8uVLOHbpUvjoI9i82Vwzfpv8/CA83CTEjh+Hb74xs21jY2HaNHj8cVP/9qWXYOXKO3qKDCNDxeg9FBFhZoDHz/Z+qtVZooaP5NypGIKD4cknoUUrD5OwLVAA3nzT/F85etQUtm3USAnbFChGxeoUo2J1ilGxOsWoWJ1i1JX+apFUWbJkibu7IHJLGTZGc+SAzp1h7Fg4fRqWLzdZ1XijRpkEb4UKJpnbvTv89ZdruYVUypkT/u//YN062LYN3nnH1Lu9eBF+/BFq14aiRU35wQMH0uwVPjAybIymgRMnTIy1aGHisFen42Qb/x2TLzfmJLkZSTdWDVnK6dMwZgwU+/ZV2LAB9u+Hzz+HWrWUqE0FxahYnWJUrE4xKlanGBWrU4y60l8wIiIPCi8vkzlNnJxq0sTULwgIMDMNhw+HRx+FbNmgeXO4evWOnqpUKfj4Yzh4EObPN2USAgNh3z7o3x8KFYJ69eDnn83MSJHbtXs3fPop1KwJoaHQ96XTlJrzJYtianOUh/iOV2jMQryIgwoVqFIuGh+fGw8uVAgqVVKtWhERERERSbeUtBUReZB16mRm1p47B7NmmamyhQpBdLSpjRsQkHDsL7/AggVmXyp5ekLjxmZC78mTpvZtkyYmV7ZsGbzwgimf0LGja01ckZs5HGYW93vvmS8FiheHfv+5zurVZn/LMkf5kjepzUo8cJhF9z77zHxT8PffpsiyiIiIiIjIA0ILkd2hjLYQ2f79+ylUqJC7uyGSIsXobXA4YNcuUw+3fn3Tdv06ZM9uZt4GBUHTptC6tUmE5clz209x9Ki5TH30aNi+PaE9Vy5Tc/Tpp6F8+Yw1EVIxmlRMDCxZYhYSmzIFjh1zUJ7NhDORcCZyLE9V9vYdxaOPQmgehwme2rWhbVtTm0PSlGJUrE4xKlanGBWrU4yK1WWUGE1tTlFJ2zuU0ZK2drsdD9UDFAtTjN6l06fhP/8x02FPn3bdV6mSmaH7zDO3fVqHAzZuhF9/NWV3z5xJ2Fe2rEnePvmkufz9QacYNa5cgTlzTJJ2+nSIuGinGmtNotY2iUKO/QkHh4SYgrZ63+4LxahYnWJUrE4xKlanGBWryygxmtqc4oP/TkiamDFjhru7IHJLitG7FBICI0aYBNnataYwbdWqZt/GjWZWbrzz52H8eLMC2b+w2aByZRg6FI4dg2nT4PHHwccHtmyB3r0hb16zwNTYsXdcYjddyMgxeuYM/O9/prxyjhzw2GPw228mhBZ5N2c1NenN5yZh6+dnZtL++quZEZ4BPrRZRUaOUUkfFKNidYpRsTrFqFidYtSVl7s7ICIiFuLhYZK1VavCgAEmWTtrlllVLN7MmfDUU6agbe3apoxC69amEOkt6h14e8PDD5vtwgWYMMGUT1ixwsy8nDMHMmUySd2nnzZPqXxd+nXggJlNO3my+Tf2tEfTiIV8xVSGFfiCluEBtG0LtWbXhG/WmMBo396U5AgMdHf3RURERERE3EpJWxERSVmuXEnLInh4QMmSsGMHLF1qtv/8B/LnN8nbd94x02dvIWtWePFFs+3da2Zdjh5tEn0jRpgtXz7o0sUkcIsXv3cvUdKGwwGbNyckav/5B/y4RnPmMJKJtPWcRlBcBAAvfdEMW/t25oFl34T3+5gZtiIiIiIiIgKkw/IIly9f5vXXXyd//vz4+/tTq1Yt1q1b59zvcDjo168fefLkwd/fnyZNmrBnzx6Xc5w/f57OnTuTOXNmsmTJwnPPPceVK1fu90tJVwoUKODuLojckmL0PnrySbO62P798O23praBry8cOgTffWem1Mb75x/TfgtFiphJvfv2wbJl8MILEBwMhw/DRx9BiRJQvTr8979w7ty9fWn30oMYo7GxZiGxN96AQoWgYkUYOBBi/tnOBB7nvEcOptCOp/jNJGxz54YePbAVKZxwkuBgJWwt4kGMUXmwKEbF6hSjYnWKUbE6xairdLcQ2RNPPMHWrVv5/vvvCQ0N5bfffuOrr75i+/bthIWF8cknn/Dxxx8zatQoChYsSN++fdmyZQvbt2/H78YfhS1btuTEiRP8+OOPxMTE0K1bN6pWrcrYsWNT3Y+MthCZiMgtRUbCokVmquV77yW0N20K8+dD6dIJZRRq1QKvW1/oce2aqX87ejTMng1xcabd29uc4umnoVUrkyuW++vaNZg3z8yo/esvk0jPxjmycJET/oVp3hyeqrmX9v8pah6QP78pexAeDjVrquaFiIiIiIhkaKnNKaarpO21a9cICgpi6tSptG7d2tleuXJlWrZsyeDBgwkNDeXNN9/krbfeAiAiIoJcuXIxcuRIOnbsyI4dOyhVqhTr1q2jSpUqAMyePZtWrVpx9OhRQlNYwjwqKoqoqCjn/UuXLpE3b94Mk7RdsGABjRs3dnc3RFKkGLUgux2aNTPJXLs9oT1LFmjeHNq1gyee+NfTnDoF48aZBO7ffye0Z8sGHTuaBG61arcsp2sJ6TlGz5+HGTNM2YM5c8yCcbk4STsm84TXJOrGLeJUtTZkWTiZgIAbD/rqK1OYuFIl6//jCJC+Y1QyBsWoWJ1iVKxOMSpWl1FiNLVJ23RV0zY2Npa4uDjnjNl4/v7+LF++nAMHDnDy5EmaNGni3BccHEz16tVZtWoVHTt2ZNWqVWTJksWZsAVo0qQJHh4erFmzhnbt2iX73B9//DEDBw5M0j5r1iwCbvyF2rRpU86dO8fGjRud+2vWrImXlxfLli1ztpUrV46wsDBmzZrlbCtUqBClS5dm3rx5XL9+HYCQkBBn38+ePQtAQEAAjRs3ZsuWLRw8eND5+NatW3Pw4EG2bdvmbKtfvz7Xr19nzZo1zrYqVaoQHBzMggULnG0lSpSgaNGizJgxA/uNxErevHmpUKECixcv5vLly9jtdpYvX06dOnVYv349J06cAMDb25sWLVqwc+dOlzIUzZo148yZM/ydKMNSq1YtPDw8WL58uct7ERoayuzZs51thQsXplSpUsydO9eZKM+VKxfVqlVj5cqVnLtxfXRgYCCNGjVi8+bNHD582Pn4Nm3asG/fPrZv3+5sa9iwIZGRkaxdu9bZVrVqVYKCgli4cKGzrWTJkhQpUoTp06cT/31Gvnz5KF++vPO9AMiWLRu1a9dm3bp1nDx5EgAfHx+aN2/Ojh072Lt3r/OczZs359SpU2zatMnZVrt2bQBWrFjhbKtQoQK5cuVizpw5zrYiRYpQsmRJ5syZQ3R0NAC5c+ematWqrFixgvPnzwMQFBREgwYNXN4Lm83Gww8/zN69e9mxY4fznI0aNeLy5csuZUWqVatGYGAgixYtcraVKlWKwoULM23aNGdb/HuxcOFCIiMjAciePTu1atVi7dq1nDp1CgBfX1+aNWvG9u3b2bdvn/PxLVq04Pjx4/zzzz/Otjp16mC321m5cqWzrWLFiuTMmZO5c+c624oWLUqJEiWYPXs2MTExAOTJk4cqVaqwfPlyrly5wrRp05zvxaZNmzhy5AgAHh4etG7dmj179rBz507nORs3bkxERATr1693tlWvXh0/Pz+WLFnibCtdujQFChRwWcmyQIEClC1blgULFnD16lUAcuTIQc2aNVmzZg2nT58GwM/Pj6ZNm7Jt2zb279/vfHzLli05duyYy3tRt25dYmNjWbVqlbOtUqVKZM+enXnz5jnbihUrRvHixZk1axaxsbEAhIaGUrlyZZYtW8bFixcBM/7Vq1ePjRs3cuzYMQA8PT1p1aoVu3fvZteuXc5zNmnShAsXLrBhwwZnW40aNfD19XV5L8qUKUO+fPmYOXOms61gwYKUKVOG+fPnc+3aNQBy5sxJjRo1WP3BB1zcv5+cGzcSumkTef7+22QAx4/n9O7drAkIoFWrVhw+fJiDM2dy5aGHwMOD+vXrExUVxerVqwEoXBimT6/MsWPZ+PjjoyxZ8hDnz/vx3XemIkNY2BUaNjxKgwZHqVgxG5UqVWLp0qVERJgaqlmyZKFu3bps2LCB48ePA+Dl5UXLli3ZtWsXu3fvdr6eezWWx8couG8sB8iaNWuqxvIzZ/y4dKkBf/4Zx6pVPtjtHuTjEC8yiU4+E6kSvRIPHGBCkNycYMa8qc6ZtIWbN9dYfkN6GcuvXr3q9rH8woULLu+FxnKLjOWrV3PmzBkAZ/mxrVu3cuDAAefj48fyrVu3OttuHsvBTLbImjUr8+fPd7YVL16cYsWKMXPmTOJuXFoRFhaWZCyPH9vcOZZb4XM5pH4sB30uv59jud1uZ/HixRn+c7nGcuuO5fGfR905llvhc7nGcuuO5Yn/ZnqQP5fHj1X/Jl3NtAUTlD4+PowdO5ZcuXIxbtw4unbtSpEiRRgxYgS1a9fm+PHj5MmTx/mYDh06YLPZGD9+PB999BGjRo1yGRTB/OcdOHAgPXr0SPZ5M/pM22nTptGmTRt3d0MkRYrRdCIuDtasMdM2y5eHDh1M+7Fj8NBDkCcPtGxpaiA0bQpBQSmeZsEC+PVXmDTJzPyM16CBmX0bHg5WGp6tHqMOhylVHL+QWKK/EwAoWxamX6hFvqMJf7xQrZp5o9u3N8WJJV2zeoyKKEbF6hSjYnWKUbG6jBKjD+RMW4Bff/2VZ599lrCwMDw9PalUqRKdOnVy+RbqXvD19cU3AxdPzJEjh7u7IHJLitF0wtPT1LStVcu1fds2CAyEEyfgf/8zm7e3uby+dWt47DHIm9flNM2ame2770zidvRoU4lh8WKzvfKKqcDw9NPQuPG/ltG956wYo3Y7rF6dkKg1X2A7KMc/DGQSHQP/Yv47C2jeKRuFCwNfPQ5TvE2itl07l38TSf+sGKMiiSlGxeoUo2J1ilGxOsWoq3Q30zZeZGQkly5dIk+ePDzxxBNcuXKFb7/9lsKFC/P3339ToUIF57H169enQoUKfP311/zvf//jzTffdF6yAabsgp+fHxMmTEixPMLNtBCZiEgai4qCpUvNLNwZM+IziMa4caaALcDly+Djk+wqZIcPw5gxMGoUJL6gIk8e6NzZJHDLlr3Hr8PioqJg4UKTqJ061dQMBgfVWMvjnpN40ncioVcTLp9k5Ejo2tXcdjhUn1ZEREREROQupDanmG6XcA4MDCRPnjxcuHCBOXPm8Oijj1KwYEFy587tUkvk0qVLrFmzhpo1awKm/snFixddZuYuXLgQu91O9erV7/vrSC8S12wRsSLF6APA19eURBg6FPbsMVnXr74ybc2aJRz37beQPbuZ6fnzz6a0wg358sG778KOHbB2LfTsaQ49cQI+/xzKlYOKFeHLL+FG2bv7xp0xGhEBv/9u1n3LmRNatYLhw03CtlngCs4G5GMNNXgr7lOTsPX1hUcfNdnvRx5JOJEStg80jaNidYpRsTrFqFidYlSsTjHqKt2VR5gzZw4Oh4PixYuzd+9eevfuTYkSJejWrRs2m43XX3+dDz74gKJFi1KwYEH69u1LaGgobdu2BUwR5BYtWvDCCy/www8/EBMTQ8+ePenYsSOhoaHufXEWFl+8XcSqFKMPoGLFzPb6667tq1dDZKSZKjplimmrUMGUUWjdGqpXx+bhQdWqULUqfPEFzJplyidMmwabNpnt7bdNLvjpp01+0t//3r6c+x2jJ06YmbRTppiZtTEx4E00DVlEUHZfQjo0oF07qF+8MD4FjkGmTOb9a9/eZHUzZbqv/RX30zgqVqcYFatTjIrVKUbF6hSjrtJd0jYiIoJ3332Xo0ePki1bNsLDw/nwww/x9vYG4O233yYyMpIXX3yRixcvUqdOHWbPno2fn5/zHGPGjKFnz54pKoooAAEAAElEQVQ0btwYDw8PwsPD+eabb9z1kkRE5HZMmWKyrvFlFNauTcjEfv01nDtnyicAxMTg4+PNo4+axOy5c/DHHyaBu3q1SebOmmUWLHv8cZPArVMHPNLpdSi7d5vatFOmmNcH4Mc1WjKXZzNPpFnUNPyjLuIo3wjbdw1uPCq3KQJcrRok+l0pIiIiIiIi7pPukrYdOnSgQ/xq48mw2WwMGjSIQYMGpXhMtmzZGDt27L3o3gPLT3/Ii8UpRjMQDw+oVMlsffvC6dMwe7ZJ4AYEJCRsAcqXN/URbszCzV6mDD162OjRwyQ4f/3VbIcOwS+/mK1AAXjqKbMVLZp23b4XMWq3w4YNCYnaHTsS9rVjEi9nG0+9KzPwiY6ESzd2hIRgK1nStT5tvXpp3jdJfzSOitUpRsXqFKNidYpRsTrFqKt0uxCZu2khMhERizt4EAoWdG3Lm9dc+t+6NTRuDAEB2O2wbJmZfTthglnnLF7Nmmb2bYcOkC3bfe19imJiYMkSk6idOjWhpG8mLnPdK4hGjUy532d+b47fkrlmZ968puxBeDjUqgWenu57ASIiIiIiIhlYanOKStreoYyWtN22bRulS5d2dzdEUqQYlWQdOgQzZ5pZuAsWwPXrCfu6d4cffnA5/OpVkwgdPRrmzjUzWcFM3m3TxiRwW7RwncybWncTo1euwJw5JlE7YwZcvGjaQzjFE75TeDbLJMqeXcSVzfsJLv2Q2fnnn7B+vUnUVqmiRcTkX2kcFatTjIrVKUbF6hSjYnUZJUZTm1NMp1X75H7bv3+/u7sgckuKUUlW/vzQowdMnw7nz5uM58svm/aWLROOW7UKSpUioH9vOuVZzKy/Yjh61CxiVq4cREfDxImmLm5YGLz6qsmH3s7Xnrcbo2fOmHINbdpAjhzw2GMwZgxkuniE9zJ9za7c9Thpy8M3US9R4dRcPONiCN6wMOEEjz0GQ4aY1diUsJVU0DgqVqcYFatTjIrVKUbF6hSjrtJdTVsREZE74u9vSiO0agXDhrlmXGfONAVhd+yAzz+H4GDyNGtGr9at6TW3BZtP5uLXX03S9ORJ+PZbs5UsaWbfdu5sKhDcrf37TW3aKVNgxYqEmb4AhQpBn/IzeG7yw3AFs4FJyoaHm/IHaVmEV0RERERERNxGSVsREcl4bDbX2ae9ekHZsmYm7qxZZprrhAlms9kov3Ej5T+vwJAhMH++KZ8webLJ8b77LvTpA40amQRu+/aQKVPquuFwwObNCQuJ/fOPcw9l2MoreSaRp0YBCg/qSunSYLtUB2b5JSRq27WDfPnS+M0RERERERERd1NN2zuU0WraxsbG4uWlHL9Yl2JU0ozdDuvWJdTCPXTITK+NX7zrvffg+HEiG7Zm0uVm/DIhM0uWJDw8IMDkU59+Gho2NDVyBw6EXbscFC9u4/33ISQkIVF76FD8Ix1U91jPaw9NpMW1SWQ9s8c0V60Ka9cmPEFEBAQH34c3QjIajaNidYpRsTrFqFidYlSsLqPEqBYiu8cyWtL20KFD5M+f393dEEmRYlTumcuXISjI3HY4zMzWo0fNfS8vqFuX8zVbM/5Ka76aWZw9e80M3v4MwMfPk/eu98Vmc63G8D6D8SSOgQzA3x9G532Plmd/JfD8kYSDfH2hWbOEDLDq0so9pnFUrE4xKlanGBWrU4yK1WWUGNVCZJKm/km4ZlfEkhSjcs/EJ2zBZF5HjoQ33oBixSA2FhYtIttHb9Hjm5LsKticVavM2mc+fp70ud6P9xnskrDtxwAG049yFTyZMgXOnoXHyu02CdvAQHj8cfj9d1Oi4a+/oGtXJWzlvtA4KlanGBWrU4yK1SlGxeoUo64e/DnHIiIiacXDAxo3NtuXX8LevaaEwsyZsHgxttKlqVEDatSAqE/+w7bMvzOYfmTlPItoxED6UYlNALQf9ziUuHHeXr2gSxczs9bf320vT0RERERERKxBSVsREZE7VaQIvPaa2a5cgWvXnLt81y6jNNsB6MVQejHUue+8V06y7dsHJW5kbWvWvJ+9FhEREREREYtTTds7lNFq2l68eJEsWbK4uxsiKVKMiuUcPsy2d3/j4tgZ1GIlNiAODxqxkNcn1KHdY57u7qGIC42jYnWKUbE6xahYnWJUrC6jxKhq2kqaio2NdXcXRG5JMSqWky8fpcf0IWvHFtiAKHzwxM73HZcqYSuWpHFUrE4xKlanGBWrU4yK1SlGXSlpK6myatUqd3dB5JYUo2JJgwdT6vd+MGgQc//6EwYNMvcHD3Z3z0SS0DgqVqcYFatTjIrVKUbF6hSjrlTTVkRE5F4YPBj6mYQtffvCtGnmJ5h2SLgvIiIiIiIikoiStiIiIvdCXFxCwjax+Ptxcfe/TyIiIiIiIpIuaCGyO5TRFiI7duwYYWFh7u6GSIoUo2J1ilGxOsWoWJ1iVKxOMSpWpxgVq8soMaqFyCRNZc+e3d1dELklxahYnWJUrE4xKlanGBWrU4yK1SlGxeoUo66UtJVUmTdvnru7IHJLilGxOsWoWJ1iVKxOMSpWpxgVq1OMitUpRl0paSsiIiIiIiIiIiJiIVqI7A7FlwK+dOmSm3tyf1y9ejXDvFZJnxSjYnWKUbE6xahYnWJUrE4xKlanGBWryygxGv8a/22ZMSVt79Dly5cByJs3r5t7IiIiIiIiIiIiIunJ5cuXCQ4OTnG/zfFvaV1Jlt1u5/jx4wQFBWGz2dzdnXvq0qVL5M2blyNHjtxyVTsRd1GMitUpRsXqFKNidYpRsTrFqFidYlSsLiPFqMPh4PLly4SGhuLhkXLlWs20vUMeHh489NBD7u7GfZU5c+YH/j+OpG+KUbE6xahYnWJUrE4xKlanGBWrU4yK1WWUGL3VDNt4WohMRERERERERERExEKUtBURERERERERERGxECVt5V/5+vrSv39/fH193d0VkWQpRsXqFKNidYpRsTrFqFidYlSsTjEqVqcYTUoLkYmIiIiIiIiIiIhYiGbaioiIiIiIiIiIiFiIkrYiIiIiIiIiIiIiFqKkrYiIiIiIiIiIiIiFKGkrIiIiIiIiIiIiYiFK2sot/fe//6VAgQL4+flRvXp11q5d6+4uiTgtXbqUNm3aEBoais1mY8qUKe7ukojTxx9/TNWqVQkKCiIkJIS2bduya9cud3dLxOn777+nXLlyZM6cmcyZM1OzZk1mzZrl7m6JpGjIkCHYbDZef/11d3dFBIABAwZgs9lcthIlSri7WyIujh07RpcuXciePTv+/v6ULVuW9evXu7tbIk4FChRIMpbabDZeeeUVd3fN7ZS0lRSNHz+eXr160b9/fzZu3Ej58uVp3rw5p0+fdnfXRACIjIykfPny/Pe//3V3V0SSWLJkCa+88gqrV69m3rx5xMTE0KxZMyIjI93dNREAHnroIYYMGcKGDRtYv349jRo14tFHH2Xbtm3u7ppIEuvWrePHH3+kXLly7u6KiIvSpUtz4sQJ57Z8+XJ3d0nE6cKFC9SuXRtvb29mzZrF9u3b+eKLL8iaNau7uybitG7dOpdxdN68eQA8/vjjbu6Z+9kcDofD3Z0Qa6pevTpVq1Zl2LBhANjtdvLmzcv//d//8c4777i5dyKubDYbkydPpm3btu7uikiyzpw5Q0hICEuWLKFevXru7o5IsrJly8Znn33Gc8895+6uiDhduXKFSpUq8d133/HBBx9QoUIFhg4d6u5uiTBgwACmTJnCpk2b3N0VkWS98847rFixgmXLlrm7KyKp9vrrrzN9+nT27NmDzWZzd3fcSjNtJVnR0dFs2LCBJk2aONs8PDxo0qQJq1atcmPPRETSp4iICMAkxUSsJi4ujt9//53IyEhq1qzp7u6IuHjllVdo3bq1y+dSEavYs2cPoaGhFCpUiM6dO3P48GF3d0nE6a+//qJKlSo8/vjjhISEULFiRX766Sd3d0skRdHR0fz22288++yzGT5hC0raSgrOnj1LXFwcuXLlcmnPlSsXJ0+edFOvRETSJ7vdzuuvv07t2rUpU6aMu7sj4rRlyxYyZcqEr68vL730EpMnT6ZUqVLu7paI0++//87GjRv5+OOP3d0VkSSqV6/OyJEjmT17Nt9//z0HDhygbt26XL582d1dEwFg//79fP/99xQtWpQ5c+bQo0cPXn31VUaNGuXurokka8qUKVy8eJFnnnnG3V2xBC93d0BERORB98orr7B161bVuRPLKV68OJs2bSIiIoI///yTrl27smTJEiVuxRKOHDnCa6+9xrx58/Dz83N3d0SSaNmypfN2uXLlqF69Ovnz5+ePP/5QmRmxBLvdTpUqVfjoo48AqFixIlu3buWHH36ga9eubu6dSFK//PILLVu2JDQ01N1dsQTNtJVk5ciRA09PT06dOuXSfurUKXLnzu2mXomIpD89e/Zk+vTpLFq0iIceesjd3RFx4ePjQ5EiRahcuTIff/wx5cuX5+uvv3Z3t0QA2LBhA6dPn6ZSpUp4eXnh5eXFkiVL+Oabb/Dy8iIuLs7dXRRxkSVLFooVK8bevXvd3RURAPLkyZPki9iSJUuqjIdY0qFDh5g/fz7PP/+8u7tiGUraSrJ8fHyoXLkyCxYscLbZ7XYWLFigWnciIqngcDjo2bMnkydPZuHChRQsWNDdXRL5V3a7naioKHd3QwSAxo0bs2XLFjZt2uTcqlSpQufOndm0aROenp7u7qKIiytXrrBv3z7y5Mnj7q6IAFC7dm127drl0rZ7927y58/vph6JpGzEiBGEhITQunVrd3fFMlQeQVLUq1cvunbtSpUqVahWrRpDhw4lMjKSbt26ubtrIoD5YJx4JsOBAwfYtGkT2bJlI1++fG7smYgpiTB27FimTp1KUFCQsx54cHAw/v7+bu6dCLz77ru0bNmSfPnycfnyZcaOHcvixYuZM2eOu7smAkBQUFCSOuCBgYFkz55d9cHFEt566y3atGlD/vz5OX78OP3798fT05NOnTq5u2siALzxxhvUqlWLjz76iA4dOrB27VqGDx/O8OHD3d01ERd2u50RI0bQtWtXvLyUqoynd0JS9MQTT3DmzBn69evHyZMnqVChArNnz06yOJmIu6xfv56GDRs67/fq1QuArl27MnLkSDf1SsT4/vvvAWjQoIFL+4gRI1RYXyzh9OnTPP3005w4cYLg4GDKlSvHnDlzaNq0qbu7JiKSLhw9epROnTpx7tw5cubMSZ06dVi9ejU5c+Z0d9dEAKhatSqTJ0/m3XffZdCgQRQsWJChQ4fSuXNnd3dNxMX8+fM5fPgwzz77rLu7Yik2h8PhcHcnRERERERERERERMRQTVsRERERERERERERC1HSVkRERERERERERMRClLQVERERERERERERsRAlbUVEREREREREREQsRElbEREREREREREREQtR0lZERERERERERETEQpS0FREREREREREREbEQJW1FRERERERERERELERJWxERERGRO2Cz2RgwYIC7u3FLzzzzDAUKFHB3N0RERETkNilpKyIiIiJus2XLFh577DHy58+Pn58fYWFhNG3alG+//dbdXbvvChQowMMPP+zuboiIiIiIBShpKyIiIiJusXLlSqpUqcLmzZt54YUXGDZsGM8//zweHh58/fXX7u6eiIiIiIjbeLm7AyIiIiKSMX344YcEBwezbt06smTJ4rLv9OnT7umUiIiIiIgFaKatiIiIiLjFvn37KF26dJKELUBISIjL/REjRtCoUSNCQkLw9fWlVKlSfP/990keF19iYPHixVSpUgV/f3/Kli3L4sWLAZg0aRJly5bFz8+PypUr8/fff7s8/plnniFTpkzs37+f5s2bExgYSGhoKIMGDcLhcPzrazp27BjPPvssuXLlwtfXl9KlS/O///0v9W9KIgcPHsRms/H5558zfPhwChcujK+vL1WrVmXdunVJjp8yZQplypTBz8+PMmXKMHny5GTPa7fbGTp0KKVLl8bPz49cuXLRvXt3Lly44Dymf//+eHh4sGDBApfHvvjii/j4+LB58+Y7ek0iIiIikjqaaSsiIiIibpE/f35WrVrF1q1bKVOmzC2P/f777yldujSPPPIIXl5eTJs2jZdffhm73c4rr7zicuzevXt58skn6d69O126dOHzzz+nTZs2/PDDD/Tp04eXX34ZgI8//pgOHTqwa9cuPDwS5jLExcXRokULatSowaeffsrs2bPp378/sbGxDBo0KMU+njp1iho1amCz2ejZsyc5c+Zk1qxZPPfcc1y6dInXX3/9jt6nsWPHcvnyZbp3747NZuPTTz+lffv27N+/H29vbwDmzp1LeHg4pUqV4uOPP+bcuXN069aNhx56KMn5unfvzsiRI+nWrRuvvvoqBw4cYNiwYfz999+sWLECb29v3n//faZNm8Zzzz3Hli1bCAoKYs6cOfz0008MHjyY8uXL39FrEREREZFUcoiIiIiIuMHcuXMdnp6eDk9PT0fNmjUdb7/9tmPOnDmO6OjoJMdevXo1SVvz5s0dhQoVcmnLnz+/A3CsXLnS2TZnzhwH4PD393ccOnTI2f7jjz86AMeiRYucbV27dnUAjv/7v/9zttntdkfr1q0dPj4+jjNnzjjbAUf//v2d95977jlHnjx5HGfPnnXpU8eOHR3BwcHJvoab+966dWvn/QMHDjgAR/bs2R3nz593tk+dOtUBOKZNm+Zsq1ChgiNPnjyOixcvOtvmzp3rABz58+d3ti1btswBOMaMGePy3LNnz07SvmXLFoePj4/j+eefd1y4cMERFhbmqFKliiMmJuaWr0NERERE7p7KI4iIiIiIWzRt2pRVq1bxyCOPsHnzZj799FOaN29OWFgYf/31l8ux/v7+ztsRERGcPXuW+vXrs3//fiIiIlyOLVWqFDVr1nTer169OgCNGjUiX758Sdr379+fpG89e/Z03o6fORsdHc38+fOTfS0Oh4OJEyfSpk0bHA4HZ8+edW7NmzcnIiKCjRs3pvatcfHEE0+QNWtW5/26deu69PvEiRNs2rSJrl27Ehwc7DyuadOmlCpVyuVcEyZMIDg4mKZNm7r0sXLlymTKlIlFixY5jy1TpgwDBw7k559/pnnz5pw9e5ZRo0bh5aWL9URERETuNX3iEhERERG3qVq1KpMmTSI6OprNmzczefJkvvrqKx577DE2bdrkTDquWLGC/v37s2rVKq5evepyjoiICJdkZeLELODclzdv3mTbE9dyBfDw8KBQoUIubcWKFQNMndnknDlzhosXLzJ8+HCGDx+e7DF3urjaza8nPoEb3+9Dhw4BULRo0SSPLV68uEuyeM+ePURERCSpGZxSH3v37s3vv//O2rVr+eijj5IkgUVERETk3lDSVkRERETczsfHh6pVq1K1alWKFStGt27dmDBhAv3792ffvn00btyYEiVK8OWXX5I3b158fHyYOXMmX331FXa73eVcnp6eyT5HSu2OVCww9m/i+9ClSxe6du2a7DHlypW7o3OnZb/tdjshISGMGTMm2f05c+Z0ub9//3727NkDwJYtW277+URERETkzihpKyIiIiKWUqVKFcBc9g8wbdo0oqKi+Ouvv1xmnSa+lD8t2e129u/f75xdC7B7924AChQokOxjcubMSVBQEHFxcTRp0uSe9Csl+fPnB3AmVxPbtWuXy/3ChQszf/58ateu7VJyIjl2u51nnnmGzJkz8/rrr/PRRx/x2GOP0b59+7TrvIiIiIgkSzVtRURERMQtFi1alOxs0ZkzZwLm0n5ImGma+NiIiAhGjBhxz/o2bNgw522Hw8GwYcPw9vamcePGyR7v6elJeHg4EydOZOvWrUn2nzlz5p71NU+ePFSoUIFRo0a51PedN28e27dvdzm2Q4cOxMXFMXjw4CTniY2N5eLFi877X375JStXrmT48OEMHjyYWrVq0aNHD86ePXvPXouIiIiIGJppKyIiIiJu8X//939cvXqVdu3aUaJECaKjo1m5ciXjx4+nQIECdOvWDYBmzZrh4+NDmzZt6N69O1euXOGnn34iJCTEORs3Lfn5+TF79my6du1K9erVmTVrFjNmzKBPnz5JygckNmTIEBYtWkT16tV54YUXKFWqFOfPn2fjxo3Mnz+f8+fPp3lf43388ce0bt2aOnXq8Oyzz3L+/Hm+/fZbSpcuzZUrV5zH1a9fn+7du/Pxxx+zadMmmjVrhre3N3v27GHChAl8/fXXPPbYY+zYsYO+ffvyzDPP0KZNGwBGjhxJhQoVePnll/njjz/u2WsREREREc20FRERERE3+fzzz2nYsCEzZ86kV69e9OrVi7Vr1/Lyyy+zZs0asmTJApgZt3/++Sc2m4233nqLH374gRdffJHXXnvtnvTL09OT2bNnc/LkSXr37s26devo379/srNTE8uVKxdr166lW7duTJo0iZ49e/L1119z/vx5Pvnkk3vS13gtWrRgwoQJxMXF8e677zJp0iRGjBjhLDWR2A8//MDw4cM5ffo0ffr04d1332XhwoV06dKF2rVrExcXR9euXcmRIwdDhw51Pq5o0aJ8/PHHTJgwQUlbERERkXvM5kiLlRdERERERB4AzzzzDH/++afL7FQRERERkftNM21FRERERERERERELERJWxERERERERERERELUdJWRERERERERERExEJU01ZERERERERERETEQjTTVkRERERERERERMRClLQVERERERERERERsRAlbUVEREREREREREQsRElbEREREREREREREQtR0lZERERERERERETEQpS0FREREREREREREbEQJW1FRERERERERERELERJWxERERERERERERELUdJWRERERERERERExEKUtBURERERERERERGxECVtRURERERERERERCxESVsRERERERERERERC1HSVkRERERERERERMRClLQVERERERERERERsRAlbUVEREREJIkBAwZgs9lYvHixs+3gwYPYbDaeeeYZt/UrtRYvXozNZmPAgAHu7oqIiIjIbVPSVkRERETSjM1mu61NEpKjibfAwEDKlSvHgAEDiIyMdHcX05TNZqNBgwbu7oaIiIiIpXm5uwMiIiIi8uDo379/krahQ4cSERGR7D5JEB4eTpkyZQA4ceIEf/31FwMHDmTatGmsWrUKHx8fN/cQwsLC2LFjB8HBwe7uioiIiMgDTUlbEREREUkzyV2KPnLkSCIiInSZ+r947LHH6Nixo/P+559/TrVq1di4cSNjx461REkCb29vSpQo4e5uiIiIiDzwVB5BRERE5AGydOlS2rZtS65cufD19SVv3ry0b9+e5cuXA3Du3DkeeughgoKC2Lt3r8tjb7UvrSWujbpjxw7atWtH9uzZsdlsHDx48F9rp6Z0if3ly5fp378/pUuXxt/fnyxZstC8eXPn6/83gwcPxmazMXr06GT3T5o0CZvNxnvvveds27hxI4899hj58uXD19eXnDlzUrVqVT788MNUPWdKgoKCnK9/3bp1gEmA22w2Ro4cybRp06hduzZBQUEUKFDA+bjo6Gi+/PJLKlWqRGBgIEFBQdStW5e//vor2ec5cuQInTp1Ilu2bGTKlIn69euzdOnSZI+91b/L5cuXGThwIOXKlSMgIIDg4GAqVqxI3759iYmJcdaYBViyZIlLOYiRI0e6nGvq1Kk0btyYrFmz4ufnR5kyZfj888+Ji4tL8rzXrl3jnXfeIW/evM5jf/rpp395d0VERESsTUlbERERkQfE119/TYMGDZg3bx5NmzblzTffpFGjRmzevJk///wTgOzZszN69GiuXr3Kk08+SUxMjPPxzz33HMeOHWPYsGEUKVLE2R5fc/VezJTdu3cvNWrU4MyZMzzzzDN07dr1jssAnD9/npo1azJo0CCyZs3KSy+9RHh4OBs2bKBhw4ZMmTLlX8/RpUsXbDYbv/32W7L7f/31VwCeeuopADZt2kStWrWYNWsWderUoVevXjz22GMEBAQwfPjwO3odybm5/u+ECRNo3749ISEhvPzyy7Rs2RKAqKgomjdvzptvvonD4eC5556jS5cuHDp0iEcffZRhw4a5nOfEiRPUrFmT33//nWrVqvHqq6+SLVs2mjZtyurVq1Pdv9OnT1OtWjUGDBiAp6cnPXr04NlnnyV37tx88sknREZGUqBAAWeJjPz589O/f3/nVqFCBee53n33Xdq2bcuuXbto3749L7/8Mv7+/vTu3dtlJjKA3W7nkUce4ZNPPiFr1qy89tpr1KhRgzfeeIMvvvjidt5iEREREWtxiIiIiEi6t2nTJoeHh4cjNDTUceDAAZd9drvdcezYMZe2d955xwE43n77bYfD4XD897//dQCOTp06JTl3//79HYCjf//+d9S3/PnzO27+2HngwAEH4AAc/fr1S/KY+P1du3ZN9pyAo379+i5tTz75pANw/PTTTy7tp06dcuTNm9eRM2dOx7Vr1/61v3Xq1HF4eno6jh8/7tJ+7tw5h4+Pj6NKlSrOtl69ejkAx5QpU5Kc5+zZs//6XA5Hwvs7btw4l/bLly87SpUq5QAco0aNcjgcDseIESMcgMPDw8Mxb968JOfq06ePA3D07dvXYbfbne2XLl1yVKlSxeHj4+MSC127dnUAjg8++MDlPD/++KPz32fRokXO9pT+XcLDwx2Ao0+fPkn6dPLkSUdMTIzzfnL/dvHmzp3rABzNmzd3XLlyxdlut9sdL730kgNw/Pnnn872+PejRYsWjtjYWGf7P//84/Dx8bmruBURERFxJ820FREREXkA/Pjjj9jtdj744AOXS+XBzNIMDQ11aRs0aBBVq1bl888/59tvv+Wtt96iQIEC/PDDD0nO3bNnT3bs2EHPnj3TvN+5c+d2KTVwp86ePcv48eNp1KgRzz//vMu+kJAQevfuzZkzZ5g/f/6/nuupp54iLi6OcePGubSPHz+e6OhounTpkuQx/v7+SdqyZ89+W6/hzz//ZMCAAQwYMIAePXpQvHhxtm/fTpUqVZLMMH300Udp0qSJS5vdbuf777+ncOHCDBw40GV2blBQEP369SM6OppJkyYBpozC+PHjCQkJ4c0333Q51/PPP0/RokVT1e+TJ08yadIkChcunOxs7Fy5cuHllbqlNOJnAg8fPpzAwEBnu81mY8iQIdhsNpd/l/gyFh9++CGenp7O9rJlyzpnQ4uIiIikR1qITEREROQBsHbtWgCaNWuWquO9vb0ZN24cFSpU4NVXX8XT05MxY8aQOXPmJMfmyJGDHDlypGl/45UvX/6OyyEktm7dOuLi4oiKiko2cbhnzx4Adu7cycMPP3zLc3Xo0IFXX32VX3/9lV69ejnbf/vtN7y8vOjUqZPLsUOHDqVdu3Y88cQTNG3alHr16hEWFnbbr2HixIlMnDgRgICAAAoXLsyLL77IW2+9leQ9qlatWpLH79q1iwsXLhAaGsrAgQOT7D9z5gxg3oP4469fv06jRo3w8/NzOdbDw4PatWs737dbWb9+PQ6Hg4YNG+Lt7Z26F5uC1atXExgYyP/+979k9/v7+zv7D7B582YCAwOpVKlSkmPr1q3LL7/8clf9EREREXEXJW1FREREHgARERHYbDby5MmT6scUKlSI8uXLs2LFCipXrkytWrXuYQ+TlytXrjQ5z/nz5wFYsWIFK1asSPG4yMjIfz1XlixZePjhh5k4cSLbt2+nVKlS7Nu3j5UrV9KqVStCQkKcx1avXp3Fixfz0UcfMXbsWEaMGAFA1apV+eSTT2jYsGGqX8O4ceOSzKhNSXLvW/x7sG3bNrZt25biY+Pfg4iICACX1/Nvz5Gc+PPcSaL6ZufPnyc2NjbZpHO8xP+GERER5M2bN9nj0iq2RERERNxB5RFEREREHgBZsmTB4XBw4sSJVD/myy+/ZMWKFWTPnp21a9fy3Xff3cMeJu/mBbbieXiYj6mxsbFJ9sUnCROLnyEcvwBXSlv8Qlj/Jv7S+viFx+IXJkvukvu6desya9YsLly4wKJFi+jVqxdbtmyhdevW7N+/P1XPd7uSe9/i34Pw8PBbvgfxieXg4GDALCKWnFOnTqWqL1myZAHg2LFjt/syksicOTPZs2e/Zf8PHDjgPD44ONg5g/hO+y8iIiJiRUraioiIiDwA4i+Xnzt3bqqO//vvv+nTpw/Fixdny5YtFCxYkLfeeuuWMzTvp1slAv/+++8kbVWrVsVms7Fq1ao0ef5WrVqRPXt2xo4di91uZ8yYMQQFBfHoo4+m+Bh/f38aNGjAF198QZ8+fbh27Rrz5s1Lk/6kRsmSJcmcOTPr168nJibmX48vVqwYfn5+rF+/nuvXr7vss9vtrFy5MlXPW6VKFTw8PFi0aFGqntfDw4O4uLhk91WvXp1z586lqiwDmPIakZGRbNy4Mcm+ZcuWpeocIiIiIlakpK2IiIjIA+Cll17C09OT999/n0OHDrnsczgcHD9+3Hk/MjLSWZd13Lhx5MmTh7FjxxITE0OnTp2SJPDOnj3Lzp07OXv27L1/ITdkzpyZ4sWLs3z5cvbu3etsv3z5Mu+++26S43Pnzk2HDh1YuXIln332GQ6HI8kxa9as4erVq6l6fm9vb5544gkOHz7Mp59+yp49ewgPD0+y4NiqVauSvF+QMMvz5lqx95KXlxc9evTg0KFDvPXWW8kmULdu3eqcWevr60uHDh04ffo0X3zxhctxP//8M7t3707V8+bKlYvw8HD27duXbFmD06dPu8yYzpYtG0ePHk32XK+++ioAzz77LOfOnUuy/+TJk+zYscN5P37m83vvveeSCN6yZYtzlrSIiIhIeqSatiIiIiIPgLJlyzJ06FBeffVVSpcuTdu2bcmfPz8nT55k6dKltG7dmqFDhwLw2muvsWvXLj7//HMqVqwIQI0aNejfvz99+/ald+/efPvtt85zDxs2jIEDB9K/f/9kF/m6V958801efPFFatasyeOPP47dbmfWrFlUrVo12eO/++47du3axdtvv82vv/5KzZo1yZIlC0eOHGH9+vXs2bOHEydOEBAQkKrnf+qpp/juu+/o16+f8/7NPvnkExYtWkS9evUoWLAgfn5+bNy4kQULFlCoUCHatWt352/AHRg4cCAbN27km2++YcaMGdSrV4+QkBCOHTvGli1b2Lx5M6tWrXLWsR0yZAgLFizg/fffZ/ny5VSsWJEdO3Ywc+ZMmjVrluqZ29999x1bt27lww8/ZObMmTRq1AiHw8Hu3buZO3cup06dcs6ebtSoEX/88Qdt27alYsWKeHp68sgjj1CuXDlatGhB3759GTx4MEWKFKFFixbkz5+fc+fOsXfvXpYtW8YHH3xAyZIlAejatStjx45l9uzZVKxYkZYtW3L+/HnGjRtHs2bNmD59+j15n0VERETuNSVtRURERB4QPXv2pEyZMnzxxRfMmjWLK1euEBISQvXq1enQoQMAEydO5JdffqFp06b06tXL5fF9+vRh3rx5DBs2jObNm/Pwww+742U4vfDCC8TExDB06FB+/vln8uTJwzPPPMP777+Pj49PkuOzZcvGypUrGTZsGOPHj2fMmDHY7XZy585N+fLl6du3Lzly5Ej189eoUYOiRYuyZ88eHnroIRo0aJDkmB49ehAcHMyaNWtYsmQJDoeDfPny0adPH9544w1nndn7xdfXl1mzZvHLL78wevRoJk6cSFRUFLly5aJUqVK89NJLlC1b1nl8njx5WLlyJW+//TZz5sxh6dKlVK5cmXnz5rFw4cJUJ21z5MjB6tWr+fzzz5kwYQLDhg3Dz8+PggUL8s477xAYGOg89uuvvwZg4cKFTJs2DbvdzkMPPUS5cuUAGDRoEPXq1eObb75hwYIFXLx4kezZs1OwYEEGDBhA586dnefy8PBg6tSpDBw4kDFjxvD1119TuHBhvvrqK4oWLaqkrYiIiKRbNkdy146JiIiIiIiIiIiIiFuopq2IiIiIiIiIiIiIhShpKyIiIiIiIiIiImIhStqKiIiIiIiIiIiIWIiStiIiIiIiIiIiIiIWoqStiIiIiIiIiIiIiIV4ubsD6ZXdbuf48eMEBQVhs9nc3R0RERERERERERGxOIfDweXLlwkNDcXDI+X5tEra3qHjx4+TN29ed3dDRERERERERERE0pkjR47w0EMPpbhfSds7FBQUBJg3OHPmzG7uzb03a9YsWrZs6e5uiKRIMSpWpxgVq1OMitUpRsXqFKNidYpRsbqMEqOXLl0ib968ztxiSmwOh8Nxn/r0QLl06RLBwcFERERkiKTtuXPnyJ49u7u7IZIixahYnWJUrE4xKlanGBWrU4yK1SlGxeoySoymNqeohcgkVW5VY0PEChSjYnWKUbE6xahYnWJUrE4xKlanGBWrU4y60rshqbJ8+XJ3d0HklhSjYnWKUbE6xahYnWJUrE4xKlanGBWrU4y6UtJWRERERERERERExEKUtBURERERERG5XQMGwODBye8bPNjsFxERuUNK2kqqlCtXzt1dELklxahYnWJUrE4xKlanGBXL8fSEfv2ciVtnjA4ebNo9Pd3YOZGkNI6K1SlGXXm5uwOSPoSGhrq7CyK3pBgVq1OMitUpRsXqFKNiOX37mp/9+gEQ+p//JCRsBw1K2C9iERpH01ZcXBwxMTHu7sYDJVu2bFy/ft3d3bhjXl5eeHp6YrPZ0uZ8aXIWeeDNnj2bNm3auLsbIilSjIrVKUbF6hSjYnWKUbGkRIlbrxvJW8LCYP16ePFFyJ3bbKVLQ/367uunCBpH04rD4eDkyZNcvHjR3V154Fy9epWAgAB3d+OueHp6EhISQnBw8F0nb5W0FREREREREblTffvCBx9gi442948dM1ti7dsnJG0dDsiZE7Jlg1y5EhK78VvJklCr1v19DSKSavEJ25CQEAICAtJsVqXApUuXyJw5s7u7cUccDgexsbFcunSJEydOcO3aNfLkyXNX51TSVkREREREROR2HToE2bPDV19BdDR2Ly88YmPhySdNgvbkyYQtcRL2wgU4d85se/YkPW/79gnHOxxm5m5KCd4SJaBq1fvzekWEuLg4Z8I2e/bs7u7OA+f69ev4+fm5uxt3JSgoCF9fX86ePUtISAied1HfXElbSZXChQu7uwsit6QYFatTjIrVKUbF6hSjYinHjkHDhhATA0ePwqBB7AwPp9TEiaambYkSzlq3SQQHw+7drknd+O3UKahWLeHY8+fhxAmzbduW9Fzh4fDnn+a23Q4FC0KOHCahe3OSt1gxqFAhzd8KST80jt69+Bq26f0Sfqvy9fV1dxfSRGBgIGfOnCEmJkZJW7n3SpUq5e4uiNySYlSsTjEqVqcYFatTjIplnD0LzZrBgQPmfu/e0LcvpQDi4zQ+YZvcYmSenlC0qNn+TXAwbNlikrnJJXmrVEk49vx5OHzYbMl57DGYMMHcttuhePGEBO/NSd6iRU0dXnmgaBxNOyqJcG/4+/u7uwtpQguRyX01d+5cmjVr5u5uiKRIMSpWpxgVq1OMitUpRsUSLl2CFi1g+3YICoLnn4dPPwUSxWh8ojYu7u6fz8sLypQx278JDjYLoMXP2L05wVu+fMKx587B3r1mS87jj8Mff5jbdrt5/pw5XWfuxid5ixQxs3jF8jSOitVFREQQHBzs7m5YhpK2kipRUVHu7oLILSlGxeoUo2J1ilGxOsWouN21a9CmDWzYYGaoLl1qFg27wSVGk5the695e0Plyqk7NjgYVq50LcuQOMGbeJbtuXOwY4fZktOhA4wfb27HxZk+hIQkrb+bKxcUKmRKOIhbaBwVq3M4HO7ugqUoaSsiIiIiIiJyK9HRprzA0qWQOTPMmeNM2E6aBAMHwo4drShZEvr3N2uJWZqPD9SsmbpjM2eGxYtTTvCWKJFw7LlzsHlzyud64gn4/XdzOy7O9CG5BG/u3FCgADz00J2+QhGRdE9JW0mVXLlyubsLIrekGBWrU4yK1SlGxeoUo+JWR46YGbb+/jB9OlSqBJiEbXg42GzgcHiyZYu5P3o0PPmkKV+b7vn6Qv36qTs2KMgktG9eXC3+dpEiCceePQvr1qV8ro4dYdw4czsuzvQhpQRvvnzmp9ySxlFJSWprsC5atIgGDRrcs354e3vfs3OnRzaH5h7fkUuXLhEcHExERASZM2d2d3dERERERETkXtqzBw4ehKZNnU3ly5t1wlL6qzogwExUDQpK+Jn4dko/k2t7IBLAiV29CgsXJq29G5/kffxx+Ogjc+zJk5AnT8rn6tQJxo41t2NjzUJxNy+uFr899BBkz37vX588kK5fv86BAwcoWLAgfn5+7u5Omvntt99c7o8ePZp58+bx66+/urQ3bdpUyf9U+Lc4SW1OUTNtJVVWrlxJrVq13N0NkRQpRsXqFKNidYpRsTrFqNx3DgccOmQu0wcoWtRsiezYkXLCFkxe8upVk3O8WwEBqU/w3uqYoCCzvpnbBQTAww+n7tigIJg4MWmCNz7Jmy9fwrFnzsCiRSmf68knYcwYczs21vTh5sXV4rfQUFP/9wGhcVRS0qVLF5f7q1evZt68eUnab3b16lUCAgLSrB9XrlwhU6ZMaXa+9M4KQ7WkA+fOnXN3F0RuSTEqVqcYFatTjIrVKUblvhsyBAYPNjUQWrRIsnvaNIiJSfowmw3KloUFC+DSJbh8OenP5NpS+hkdbc4bnwA+deruX5q/f9rNAL4vCeDAwNQXCg4KMknZm2vvxm+hoQnHnj5tyjmkpHNniJ+BGBNjal8kV54hfkvD5NW9oHFU7kaDBg04e/Yso0aN4o033mD9+vW8+OKLDB06FJvNRv/+/RkwYIDLYwoUKECDBg0YOXKks+3ixYsMGDCAiRMncvr0afLmzcsLL7xA7969iY2Nvb8vyuKUtBURERERERFJ7LvvoE8fc3vHjiRJ2/nzzdX78UxN24SfAwZAjhxmu1tRUalP9P7bMfEJ4GvXzJZWCeC0mgGcJuUsM2Uys2lTknhqdKZMMGJE8gusnTzpWif39GmTqU9Jly4Qfyl5dLRJ+N6c1I2fyRsSYhaDE7khfkHD3buhWDHrLmh47tw5WrZsSceOHenSpcttl0q4evUq9evX59ixY3Tv3p18+fKxcuVK3n33XU6cOJEk6ZvRKWkrqRIYGOjuLojckmJUrE4xKlanGBWrU4zKffPbb/DKK+Z2v37wxhsuu5cvh0cfNcnUtm1NOdWPPoLt2+MoVcqT/v2hXbu0646vr9nSIgEcHX17s3xvtS8qypwzPgF8+vTd98/PL+1mAKeYAE684FLmzPDMMyl3yG5PuJ0pE/z4Y/Kzd0+cSJrg/fPPlM97c4K3W7fkZ+7mymX+4T08/u2tS96AAaYYct++wE3j6ODBZoE3JcnumsNhZsHfqalTTY4//kuf+AUNx4wxY82dCAhwDfW0cvLkSX744Qe6d+9+R4//8ssv2bdvH3///TdFb5Sb6d69O6GhoXz22We8+OKLZMmSJQ17nL4paSup0qhRI3d3QeSWFKNidYpRsTrFqFidYlTui6lTE5J4r76aJKG1fj20bm0SNM2bw++/m4Rqhw4A1l8pzMfHrMGVFutw3ZwAvpskcHwC+Pp1s6VVAvjuZwB7kDnzjQRwcDC8+GLyT+ZwmARovMBA+Oab5BdYO3XKdVG1U6cSFlFLztNPw6hR5nZUFPTokXJ5hqAg10ydp6f54gGgb9+EcXTwYNM+aNBtv6+S1NWrJqd/t+Ingcf/7Nz5zs915YoJw7Tm6+tLt27d7vjxEyZMoG7dumTNmpWzZ88625s0acKQIUP4+++/KVWqVFp09YGgpK2kyubNmylfvry7uyGSIsWoWJ1iVKxOMSpWpxiVe27BApN9jYuDrl3hq69cEmBbt5pE7aVLUK+euZzZ1zfh4RktRu9FAvh26/0m13b9ujlnfAL4zJm775+v778leG0EBXkl2peVoCL/R+ZKSRPFPl5212LIgYHw+efJL7B25ozrDN5Tp0w5h5Q8+yz88kvCG3D8ODRsaBK0O3aw9aWXKLNkSULC9sYMXJHUCgsLw+cuSnvs2bOHf/75h5w5cya7/+jRo3d87geRkraSKocPH85QH0Ak/VGMitUpRsXqFKNidYpRuedGjzbZw3bt4OefXS5J37MHmjSB8+ehWjWYPj3pmlOK0TuXlgngmJg7X/zt5rb4BHBUlMmfpk0C2IOgIN9ECd5sBAW9mZDYLQeZ65h9wQExBAfEEDjL3M8SG0DoWx/hH3ESnwsn8TydKMl76ZJrDY1Tp+CHHxLujxtH6XHjANjecRCllLBNMwEBZmbrnapRA7Ztcy23bLNBmTKwatWd9+le8Pf3v63j4xLPQAfsdjtNmzbl7bffTvb4262R+6BT0lZERERERETkl1+gfHlTz9Yr4U/lQ4egcWOTAytXDmbdSKCJNXl7Q7ZsZrtb8QngtEgCX7tmzhkVZbZEV4bf6tXc2OLlAN513vPxuZHozQ4h+a8SvDQWz1amLY9XAC1q9Mfj9Eki95/kUaZiAxzAV7/npuXj1lzoKj2y2e6uFMHAgaaG7c0LGg4ceG9KHNwLWbNm5eLFiy5t0dHRnDhxwqWtcOHCXLlyhSZNmiR7npvPkdEpaSsiIiIiIiIZ06lTkDOnmVXr5QW9ernsPn7cJGyPHIHixWHevLRJBkr6kNYJ4CtX7mzRt5uPiU8AR0eb5O/Zs3CAm6dW5mQoAwB4n8G0ZSpxeOCJnR/pTnifOrRvX/LuX5jctfbtYeJEU7Fi1y4z1qT1gob3WuHChVm6dKlL2/Dhw5PMtO3QoQMDBgxgzpw5NG/e3GXfxYsXiY2Nved9TU+UtJVUadOmjbu7IHJLilGxOsWoWJ1iVKxOMSpp7uhRqFMHGjWCn34yizYlcuYMNG0K+/ZBwYKm5G1ISMqnU4zKrXh7Q9asZrtbsbH/nuiNv+3/+WAGOvrRl0F8wPvMoylNWECFfX8CKpFgFe3bp++Zz88//zwvvfQS4eHhNG3alM2bNzNnzhxyJC7ZAfTu3Zu//vqLhx9+mGeeeYbKlSsTGRnJli1b+PPPPzl48KB7XoBFKWkrqbJv3z4KFy7s7m6IpEgxKlanGBWrU4yK1SlGJU3FZ2QPHYLly+HiRZeCqhcvmkXHtm+HsDCTsA0Lu/UpFaNyv3h5pTIBPHgwOPrRj0F8cCNB25T5vM9gBsf2g8FAp05w9aqp/SFyh1544QUOHDjAL7/8wuzZs6lbty7z5s2jcePGLscFBASwZMkSPvroIyZMmMDo0aPJnDkzxYoVY+DAgfgmXt1R8Pj3Q0Rg+/bt7u6CyC0pRsXqFKNidYpRsTrFqKSZiAho0QJ27oS8eWH+fJeE7ZUr0KoV/P23qZwwf76ZaftvFKNiOXFxbO84iMH0xWZLaP6AvvRlEOuWXIVHHoFatWDSJPf1Uyxn2LBhOBKvjAYsXryYrVu3Jnu8h4cHQ4YM4cyZM0RGRjJ79mwKFy7MwYMHGTlypMuxmTJl4qOPPmLPnj1ERUVx5swZVqxYwZtvvpmknEJGp6StiIiIiIiIZAxXr0KbNrBxo8nIzpsH+fI5d1+7ZnJYq1aZWYzz50OJEm7sr8jdGDCAUuP6MnGimUjr7R1HuXLw8MMmcdtswdvsvR4GkZFmJawBA8Bud3evReQGJW1FRERERETkwRcdbRJTy5ZBcDDMmWNW/Em0+7HHYNEiyJQJZs/WFePyYGjfHjZtgokTZ7J5M/z1F3z4IVwkKyUOzGJB2dfNgQMHwuOPm+nmIuJ2NsfN850lVS5dukRwcDARERFkzpzZ3d25565cuUKmTJnc3Q2RFClGxeoUo2J1ilGxOsWo3LUVK6BhQ1MQdN48qF3buSs21pT2/PNP8Pc3Cdt69W7v9IpRsbqbY/THH6FHD3A4YFiVEbz8z0vYoqOhbFmYOjV1dUEymOvXr3PgwAEKFiyIn5+fu7vzwImLi8PzpkUh06N/i5PU5hQ101ZSJTIy0t1dELklxahYnWJUrE4xKlanGJW7Vru2SURNnuySsLXb4dlnTcLWx8fsvt2ELShGxfpujtHu3WH8ePD2hp7ru/FaucXYc+WGLVvg1Vfd1EvJyOwqz+FCSVtJlbVr17q7CyK3pBgVq1OMitUpRsXqFKNyRxwOuHgx4X7LltC8ucvuV16BX38FT0+TwEq0+7YoRsXqkovRxx+HGTMgMBC+XV+TR/KsJ6pVW/jpp/vfQcnw9OWXKyVtRURERERE5MH04YdQoQLs3Ztkl8MBvXvDDz+AzQajR0Pbtve9hyJu17QpLFgA2bLBjE1hVDwwmaOxuRMOmDQJoqLc10GRDCrdJW0HDBiAzWZz2UokWs7z+vXrvPLKK2TPnp1MmTIRHh7OqVOnXM5x+PBhWrduTUBAACEhIfTu3ZvY2Nj7/VJERERERETkXvn2W+jbFw4dgvnzk+weNAi++MLcHj4cnnzyPvdPxEKqVzdr9IWFwY4dpoLIrl3AuHFmAb9GjeCm3IqI3FvpLmkLULp0aU6cOOHcli9f7tz3xhtvMG3aNCZMmMCSJUs4fvw47du3d+6Pi4ujdevWREdHs3LlSkaNGsXIkSPp16+fO15KulG1alV3d0HklhSjYnWKUbE6xahYnWJUbsvo0Qk1OQcMgJdectn9+eemGWDoUHj++bt/SsWoWN2/xWipUma9vmLF4PBhqFMH9pzNCsHBsHIlVKkCGzbcp95KRhQYGOjuLlhKukzaenl5kTt3bueWI0cOACIiIvjll1/48ssvadSoEZUrV2bEiBGsXLmS1atXAzB37ly2b9/Ob7/9RoUKFWjZsiWDBw/mv//9L9HR0e58WZYWFBTk7i6I3JJiVKxOMSpWpxgVq1OMSqpNngzdupnbr78ON03Q+e47UxYBTPWE115Lm6dVjIrVpSZG8+eH5cuhcmU4exYq9WnB6q/XQPHicPSoyeSOG3cfeisZkYdHukxT3jPp8t3Ys2cPoaGhFCpUiM6dO3P48GEANmzYQExMDE2aNHEeW6JECfLly8eqVasAWLVqFWXLliVXrlzOY5o3b86lS5fYtm1bis8ZFRXFpUuXXLaMZOHChe7ugsgtKUbF6hSjYnWKUbE6xaikyvz50LEj2O0mcfvFF6Zg7Q2jRpmFxwDefRf69Em7p1aMitWlNkZz5oSFC6FhQ7hyBeq/WJy/3lsDrVrB9eumlsi770Jc3D3usWQ0ly9fdncXLMXL3R24XdWrV2fkyJEUL16cEydOMHDgQOrWrcvWrVs5efIkPj4+ZMmSxeUxuXLl4uTJkwCcPHnSJWEbvz9+X0o+/vhjBg4cmKR91qxZBAQEANC0aVPOnTvHxo0bnftr1qyJl5cXy5Ytc7aVK1eOsLAwZs2a5WwrVKgQpUuXZt68eVy/fh2AkJAQqlevzqpVqzh79iwAAQEBNG7cmC1btnDw4EHn41u3bs3BgwddEs/169fn+vXrrFmzxtlWpUoVgoODWbBggbOtRIkSFC1alBkzZmC32wHImzcvFSpUYPHixVy+fBm73c7y5cupU6cO69ev58SJEwB4e3vTokULdu7cyZ49e5znbNasGWfOnOHvv/92ttWqVQsPDw+XchblypUjNDSU2bNnO9sKFy5MqVKlmDt3LlE3ip3nypWLatWqsXLlSs6dOweYafONGjVi8+bNzsQ9QJs2bdi3bx/bt293tjVs2JDIyEiX1TKrVq1KUFCQyy+ukiVLUqRIEaZPn47D4QAgX758lC9f3vleAGTLlo3atWuzbt06Z9z4+PjQvHlzduzYwd5ECx00b96cU6dOsWnTJmdb7dq1AVixYoWzrUKFCuTKlYs5c+Y424oUKULJkiWZM2eOcyZ47ty5qVq1KitWrOD8+fOA+ca0QYMGLu+FzWbj4YcfZu/evezYscN5zkaNGnH58mXWrVvnbKtWrRqBgYEsWrTI2VaqVCkKFy7MtGnTnG3x78XChQudqzpmz56dWrVqsXbtWmf9aF9fX5o1a8b27dvZt2+f8/EtWrTg+PHj/PPPP862OnXqYLfbWblypbOtYsWK5MyZk7lz5zrbihYtSokSJZg9ezYxMTEA5MmThypVqrB8+XLsdjvTpk1zvhebNm3iyJEjgPm2rnXr1uzZs4edO3c6z9m4cWMiIiJYv369s6169er4+fmxZMkSZ1vp0qUpUKAAM2bMcLYVKFCAsmXLsmDBAq5evQpAjhw5qFmzJmvWrOH06dMA+Pn50bRpU7Zt28b+/fudj2/ZsiXHjh1zeS/q1q1LbGys80smgEqVKpE9e3bmzZvnbCtWrBjFixdn1qxZznrcoaGhVK5cmWXLlnHxxgrJwcHB1KtXj40bN3Ls2DEAPD09adWqFbt372bXrl3OczZp0oQLFy6wIdHlTjVq1MDX19flvShTpgz58uVj5syZzraCBQtSpkwZ5s+fz7Vr1wDImTMnNWrUYPXq1Zw5cwYAf39/mjRpwtatWzlw4IDz8a1ateLw4cNs3brV2Va/fn2ioqKcV0kAVK5cmaxZszI/UU264sWLU6xYMWbOnEncjQ+NYWFhVKpUiaVLlxIREQFAlixZqFu3Lhs2bOD48eOAuWqjZcuW7Nq1i927dzvPea/G8vgYBfeN5QBZs2bVWK6xPNmxHHD7WH7hwgWX90JjucbyxGN5/NjmzrHcCp/LQWN5imP5iRPU6d2brNHREB7OjjfeYG+i//ORkS149lkvwMbDD++nRo1tnD+fdmO53W5n8eLFGf5zucZy647l8Z9HUzuWv/KKB4GBzZg+3Zt2z2TmlZcG8X/h/hSdOBGGDGFlYCDnypcH0tfn8rsZyy9fvszVq1e5dOkS169fJyAgAE9PT5dko5+fH35+fs5/fzCfMQMCArh8+bLz/fH09CQoKIjIyEjn/yWbzUZwcDDXrl1zjrsAmTNnJjY21hnjAJkyZQLgypUrzjZ/f3+8vb1dJhr6+vri7+9PRESEczz19vYmMDCQK1euOGPXw8ODzJkzc/XqVZcr0bNkycL169ed7yOY/992u905/oD5XeDh4XFH74WXl5fz9cQfe7fvRUBAAF5eXnf0XsT/29zpe+Hp6YndbmfRokXOcyYeyxP3/VZsjvheplMXL14kf/78fPnll/j7+9OtWzeXf0wwv/gaNmzIJ598wosvvsihQ4dcfgFfvXqVwMBAZs6cScuWLZN9nqioKJfzXrp0ibx58xIREUHmzJnvzYuzkGnTptGmTRt3d0MkRYpRsTrFqFidYlSsTjEqqXLuHHz8sal74OvrbJ4xA9q2hdhYePZZ+OknSOurcBWjYnV3EqOxsaYk9C+/mPuffAJvPzQWdu9OKAydgVy/fp0DBw5QsGBB/Pz83N2dB87FixeTTMRMj/4tTi5dukRwcPC/5hTTZXmExLJkyUKxYsXYu3cvuXPnJjo62iWDD3Dq1Cly584NmG9DT9204mH8/fhjkuPr60vmzJldtoykZMmS7u6CyC0pRsXqFKNidYpRsTrFqKQo8Yyl7NnNKmOJErYLF0J4uEk+dewIw4enfcIWFKNifXcSo15e5kuO//zH3P/Pf6D330/i6D8g4aATJyDRDGSRO1W+fHmeeeYZ5/3Fixdjs9lYvHix2/p0swIFCrj08V5K90nbK1eusG/fPvLkyUPlypXx9vZ2ucRo165dHD58mJo1awJmKv2WLVucl0gAzJs3j8yZM1OqVKn73v/0okiRIu7ugsgtKUbF6hSjYnWKUbE6xagk68gRKF3arC6WjJUr4ZFHICrK/Bw9Gjw9701XFKNidXcaozYbDBkCn35q7n/+OTz3nPkihOvXoV07aNHC1JBO3xdzZ3gjR47EZrM5Nz8/P4oVK0bPnj2TTIC8F2yJapDfjZkzZzLgAZgJnu6Stm+99RZLlizh4MGDrFy5knbt2uHp6UmnTp0IDg7mueeeo1evXixatIgNGzbQrVs3atasSY0aNQBT06lUqVI89dRTbN68mTlz5vD+++/zyiuv4Jvo21hxNX36dHd3QeSWFKNidYpRsTrFqFidYlSSOH0amjaFgwfhm2/gRg3PeBs3mnWTIiPNYePHg7f3veuOYlSs7m5jtHdvUybBwwNGjIDHH4frUTYoU8Ys/vfWW9C1q0nkSro2aNAgfv31V4YNG0atWrX4/vvvqVmzZqprsd6p+Hru8erVq8e1a9eoV6/ebZ1n5syZya5Lld6ku4XIjh49SqdOnTh37hw5c+akTp06rF69mpw5cwLw1Vdf4eHhQXh4OFFRUTRv3pzvEn3r6unpyfTp0+nRowc1a9YkMDCQrl27MmjQIHe9pHQhnZc+lgxAMSpWpxgVq1OMitUpRsXFxYvQvDns2gX58plLs/39nbu3bYNmzSAiAurWhSlT4F6Xn1SMitWlRYw++yxky2ZKjUyZAi3b+jJ1yk9kLl8e3ngDfv0Vdu6EyZMhLOzuO/2gGzDATP/v2zfpvsGDIS7OLbWDW7ZsSZUqVQB4/vnnyZ49O19++f/s3Xd4FGXXx/HvpkMICYQk9N57771XRcCKUmyIiKLPY8EH6Ypd7IgFUFGUVxTpvfciSO9NkA4BEkjbff+4ySYLCYSQZCfJ73Nde2V3Znb23uUw2Zy555wPmT59Og8//PBN20dERODv75/m4/Dw8MjWtYMz3UzbKVOmcOLECaKiovjnn3+YMmUKpUqVcq738/Pj888/5/z580RERDBt2rSbatUWK1aM2bNnExkZyZkzZ3j//ffx8sp0+WsREREREZHsJyICOneGLVsgNNQkbIsUca7evx9atzY9yWrXhpkzIWdO9w1XJKvp2hXmzIGAAFi6FFq0tHH6wYEwb57J6G7YAHXqwNq17h6q9Xl6wtChJkGb2KhRZnl61XO5Qy1btgTg0KFD9OnTh1y5cnHgwAE6duxIQEAAPXv2BMxM2bFjx1KpUiX8/PwICwujX79+XLhwwWV/DoeD0aNHU7hwYXLmzEmLFi3YsWPHTa+bXE3bdevW0bFjR/LkyYO/vz9Vq1bl448/BqBPnz58/vnnAC6lHuKl9RjTkzKVkiJFixZ19xBEbkkxKlanGBWrU4yK1SlGBTDFabt1g1WrICjIJGzLlnWuPnoUWrWCkyehShWTQ8qoHtKKUbG6tIzRFi1MwrZ9e1OKpHFjWLCgFcU2bDAFpHfsgOeeg/Xr06fznxVFRCS/ztPTdbp//LYvvQTR0SZBGx0Nr70G77xjkrYjR5oZuLfar4eHy1UGREamy1mqAwcOABAcHAxAbGws7dq1o3Hjxrz//vvkvP6a/fr1Y+LEifTt25fnn3+eQ4cO8dlnn/HXX3+xatUqvK/XqBk6dCijR4+mY8eOdOzYkc2bN9O2bVuio6NvO5YFCxbQuXNnChQowAsvvED+/PnZtWsXM2fO5IUXXqBfv36cOHGCBQsW8MMPP9z0/IwYY5pxSKqEh4c7AEd4eLi7hyIiIiIiIpI9TJ7scIDDkTOnw7F6tcuqEyccjtKlzeqyZR2OkyfdNEaRbGTPHoejaFHz/65QIYdj+3aHw3HpksPRp4/DsX+/u4eX5q5everYuXOn4+rVqzevNG3Ykr517Oi6bc6ct95+5MiEbfPlS3672rVd91us2F29vwkTJjgAx8KFCx1nzpxxHDt2zDFlyhRHcHCwI0eOHI5//vnH0bt3bwfgeO2111yeu2LFCgfgmDx5ssvyuXPnuiw/ffq0w8fHx9GpUyeH3W53bvf66687AEfv3r2dy5YsWeIAHEuWLHE4HA5HbGyso0SJEo5ixYo5Lly44PI6ifc1YMAAR1Ipz/QYY1JuGSeOlOcUs8npDrlbN05FF7EaxahYnWJUrE4xKlanGBUAHnnEzEL74w9o0MC5+OxZ02xs/34oXhwWLYKwsIwdmmJUrC49YrRsWTPxvWJFOH7c1JBeuyPAdCpLVMqS336D8+fT/PWzJJst6Rq3Gah169aEhIRQpEgRHnroIXLlysXvv/9OoUR1ivv37+/ynKlTpxIYGEibNm04e/as81arVi1y5crFkiVLAFi4cCHR0dEMHDjQpWzBoEGDbjuuv/76i0OHDjFo0CCCgoJc1iXeV3IyYoxpSeURJEUuX77s7iGI3JJiVKxOMSpWpxgVq1OMZmMOB8TEgI+PefzKKy6rw8NNT7IdO6BgQVi4EAoXzvhhKkbF6tIrRgsXhuXLoVMnWLfOlCiZNs38vwRg7lx44AEoWRKmTzcZ3qzoypXk191Ym/b0adfHb78No0eb41x0tCmPEJ+4PXw4+f3eWHpi584UD/dWPv/8c8qWLYuXlxdhYWGUK1cOj0Sv5eXlReEbDrT79u0jPDyc0NDQJPd5+vp7PnLkCABlypRxWR8SEnJTIvZG8WUaKleufEfvJy3HmCdPnlS9dmooaSsiIiIiIiLWNXo0LF4Mf/5pOh8lEhEBHTuampr58pmEbeLJfSKSMYKDzf+/7t1h/nzo0gV++AEefBAoUMA0C9y/H+rXh8mTzQZZjb9/6rYdNcoc5+Jr2MY3IQPz+E72m0b1bOvWrUvt2rWTXe/r6+uSxAXT4Cs0NJTJkycn+ZyQkJA0GdvdyAxjTExJW0mRvHnzunsIIrekGBWrU4yK1SlGxeoUo9nUxx8nJC9mzDDlEa67dg3uvRdWr07oSVahgnuGCYpRsb70jtFcucx/08ceg19/hYcfNhUR+vevBhs2wP33w7Jl5j/u6NEweLApBZCdxSdo4xO2kPAzceI2EyhVqhQLFy6kUaNG5EjcHO0GxYoVA8ys15IlSzqXnzlzhosXL972NQC2b99O69atk90uuVIJaTHGCxcu3HKMaUk1bSVFGjVq5O4hiNySYlSsTjEqVqcYFatTjGZDEydCfP3AESNcErbR0dCjh6ldmysXzJkD1au7Y5AJFKNidRkRoz4+8NNP8MwzprLJs8+a/KwjX4g5s/Lss2bF//4HDz1kpstnZ3FxrgnbeG+8YZbHxblnXKnwwAMPEBcXx6hRo25aFxsb60zItm7dGm9vbz799FMcDodzm7Fjx972NWrWrEmJEiUYO3bsTQnexPvyvz47+cZtMmKMaUkzbSVFNmzYQJ06ddw9DJFkKUbF6hSjYnWKUbE6xWg2M20aPPGEuf/SSy4Jjbg4ePRRmDUL/PzMzL769d00zkQUo2J1GRWjnp7wxRcQEpJQmvXsWfjwQ288Pv8cqlWDAQPMdNx77oGePdN9TJY1fHjy6zLJDNt4zZo1o1+/fowZM4YtW7bQtm1bvL292bdvH1OnTuXjjz+mR48ehISE8N///pcxY8bQuXNnOnbsyF9//cWcOXMIDg6+5Wt4eHjw5Zdf0qVLF6pXr07fvn0pUKAAu3fvZseOHcybNw+AWrVqAfD888/Trl07PD09eeihh9JkjPny5Uv3zzKekraSIidPnnT3EERuSTEqVqcYFatTjIrVKUazkfnzzQw8u90kbt9/33kJtd0OTz4JU6eCt7fJ7TZv7t7hxlOMitVlZIzabGaiaHCwmTD/8cdw7hx89x14P/20qWUyc6bLDHrJ/MaNG0etWrX46quveP311/Hy8qJ48eI8+uijLjO9R48ejZ+fH+PGjWPJkiXUq1eP+fPn06FDh9u+Rrt27ViyZAkjRozggw8+wG63U6pUKZ566innNt26dWPgwIFMmTKFH3/8EYfDwUMPPZQmY+zUqVMafmK3ZnMknucrKXbp0iUCAwMJDw8nd+7c7h5OupsxYwZdsmKhcMkyFKNidYpRsTrFqFidYjSbiIqC0qXhn39M/cuff3Z2XXc44LnnzAw+T08zSa9bNzePNxHFqFidu2L0xx+hTx8zS75TJ/N/96Z+WRcumOnzjz6a4eO7E9euXePQoUOUKFECPz8/dw8ny7l48SJBQUHuHsZdu12cpDSnqJq2kiI+Pj7uHoLILSlGxeoUo2J1ilGxOsVoNuHrC7NnQ+/eJtOTKGH76qsmYWuzmXK3VkrYgmJUrM9dMfroozB9uilnMmsWtG0LLqVG4+JM17LHHjM1b2Ni3DJOcb/kGohlV5ppm0rZbaatiIiIiIhIuomLcyZokxLfYB3gq6/g6aczaFwikmZWroTOnSE8HKpWhblzoUABzFmZt982zckcDmjWzNRACQlx95Bvopm2khKaaSsZateuXe4egsgtKUbF6hSjYnWKUbE6xWgWdvSoaUy0bFmSqz/8MCFh++GH1k3YKkbF6twdo40bw/LlkD8//P23eXzwIGb6/ODBZjpuQIA5FtSpA1u3unW8kvGuXr3q7iFYipK2kiL79+939xBEbkkxKlanGBWrU4yK1SlGs6hTp6BNG9ixA1580XQaS+Srr+A//zH3R440m1iVYlSszgoxWrWqmXFbsqRJ2DZqZBK4AHTpAmvXQqlScOQINGwIv/3m1vFKxoqKinL3ECxFSVsRERERERHJeBcuQLt2sHcvFCsGf/4JHgl/ov7wA/Tvb+6/+ioMGeKmcYpImipVyiRuq1SBkyehaVPzGICKFWH9enMyJzIS/vtf0OxLyaaUtBUREREREZGMFRFh2shv3QphYbBgARQu7Fz922+m27zDAQMGwJgx5gpqEckaChQwVRAaNTI1btu2NU3KAMib1zQkfOUV+P13yJHDrWNNitpDya2kVXyoEVkqZbdGZNHR0eqGKpamGBWrU4yK1SlGxeoUo1lIVJS5DHrBAggKMpmbqlWdq+fMgXvvNQ3k+/SBb791mYBrWYpRsTorxmhkJNx/v8nRenrCxInw6KPJbPz776b+dcmSGTlEF3Fxcezdu5fQ0FCCg4PdNo6sym6345EZDvi3cfbsWc6ePUuZMmXwTKLJZkpzil7pOUjJOk6dOkWRIkXcPQyRZClGxeoUo2J1ilGxOsVoFvLRRyZh6+9vMrSJErZLl0K3biZh+8AD8M03mSNhC4pRsT4rxmjOnPDHH/D44/Djj/DYY3D+PDz//A0brl0LDz0EuXLB1KnQsqU7hounpydBQUGcPn0agJw5c2LTZQBpxoonFlLK4XAQGxvLpUuXuHTpEkFBQUkmbO+EkraSIlu2bLHcwV0kMcWoWJ1iVKxOMSpWpxjNQl56yTQe69MH6td3Ll6zBjp3hmvXzETcH380M+8yC8WoWJ1VY9TbGyZNMlURPvkEXngBzp6FESMSlUUpUsTMst2wwdRS+OgjeO45t9RNyZ8/P4AzcStpJzIykpw5c7p7GHfF09OTAgUKEBgYeNf7UtJWRERERERE0ld8VT6bDXx8TJexRP76Czp0MKVuW7WCX381iRwRyR48PGDsWAgJgTfegFGj4MwZ+Oyz6ydvChWC5cvh6afN8eP5501N7M8/B1/fDB2rzWajQIEChIaGEhMTk6GvndUtWbKEFi1auHsYqebl5YWnp2eazb5W0lZERERERETS14gR5prnsWNvqnewa5eZOBcebpoSTZ8Ofn7uGaaIuI/NBkOGQHCwaUA4bhxcuADff2/O9eDnZ6bkVqtmmpR9+605gPz2G1yf/ZqRPD097/ryd3EVGxuLn34BOKkRWSplt0Zk58+fJ2/evO4ehkiyFKNidYpRsTrFqFidYjQT++gjUxIBYP58aNPGuerAAWjSBP79F2rVgkWLIA2uKHULxahYXWaK0V9/NQ3JYmLMSZ1p00wZbKd58+DBB83Znvfeg//+121jlbSTmWL0bqQ0p5hJSrqLiIiIiIhIpvPddwkJ29GjXRK2x46ZUgj//guVK5scTGZN2IpI2nrgAZg50zQqmz/fHCvOnUu0Qbt2sH69SdbGH2NEshglbSVFVq1a5e4hiNySYlSsTjEqVqcYFatTjGZCU6fCU0+Z+//9L7z+unPVyZMmCXPkCJQuDQsWmEuiMzPFqFhdZovRtm3N7Ps8eWDdOmjaFI4fT7RB2bJmlm18yZXISPj4Y4iLc8t45e5lthhNb0raioiIiIiISNqaOxd69gS7HZ58Et5919nl/dw5M+F23z4oWtQkZdxQjlJEMoH69WHFCihYEHbuNHWv9+5NZuOnnoJBg6BLF7h4MQNHKZI+lLQVERERERGRtHPuHNx/vylG+eCDppvQ9YRteDi0bw/bt0OBAiZhW7Som8crIpZWqRKsWgVlypjZ+Y0bw+bNSWzYubNpVjZnjsn2JpvdFckclLSVFKlevbq7hyByS4pRsTrFqFidYlSsTjGaiQQHw8SJcN99pu379e7qEREmp7Jxo9lk4UJTGiGrUIyK1WXmGC1eHFauhBo14MwZaN4cli69YaOHHzYbFS4Me/ZA3bpm1r9kGpk5RtODzeFwONw9iMwopZ3esoro6Gh8fHzcPQyRZClGxeoUo2J1ilGxOsVoJuRwOGfYXrsG99xjatcGBsLixVCzppvHl8YUo2J1WSFGL10yx5Jly8DXF6ZMga5db9jo1Cno3t1Mz/XwgHfegf/8x3k8EuvKCjGaEinNKWqmraTIvHnz3D0EkVtSjIrVKUbF6hSjYnWKUYs7csR0Fjt6NGHZ9QRJfJWEBQvA399cuZzVEragGBXrywoxmju3mTzbtStERZnc7IQJN2wUFmZqrzz5pKmr/c47ZnquWF5WiNG0pKStiIiIiIiIpN7Jk9C6tZk++/TTLqvi4uCxx+DPP02pyRkzoEEDN41TRLIEPz+YOhX69jU52ccfh/ffv2EjX18YPx4+/RR++w1CQ90yVpG74eXuAYiIiIiIiEgmdeECtG0L+/ebopPffutcZbebZu6//ALe3iZv0qKF+4YqIlmHl5c53OTLB++9By+/DGfPwpgxiaog2Gzw3HOuT5w9G/LmNY3KRCxOM20lRUpnpQ4BkiUpRsXqFKNidYpRsTrFqAVduQIdO8K2bZA/v+ksVqgQYMrZDhpkLlv28ICffjKbZmWKUbG6rBajNhu8+66pfgDm51NPQWxsMk/YtcvUamnWzDRLFMvJajF6tzJ10vbtt9/GZrMxaNAg57Jr164xYMAAgoODyZUrF927d+fUqVMuzzt69CidOnUiZ86chIaG8vLLLxOb7P9qAahQoYK7hyByS4pRsTrFqFidYlSsTjFqMdeumaKSa9dCnjymYG2pUs7V//ufuSoZTOK2Rw/3DDMjKUbF6rJqjL7yCnzzjTlB9O238MAD5hB1kyJFoE0biI42tRUGDbpFhlfcIavGaGpl2qTthg0b+Oqrr6hatarL8hdffJEZM2YwdepUli1bxokTJ+jWrZtzfVxcHJ06dSI6OprVq1czadIkJk6cyNChQzP6LWQqKgYtVqcYFatTjIrVKUbF6hSjFvPqq6bRT65cpitQ5crOVW++aS5RBvjyS+jVy01jzGCKUbG6rByjTzxh6tz6+MDvv5uZ/Zcu3bBRrlzwf/8Hw4aZxx9/DB06wPnzGT5eSVpWjtHUyJRJ2ytXrtCzZ0++/vpr8uTJ41weHh7Ot99+y4cffkjLli2pVasWEyZMYPXq1axduxaA+fPns3PnTn788UeqV69Ohw4dGDVqFJ9//jnR0dHuekuWp89GrE4xKlanGBWrU4yK1SlGLWbwYKhb13QYq1vXuXjsWBgyxNx//3145hn3DM8dFKNidVk9Rrt1gzlzTG52yRJo2RLOnLlhIw8PGD7cJG/9/U1Zl7p1YccOdwxZbpDVY/ROZcqk7YABA+jUqROtW7d2Wb5p0yZiYmJclpcvX56iRYuyZs0aANasWUOVKlUICwtzbtOuXTsuXbrEjlv8J42KiuLSpUsuNxERERERkWwpf35Ys8als9jXX8OLL5r7w4fDf/7jnqGJSPbVsqVJ2ObLB5s2QePGcPRoEht27w6rV5sGigcOmDouIhbj5e4B3KkpU6awefNmNmzYcNO6kydP4uPjQ1BQkMvysLAwTp486dwmccI2fn38uuSMGTOGESNG3LR8zpw55MyZE4A2bdpw7tw5Nm/e7FzfoEEDvLy8WLFihXNZ1apVKVSoEHPmzHEuK1myJJUqVWLBggVcu158JTQ0lHr16rFmzRrOnj0LQM6cOWnVqhXbtm3j8OHDzud36tSJw4cPuySemzVrxrVr11i3bp1zWe3atQkMDGTRokXOZeXLl6dMmTLMmjULu90OQJEiRahevTpLly7l8uXL2O12Vq5cSePGjdm4cSP//vsvAN7e3rRv357du3ezb98+5z7btm3LmTNn+Ouvv5zLGjZsiIeHBytXrnT5LAoWLMjcuXOdy0qVKkXFihWZP38+UVFRgPk3qlu3LqtXr+bcuXMA+Pv707JlS7Zu3crRREfhLl26cODAAXbu3Olc1qJFCyIiIli/fr1zWZ06dQgICGDx4sXOZRUqVKB06dLMnDkTh8MBQNGiRalWrZrzswDImzcvjRo1YsOGDc648fHxoV27duzatYv9+/c799muXTtOnTrFli1bnMsaNWoEwKpVq5zLqlevTlhYmMvlAKVLl6ZChQrMmzfPecYpf/781KlTh1WrVnH++mUcAQEBNG/e3OWzsNlsdO7cmf3797Nr1y7nPlu2bMnly5dd/g/VrVsXf39/lixZ4lxWsWJFSpUqxYwZM5zL4j+LxYsXExERAUBwcDANGzZk/fr1zvrRvr6+tG3blp07d3LgwAHn89u3b8+JEyf4+++/ncsaN26M3W5n9erVzmU1atQgJCSE+fPnO5eVKVOG8uXLM3fuXGJiYgAoUKAAtWvXZuXKldjtdmbMmOH8LLZs2cKxY8cA8PDwoFOnTuzbt4/du3c799mqVSvCw8PZuHGjc1m9evXw8/Nj2bJlzmWVKlWiePHizJo1y7msePHiVKlShUWLFhEZGQlAvnz5aNCgAevWreP06dMA+Pn50aZNG3bs2MHBgwedz+/QoQPHjx93+SyaNGlCbGys8yQTQM2aNQkODmbBggXOZWXLlqVcuXLMmTPHWY+7YMGC1KpVixUrVnDx4kUAAgMDadq0KZs3b+b48eMAeHp60rFjR/bu3cuePXuc+2zdujUXLlxg06ZNzmX169fH19fX5bOoXLkyRYsWZfbs2c5lJUqUoHLlyixcuJCrV68CEBISQv369Vm7di1nrp/ezpEjB61bt2b79u0cOnTI+fyOHTty9OhRtm/f7lzWrFkzoqKinFdJANSqVYs8efKwcOFC57Jy5cpRtmxZZs+eTVxcHACFChWiZs2aLF++nPDwcACCgoJo0qQJmzZt4sSJEwB4eXnRoUMH9uzZw969e537TK9jube3t/P/k7uO5QB58uTRsVzH8iSP5fnz53f7sfzChQsun4WO5TqWJz6We3p6Arj1WG6F7+XgvmN52Z9+wrtsWUqOGHHTsfzkyZb06+cAbNx3335q1NgFZK9jud1uZ+nSpdn+e7mO5dY9lsf/zZQdvpdPmFCeZ58tw969ULPmVUaMWEvt2jlvOpYHfvABTdetY9uDD3I40f+xrHwsB+t+L/fx8XEe67Ly9/L4Y9Xt2Bzxn1omcOzYMWrXrs2CBQuctWybN29O9erVGTt2LD/99BN9+/Z1BmG8unXr0qJFC9555x2efvppjhw54vKPFhkZib+/P7Nnz6ZDhw5JvnZUVJTLfi9dukSRIkUIDw8nd+7c6fBuRURERERELOL99+Hll0279r//dqlh+/vvcP/9EBcH/fvD55+bzURE3OnYMWjXDnbtgrx5TemERNVckhYTA+++a5qU+ftnxDAlG7p06RKBgYG3zSlmqvIImzZt4vTp09SsWRMvLy+8vLxYtmwZn3zyCV5eXoSFhREdHe08mxXv1KlT5M+fHzAZ9PizjonXx69Ljq+vL7lz53a5ZWnDh8OoUc6Hic9WMGqUWS9iIS4xKmJBilGxOsWoWJ1i1I2+/tokbAHeesslYTt3Ljz4oEnY9uoFn32WfRO2ilGxuuwWo0WKwIoVJlF7/rwpnZBocnDSXnnFFOZu3BiOHMmQcUqC7Bajt5Opkrbxlx9t2bLFeatduzY9e/Z03vf29naZlr5nzx6OHj1KgwYNADOVftu2bc5LJAAWLFhA7ty5qVixYoa/J8vy9IShQ52J2/gp4owaZZZfvzxNxCrOq+OnWJxiVKxOMSpWpxh1k19+gX79zP1XX4XXXnOuWrYM7rvPTEzr0QO+/db0+MmuFKNiddkxRoODYdEiaNMGIiKgY0fTgyxZ3btDaChs2QJ16sDy5Rk1VCF7xuitpGtN27i4OKZOncqSJUs4ffo0I0eOpEqVKoSHh7No0SIaNWp0U33ZWwkICKByorO6YGpuBAcHO5c/8cQTvPTSS+TNm5fcuXMzcOBAGjRoQP369QFTB6RixYo89thjvPvuu5w8eZIhQ4YwYMAAfH190+7NZ3ZvvGF+Dh1qflavnpCwHTkyYb2IiIiIiGRNs2fDo4+Cw2ESt2PGOFetXw+dO8O1a9CpE0yeDF6ZrmOKiGQHuXLBjBnw2GMwdSo88AB8+WXC+SgXjRvDhg3mjNTmzdCqFXz6KTzzTIaPWyTdfq1evHiR9u3bs379enLlykVERAQDBw4EIFeuXDz//PP06tWLt956K01f96OPPsLDw4Pu3bsTFRVFu3bt+OKLL5zrPT09mTlzJv3796dBgwb4+/vTu3dvRo4cmabjyBISJW47eXqaa56UsBWLCggIcPcQRG5JMSpWpxgVq1OMZrB9+8yMs9hYePhhl0K1W7eaOpFXrpjLjadOBR8fN4/XAhSjYnXZOUZ9feHnn01t26++MjnYc+dg8OAkSroULWrqKjzxBEyZYop1b90KH3+sg106y84xmpR0a0T2zDPPMHnyZKZNm0aNGjUIDQ1l4cKFtGzZEoBBgwaxdOlSl25vmUlKiwZnCV5eJmFrs8H+/VCypLtHJCIiIiIi6cnhMJM1tmwxnca8vQHYvRuaNoUzZ6BBA5g/38xiExHJDOIPbW++aR6/+KLps5hkaReHA955B15/3TQl27QJypbN0PFK1uT2RmR//PEHAwcOpE2bNtiSqERftmxZDh8+nF4vL2ll1CiIi8MB5oBVvrw5y263u3tkIi62bt3q7iGI3JJiVKxOMSpWpxjNYDYbjB4Nf/zhTNgePGiuFD5zBmrUMNUTlLBNoBgVq1OMJhzaPvzQPP7oI+jTx9TmTnLj116DP/+En35SwjYDKEZdpVvSNjw8nBIlSiS7PiYmhtjY2PR6eUkLiWrYLh4/HooXN0ey556D1q1BSXexkKNHj7p7CCK3pBgVq1OMitUpRjPAoUPmcuDIyIRl1wvV/vOP+RPgxAmoWNHMsA0Kcs8wrUoxKlanGE3w4oswaZLpsf7DD9CtG1y9mszGnTtDly4Jj5cvN3VhJM0pRl2lW9K2VKlSbN68Odn18+fPp2LFiun18nK3bmg6Fpk/Pxw4YLoMACxZApUrw7Rp7h2niIiIiIjcvX//Ne3Vv/sOXnjBZdWpUyZhe+gQlCoFCxdCvnxuGqeISBrp1ctUf/Hzg5kzTa3uixdv86QTJ6BHD9PN7I03dBWypKt0S9o++eSTfPfdd/zyyy/El8212WxERUXxv//9j7lz59IvyVZ9Ygk3NB2z2WymyMvMmTBokCnMHRNjyiWIWEBSZVhErEQxKlanGBWrU4ymo/PnoW1bM0mjRAkYMeKmVXv2QJEisGgRFCjgxrFamGJUrE4xerMuXcyVA7lzm95jzZvDyZO3eEJoKDz2mLk/erSZonv5ckYMNVtQjLpKt0ZkDoeDp59+mm+//ZagoCAuXrxIWFgY586dIzY2ln79+vHll1+mx0tniGzViCwpdjts3gy1aycs27DBPNZ/MhERERGRzOHyZTONdv16k41dudLZePjSJTP5dv16CAszCY0yZdw8XhGRdLBlC7Rvb64sKFUKFiww57CS9f338PTTEBUFlSrB9OnmiSIp4PZGZDabja+//prly5fTq1cvOnToQPXq1Xn66adZunRppk7YZkf79+93XeDh4ZqwXb8e6tc31xMcO5axgxMhiRgVsRjFqFidYlSsTjGaDq5dg65dzXf5vHlNluJ6wjYy0sxAW78egoNNSQQlbG9NMSpWpxhNXvXqsGqVSdQeOACNGsG2bbd4Qq9esGyZOdm1YwfUrWsuRZC7ohh1lW5J23iNGzdm7NixzJo1izlz5vDZZ5/RtGnT9H5ZSWO7du269QZ794KPj/miV7kyfPstpM8kbpEk3TZGRdxMMSpWpxgVq1OMpoMnn4TFiyFXLpg718wWw0wcu+8+02snd26YN898xZdbU4yK1SlGb61UKZO4rVLFlPlu2hRWr77FE+rVg40bTcL2/HmYMCHDxppVKUZdpXvSVrKJRx811xM0aGCuo3rySejY0bSZFRERERER63nhBShUCGbMgDp1ANO24sEHTY3HnDlh9myoVcvN4xQRySAFCpgJtA0bmqZkrVub42CyChY0Txg+HMaPz6BRSnaRbknbEiVKULJkyVveSqneR9ZSrpwpdPXee+Dra87WV64MP/3k7pGJiIiIiMiN6tSB/ftN5x1ML+I+fUxpRl9f+PNPc4mwiEh2kiePOXHVoQNcvQr33nubtIafHwwbZs50gekBNGyYma4rchfSrRFZnz59bur6FhcXx5EjR1i1ahWVK1emRo0aTMik08ezWyOyiIgI/P39U/6E3bvNN7516+CLL6B//3QbmwikIkZFMphiVKxOMSpWpxhNI2+9ZbqLXZ9ZG8/hMD11vvkGvLzg99+hc2c3jTGTUoyK1SlG70xMjElrxCdsP/kEBg5MwRPHjIHXXzdXMvz++03HW0ledonRlOYUvdJrABMnTkx23datW2nXrh09e/ZMr5eXNHb58uU7+49TvrzpPPvLL/DwwwnLT540rWdvSOiL3K07jlGRDKYYFatTjIrVKUbTwLvvwv/+B2+/bXpS5M8PmITtoEEmYevhAZMnK2GbGopRsTrF6J3x9oYffjB9Gj/7DJ5/Hs6dM5Nob5nS6NHDPHHXLmjSxBxcH300w8admSlGXbmlpm21atXo168fr776qjteXu7AtGlQrRoULRpCtWrmcYp5eUHPnuabH8Dly1C/vrm2QJcJSBrbsGGDu4cgckuKUbE6xahYnWL0Ln31FcT//TVkiDNhC/DGG2YGGZh+wg884IbxZQGKUbE6xeid8/Awx8cRI8zjESPMbFu7/RZPKlMG1q41Z7+iouCxx+Dll00NGrklxagrtzUiCwsLY+fOne56eUmBadOge3fYtg1iYjzZts08vqPEbWKrVsGJE6bRQaVK5hR++lTnEBERERGReD//nFCubPBgeOUV56oxY+DNN839zz4zlwKLiEgCmw2GDoXPPzf3P//cTJyNjr7Fk3Lnhj/+MMdcgPffN0ncixczYMSSVbglaXvu3Dm+/fZbChcu7I6XlxQaMcIckOLzqg6HeTxyZCp32L49bNoENWvChQvmKHfffaZkgoiIiIiIpL2ZM6FXL/Nl/tlnEzK0mNljr79u7r/zDgwY4KYxiohkAs8+a+rbenmZc2H33gsREbd4gqenqSM+ZQrkyAGLF5vSNCIplG6NyFq2bJnk8osXL7J7926io6P54YcfeDhxvdNMJDs0IsuRA65du3m5n5/poJhqMTHmW+HIkeZ+fIGYhx5SrVtJtVOnThEWFubuYYgkSzEqVqcYFatTjKbChg3QtKn5Uv/oozBpkrN02bffwpNPms2GDk249FdSTzEqVqcYTRtz55qrkCMjoUEDc24sb97bPGnzZti3Dx58MEPGmFlllxhNaU4x3Wba2u12HA6Hyw2gRIkSPPfcc2zfvj3TJmyzi7Jlk8+h/vnnXVQ28PY2dbQ2boTq1eH8eZg6NbXDFAFQsXKxPMWoWJ1iVKxOMZoKlStDy5Zwzz3w3XfOhO3PP8NTT5lNXnoJhg933xCzEsWoWJ1iNG20bw8LF0KePLBmjTk3dvz4bZ5Us6ZrwnbrVvjgA5WMvIFi1FW6zbTN6rLDTNv4mraJSyQkVru2OSPfocNdTJCNiTG1XR5/HOLPpkRHg49Pqsct2dOMGTPo0qWLu4chkizFqFidYlSsTjGaStHRpmOOnx8A06eb7/hxcdCvH3z5pS52SyuKUbE6xWja2r4d2rY1fdaLF4f5800Pstu6fBmqVIEjR0zz9q+/Npc6S7aJUbfPtJXMr1s3+O03qFoVvL3jqFbNXFE1eDD4+5uJsp06QcOGsGBBKk8QeXubHSae/t6nj2lZe+ZMWr0VEREREZHs4eBBePvthC/nPj7OhO38+eZrdlycaWb+xRdK2IqIpFblyqbfeunScPgwNG4Mf/2VgifmygUvv2xq3k6ebKbq/vNPeg9XMiGvtNrR999/n6rn9erVK62GIOmgWzdzmzFjtsvZjhdfhHffNV0T1641Z5caNzZlalu0uIsX3LPHlEqIjYWlS82p/+7d7/p9iIiIiIhkeSdOQJs2JnEL8NprzlUrVkDXrmbibbduLtUSREQklUqUgJUrTcmELVugeXOYMcPkYZNls5nOj5UqQY8eZkZc7drmcueGDTNo5JIZpFl5BI9U/Ma32WzExcWlxctnuOxQHiGxAwcOUKpUqZuWnzxpeop9+SVERZllLVqYsglNmqTyxTZvNrNtt20zjx980DQqy5cvlTuU7CC5GBWxCsWoWJ1iVKxOMXob585Bs2awYweUKmWytAUKAKYfWatW5orcDh3gjz9UjSw9KEbF6hSj6Sc83JQPX77cXNzwyy/m8W0dOgT33mvyHz4+Jrny+OPpPl6ryi4xmtKcYpolbY8cOZKq5xUrViwtXj7DZbek7e2cOAFjxsD48ebsPZiT/CNGmG6KdywqCkaNMpd2xcVBaCiMGwf33Zem4xYRERERyfQuXTJZ2Y0boVAhM+2reHEA/v7bzPy6cMH8nD1bpRNFRNLD1avw0EOmcbunJ3z7LfTunYInXrliNpw2zVzGPGeOLoXI4jK8pm2xYsVSdZPMYcaMGbdcX7AgfPop7NtnGhp4eZk6tw0bQseO5uz+HfH1hdGjTe2FihXh9GkYOBAiI1P/JiRLu12MiribYlSsTjEqVqcYTcbVq2Y618aNEBxsvoRfT9ju2WMmUly4APXrm0SCErbpRzEqVqcYTV85cpi+QL17m7lnffrAhx+m4Im5cpkykR9/DFOmZOuErWLUVfaNBEkXRYuaCbH79sETT5izS3PmQN26Zsb/li13uMPatU25hMGDTUfFnDnTY9giIiIiIpmPw2GmdS1bBgEBMG8eVKgAmCtuW7Uycx+qVzczbAMC3DtcEZGszsvL1Az/z3/M4//8B15/PQWN2z084PnnIU8e89jhgOHDYfv29ByuWFy6Jm1PnjzJm2++Sffu3WndujUtW7Z0ubVq1So9X17cqHhx+OYbc3a/d29z/PnzT6hRw/QViy9XmyK+vvDWW6YAV7yJE6FXLzNtQEREREQkO7LZzJfrXLlg5kyoVQuA48ehdWvzs0IFmD8/IQ8gIiLpy8MD3nvPVHsEU0qyXz8z+zbFJk5MqDf5xx/pMErJDNItafv3339TsWJFRo8ezYEDB1iyZAlnzpxh3759LF26lGPHjpFG5XQlAxQtWjRVzytVyhxrdu6ERx4x3yunTYOqVU1/sV27UrHTK1fM6aoffjDdFmfOTNXYJGtJbYyKZBTFqFidYlSsTjGajF69zLTa663Kz5wxCduDB6FkSVMtISTEzWPMJhSjYnWK0Yxjs8Grr5q+Px4e5sLhBx9MaOB+W126mC7vV66Y3j4jR4Ldnq5jtgLFqKs0a0R2o44dO7J9+3ZWrlxJzpw5CQ0NZeHChbRs2ZKpU6fSv39/Zs+eTd26ddPj5dOdGpGlzs6dZob/1Knmsc1mkrlDh0LZsnewo7VrTYGYPXvM4969YexYCApK0/GKiIiIiFjOJ5/AAw9A/vwuiy9cMH/jb90KhQvDihXO8rYiIuImv/1m8h7R0aZsze+/p7BcTUwMvPQSfPaZedy9u5kVlytXeg5XMkCGNyK70apVq+jXrx9FixbF43oRZfv1swL3338/PXv25OWXX06vl5c0tnjx4jTZT8WK8Ouv5ovkffeZMi2TJ5vLtvr2NTMCUqR+ffjrLzPj1maDSZOgcmVTQFeypbSKUZH0ohgVq1OMitUpRq97+2144QUzszZRk97Ll001sa1bISwMFi1SwjajKUbF6hSj7tG9u6krniuXOTa3bAlnz6bgid7epuP7+PHm/m+/QaNGcPhweg/ZbRSjrtItaWu32wkLCwMgKCgIT09Pzp8/71xfpUoVNm3alF4vL2ksIiIiTfdXtaopk7Bpk5n1b7ebE0Zly8JTT8GRIynYSY4c8P77ZgpBmTKmaFfnzrB/f5qOVTKHtI5RkbSmGBWrU4yK1SlGgS+/NA16wRRIvN6kNzLSfKdet87Url2w4A6vYpM0oRgVq1OMuk+rVrB4MQQHw8aN0KQJHDuWwic/9ZR5cmioaRC0e3e6jtWdFKOu0i1pW6JECQ4dOmRexMODEiVKsHDhQuf61atXE6RL2bO9mjVNg7J166B9e1OY+5tvTA62f3/4558U7KRRI9iyBV580Vw6ULp0eg9bRERERCRj/fgjDBhg7g8Z4mxNHhVlZnEtW2Yut503D6pUceM4RUQkSXXqwMqVpnzN7t0mlZHi/Gvjxibb+/33Jnki2UKaJm0vXLjgvN+2bVumxhcuBfr3788333xD69atadWqFZMmTeKRRx5Jy5eXdBQcHJyu+69b11Q2WLXKNE6IiYFx40wjs+efh3//vc0OcuaEDz+Ed99NWLZ3r8n8XrqUrmMXa0jvGBW5W4pRsTrFqFhdto7RP/80/RwcDnjuOdOQBoiNNXUS5841F6HNnm2SAuIe2TpGJVNQjLpf+fKwerX5eeyYycVu2JDCJxcpAo8+mvD44EH4739NsdwsQjHqKk0bkfn6+tKxY0d69uxJo0aNOHHiBFWrVsXb2xuHw8Gbb77Jb7/9hqenJ507d+b111/Hx8cnrV4+Q6kRWfpavtw0J1u2zDz28zP511dfNTW6bsvhMHW+Vq40B7bvvjPZYBERERGRzGTZMmjXzkyp7dULJkwADw/sdvNw8mTw8YGZM6FNG3cPVkREUuLsWejY0SRsc+WCP/4wJRRSLC7OXLr899+m1sL//Z8pnyCZglsakfXo0YOFCxfy4IMPUqFCBT7//HOWL1+Ow+HAZrMxZMgQ/vrrLzZu3Mjw4cMzbcI2O1q/fn2Gvl7TprBkiSnS3bAhXLsGH30EJUrAK6+koGi3zQajR0PJkub0VZs28MwzpkODZEkZHaMid0oxKlanGBWry7YxWqIEFCsGXbvCt9+ChwcOh5nQMHkyeHrC1KlK2FpBto1RyTQUo9aRL5/Jd7RqBVeumATub7/dwQ48PeGttyB3btPnp04dUzYyk1OMukrTpO3kyZM5ffo0P/74I02aNGHy5Mm0bduWQoUK8Z///IfNmzen5ctJBjp16lSGv6bNZroqrlxpanPVrQtXr8J775nvrv/7HyTqbXezZs3MWafnnjOPv/rKFPhSN8IsyR0xKnInFKNidYpRsbpsG6NFi5ovxD//DF5eOBymnO348eb78o8/wj33uHuQAtk4RiXTUIxaS0AAzJpl6pJHR8MDD8DXX9/BDjp1Mg2CypaFo0fNjLdff0238WYExairNG9EliNHDh5++GFmzJjByZMn+eKLLyhTpgxjx46lTp06lC9fntGjR3Pw4MFU7f/LL7+katWq5M6dm9y5c9OgQQPmzJnjXH/t2jUGDBhAcHAwuXLlonv37jf9ox89epROnTqRM2dOQkNDefnll4mNjb2r9y3px2aDtm1h7Vpz2VfNmuZM1FtvmeTt8OFw8WIyT/b3h08/NYna4sXhyBFzKmv27Ix7AyIiIiIid+LAAZg+PeFxSIipFwYMG2auQAPTwPehh9wwPhERSRO+vvDLL/DUU2C3w9NPw9tvm4qPKVK+fEJn96tX4cEHTbNKuz1dxy0ZI82TtonlyZOHfv36sWzZMo4ePcrbb79Nzpw5GTp0KGXKlKFhw4Z3vM/ChQvz9ttvs2nTJjZu3EjLli2599572bFjBwAvvvgiM2bMYOrUqSxbtowTJ07QrVs35/Pj4uLo1KkT0dHRrF69mkmTJjFx4kSGDh2aZu87K/L19XX3ELDZzImkjRtNvZeqVU2PsREjTPJ29Ohb9Bxr0cLMun3mGZP11fVjWY4VYlTkVhSjYnWKUbG6bBOjx4+bXgzdusG0aS6r3nkHRo0y9z/5BB5/3A3jk2RlmxiVTEsxak2enubC4MGDzePBg+Hll+8gcRsUZGa4vfyyebxwoenungkpRl2laSOylNi2bRtDhw5l+vTp2Gw24uLi7nqfefPm5b333qNHjx6EhITw008/0aNHDwB2795NhQoVWLNmDfXr12fOnDl07tyZEydOEHa9o9W4ceN49dVXOXPmTLJ1dqOiooiKinI+vnTpEkWKFFEjMjey28332GHDYOdOsyxvXnOceu45U8w7SVevmva6YK5B+OADeP55MytXRERERMRdzp41zR127YLSpU2dwvz5Afj884SqX2PGwGuvuXGcIiKSLj74AP77X3O/Tx9TLsHL6w52MGWK+T1SsGB6DE/SSEobkd3JP32qHT16lJ9++omff/6Z7du343A4aNiwIT179ryr/cbFxTF16lQiIiJo0KABmzZtIiYmhtatWzu3KV++PEWLFnUmbdesWUOVKlWcCVuAdu3a0b9/f3bs2EGNGjWSfK0xY8YwYsSIm5bPmTOHnDlzAtCmTRvOnTvnUru3QYMGeHl5sWLFCueyqlWrUqhQIZeyDiVLlqRSpUosWLCAa9euARAaGkq9evVYs2YNZ6933sqZMyetWrVi27ZtHD582Pn8Tp06cfjwYeeMY4BmzZpx7do11q1b51xWu3ZtAgMDWbRokctnVKZMGWbNmoX9+hT6IkWKUL16dZYuXcrly5dxOBzkzZuXxo0bs3HjRv79918AvL29ad++Pbt372bfvn3OfbZt25YzZ87w119/OZc1bNgQDw8PVq5c6fJZFCxYkLlz5zqXlSpViooVKzJ//nxnojwsLIy6deuyevVqzp07B4C/vz89erSkZMmt/PxzLD//XI7jx3MxeDC8914c9967m44dj+DrG0eLFi2IiIhwKWpdp04d8o4di8877xDxySdseeEFwnr0oHTp0sycOZP48xlFixalWrVqzs8CzImCRo0asWHDBk6ePAmAj48P7dq1Y9euXezfv9/5Ou3atePUqVNsSVQUvFGjRgCsWrXKuax69eqEhYUxb94857LSpUtToUIF5s2bR3R0NAD58+enTp06rFq1ivPXi/oGBATQvHlztm7dytGjRwGw2Wx07tyZ/fv3s2vXLuc+W7ZsyeXLl9mwYYNzWd26dfH392fJkiXOZRUrVqRUqVLMmDHDuSz+s1i8eDEREREABAcH07BhQ9avX+8sReLr60vbtm3ZuXMnBw4ccD6/ffv2nDhxgr///tu5rHHjxtjtdlavXu1cVqNGDUJCQpg/f75zWZkyZShfvjxz584l5vpZwwIFClC7dm1WrlzJ+fPnsdlszs9iy5YtHDt2DAAPDw86derEvn372L17t3OfrVq1Ijw8nI0bNzqX1atXDz8/P5YtW+ZcVqlSJYoXL86sWbOcy4oXL06VKlVYtGgRkZGRAOTLl48GDRqwbt06Tp8+DYCfnx9t2rRhx44dLmVhOnTowPHjx10+iyZNmhAbG8uaNWucy2rWrElwcDALFixwLitbtizlypVjzpw5ztIuBQsWpFatWqxYsYKL1+uFBAYG0rRpUzZv3szx48cB8PT0pGPHjuzdu5c9e/Y499m6dWsuXLjApk2bnMvq16+Pr6+vy2dRuXJlihYtyuxEJUZKlChB5cqVWbhwIVevXgUgJCSE+vXrs3btWs6cOQOY8jmtW7dm+/btHDp0yPn8jh07cvToUbZv3+5c1qxZM6Kioli7dq1zWa1atciTJw8LFy50LitXrhxly5Zl9uzZzpOAhQoVombNmixfvpzw8HAAgoKCaNKkCZs2beLEiRMAeHl50aFDB/bs2cPevXud+0yvY3niZe46loO5CsZqx/KWLVu6HL8AunTpwoEDB9gZf1YOkj2WBwQEsDhRvfIKFSroWH7dnRzLg4KCuHLliluP5RcuXHD5LHQs17E88bE8/v+nO4/l6fm93CsykhajR+O3axdX8+Vj1WuvcXXDBooUKcKWLdWdCdsHHthL48anAR3LwVrHcofDQe7cubP993Idy617LD99+jQ2my3bfy+3Qo4Fkv5eXqmSNxMntueJJxxMnGhj586TvPzyJrp0aZ2yY3mDBhQMCWHu9eNF6V9/JWezZhR78slMcSxP/P84K38vj3+Pt+VIJ2fOnHF8/vnnjkaNGjk8PDwcNpvNUaFCBcfo0aMdhw4duqt9//333w5/f3+Hp6enIzAw0DFr1iyHw+FwTJ482eHj43PT9nXq1HG88sorDofD4Xjqqaccbdu2dVkfERHhAByzZ89O9jWvXbvmCA8Pd96OHTvmABzh4eF39V4yiz///NPdQ7it2FiH44cfHI7SpR0OcyGBwxEW5nCMHetwXL2azJPmzXM4ihQxG9tsDsegQQ5HRESGjlvSRmaIUcneFKNidYpRsbosHaMREQ5H06bmO2m+fA7Hrl3OVVOmOBweHmbVoEEOh93uxnHKLWXpGJUsQTGaeUyf7nD4+ppjf7NmDsfFi6nYyezZZgceHg7HRx9lil8g2SVGw8PDU5RTTNOathEREfz444907NiRQoUK8dxzz3Ho0CEGDRrExo0b2blzJ//73/8oXrz4Xb1OuXLl2LJlC+vWraN///707t3bJeOfHnx9fZ3Nz+JvYi2envDoo+Zqsu++M33HTp2CQYOgVClzSVmiChdG27awbRs88YTJ844dC9WrQ6KzMyIiIiIi6SYmBu6/H5Yvh9y5Yd4801gGmDHDfL+12+HJJ+HDD02fBxERydruucf8OsidG5Ytg+bNTX7jjrRoAb17m18iL75oCqHflBQRK0vTpG1oaCi9e/dm1apVPPLII8yfP59jx47xwQcfULNmzTR7HR8fH0qXLk2tWrUYM2YM1apV4+OPPyZ//vxER0c7L0GId+rUKfJfrwWVP39+56UiidfHr5PMz8sL+vaFPXtg/HgoUgROnDA1wMqUMcuuz4I3AgNN693Zs6FQIdi3D5o0MZXARURERETSk6enmWGQIwfMmmWa5mL6yNx/P8TGwiOPwLhxStiKiGQnzZrB0qUQGgpbtkDjxpCogsPt+fnBhAnw0Ufg4QETJ5rs7/VSDGJ9adqI7N5776Vnz57cc889+Pn5pdVub6tly5YULVqUjz/+mJCQEH7++We6d+8OwJ49eyhfvvxNjcj+/fdfQkNDARg/fjwvv/wyp0+fTnGnupQWDc4qYmJi8Pb2dvcwUiUqCr79Ft580yRvwczCHToUHnvshqLeFy+aM1C//gp//22+QEumkJljVLIHxahYnWJUrC5Lx6jDYSYOlC0LmIu+2raFyEjo2tV8Nc2qbz0rydIxKlmCYjRz2rfP/E44fNj0F5s3DypXvsOdLFgADz4IFy6YnfzxB9Spkw6jvTvZJUZTmlNM05m206dP54EHHkjXhO3gwYNZvnw5hw8fZtu2bQwePJilS5fSs2dPAgMDeeKJJ3jppZdYsmQJmzZtom/fvjRo0ID69esDphB/xYoVeeyxx9i6dSvz5s1jyJAhDBgwIMUJ2+wovkB4ZuTrC88+CwcOwMcfQ1iYOdg9/jhUqAA//ADX66RDUJA5E7V7t2vC9s8/4XrxcrGmzByjkj0oRsXqFKNidVkqRh0O+PHHhMu/bDZnwnbjRujY0SRs27UzjcCzwd+vWUKWilHJkhSjmVOZMuZkXuXKZiJa06aQqEdeyrRpA+vXmyTIiRMmE2xBilFXaZq0zQinT5+mV69elCtXjlatWrFhwwbmzZtHmzZtAPjoo4/o3Lkz3bt3p2nTpuTPn59p06Y5n+/p6cnMmTPx9PSkQYMGPProo/Tq1YuRI0e66y1lCok7aWZWfn7w/PNw8CC8/z6EhMD+/dCrF1SqBD//nCh5W6RIwhOXLYN774UaNSBRl0ixlqwQo5K1KUbF6hSjYnVZKkbfestc8tW1q6k1eN327SZRe+mS+aN82jQzAUEyhywVo5IlKUYzr4IFTWqiQQMzWbZ1a5g79w53Uro0rF0L339v6u5YkGLUVaZL2n777bccPnyYqKgoTp8+zcKFC50JWwA/Pz8+//xzzp8/T0REBNOmTbupVm2xYsWYPXs2kZGRnDlzhvfffx8vl2vkJSvLmRP+8x+TvH37bcib19S/feQRqFYN/u//XL47mxkQ+fOb2bcNG8LgwSreLSIiIiKp89lnMGSIud+2rakziJn01Lo1nD8PdevCzJnme6uIiAiY3MWCBdC+vbkao0sXczXGHcmd25w0jHfypGkKdOFCmo5V0kamS9qKpJVcueDVV+HQIRg1ylRG2LHDNHyoUcOUeHE4MJcR7NgBPXuabO7bb5sGERs2uPkdiIiIiEim8v33MHCguT9sGAwaBMCRI9CqlekMXrUqzJkDAQHuG6aIiFiTvz9Mnw4PPZTQqPKLL+5ih489ZhqU1atnJqqJpaRpI7LsJLs1Irtw4QJ58uRx9zDS1cWLMHasaax46ZJZVrMmjBxp6orZbJhMbr9+cPq06fQ7apSZeStulx1iVDI3xahYnWJUrC7Tx+gff0CPHqYe1wsvmC+dNpuzPuGBA1CuHCxfbjqFS+aT6WNUsjzFaNZht5vyj59/bh6PGAFvvHE9b3Entmwx5SCPHjWzcH/6CTp1Suvhplh2iVG3NCKTrMvuUi8gawoKguHDzczb//3PzMTdvBk6d4b69U2HRse9XWHnTnj4YfOFu3BhN49a4mWHGJXMTTEqVqcYFavL1DG6cKHp2h0XB336wIcfgs3GmTPmoq4DB6BECVi0SAnbzCxTx6hkC4rRrMPDAz791Fy0AebnCy/cUOoxJapXN1cRN2liZq916WKuLnbT/E7FqCslbSVFVq9e7e4hZJi8eWH0aJO8feUVU0ts/XpTN6ZJE1i8NRjH5J9gxQp49NGEJ+7aldABWDJcdopRyZwUo2J1ilGxukwdoz4+pqNYt27w9dfg4cHFi6bp2M6dUKiQSdgWKuTugcrdyNQxKtmCYjRrsdnMxLNPPzWPP/3UVDuIibnDHYWGmpOL/fqZZO3gwaY8ZGRkWg/5thSjrpS0FUlGvnzwzjumYdmLL4KfH6xaZeqNtWgBy+2NE649OH/erKhTB/76y70DFxERERFradrUdOz+6Sfw8uLKFVN+66+/zN/KixaZmbYiIiJ36rnnYPJk8PIyv2buvTcV+VYfHxg3zhTI9fIyZRNiY9NjuHIHlLQVuY2wMHMF24EDpm+Ejw8sWwbNmpkOv6tXA3v3mtNZf/9t2v0OH65ZtyIiIiLZ2b59sG1bwuOKFcHXl6tX4Z57YM0ayJPHdAIvV859wxQRkczvkUfgzz8hRw7TzLJNG7hwIRU76t/fzLqdPt3UuBW3UtJWUqRGjRruHoLbFSwIn3xikrf9+4O3t5kV0agRdBhRn80/7IDu3c3ZqBEjTPfFrVvdPexsQzEqVqcYFatTjIrVZaoYPXbMnN1v1sw0SbguOtr0IluyxPRPmDsXqlZ14zglTWWqGJVsSTGatXXoYPKtQUFmclnTpnDiRCp21KwZlCmT8PiTT+Dbb9NqmLekGHWlpK2kSEhIiLuHYBmFC5srBvbuhSefBE9P84W7VodQulybyqExUyA42FxOUKcOjBrltiLe2YliVKxOMSpWpxgVq8s0MRrfXezoUQgJcRaqjY01JQJnzzYzoWbNMhdoSdaRaWJUsi3FaNbXsCEsXw4FCsD27dC4Mezffxc73LzZ1It88kl4/vlUFMy9M4pRV0raSorMnz/f3UOwnOLFTR+JPXtME2APD5g5y0bJwQ/St+4Owlt0NQe0vXsTat9KulGMitUpRsXqFKNidZkiRsPDTXexPXugSBFT+yAsDLsdnngC/u//TKmt3383M6Aka8kUMSrZmmI0e6hSBVauhFKlTIP1xo3v4iLgGjVM+Ucwnc7at4dz59JqqDdRjLpS0lbkLpUqBRMmwK5dZvaEzQYT54QRtGQaH9Wfwu7+HydsfPGiinmLiIiIZEWRkdC5s+kuFhJirlEtWhSHAwYMgO+/N1do/fKLyeuKiIikl5IlTeK2WjU4dcpUPFixIhU7stngjTfM2cZcuWDxYnNFceKa7ZJulLQVSSNly8KPP8KOHfDggwA2Xlr7IBUb5+WRR2DPbgf06gUNGpiNRERERCRriI42vQ1WroTAQJg/H8qWxeGAl182DbltNpO47drV3YMVEZHsIH9+WLoUmjQxF4K0bQszZ6ZyZ127mg6aJUqY6bsNGsAff6TdYCVJStpKipRJXIRabqlCBZgyBf7+G7p1M+Vsf/4ZOlQ8QsS8FbBxI9SsCW+/rVm3aUgxKlanGBWrU4yK1Vk6RqOj4epVyJnTFKutXh2AkSPhgw/MJuPHm+7eknVZOkZFUIxmR0FBMG8edOkC166Z3Ov336dyZ5Urw4YN0LIlRESYpptpTDHqyuZwqENSaly6dInAwEDCw8PJnTu3u4cjFvbXX6YEzJ9/QgFOMJ5+dOb66a26dWHiRJPpFREREZHM6+pV0/WlTh0A3n/fzLIFGDsWXnjBfUMTEZHsLSbG9BKLT9h+9BEMGpTKncXGwtSp8NBD6t+TSinNKWqmraTI3Llz3T2ETKtGDZg+3ZyQqtGxIF34k95M5CKBsH49jho14L33IC7O3UPN1BSjYnWKUbE6xahYneVi1OGARYsSHufI4UzYfvllQsL2zTeVsM0uLBejIjdQjGZf3t6mF8+LL5rHL74IQ4aYX2V3zMsLHn44IWF78SL06GHKJtwlxagrJW0lRWJiYtw9hEyvdm1ztdzq1Tb+bdObSuxgNh2wRUVxZvQ4/j10zd1DzNQUo2J1ilGxOsWoWJ3lYnT0aGjdGgYPdlk8aRI8+6y5P3gwvP66G8YmbmG5GBW5gWI0e/PwMCV73nrLPH7zTejfPw3mj73wAvz2mzlxuWTJXe1KMepKSVuRDNaggelNMWV5Id5rNovH+ZbulyZQorI/L74IJ0/YNetWRERExMo++QSGDjX38+d3Lv6//4PHHzf3n3/e/EEsIiJiFTabOaH41Vfm/ldfmUmzUVF3sdPRo6FWLTh3Dtq0gS++SOUUXrmRkraSIgUKFHD3ELKcJk1gyVIbjy1+HEfjpkRFmXpn7xb/nMNFm3J+7V53DzFTUYyK1SlGxeoUo2J1lonRSZMS6h2MGOG8P2uW+cPXbocnnjD1AlXqL3uxTIyKJEMxKvGefhp+/dWUTZg61TQqu3IllTsrUgRWrDDdNuPiYMAAeOYZ06TzDilGXakRWSqpEZmkJYcDFi6EUf+7xi8bSlCAk1zFj0WtxtDg5+cJDtH5FRERERG3mzYN7r/fZGZffNFcZ2qzsXgxdOxoZio99BD8+CN4erp7sCIiIre2YAHcdx9ERJg+6bNnQ3BwKnfmcJh+Pa+9Zu43bmzKJoSGpumYswI1IpM0tXLlSncPIUuz2cxVBMvW+bF74jrWBbQmB9fovOhFdhdoztjn9nPxortHaW2KUbE6xahYnWJUrM7tMbpgQcJU2scfdyZsV6+Ge+4xCdt77jGduZWwzZ7cHqMit6EYlRu1aQOLF0PevLB+vbki+J9/Urkzmw1eeQVmzoTcueHIkTvehWLUlZK2kiIXLlxw9xCyBZsNWvQuSt2L89nafxwRHrloFLeCpz+vylsFPmXUCDuXLrl7lNakGBWrU4yK1SlGxercHqMHD5pLPe+/H8aPB5uNzZvNDNuICPOH7y+/mEtNJXtye4yK3IZiVJJSty6sXAmFC8OuXdCoEezZcxc77NjRZID//POOZ9kqRl0paStiQTYPG9W+6EeOfds4XaUlObnKW9de5OfhuyleHMaMuYt6MyIiIiJy5/r1M91kr9c+2LED2raF8HAzM+mPP8DPz92DFBERuXMVKsCqVVCuHBw9aiobbNp0FzssVw6qV094/P338Prr5moVSTElbSVFAgIC3D2EbMmjZHFCtyzA/tnn7Hh4NI7yFblwwRzrSpQw5WIiI909SmtQjIrVKUbF6hSjYnVuidEDB0w37Hht2oCPD/v3Q+vWZlXt2uZK0Jw5M354Yi06jorVKUblVooWNf3EatWCs2eheXNYsiQNdvzPP6bz2ZgxcO+93OryYcWoKzUiSyU1IhN3iIuDKVNgyut/M+DoKzzDOK6FFee118zkjxw53D1CERERkSzi2DEz1SggwNSzvd7R+uhRM7P26FGoUgWWLjW1AEVERLKCy5eha1dT69bHB37+Gbp1u8udTp4MTz4J166Zab3Tp0OZMmkx3ExJjcgkTW3ZssXdQxBMU4uePeHPIgNozzy226rQ9dQ4XnzRQalS8NlnpglGdqQYFatTjIrVKUbF6jI0Rk+fNlNpjx6FmBhnZ7F//4VWrczismVNLlcJW4mn46hYnWJUUiIgAGbNMona+FLu3357lzvt2ROWL4eCBU3h3Lp1TcmhGyhGXSlpKyly7Ngxdw9BErFNmghNmpDLcYVx9Ge5X1u8/z3CwIFQujR89ZU5uGYnilGxOsWoWJ1iVKwuw2L04kVo1w727jXXii5cCKGhnD1rqiPs3w/Fi8OiRRAWljFDksxBx1GxOsWopJSfH/z6q5kca7ebn+++e5c7rVMHNm6E+vXN79oOHWDsWJdNFKOulLQVyYxKlTLX4o0dCzly0OTaQvb5VeHloK/55x8HzzxjZn98+62ZHCIiIiIiKRARAZ07w5YtJiO7cCEUKUJ4uMnj7thhJgktXGi6bIuIiGRVnp4wfjy8+qp5/Oqr8MorcFdFVgsUMLmMvn1NNvj332HUqKS3HTUKhg+/ixfL/JS0lRTx8FCoWI6HB7zwAmzdCo0a4XPtMu9efJrZfaaSPz8cOWLOhlWoYBo1xsa6e8DpSzEqVqcYFatTjIrVpXuMRkWZa0FXrYKgIHPZZpkyRERAx46weTPky2cStqVKpe9QJHPScVSsTjEqd8pmg7ffNk3Qwfx88sm7zC/4+poZZn/8YWoODR3qTNw6Y3TUKLP8enmi7EqNyFJJjcjEUuLi4OOPYc4cmDuXq9GejBtnDq6nT5tNypaFYcPgwQez/XFPRERE5GbHjpkOY2fPmmK1DRpw7ZqZeLtokcnjLlkC1au7e6AiIiIZb8KEhHIJXbuaBmV+fmmw4/gEbblypibD9Onm8ciR8MYbafAC1qNGZJKm9u3b5+4hyK14esJLL5kZIZ6e5MgBL/aL5J/Oz/D54H8IDjZl2Xr2NF2Of/3VHGizEsWoWJ1iVKxOMSpWl+4xWqQIrFhhuq80aOBsvrJoEeTKZc6NK2Ert6LjqFidYlTuRt++8NtvZqLsH3+YkrSXLqXBjt94w5w03bMHR+3aWT5heyeUtJUU2b17t7uHIClhsyXcHzoU7+++4tkvKnNs9ETeHO0gTx7TqPHBB80fHb//fpf1aCxEMSpWpxgVq1OMitWlS4w6HLBzZ8LjIkWgWTPi4uDRR2HmTDOLaMYM0zdF5FZ0HBWrU4zK3eraFebOhYAAU5q2RYuEq3vvyqxZ4O2NLSYGfHyUsL1OSVuRrOqJJ6BuXQgPJ0f/vry+pguHV59g+HDInRu2bTNl22rVMn+IZJXkrYiIiEiKjRwJ1aqZy5Cui++SPXUqeHubk9zNm7tviCIiIlbSvLlJ2IaEmHrvjRubnjp3ZexYiIkhzssLoqOTb06WzShpK5JVVahgGmm8/bY5UzVrFrkbVGJYyR84fMjBkCHmUr+//oJ77oF69cwZMyVvRUREJFsYO9Z0pY6NhVOnAPM96PnnYeJEU33ql1+gfXt3DlJERMR6ataElSuhWDHYtw8aNXK9cOWOxNe0HTmS2dOmmROqiZqTZWeZLmk7ZswY6tSpQ0BAAKGhoXTt2pU9e/a4bHPt2jUGDBhAcHAwuXLlonv37py6/kUs3tGjR+nUqRM5c+YkNDSUl19+mdi7an+XtbVq1crdQ5DU8PKCV181p79q14aLF6FXL/J88SajRsGhQ2Z1zpywYYOpSdOokemKnNmSt4pRsTrFqFjVtGlmouH993emWjXzWMSK0vQ4OmECvPiiuT9qFAwciMMBr70Gn39uKk5NnAj33Zd2LylZn37Xi9UpRiUtlS1r5olVrAjHj5uytOvW3eFOEiVseeMNE6NvvKHE7XWZLmm7bNkyBgwYwNq1a1mwYAExMTG0bduWiIgI5zYvvvgiM2bMYOrUqSxbtowTJ07QrVs35/q4uDg6depEdHQ0q1evZtKkSUycOJGhQ4e64y1lCuHh4e4egtyNSpVgzRp4801zDUOfPgDky2cm4h46BP/5j6nZtmYNtGljLnlYtsyto74jilGxOsWoWNG0adC9uymZExVlY9s281iJW7GiNDuO/vabqX8A5gvQ//4HwOjR8O67ZvG4caamrcid0O96sTrFqKS1QoVMD8/69eH8eWjVyvRHT7G4OJemY84YjU/cxsWl/aAzEZvDkdnm07k6c+YMoaGhLFu2jKZNmxIeHk5ISAg//fQTPXr0AEyx7QoVKrBmzRrq16/PnDlz6Ny5MydOnCAsLAyAcePG8eqrr3LmzBl8fHxu+7qXLl0iMDCQ8PBwcufOna7v0QpmzJhBly5d3D0MSQtXrpi6CPHGjTPTSMLC+Pdfk8T96iuIijKrW7Y0x8pGjdwz3JRSjIrVKUYlvUVHw4UL5gtzSm+HD5v6nTcKDYV33oFy5aB8eciTJ8PfjshN0uQ4Om8edOkCMTGm/v/XX4PNxocfmvwtwIcfJkzCFbkT+l0vVqcYlfQSEWF65syfb+rB//gjPPDAne8nu8RoSnOKXhk4pnQRn4XPmzcvAJs2bSImJobWrVs7tylfvjxFixZ1Jm3XrFlDlSpVnAlbgHbt2tG/f3927NhBjRo1bnqdqKgoouKzWJgPWCRTSpywnTMH+veHIUPgs88o8OCDfPyxjZdfhjFjzN8xixebW9u2Jnlbr577hi4ikh1cu3b7ZOu5czcvu3Il7cZw+jT07ZvwOCQkIYGb+GeJEqYSj0imMWOGSdjef785S22zMX58QsJ21CglbEVERO6Uv7/5Fdurl6kH/9BD5vtq//7uHlnmlqm/ZtvtdgYNGkSjRo2oXLkyACdPnsTHx4egoCCXbcPCwjh58qRzm8QJ2/j18euSMmbMGEaMGHHT8jlz5pAzZ04A2rRpw7lz59i8ebNzfYMGDfDy8mLFihXOZVWrVqVQoULMmTPHuaxkyZJUqlSJBQsWcO3aNQBCQ0OpV68ea9as4ezZswDkzJmTVq1asW3bNg4fPux8fqdOnTh8+DA7duxwLmvWrBnXrl1jXaKiIrVr1yYwMJBFixY5l5UvX54yZcowa9Ys7Nen2xQpUoTq1auzdOlSLl++jN1uZ+XKlTRu3JiNGzfy77//AuDt7U379u3ZvXs3+/btc+6zbdu2nDlzhr/++su5rGHDhnh4eLBy5UqXz6JgwYLMnTvXuaxUqVJUrFiR+fPnOxPlYWFh1K1bl9WrV3Pu3DkA/P39admyJVu3buXo0aPO53fp0oUDBw6wM1EV7BYtWhAREcH69eudy+JrIy9evNi5rEKFCpQuXZqZM2cSPwm9aNGiVKtWzflZgDlJ0KhRIzZs2OCMGR8fH9q1a8euXbvYv3+/c5/t2rXj1KlTbNmyxbms0fVpq6tWrXIuq169OmFhYcybN8+5rHTp0lSoUIF58+YRHR0NQP78+alTpw6rVq3i/PnzAAQEBNC8eXOXz8Jms9G5c2f279/Prl27nPts2bIlly9fZsOGDQQcPkyNEiUIPHQIHn6Yfz/5hL/79yc6KIiXXqrIq6+W4umnj7BwYRHmz/dg/nzo1Ak6d95AoULmfQcHB9OwYUPWr1/vrB3t6+tL27Zt2blzJwcOHHC+dvv27Tlx4gR///23c1njxo2x2+2sXr3auaxGjRqEhIQwP9F1FWXKlKF8+fLMnTuXmJgYAAoUKEDt2rVZuXIldrudGTNmOD+LLVu2cOzYMQA8PDzo1KkT+/btY/fu3c59tmrVivDwcDZu3OhcVq9ePfz8/FiWqDZEpUqVKF68OLNmzXIuK168OFWqVGHRokVERkYCkC9fPho0aMC6des4ffo0AH5+frRp04YdO3Zw8OBB5/M7dOjA8ePHXT6LJk2aEBsby5o1a5zLatasSXBwMAsWLHAuK1u2LOXKlWPOnDnOWtwFCxakVq1arFixgosXLwIQGBhI06ZN2bx5M8ePHwfA09OTjh07snfvXpd64K1bt+bChQts2rTJuax+/fr4+vq6fBaVK1emaNGizJ4927msRIkSVK5cmYULF3L16lUAQkJCqF+/PmvXruXMmTMA5MiRg9atW7N9+3YOHTrkfH7Hjh05evQo27dvdy5r1qwZUVFRrF271rmsVq1a5MmTh4ULFzqXlStXjrJlyzJ79mzirl86U6hQIWrWrMny5cudJ/aCgoJo0qQJmzZt4sSJEwB4eXnRoUMH9uzZw969e537TKtjedHvvsPh4UH4889Tr149Z4wCVJw2jVLFirGte/cMPZYD5MmTR8fyDDiWz507j2vXPLlyxYegoJIEBZVk8eItXLhg48oVH+z2IHx9C7Bv3znOn3dw+bIPERG+RET4cv2/UarYbA78/WPIlSuGgIBo8uf3pXDhnISHHyIgIIZcuaIpUSI31asX5eDBjbzzTjlOnMiFw2FLtBcHAQHRlCp1hTNngjl+HM6cMbdE/+wAeHnZKVAggqpVfSlVKg6bbTeFCkVQqNAVmjatfMfH8gsXLgDoWK5jeZLH8vhj210dy0eO5AhwrGVLHLNnc+BAA156KRiw0b37PqpW3c2OHdb+Xg46llv1e7ndbmfp0qWp+l4er27duvj7+7NkyRLnsooVK1KqVCnn94jEn8XixYudpQKt8r1cx3LrHsvjv49mt+/lOpZn3LF8/PgALl06w5w5xXn2Wdi79xwffhjMrFkpO5Yn/pspM+ZY4t3uWB5/rLqdTF0eoX///syZM4eVK1dSuHBhAH766Sf69u3rMisWzAfWokUL3nnnHZ5++mmOHDni8g8XGRmJv78/s2fPpkOHDje9VlIzbYsUKZJtyiOcPn2a0NBQdw9D0kNMjJlWO2qU6Z6cL5/pwJHoWoaDB02dt++/Tygpc++9puFy9epuGfVNFKNiOTcU1XfG6A3LxdocDrh06c5KDsTPgr3+d2yqeHpC3rx3fgsMNM9Nqfiatjabea/xP6dNS2jAdPky7N0Le/aY2+7d5ufevdwywXzj7Nz4+5qdK6mV6t/1//wD+fPfFHi//Wa+7tjtMGAAfPqp+T8gklr6PipWpxiVjOBwmFzByJHm8QsvmNJDHinoqpVdYjTLl0d47rnnmDlzJsuXL3cmbMFkyKOjo7l48aLLbNtTp06RP39+5zaJzwbEr49flxRfX198fX3T+F1kHn5+fu4egqQXb2+TQLrnHujdG/7+Gx58EJYuhS++AKBkSfjuOxg82Bx4f/oJpk83t+7dzQH5+mR3t1GMiuXEJ2SvN7n0e+EFJWzdKC4OwsOTLitwq9uFC3fX/8DbG4KDU5ZwTbxdQEAGJI+GD6ebpye//fYGI0fC7t0Oype3MWwY3Ld9FGyNg+HDCQiAWrXMLTG7HY4duzmZu3s3t5yd6+0NpUrdnMwtV868d5HkpOp3/dGj0Lgx1KljvsBc/z4/Zw48/LCJ4z594JNPlLCVu6fvo2J1ilHJCDYbjBhhvtu+8AJ8/LH5Dv7dd+Z74K0oRl1luqStw+Fg4MCB/P777yxdupQSJUq4rK9Vqxbe3t4sWrSI7t27A7Bnzx6OHj1KgwYNADOd/s0333TJ4C9YsIDcuXNTsWLFjH1DmcSyZcuyRTHobK16ddiwAd5809zatLlpkzJl4Icf4PXXTc7pl1/MLJVp00yed9gw84e3OyhGxVKuXIFDh1wSt7mGDzfZgTJlYP166NrVTIn08DA/v/8e4hthfvMNrFvnuj7x/eHDTeEogJkzYdMm1/WJn/P44yYDCGafO3Ykva2HhyleHb/tvn3mPST1+h4e5kxN/BjOnjXZuaRe38PDzOCPf29RUaZjVlKvn4KMSUzMnTfbOn8eLl40Z/1TK2fO1M18zZnTwokgT08YOpRuI6HbljeYMWOmOY4mPrlwCx4eUKyYubVt67ruyhUzEzc+kRufzI2fnbt7t7ndKF++m+vmlitnTh5qdq7c8e/6U6egdWtzdsHf30wb9/Vl6VLTLCUmxnx/+eablM3+EbkdfR8Vq1OMSkZ6/nmTuO3TxzQmu3ABfv3VfD9OjmLUVab7+jtgwAB++uknpk+fTkBAgLNuUWBgIDly5CAwMJAnnniCl156ibx585I7d24GDhxIgwYNqF+/PmBqgVSsWJHHHnuMd999l5MnTzJkyBAGDBiQrWfTiuDjY06J9eljrl+Nt2qV+as5Xz4AKlSAn3+G//3PbP5//wdTppgD8COPmL/1y5Rxz1sQyVBXrsCuXSYRGn/buROOHDGzuSIiTOJ29Gg8rtdMYt8+c7vRpEkJ95cuhcmTk3/d119PSJj++afpGpic7t0TErFTpsDYsclvu3u3+b8eP54330x+202boGZNc//rr82YkrNihZnpBjBuHAwalORmDpuN356Yw+aQdpw/D1U2T6LP5ueJxZNYhydxDg9iHZ7Y8SAHnoxgPPNpB0AHZvMurxCHWX/jz5EMZT7tCAiA1v5r+G/ECDx9PPHy8cDT1xMvX0+8fT3w9vXkROensDdvRd68EHpuF3knfYiXTzIJ9E5doGlT8waOHTNTCJJLoDdsaGb7gckk//FH8tuWKweVKpltIyPNdNXkEugFCkDRombbmBjYvz/5bf39TQ0FME0oo6LMQTs21kylTaPZ4LlymfCID5F4dru5Uv3GZO6ePWb52bPmrSY3OzepcguanStJunAB2rUzx9tixWDBAsiXj7VroXNn0/CvSxdzMvpOSoqIiIhIyvXsCXnyQI8eMGuW+dU8Ywbc0IZKkpHpkrZffvklAM2bN3dZPmHCBPr06QPARx99hIeHB927dycqKop27drxxfXLvMEU/J45cyb9+/enQYMG+Pv707t3b0beZkaJSLaROGF76pQpYOvpaZIt8UUOMRPtpk6FrVvNLNvp080ZtJ9/Nl0jhwwxs6NEMr2ICJOc3bkTHnssYepknz5munlSgoLg5EmTxIuOxu7piUdcnJlh26mTuebebk/4mfhaoQceMGdH4tffuG3iy4aaNTPJuMTrEz8nPrkLULGiee3ktk182jssDKpVS/r14+LAzw+Hw+QTo6/5ERAUjCPWdVubw47NHscbQzxYYzN5ym5H7AxL5mO2ORx89Y0H8S0tniIKfy4l+89SIv816hQxSbtO4eepvHZHstv++vlZcj51/WP+/SR0m5fstiWfagVNW5kH84/BhG+S3ZZChRKStkePmlnQyXnzzYSk7dGj8MQTyW87eDC89Za5/88/5htucp5/3lx3BnD6tPl3Ts6TTyYk+cPDExLzI0fSOX6bsDBz4sDXF155JeG5v/xiPux8+cwtOPjWUyWS4OFh8stFiyY/O/fGUgs3zs6dPt31eYln5yZO6pYocftL8CSLunLFHOu2bjXxvHAhFC7MX39B+/bmkN6qlTnZrBgRERFJXx07mnOnnTubE/PNmsG8eabcvNxapm5E5k4pLRqcVRw8eJCSyr5lT7t2mdNi8Z0iH3nEFH4LDr5p002bTPI2vpmrlxf07Wtm5BYrlr7DVIxKmtm7F9asMTEfP3s2USdZjhxJmNU4bBh89ZWZEVmpkkmWxf8MDnaZtXiwZ09KTp5syZq2Doe5avh2jbWSusVPIE4pT2LxJgZP4vCy2cmXJ458eeLIG2Qnb2AcPmF5CAjxI29eyJ8jnAKepwkKiCMot53AXHEE5oojwN+OJ3FQurQ5dQ8mQb5zZ9IJ5rg4qF074d/t6FGTlExqW7sdWrRIKNR98KA5E5VcAr1LF2jSxGy7fz988EHySfEHHjBJe4ADB0yRr+S2fewxePpps+3hw+Z5yY338ccT4un48Vsn25980pyAA/MPmMSx3KlPH5gwwdyPjHQ9ARAvRw6TNe3WzXUW95tvmn+b+ARv4kTvHV7VdLvZucnx8jIhcmMyt1y5W79tsa4U/a6PijJ/FS5caGJw2TKoUoVdu8z5lbNnoVEj88diUiEtcjf0fVSsTjEq7vT332YewsmTZnLXggU3T/LKLjGa0pyikraplN2Stna7HQ8V+8q+oqJMHYR33jF/PefPbxJV99yT5Obr1plc1rzrE9m8veGpp8zV04UKpc8QFaNyRyIjE8oa7NwJ//2vs/wHr71mYv1GoaEmIfvZZwkzGePikr+u9obLzJ0xmo7NyOKbbd1pvdfz5+++2datmmoldwsIUB1Jt3I4zDXib70Fo0fj8PHBFh1tLpVo184kuePLWpw7B/ffbzJe8beYmIR99e1rZpVD8gneeA88YGbtxo/h8cfNzPQbE7z58pnfN7fIsCY1Ozf+dvVq8kPIly/pUguanWttKfpdv3Gjyc56eJjEbf36HDhgzq38+6+pArJoUUKVEJG0pO+jYnWKUXG3gwdN+5yDB83XvHnzoGrVhPXZJUaVtE1n2S1pO2PGDBWDFtM8qXfvhO4xvXol1G9MwsqVJnm7eLF57OsL/fqZnFiBAmk7NMWo3NLGjab4cuKZs4l//S1aBC1bmvvTpsGnn948ezY+qZtSw4eDpyfTKr3BiBGwa1ccFSp4MmwYdNsxymRJk7mUPjb2zpptxc+EvdtmWzlypK7Zlr+/hZttya0lOokwo3p1umzZkrKTCvHTs8+eNQEYEJDQiTI83JRVSJzgjd8uLs41wRsRYQrgJufee03t3/jXbN4ccudOOsFbooTzW3/87Nwbk7m7d99+dm6pUkmXW9DsXPdL8e/6lSvNZQAtW3LsmEnYHjliJtAvXap/S0k/+j4qVqcYFSv4919Trujvv81J1JkzE+YJZJcYTWlOMdPVtBURN6pbF/76y2Ri33/f1DK8RfeOxo1NLmzpUpMDWLHCVFYYPx6efRZefdVMXhS5a/EzZxOXNBg+3EypAtiy5ebZsyEhCQnZkJCE5d26mdtdsg8dzuTJ0Ku7SWg6HJ5s22b6gvXu/QaFCsH5/kknYS8lX8Y1RXLlSj7BmtwM2Dx5TNJWspEbZ33PmJGQqB061PxMLnFrs5nkae7cN1/XFhhorsa4kd1uErp2u+vyd991TewmTvQm/r8ZGQnLlyf/fhIleD1sDoo2KEzRgADaxCd1i+WDWvmICsjHP4GVWB/cISGRu/MSf+0PIPKqzZngvVH87NwbZ+iWLKnZuW7ncJh6zmFh5vH1v/xOnjS1a48cMaUyFixQwlZERMTdChQw1Yu6dDHnWdu2hRdfNMnbXbs6UqGCSTmkwZ9kmZ6StiJyZ/z8TPKrWzfXZjcnTpgkbhJtIJs3NwflRYtMHmDNGvjwQ1NWceBA1yvTRVJszRoYM8YkaA8dunmKaZcuCUnb+vXNmYL4JO2NidpE4ptrXbpk8kuXLrneT+7njcsuX3bdZ+Kfkyal7C0GBd35rNc8ecDHJ+Ufo2RjcXFJz6iNf3w3NTOS4uGRUIM4nr8/vPxy8s9J/P/aywt+//3mGbzxt8S/kyIizO8luCkD6wuU6tqVUr93SHgNvxAcdjv2kGCu5sxHuHc+ztiD+ScqHysia/PuhaecL3Nl1RYWEcRZ8hGBP15eNkqVck3manZuBhs+3HypmD/f1HTG5P/btIF9+0ylj0WL1PBERETEKoKCTGmEBx4wPXHeeuvmiS6//abErcojpFJ2K4+wbds2qlSp4u5hiFXZ7eYvoz17TFfyDh2S3dThMAfnoUNhwwazLFcuGDQIXnrp5r/nU0oxmsXEt4qPnzUbP4N22DDToAnMFO4WLRKeky8f9gqViCpVkSvFKnG6WhtOB5VNcfI18f20zlXdyMMDBgy49SzYwECToxLJKFnqOBoXZ44hySV4a9c2jeDAnGG51Xe5++4j4odp7N0Lu3c5eOAxXzztpp7vNXw5RzBnycdZ8rGCJoxguPOpvXJNI2/RXASVzkdoxXwUrZmP0lVzanZuKiUZox9+CP/5j7n/1Vfw9NNcumRm2G7caGbzLF9uZtqKpLcsdRyVLEkxKlYTE2Ouvr140XW5zWaqXm3Z4o5RpT/VtE1n2S1pK3JL//4LzZqZ6Sxgmsp8+OEtu3w4HOaM2tChpuICmL+ZX3rJJHDVICSbuHYNoqKI9Q/k0iW4tuYvgvvfj88/B7El8etpQY2X+aHyuyaxevYCjY9MZpu9EpujKnHgcijR0Wk3NA8PE5OBga4/k1qW3LpWrUyuOfFbyepfQEQypWvXbi7NEH8rWxYefthsFxEBFSrAmTPmOTfYUvI+Xi45jT174NgxB1H44kOMyzaR5OAs+VgX2JYfm33jnJXbYvMHhBTLQa5iN9TqDQ42ReHlZt9+C08+ae6/9RYMHkxEhKmTt3Kl+eiWL3edhC0iIiLW4udnep8ntfxWjWUzMyVt01l2S9ouWrSIVq1auXsYYmWRkTBkCIwdazJUhQubP6batr3l0xwOU4Jw2DDYts0sCwoyJROef970tkkJxah72O2me/vtZrBGnLuG/7Hd5Dmxg9CzOyl0cQfFInZQJOYg73m9zuDYUQAU5hjHKArAWYLZQSV2UpEdVGIHldhGFc5x+1oauXKlPLGa3Lq0aK41bZq5tMdc6pPwc9o0uO++u9u3SFrTcfQORUbenOANCzNnazDHPXv7jsSdOovnhbPkiDyLlz0hgfsb3ejBb9cfOYjGB29ik3ypK03a47toTsLs3AEDTB2UxMndkBDzMywsy9ZlcInRqVPhoYfML6JXXoG33+ZalI177jG1awMDTSPUmjXdO2bJXnQcFatTjIoVVatmcgHZaaKLGpFJmoqMjHT3EMTqcuY0s2vvu890Bj9wANq1MzNgPvoo2e7gNpt5yr33mpo1w4aZflJDhpinvfKK+dvU3//WL68YvTMOhzlreadlA278efmy6y9XX65Rjj3E4sVOKgFQlCMcpCSe2JMcS+HYQ8775/wK0z3HYk4EVSQ2byi5A23OJGrVQGicgqRrQMAt++NlqG7dTFyPHAk7d8ZRsaInw4YpYSvWpOPoHcqZ0xRLLVo0ydX+wX6wYXHCAocDLl/GfvosZ3afo8CJHHwabSoL7d8Zw6/rHscvIr7QgrkFcw4v4pi3IicP5cTUzi3rYNrMr/B0JFPHpXlzWLIk4XHHjuagmC/fzbeiRaFGjbT7TNKZM0bnzIGePU3C9umn4e23iYm18eCDJmHr7282UcJWMpqOo2J1ilGxomHDkp7oMmyYu0fmfkraikjaatIEtm6F11+HTz6B1atTVLjPwwPuv98kuX75BUaMgL174dVX4YMPzM9nnjF/I2d30dGpS7DeeD826QldKWLDTmW2X5//uoPKth1Utu2khH0/nthZGPIwn9T/idy5ISigMPZvfIj2zsGFgpW4UqwSUaUrYS9XEc+qlWhYIoyzQSbZ6uNjA1rc7uUzlW7dzG3GjNl06dLF3cMREXex2SB3bjxy5yasdEnCgIbOlT7AV0REmN992/aYZO6eXXaO7wznyP4YYq+aZQf2xPIaYwjmnDO5m9/rLAW8z5LXfpbj50LYM900QytZ3I73/PnJF+q+McFboYL5KympBG/ZsnDPPQnbXr5sTsje7SUJtzJ8uEk4J26W53DAe++ZIniVKsEXXxBnt9GrF/z5p7mUcsYMaNAg/YYlIiIiaUcTXZKnpK2kSL58t78cWcTJ3x8+/tgcfQMCEmrxxcaa6Z23qHng6QmPPGK6SP70k0neHjxoeoy89x4MHmwm1fj5uT4vM8RobKz5G/dWidWUJF+TqveTWtdzCMmWCcib8xolYvZS9PIOfHP7crFlNwIDITBHLDWb1sIWn/l1XL8BBAXRupMvrSfEv4onjDqGd3AwOdLzj3uLywwxKtmbYtT9/P3NxNeEya8eQB7sdjh+3CRtd+/2Zs+el1m8x/RaO3YMiL1+A9jmgK7mro+ngyfC/o+KIWcpGXiWIn5nCfU8S57Ys/hcOguVKye8uN1uatPHxZkXulGLFq5J21Kl4MIFU4ohvvZufIK3ShV47rmEbbdvNwne4OA7S/R6epri9wBvvGFi1GaDRo1MsrlHD+w2T55+CqZMMeeIf/vNtUelSEbScVSsTjEqVhU/0WXNmvU00JlXJ9W0TaXsVtNWJE28/TaMGwfffQctW6boKTEx8P33MGoUHDlilhUqBP/7n+l3NmtWwqzcsmXNJRTduqXtsO1203smtbNa439GRKTtuPz9ky8TkNL6rTf97fzrr6ag0I4d5rZ/v/kAAOrUgfXrE7Zt1Mg8uWJFM9sp/pY/f/rOvBIREaeICJNr3b07Pql7fZbuHlN2Nzl58+Jsgla+PJQrY6eK1y6K5jyL18UkGrJVqGCuogHze8HbO+H3w41atDAFZeOFhJh9wM21eGvVgnffTdh2xgxzsjd+/TffmC8Br78Ob75p7g8dCiNH4hjyBi+8AJ9+aq7Y+eUX6NHj7j5PERERkfSmRmTpLLslbdetW0e9evXcPQzJzGJizMyb+Nk7zz4L77yTbK3bG0VHw4QJMHo0/POPWZYvn/kb8MbaN7/9ZhK38XVb76Zma/wtLY+Ufn63T6jeLuma6rqtUVEmw71jB+zcaf7gHj06YX3p0qYecWKBgSYZW7euKTQsqaLjqFidYjRrSTw7N3Ey1zk7NxleXlCyZKJkbrmE+y4TtK5dg3Pnbk7unj0LRYqYM6tgfoGWLAknT5rn3KhlS1i0KOFxvnxmvzcOKjYWh4cHNrvdXD/5xhu8/jqMGWM2mTQJevVK1UclkmZ0HBWrU4yK1WWXGFUjMklTp0+fdvcQJLPz9oYNG0xnsXHj4IsvTJeQCROgWbPbPt3HB/r1gz594Ouv4a234N9/zbr4hGr8z4cfNrngu63beiNPT5O/vNPZrDcu8/FJuzGlyNixsGKFSdLGX/oaL08eM2spfmZs9+5w/rzrzNkCBTRzNg3oOCpWpxjNWjw8TO60SBFo3dp13Y2zcxMndSMjzbm9vXvNpNfEEs/OLVfOj/LlC1GuXCFKNb1F+XqbDQ5dbzgZGXlzgjcoKGFbhwOqV4fTpxPWx8Q4f5nb7HbzS/SNN3jrrYSE7ZdfKmEr1qDjqFidYlSsTjHqSklbEck4AQHmL6vu3eGJJ8wfcc2bw8CB5i8vf//b7sLX15TJe+IJkwBNKikbHW3yjvFsNvPSqS0hEH8/Rw4L5i6jo81f1jt3JpQ0OHMGli1L2GbOHJg/P+Fx7tyuSdm4ODOLCczsZxERydL8/U1utHp11+UOh5mdm1SphaNHze/W1avNLTFPT1PiNvGs3CRn5+bMCUWLmltSbDZYuNB1QJcvm9pHY8cS5+WFZ3Q0qzuO4n9zTHOy9983jUpFREREsholbSVF/G7s+iRyN1q3NnVTX34Zxo83t/79Tb28FMqRw5RS3bbNtXSBzWb+cJw+PSHh6u9vZhxlarGxCYlVMIV8f/nFTJVKKnN9/ryZEgUmw92+fUKStmBBC2afsz4dR8XqFKNis0HhwuaW3OzcG5O5e/aYdbeanZtUqYWSJVNw5YnNZhqbjh0LI0eyuH598ny2loZ/DmUI4DX8Df7znzT8AETuko6jYnWKUbE6xagr1bRNpexW01Yk3cyfbzqMPfVUwrK4uBQVbJ02zUzavbGm7bRpcN996Tjm9BQTY/4qjp81Gz+Ddv9+U+MvvgbwgAGmxASYacTxCdn4pmDNmpniuSIiIukofnbujXVz42fnJsfT0yRub0zmlitnZufabDibju18aCQP73yDXbvMr8khjGIUQ3GMGIlt6BsZ9l5FRERE0oIakaWz7Ja03bFjB5UqVXL3MCQ7WLfOFK795hto1Oi2m0+bZvqR7Nplp0IFD4YNyyQJ2/jkbJkyCYUAhwwx5QmSK8S7fj3UqWPub9kCp06ZBG2hQpo5mwnoOCpWpxiVtJZ4du6NM3QjIpJ/Xvzs3FcihxPr8OT+v99wnpiNt/3BUVQqHwfDh6f7+xBJKR1HxeoUo2J12SVG1YhM0tTBgwezxX8csYAhQ8xfdU2awIsvwujRphZCMrp1M7cZM2bRpUuXDBxoCiWeOZu47uzevSY5u3UrVK1qts2b1yzLlct11mz8/SJFEvZ7YyFCsTwdR8XqFKOS1m5XO/fGRO7u3Qm1c9esgfsY7vKceDYb9Nz9BlumZMS7EEk5HUfF6hSjYnWKUVdK2oqItUydapK1EyfChx/CzJnmfoMG7h7ZrcXEmBIGO3eahHNoqFn+/vvw+utJPydXLjhxIiFp26sX9OhhkrOaOSsiIllU4tq5rVq5rouMNOc645O5I0aA3e66jcNh1omIiIhkZUraioi1BAXBhAkmefnUU2ZGauPG8NJLpg7CLWbdZphTp2DlSte6s3v2mMQtwG+/mem/YGbJ5sp186zZSpVuTs66tNgWERHJfnLmhGrVzA3Mr9Skmo6WK+ee8YmIiIhkFNW0TaXsVtM2NjYWLy/l+CWDXbgAgwbB99+bx99/D489luSmaR6jsbFw4EBCYrZTJ6hZ06ybOhUeeODm5/j7m4TskCFwzz1mWVwceHho5qzoOCqWpxgVK8qSTUcly9JxVKxOMSpWl11iVDVtJU0dP36cYsWKuXsYkt3kyQOTJplZt7/+Co8+muymdx2jR4+apHB8knbPHoiOTljv65uQtK1SxTQESzx7Nn7mrIeH6349PVM/JslSdBwVq1OMihV162Zm244cCbt3Oyhf3pZ5mo5KtqPjqFidYlSsTjHqSklbSZG///5b/3HEfbp0Mbd4ly6ZBGrr1jBuHHBDjI4aZWa4Ju4oHReXMHM2viHYPffAQw+Z9WfPwhtvuL5uzpwmMVuxIlSunLC8fHlYvz7t36dkaTqOitUpRsWqEpqOzrRm01GR63QcFatTjIrVKUZdKWkrIpnPyJEmAXvgAOzaBfPnJ6wbNQqGDjXbnDgB//1vwszZqCjX/QQEJCRtK1QwjcAS15wtVuzmmbMiIiIiIiIiIulMSVsRyXxeew2OH4cpU2D5cihShBoVKsDTT8PJkyZh+8YbEB4OP/+c8LwcOUxyNr6cQePGrusmTcr49yIiIiIiIiIicgM1Ikul7NaI7OLFiwQFBbl7GCKupk0zjckiIxOWlSgBBw8mPP70Uyhe3CRpixfXzFlxGx1HxeoUo2J1ilGxOsWoWJ1iVKwuu8SoGpFJmoqNjXX3EERu1q0bNG0K+fObmrVeXrB4ses2Awe6Z2wiN9BxVKxOMSpWpxgVq1OMitUpRsXqFKOuNOVMUmTNmjXuHoJI0r78EuLiiPPygthY+OEHd49IJEk6jorVKUbF6hSjYnWKUbE6xahYnWLUlWbaikjmlajp2Ozq1emyZYt5DKamrYiIiIiIiIhIJqSkrYhkTokStrzxBsyYkZCoVeJWRERERERERDIxJW0lRWrWrOnuIYi4iotLSNiSKEbjE7VxcW4amEjSdBwVq1OMitUpRsXqFKNidYpRsTrFqCubw+FwuHsQmVFKO71lFdeuXcPPz8/dwxBJlmJUrE4xKlanGBWrU4yK1SlGxeoUo2J12SVGU5pTVCMySZEFCxa4ewgit6QYFatTjIrVKUbF6hSjYnWKUbE6xahYnWLUlZK2IiIiIiIiIiIiIhaimrapFF9V4tKlS24eScaIjIzMNu9VMifFqFidYlSsTjEqVqcYFatTjIrVKUbF6rJLjMa/x9tVrFXSNpUuX74MQJEiRdw8EhEREREREREREclMLl++TGBgYLLr1Ygslex2OydOnCAgIACbzebu4aSrS5cuUaRIEY4dO5Ytmq5J5qMYFatTjIrVKUbF6hSjYnWKUbE6xahYXXaKUYfDweXLlylYsCAeHslXrtVM21Ty8PCgcOHC7h5GhsqdO3eW/48jmZtiVKxOMSpWpxgVq1OMitUpRsXqFKNiddklRm81wzaeGpGJiIiIiIiIiIiIWIiStiIiIiIiIiIiIiIWoqSt3Javry/Dhg3D19fX3UMRSZJiVKxOMSpWpxgVq1OMitUpRsXqFKNidYrRm6kRmYiIiIiIiIiIiIiFaKatiIiIiIiIiIiIiIUoaSsiIiIiIiIiIiJiIUraioiIiIiIiIiIiFiIkrYiIiIiIiIiIiIiFqKkrYiIiIiIiIiIiIiFKGkrt/T5559TvHhx/Pz8qFevHuvXr3f3kEScli9fTpcuXShYsCA2m40//vjD3UMScRozZgx16tQhICCA0NBQunbtyp49e9w9LBGnL7/8kqpVq5I7d25y585NgwYNmDNnjruHJZKst99+G5vNxqBBg9w9FBEAhg8fjs1mc7mVL1/e3cMScXH8+HEeffRRgoODyZEjB1WqVGHjxo3uHpaIU/HixW86ltpsNgYMGODuobmdkraSrF9++YWXXnqJYcOGsXnzZqpVq0a7du04ffq0u4cmAkBERATVqlXj888/d/dQRG6ybNkyBgwYwNq1a1mwYAExMTG0bduWiIgIdw9NBIDChQvz9ttvs2nTJjZu3EjLli2599572bFjh7uHJnKTDRs28NVXX1G1alV3D0XERaVKlfj333+dt5UrV7p7SCJOFy5coFGjRnh7ezNnzhx27tzJBx98QJ48edw9NBGnDRs2uBxHFyxYAMD999/v5pG5n83hcDjcPQixpnr16lGnTh0+++wzAOx2O0WKFGHgwIG89tprbh6diCubzcbvv/9O165d3T0UkSSdOXOG0NBQli1bRtOmTd09HJEk5c2bl/fee48nnnjC3UMRcbpy5Qo1a9bkiy++YPTo0VSvXp2xY8e6e1giDB8+nD/++IMtW7a4eygiSXrttddYtWoVK1ascPdQRFJs0KBBzJw5k3379mGz2dw9HLfSTFtJUnR0NJs2baJ169bOZR4eHrRu3Zo1a9a4cWQiIplTeHg4YJJiIlYTFxfHlClTiIiIoEGDBu4ejoiLAQMG0KlTJ5fvpSJWsW/fPgoWLEjJkiXp2bMnR48edfeQRJz+/PNPateuzf33309oaCg1atTg66+/dvewRJIVHR3Njz/+yOOPP57tE7agpK0k4+zZs8TFxREWFuayPCwsjJMnT7ppVCIimZPdbmfQoEE0atSIypUru3s4Ik7btm0jV65c+Pr68swzz/D7779TsWJFdw9LxGnKlCls3ryZMWPGuHsoIjepV68eEydOZO7cuXz55ZccOnSIJk2acPnyZXcPTQSAgwcP8uWXX1KmTBnmzZtH//79ef7555k0aZK7hyaSpD/++IOLFy/Sp08fdw/FErzcPQAREZGsbsCAAWzfvl117sRyypUrx5YtWwgPD+f//u//6N27N8uWLVPiVizh2LFjvPDCCyxYsAA/Pz93D0fkJh06dHDer1q1KvXq1aNYsWL8+uuvKjMjlmC326lduzZvvfUWADVq1GD79u2MGzeO3r17u3l0Ijf79ttv6dChAwULFnT3UCxBM20lSfny5cPT05NTp065LD916hT58+d306hERDKf5557jpkzZ7JkyRIKFy7s7uGIuPDx8aF06dLUqlWLMWPGUK1aNT7++GN3D0sEgE2bNnH69Glq1qyJl5cXXl5eLFu2jE8++QQvLy/i4uLcPUQRF0FBQZQtW5b9+/e7eygiABQoUOCmE7EVKlRQGQ+xpCNHjrBw4UKefPJJdw/FMpS0lST5+PhQq1YtFi1a5Fxmt9tZtGiRat2JiKSAw+Hgueee4/fff2fx4sWUKFHC3UMSuS273U5UVJS7hyECQKtWrdi2bRtbtmxx3mrXrk3Pnj3ZsmULnp6e7h6iiIsrV65w4MABChQo4O6hiADQqFEj9uzZ47Js7969FCtWzE0jEknehAkTCA0NpVOnTu4eimWoPIIk66WXXqJ3797Url2bunXrMnbsWCIiIujbt6+7hyYCmC/GiWcyHDp0iC1btpA3b16KFi3qxpGJmJIIP/30E9OnTycgIMBZDzwwMJAcOXK4eXQiMHjwYDp06EDRokW5fPkyP/30E0uXLmXevHnuHpoIAAEBATfVAff39yc4OFj1wcUS/vvf/9KlSxeKFSvGiRMnGDZsGJ6enjz88MPuHpoIAC+++CINGzbkrbfe4oEHHmD9+vWMHz+e8ePHu3toIi7sdjsTJkygd+/eeHkpVRlPn4Qk68EHH+TMmTMMHTqUkydPUr16debOnXtTczIRd9m4cSMtWrRwPn7ppZcA6N27NxMnTnTTqESML7/8EoDmzZu7LJ8wYYIK64slnD59ml69evHvv/8SGBhI1apVmTdvHm3atHH30EREMoV//vmHhx9+mHPnzhESEkLjxo1Zu3YtISEh7h6aCAB16tTh999/Z/DgwYwcOZISJUowduxYevbs6e6hibhYuHAhR48e5fHHH3f3UCzF5nA4HO4ehIiIiIiIiIiIiIgYqmkrIiIiIiIiIiIiYiFK2oqIiIiIiIiIiIhYiJK2IiIiIiIiIiIiIhaipK2IiIiIiIiIiIiIhShpKyIiIiIiIiIiImIhStqKiIiIiIiIiIiIWIiStiIiIiIiIiIiIiIWoqStiIiIiIiIiIiIiIUoaSsiIiIikgo2m43hw4e7exi31KdPH4oXL+7uYYiIiIjIHVLSVkRERETcZtu2bfTo0YNixYrh5+dHoUKFaNOmDZ9++qm7h5bhihcvTufOnd09DBERERGxACVtRURERMQtVq9eTe3atdm6dStPPfUUn332GU8++SQeHh58/PHH7h6eiIiIiIjbeLl7ACIiIiKSPb355psEBgayYcMGgoKCXNadPn3aPYMSEREREbEAzbQVEREREbc4cOAAlSpVuilhCxAaGuryeMKECbRs2ZLQ0FB8fX2pWLEiX3755U3Piy8xsHTpUmrXrk2OHDmoUqUKS5cuBWDatGlUqVIFPz8/atWqxV9//eXy/D59+pArVy4OHjxIu3bt8Pf3p2DBgowcORKHw3Hb93T8+HEef/xxwsLC8PX1pVKlSnz33Xcp/1ASOXz4MDabjffff5/x48dTqlQpfH19qVOnDhs2bLhp+z/++IPKlSvj5+dH5cqV+f3335Pcr91uZ+zYsVSqVAk/Pz/CwsLo168fFy5ccG4zbNgwPDw8WLRokctzn376aXx8fNi6dWuq3pOIiIiIpIxm2oqIiIiIWxQrVow1a9awfft2KleufMttv/zySypVqsQ999yDl5cXM2bM4Nlnn8VutzNgwACXbffv388jjzxCv379ePTRR3n//ffp0qUL48aN4/XXX+fZZ58FYMyYMTzwwAPs2bMHD4+EuQxxcXG0b9+e+vXr8+677zJ37lyGDRtGbGwsI0eOTHaMp06don79+thsNp577jlCQkKYM2cOTzzxBJcuXWLQoEGp+px++uknLl++TL9+/bDZbLz77rt069aNgwcP4u3tDcD8+fPp3r07FStWZMyYMZw7d46+fftSuHDhm/bXr18/Jk6cSN++fXn++ec5dOgQn332GX/99RerVq3C29ubIUOGMGPGDJ544gm2bdtGQEAA8+bN4+uvv2bUqFFUq1YtVe9FRERERFLIISIiIiLiBvPnz3d4eno6PD09HQ0aNHC88sorjnnz5jmio6Nv2jYyMvKmZe3atXOULFnSZVmxYsUcgGP16tXOZfPmzXMAjhw5cjiOHDniXP7VV185AMeSJUucy3r37u0AHAMHDnQus9vtjk6dOjl8fHwcZ86ccS4HHMOGDXM+fuKJJxwFChRwnD171mVMDz30kCMwMDDJ93Dj2Dt16uR8fOjQIQfgCA4Odpw/f965fPr06Q7AMWPGDOey6tWrOwoUKOC4ePGic9n8+fMdgKNYsWLOZStWrHAAjsmTJ7u89ty5c29avm3bNoePj4/jySefdFy4cMFRqFAhR+3atR0xMTG3fB8iIiIicvdUHkFERERE3KJNmzasWbOGe+65h61bt/Luu+/Srl07ChUqxJ9//umybY4cOZz3w8PDOXv2LM2aNePgwYOEh4e7bFuxYkUaNGjgfFyvXj0AWrZsSdGiRW9afvDgwZvG9txzzznvx8+cjY6OZuHChUm+F4fDwW+//UaXLl1wOBycPXvWeWvXrh3h4eFs3rw5pR+NiwcffJA8efI4Hzdp0sRl3P/++y9btmyhd+/eBAYGOrdr06YNFStWdNnX1KlTCQwMpE2bNi5jrFWrFrly5WLJkiXObStXrsyIESP45ptvaNeuHWfPnmXSpEl4eeliPREREZH0pm9cIiIiIuI2derUYdq0aURHR7N161Z+//13PvroI3r06MGWLVucScdVq1YxbNgw1qxZQ2RkpMs+wsPDXZKViROzgHNdkSJFklyeuJYrgIeHByVLlnRZVrZsWcDUmU3KmTNnuHjxIuPHj2f8+PFJbpPa5mo3vp/4BG78uI8cOQJAmTJlbnpuuXLlXJLF+/btIzw8/KaawcmN8eWXX2bKlCmsX7+et95666YksIiIiIikDyVtRURERMTtfHx8qFOnDnXq1KFs2bL07duXqVOnMmzYMA4cOECrVq0oX748H374IUWKFMHHx4fZs2fz0UcfYbfbXfbl6emZ5Gskt9yRggZjtxM/hkcffZTevXsnuU3VqlVTte+0HLfdbic0NJTJkycnuT4kJMTl8cGDB9m3bx8A27Ztu+PXExEREZHUUdJWRERERCyldu3agLnsH2DGjBlERUXx559/usw6TXwpf1qy2+0cPHjQObsWYO/evQAUL148yeeEhIQQEBBAXFwcrVu3TpdxJadYsWIAzuRqYnv27HF5XKpUKRYuXEijRo1cSk4kxW6306dPH3Lnzs2gQYN466236NGjB926dUu7wYuIiIhIklTTVkRERETcYsmSJUnOFp09ezZgLu2HhJmmibcNDw9nwoQJ6Ta2zz77zHnf4XDw2Wef4e3tTatWrZLc3tPTk+7du/Pbb7+xffv2m9afOXMm3cZaoEABqlevzqRJk1zq+y5YsICdO3e6bPvAAw8QFxfHqFGjbtpPbGwsFy9edD7+8MMPWb16NePHj2fUqFE0bNiQ/v37c/bs2XR7LyIiIiJiaKatiIiIiLjFwIEDiYyM5L777qN8+fJER0ezevVqfvnlF4oXL07fvn0BaNu2LT4+PnTp0oV+/fpx5coVvv76a0JDQ52zcdOSn58fc+fOpXfv3tSrV485c+Ywa9YsXn/99ZvKByT29ttvs2TJEurVq8dTTz1FxYoVOX/+PJs3b2bhwoWcP38+zccab8yYMXTq1InGjRvz+OOPc/78eT799FMqVarElStXnNs1a9aMfv36MWbMGLZs2ULbtm3x9vZm3759TJ06lY8//pgePXqwa9cu3njjDfr06UOXLl0AmDhxItWrV+fZZ5/l119/Tbf3IiIiIiKaaSsiIiIibvL+++/TokULZs+ezUsvvcRLL73E+vXrefbZZ1m3bh1BQUGAmXH7f//3f9hsNv773/8ybtw4nn76aV544YV0GZenpydz587l5MmTvPzyy2zYsIFhw4YlOTs1sbCwMNavX0/fvn2ZNm0azz33HB9//DHnz5/nnXfeSZexxmvfvj1Tp04lLi6OwYMHM23aNCZMmOAsNZHYuHHjGD9+PKdPn+b1119n8ODBLF68mEcffZRGjRoRFxdH7969yZcvH2PHjnU+r0yZMowZM4apU6cqaSsiIiKSzmyOtOi8ICIiIiKSBfTp04f/+7//c5mdKiIiIiKS0TTTVkRERERERERERMRClLQVERERERERERERsRAlbUVEREREREREREQsRDVtRURERERERERERCxEM21FRERERERERERELERJWxERERERERERERELUdJWRERERERERERExEKUtBURERERERERERGxECVtRURERERERERERCxESVsRERERERERERERC1HSVkRERERERERERMRClLQVERERERERERERsRAlbUVEREREREREREQsRElbEREREREREREREQtR0lZERERERERERETEQpS0FREREREREREREbEQJW1FRERERERERERELERJWxERERERERERERELUdJWRERERERuUrx4cYoXL+6ybPjw4dhsNpYuXeqWMd2JPn36YLPZOHz4sLuHIiIiInLHlLQVERERkTQxceJEbDZbim99+vRx95AtoXjx4i6fi6enJ/ny5aNt27ZMnz7d3cNLU/ExMnHiRHcPRURERMTSvNw9ABERERHJGqpXr86wYcNclh0+fJhJkyZRrVo1unbtetP2Ynh6ejJkyBAAoqOj2b17N3/++ScLFizg/fff5z//+Y+bR2g899xzPPTQQxQtWtTdQxERERHJ0pS0FREREZE0Ub169ZsSsUuXLmXSpElUr16d4cOHu2VcmYGXl9dNn8/8+fNp3749Q4cOpX///uTMmdM9g0skX7585MuXz93DEBEREcnyVB5BREREJItZvnw5Xbt2JSwsDF9fX4oUKUK3bt1YuXIlAEOGDMFms/Hrr78m+fzvvvsOm83GmDFj0m2MiWujTpw4kZo1a5IzZ06aN29+0/ob3eoS+7///puHHnqIAgUK4OPjQ7FixRg4cCDnzp1L0bhKly5NQEAAkZGRSa6/5557sNls7N27FwC73c4333xD3bp1yZs3Lzly5KBw4cJ06dLlruu+tm3blnLlyhEZGcmOHTsAaN68OTabjWvXrjFkyBBKlSqFt7e3S8L30KFDPPnkkxQtWhRfX18KFChAnz59OHLkSJKvM336dOrUqUOOHDkICwvjqaee4sKFC0lue6t/l61bt9KzZ08KFy7sfN327dszY8YMwNSY7du3LwB9+/Z1KQmR2OXLlxk2bBiVKlUiR44cBAUF0a5dO2f83mjHjh107tyZgIAAAgMD6dixI9u3b7/lZyvy/+zddXgUVxfA4d/GXdAAxd2Du2uQYi3aFihtKV+pUuo4BUoNWgp1pEgpUtyCuxMsOEGKS4gS3fn+uGSTJSSEkDCT5LzPs0+yM7OzZ5fDTXL2zrlCCCGE0clMWyGEEEKIbGTy5Mm8//77ODs706VLF4oUKcKVK1fYvn07CxcupGHDhrz++uuMHz+e33//ne7duyc7x2+//YadnZ2lwFasWDEuXrxIUFBQsoWpntbXX3/Npk2b6NSpE61bt8bW1jbd51q2bBndu3fHxsaGTp06UbhwYQIDA5kyZQpr165lz549eHt7p3qOl156iVGjRrFkyRJ69+5tte/27dusWbOGOnXqUKZMGQA+/fRTJk6cSMmSJenduzfu7u6W93v9+vWWIvTTeriw2a1bNw4fPkzbtm3x8vKiePHiAOzZs4c2bdoQERFBhw4dKF26NBcuXGDOnDmsXr2aXbt2UaJECct5Zs2aRd++ffHw8ODll1/Gy8uLFStW0LJlS2JiYnBwcEhTfIsWLaJ3795omkbHjh0pW7YsN2/eZM+ePfzxxx907NiRzp07c+/ePZYuXUqnTp0e2R7j7t27NG7cmOPHj9OgQQPefPNNQkNDWbp0Kc2aNWPBggVWbTaOHTtGgwYNCA8Pp2vXrpQuXZq9e/fSoEEDqlat+uRvtBBCCCGEUWhCCCGEECJbCAgI0GxsbLSCBQtqQUFBVvvMZrN25coVy30/Pz/NZDIlO+7YsWMaoHXu3NmyrWjRohqQ7Ni02LRpkwZoffv2tdo+YsQIDdBcXV21I0eOJHtcwv5NmzYl2zd9+nQN0KZPn27Zdvv2bc3Dw0MrVKiQduHCBavj582bpwHa4MGDHxvvmTNnNEDz8/NLtu/HH3/UAG3KlCmWbbly5dIKFiyoRUREJDv+zp07j30+TVPvr6OjY7Lt69ev10wmk+bq6qpFRkZqmqZpTZo00QDN19c32fljYmK0YsWKae7u7trBgwet9m3btk2ztbXVOnToYNkWEhKieXh4aK6urtqpU6esztO4cWMN0IoWLWp1nkf9u1y/fl1zdXXVXF1dkz2vpmna5cuXLd8/6t8uqd69e2uA9ttvv1ltv3Hjhla4cGEtb9682v379y3bE96P2bNnWx3/6aefakC681YIIYQQQm/SHkEIIYQQIpv45ZdfMJvNjB07NtmMWJPJRMGCBS3333zzTTRN448//rA67vfffwfg9ddft2zbsGEDJ06coFChQhke8xtvvEHlypWf+jyzZs0iNDSU8ePHU7RoUat9PXv2pHr16vz999+PPU+pUqWoV68e/v7+3Lx502rfX3/9hb29PT169LDa7uDg8MgZwrly5Upz/HFxcYwcOZKRI0fy+eef88ILL9C2bVs0TWPMmDE4OztbHT9q1Khk51+xYgUXLlxg6NChVKtWzWpfw4YN6dSpE6tWrSI0NBSAJUuWEBoayquvvmqZOQxgb2/Pl19+mebYZ86cSUREBEOGDEn2vADPPfdcms5z+/Zt5s+fT/PmzXnttdes9uXLl4+hQ4dy69Yt1q9fD8ClS5fYsmULVapUoU+fPlbHf/bZZ3h5eaX5NQghhBBCGI20RxBCCCGEyCb27t0LqF6oj9O+fXsKFSrE9OnTGTlyJLa2tsTExPDXX39RuHBh2rZtazm2ZMmSmRZz7dq1M+Q8u3fvBlR7gHPnziXbHxUVxe3bt7l9+/ZjF9J6+eWX2bVrF/PmzePdd98F4MyZM+zdu5eOHTtaPb5nz55MnTqVSpUq0bNnT5o1a0a9evWSFVkfJz4+nlGjRgFgY2ODt7c3zZs356233uL5559Pdvyj3reE9+DUqVOPXPTt+vXrmM1mTp8+Tc2aNTl8+DAAjRo1SnZsvXr1sLNL258KT5J3qdm3bx/x8fFER0c/Mv4zZ84AcPLkSTp06GCJv2HDhsmOdXNzw9fX96n7CgshhBBC6EWKtkIIIYQQ2URISAgmk4kCBQo89lhbW1tee+01Ro0axerVq+nQoQP//vsvd+7cYfDgwdjYPJsLsvLnz58h57l79y4AP/30U6rHRUREPLZo26NHD9577z1mz55tKdr+9ddfgCroJjV58mSKFy/O9OnTGTt2LGPHjsXJyYnu3bvz7bffPva5Ejg6OhIVFZWmY+HR71vCezBnzpxUHxsREQGofAE1i/Vhtra25M6dO02xJJznaWdiJ8S/Y8cOduzYkeJxaYkfMi63hBBCCCH0IO0RhBBCCCGyCS8vLzRN49q1a2k6/rXXXsPW1pbffvsNUK0RbGxsePXVVzMzTCsPL7CVIKFoHBcXl2xfQrEuKQ8PDwCOHj2Kpmkp3h5unfAouXLlol27duzfv59Tp04BMHv2bDw9PenYsaPVsXZ2dnz44YccP36cK1euMHfuXBo1asSsWbOSXbKfkR71viW8B8uXL0/1PWjSpAkAnp6eAMnaQICa+Xvnzp00xZLQhuDKlSvpeSnJ4h8yZEiq8Y8YMeKx8QPcuHHjqeIRQgghhNCTFG2FEEIIIbKJhEvm161bl6bjn3vuOdq3b8+qVavYuXMnGzZsoE2bNhQpUiQzw0wTb29v4NGFwEOHDiXbVqdOHQB27dqVIc+fMKN29uzZ7Nixg6CgIF544QWcnJxSfEzBggXp1asXa9asoVSpUqxfv5779+9nSDxp8aTvQdWqVQHYtm1bsn27du16ZMH8UZ4k7xJ6/8bHxyfbV6tWLUwm0xPHv3379mT7wsPDCQgISNN5hBBCCCGMSIq2QgghhBDZxJtvvomtrS1ffPEFFy9etNqnaRpXr15N9piBAwcSFxfHiy++iKZpVguQJTh37hwnT54kNjY202J/WK1atQC1wJjZbLZs37Vr1yMv/+/fvz/u7u58/vnnHD9+PNn+yMhIS8/XtGjfvj3e3t7MmTOHWbNmAclbI0RHR7Nz585kj42IiCA8PBx7e/tn1mYCoFOnThQpUoTvvvuOrVu3JtsfGxtrVeDs1KkTHh4e/Pnnn5w+fdrquC+++CLNz9u3b1/c3Nz49ttvH1koTVp4T1g87fLly8mO8/HxoXv37uzcuZOvv/4aTdOSHbNnzx4iIyMBKFKkCI0bN+bIkSPJcmLcuHHcu3cvza9BCCGEEMJopKetEEIIIUQ2UblyZSZNmsQ777xDxYoV6dy5M0WLFuX69ets3bqV9u3bM2nSJKvHtG3blqJFi3Lx4kV8fHySXf4P0KJFCy5evEhQUBDFihV7Jq+lbt26NGjQgI0bN1KvXj0aN27MxYsXWbp0KR07duTff/+1Oj5v3rzMmzePF198kapVq9K2bVvKlStHdHQ0Fy5cYMuWLdSvX581a9ak6fkdHR3p3r07v/zyC9OnT6do0aI0btzY6pj79+/ToEEDypQpQ40aNShSpAjh4eGsWLGC69ev8+GHH+Lo6Jhh70laYl64cCF+fn40adKE5s2bU7lyZUwmExcvXmTbtm3kzp2bkydPAqq9wA8//EC/fv2oVasWPXv2xNPTkxUrVuDs7Jym3sigesrOmjWLnj17Urt2bZ5//nnKli3L7du32bNnD8WKFWPJkiUAlkXaJk2aRHBwMHnz5gWwFImnTp3KqVOn+Oijj/jrr7+oV68eXl5eXL58mf3793PmzBmuXbuGi4sLoHoYN2jQgFdeeYUlS5ZQunRp9u7dy759+2jUqNEjZxELIYQQQmQFUrQVQgghhMhGBg8eTKVKlfj2229ZvXo14eHh5MuXjzp16tC9e/dkx9vY2PDyyy8zduxY+vXrh52dcX49XLp0KR988AErVqzg6NGjVK1aleXLl3P16tVkRVtQs2MPHTrE119/zfr16/H398fV1ZXnnnuO/v3789JLLz3R87/88sv88ssvxMbG0rt372R9ZF1dXfnqq6/YsGED27Zt4+bNm3h7e1O2bFnGjx9Pz549n+r1p0etWrU4fPgwX3/9NatWrWLHjh04OjpSqFAhOnfuTK9evayO79u3L56enowdO5aZM2fi6enJ888/z8SJE6lWrVqan7dLly7s2bOH8ePHs2XLFpYtW0aePHnw9fW1mr2dK1cuFi5cyMiRI/ntt98s7SMSira5cuVi586dTJkyhfnz5zNnzhzMZjM+Pj5UrVqVYcOGWS3uVqlSJXbs2MHHH3/MmjVrWLt2LQ0bNmTHjh188803UrQVQgghRJZl0h513ZEQQgghhMgxOnTowKpVqzh9+jSlSpXSOxwhhBBCCCFyPOlpK4QQQgiRgwUGBrJq1SpatWolBVshhBBCCCEMwjjXvwkhhBBCiGdm7ty5nDp1yrLI1ogRI3SOSAghhBBCCJFAirZCCCGEEDnQr7/+yrZt2yhatCh//PEH9evX1zskIYQQQgghxAPS01YIIYQQQgghhBBCCCEMRHraCiGEEEIIIYQQQgghhIFIe4R0MpvNXL16FXd3d0wmk97hCCGEEEIIIYQQQgghDE7TNMLCwihYsCA2NinPp5WibTpdvXqVwoUL6x2GEEIIIYQQQgghhBAii7l8+TLPPfdcivulaJtO7u7ugHqDPTw8dI4m861evRo/Pz+9wxAiRZKjwugkR4XRSY4Ko5McFUYnOSqMTnJUGF1OydHQ0FAKFy5sqS2mRBYiS6fQ0FA8PT0JCQnJEUXbO3fukDt3br3DECJFkqPC6CRHhdFJjgqjkxwVRic5KoxOclQYXU7J0bTWFGUhMpEmqfXYEMIIJEeF0UmOCqOTHBVGJzkqjE5yVBid5KgwOslRa/JuiDTZvn273iEIkSrJUWF0kqPC6CRHhdFJjgqjkxwVRic5KoxOctSaFG2FEEIIIYQQQgghhBDCQKRoK4QQQgghhBBCPKmRI2HMmEfvGzNG7RdCCCHSyU7vAHKC+Ph4YmNj9Q7jqVSoUIGoqCi9w8hW7O3tsbW11TuMbKNKlSp6hyBEqiRHhdFJjgqjkxwVhmNrC8OHq++HDUvM0TFj1PbRo/WLTYhHkHFUGJ3kqDWTpmma3kFkRWlZ6U3TNK5fv05ISAhZ/W3WNA2TyaR3GNmKyWTC09MTHx8feW8zQGxsLPb29nqHIUSKJEeF0UmOCqOTHBWGlFCgff554j78ELvNmxMLtsOG6R2dEFZkHBVGl1NyNC01RZCibbql5Q2+d+8e165dI2/evLi6umbpwlxoaGiqiSSejKZpREREcOvWLQoUKICXl5feIWV5y5cvp2PHjnqHIUSKJEeF0UmOCqOTHBWGFBMDvr5w4gQaYAIYNSpxBq4QBiLjqDC6nJKjaS3aSnuETKJpGjdv3sTDw4M8efLoHc5Ti4qKwsnJSe8wshVnZ2eio6O5efMmnp6eWbqoL4QQQgghRI4TFQUvvAAnTgAPCrYA8neTEEKIDCALkWWS+Ph44uPjZXaqSJWHh4clV4QQQgghhBBZREQEdOwIK1eCnZoLZbZ58Of1rVs6BiaEECK7kKJtJomLiwPAzi57TGZ2dHTUO4RsKSE/EvJFpF/JkiX1DkGIVEmOCqOTHBVGJzkqDOX+fbh6FeztIS4ORo/m5NGj8MUX8M03qtctwO3b+sYpRBIyjgqjkxy1JkXbTJZdLnl3dnbWO4RsKbvkhxFUqFBB7xCESJXkqDA6yVFhdJKjwlDy5IH27SE21rLoWIUKFVSxdvRo1dO2e3coUQKWLdM7WiEAGUeF8UmOWpOirUiTkJAQvUMQIlXr1q3TOwQhUiU5KoxOclQYneSo0N2dO7BoUeJ9FxdLwRaS5OiwYWoxsoAACAuDzp1hwgSQNcCFzmQcFUYnOWpNirYiTTT5BUMYXHR0tN4hCJEqyVFhdJKjwugkR4WubtyApk3hxRfh77/VtpEjYdgwFi+GqlWhQ4cWVK0KixejZtoePw5vvaWKtZ9+Ci+/rBYvE0InMo4Ko5MctSZFWyGEEEIIIYQQIiX//QeNG8OxY+Djoyq0DyxeDN26wdGjEBtry9Gj6v7ixah+t1OmwNSpYGsLc+aowu+1a7q9FCGEEFmHFG1Fmtjb2wOqB2tabps3b9Y3YJHj5M+fX+8QhEiV5KgwOslRYXSSo0IXFy6ogu3p01CkCGzdCuXLW3aPGgUmU2LnA01T90ePTnKOQYNg3Trw9oY9e6B2bQgOfqYvQwiQcVQYn+SoNZMm172nS2hoKJ6enoSEhODh4ZFsf1RUFEFBQRQvXhwnJycdIswcs2fPtro/a9Ys/P39+euvv6y2t2rVSv6zpUF2zRMhhBBCCCGyvDNnoEULuHxZLSi2cSMULWp1iIODWovsYU5OcP/+QxvPnoXnn1e3CRMyL24hhBCG9riaYgK7ZxiTyMLCw8Nxc3PjpZdestq+e/du/P39k21/WGRkJC4uLpkZosjhdu7cSf369fUOQ4gUSY4Ko5McFUYnOSqeqZs31Qzb69ehXDlYvx4KFbI6ZPHiRxdsAby8wGwGm6TXtpYqpWbaJv27KDQU3NweOlCIzCHjqDA6yVFr8pMhi0locu/sTGKT+2cgLi4uzcc2bdqUSpUqceDAARo3boyLiwufffYZoNorjBw5MtljihUrRr9+/ay23bt3j/fee4/ChQvj6OhIqVKl+OqrrzCbzU/zUkQ2defOHb1DECJVkqPC6CRHhdFJjopnKm9eeOklqFwZNm9OVrD980+1JlkCk8n64devQ/v2cPv2Q+d1d1f9bQGio8HPD7p3h4iIDH8JQjxMxlFhOCNHwpgxlrtWOTpmjNqfg8lM22dM0yAyMn2PXboU+vRJ7JmU0OR+zhzo1Cl953RxSf4LRka4c+cOfn5+9OzZk5deeumJWyVERkbSpEkTrly5wsCBAylSpAg7d+7k008/5dq1a0yaNCnjgxZCCCGEEEIIUH8kTZwIw4erQmsS334LH36ovh8wANq2hbFjITAwngoVbGnQQBV116wBX1/4+29o2PARz7F3L+zfDzExcO6c+oOvSJFMf2lCCGEYtrZqnAUYNixx+5gxartVg/CcR4q2z1hkpLr65WkkbXIPqpCbXuHh4Or6+ONsnvBynevXr/Pzzz8zcODAdMX13Xffce7cOQ4dOkTp0qUBGDhwIAULFuTrr79myJAhFC5cOF3nFtmTa1oSWQgdSY4Ko5McFUYnOSoy3c6d8N13MHu2akprMlkVbDUNvvgCxo1T94cOha++Uoe98AJs3LiF5s2bAzBwoJqJe/o0NG0KX36pjrf6s6pRI9i0Cbp0gYAAqFUL/v0X5NJgkUlkHBWGk1CofVC4dW3QwLpgm7SQmwNJewSRJqk1Rn4UR0dH+vfvn+7nW7BgAY0aNcLb25vbt29bbi1btiQ+Pp6tW7em+9wie0r4BVkIo5IcFUYnOSqMTnJUZKpNm6B1a1i0SFVYH2I2w1tvJRZsx49XE3GTXrWYNEerVFGTaHv3hvh4+OQT6NDhEe0S6teHfftU77ubN6FZM5g5MxNeoBAyjgqDGjZM3YYPp7mfnxRsk5Ci7TPm4qJmt6bnVqlS8lYGJpNqs5Tec6Z1bbDIJ+zpUKhQIRwcHJ7oMUmdOXOGNWvWkDdvXqtby5YtAbh582a6zy2yp8OHD+sdghCpkhwVRic5KoxOclRkmjVroF071Ve2dWv49FOr3TEx6urGadPU318//6yKsA97OEfd3dWk3d9+UxN3V69W7RJ27HjogUWKwPbtasZtTAz066dm/AqRwWQcFYZ04gQsWaIG2JgYcHCQgu0DUrR9xkwm1Y4gPbdRo9QlOQmF24TetqNGpf+cae1nGxMT80Sv09nZ+YmOj4+Pt7pvNptp1aoV/v7+j7x169btic4vsr9Lly7pHYIQqZIcFUYnOSqMTnJUZIqlS9UCIVFR0LGjup9kZktkJHTurPrS2tvDvHmq9cGjPCpHTSZ47TXYswfKlIErV6BJEzVL12p9ZTc3WLhQFSpy5VKxCJHBZBwVhrNgAdSsqRZt0jTMtraqcJtkcbKcTHraZiFdu6qrdUaPhlOnoGxZGDFCfSCbVXh7e3Pv3j2rbTExMVy7ds1qW8mSJQkPD7fMrBVCCCGEEEKIDPXPP2oKbVycako7Z46a4fXAvXuqdrp9Ozg7w+LFatGx9EholzBwoCr8fvwxbNmiOiHkyfPgIBsb9cfeO+8k2YiaASy9SIUQ2VGhQnD/vvp+6FBWNmpEx4CARy9OlgPJTNsspmtX1aP+/n31NSsVbEEVYx/uR/vrr78mm2nbvXt3du3axdq1a5Od4969e8TFxWVqnEIIIYQQQohsLCQE/vc/VbB96SVVSU1SsL1xQ7WX3b4dPD3B3z/9BdsE7u6qLvzrr+DoCKtWQbVqj2iXkLRgu24dlCiheu4KIUR2EBqa+P2GDYmXkE+cqLYNG6Y+wBo+PMfPuJWirUgTLy+vDDnPa6+9xqFDh+jWrRs///wzgwYN4rvvviNP0l9MgKFDh1K9enU6dOjA66+/zs8//8y3335Lv379eO6555LN1hWio1xCJgxOclQYneSoMDrJUZGhPD1h5Uo1q3XGDLBLvAj14kVo2FBNksmfX82IbdDg8adMS46aTPD666pdQunS8N9/ql3C118/1C4hwXffqQXKWrdWzXSFeAoyjgpdaRpMmQJFi8KxY2pbfHxigZYkOZpQuH1ogl9OI0VbkSZRUVEZcp7XX3+djz/+mK1btzJkyBCCgoLw9/fH9aHLfVxcXNiyZQtDhw5l8+bNvPvuu0yYMIEzZ84watQoPD09MyQekX2cO3dO7xCESJXkqDA6yVFhdJKjIkPcuJH4fZ06MHky2NpaNgUGqgLt2bOqrrBtG1StmrZTP0mOVq0KBw5Az56qJvHRR/D883DnzkMH/vsv9O6tZgQPGgSDB0NsbJqfR4ikZBwVugkOhm7d4O23Ve+ZP/9U20eOhGHDWLxYjYuOjmaqVlXtaBg2TO3PwaRoK9IkpaLtlClT0DTNatvmzZs5lvCpyUNsbGyYMGECt27dIiIigjVr1lCyZEkuXLjAjBkzrI51c3Nj3LhxnDlzhujoaG7dusWOHTsYMmQI9vb2GfK6RPYRGBiodwhCpEpyVBid5KgwOslR8dS++kotDHLgwCN379sHjRurxcIqVFBtC0qXTvvpnzRH3d1h7lz45RfVLmHlStUuYdeuJAc5O8Ps2TBunLr/00/g5wd37z7RcwkBMo4KnezaBb6+6kMoe3uYNAm+/daye/FiVc89cgRiYmw4elTdX7xYt4gNQ4q2QgghhBBCCCGyL01Ts7U++UT1svX3T3bIpk3QvLma6VqrFmzdqtbHyWwmE7zxBuzerQrEly+rwvE33yRpl2AywaefwpIlakGyDRvULOFk03KFEMJAzGb1YVmjRnDpEpQqpQq4776rxrUHPv3U+mGapnaPHv2M4zUgKdoKIYQQQgghhMieNE0Va0eNUvfHjVP3k1i6VE1eDQ9XhdsNGyB37mcbpq8v7N8PPXqoTghDh0KnTg/VZTt1gp07Vd+Gxo0hV65nG6QQQjyJ2bPVeBsfD716qascatSw7I6LU0Py6dPJH6ppcOrUM4zVoEzaw9e2izQJDQ3F09OTkJAQPDw8ku2PiooiKCiI4sWL4+TkpEOEGSs+Ph7bJL2eRMbIbnmip/DwcNzc3PQOQ4gUSY4Ko5McFUYnOSqemNkM770HP/6o7n//vbqfxKxZ8OqrqqbQuTPMmwfp/bU8I3JU0+DXX9VEtOhoKFwY5s+HevWSHHT7tuqt4Oio7kdHg4OD1cw1IR5FxlHxTMXHq2bdXbuqgTbJGBUYCH37qg+rHsVkgipV1IKQ2dHjaooJZKatSBPzI5cyFcI4IiIi9A5BiFRJjgqjkxwVRic5Kp6I2QxvvplYsP3552QF28mTVdEgPh769YMFC9JfsIWMyVGTCQYOVO0SSpVKbJfw7beqoAtAnjyJBdv4eOjSBV57TRVvhUiFjKMiU8XFwZQpkLAmkq0trFgBAwZYCrZxcapjQrVqqmDr5aXWJoPEmq7JpMa7ESOe/UswGinaijSRwV0Y3d69e/UOQYhUSY4Ko5McFUYnOSqeSGwsXLwINjYwY4aqhD6QUAxIqOG+/z788QfY2T3dU2Zkjvr6qiuJu3dXRY4PP1TdEZKtP7ZjB6xdq1Zib9kSbt7MsBhE9iPjqMg0//2n+su8/bbq75IgyezakyehYUPVMSEmBtq1g2PH4IcfYNEiNbPW3j6eKlXUImRduujwOgxGirZCCCGEEEIIIbIXR0e1Uvnq1Wo67QNms2o9kLDAzdixaharjQH/MvbwgL//hqlTVfeD5cvV7LTdu5Mc1LgxrFypDt6+HWrXVkuwCyHEs7Jihfqkads21bqlfn2r3fHxapz19YU9e9Rw9eef6mEJCz527apaISxatIqAACnYJjDgjyYhhBBCCCGEEOIJRUfDzJmJfQRcXKB1a8vu2FhVv03omDBlCnz+ubFbwZpMMGiQKtSWLKkWYG/UCL77Lkm7hLZtVSWkVCk1u7h+fViyRM+whRA5QUyMulShY0e1amKNGnDwoFp07IHTp9VnSx9+qIbo1q3V7Nr+/Y099hqFFG1Fmri6uuodghCpqlWrlt4hCJEqyVFhdJKjwugkR0WqIiNV/4B+/RKn0SZx/z5066YWM7ezgzlz4K23MjaEzMzRatVULeTFF1W7hCFD1MJplnYJ5cqpwm2LFhARoaap/fRTpsUjsiYZR0WGCQqCBg1g0iR1/733VLuWUqUAdVXD5Mlqdu3OnWoC7m+/wZo1aoHFlEiOWpOirUgTGyNeLyREEu7u7nqHIESqJEeF0UmOCqOTHBUpCg+H9u1Vb1cXFzUVNYnQUPDzU+0FnJzUJNTevTM+jMzOUQ8PmD8/sV3CsmVQvbqq1QKQK5dqBzF4MDg7Q716mRqPyHpkHBUZxsYGzp5V487SpfD995YFEs+dg6ZNVR33/n31WdLRo2q9xMfNrpUctSaVOJEmYWFheocgRKo2btyodwhCpEpyVBid5KgwOslR8UghIdCmDWzerKZyrV2rFsN54NYtaNYMtmxRRc+1a1V9NzM8ixxNaJewa5dql3DxolrY5/vvH7RLsLdX/R+OHVMV3QSxsZkemzA+GUfFU4mPT/y+aFG1WlhAADz/PKBm106ZohYU27YNXF1h2jTw91eHp4XkqDUp2gohhBBCCCGEyHru3oWWLdW1t15esH69qmA+kND/9eBByJsXNm1SvRWzg+rV4cCBxHYJH3ygOiIEBz84oESJxIP37IHy5WH/fl1iFUJkA4GBqk/L6tWJ25o1s/Q6CApSM2rfflt1q2naVM2uffNN6V37NKRoK7KkYsWK0a9fP8v9zZs3YzKZ2Lx5s24xPezhGIUQQgghhBAZJC5OFWz374c8eVRFtnZty+5Tp1T99tQpVVPYvt164ml24Omp2iX89JNql7B0qaqp7N370IGff66uV27UCP7+W5dYhRBZlKbBn39CzZqqCvvxx2pK7QNms5pNW7myuuDBxUVN9t+wAYoX1y/s7EKKtiJNnJycrO7PmDEDk8lkuTk5OVGmTBkGDx7MjRs3dIryya1atYqRI0fqHYbIAOXLl9c7BCFSJTkqjE5yVBid5KiwYmenercWKKAqBb6+ll0HD6r65OXLULasWhunTJnMD0mPHDWZ4H//U5ONS5RIbJcwadKDdgmgLmFu3x6iotSq7sOGWRVdRM4h46h4IqGh8NJLMGCAak7bqpXqdfBgzaOLF6F1azUGRUSocffIETU0p3dZJMlRa1K0FWnycNE2wejRo/nrr7+YMmUK9evXZ9q0adSrV4/IyMhnGl/jxo25f/8+jZ/weqdVq1YxatSoTIpKPEulHqxSKYRRSY4Ko5McFUYnOSqSefVVNZW2YkXLpq1b1WW5t26pmbXbtqW+UnlG0jNHa9RQxepu3VT72vffh65dH7RL8PBQ03CHDlUHjx0LL7ygFnATOYqMoyLNDh5UA8vcuWBrC+PHw5o1kD8/mga//aZm127YoNY9nDRJfX5WsuTTPa3kqDVDFW23bt1Kx44dKViwICaTiSVLlljtX7x4Ma1btyZ37tyYTCYCAgKSnSMqKoq33nqL3Llz4+bmRrdu3ZLN/Lx06RLt27fHxcWFfPnyMXToUOLi4jLxlWWAkSNhzJhH7xszRu3PRPfu3Xvkdj8/P1566SVee+01ZsyYwXvvvUdQUBBLly595PERERGZEp+NjQ1OTk7YpPfjHJHlrVixQu8QhEiV5KgwOslRYXSSo4Lz56FdO7h5M3FbkpXGV65Ua5KFhUGTJqpjQt68zy48vXPU0xMWLFCXJjs4wJIlqnC9dy+q6DJxIsyYoXb++y80aAB37ugas3i29M5RkUWcOQP16sHZs+pTry1b4JNPwMaGy5fBzw/eeEONtfXrq7XI3n03/bNrk5IctWaoCldERARVq1blp59+SnF/w4YN+eqrr1I8x/vvv8/y5ctZsGABW7Zs4erVq3Tt2tWyPz4+nvbt2xMTE8POnTuZOXMmM2bMYPjw4Rn+ejKUrS0MH568cDtmjNpua6tPXA9p/mCl1qCgIPr164ebmxvnzp2jXbt2uLu706dPHwDMZjOTJk2iYsWKODk5kT9/fgYOHEiwpXO+omkaY8eO5bnnnsPFxYVmzZpx/PjxZM+bUk/bPXv20K5dO7y9vXF1daVKlSpMnjwZgH79+llyLWmrhwQZHaPIXJrl+i8hjElyVBid5KgwOsnRHO7UKbWK2OrV6lrch8yZA507qw4AHTuqwzw8nm2IRshRk0ldmrxjh+oneeGCapcwefKDdgl9+6rpcPnyqQO8vXWOWDxLRshRkQWULq3aInTurCqyDRqgaTB9OlSqBGvXgqMjfPuturohI9vPSI5as9M7gKT8/Pzw8/NLcf/LL78MwIULFx65PyQkhD/++IO5c+daiofTp0+nfPny7N69m7p167Ju3ToCAwNZv349+fPnx9fXlzFjxvDxxx8zcuRIHBwcMvx1PVJqM05tbSFpO4KICLUcaEyMKtDGxKhPOSZMUJe2jB6t+hI97rw2NmreeiY6d+4cALlz5wYgLi6ONm3a0LBhQ7755htcXFwAGDhwIDNmzKB///688847BAUFMWXKFA4dOsSOHTuwt7cHYPjw4YwdO5Z27drRrl07Dh48SOvWrYmJiXlsLP7+/nTo0IECBQrw7rvv4uPjw4kTJ1ixYgXvvvsuAwcO5OrVq/j7+/PXX38le/yziFEIIYQQQgjxGMeOqUXHbtxQrRCmTLHa/dNPqlAJqs7w55/w4Ff1HKtmTXV182uvwaJF8N57qlb755/gXa+eWsDN2ztxapzZnDHT5IQQWdOuXaq3Qb586v60aWogNZm4ckXNrF21Su2qU0dN2i9XTrdocw7NoADt33//feS+oKAgDdAOHTpktX3Dhg0aoAUHB1ttL1KkiPbdd99pmqZpw4YN06pWrWq1//z58xqgHTx4MMV4oqKitJCQEMvt8uXLGqCFhIQ88vj79+9rgYGB2v3791N6gSnf2rWzPtbFJeVjixWzPjZPnpSPrVkzxdf3OBEREVb3p0+frgHa+vXrtVu3bmmXL1/W/v77by137tyas7Oz9t9//2l9+/bVAO2TTz6xeuy2bds0QJszZ47V9jVr1lhtv3nzpubg4KC1b99eM5vNluM+++wzDdD69u1r2bZp0yYN0DZt2qRpmqbFxcVpxYsX14oWLZosH5Ke66233tIe9d8gM2J8lMfmiUizgIAAvUMQIlWSo8LoJEeF0UmO5lAHDmha7tzq7xlfX027dcuyy2zWtDFjEv/cefttTYuP1y9UI+ao2axpP/6oafb2iX8+7t37iINeeknThgzRtLg4XeIUz4YRc1ToLD5e08aP1zRbW01r29ZqEDWbNW3mTE3z8lLjh4ODpn31VeYOEzklR0NCQlKtKSYw1Ezbp3X9+nUcHBzw8vKy2p4/f36uX79uOSZ//vzJ9ifsS8n48eMfuWDV6tWrLbNHW7VqxZ07dzh48CB2dnbky5eP2NhY7OzsCE/S5N3Z2RnHVF5HbGwsEffuYWdnh5ubGxpgSuHYuEKFCL93D09PT2JiYrDXtBR7XsTFx2OOicHW1pawsDDLdicnJ5ycnKz61jo4OODi4kJYWBjx8fGAai3h7u5ORESEZaGxli1bWj1H4cKF+eWXXyhQoADmByuS9u7dm3v37uHm5gbA7Nmz8fDwoHbt2ly5cgV7e3vCwsIoVaoUbm5u+Pv707t3b5YtW0ZMTAz9+/cnMjISV1dXwsPD6d+/P+PGjSM2NhaAyMhIy/ub8HX37t0EBQUxbtw4S+xms9mqp66rq6tl6n3Ca094L5LGeOnSJVxcXAgPuis4zAABAABJREFUD7fEuG7dOnr37s2KFSssMYaGhuLp6cn9+/ctMcbExGA2m4mLi7NanC3hvQgNDSUyMpJNmzZRqVIl8ufPz9q1ay3HlSpVivLly7N27VrLzF0fHx9q1arFjh07uHv3LgDu7u40bdqUw4cPc+nSJUC1fOjQoQNnz57lxIkTlnM2b96csLAw9u3bZ9lWu3ZtXF1d2bRpk2VbhQoVKFmyJMuXL7dsK1KkCFWrVmXjxo2W9zJ37tzUr1+fvXv3WvpHOzo60rp1awIDAy2zrwHatm3L1atXOXLkiGVbw4YNMZvN7Ny507KtWrVq5M2bl3Xr1lm2lS5dmnLlyrFmzRrLv32BAgWoWbMm27dvJzg4mEuXLlnei4CAAC5fvgyonsft27fnzJkznDx50nLOFi1aEBISwv79+y3b6tSpg5OTE1u2bLFsq1ixIsWKFWPlypWWbcWKFaNy5cps2LDB8m+bJ08e6tWrx549e7j5oNeak5MTrVq14vjx45w/f97yeD8/P65cuWL1XjRq1Ii4uDh27dpl2Va9enVy586Nv7+/ZVuZMmUoW7Ysq1evtvTjLliwIDVq1GDbtm2WfPb09KRx48YcPHiQK1euAGBra0u7du04ffo0p06dspyzZcuWBAcHc+DAAcu2unXr4ujoaPVeVKpUiSJFirAq4WNWoHjx4lSqVIn169dz//59APLmzUvdunXZvXs3t27dAtTY17JlS44dO0ZQUJDl8e3atePSpUscO3bMsq1JkyZER0eze/duy7YaNWrg7e3N+vXrLdvKli1LmTJlWLVqlWWsKlSoENWrV2fr1q2EhIQA4OXlRaNGjThw4ABXr14FwM7ODj8/P06dOsXp06ct50w6lieoV68ednZ2bNu2zbKtSpUqFCpUiNWrV1u2lShRgooVK+Lv709UVBQA+fLlo06dOkRGRlr+P7m4uNCiRQuOHj1qdfVI+/btuXDhglWLlSZNmhAVFcWePXss22rWrImnpycbNmywbCtXrhylS5dm5cqVlvG3cOHC+Pr6snnzZsu47+3tTcOGDdm/fz/Xrl0DwN7enrZt23Ly5EnOnDljOWfr1q25desWhw4dsmyrX78+NjY2bN++3eq9KFiwIGvWrLFsK1myJBUqVGDdunVER0cD6udt7dq12blzJ3ce9NBzdXWlefPmVuMXQMeOHTl37hyBgYGWbc2aNSMiIoK9e/dattWqVQt3d3c2btxo2Va+fHlKlSrFihUrLON8wviV9L3IlSsXDRo0YN++fZbfARwcHGjTpg0nTpzg7NmzlnO2adOGGzduWPXTb9CgAQA7duywbPP19ZWx/IH0juVJ3wsZy2Usf3gsB3Qdy3ft2sXt27cBGcufyVh++zaxLVtiHxFBcJkyXPnhByrlycPmzZsJCQnjzz8rsmxZCQBee+0KLVseZOVKfcfy4OBgw43lgwe3Jl++87zzTn4uXHClfn0zEydqdOnyH0ePHiFXYCANZs8GIObwYTYMGECcqysgY3l2HMsvXbqk+1iu9+/lMpY/GMuLFuVex454PRiDrsfE4BMdzeHTpwkIuMHUqVXYu9cHgMqVoxg4cBdFioSzalXm/V4eExNjGeuy8+/lSetDqXoWFeT0IB0zbefMmaM5ODgkO75WrVraRx99pGmapr3++uta69atrfZHRERogLZq1aoU48nwmbbh4SnfHn5M0n1ffJH4EQdo2rBhaT9vZGSKr+9xQkNDre4nzLT96aefNH9/f23Tpk1aYGCgFp/kU5m+fftqdnZ2Vts0TdP8/Pw0IMXb888/r2mapo0fP14DtHPnziWLx9vbO9WZtn///bcGaP7+/qm+rpRm2mZGjI8iM20zTsK/vRBGJTkqjE5yVBid5GgOEx+vZtaCpjVsqGlJ/u6KjdW0fv0SZ9hOmqRjnEkYPUeDgzWta9fE961rV7VN0zRNmz9f05yd1Y7y5TXtzBkdIxWZxeg5Kp4hf39Ny59f/Z93dta0P/7QNLNZM5s1bc4cTfP2Vrvs7TXtyy/VuPss5JQczZEzbX18fIiJieHevXtWs21v3LiBj4+P5ZiknwQk7E/YlxJHR0ccHVObH/uEHnxy+UTHjhlj3cM2YREye/vEnrZPct4nkPBJ2cNq165NzZo1U3yco6MjNg/1RjKbzeTLl485c+Y88jF5n+USrynICjEKa0lnjwthRJKjwugkR4XRSY7mMDY2sGSJ+ntn6lTL3zlRUdCrl9pla6t6tL7yiq6RWhg9R728YOFC+PFH+PBDWLwYDh2Cf/6Bmt27q36WnTrBiRNQu7Y6+MFaMSJ7MHqOimcgLg5GjoRx49TnNxUrwvz5ULEiN27AoEHw77/q0OrVVe/aypWfXXiSo9ayVdG2Ro0a2Nvbs2HDBrp16wbAqVOnuHTpEvXq1QPUVPovv/ySmzdvku9Bg2V/f388PDyoUKGCbrE/VkKBNumiYwlfhw+3vm9wJUuWZP369TRo0ADnVBZGK1q0KABnzpyhRIkSlu23bt2yXHKT2nMAHDt2LFkLh6RMpkc3nngWMQohhBBCCCEecuMGJLSzK1oUZs607AoLU4uZb9yoVi7/5x94/nl9wsyqTCZ45x2oVw+6d4egIKhfX60CP3hwDUz79qk3ee9eaN0afv0VXn1V77CFEBnl/n1VpNU0tbrY99+Diwvz58Nbb8GdO2Bnp8pMn3wiizrqzVDLQ4aHhxMQEGDpSxEUFERAQIClf8Tdu3cJCAiw9EQ6deoUAQEBlj50np6eDBgwgA8++IBNmzZx4MAB+vfvT7169ahbty6g+oBUqFCBl19+mcOHD7N27Vq++OIL3nrrrYydSZvR4uOtC7YJhg1T21OYCZtR7Owyrr7fvXt34uPjGTNmTLJ9cXFxlr4/LVu2xN7enh9//NHS+wRg0qRJj32O6tWrU7x4cSZNmmTVqxewOpfrg0/sHz7mWcQoMlauXLn0DkGIVEmOCqOTHBVGJzmaAyxaBMWLJ07zSuLOHWjRQhVs3dxg9WrjFWyzUo7WqqVm2XbpArGxqpD74osQ4lIAtmyBPn1Uhbd4cb1DFRkoK+WoyCTu7vD33+r2yy/cinDhxRehZ081zlatCvv2qVKTHgVbydGHPIteDWmV0Jf04VtCX9CEPqoP30aMGGE5x/3797X//e9/mre3t+bi4qJ16dJFu3btmtXzXLhwQfPz89OcnZ21PHnyaEOGDNFin7BBx+P6T2T3XqUJ/xb79u1L8Zi+fftqrq6uj9w3cOBADdD8/Py077//XpsyZYr27rvvagULFtQWLFhgOe7TTz/VAK1du3balClTtAEDBmgFCxbU8uTJk2pPW03TtDVr1mj29vZa0aJFtZEjR2q//PKL9v7771v1NP7nn380QHv55Ze12bNna/Pmzcu0GB8lu+eJEEIIIYQQaTJnjlq9HDTtlVesdl2+rNqsgqblzq1pqfwJIp6Q2ax6Atvbq/e3RAlN27//wY6DB5MfLITIWqKjNe399zXtxx+T7Vq4UNPy5lX/921tNW34cHW4yHxp7WlrqKJtVpLTirbh4eFW95+2aKtpmvbrr79qNWrU0JydnTV3d3etcuXK2kcffaRdvXrVckx8fLw2atQorUCBApqzs7PWtGlT7dixY1rRokUfW7TVNE3bvn271qpVK83d3V1zdXXVqlSpov2YZLCKi4vT3n77bS1v3ryayWRKtihZRsb4KNktT/S0d+9evUMQIlWSo8LoJEeF0UmOZmN//KFpJpOqHPTrp2lxcZZdp09rWtGialehQpoWGKhfmI+TlXN0zx5NK1Yscc3rH398qEYbGKhpNWoY+x9APFZWzlGRDmfPqv+3oGmOjpp25YqmaZp2+7am9eyZuChh5cqaduCAzrE+kFNyNK1FW5OmJbmmW6RZaGgonp6ehISE4OHhkWx/VFQUQUFBFC9eHCcnJx0izFgPL+4mMkZ2yxM9LV++nI4dO+odhhApkhwVRic5KoxOcjSb+uknGDxYfT9oEEyZohYhAw4fhjZtVJvb0qXB31+1uTWqrJ6jwcGqfe2SJer+Cy/A77+DpyfQqhWsXw8eHuqyaj8/PUMV6ZTVc1Q8gb//Vj1rw8IgVy61oljHjixZAm++qcZVW1vVt3bYMNUn3AhySo4+rqaYwFA9bYUQQgghhBBC5BBq9Sv1/fvvqwLug4Ltjh3QpIkqLPj6wrZtxi7YZgfe3rB4MUyapHpZLlyoVo8/eBCYOxcaNYLQUOjQAb77Tk3SE0IYS2SkKtb26qUKtg0bQkAAdxt05KWXVB/rGzegQgXYtQvGjjVOwVYkJ0VbkSYmk0nvEIRIlYODg94hCJEqyVFhdJKjwugkR7MZTYNz59T3n32mCrgP/uZYvVpN7AwJUfWGTZsgf34dY02j7JCjJhO8+y5s366K5OfPQ716MHVBXjT/9fDaa2A2w5AhMGAAREfrHbJ4AtkhR0UqYmOhQQP47Tf1n/mLL2DTJlYcLkzFijBnjvpc7OOP4cABtSCh0UiOWpP2COmU09ojiMwheSKEEEIIIXIssxlWroQkl8LOnw8vvQRxceoK/IULwcVFxxhzsLt3oX9/WLZM3X/xRfjtVw3PmT/ABx+of78GDdQBsuK7EMbw1Vfw/fcwZw73arTgvfdg5ky1q2xZ9X2dOrpGKJD2CCKD3b9/X+8QhEjViRMn9A5BiFRJjgqjkxwVRic5mg1oGkyfrmaDgZrylaRg+8sv6oreuDjo2VP1Vs1KBdvslqO5cql/g+++Azs7WLAAatQ0cbDRu7BqlWp2a2cH7u56hyrSKLvlqEC1QDh/PvH+0KFw7BirY1pQsaIq0ppM8OGHcOiQ8Qu2kqPWpGgr0iRaLnsRBnf27Fm9QxAiVZKjwugkR4XRSY5mcWaz6l/76qtqKm2SCz41DcaPV4vjaJpaj2z2bMhqV8lmxxw1mVS74e3boUgR1dGiXj2Yeq4N2u49aiq0vb06WC7iNbzsmKM52sGDqvF0x46qly0QEmbDgI/z0K4dXL2qFnHcvh2+/hqcnXWONw0kR61J0VYIIYQQQgghROaJj1e9UKdOVVXA1q0t/Ws1TfVX/Owzdejnn6v1yGxtdYxXJFOnjpql9/zzEBMDb70FPUeUJdQhT+JBQ4bAl19K8VaIzKZp8MMP6hOUs2chPBwuXWLdOqhUCf78Uw2x770HAQFQv77eAYv0kqJtJpOWwSI1kh9CCCGEECJbi42Fl19WbRFsbGDWLLWAFaqW+/rragYYqLXIxo611HOFwSS0S/j2W9UV4Z9/1CS/Q4dQy9B//71a+Kh3b5D2ekJkjrt3oUsXtWJgTAx07kzY1kMM/L4cbdrAf/9ByZKwZYv6L5mVWsyI5GQhsnR6XNPg+Ph4Tp8+Tb58+cidO7cOEWYss9mMjY3U+DPanTt3uHnzJmXKlMFWphM8lZiYGFlpUhia5KgwOslRYXSSo1lQTIxqTvvvv6rKN28evPACANHR0KcPLFqkarm//aY6J2RlOSlHd++GHj3g0iVwdIRJk2Cg6VdMg99STYlr1lQV3kKF9A5VJJGTcjRb2rFDNf6+fFn1j/n2WzaUe4sBr5m4eFEd8vbbqt2Mq6u+oaZXTsnRtC5EZvcMY8pRbG1t8fLy4ubNmwC4uLhgysIfGeeU/zjPiqZpREZGcvPmTby8vKRgmwFu3LhB4cKF9Q5DiBRJjgqjkxwVRic5mgW9/LIq2Do4qN6nDxYdCw+Hrl3B31/tmjdP3c/qclKO1q2rZtj26wfLl6s+xJt7vMEfS8rg2vcF2L8fatWCpUvVV2EIOSlHsx1Ng5EjVcG2VCkiZ/zDh3OqMe1ttbtYMXVBQ9OmOsaYASRHrUnRNhP5+PgAWAq3WVlkZCQuMq8+w3l5eVnyRDydgIAAGdyFoUmOCqOTHBVGJzmaBb35Jqxfr6qyrVsD6sre9u3VTE1XVzUZs2VLfcPMKDktR3PlUjXZ776DTz6B+fPhwIGmLJ2xlwqfPA/Hj0PjxjBjhpqWK3SX03I0WzGZYOZMGDuWbR2+ou/L7gQFqV2DBsHEieDmpm+IGUFy1JoUbTORyWSiQIEC5MuXj9jYWL3DeSqbNm2iWbNmeoeRrdjb28sMWyGEEEIIkX01awYXLoC7OwDXrqna7bFj4O0Nq1erBa5E1mUyqfXH6tdXddmzZ6H6CyWYOmEn/Tf0wbRihZpOLYR4cuvXw/btaoYtEOFZkE/tpvJje7W7SBG16FiLFvqFKDKXFG2fAVtb2yxfnIuLi8PJyUnvMIQQQgghhBBGde+eaokwYQJUrKi2PSjYnjsHrVpBUBAUKIBllXORPdSrp9ol9O0LK1fCgPc9WN99Cb8t24Jrx+Z6hydE1hIXpwq148aptgh167LNtS39+6uxFOCNN9Qijqm0QxXZgCxElk5pbRqcXdy9e5dcuXLpHYYQKZIcFUYnOSqMTnJUGJ3kqMHdvq2m0R46pAq2R46oFcaAo0fVruvX1arm/v5QvLjO8WYCyVEwmxPbJcTHQ+nS8M8/4OuLWrXstdfUqnNFi+odao4kOZoFXL6sFhvbsQOA2AED+cLle76e4oymwXPPwR9/WDrOZDs5JUfTWlO0eYYxCSGEEEIIIYTIbq5fV6vfHDoE+fKpHrYPCra7d0OTJuqQypVh27bsWbAVio0NfPghbN0KhQvDmTNq0bJffgHtzTdVxb5WLXXJtxDC2rJlULWqKth6eHBq9Hwqbv2ZiT+qgu2rr6r2Mtm1YCuSk6KtSJMdDz7lEcKoJEeF0UmOCqOTHBVGJzlqUP/9p6qyx49DwYKwZYuqzqLqcy1aQHCwunx+yxbVGiG7khxNVL++quG3bw/R0WpNurftfyG+ajW4dQuaN1fNOMUzJTlqYMOGQadOEByMuXpNxnc/RPkR3TlzRg2tK1eqGbaennoHmrkkR61J0VYIIYQQQgghxJO7cAEaN4bTp9WKOFu3QrlyACxcqAp2kZFqVpi/v1p8TOQcuXOriYMTJ4KtLfy0rDA1IrZxr9ULEBsLAwaoVczi4/UOVQj9VasGwLVeH+AbsYPPfi+Bpqk+0ceOQbt2OscndCFFWyGEEEIIIYQQT+6TT9TKYiVLqoJtyZKAmg3Wo4eqy734IixfDq6uOscqdGFjA0OHqvR47jk4fNaVglvnc6DjSHXAd99Bhw4QEqJrnELo4sYNy7dR7bry/atHeW7+txw95YCPj/rQY8YM+cArJ5OirUgTX19fvUMQIlWSo8LoJEeF0UmOCqOTHDWgX3+FPn1U34MHC0t9/bVaa8pshtdfV+1tHRx0jvMZkRxNWUK7hHbt4H60DTWXj2Byw3/QnJ1Vw2M7O71DzBEkRw0iMlINkJUqwdWr7N8PNWrAB39WwmxWw+rx49Cxo96BPnuSo9ZMmqZpegeRFaV1pbfsIiYmBoec8tuWyJIkR4XRSY4Ko5McFUYnOWoQN25A/vzJNmsafPYZTJig7n/8MYwfDybTM45PR5Kjj2c2wzffqFyJj4fORQ4y7tc8lG9TRO/QcgTJUQM4flxdinD8OJrJxOIO0+mxqi/x8Wodx19+gc6d9Q5SPzklR9NaU5SZtiJN1q5dq3cIQqRKclQYneSoMDrJUWF0kqMGsG8flC+vmpQmER8PgwYlFmwnTFC3nFSwBcnRtLCxgY8+UpOzCxWCJZeqU71zEX7/XRX++eor+OknvcPMtiRHdaRp8PvvUKsWHD9ObG4fXi+2nheWq4Jtz56qnpuTC7YgOfowKdoKIYQQQgghhEjd9u3QogUEB8PSpaphLRAToy7l/eUXVaT99Vc1y1aI1DRoAAEB4OcHUVHqSvER7fapPsmDB8P//mfJMSGyvNBQ6N1bJfr9+5wt2Zqi9w7zR1Bz8uSBBQtUK5k8efQOVBiNFG2FEEIIIYQQQqRs40Zo0wbCwqBpU1i7FuztiYyETp1g/nywt1dfX39d72BFVpEnD6xYoWZl29rCmDU1+TrPV2gmE0ybpnLuzh29wxTi6U2YAH//jWZry+QCEyhzbjXX4vPRrZuaXfvCC3oHKIxKirYiTUqVKqV3CEKkSnJUGJ3kqDA6yVFhdJKjOlmzBtq3VwvntGkDK1eCmxvBwdCqldrt4gLLl8OLL+odrL4kR5+cjY2amb15MxQqZOKj2x/xgt1SYhzdYNMmqF0bAgP1DjPbkBzVR+xHn3OmtB9N2Mp71z4mV24b/v5bzbDNl0/v6IxFctSaLESWTjltITIhhBBCCCFEDrN0qarExsbC88/DP/+AoyPXr6v67ZEj4OWl6rj16+sdrMjqbt+Gl19WHwRU5BibXDuSN+ICuLvD339Du3Z6hyhE2ty9C1OnwmefcSzQhr594eBBtatzZ/j550eu5yhyEFmITGQoaQYtjE5yVBid5KgwOslRYXSSozq4eFEVbF98ERYuBEdHLlyARo1UwTZ/frWglBRsFcnRp5Mnj/oAYPx4OGlbifIR+9jn3Fi15bh2Te/wsgXJ0Wdg+3bw9YVhw9jY/huqV1cFW29vmDMHFi+Wgm1qJEetSdFWpElMTIzeIQiRKslRYXSSo8LoJEeF0UmO6uCdd1Tfg7lzwd6ewEC1gNTZs1CsmKpNVKmid5DGITn69Gxs1FpkmzaBY8E8NLjvTx+Hf/jTNAC5RvjpSY5mIrMZxo1Tfb8vX+aSY2mGrGlFbCx07Kh61/burRZsFCmTHLUmRVshhBBCCCGEEMqCBRAcnHi/Qwews2PvXjXD9upVqFhRFWyl9aDILI0aQUAANG/jwNyYFxkwAPr2hfALt1Xl68YNvUMUIlFCz5jPP4f4eObZ9KFi9AGCPKsxc6bqNFOggN5BiqxIirYiTXx8fPQOQYhUSY4Ko5McFUYnOSqMTnL0GZg8Gbp3h7Zt4f59y+aNG6FFC9WmsXZt1RKhUCEd4zQoydGMlTcvrFqlJi/a2MBff8Huyq/BvHlQq5aq6oonIjmaCbZsgapVYf167tu40J8/6W3+i8bt3Dl+HF55RWbXPgnJUWuyEFk6yUJkQgghhBBCiGxjwgT49FP1/UcfqfsmE0uWQI8eEBOjCrdLloCbm56Bipxo61bo1Qvcrp5iuel5yminwcVFVXK7dtU7PJGDxe87iFavHifNZXhR+4erHuWZNAn69ZNirUiZLEQmMtSOHTv0DkGIVEmOCqOTHBVGJzkqjE5yNJNoGowcmViwHTHCUrCdMQO6dVMF265d1SJRUrBNmeRo5mncGA4dgmKty1JH2806WkFkpErQMWOQhrdpIzmaQaKiADhzBpq8X53W8auppe2lSOvyHDsG/ftLwTa9JEetpbtoGx8fz99//83AgQPp0qULR48eBSAkJITFixdzQ3rMZCt3797VOwQhUiU5KoxOclQYneSoMDrJ0UygaWrVp1Gj1P3x41UB12Ri0iRVeDCb1df588HRUc9gjU9yNHPlywerV8PQL73pYFrFZN5RO4YPV9NwIyP1DTALkBzNAEuXohUvztwPD1K1KuzYAfvdm/PDr86sWQOFC+sdYNYmOWotXUXbe/fu0aBBA3r37s28efNYtmwZt27dAsDNzY133nmHyZMnZ2igQgghhBBCCCEy0OjRMHGi+n7SJPjkEzQNhg2D999Xmz/4AP74A+zsdItSCAsbG/jsM1i/2Y6vCkzmdX4lFjtCN+236sMsRIaLjoZ334XOnTFdv47p26+5f1+1jTl6FF5/XWbXioyXrqLtJ598wvHjx1m7di3nz58naVtcW1tbXnjhBVatWpVhQQr9ubu76x2CEKmSHBVGJzkqjE5yVBid5Ggm6NVLLWn+88/w7ruYzfD22zB2rNr95ZfwzTdSiEgrydFnp3FjtQ7ZxVav04IN1Lm5nH5DchMRoXdkxiY5mk5nzqDVrw8//ADANwzhfy4zmTYN/P2haFGd48tGJEetpWshMh8fH1599VXGjRvHnTt3yJs3L+vXr6d58+YATJ06lc8++4x79+5ldLyGIQuRCSGEEEIIIbK8sDBwdyc2Vi2cM3euKtL+9BMMGqR3cEKkzmxWXT2GD1ffV6gA/j1+p2ApF+jdW+/wRHYwdy7mNwZiExHObXLTl5lENm3Pn39C8eJ6ByeyqkxdiCwkJITiqWRnbGwscXFx6Tm1MKjDhw/rHYIQqZIcFUYnOSqMTnJUGJ3kaAaIjYVXXoG1axO3ubtz/z506aIKtnZ2MGeOFGzTQ3L02bOxgc8/hw0bwMcH7AMDyDtiEPTpo/oomM16h2gokqNPRlu5Cvr0wSYinC00pp5TAH4/tmfDBinYZhbJUWvpKtqWLFmSgwcPprh/3bp1VKhQId1BCeO5dOmS3iEIkSrJUWF0kqPC6CRHhdFJjj6l6Gh44QX46y/o0QMeXBUZEgJt2sDKleDkBEuXqq4J4slJjuqnaVPVLiF/i8p8w4dq4/jxxHXqqmaTC0By9ElcvAhtvm/LKvwYxXBGNtzAmmPPMXiw+rBAZA7JUWvpSrXXXnuNP//8k/nz51v62ZpMJqKjo/n8889Zs2YNAwcOzNBAhRBCCCGEEEKkQ2QkdOoEy5apyuy8eeDlxc2b0KwZbNsGHh6wbh20a6d3sEKkT/78sGqtLfFjxvOK6S+icMRuxVKiajaACxf0Dk9kBZqGNnce03+KpHJl8N9gQ3en5XhNGsWGLXaULKl3gCKnSdcaoO+++y7Hjx+nV69eeHl5AdC7d2/u3LlDXFwcAwcOZMCAARkZp9CZSVYfEAYnOSqMTnJUGJ3kqDA6ydF0Cg+Hjh1h82ZwcYHly6F5cy5dglat4PRpyJcP1qyBatX0DjZrkxzVn60tfPEFbG74Et26leKPu53xOX2UqCq1cFq5GBo10jtEXUmOpiI0lMiX3sBl+XziGUAYv1O/PkyfbkuZMnoHl3NIjlpL10JkCbZv387ChQs5c+YMZrOZkiVL0r17dxo3bpyRMRqSLEQmhBBCCCGEMLSQEPDzg127wN0dVq2Chg05eVIVbP/7D4oUUaufS1FCZDc3bsD7L1xmyPbO1OAgC2uMp93WT3Bx0TsyYTTavv2Ete+Bx63zxGHLcNtx5J4wlPfeN2Frq3d0IjtKa03xqYq2OVlOK9qePXuWUqVK6R2GECmSHBVGJzkqjE5yVBid5Gg6jB4NI0aAl5dafKx2bQ4cgLZt4fZtKFdOFWyfe07vQLMHyVHjiY+Hr0ZEcuXLGUxlEBUrmliwAMqX1zsyfUiOPkTTCBk9GZdRH2GvxXKBooytMI8PF9WjXDm9g8uZckqOprWmKO2TRZqcOHFC7xCESJXkqDA6yVFhdJKjwugkR9Phs89g4EDYtAlq12bzZtXD9vZtqFlT9bKVgm3GkRw1Hltb+GysC902/I/8+U0cPw5NaoRzsvU7lsX4chLJ0UTa7TtcrtEZz5HvY6/FssTUhaUjDvHzYSnY6kly1Fq6etoWL178sX0mTCYT586dS1dQQgghhBBCCCHS4fZt8PZW1So7O/j5Z0C1sn3xRYiOhqZNYelStfiYEDlB8+YQEAAvvQSvbniDcv7zuFZsHV5bl+NcpbTe4Yln7Pp1+PSVKCYe2kk0Dkwu8h3tV/6PzpWkn6owlnQVbZs0aZKsaBsfH8/FixfZsWMHlSpVopp0sRdCCCGEEEKIZ+fSJVWdatQI/vgDbNSFlbNnQ79+6lLx55+H+fPByUnfUIV41nx8VJeQPwYP5fLP2ygccoqQ6nW49es/FHm1pd7hiWdAM2vM+9vE22/D3buFuGI7n+5v5uKDSb7Ypas6JkTmyvCetocPH6ZNmzbMnj2bli2z78CX03raRkRE4OrqqncYQqRIclQYneSoMDrJUWF0kqOPce4ctGgBFy9C8eKwezfky8ePP8I776hDXnlF1XKlOJE5JEezju0Lr+PUuws1Y3cThy2H+k6m1vT/QTZfuT4n5+ito9e52uJlRt0axL90pXp1mDEDKlfWOzKRVE7JUd162latWpWBAwfy8ccfZ/SphY7CwsL0DkGIVEmOCqOTHBVGJzkqjE5yNBUnT0LjxqpgW6YMbN2Kljcfo0cnFmzfeQemT5eCbWaSHM06Gr7gw3OnN7HO52XsiKfWzMFsrvA/7ofG6h1apsqpObrlC3+0qlWpems9P/AOXw6PZvduKdgaUU7N0ZRkykJk+fPnJzAwMDNOLXSyb98+vUMQIlWSo8LoJEeF0UmOCqOTHE3B0aPQpAlcvQoVK8KWLZgLPsd778GIEeqQUaNg0iRLtwSRSSRHsxafYk60uDwT/5ZfYcZEmZNLaV/nNidP6h1Z5slpOXrrWhz/lv+MRl+2IZ92k9NOlQlb5M9noxyxt9c7OvEoOS1HHyfDf2zfuXOHP/74g+dkGVIhhBBCCCGEyDwHD6pVxW7ehGrVYPNm4vL40L8//PCDOuSHH2D48Gx/1bcQ6WJrZ6KV/0ccGbuMAbn+ZdPJAtSsCXPm6B2ZeFqrfr5EUJEmdDk5Hhs09tV4k2LX91C+a3m9QxMizdJVtG3evPkjb9WrV6dw4cIcPnyY0aNHP/F5t27dSseOHSlYsCAmk4klS5ZY7dc0jeHDh1OgQAGcnZ1p2bIlZ86csTrm7t279OnTBw8PD7y8vBgwYADh4eFWxxw5coRGjRrh5ORE4cKFmThx4hPHKoQQQgghhBC6un4dwsKgTh3YsIEotzx06wazZoGtLfz1F7z9tt5BCmF8vp93YPrxOjRrBhERsOilxfzYZgX37+sdmXhSd+7Am11vUneQL7XjdhJm48H5Cf9Qa/80HDyd9Q5PiCeSrqKt2WxG0zSrG0Dx4sUZPHgwx44do1evXk983oiICKpWrcpPP/30yP0TJ07khx9+4Oeff2bPnj24urrSpk0boqKiLMf06dOH48eP4+/vz4oVK9i6dStvvPGGZX9oaCitW7emaNGiHDhwgK+//pqRI0fy66+/PnG8OUnt2rX1DkGIVEmOCqOTHBVGJzkqjE5y9BHatYM1a2DdOkJtvWnXDpYtA0dH+PdfeOklvQPMWSRHszYfH/D3hx8HBTKbl3hr3fNMK/E1p05m6NrtusruObp0qeoS88u/+Zhn6s1/BWrhcOwQJT5+Ue/QRBpl9xx9UiYtoeJqMCaTiX///ZfOnTsDapZtwYIFGTJkCB9++CEAISEh5M+fnxkzZtCzZ09OnDhBhQoV2LdvHzVr1gRgzZo1tGvXjv/++4+CBQsybdo0Pv/8c65fv46DgwMAn3zyCUuWLOFkKs1roqOjiY6OttwPDQ2lcOHCj13pLbsIDw/Hzc1N7zCESJHkqDA6yVFhdJKjwugkRx/YsAGKFoVSpSybbt8GPz/Yvx/c3VXhtmlT/ULMqSRHs4mYGP7r+jbPrVQTu2bb9cXu91/o2ddR58CeXnbN0bt3YVz/M8xd5so1ClKhAsz8NZqatUzwoO4jsobsmqMPCw0NxdPT87E1xSyzdmhQUBDXr1+nZcuWlm2enp7UqVOHXbt20bNnT3bt2oWXl5elYAvQsmVLbGxs2LNnD126dGHXrl00btzYUrAFaNOmDV999RXBwcF4e3s/8vnHjx/PqFGjkm1fvXo1Li4uALRq1Yo7d+5w8OBBy/569ephZ2fHtm3bLNuqVKlCoUKFWL16tWVbiRIlqFixIv7+/paZw/ny5bO8vtu3bwPg4uJCixYtOHr0KBcuXLA8vn379ly4cIHjx49btjVp0oSoqCj27Nlj2VazZk08PT3ZsGGDZVu5cuUoXbo0K1euxGw2A1C4cGF8fX3ZvHkzYWFhmM1mcufOTcOGDdm/fz/Xrl0DwN7enrZt23Ly5EmrVhWtW7fm1q1bHDp0yLKtfv362NjYsH37dqv3omDBgqxZs8ayrWTJklSoUIF169ZZCuX58+endu3a7Ny5kzt37gDg6upK8+bNOXz4MJcuXbI8vmPHjpw7d85qMbxmzZoRERHB3r17Ldtq1aqFu7s7GzdutGwrX748pUqVYsWKFZYZ5EWKFKFq1aqW9wIgV65cNGjQgH379nH9+nUAHBwcaNOmDSdOnODs2bOWc7Zp04YbN24QEBBg2dagQQMAduzYYdnm6+tL/vz5Wbt2rWVbqVKlKF++PGvXriUmJgYAHx8fatWqxY4dO7h79y4A7u7uNG3a1Oq9MJlMdOjQgbNnz3LixAnLOZs3b05YWJhVg+/atWvj6urKpk2bLNsqVKhAyZIlWb58uWVbwnuxceNGIiIiAMidOzf169dn79693LhxAwBHR0dat25NYGAg586dszy+bdu2XL16lSNHjli2NWzYELPZzM6dOy3bqlWrRt68eVm3bp1lW+nSpSlXrhxr1qwhNlat6lqgQAFq1qzJ9u3buXPnDjY2Npb3IiAggMuXLwNgY2ND+/btOXPmjNWHMy1atCAkJIT9+/dbttWpUwcnJye2bNli2VaxYkWKFSvGypUrLduKFStG5cqV2bBhA5GRkQDkyZOHevXqsWfPHm7evAmAk5MTrVq14vjx45w/f97yeD8/P65cuWL1XjRq1Ii4uDh27dpl2Va9enVy586Nv7+/ZVuZMmUoW7Ysq1evJi4uDoCCBQtSo0YNtm3bxr179wA1RjZu3JiDBw9y5coVAGxtbWnXrh2nT5/m1KlTlnO2bNmS4OBgDhw4YNlWt25dHB0drd6LSpUqUaRIEVatWmXZVrx4cSpVqsT69eu5/+Aasrx581K3bl12797NrVu3ACxtbY4dO0ZQUJDl8e3atePSpUscO3bMsq1JkyZER0eze/duy7YaNWrg7e3N+vXrLdvKli1LmTJlWLVqFfHx8QAUKlSI6tWrs3XrVkJCQgDw8vKiUaNGHDhwgKtXrwJgZ2eHn58fp06d4vTp05ZzZtZYvmHDBmwerACj11gO4O3tLWO5jOWPHMvv3LlD/vz5dR3Lg4ODrd4LGctlLE86lpvNZjp16qTrWK737+UuGzZQY8IEYnPnxunAAfZfu8aRI8GMGFGX//5zJ08e+PnnIMLCjpHw317G8mc3lpvNZjw9PXP87+XZYiz/awJXvy5BvvGf81LcTHb2O81by2Yz9veCbN+edcfyGzduYGNjk61+L9+3Lx+3Jp9mYuj/6EANpnb9mR69z+HsVQwcjDmWy+/lKY/lSf9mys6/lyeMVY+Tppm2s2bNStPJHvbKK6+k63GQfKbtzp07adCgAVevXqVAgQKW47p3747JZGL+/PmMGzeOmTNnWg14oP5jjho1ikGDBtG6dWuKFy/OL7/8YtkfGBhIxYoVCQwMpHz5RzelzukzbZcvX07Hjh31DkOIFEmOCqOTHBVGJzkqjC7H5+jChdCrF8TFQZcu8PffnL7gQKtWcOkSPPecurS7XDm9A825cnyOZkPxa/yJ6dId56h7XKIwQ0svZcyKapQpo3dk6ZOdcvTePfjorQjqzH2HAfwJQKhvYzw2/Au5cukbnEi37JSjqcnQmbb9+vV74gBMJtNTFW2NxtHREUfHrH85hBBCCCGEECKLmTMHXnkFzGbo2RNmzSLguD1t2sDNm1CmjCrYFimid6BCZC+2bVvhfHgPES06UuS/0/ie+YcaNarx66/qMxShj9Wr4Zt+x/jhZg8qEogZE/GfDsNj9DCwyzIXlAvxWGnK5qTT5fXi4+MDwI0bN6xm2t64cQNfX1/LMQmXPiSIi4vj7t27lsf7+PhYLhVJeo6kzyGSq1Chgt4hCJEqyVFhdJKjwugkR4XR5dgc/eMPeP110DTo1w9+/51tO23p0AFCQ6FaNbUWWb58egcqcmyOZndlyuB6dA+hYyfjv+8LwrdC796wZQt8/z04O+sdYNpl9RwNCYEhH2iY/vydFbyDM1HE5C6Aw4I52DRrpnd4IgNk9RzNaGkq2hYtWjSz43is4sWL4+Pjw4YNGyxF2tDQUPbs2cOgQYMA1dvk3r17HDhwgBo1agCwceNGzGYzderUsRzz+eefExsbi729PQD+/v6ULVs2xX62QvVAEcLIJEeF0UmOCqOTHBVGlyNzdP58eO019f2gQTBlCqvW2NCtG0RFQaNGsHw5eHrqG6ZQcmSO5hReXnh8M4J1cTB6NHw1JoZ8v0yg2c4PmbXQJcu0S8jKOervDwMGwM3L0Rzke5yJIr5lGxzmzJJPrbKRrJyjmcFG7wCSCg8PJyAgwNJMOCgoiICAAC5duoTJZOK9995j7NixLFu2jKNHj/LKK69QsGBBS9/b8uXL07ZtW15//XX27t3Ljh07GDx4MD179qRgwYIA9O7dGwcHBwYMGMDx48eZP38+kydP5oMPPtDpVWcNSZveC2FEkqPC6CRHhdFJjgqjy5E52rIlVK4M778PP/3EvPk2dOqkCrbt28PatVKwNZIcmaM5jJ2dKtqebfcOoxnBT0cb0bHaf/z9t96RpU1WzNGwMHjzTWjdGi5fhkIlnIic/g9MnIjt2lVSsM1msmKOZqZ0N/u4fv06f/zxBwcPHiQkJMSyIl4Ck8lktXpeWuzfv59mSaa0JxRS+/bty4wZM/joo4+IiIjgjTfe4N69ezRs2JA1a9bg5ORkecycOXMYPHgwLVq0wMbGhm7duvHDDz9Y9nt6erJu3TreeustatSoQZ48eRg+fDhvvPFGet4GIYQQQgghhMgcuXPDjh3g5sa0n0289ZbqktC7N8yYAQ8uHBRCPGOFP+5N/O5F1Lh7kM2RtejcawlbttTh++8hSXlCPKUNG2DAqxqdL03mfczEvf0B48eDq2sloJLe4QmR6dJVtD1y5AhNmzbl/v37lC1blqNHj1KhQgXu3bvHlStXKFmyJIULF37i8zZt2hRN01LcbzKZGD16NKNHj07xmFy5cjF37txUn6dKlSps27btieMTQgghhBBCiEyjaTBsGBQqpNohAJqbO+PGwRdfqEPeegt++AFsDHXNpBA5TOPG2B7Yh9ahIwWOH2MLTRjw8x/U3dWHBQugdGm9A8zawsPh44/h76l3mEE/OrICs60dNoP8wLW83uEJ8cyk60f9J598gpubG6dOnWL9+vVomsbkyZO5fPky8+fPJzg4mAkTJmR0rEJHRWQpWmFwkqPC6CRHhdFJjgqjy/Y5qmkwZAh8+aWqzB4/jqbB0KGJBdthw+DHH6Vga1TZPkeFtWLFMO3aCc8/jxPRzOElehz+lJrVzcyfr3dwj5YVcnTLFqhSBY5M3UYAvnRkBZqjIzY/TIZy5fQOT2SyrJCjz5JJS21qawo8PT356KOP+Pzzz7l79y558uRh3bp1tGzZEoB3332XgIAAtmzZkuEBG0VoaCienp6EhITg4eGhdzhCCCGEEEKIrMpsVoXan39W96dMIW7gWwwcCH/+qTZ9951qbSuEMBizWX2yMn48YbaeVIo/zCWKMmiQ+n8r7RLSJiICPvsMpvwQz6eMZxQjsMUMZcqoRRkfLEgvRHaQ1ppiuj6jNZvN5M+fHwAvLy9sbW25e/euZX/lypU5cOBAek4tDGrjxo16hyBEqiRHhdFJjgqjkxwVRpdtczQ+Xi2J/vPPYDLB778T/dpb9OihCrY2NjB9uhRss4Jsm6MidTY2MG4czJ6Ny/J/ePnzogBMmwb16sHZszrHl4RRc3T7dqhaFX74QWMZzzOWYapg+/LLcOCAFGxzEKPmqF7SVbQtXrw4QUFB6gQ2NhQvXpz169db9u/cuRMvL68MCVAYQ0REhN4hCJEqyVFhdJKjwugkR4XRZcscjY2Fl15Sq4rZ2sJffxHeYwDt28PixeDgAIsWQb9+egcq0iJb5qhIuz59sPVrzdixsGYNdPLYhHvAVqpXh3/+0Ts4xWg5GhkJH3wAjRvDuXPw3HMmSrzZGlxc1Lg4axa4uekdpniGjJajektz0TY4ONjyfevWrVmwYIHl/qBBg/j9999p2bIlLVq0YObMmfTu3TtjIxVCCCGEEEKI7GTJEvj7b7Czg/nzudO2Dy1bqhXTXV1h1Sro3FnvIIUQT6pN6fMsNnVjo6kF3cN+p0cP1QElKkrvyIxj1y6oVg1+/D6W57RLvPoqHDsG5ae+A4GB0Lev3iEKobs0F219fHzo0qULCxcuZMiQIcybN4/Y2FgA3nvvPUaPHs2dO3cICQlh2LBhjB07NtOCFs9e7ty59Q5BiFRJjgqjkxwVRic5KowuW+boiy/CiBGweDFX63WjSRPYswdy5YKNG6FFC70DFE8iW+aoSB8fH2zatMJOi+N3Xud73uOXqXHUr69vuwQj5GhUFHz0ETRsCFGnL7LLvgknCrbgj0lheHqi2sQULap3mEInRshRI0nzQmR9+vRh2bJlREZG4u7uTteuXenTpw/NmzfHZDJldpyGIwuRCSGEEEIIIZ5YRARomtUlv2fPQqtWcOECFCwI/v5QoYJ+IQohMoCmwdixMHw4ABvtW9M1dj5mdy/++EN9ZpPT7Nmj2r2cPAmdWMIch/64xtwDDw/VU6JePb1DFOKZyPCFyObMmcPNmzeZPXs2jRo1Ys6cObRu3ZpChQoxZMgQDh48mCGBC2Pau3ev3iEIkSrJUWF0kqPC6CRHhdFlixwNDQU/P+jYUTVzBI4cUTPOLlyAUqVgxw4p2GZV2SJHRcYxmWDYMFi4EFxcaB67jiPOdfAJO0337jB4MERHP9uQ9MrR6Gj49FOoXx/On4zmN5d3WEIXVbCtXRsCAqRgKwAZRx/2RAuROTs706tXL5YvX87169eZOnUqpUuXZtKkSdSqVYty5coxduxYzp8/n1nxCp3cuHFD7xCESJXkqDA6yVFhdJKjwuiyfI4GB6vptNu2waFDcO4cO3dCkyZw4wZUqaJ2FSumd6AivbJ8jorM0a2b+jSmcGGK3D/NzOo/APDTT6qIee7cswtFjxzdvx9q1IAJE6CE+QynvOvxWuSPaueHH6qBr3jxZx6XMCYZR609UdE2KW9vbwYOHMiWLVu4dOkSEyZMwMXFheHDh1O6dGnq16+fkXEKIYQQQgghRNZ0+zY0bw5790Lu3LBxI2uvVqZVK7h3TxVutmwBHx+9AxVCZApfX9i3DwYPpt7Ob1m1Sg0FBw9C9epqMm52ExOjJhrXrQvHj0O+fLC57qcUCz6kXvzKlfD11+DgoHeoQhhWuou2SRUqVIihQ4cyc+ZMOnXqhKZp7NmzJyNOLQzC0dFR7xCESJXkqDA6yVFhdJKjwuiybI5evw5Nm6rLf/Plg82b+edsdUuHhLZtYd068PLSOU7x1LJsjopnI39++PFHcHTEzw8CDsTzTYmp3A+N4cUX4e23M79dwrPK0UOHoGZN1dI3Ph569lSF20JLp0L37nD4MLRr90xiEVmLjKPW0rwQWUouXbrE3LlzmTdvHseOHUPTNOrXr0+fPn0YNGhQRsVpOLIQmRBCCCGEECJV//0HLVrA6dNqhbENG/htWzkGDlRrFPXoAbNmyUQzIXKkTz6Br77ifOEm1L68kDvkoUYNmD8fSpbUO7j0iY2FceNUsTYuDhp6HePnNv9S8e9heocmhKFk+EJkSd2+fZupU6fSsGFDihcvzmeffUZsbCyjR4/m/PnzbN++PVsXbHOiwMBAvUMQIlWSo8LoJEeF0UmOCqPLkjkaHAy3bkGRIrB1K18tLccbb6iC7cCBMGeOFGyzkyyZo0I/DRuCuzslLm/hUv7a1PM4zoEDql3CokWZ85SZmaOHD6s1xUaOhLg4jWnVf2NrVC0qzh+uKtFCpIGMo9bSXLSNiIhg9uzZtGvXjkKFCjF48GCCgoJ477332L9/P4GBgXz++ecUk8752dK5Z9kdXYh0kBwVRic5KoxOclQYXZbM0cqVYf16tK3b+PjXknzyidr86acwbRrY2uobnshYWTJHhX46dIBdu6BECVxuBLE9vi4flltBaCi88AK8807Gt0vIjByNjVUza2vVUl1ginqFcLFeL948+AamqCjVA6ZZswx/XpE9yThqzS6tB+bLl4+oqCjc3Nzo3bs3ffr0oXnz5tjYZEhbXCGEEEIIIYTI+gID4e5dNYsOiK9anUGD4Lff1O6JE2HoUB3jE0IYR8WKsGcPvPgiNps3M/HU8zRrMoH2W4by448mdu1Sk1RLlNA70Ec7dgz69YMDB9T9IU32M+FCD+x2nQc7O9UrYcgQkLqREOmS5v85LVu2ZN68edy4cYPp06fTsmVLKdgKIYQQQgghRIKAAGjSBPz84MABYmKgVy9VsLWxUV+lYCuEsJInj1qNcOBATJpGuz0j2PjbeXLlgv37VbuExYv1DtJaXByMHw81aqiCrbc37B7wG1/vrI/dxfNQtChs26YGPKkbCZFuT70QWU6V0xYii42Nxd7eXu8whEiR5KgwOslRYXSSo8LoDJ+je/dCmzZw7x7UrEnE4rV0fS0X69aBvT3MnasueRbZl+FzVBibpsHUqZA7N/TsyeXLarHCXbvU7nfeUTP1HR3T/xQZkaMnTkDfvrBvn7rfoQP8+isUOLQK2reHrl3h999VJVeIJ5RTxtFMXYhM5DxXr17VOwQhUiU5KoxOclQYneSoMDpD5+j27dCypSrY1q9P8ML1tOqhCrYuLrBypRRscwJD56gwPpMJ3noLevYEoHBh2PL9Ab5/5RAAP/wAjRpBUFD6n+JpcjQ+Hr7+GqpVUwVbT0+YOy2EZcugQAGgXTvYsQMWLpSCrUg3GUetSdFWpGrxYqhaFUqXfo6qVY13WYYQCY4cOaJ3CEKkSnJUGJ3kqDA6w+boxo1qhm1YGDRtyvWZa2nS0ZNdu8DLC9avh1at9A5SPAuGzVGRNV29in3X53lvQQP2f7KQXLlUsbRaNfj33/SdMr05euqUatP90UdqcbT2beO59MZYeg0rhenihcQD69dXxWch0knGUWtStBUpWrwYunWDo0chNtaWo0fVfSncCiGEEEIIgaqgtGsHkZHQpg0Xpq6iYVs3jh4FHx/YuhXq1dM7SCFEluTiApUrw/371JjwIuf6jqJ+XTMhIaoDwXvvQUxM5oYQHw/ffw++vrB7N3h4wNxvr7E8pjUeXw+D27dh3rzMDUKIHMxO7wCEcY0apT4kS+h6nPC1Vy/16V7u3Kpneu7cqd+cnfV7DUIIIYQQQmSaqlWhRQuws+P4iH9o1cKRa9egeHE1w9aoK74LIbIALy9YsUJNb/3+e7y+H8m2bsf54t0ZjJ/swuTJsHMn/PMPFCuW8U9/5gz07686HgC0bg1/vbKOfB+8DDdvqqLy1Kmqwa0QIlPIQmTplBMWInN2hqiojDlPWgu8Ccd5espVFeLJBAcH4y29k4SBSY4Ko5McFUZn2ByNimLvAVvadrQnOBgqVYK1a6FgQb0DE8+aYXNUZH1//glvvgmxsVCtGv6Dl9Ljw8IEB6va7vTp0Lnz40+Tlhw1m2HKFPjkE7h/H9zc4PuJsQy4OBzTVxPUQVWqwPz5UK7cU780IZLKKeNoWmuKMtNWpKhMGdUaIWlZ32SCkiVVA/I7dxJvt29b30+4xcergf6//9QtrWxtIVeutBV4E77PlQscHDL+fRBZg9ls1jsEIVIlOSqMTnJUGJ1hcnTmTAgIgO++A5OJ9dud6NwZIiKgbl216FiuXHoHKfRgmBwV2c+rr6o/0Lt0gUOHaLV9BIcO/UmPHrBnj9r8/vswYULqfxM/LkfPn1eza7duVfdbtIA//oCiC3+AhILtoEHw7bdySa3IFDKOWpOZtumUE2baJvS0TWiRkPB18WL1Q+FxNA1CQ5MXclMq8CbcIiLSH7O7e9oKvElvbm4yqzc7WL58OR07dtQ7DCFSJDkqjE5yVBidIXL0l1/UbDeARYtYTFd69VJ9JVu1Ur8nu7npG6LQjyFyVGRvFy6oKbC//goeHsTEwGefqRoqQO3aagJsSu0SUspRsxmmTVOdGCIjwdUVvvkGBg588LdyVBT4+cFbb8ELL2TWqxMix4yjMtNWPLWuXWHRIhg9GgID46lQwZYRI9JWsAU1uHt6qtuT9POKioK7d9NW4E243b2risRhYep24ULan8/ePm3F3aS3XLnUbGAhhBBCCJFDTJ6sVv4BePtt/gzuwutvqGJHt24wZw44OuoaoRAiuytWDP7+23LXwV7jm9oLaLy4G/0G2LJ3r1p/ZsYM6NQpbae8cEFN5N20Sd1v2hSmT4ui2NpfwDxY/eHr5AQbN8psJyGeMSnailR17apuy5evemafdjg5qR5gT9IHLD4e7t1LW4E36Yzf6GjVFuj6dXV7El5eae/Tm1AMlitIhBBCCCGyoAkT4NNP1fcffcR3+SYw5DVVvBgwQE3AlQ/0hRDP3LffwtChPN+xIwHb5tB9gDt79qj+to9rl6BpasLuhx9CeLhaV+yrr+B/LU9j06uHagNz7x6MGKEeIAVbIZ45KdqKNKlWrZreIaTK1jaxOJpWmqYu/UhrgTfh+5AQ9fh799Tt7Nm0P2fComxp7dObO7eaqWxj8yTvRs5k9BwVQnJUGJ3kqDA6XXJU02DkSHXpGaANH8GwuBF8+aEqXnz4IUycKLUMocg4Kp65ggXVFP/lyykSVJ+tC5fx6a/F+e47+P572LlTtUsoWlQdnpCjly6pD5zWr1fbGzZUi5mV2j0bag1SVdw8eaBWLZ1emMipZBy1Jj1t0ynb97QdOVJVQocNAyA6OhrHhOu9xoxRU1tHjtQtPD3FxSW2b3hcgTfpLS4ufc9nY5PyomypzfTNaYuyWeWoEAYkOSqMTnJUGJ0uOXrkiLrW2GzGPH4Cgy99zLRpatf48fDxx1KwFYlkHBW62LtXTa29dk39IbhoEUvvNaFfPzXJyMtLteJetQpOndLIm9fE7duqLaGzM4wbB+8MiMDm3bdV5RagSRPV86VQIf1el8iRcso4Kj1txdOxtYXhw9X3w4axbt061R5hzBi1/cFsg5zIzg7y5VO3tErot/skRd47d9QHnGazOub27SeL083tyXv1urtn3T88LDkqhEFJjgqjkxwVRqdLjlapAjNmEH/rLi/vf5d589TvStOmqQV6hEhKxlGhi9q1Yd8+Vbjdvx9atqTTTz9x6NAb9OiharoTJiQcbOK//9R3ZcvCsmVQJvY41HkRTpxQM4aGDVM36fkidCDjqDUp2opHezDD1lK49fW1Ltgm7BdpYjKBh4e6FS+e9sdFR1vP6k3Lwmx376pCb3i4ul28mPbns7dXs3qfpFdvrlyqkC2EEEIIkS2YzeqXqrx5AYjs9jIvvqhmqdnZwezZ0KOHzjEKIURShQrBli1qRbH58+F//6PY8SZs21aWQoWSTwAymVRXhTJlgGMaBAVBgQIwd65aiUwIYQhSahEpS1K47WAyqemibduqhjgrVyZO3yxYUHUtFxnO0VH97CxQIO2PMZtV3920FHiTFoOjotSibDduqNuT8PJ68l69kjJCCCGEMJy4OFX02L0btmzhnnMBOnaE7dvVZcSLFoGfn95BCiHEI7i4wLx5UKkSeHtD2bI4jBzJ4Hu2jMR60pVJi6dr4DgY+aDt4eLFULOm5cMqIYQxSNFWpG7YMBg9GlNCQ9Y1a9QtqWnTVJMcUNdeDBny6CpdnjyqJ1iRIs/2NeQwNjbqZ7S3N5QunfbHpWdRtnv31GMTFmU7dy7tz+fklPYCb8LNyyv5omyLF8OoUXDyZHvKlVOLm3btmvY4hHhWSj/Jf0ghdCA5Kowu03M0Nhb69IEFC8DOjuD1B2j+XQcCAtTCsCtXQoMGmRuCyNpkHBW6M5ngiy8S79vaMiJuOF7c5j0mA1CTfazCj7xxd8D2QdtD+TRKGISMo9ZkIbJ0yvYLkSVIaIlga6sWH6tcWU37TFq5+/NPePFFdfzChYnfP0rSAu+WLdClS8qVOj8/qF5dHRsVBcHBOXOFLQOLi1P/LE+6KFtsbPqeL6EgnZAiMTFw4EDi/oQJ4YsWSeFWCCGEEE8gKgq6d4fly8HBgZtT/qHBxE6cPavWMVi3DqpW1TtIIYR4QsHBRBcphWP4XWbyCgH48jUfYoeZiLzFcL0ZpHeEQuRIshCZeHpJetiuqVWLtvv2qfsvvmjd0zZp3b9ePTU74eGKXcL3xYolHnvrlqr4BQfD2bPJnz9PnsSi7c6d0KKF+t7NLXmBt18/aN1a7Q8OVpW8h6/Fz6orbBmYnZ26guZJrqLRNNVr90kWZLtzRy3kltBi7s6dlM8N8P770Ly5mpkrhFGsWbOGtm3b6h2GECmSHBVGl2k5GhmpJhKsWwdOTlya/C/1R7XlyhXVFczf/8muXhI5l4yjwnBiY3GsUg527qQvs+jLLABCn6uAx9EdOgcnRHIyjlqToq14tIcWHYtdvjz54mQJ95MWQwsVghdeSNtz+PlBYGDyql3C18qVE48NDVXTLJOusHXhQuL+pM3SDx6EVq2snyvptfgffwy9e6vt166pRu2PauXg4SGF3kxgMoG7u7olreE/TkxM8kXZevRQs30fdumSmhXTogV06wadOkl7JqG/2PROMRfiGZEcFUaXKTkaFgbPPw+bN4OLC6e+WU6Dz5pz5w6UL68KtoUKZfzTiuxJxlFhOPnywcaNMGgQTJ+uttnZ4XHpmPytKwxJxlFrUrQVjxYfbynYWkm4Hx//9M/h6qp+G06Lzp3VNfUhIY+exVu/fuKxtraq4JtwTEyMuuTtyhV1Cw9PPDYwUE3LfBQ7O/jmG3j3XXX//HkYP966wJvwfcKCbG5u6XorxOM5OICPj7olqFABjh61nuwNagG36OjEFswDB0LjxqqA26WL/PElhBBCiAciItTvh+7uHPxyNU0+akB4ONSqBatWqV/xhBAiS3N0tMyWMdvZYRMXB2PHJv9bXwhhOFK0FY82cqTV3QIFCiTe0WtwT7rCVqlSKR/XtCkcOaK+f/ha/Nu3rQvF3t5quubDheDISDWF08Ul8djz5+H331N+3vHj4ZNP1PcnTsCAAckLuwnF3qpVoWTJdL8VQhkxQhViE3rZJnydN0/9My9erG4HDqgJNJs3w9tvQ926qudtt25QooTer0LkFFbjqBAGJDkqjC5TctTHBzZsYMs/N2gztCbR0arF0pIl6qogIZ6EjKPCkMaMUX84jR7NQT8/aq5enfzqWSEMQsZRa7IQWTrlmIXIcqr791Xx1t1dLRcMqu/uvHkpN2H95ht47TV17Pr1yVs0JJW0wHvokCo0P1zYTfi+ZUvVKxjUrOGbN9V2Z+dMe/lZyeLFalL4qVNQtqz6faRLF+tjLlxILODu3Gk9M9fXN7GAW6HCs4xcCCGEELq4cQN27VJXcgGzZsGrr6oLyTp3Vr/uOTnpGqEQQmSMh9oePna7EOKZSGtNUYq26ZTTirbbt2+nYcOGeodhbAlTPUEVVrdvT3mlrfffT+z96++fuIjao3z1FXz0kfr+wAGoWVN97+ycfBZvz56WP0AIC4MdO6yPcXPLtr2L0pqj166p2TOLFqmZt0k7fZQrl1jArVYt275VQicyjgqjkxwVRpchOXrlivpA/PRpWLCAyZe78t57ale/fvDbb6pDlhDpIeOoMJyRI1X7wAeFWascHTNG/TH00FW2Qugpp4yjaa0pyq8kIk2Cg4P1DsH4klb48uVT1b+0aNgQTp5MucBbo0bisWFh6i+JuDg1G/jyZXVLUL164venT6vF3pKyt08s4A4erJq9glrha/r0R8/09fJSrSkMLq05WqCA6sM/aJB6m5cvVwVcf3/1zzBunLoVK6b+Cbt2VROds8BbIAxOxlFhdJKjwuieOkcvXlSrlJ47h1a4MD9uqsx7U9Su996Db7+Vn/fi6cg4KgznoYKsVY7KDFthQDKOWpOirRB6c3ZW1/WnRdOmqkVCaOiji7xJP5HSNNU7N2FfVJRazO36dXULDU08NigIPvzw0c9pY6N6DiT0Pbp+HT77LOV+vYUKJbaUyEwPfWpsJY2fGufJA/37q1toKKxcqQq4q1erlgrffaduBQqolgtdu0KTJjIDRwghhMhyzp5VBdtLl9CKF2dU442MmlIMUL82fP65XGEjhBBCCGOR0oNIE3dZicE4TCZVFPX0TH0VrZo1ISAg8X5kpPUM3qSPdXWF3r2Tz/INCwOz2bp/7n//qVm5Kfn4Y5gwQX1/+bJqA5FSv97KlVVPgvSwtbVqoG/J0aT9mZ6Ahwf06qVukZGwdq3qgbt8uWqpMHWquuXKBZ06qRYKLVuqxViFSAsZR4XRSY4Ko0t3jp48qVYXu3YNrXQZ3q20gR9nPgfAlCnw1lsZGKTI0WQcFUYnOSqMTnLUmvS0Taec1tNW5FDR0ap1gpMTeHurbf/9p1bseHiWb8LXzz+HIUPUsfv3Q61aKZ//k0/UomwA589DlSrJC7sJX5s0gWbN1LFxcaon3e+/w9ixiQ30M6GhfkwMbNyoZuAuWaJeZgJ3d+jQQRVw27ZVtW8hhBBCGMjVq6pR/c2bmCtUpF+h9fzl74OtLcycCX366B2gEEIIIXIaWYgsk+W0om1AQAC+vr56hyGymuBg2LYteWE34fsBA9SqHwB790KdOimf69NPVbNZgHPnoFQp9b2tLcTHo5lMmDQN3nxTTZuxtc3wlxMXp9aXW7RIzcK9ejVxn7OzKtx27QodOz6bDhEia5FxVBjV4sUwahScPGmmXDkbRoxIe1t2IZ6ldI2jmgbvvkv8lu10dVvHsp15cHKCBQvUB69CZCT5WS+MTnJUGF1OyVFZiExkqMuXL+eI/zgig3l7w/PPp+1YX1/Vb+7hwm7C13r1Eo8NDVV9CaKjVe9aUAVbgJ9/VhXU775T981m9TUDVhaxs1NthZs2hcmTVZ150SJ1CwqCf/9VN3t71Tqha1fVSiFv3qd+apENyDgqjGjxYnW1gMkEmmbD0aPq/qJFUrgVxpOucdRk4tYXk+myNYIdO93w8FCtjxo3zpQQRQ4nP+uF0UmOCqOTHLUmRVshhDE4OEDJkur2ONWqwf37qvns8OHw3XeYbWywMZvVeZIuyLZ9u6pANG2q+tk1a6YWfnvK1UZsbKBuXXWbOBEOH1bFj0WLIDBQLWa2ejUMHKj+MOzWTS1mVqjQUz2tEEI8NbMZjhyBzZvVOpOgJiMm/dqjB1SoAPnyqQ+e8uVLvD18381NFnASBrNli2pEP2sWl2860qqViVOn3MibF9asgerV9Q5QCCGEEOLxpGgr0sQmA2YpCpGhTCY1m/a772D0aFZXr077gwdVEffIkcQpYps3q5m6CxeqG0CBAqp426wZdO6s+uY+ZSi+vuo2erRa7yShgHvwoAph82Z4+21V5O3WTYWX2jpyIvuRcVToJWmRdvNm2LpVda8ZwUjewZaxJO8B/kncGGyPxDOKkY89v6OjdRE3tUJv3rzWa1sK8STSNI6uW6d+tt+/z60ClWmw+AsuX4bChcHfX31uK0RmkZ/1wugkR4XRSY5ak5626ZTTetoKYTgpLTr28PaYGNXHYNMmddu5U7VVSLBvH9Ssqb4/f171NihcOMPCvHBBFXAXL1ZPnXTE9fVNLOBWqJBhTymEyOFSKtIm5eYGP/mM4ZWzwxnOaMYkKdwOYwyjGc6Zl0ezu9Uwbt6EW7fg5s3E261bcOOGuujhSbm7P372bsL9PHnUsCxEmixfDi+8ADExhDRoR6VTi/jvthNly6pabpEiegcohBBCCJGNFyILCwtj2LBh/Pvvv9y8eZNq1aoxefJkaj1YoV7TNEaMGMFvv/3GvXv3aNCgAdOmTaN06dKWc9y9e5e3336b5cuXY2NjQ7du3Zg8eTJubm5pjiOnFW3PnDlj9R4KobuRI9ViYw8KtlY5OmaM6nU7cmTyx0VFwa5dqoC7Zw+sWpW4aNmAAfDnn6pFQ0IrhWbNwMcnQ0K+dk31vF28WBVSHrTjBaBcOVW87dZNdX+QS42zHxlHRWZJa5G2UaPEvtzVq6s+3YE9RlHhn5GWwu23fMAHfM/Fpn0pOv5N9cCkN0dHqwEqIoIUi7qPuh8b++SvL1eutBd5c+XKkBbmwqBSHUcXLIDevSEujluNu1L+0DzuhDlQvbpqiSD95cWzID/rhdFJjgqjyyk5mm2Ltj169ODYsWNMmzaNggULMnv2bL7//nsCAwMpVKgQX331FePHj2fmzJkUL16cYcOGcfToUQIDA3FycgLAz8+Pa9eu8csvvxAbG0v//v2pVasWc+fOTXMcOa1ou3z5cjp27Kh3GEKkKENy9MUXVUU1YfGyBOXKqSLuDz8kFnif0u3bsGyZejp/fzUhOEGxYokF3Lp1pQCRXcg4KjJKfHzyIu29e9bHpFSk5fZt2L1bfXi1cyfs28f5Bi9TYt3PROOAIzEPP521f/9Vl54DrFgBo0YlL+y6u6uv3btDpUrq2GvX0I4cJRw37kS7cTvKjRuR7lwLc+NasBO3bpuSFXlv304+HD+Ora2anZuWXrx584KHh3xIlpWkOI7Ong19+4LZzJUmvSi7exYR0XY0bqwm3+aAX9WFQcjPemF0kqPC6HJKjqa1ppiletrev3+fRYsWsXTpUho/WPJ15MiRLF++nGnTpjFmzBgmTZrEF198QadOnQCYNWsW+fPnZ8mSJfTs2ZMTJ06wZs0a9u3bR80Hl0T/+OOPtGvXjm+++YaCBQs+8rmjo6OJTnJJdWhoaCa/WiHEM7dgAYSGwrZtsHGjmo0bEKCa1JpM1gXbqVPhuefUKmNeXk/8VHnywKuvqltIiJrwu2iRWrzswoXEdr0FCqgFzLp2hSZNHhRdhBA5ylMVaUE11x4wWRVqz5xJdv4SnSrDZgccY2LUg2rVgvBw61tCH4SkVyVdvQr796ccuK9vYtF2yxZMvXrhDrgDxZIeZ2MDs2ZBnz7q/o4d8NlnaK5uRDu4cd/GjQgbd0LNbtyLc+NQgXYcs6nCzZtw/8pdvK4GcvmeO1fD3AiPdyPshhs3brgAj6/GOjikXNR9eFvevODi8thTimft7l0YPBjMZs416U+F7b8RE29Lhw7wzz/SQ1kIIYQQWVeW+vM/Li6O+Ph4y4zZBM7Ozmzfvp2goCCuX79Oy5YtLfs8PT2pU6cOu3btomfPnuzatQsvLy9LwRagZcuW2NjYsGfPHrp06fLI5x4/fjyjRo1Ktn316tW4PPgNvlWrVty5c4eDBw9a9terVw87Ozu2bdtm2ValShUKFSrE6tWrLdtKlChBxYoV8ff3JyoqCoB8+fJZYr99+zYALi4utGjRgqNHj3LhwgXL49u3b8+FCxc4fvy4ZVuTJk2Iiopiz549lm01a9bE09OTDRs2WLaVK1eO0qVLs3LlSswPprQULlwYX19fNm/eTFhYGGazme3bt9OwYUP279/PtWvXALC3t6dt27acPHmSM0n+EGzdujW3bt3i0KFDlm3169fHxsaG7du3W70XBQsWZM2aNZZtJUuWpEKFCqxbt85SKM+fPz+1a9dm586d3LlzBwBXV1eaN2/O4cOHuXTpkuXxHTt25Ny5cwQGBlq2NWvWjIiICPbu3WvZVqtWLdzd3dm4caNlW/ny5SlVqhQrVqwgYRJ6kSJFqFq1quW9AMiVKxcNGjRg3759XL9+HQAHBwfatGnDiRMnOHv2rOWcbdq04caNGwQEBFi2NWjQAIAdO3ZYtvn6+pI/f37Wrl1r2VaqVCnKly/P2rVriXkwFdPHx4datWqxY8cO7t69C4C7uztNmza1ei9MJhMdOnTg7NmznDhxwnLO5s2bExYWxr59+yzbateujaurK5s2bbJsq1ChAiVLlmT58uWWbQnvxcaNG4mIiAAgd+7c1K9fn71793Ljxg0AHB0dad26NYGBgZw7d87y+LZt23L16lWOHDli2dawYUPMZjM7d+60bKtWrRp58+Zl3bp1lm2lS5emXLlyrFmzhtgH19cWKFCAmjVrsn37dsxmM8uXL7e8FwEBAVy+fBlQzczbt2/PmTNnOHnypOWcLVq0ICQkhP1Jig516tTBqVEjtpjN0LQp9mFh+IaEkC9XLlY+eC9sYmPxGzIEm6goNBsbQkqU4HblysQ2bEj5119nT2AgN2/eBMDJyYlWrVpx/Phxzp8/b3kePz8/rly5Ynkv3Nzg998bERoax88/B7FzZwH27cvPtWv2TJ2qasTu7jHUqXOdF16woV+/59i4cTVxcXEAFCxYkBo1arBt2zbuPajmeHp60rhxYw4ePMiVK1cAsLW1pV27dpw+fZpTp05Z4mnZsiXBwcEcOHDAsq1u3bo4OjqyZcsWy7ZKlSpRpEgRVq1aZdlWvHhxKlWqxPr167n/oLCTN29e6taty+7du7l16xagxuqWLVty7NgxgoKCLI9v164dly5d4tixY5ZtTZo0ITo6mt27d1u21ahRA29vb9avX2/ZVrZsWcqUKcOqVauIf9BvolChQlSvXp2tW7cSEhICgJeXF40aNeLAgQNcvXoVADs7O/z8/Dh16hSnT5+2nDOzxvKEHAX9xnIAb29vGcsNPpYfPHiYrVvvcexYHo4dy82pUz6PKNJq1K4dQ+HC56hc+Q4lS4ZQv1wp3I8f5/K3/7DH15e7lSqpsfzePVUUfSCqeHGcmjblpLc314sXx2f7dsrFxBBvZ4dtXBwnixfnTM+eVmP5+dOnsY2KIj40lDaxsVy9epXTdnZ4DBuGXVQU5Z57DsLDuXziBLb372MXFYWzhwfe0dGsW7eO/MePU7Z4cZzj4nCIjiYuJAS7hA/DzWZwcmL79u0EBwdTcNs2amzdiglwenDzTvLaS46HIhUvApDvwAHqPOL3M81kItbBlb9rDmGZTx9CQhwpFnaNV0+O5HaUE3fjPAmJ9yA8xo3w/9RtK41Ziy8ALkRQhtOE42a5ReCKk7OGh0cUnp4xeHlFU6FCPpydw4iJ+Q9Pz2g8PWNo1qwi3t6xnD69E3t7lX/Vq1cnd+7c+Pv7W2IsU6YMZcuWZfVqGcvTOpYnjG3JxvLly9k5dA6NtvyEGVuaNv2PuXPzcPdu9vy9HGQsN+pYbjab2bx5c47/vTz4QY+eDPm93MnJavyqWLEixYoVY+XKlZZtxYoVo3LlymzYsIHIyEgA8uTJQ7169dizZ88T/14O0KhRI+Li4ti1a5dlW3YYyxN+H83pv5fLWG7csTzp30xG+L08s8byhLHqcbJce4T69evj4ODA3LlzyZ8/P/PmzaNv376UKlWK6dOn06BBA65evUqBAgUsj+nevTsmk4n58+czbtw4Zs6caTUogvrPO2rUKAYNGvTI533UTNvChQvnmPYIkZGRluK0EEb0THP0zh344gs1GzfJLxWAmo379tvw/fdP/TQxMbBhg2qhsGSJulQ4gbs7dOigWii0bQuurk/9dCKTyTgqUpKWmbTu7tYzaatVicfudKCaPZtwS/q7zfvvq+n6oGbKTpwI9epBnTqq8WuCJIs3Rg4Zgsu33z56kcfMEB8PkZEqPk/PxGmsly+rFg4Pz/YNC1NfX39dvRZQ/WX+9z/r45L6/XfVrxxg7Vo1YKZgb8/v2FztfW7eBI/juxi+pn6yYyJwIRw3vuRzfuQdAIpygW8ZQhjuVkXecNyId3bnUt4a3C3iS758UCBXNKXtL+BR0A2v59zIVdiVPD52ln68GdSBJ9uyGkdv3oR8+dA0+PLLxHQdPBgmT5bWQkIf8rNeGJ3kqDC6nJKj2bI9AsBff/3Fq6++SqFChbC1taV69er06tXL6lOozODo6Iijo2OmPoeRhYSE5Ij/OCLreqY5mjs3TJumvr9yRVVZEtopBAVZL1x29Sr06qUWNGveXBVM0jiWODiAn5+6TZumujYsXqxuV6/CvHnq5uys6hDduqlCrqdnxr9k8fRkHBUJ4uPh8GHrIu2DyScWyYq0xYKxiwhRTa8BLlyGKlWSn7xMGVXQbNIkcZubmyrCPixJwZZhwwi5dg2XhMrX8OHqa2YWbm1t1Qt1d7feXriwuqVFq1bWLR/MZtXKIaGAmzt34r6KFWHGDOsCcJJb7X4VqN3mwbE7zHCkYOL+B7NkXInElUhe7xdH5fqqbuh8+DrdFix+dHz3YeSlEYy65AtAec4xhYoPHeJEOG5cxJ3Zrm/yT7GPyJcPSnre5vUTH2Dj4YadlxsOud1wzuuOSz433HzccKlZAZNvVXWS+Hj1gyGhr7C9fdrevywmJCQEF2dnGDsWJk3CvGETH86qYvmcdPhwtQap9CkWepGf9cLoJEeF0UmOWstyRduSJUuyZcsWIiIiCA0NpUCBAvTo0YMSJUrg86BQcuPGDauZtjdu3MDX1xdQ054TLo9IEBcXx927dy2PF8nt378/RzSDFlmXbjlaqJDqw5jQi/HCBeumh5s2qYrM1q1qwR5nZ6hfXxVwmzWDmjXT9Me1nZ06vFkzNYNozx5VvF20SNWJ//1X3eztoWVLVcB9/nlZLdtIZBzNuZ64SNvYTDWnE9jtezCDdvouOHECOnVS0+4BihaF0qVVb+369VWhtm5d6yJlWgJLMqPWkqMJhdoHlzZmKTY26tIDV1fIn99633PPqcWq0qJBA/WhHICmQVSU1YzfyvnzUznh9NeKQtOfrArAWlg4MXfDiQkOp3uj8lSspBZXszkcTeQMLxxjw7DV1PvrTBTORJGX2xARzvHjcPw4XOU2v/FXiiH+YPMuEwtMIm9eKOdxg3lbi1j2xdk5YnZ2Q3Nzw+TuBj164jD6C7Xz/n01E/vhheMSbiVKQOXKia89OFhtd3BI23uXkUaOVMX9hBzdt4+Ou3fD+PEAHG//Ed9fVZd/TpoE77777EMUIin5WS+MTnJUGJ3kqLUsV7RN4OrqiqurK8HBwaxdu5aJEydSvHhxfHx82LBhg6VIGxoayp49eyxtD+rVq8e9e/c4cOAANWrUAGDjxo2YzWbq1Kmj18sRQmQXCbPgEjRtCr/8kjgT9+ZN1fMgoefR3LlqJi6oy4QdHR97fayNjarP1Kunrng+fFgVbxctUnWd1avVzcZGTbbr2lUtZlaoUIa/WiHEI6RrJm01sLPV1H/YLzclfwCoql8Ck0m1Q3iaKYUjR6a8L7NbI2QlJpP6wM3Z+dGfhBUooFo0JH0I4PjgVuHBTakGvwSrYmh0tKXIGxscTujVcF608aG+vfpRER6Um9UbvyY2OJz4UHWcTUQ4tlHhOMWFE2gux5UrqrYcRiSx2GGP6qdoFxcNYdEQdgeuweQxt/jsW7WgWnmve6wK+CXFlxvRvR/2f01XNdrIyMQPAuztrYu7bm7qUpCEnsKaBh9+qArmDxeC3d2hYEGokPhOEBWlfuallsO2tomzvr/4gop//AHLlll2/3O1Aba28Oef8MorKZ9GCCGEECIrynJF27Vr16JpGmXLluXs2bMMHTqUcuXK0b9/f0wmE++99x5jx46ldOnSFC9enGHDhlGwYEE6d+4MqCbIbdu25fXXX+fnn38mNjaWwYMH/5+9+w6L4uzaAH4vHaQpgoLSVBB7AQXEghVrNJbExPiqMdEkamLqF/NGsUXTo0ksMW+iJtEUY0nsFTt2sXdRsYGNLnWf74/HbbAgIrAD3L/rmguYmZ19djkMu2fPnAeDBw+Gh4eHaR8cEVU8tWoBo0bJRQiZVdUkcHfskNkajW+/BT79VGZaNe0UGjcutDGfSiUnaG/eXF7pfOaMroXCkSPybqKiZJvdkBBZgdu/vyykIqKSUdQkbfv2soq2u+85NEiMhvmBaGDffeD95Y/2UslsXVKSrNhv3Vr3CU1ISP6EIa8BL79UKsDGRi7Vq8PSB3BpAbgAaKDdyRX473tGb56RAdS/A7yaIEMmIaEeZt/Jxr1bWUi+mYrU26l4eCcVGXdlxe/VbHekp8uLQR7AFpMwxaD7rgNStN+v/ssPM/+SrXYaVEuFdgqe7GxZdftogiEAeODeANkJMq9rnpWh66NsTL9+8pIQQP4/dHCQX/Mmgu3tgbZtZQsE/XYdf/6JOnqTwUzEVHxhPRHL/5RF6EREREQVTbmbiOyvv/7ChAkTcP36dVSrVg0DBgzAJ598AqdHTRyFEIiMjMSCBQuQmJiItm3bYu7cufD399ce4/79+xg7dixWr14NMzMzDBgwAN9++y3s7e2LPI6iNg2uKBISEuDm5mbqYRAVqFzGqFptmJDt29egggiAfCccHi4TuMOHG7ZeeAxN24TlywG9SYAByCSvJoGrX/hEpadcxigZlZsLxMTokrS7dhWSpA0HelXdC/+4LTDfHy0n2NKfZUylkj9rXkvs3SsrOps0kX1RyhBjtGISQhb03rmjSfDKpaCf79wBHk2ADgCwQDaqIC3PFGtyuY2aOIwgqFRA7WrpiMQUuFinoqplKpzMU+GgSkUVkQqb3FSkBndB2tSv4OYGONtmQmVrU/Cg9VuBAFCbm8NMrYaArGKeiKmYZT8R//4rP+MkUgqeR0npGKOkdJUlRouaUyx3SVulqGxJ2+Tk5ErxOKn8qhAxmpMDHD0qS2O3bQN27wbS0uQ2OztZ3aTpKbhnj+zXWLdukartbt6U73+XL5cFvvqtKgMCZPJ2wAB5iTaL90pHhYjRSqooSVpHR6BdW4FnG51HJ7t98JzwEiysH7U6GToU+O033c62tkCrVroq2ogIWXFpYoxRAuTniYmJRU/y3rsnE8NPwsJcwLd6CrxdUlHbORW1nFJRs0oK3OxSUd0mFTbeNWDWKRxubkD0HjXu/+ctvIG5MIcambCCDTLx2WfABx+UylNAVGw8j5LSMUZJ6SpLjDJpW8oqW9J29erVbAZNilYhYzQ7Gzh4UCZwU1Nl6wSNBg2As2flDOuaGco6dpSTEz3G3buyoHf5cmDzZnk3Gj4+ugRuSEihnRnoCVXIGK2g8iZpd+4EkpMN93F0BLqFpmCQ9wGEmUXD/Wo0zPbvA+7flzucOCHbmwDA778Dq1frkrTNmhVpAsKyxhil4sjJkYnbvEndghK9xto1P87HmIZpmIRMWMEaWZiEqfi32UTExJT4wyF6KjyPktIxRknpKkuMFjWnWO562hIRVRqWlnJW+DZtDNdnZMjelpcuAXFxwC+/yAWQzWqHDJEzwhegenXg5ZflkpQErF0re+CuXy/7HX79tVzc3eUEZgMGyMu8y/hKbaIyU6QkrYNAeHs12nc0lxOH7Z0Ds/FvyrJEfTY2QFCQrkoekJMNaiYcJKpgLCzkhR81ahRt/8xMw1YMhSV5ExKAdx/KhO1ETMV0TNQmcM1PAQAnzCMiIqKKi2/BiYjKGxsbmVVKS5P9LzXtFA4dAi5flr0QNHJygHfflZO6hIfnm8jIyQl48UW5pKcDGzfKCtzVq4Fbt4C5c+Xi4iJbDPbvD3TpIif8JiqvcnLytzvIm6R1d0jF8EYH0aNqNJqkRsPpzD6oXv2fbsajO3VlwtbLS36wol9Fq2ljQkT5WFsDtWvL5bGmTQMmTcKkRwlbAJiOiVABmJozCZgG3WRlRERERBUM2yMUU2Vrj3D58mXU4XTzpGCMUcis0+7dstwpMFCuO3hQzkCv0aSJrpVChw5A1apGD5WZKfPAy5fLXrj37um2OToCvXvLBG737kCVKqX3kCoSxqjpFCVJ6+gIDAq8jLGZX8H/XjRsLx6HSr/5MwD83//p2pQ8fCj7THt4lMEjKBuMUVKcyZNx+pw5Gv0xESqV7J2r+Xpq8DQ0rJ8LTJ5s6lESafE8SkrHGCWlqywxyp62payyJW3VajXM2NySFIwxWoDz54E5c2Q17okThttUKllG+9prhR4iJ0cmuZYvB1auNCzktbWVidsBA2Qi18mpFB5DBcEYLTuPS9LaIh0d7A7hea9oOIU2hNeYPmjeHDC/fAHw99ftWLu2roI2NFTO1FeBy8wZo6RUK1bIrj/nzgnUr69CZKRs30OkNDyPktIxRknpKkuMMmlbyipb0rayNIOm8osxWgR37sgMlqadwrlzss1Cu3Zy+z//ADNnAp06yUrcsDDAzs7gEGo1sH+/fAO9fDkQG6vbZmkpWycMGAA880y+TgyVHmO09BSepBXwwRV0to1GvxrRCMqJRo1bx6DKzZGbBw0C/vrr0a4C+OgjoGVLmaQt0vXbFQdjlJSOMUpKxxglpWOMktJVlhjlRGRERGTI1VUmqAYNkj/fvGmYWd28WWZk9++XyVtLSyAkRNdOoU0bmFlZaYsOP/9cJso0CdwzZ+RkZuvXA2ZmsvvCgAFAv35ArVqmeMBUUeXkAEePGiZpU1LkNhs8RE3chsrJF+3bA13CMjDuv/5QPcwBrugdxMNDBnL37rp1KpWMfSIiIiIiIhNj0paIqLLK24vzww+BVq1kFW5UFBAXJ7Nhu3bJ61JjYwEfH7lvfDxU1aqhRQtLtGgh54o5c0YmcFesAI4ckYeIigLGjpW5sf79ZRLX17fMHymVcwUnaQW8cA09EY1wq2h0sotG3eSjyKjfDDYnDsHcHABsgdXBQHa2YasDT0+ZpCUiIiIiIlIgJm2pSHw0iRoihWKMloDatYFhw+QiBHDpki7zqp+wBYBRo4CtW4G2bbXtFBq0aIH//tcC//2v3F2TwN27F4iOlsv778u2oJoEboMGJnu0ZY4xWnSFVdJq/GA1DgNUy+GSeUuuyHq0AKiSmgCIHGhf5uzcKcu/qVCMUVI6xigpHWOUlI4xSkrHGDXEnrbFVNl62hIRaQkB+PnJpK4+R0egfXt5ufmYMdrVN28Cq1bJFgo7dgC5ubqbBATI5G3//jKZy8LHyqmgJG1txCEU0QhFNJpZnMLsHhsR3lGF8HCg2aeDYfbXn4CFBdC8uWEVrbc3g4mIiIiIiBSJE5GVssqWtN26dSs6d+5s6mEQFYgxWsbUauDkSV0rhR07gKQkua19e/mzxtKlMqnWoAHu3lPh339lAnfzZnnFuoavr0ze9u8vW+lWtMJIxqhOQUnaRjiJbtiEUESjjSoatcQNwxuePQvUry+/P3wYSE8HAgPzTZhHxcMYJaVjjJLSMUZJ6RijpHSVJUY5ERmVqPT0dFMPgahQjNEyZmYGNG0ql/HjZfns0aMygas/69j9+8BLL8nq3Bo1UD08HC936oSXZ3VEkms9rF2nwvLlcvKy2Fjgq6/k4u4OPPusrMJt314WU5Z3lTlGc3Jkn2NNknb3bsAh5QZCEY3d6IoUOMHZGYh0XYpBFx5NBCYAmJsDzZrpKmhr1NAdNDCw7B9IBVeZY5TKB8YoKR1jlJSOMUpKxxg1VAHeBhMRkcmZmwNBQXLRd/cu0LmzzNLFxwN//ikXAE61auHFjz/Gi8tfQ3o6sGGD7IG7ejVw6xYwd65cXFyAvn1lArdzZ8Da2gSPj55I3iTt/l1ZqJsagzbYi2GIxnxEwwtxAICVr66Dz+s90LQpYB7VCfj2pEzQtmkj46lKFZM+FiIiIiIiIlNg0paKpHr16qYeAlGhGKMK5e8v+yBkZgL798tK3G3bgH37gBs3AEtLAPLq9v4NzqC/9ZfIntURO8074vedtbBqFXDvHvDzz3JxdAR695YJ3IiI8pXPq8gxmq+SdqcaKWmyv0Uf/IvreB62yDC4jTAzg6ppUzzbJwdo8Whlly5yIZOoyDFKFQNjlJSOMUpKxxglpWOMGmJP22KqbD1tiYhKVHo6EB0NNGkCuLnJdbNny1YLGv7+UHfoiNPunfBbXDh+2eCGW7d0m21tgR49ZA/c3r0BJ6cyfQSVmn6Sdte2bCTvjEGzh3LCsDbYi8/xAZY6j0GHDkD/+qfwn88bQ7i4QBUSoquibdUKsLc39UMhIiIiIiIqU5yIrJRVtqTt/v37ERwcbOphEBWIMVoBHD4sWydERcmMoFptsFm9Yxf2W7bF8uXA8r8FrlxVabdZWsoCzQEDZCsFJX5AW55jNCdH/no0lbRndt3F62lfoA32IgiH8lXR3u85BE7//gZzc8jf48WLgJ8foFIZOzwpRHmOUaocGKOkdIxRUjrGKCldZYlRTkRGJSohIcHUQyAqFGO0AggM1E0ulZgI7NwpWylERQHnzsEsqCVC7WSh5hf4AA/XbsURp45YcqMjllxvj/XrHbF+PTBqFNChg0zg9utnOC+aKZWnGM3OlnnznVuzcW3NcVgdjsatrGr4HS8CAKrABu/hS5hDJtZzHKvCvE0IVGFtgNBQVGvdGjB/dDAzM9kmgxSvPMUoVU6MUVI6xigpHWOUlI4xaohJWyIiUh5nZ+CZZ+QCAMnJsvHtI6ptW2F39ija4ija4mvMNTfHTfdAbMrqiN8TOmFLVBdERZlh7FiZ5B0wQLZR8PU1zcNROk2S9sCaBNxfGw2Hk9EIzI7GGByEHR4CAA6YhyK994sIDwfCw+2hWjkJ8PECQkNh4e8vk7NERERERERUIpi0pSKxsbEx9RCICsUYreDyXjKydq28Tv/RxGaqS5dQ6/oBjMABDHX7BbPfv4HlK2Tb3KToU/hvdF28954NWrSQydsBA4AGDcr2ISgpRrOzgSMHcnD03zj8c9wXu3cDqakCN9AcHrhlsG+GrTOyWoYgqHc4Vn2ot6F5ZNkOmkqdkmKUyBjGKCkdY5SUjjFKSscYNcSetsVU2XraEhEpWlycNoELFxfgq68AADevq+HcoCYs0pOxW90GUeiIKHTEAbRG3QArDBggE7jNm1fsdqvZ2cCxrXdx5fdo5OyKhsfVaLRUH0Qq7OGOWwBUqFoVWGM7EPXVZ4DQUFTt2QZmYaFA/fqsoiUiIiIiIiohnIislFW2pO2pU6fQqFEjUw+DqECMUTLqxg2gVSvglmH1aBrssBtt8Qv+g6UYAl9fWYHbvz8QElI6OcqyjNHsbN3EYTV+noG2FxfBT1zIt1+ahSOWTjqH1s/URJMmgJnIhZw9jCojnkdJ6RijpHSMUVI6xigpXWWJ0aLmFFk6Q0Vy+fJlUw+BqFCMUTKqVi2ZuD1zBpg7Fxg0CKheHVWQjghswgD/k7C1BWJjgR++SsHfYV+je82jGDdGjW3bgJyckhtKacZodvx9nP16HfZ0mogj1bvCyzkZoaHAhAnA3QsPtAnb6/YBONV6BOImLoD62AlUybiPVyfWRLNmjxLVTNhWajyPktIxRknpGKOkdIxRUjrGqCH2tCUioopNpQICAuTy+uuAWg2cOgVERaF/u3a4Wx/YsAG4+O0ufLDjXeAOcG9uNeyY2wETq3SEZUQnhLzcEJ27qGBtbeoHI2VfvIq4/21E6pZoVD0bDc+0cwjQ294IB5BVrQs6dADc6w9HrGcneD8XjNrVq6G2yUZNRERERERERcWkLRERVS5mZkCTJnIBYAfZFgEuVZD7aU+IHTvh8vA++mMl+qetBFYA8Svc8ILdL7DtF4EBA4Du3QE7uzIa74MHyNm9DzGiGTaf8sD27UCD7eswK+sNg90umvnjWu1QICQU345qhICOmjYPjR4tREREREREVF6wp20xVbaetjk5ObCwYI6flIsxSiXmUUPY3K1RSFoZBftju2GV8xABOANNPetQyz8wsuYaWHfvhIZjOsKxmW/+40yeLNsNTJwIIE+MTpsG5ObKffSp1cCZM8jZHY37a6Jhtj8a1e+cAQCMwg/4EaMAAI1xAnMt3sLtum1g3SEUdYeEoEFbF84XRk+F51FSOsYoKR1jlJSOMUpKV1litKg5xYr/TFCJuHHjBry9vU09DKICMUapxFhaAiEhMA8JQbX/TgAyM6E+cAgLzetj+Qpg+XKg15WV6BD3F/DjEuBHIN7WG0ktO8H9xY5weKYjULu2TNhOmiSPOXGiLkanTZPrp04FhABUKmRnA2d+PQT/MV1gk5EECwBuekO6gHqws1Ph2QggPBwID2+Cxo23MUlLJYrnUVI6xigpHWOUlI4xSkrHGDXEpC0VyfHjx/mHQ4rGGKVSY20Ns3ZhCAUQ2gb44gvgwqI3sf0nPzgeiUKThwdQ4+FV1NizENizELljzPDTl4noPXIiPABg0iTMmQO8c+9DLHR6Ey/e+w7qloHIWPgnYrY+xBTrGdi9G7BMr4dEJCENdjiA1oixDUVG81BU7x2CkD6u+LoRmKSlUsXzKCkdY5SUjjFKSscYJaVjjBpi0paIiOgJqFSA/4gw+I8IAwCcPZSKI9/tRtaGKDRMiEIuzDH6PQfgPcDffyI24UeMiZ+ENzAJqnvyGGZHDsMOQHasCzY9Oq6LizPGtziJer3qo0NnC7zFJC0REREREVGlxaQtERHRUwgIskfA4u4AuuPyZWDV3zkIXQVERwPXzj9ETcQDAFQABICdaI9ohOKUQygs24Xg2+6y5UGjRoCZGScMIyIiIiIiIk5EVmyVbSKyxMREODs7m3oYRAVijJLS3LgB+PgAU3MmYAI+RRYsYYVsTMRUfG41EQ8fspKWlIXnUVI6xigpHWOUlI4xSkpXWWK0qDlFvl2kIsnJyTH1EIgKxRglpalVC5jlMg0T8CkmYiqskYWJmIppmISvq01jwpYUh+dRUjrGKCkdY5SUjjFKSscYNcS3jFQk0dHRph4CUaEYo6Q406ZhTPwkTMRUfKKaCAD4RDUREzEVY25PAqZNM/EAiQzxPEpKxxglpWOMktIxRknpGKOG2NOWiIioNOTmAlOnokWjiWg6FTh9OhcNG5qjZeRE4OSj7URERERERERGMGlLRERUGiZPBgD0B9C/P7B69Tr06dNHbnt2osmGRURERERERMrH9ghUJC1btjT1EIgKxRglpWOMktIxRknpGKOkdIxRUjrGKCkdY9QQk7ZUJC4uLqYeAlGhGKOkdIxRUjrGKCkdY5SUjjFKSscYJaVjjBpi0paKZPPmzaYeAlGhGKOkdIxRUjrGKCkdY5SUjjFKSscYJaVjjBpi0paIiIiIiIiIiIhIQTgRWTEJIQAAycnJJh5J2UhPT680j5XKJ8YoKR1jlJSOMUpKxxglpWOMktIxRknpKkuMah6jJrdYECZtiyklJQUA4OnpaeKREBERERERERERUXmSkpICJyenArerxOPSumSUWq3GzZs34eDgAJVKZerhlKrk5GR4enoiLi4Ojo6Oph4OUT6MUVI6xigpHWOUlI4xSkrHGCWlY4yS0lWmGBVCICUlBR4eHjAzK7hzLStti8nMzAy1a9c29TDKlKOjY4X/w6HyjTFKSscYJaVjjJLSMUZJ6RijpHSMUVK6yhKjhVXYanAiMiIiIiIiIiIiIiIFYdKWiIiIiIiIiIiISEGYtKXHsra2RmRkJKytrU09FCKjGKOkdIxRUjrGKCkdY5SUjjFKSscYJaVjjObHiciIiIiIiIiIiIiIFISVtkREREREREREREQKwqQtERERERERERERkYIwaUtERERERERERESkIEzaEhERERERERERESkIk7ZUqDlz5sDHxwc2NjYIDg7GgQMHTD0kIq2dO3eiT58+8PDwgEqlwqpVq0w9JCKtmTNnolWrVnBwcICbmxv69euHc+fOmXpYRFrz5s1D06ZN4ejoCEdHR4SGhmL9+vWmHhZRgT799FOoVCqMHz/e1EMhAgBMnjwZKpXKYAkICDD1sIgM3LhxAy+99BJcXFxga2uLJk2a4NChQ6YeFpGWj49PvnOpSqXCmDFjTD00k2PSlgr0559/4p133kFkZCSOHDmCZs2aISIiAgkJCaYeGhEAIC0tDc2aNcOcOXNMPRSifHbs2IExY8Zg37592Lx5M7Kzs9GtWzekpaWZemhEAIDatWvj008/xeHDh3Ho0CF06tQJffv2xalTp0w9NKJ8Dh48iB9++AFNmzY19VCIDDRq1Ai3bt3SLrt37zb1kIi0Hjx4gLCwMFhaWmL9+vU4ffo0vvrqK1StWtXUQyPSOnjwoMF5dPPmzQCAQYMGmXhkpqcSQghTD4KUKTg4GK1atcL3338PAFCr1fD09MS4cePw4Ycfmnh0RIZUKhVWrlyJfv36mXooREbduXMHbm5u2LFjB9q3b2/q4RAZVa1aNXzxxRcYOXKkqYdCpJWamoqWLVti7ty5mD59Opo3b45Zs2aZelhEmDx5MlatWoWYmBhTD4XIqA8//BB79uzBrl27TD0UoiIbP3481qxZgwsXLkClUpl6OCbFSlsyKisrC4cPH0aXLl2068zMzNClSxdER0ebcGREROVTUlISAJkUI1Ka3Nxc/PHHH0hLS0NoaKiph0NkYMyYMejVq5fB61Iipbhw4QI8PDxQp04dDBkyBNeuXTP1kIi0/v33XwQFBWHQoEFwc3NDixYt8OOPP5p6WEQFysrKwm+//YaXX3650idsASZtqQB3795Fbm4uatSoYbC+Ro0auH37tolGRURUPqnVaowfPx5hYWFo3LixqYdDpHXixAnY29vD2toar732GlauXImGDRuaelhEWn/88QeOHDmCmTNnmnooRPkEBwdj0aJF2LBhA+bNm4fY2Fi0a9cOKSkpph4aEQDg8uXLmDdvHvz8/LBx40a8/vrrePPNN7F48WJTD43IqFWrViExMRHDhw839VAUwcLUAyAiIqroxowZg5MnT7LPHSlO/fr1ERMTg6SkJPz9998YNmwYduzYwcQtKUJcXBzeeustbN68GTY2NqYeDlE+PXr00H7ftGlTBAcHw9vbG3/99RfbzJAiqNVqBAUFYcaMGQCAFi1a4OTJk5g/fz6GDRtm4tER5ffTTz+hR48e8PDwMPVQFIGVtmRU9erVYW5ujvj4eIP18fHxqFmzpolGRURU/owdOxZr1qxBVFQUateuberhEBmwsrJCvXr1EBgYiJkzZ6JZs2aYPXu2qYdFBAA4fPgwEhIS0LJlS1hYWMDCwgI7duzAt99+CwsLC+Tm5pp6iEQGnJ2d4e/vj4sXL5p6KEQAAHd393wfxDZo0IBtPEiRrl69ii1btuCVV14x9VAUg0lbMsrKygqBgYHYunWrdp1arcbWrVvZ646IqAiEEBg7dixWrlyJbdu2wdfX19RDInostVqNzMxMUw+DCADQuXNnnDhxAjExMdolKCgIQ4YMQUxMDMzNzU09RCIDqampuHTpEtzd3U09FCIAQFhYGM6dO2ew7vz58/D29jbRiIgKtnDhQri5uaFXr16mHopisD0CFeidd97BsGHDEBQUhNatW2PWrFlIS0vDiBEjTD00IgDyhbF+JUNsbCxiYmJQrVo1eHl5mXBkRLIlwtKlS/HPP//AwcFB2w/cyckJtra2Jh4dETBhwgT06NEDXl5eSElJwdKlS7F9+3Zs3LjR1EMjAgA4ODjk6wNepUoVuLi4sD84KcJ7772HPn36wNvbGzdv3kRkZCTMzc3xwgsvmHpoRACAt99+G23atMGMGTPw3HPP4cCBA1iwYAEWLFhg6qERGVCr1Vi4cCGGDRsGCwumKjX4TFCBnn/+edy5cweTJk3C7du30bx5c2zYsCHf5GREpnLo0CF07NhR+/M777wDABg2bBgWLVpkolERSfPmzQMAhIeHG6xfuHAhG+uTIiQkJOA///kPbt26BScnJzRt2hQbN25E165dTT00IqJy4fr163jhhRdw7949uLq6om3btti3bx9cXV1NPTQiAECrVq2wcuVKTJgwAVOnToWvry9mzZqFIUOGmHpoRAa2bNmCa9eu4eWXXzb1UBRFJYQQph4EEREREREREREREUnsaUtERERERERERESkIEzaEhERERERERERESkIk7ZERERERERERERECsKkLREREREREREREZGCMGlLREREREREREREpCBM2hIREREREREREREpCJO2RERERERERERERArCpC0RERERERERERGRgjBpS0RERERUDCqVCpMnTzb1MAo1fPhw+Pj4mHoYRERERPSEmLQlIiIiIpM5ceIEBg4cCG9vb9jY2KBWrVro2rUrvvvuO1MPrcz5+Pigd+/eph4GERERESkAk7ZEREREZBJ79+5FUFAQjh07hldffRXff/89XnnlFZiZmWH27NmmHh4RERERkclYmHoARERERFQ5ffLJJ3BycsLBgwfh7OxssC0hIcE0gyIiIiIiUgBW2hIRERGRSVy6dAmNGjXKl7AFADc3N4OfFy5ciE6dOsHNzQ3W1tZo2LAh5s2bl+92mhYD27dvR1BQEGxtbdGkSRNs374dALBixQo0adIENjY2CAwMxNGjRw1uP3z4cNjb2+Py5cuIiIhAlSpV4OHhgalTp0II8djHdOPGDbz88suoUaMGrK2t0ahRI/z8889Ff1L0XLlyBSqVCl9++SUWLFiAunXrwtraGq1atcLBgwfz7b9q1So0btwYNjY2aNy4MVauXGn0uGq1GrNmzUKjRo1gY2ODGjVqYPTo0Xjw4IF2n8jISJiZmWHr1q0Gtx01ahSsrKxw7NixYj0mIiIiIioaVtoSERERkUl4e3sjOjoaJ0+eROPGjQvdd968eWjUqBGeeeYZWFhYYPXq1XjjjTegVqsxZswYg30vXryIF198EaNHj8ZLL72EL7/8En369MH8+fPx0Ucf4Y033gAAzJw5E8899xzOnTsHMzNdLUNubi66d++OkJAQfP7559iwYQMiIyORk5ODqVOnFjjG+Ph4hISEQKVSYezYsXB1dcX69esxcuRIJCcnY/z48cV6npYuXYqUlBSMHj0aKpUKn3/+Ofr374/Lly/D0tISALBp0yYMGDAADRs2xMyZM3Hv3j2MGDECtWvXzne80aNHY9GiRRgxYgTefPNNxMbG4vvvv8fRo0exZ88eWFpa4uOPP8bq1asxcuRInDhxAg4ODti4cSN+/PFHTJs2Dc2aNSvWYyEiIiKiIhJERERERCawadMmYW5uLszNzUVoaKj44IMPxMaNG0VWVla+fdPT0/Oti4iIEHXq1DFY5+3tLQCIvXv3atdt3LhRABC2trbi6tWr2vU//PCDACCioqK064YNGyYAiHHjxmnXqdVq0atXL2FlZSXu3LmjXQ9AREZGan8eOXKkcHd3F3fv3jUY0+DBg4WTk5PRx5B37L169dL+HBsbKwAIFxcXcf/+fe36f/75RwAQq1ev1q5r3ry5cHd3F4mJidp1mzZtEgCEt7e3dt2uXbsEALFkyRKD+96wYUO+9SdOnBBWVlbilVdeEQ8ePBC1atUSQUFBIjs7u9DHQURERERPj+0RiIiIiMgkunbtiujoaDzzzDM4duwYPv/8c0RERKBWrVr4999/Dfa1tbXVfp+UlIS7d++iQ4cOuHz5MpKSkgz2bdiwIUJDQ7U/BwcHAwA6deoELy+vfOsvX76cb2xjx47Vfq+pnM3KysKWLVuMPhYhBJYvX44+ffpACIG7d+9ql4iICCQlJeHIkSNFfWoMPP/886hatar253bt2hmM+9atW4iJicGwYcPg5OSk3a9r165o2LChwbGWLVsGJycndO3a1WCMgYGBsLe3R1RUlHbfxo0bY8qUKfjf//6HiIgI3L17F4sXL4aFBS/WIyIiIiptfMVFRERERCbTqlUrrFixAllZWTh27BhWrlyJb775BgMHDkRMTIw26bhnzx5ERkYiOjoa6enpBsdISkoySFbqJ2YBaLd5enoaXa/fyxUAzMzMUKdOHYN1/v7+AGSfWWPu3LmDxMRELFiwAAsWLDC6T3EnV8v7eDQJXM24r169CgDw8/PLd9v69esbJIsvXLiApKSkfD2DCxrj+++/jz/++AMHDhzAjBkz8iWBiYiIiKh0MGlLRERERCZnZWWFVq1aoVWrVvD398eIESOwbNkyREZG4tKlS+jcuTMCAgLw9ddfw9PTE1ZWVli3bh2++eYbqNVqg2OZm5sbvY+C1osiTDD2OJoxvPTSSxg2bJjRfZo2bVqsY5fkuNVqNdzc3LBkyRKj211dXQ1+vnz5Mi5cuAAAOHHixBPfHxEREREVD5O2RERERKQoQUFBAORl/wCwevVqZGZm4t9//zWoOtW/lL8kqdVqXL58WVtdCwDnz58HAPj4+Bi9jaurKxwcHJCbm4suXbqUyrgK4u3tDQDa5Kq+c+fOGfxct25dbNmyBWFhYQYtJ4xRq9UYPnw4HB0dMX78eMyYMQMDBw5E//79S27wRERERGQUe9oSERERkUlERUUZrRZdt24dAHlpP6CrNNXfNykpCQsXLiy1sX3//ffa74UQ+P7772FpaYnOnTsb3d/c3BwDBgzA8uXLcfLkyXzb79y5U2pjdXd3R/PmzbF48WKD/r6bN2/G6dOnDfZ97rnnkJubi2nTpuU7Tk5ODhITE7U/f/3119i7dy8WLFiAadOmoU2bNnj99ddx9+7dUnssRERERCSx0paIiIiITGLcuHFIT0/Hs88+i4CAAGRlZWHv3r34888/4ePjgxEjRgAAunXrBisrK/Tp0wejR49GamoqfvzxR7i5uWmrcUuSjY0NNmzYgGHDhiE4OBjr16/H2rVr8dFHH+VrH6Dv008/RVRUFIKDg/Hqq6+iYcOGuH//Po4cOYItW7bg/v37JT5WjZkzZ6JXr15o27YtXn75Zdy/fx/fffcdGjVqhNTUVO1+HTp0wOjRozFz5kzExMSgW7dusLS0xIULF7Bs2TLMnj0bAwcOxJkzZzBx4kQMHz4cffr0AQAsWrQIzZs3xxtvvIG//vqr1B4LEREREbHSloiIiIhM5Msvv0THjh2xbt06vPPOO3jnnXdw4MABvPHGG9i/fz+cnZ0ByIrbv//+GyqVCu+99x7mz5+PUaNG4a233iqVcZmbm2PDhg24ffs23n//fRw8eBCRkZFGq1P11ahRAwcOHMCIESOwYsUKjB07FrNnz8b9+/fx2WeflcpYNbp3745ly5YhNzcXEyZMwIoVK7Bw4UJtqwl98+fPx4IFC5CQkICPPvoIEyZMwLZt2/DSSy8hLCwMubm5GDZsGKpXr45Zs2Zpb+fn54eZM2di2bJlTNoSERERlTKVKImZF4iIiIiIKoDhw4fj77//NqhOJSIiIiIqa6y0JSIiIiIiIiIiIlIQJm2JiIiIiIiIiIiIFIRJWyIiIiIiIiIiIiIFYU9bIiIiIiIiIiIiIgVhpS0RERERERERERGRgjBpS0RERERERERERKQgTNoSERERERERERERKQiTtkREREREREREREQKwqQtERERERERERERkYIwaUtERERERERERESkIEzaEhERERERERERESkIk7ZERERERERERERECsKkLREREREREREREZGCMGlLREREREREREREpCBM2hIREREREREREREpCJO2RERERERERERERArCpC0RERERERERERGRgjBpS0RERERERERERKQgTNoSERERVRDh4eFQqVSmHgZRqRk+fDhUKhWuXLmiXbd9+3aoVCpMnjzZZOMqqkWLFkGlUmHRokWmHgoREREpHJO2RERERFRhXblyBSqVqsiLj4+PqYesCJrkqP7i6OiIVq1a4ZtvvkF2draph1hiNDEyfPhwUw+FiIiISMvC1AMgIiIiIiotzs7OiIyMzLd+ypQpcHJywvjx4/PtTzojR45E7dq1IYRAXFwcVqxYgXfeeQfbtm3D6tWrTT08AEDr1q1x5swZVK9e3dRDISIiIioxTNoSERERUYXl7Oxs9LL5KVOmFLiNdF555RWEhIRof54+fTpatGiBNWvWYPv27QgPDzfd4B6xs7NDQECAqYdBREREVKLYHoGIiIiomHbu3Il+/fqhRo0asLa2hqenJ/r374/du3dr97l58yYiIyMREhICNzc3WFtbw8fHB2+88QYSEhLyHVNzWfrly5fx1VdfoWHDhrC2tja4dHv37t3o0KEDqlSpAhcXFzz//POIi4t7qsdy/vx5fPDBB2jZsiVcXFxgY2MDf39/fPjhh0hNTc23v6Z/bkZGBj7++GPUrVsXlpaWBknQ2NhYvPLKK/Dy8oK1tTXc3d0xfPhwXL16Nd/xVq5ciRdeeAH16tWDnZ0dnJyc0K5dOyxfvvypHteT0O+NunfvXnTr1g3Ozs7aPsGF9U4t7BL7hIQEvP3226hXrx6sra1RvXp1DBgwACdPnizSuEaOHAmVSoWdO3ca3f71119DpVLhxx9/1K6LiopCjx494OHhAWtra9SoUQPt2rXDggULinSfBfHw8ED//v0BAAcPHgQATJ48GSqVCtu3b8eiRYvQsmVL2NnZGSR0U1JSEBkZiUaNGsHW1hbOzs6IiIgw+FvRd+rUKfTu3RsODg5wcnJCz549C3y+Cvu9JCQk4N1330X9+vVha2uLatWqITg4GF9++SUA2WPW19cXALB48WKDdhDbt2/XHkcIgZ9//hlhYWFwdHSEnZ0dgoKC8PPPPxsd0/379/Haa6+hRo0asLOzQ6tWrbBy5cpCn1siIiIifay0JSIiIiqG2bNn4+2334atrS2effZZeHl54caNG9i9ezf+/vtvtG3bFoBM7H711Vfo3LkzgoODYWlpiaNHj2LevHnYuHEjjhw5Aicnp3zHHzduHPbt24devXqhT58+cHNzAwBs3boVPXr0gJmZGZ5//nl4eHhg69atCAsLQ9WqVYv9eFasWIGffvoJHTt2RHh4ONRqNfbt24fPPvsMO3bswM6dO2FpaZnvdgMGDMCxY8fQvXt3ODs7axNg+/fvR0REBNLS0tC7d2/4+fnhypUrWLJkCdavX4/o6GjUqVNHe5wJEybAysoKbdu2hbu7O+7cuYN///0XAwcOxLfffotx48YZ3O/w4cOxePFiLFy4sMR7ke7duxczZsxAx44dMWrUKFy7dq3Yx7p06RLCw8Nx/fp1dOvWDf369UNCQgKWL1+OjRs3YuvWrQgODi70GEOHDsXPP/+M3377De3bt8+3/ddff4W1tTUGDRoEAFi7di369OkDZ2dn9O3bV/t8Hjt2DL/++itGjRpV7MejL++kd1988QWioqLQt29fdOvWDebm5gBkArN9+/Y4deoUwsLC8NprryE5ORn//PMPOnbsiGXLlqFfv37a45w8eRJhYWFITU1F//794efnhwMHDiAsLAzNmjUr8vjOnTuHjh074tatW2jbti369euHtLQ0nDp1CjNmzMB7772H5s2b46233sLs2bPRrFkzg3Fo+hsLITBkyBD8/vvv8PPzw4svvggrKyts3rwZI0eOxOnTp7VJYABIT09HeHg4Tpw4gdDQUHTo0AFxcXF4/vnn0a1btyd/oomIiKhyEkRERET0RGJiYoSZmZnw8PAQsbGxBtvUarW4ceOG9uf4+HiRkpKS7xiLFy8WAMT06dMN1g8bNkwAELVr1xZXr1412Jabmyvq1KkjVCqV2LVrl8F9vvjiiwKAKO7Lu+vXr4vMzMx866dMmSIAiN9++81gfYcOHQQA0bx5c3Hv3j2DbVlZWcLHx0c4ODiII0eOGGzbtWuXMDc3F7179zZYf+nSpXz3nZKSIpo0aSKcnJxEWlqawTbN87Rw4cIneZhaAIS3t7fBuqioKO1z+PPPP+e7jWZ7ZGRkvm2xsbECgBg2bJjB+jZt2ghzc3OxYcMGg/Xnzp0TDg4OokmTJo8dq1qtFl5eXqJq1aoiIyPDYNuJEycEADFw4EDtuv79+wsAIiYmJt+x7t69+9j7E0L3/EZHRxusv3XrlqhRo4YAIHbs2CGEECIyMlIAEFWqVBHHjx/PdyxNbP74448G6+Pj44Wnp6dwdXUVDx8+1K7XxFbemJswYYL296P/d1fQ7yUoKEgAEAsWLMg3pri4OO33Bf3uNBYsWCAAiBEjRoisrCzt+szMTNGnTx8BQBw6dEi7XvN8vPrqqwbH2bBhg3b8xY1bIiIiqjzYHoGIiIjoCf3www9Qq9WYPn26thpPQ6VSwcPDQ/uzm5sb7O3t8x1j6NChcHR0xJYtW4zex/vvvw8vLy+Ddbt378bly5fRu3dvbSWv5j5nzJihrWwsjlq1asHKyirf+rFjxwJAgeOcMmUKqlWrZrBuzZo1uHLlCt5//320aNHCYFvbtm3Rt29frFu3DsnJydr1+lW3Gvb29hg+fDiSkpK0l+JrzJw5E2fOnMGzzz5btAf4BFq2bIkRI0Y89XGOHj2KvXv3YtiwYYiIiDDY5u/vj1dffRUnTpx4bJsElUqFIUOG4MGDB1i7dq3Btl9//RUA8NJLL+W7na2tbb51Li4uT/QY/ve//2Hy5MmIjIzEyJEj0aBBA8THx6Nv3775qn5HjRqFJk2aGKy7e/cu/vzzT3Tq1AmvvPKKwTY3Nze8//77uHPnjja+rl27hh07dqBp06YYMmSIwf4fffRRkSeKO3DgAA4dOoT27dvj1Vdfzbe9du3aRToOAHz//feoUqUK5syZY1BtbmVlhU8++QQA8Pvvv2vX//LLL7CyssLUqVMNjhMREYHOnTsX+X6JiIiocmN7BCIiIqIndODAAQAo8qXOK1aswA8//IAjR47gwYMHyM3N1W67efOm0du0bt0637pjx44BANq1a5dvm7e3Nzw9PXHlypUijSkvIQQWLlyIRYsW4eTJk0hKSoJarS7WOPft2wdAXp5urM/o7du3oVarcf78eQQFBQGQvUc//fRTrF+/HlevXsXDhw8NbpP3/t3d3eHu7v5Ej7GoWrVqVSLH0TwP8fHxRp+Hs2fPar82bty40GMNHToUM2fOxK+//qrtKatWq7F06VK4uLigZ8+e2n0HDx6MFStWICQkBC+++CI6d+6Mdu3aoXr16k/8GH766Sft9/b29mjQoAGGDBmCMWPG5NvXWCwcPHgQubm5yMzMNPocXLhwAYB8Dnr37q2Ncf0PJfTvv3nz5ga9ZgvypH+jBUlPT8eJEyfg4eGBzz77LN/27OxsALrfZXJyMmJjY9GwYUPUrFkz3/7t2rXD1q1bn2pMREREVDkwaUtERET0hJKSkqBSqYqUNPzqq6/w3nvvwdXVFd26dUPt2rW1FZCzZs1CZmam0dvVqFHD6P0C0Pa3NXab4iZt33zzTXz//ffw9PTEM888A3d3d1hbWwOQ1bRPMs779+8DAJYsWVLofaalpWn3b9WqFa5du4awsDB06dIFzs7OMDc3R0xMDP75558C7780GHtMxaF5HtauXZuvQlaf5nkoTIMGDRAYGIh169bhwYMHqFq1KrZv347r16/jjTfeMKgAHTRoEFatWoWvv/4a8+fPx5w5c6BSqdCxY0d89dVXaN68eZEfQ3R0NEJCQoq0b2GxsGfPHuzZs6fA22qeg6LEeFFojlOrVq0i7V+QBw8eQAiBGzduYMqUKQXupxm/pnr8acdPRERExKQtERER0RNydnaGEAK3bt0qNCmUk5ODadOmwd3dHTExMQaJHCEEPv/88wJvm3eSJwDaCcsSEhKM3iY+Pr6oD8FAQkIC5syZg6ZNmyI6Ohp2dnbabbdv3y40WWVsnI6OjgCA1atXo3fv3o+9/59++gnXrl3DtGnT8PHHHxts+/TTT/HPP/8U9aGUCGOPCQDMzGRnsZycnHzbNElCfZrn4bvvvtO2mXgaQ4cOxfjx4/HXX39h9OjR2tYIQ4cOzbdv37590bdvX6SkpGDPnj3aiea6d++Os2fPFrnNwJMoLBbeffddg8m6ClJSMa55fDdu3CjS/gXRjD8wMBCHDh0q8v4l/TdKRERElQ972hIRERE9Ic1l4Js2bSp0v7t37yIpKQmhoaH5Ku8OHTqUrwXA4zRr1gwAsGvXrnzbrl69iri4uCc6nsbly5chhECXLl0MErYF3dfjBAcHA5BVmkVx6dIlADLRmFdx7r+0VK1aFYDxRODRo0fzrXvS5+FxXnjhBVhYWOC3337Dw4cPsWLFCtSrV6/QSlgHBwd0794dCxYswPDhwxEfH4/9+/eXyHiKolWrVlCpVEV+DjQxvnv37nzbUlNTERMTU6TjFPVvFIC2F7R+2xINBwcHNGjQAGfOnEFiYuJjj+Xo6AhfX19cvHgRt2/fzrddSfFMREREysakLREREdETeu2112Bubo6PP/4YV69eNdgmhND2X3Vzc4OtrS2OHDmC9PR07T4PHjzAuHHjnvh+27ZtC19fX6xZs8YgqSWEwEcffWQ06VQU3t7eAIC9e/ca9LG9fv06JkyY8MTH69u3L7y8vPD1119j586d+bZnZ2cbjF9z/3kTdUuXLsW6deuM3setW7dw9uxZoxWupaV+/fpwcHDAv//+q73sH5DVk9OnT8+3f+vWrREcHIzff/8df/75Z77tarUaO3bsKPL9u7m5oVu3btizZw9mzZqF5ORkoxOQ7dy502gsaKo/bWxsinyfT6tmzZp47rnnsHfvXnzxxRcQQuTbZ//+/dq/Dy8vL7Rv3x7Hjx/P115jxowZRUqcAjJZ3KpVK+zcuRM//vhjvu36ifeqVatCpVIV+KHHm2++ifT0dLz66qtGW1nExsYatCUZOnQosrKyMGnSJIP9Nm3axH62REREVGRsj0BERET0hJo0aYJZs2bhzTffRKNGjdCvXz94e3vj9u3b2LlzJ3r16oVZs2bBzMwMb7zxBr766is0a9YMffr0QXJyMtavXw9vb294eHg80f2amZlhwYIF6NmzJ7p06YLnn38eHh4e2LZtG27duoWmTZvi+PHjT/x43N3dMWDAACxfvhxBQUHo3Lkz4uPjsWbNGnTu3FlbCVtU1tbW+Pvvv9GjRw906NABnTp1QpMmTaBSqXD16lXs2rULLi4u2smbhg4dis8++wzjxo1DVFQUvL29cezYMWzduhX9+/fHihUr8t3HhAkTsHjxYixcuBDDhw9/4sdcHFZWVhg3bhxmzJiBli1batsPrF69Gh06dDD6PP3+++/o2LEjBg8ejFmzZqFly5awtbXFtWvXEB0djTt37iAjI6PIYxg6dCjWrVuHyMhIADCatH3zzTdx8+ZNtG3bFj4+PlCpVNi9ezcOHDiAkJAQo5N8laa5c+fi3Llz+OCDD/Drr78iNDQUzs7OiIuLw6FDh3DhwgXcunVLW+U9Z84chIWF4T//+Q9WrVoFPz8/HDhwAAcPHkS7du2KXK26ZMkShIeHY9SoUdr7zcjIwKlTp3D06FHcu3cPgJzgTJPgHTp0KPz8/GBmZoahQ4fC29sbo0ePxr59+7B48WLs2bMHXbp0gYeHB+Lj43H27Fns378fS5cuhY+PDwDggw8+wIoVK/Djjz/i1KlTaN++PeLi4vDXX3+hV69ehfY3JiIiItISRERERFQsUVFRonfv3qJatWrCyspK1K5dWwwYMEDs2bNHu09WVpb45JNPhJ+fn7C2thZeXl7i3XffFSkpKcLb21t4e3sbHHPYsGECgIiNjS3wfnfu3Cnat28vbG1tRbVq1cSgQYPE1atXRYcOHURxX96lpKSId999V/j4+Ahra2vh5+cnpk2bJrKysgQA0aFDB4P9i3Jf169fF2+99Zb2sTs6OooGDRqIV155RWzdutVg35iYGNGtWzdRtWpV4eDgIDp06CC2bNkiFi5cKACIhQsXGuyveZ7yri8qAPme+6ioKAFAREZGFni73NxcMXnyZOHp6SmsrKyEv7+/mD17trh8+bIAIIYNG5bvNvfv3xcff/yxaNy4sbC1tRX29vbCz89PvPjii2LFihVPNO709HTh6OgoAIjQ0FCj+/zxxx/iueeeE3Xr1hV2dnbCyclJNGvWTHz22WciJSWlSPejeX6jo6Mfu29kZKQAIKKiogod9+effy4CAwNFlSpVhK2trfD19RX9+vUTv/zyi8jOzjbY/8SJE6Jnz57C3t5eODg4iB49eogTJ04Y/fso7Pd2+/Zt8dZbb4k6deoIKysrUa1aNREcHCy+/vprg/3OnTsnevbsKZydnYVKpTL6eP7880/RpUsXUbVqVWFpaSlq1aolwsPDxVdffSXu3LljsO+9e/fEqFGjhKurq7CxsRGBgYFixYoVBcYzERERUV4qIYxco0REREREREREREREJsGetkREREREREREREQKwqQtERERERERERERkYJwIjIiIiKiCigmJgarVq167H4+Pj5lNpEXEREREREVDXvaEhEREVVAixYtwogRIx67X4cOHbB9+/bSHxARERERERUZk7ZERERERERERERECsL2CMWkVqtx8+ZNODg4QKVSmXo4REREREREREREpHBCCKSkpMDDwwNmZgVPN8akbTHdvHkTnp6eph4GERERERERERERlTNxcXGoXbt2gduZtC0mBwcHAPIJdnR0NPFoSt/69evRo0cPUw+DqECMUVI6xigpHWOUlI4xSkrHGCWlY4yS0lWWGE1OToanp6c2t1gQRfW09fHxwdWrV/Otf+ONNzBnzhxkZGTg3XffxR9//IHMzExERERg7ty5qFGjhnbfa9eu4fXXX0dUVBTs7e0xbNgwzJw5ExYWuvz09u3b8c477+DUqVPw9PTExx9//MSzJicnJ8PJyQlJSUmVIml77949uLi4mHoYRAVijJLSMUZJ6RijpHSMUVI6xigpHWOUlK6yxGhRc4oFN04wgYMHD+LWrVvaZfPmzQCAQYMGAQDefvttrF69GsuWLcOOHTtw8+ZN9O/fX3v73Nxc9OrVC1lZWdi7dy8WL16MRYsWYdKkSdp9YmNj0atXL3Ts2BExMTEYP348XnnlFWzcuLFsH2w5U1iPDSIlYIyS0jFGSekYo6R0jFFSOsYoKR1jlJSOMWpIUc+Gq6sratasqV3WrFmDunXrokOHDkhKSsJPP/2Er7/+Gp06dUJgYCAWLlyIvXv3Yt++fQCATZs24fTp0/jtt9/QvHlz9OjRA9OmTcOcOXOQlZUFAJg/fz58fX3x1VdfoUGDBhg7diwGDhyIb775xpQPXfF2795t6iEQFYoxSkrHGCWlY4yS0jFGSekYo6R0jFFSOsaoIUUlbfVlZWXht99+w8svvwyVSoXDhw8jOzsbXbp00e4TEBAALy8vREdHAwCio6PRpEkTg3YJERERSE5OxqlTp7T76B9Ds4/mGAXJzMxEcnKywUJERERERERERERU0hQ7EdmqVauQmJio7TV7+/ZtWFlZwdnZ2WC/GjVq4Pbt29p99BO2mu2abYXtk5ycjIcPH8LW1tboeGbOnIkpU6bkW79+/XrY2dkBALp27Yp79+7hyJEj2u2hoaGwsLDArl27tOuaNm2KWrVqYf369dp1derUQaNGjbB582ZkZGQAANzc3BAcHIzo6GjcvXsXAGBnZ4fOnTvjxIkTuHLlivb2vXr1wpUrV7TJaQDo0KEDMjIysH//fu26oKAgODk5YevWrdp1AQEB8PPzw9q1a6FWqwEAnp6eaN68ObZv346UlBSo1Wrs3r0bbdu2xaFDh3Dr1i0AgKWlJbp3746zZ8/iwoUL2mN269YNd+7cwdGjR7Xr2rRpAzMzM4NPTpo2bQoPDw9s2LBBu65u3bpo2LAhNm3ahMzMTADyd9S6dWvs3bsX9+7dAwBUqVIFnTp1wrFjx3Dt2jXt7fv06YNLly7h9OnT2nUdO3ZEWloaDhw4oF3XqlUrODg4YNu2bdp1DRo0QL169bBmzRpo2j17eXmhWbNm2ucCAKpVq4awsDAcPHhQG1tWVlaIiIjAmTNncPHiRe0xIyIiEB8fj5iYGO26sLAwAMCePXu065o3b44aNWoYtOqoV68eGjRogI0bN2qrxWvWrIlWrVphz549uH//PgA5MV54eLjBc6FSqdC7d29cvHgRZ86c0R6zU6dOSElJwcGDB7XrWrdujSpVqiAqKkq7rmHDhqhbty5Wr16tXad5LrZt24a0tDQAgIuLC9q0aYMDBw4gPj4eAGBtbY1u3brh9OnTuHTpkvb23bt3x82bN3H8+HHturZt20KtVmPv3r3adS1atICrqys2bdqkXefn54eAgABs2LAB2dnZAAB3d3cEBQVh9+7dUKvVWL16tfa5iImJQVxcHAB5iUWvXr1w4cIFnD17VnvMzp07IykpCYcOHdKuCw4Oho2NDXbs2KFd16hRI/j4+GDt2rXadT4+PmjSpAm2bt2K9PR0AED16tURGhqK/fv3IyEhAQBgY2ODrl274tSpU7h8+bL29j169MCNGzcMnot27dohJyfH4EOkli1bwsXFRdsuBgD8/f1Rv359rF+/Hjk5OQAADw8PBAYGYteuXUhMTAQAODk5oX379jhy5Ahu3LgBADA3N0fPnj1x/vx5nDt3TnvMLl264MGDBzh8+LB2XUhICKytrQ2ei8aNG8PLywvr1q3TrvP19UXjxo2xZcsWPHz4EIC8ciIkJAT79u3DnTt3AAC2trbo0qULTp48idjYWO3te/bsiWvXruHkyZPadR06dEBmZqb2SgoACAwMRNWqVbFlyxbtuvr168Pf3x/r1q1Dbm4uAKBWrVpo2bIldu7ciaSkJACAs7Mz2rVrh8OHD+PmzZsAAAsLC/To0QPnzp3D+fPntccsrXO5JkYB053LAaBq1ao8l/NcbvRcDsDk5/IHDx4YPBc8l/Ncrn8u15zbTHkuV8LrcoDncqWey9VqNbZv317pX5fzXK7cc7nm9Whlf13Oc7lyz+X675kq8utyzbnqcRQ1EZm+iIgIWFlZaX9ZS5cuxYgRI7QBptG6dWt07NgRn332GUaNGoWrV68a/ELS09NRpUoVrFu3Dj169IC/vz9GjBiBCRMmaPdZt24devXqhfT09AKTtpmZmQb3rZnprbJMRHb16lV4e3ubehhEBWKMktIxRknpGKOkdIxRUjrGKCkdY5SUasUKYMoU4Nw5gfr1VYiMBPSmsKpwijoRmSIrba9evYotW7ZgxYoV2nU1a9ZEVlYWEhMTDapt4+PjUbNmTe0++ll+zXbNNs1XzTr9fRwdHQtM2ALyE0pra+tiPZ7c3FztJ5DlVbVq1bSfTlHJsLS0hLm5uamHUWF4eHiYeghEhWKMktIxRknpGKOkdIxRUjrGKCnRihXAgAGASgUIocKJE/Ln5csrduK2KBSZtF24cCHc3NzQq1cv7brAwEBYWlpi69atGDBgAADg3LlzuHbtGkJDQwHIMvlPPvkECQkJcHNzAwBs3rwZjo6OaNiwoXYf/csHNPtojlGShBC4ffu29pKI8iw9PV3bBoJKjrOzM2rWrAmVSmXqoZR7GzZsQJ8+fUw9DKICMUZJ6RijpHSMUVI6xigpHWOUlObhQ+Cdd+T3mj4AQsgE7tSpTNoqLmmrVquxcOFCDBs2DBYWuuE5OTlh5MiReOedd1CtWjU4Ojpi3LhxCA0NRUhICADZ46Nhw4YYOnQoPv/8c9y+fRsff/wxxowZo62Sfe211/D999/jgw8+wMsvv4xt27bhr7/+MuiJU1I0CVs3NzfY2dmV68RccnJypWgDUVaEEEhPT9f2V3J3dzfxiIiIiIiIiIiIStfDh8D69cDffwOrVwOpqfn3EQLQa/VcaSkuabtlyxZcu3YNL7/8cr5t33zzDczMzDBgwABkZmYiIiICc+fO1W43NzfHmjVr8PrrryM0NBRVqlTBsGHDMHXqVO0+vr6+WLt2Ld5++23Mnj0btWvXxv/+9z9ERESU6OPIzc3VJmw1k3uUZxkZGbCxsTH1MCoUTTsOTWU4WyUQERERERERUUWTni4TtcuWAWvWAI/mTwQAWFoCeTuKqlRA/fplO0YlUlzStlu3bihobjQbGxvMmTMHc+bMKfD23t7e+dof5BUeHm4w415p0PSwrSgtBYrbz5cKp4mP7OxsJm2fUt26dU09BKJCMUZJ6RijpHSMUVI6xigpHWOUylJaGrBunayoXbNGJm41vL2BgQOBQYOA69fl97Knre5rZKTpxq4UKlFQhpQK9biZ3jIyMhAbGwtfX19WqFKBGCdEREREREREVBGkpQFr18qK2nXrDBO1Pj66RG2rVjI5q7Fihexhe+6crLCNjASefbbMh19mHpdT1DArwzFROZaUlGTqIRAVatOmTaYeAlGhGKOkdIxRUjrGKCkdY5SUjjFKpSE1FfjjD5mQdXUFnn9eVtempwO+vsAHHwAHDwKXLwNffAG0bm2YsAXkhGMxMcA//2xCTEzFTtg+CcW1RyBlYkE2KV1mZqaph0BUKMYoKdWKFcCUKcCZM53RoIGsbKjsM/WSMvE8SkrHGCWlY4xSSUlJkS0Pli2TvWozMnTb6tSR1bSDBgEtW+ZP0BaGMWqISVsiIiKiSmrFCmDAAE3vMHOcOCF//uMPWSVBRERERAQAycmGiVr9/Gq9erpEbfPmT5aopYIxaUtFYmlpCQBQFfEvLyoqCuHh4aU4IiJDNWrUMPUQiArFGCUlmjJFftVcUKP5OngwMH68nCTCx0d+zbs4OJhixFSZ8TxKSscYJaVjjNKTSkoCVq+WidqNGw0TtX5+ukRts2Ylk6hljBriRGTFVFknIvvtt98Mfv7ll1+wefNm/Prrrwbru3btyj+2IqiocUJEROWDhQWQm1u821arlj+Rq5/grVaNVRZERERE5U1iomGiNitLt61+fV2itkkTvtYrrqJORMZKWyqS1NRU2Nvb46WXXjJYv2/fPmzevDnf+rzS09NhZ2dXmkOkSm7v3r1o06aNqYdBVCDGKCnN3LnGE7YqFdCwIbB4MXD1KnDlivyqvzx4ANy/L5ejR40fv0qVwit1a9YEzDglLj0BnkdJ6RijpHSMUSpIYiLwzz8yUbtpE5CdrdsWEKBL1DZuXLqJWsaoISZtqUhycnKKvG94eDju3r2LxYsX4+2338ahQ4cwatQozJo1CyqVCpGRkZg8ebLBbXx8fBAeHo5FixZp1yUmJmLy5MlYvnw5EhIS4OnpiVdffRXvv/8+zPguj/K4d++eqYdAVCjGKCnJsmXA2LG6n2VPW93XadOAwEC5GJOcnD+Rq5/cjY8H0tKA06flYoyVFeDlVXClbu3ashKYSIPnUVI6xigpHWOU9D14oEvUbt5smKht2FCXqG3UqOzGxBg1xJfC5Yxmhufz5wF/f+XO8Hzv3j306NEDgwcPxksvvfTErRLS09PRoUMH3LhxA6NHj4aXlxf27t2LCRMm4NatW5g1a1bpDJyIiKiC27YNeOklmZx97TWgSxeZpD19OhcNG5ojMhJ49tnCj+HoKC+Ja9LE+PaHD4G4uIIrda9fl5faXbwoF2PMzIBatQqu1vXyAmxtn+aZICIiIqpc7t8HVq2SidotWwD9+rxGjXSJ2oYNTTZE0sOkbRkTAkhPL95t//kHGDJEVwWjmeF5yRKgb9/iHdPOrmil7U9a2Xr79m3Mnz8fo0ePLta4vv76a1y6dAlHjx6Fn58fAGD06NHw8PDAF198gXfffReenp7FOjZVTFWqVDH1EIgKxRglJThyBOjXTyZMBw4Evv8eMDeXrye2bduBTp06lcj92NrKD5f9/Y1vz84GbtwouFr32jU5xrg4uezebfw4NWoUXKnr7S2Ty1Rx8DxKSscYJaVjjFZO9+7pErVbtxomaps0kUnagQOBBg1MMLjJk+WL0YkTAeSJ0WnTZC+vPFdqVyZM2pax9HTA3v7pjpF3huchQ4p/rNRU2XPucQprjGyMtbU1RowYUcxRAcuWLUO7du1QtWpV3L17V7u+S5cu+PTTT7Fz504MeZoHThVOSSUaiEoLY5RM7eJFoEcPICUF6NgR+O03+RpZoyxj1NJSJlh9fIxvV6tli4WCKnWvXpWvYeLj5XLggPHjODsXXKnr4wO4uHACjfKE51FSOsYoKR1jtPK4exdYuVImardtM5zHoGlTXUVt/fqmGyMA+WJ00iT5/cSJuhidNk2unzrVdGNTACZtqUiedCKxWrVqwcrKqtj3d+HCBRw/fhyurq5GtyckJBT72FQxHTt2DM2aNTP1MIgKxBglU7p9G4iIABISgObNZbWFtbXhPkqKUTMzwN1dLiEh+bcLIS/vK6yv7v37clKNxETg2DHj92NnZzyZq/ne3Z2TpSmJkmKUyBjGKCkdY7Riu3NHl6iNijJM1DZvrquoLehKKJN4VGGrSdwee+YZNPv3X13CVrO9kmLStozZ2cnKkOIICQFOndJV2AKyOqRxYyA6uvjjKYqsrKwnStraPmGTudw801er1Wp07doVH3zwgdH9/RV1liEluHbtGl+AkKIxRslUkpKA7t2By5eBOnWA9euNtw0oTzGqUskqWRcXoGVL4/ukpMg2CwVV6966Ja+AOnNGLsZYWgKensYrdb295TZLy9J6lJRXeYpRqpwYo6R0jNGKJyFBzn20bBmwfbu8WkmjRQtdovZR10nlUauBN9+U30+ahMZTp8r+DUzYAmDStsypVEVrR2DMlCmy51zeGZ6nTCn+Mcta1apVkZiYaLAuKysLt27dMlhXt25dpKamokuXLmU4OiIiooolI0P2sD12DHBzAzZtAmrWNPWoyoaDg5xQo6AZjzMydJOlGavWvX5d9t69fFkuxpiZAR4eBVfqenkV/QNyIiqH8vRiNMBejERUSuLjdYnaHTsME7WBgbpEbd26phtjgRITgf37ZeVhdLT8vndv2bdr+nSYZ2UBVlZM2D7CpG050r8/sHy5/MDh3DnZe6QoMzwrSd26dbFz506DdQsWLMhXafvcc89h8uTJ2LhxIyIiIgy2JSYmwt7eHhYWDF8iIqKC5ObKvvfbt8sE5oYNCn3xbiI2NrLqpKDKk5wc4ObNwvvqZmbK5O7168CePcaP4+pacKWujw/g5FRKD5CISl+eXoxa7MVIRCXs9m2ZD1q2DNi50/AK7KAgXaK2Th3TjbFAQgCvvQbs2mX88qaYGHnezMpCroWFTNxOm8bELZi0LXf695dLWXN2di6R47zyyit47bXXMGDAAHTt2hXHjh3Dxo0bUb16dYP93n//ffz777/o3bs3hg8fjsDAQKSlpeHEiRP4+++/ceXKlXy3ocqtT58+ph4CUaEYo1SWhADGjJFVGFZWwD//yEvkCsMYNWRhIStlvbyAdu3yb1er5SWJhfXVTUmR/eXu3AEOHjR+P05OBVfqenvLpC8nS5MYo6Q4EycCWVkyQXviBPqMGiUvg5w8mZf2kiLxPFq+3LqlS9Tu2mWYqG3dWpeoLWhi1zJ3/76uijY5GZg1S65XqeR6TcK2bl0gNFQuISHA6tXaD7rMJ07UffAFVPrzKJO2VCQZGRmwsbF56uO8+uqriI2NxU8//YQNGzagXbt22Lx5Mzp37mywn52dHXbs2IEZM2Zg2bJl+OWXX+Do6Ah/f39MmTIFTixLoTwuXbqEuiwhIwVjjFJZmjIF+OEH+Rp5yRKgY8fH34Yx+mTMzGSriZo1geDg/NuFkFcAGkvmapa7d2XP4ePH5WKMra1MHBur1vXxkZOlmZuX3uNUEsYoKcLixcCRI8DZszIBERcn1y9bBrFsGVSALmH7zz+yiXjLliyrJ0XgeVT5btzQJWr37DFM1AYH6xK13t6mG6PWmTMym6xpdXDunG6blRXw2We6mW8nT5YvnkJCZM8ujWnTDD7ounTpEurmmZysMiduVULohwAVVXJyMpycnJCUlARHI7N5ZGRkIDY2Fr6+viWS7DS1xMTEEqu2JZ2KFiemtHr1an5yTIrGGKWyMm8e8MYb8vu5c4HXXy/a7RijZS8trfBK3Vu3DN+sGWNhISdEK6hS19NTvm+qCBijVOqys4FLl2RCVrOkpcnsiUZoKLBvn+HtXF3lpzBCyD+4zEy5vk4dIDZWfu/nJ69h1iwtWsjeNURliOdRZbp+3TBRqy80VCZqBwyQH+KazN278rKh7t11lwD17w+sXGm4n5+fror2P/95fHP/PL3BDWK0AvcGf1xOUYOVtkREREQVxN9/y7YIgOx7X9SELZlGlSpAw4ZyMUbTM7egSt24ONl7NzZWlxfKS6WS1bgFVep6eZWfCW2JSkxqKmBvr/v5gw/k5bkXL8o/Kn3m5rIFgubTj8GDgbZtgYAAoEEDOdHI3LnApEmGvRg//FDOCCSE/AO+cEEuv/8ujxMUZNg35cgRwN/fcFxEVGHFxcnXbcuWySJVfW3a6BK1np4mGFxODnDypPyASlNFe+GC3Hb5MuDrK7/v0kW2QdC0OQgJAVxcnuy+CkvIVuIKWw0mbYmIiIgqgG3b5MRjmrkeIiNNPSJ6WtbWsu1bQVey5ubqJksrqFo3I0Puc/MmsHev8eNUr154X11nZ/bVpXJIrZafeuhXzZ45I7/evy8raDUTG9+8KdcD8lOMgADDRb/k/a23DO9Hb9Kxdc2bo09MjO6SXk2F7t27Mil76JBcDh+WCV2NjAx53bNaLe8vKEhuDwoCmjd/fKUaEZUL167pErX6BfsqFRAWpkvU1qplujFi3jzg/fflOTKv+vWB+Hhd0vaNN3SXd1GpYHuEYqps7RFyc3NhXlkappWhihYnppSamgp7ViaQgjFGqTQdPQp06CAnvhowAPjzzyfvc8oYrXiEkJOgFVSpe+WKLJB5HAcH45W6mgSvm1vZJHUZo2RURoasADt7Vp4Azczk+pdekk29C3Lxou4TkYMHZRPqgACgdu2iB7RewhYTJ+piNM96o7KzAUtL3VjCw2Uzy7zMzIC33wa+/FL+LIR8zLa2RRsjkR6eR8velSu61gf79+vWq1SyaF+TqPXwKKMBZWcDJ07I6llNJe0PPwCaeYaWL5dNcx0d5YdJISGykjY4GKhWrdSHV1lilO0RqESp1WombUnR0tLSKsXJncovxiiVlkuXZHuxlBT5nv+334o3MRVjtOJRqWRC1c0NaNXK+D76k6UZq9S9c0fG1okTcjHGxka2WSioUtfDQ1fQ+DQYo4TTp2XJuH7lbGysrhI2NlY3jXrdujLw/PwMq2Y1LQ303yQX9AfyOLm5BolZbYxqErW5uQXfVpOwBYB69WRV8O3bsgpXU5F76JBcV7Ombt8LF2RPlcaNdf1xAwOBpk11E/4QFYDn0bIRG6urqNXvgqJSAe3by5xo//5lmKiNjZWJ2ehoeV5JTzfcHh2tS9p27Sr/4TdoYJKZThmjhlhpW0yVrdKWE5GVjooWJ6bEpvqkdIxRKg23b8vL6S5fllfQbt9e/AnKGaNkTHq6vJzTWKXu1auyMPBx7ybMzWXxYkF9dT09C881rVgBTJkCnDmTiwYNzBEZKd/sUgWUmyuDTT8p+8knQI0acvtHHwEzZ+a/nZOTTDAsWAA0aSLXpabKwNJPjpayUjmP3rwp++lWry5//usv4Pnn8+9naSkf+8SJQL9+JTsGqjD4v770XL6sS9QeOqRbb2YmE7WDBsn/XfqfwZS47Gzg2DFZQduoEdCxo1x/9CjQsqVuPycnXQ9aTRWtQvI9lSVGWWlLREREVIElJQE9esg3CXXqAOvXFz9hS1QQOztdgaIxWVm6ydKMVevGxcn3kJr1BXF3N16pe/68vDJcpQKEMMeJE/Iy0uXLmbitMDZuBH76SSZoL1yQM/Dpe+EFXdK2dWsgIiJ/5ayxHh1lWKml+2ChJxo0QMl+sJC3FG/QIJlk0fTG1VTk3rsn++bqf4qyebNMdGsqcoOCZJVuGSayiSqyS5dkknbZMvnnp2FmJq9+0lTUak5hJe7WLcPJwg4dku1TAGDECF3StkkTYPRoeQ4NCZHnTk0rGVI0Jm2JqFwr1RfJREQKlZEhC6liYmSuYtOmUq7cICqAlZX80KBOHePbc3NlRXhhfXUfPpTvOzXvPY3R5KE0X194QSZ3zczkolLpvtdfSnu9Ke9b8etVAhZ3b8Pi4llYXjoLi0tnYXH+DMwvnkXGj79B3bY9zMwAy9jrsNRM2AVAWFtDVb++LimrP3V6v36KqyJdsUJ+kFBmHyyoVPI58fQEnn1WrhNC/kEdPgy0a6fbd98+XVJXw9paXpoRFCQnVfPzK4VBElVcFy7oKmqPHtWtNzOTOdJBg+SfpptbCd9xVpac1FDzQU5SkvH+Cs7OMjEbHKxbZ2EBzJ9fwgOissD2CMVU2dojZGdnw5KfyJa4ihYnZc3wRbLuK6tvSIlu376NmsyqUQnIzZVXxi5fLieI2rEDaNHi6Y/LGCVTEEK+By2oUvfYMVOPkB7HAtmoi0u4A1fchwsAoD+W42e8DCcYn+luFH7AjxgFAKiHC+iD1TiLAJxBA1yDF9QwLzcJ+B078k/op1LJAuCTJ8tmkr4C3bgB7Nmjq8o9fFgmejSOH9e1k1i+XD4YTUVu/fom6WdJpYv/64vn/HldRa3+/yVzc6BTJ1lR++yzgKtrCd7pjRu6Ktp9++Tfb+vW8u9Uo0kTeZIJDZVLSAjg71+uq2grS4yyPQKVKLNy/EdPFdeUKfKrfvWNSgVMncqkLSmPg4ODqYdAFYAQwNix8r21lRWwalXJJGwBxiiZhkol3+S6uso8UV7Nmsn5UPTLTFQqOcfUwoWAWm24CJF/nRLXK3FMj1tvlZOO+lknUDf7LOrlnIVfzhnUyz0LX/UlWCIHr1n9jF/MR0AIIDnHBU45yciFGS6jDs4iQJuUPYsAnERj7e/zIvzwDd7J97vX3H95JIScM83Z2bCLg+ZrnTpl1KGgVi3guefkAsgn9NIlmfw5ckQORuPff4FfftH9XKWK/AcTGCj/OPv3l/1SqFzj//qiO3tWV1F7/Lhuvbm5nLNr0CBZ+K9pN11iXn8dWLtW9hfKKzZW/h1r8jNHjlS4dieMUUNM2lKRpKSkcCIyUpT4eFm9kJcQwLlzZT8eosfZtm1bpWiqT6Vr6lR5dZtKBSxZIqs7SgpjlJQoMtL4VTWffw60bWvq0VVAarVsUqyZCCw4WHeJ7eY9QLduxm9XpQrmT0/C/PGPfk5vDcSehHm9evCztkY9AfRSaDL6aW8zebKcK8zY9avJycCBA3LRZ2EB1KunS+Rqkrn16wOFFFw9PTMz2Q7Bzw8YPNhw2/PPAy4usir3yBEgLQ3YvVsuKpVhW4pVq2Rfk6Ag+QkKC3zKDf6vL9yZM7qKWv33mhYWQJcusqK2Xz/5p/JUrl/X9aG9dAn45x/dtrg4uZiZyUpaTRVtaKg8ceiX71ewhC3AGM2LSVsiKnc2bACGDSu4+oKtuYioIpo/XyYHAGDOHPnGgaii699fVpZPnQqcPp2Lhg3NERmpa+VJT+n2beDHH2Wm4uxZ+cl3erpu+3//q0vaBgTI/ol5JwELCJAVnfqJBDs7OXP5IyqVrsVARVOtmvEPFv78Uz4FZ8/qnl7N1/R0XV48r1q18j+9mqe+VFst9OwpF0D24Tl/XtcP9+5dw4ndvvxStl0AZJZZU40bFCS/r1PHxH0hiIru9GldovbUKd16Cwuga1dZUdu3r/xbL7Zjx4AtW3TtDm7cMNx+/TpQu7b8fsIE4N13gVatynRCRVImJm2JqNzIzJT/w775Rv7s6Sk/hNS8ONbIzpaVDaVaqUBEVIb+/ht44w35/aRJ8so5osqif3+5rF69jtU3T+ruXV12ULP06AGMGSO3p6fLk4o+Cwv5CXhAANCwoW69p2f+RAM99oMFvdw1AFl0cOOGLoGrn8y9fVtuu3ED2LrV8HYODvkTuQ0ayELXEi+2MzeXB2/QABg6NP/2sDCZ2I2JkS+6o6LkAsjssn6c7N4tk1He3kzkkiIIIZOzmkTtmTO6bZaW8oKCgQNlorZq1WIc/No1mZh95hldS5GffgK++063n7m57P8TEiIraPXfuIaFFfuxUcWjuKTtjRs38H//939Yv3490tPTUa9ePSxcuBBBj5pcCSEQGRmJH3/8EYmJiQgLC8O8efPgp1dad//+fYwbNw6rV6+GmZkZBgwYgNmzZ8Ne71OK48ePY8yYMTh48CBcXV0xbtw4fPDBB2X+eMsLpU2S5ePjg/DwcCxatAgAsH37dnTs2BFRUVEIDw836dg08o6Rns7Zs3Km6JgY+fPYsfLSyPXr5YvkM2fU8PIyw82bct+uXWVF7hP/oyUqJQ30+8YRPYGoKGDIEPk+YPRoXbVtSWOMktIxRguQmysvZde86b9zR2YSz5wB7t3Lv7+Dgy5p6+0NvPyynLhGkw309a2Ql9yWJs0HCxcvxqJevXqF7mtmJvPfnp75u008eCCLnfNW516+DKSkAAcPykWfhYVM3BprteDkVMIPVOOzz+TX7GxZpqiZ6OzQIRlTGkLI7Fd8vLyeXL8iNyhIJnOZyC1TlfU8KoRsd6BJ1OpXuVtZyb/FQYNknvWJukI+fChjX9PqYN8+4NYtuW3HDqB9e/l9ly4ymatJ0gYFyb7RlE9ljdGCKCpp++DBA4SFhaFjx45Yv349XF1dceHCBVTVy7p8/vnn+Pbbb7F48WL4+vpi4sSJiIiIwOnTp7WJxSFDhuDWrVvYvHkzsrOzMWLECIwaNQpLly4FIGdp69atG7p06YL58+fjxIkTePnll+Hs7IxRo0aZ5LErXd6k7aJFizBixAjtz9bW1vDy8kK3bt0wceJE1KhRo6yHWCzr1q3DgQMHMLm03gHTUxNCfjD51luyGMTFRU48oim00bxIBuT1docPy3+6Bw7IBvGbNpVCc3iiYnjcmzgiY44elZUeWVnyXDdnTum9v2WMktJV+hhNTZWXrOetnD1/Xk40pZlEytlZJg5ycuTP3t6G2bzAQN0xzc3lCy0qEU8bo1WrypxOSIjh+sxM2fbSWHVuWppM9Bqb00G/m4V+UjdvN4tis7SU1YLNmgEjR8p1+pe/paTIO7t/X36AsGmTXDT69JEToGnExwNubkzklqLKdB4VQk4gtmyZvGJJ/2/EygqIiNAlaov0AYemqbW5ufx5yRJg+HDduVbDwgJo3lz+4Wo884xc6LEqU4wWhaKStp999hk8PT2xcOFC7TpfX1/t90IIzJo1Cx9//DH69u0LAPjll19Qo0YNrFq1CoMHD8aZM2ewYcMGHDx4UFud+91336Fnz5748ssv4eHhgSVLliArKws///wzrKys0KhRI8TExODrr78uMGmbmZmJTL0/uuTk5NJ4ChQrMTHR6ERkU6dOha+vLzIyMrB7927MmzcP69atw8mTJ2FXhrOLtm/fHg8fPoSVldUT3W7dunWYM2cOk7YKdf8+MGqUvOQMkB9QLl4sX4DmtWbNGvTu3RuBgbIqrUsXmezo2FG2DyonnyNQBaaJUaKiunRJXsWckgKEh8v3Bpr3CaWBMUpKVyliVAiZuNKUgWmuIMvKksnY3Fzjt7t0Sfe9pSWwYoUs5fT3112eS6WutGLU2lp2qtDvVgHIcNGfN04/qXvrlpwg7eZNYNs2w9vZ2xfcauEJ307lp59wdXSUFRWZmcCJE4YVuSdPykmVNJKTAXd3+aI9b49cd/enHBRpVPTzqBCyfaymovbCBd02a2uge3eZqO3duwiJ2vR0Gav6VbSffioTtYCM35wcoGZNWT2rqaINDOR59ylU9Bh9UopK2v7777+IiIjAoEGDsGPHDtSqVQtvvPEGXn31VQBAbGwsbt++jS5dumhv4+TkhODgYERHR2Pw4MGIjo6Gs7OzNmELAF26dIGZmRn279+PZ599FtHR0Wjfvr1Bgi8iIgKfffYZHjx4YFDZqzFz5kxMmTIl3/r169drk5Ndu3bFvXv3cOTIEVhYWMDNzQ3Z2dmwsLBAamqq9ja2trawsrJCUlKSdp21tTVsbW2RnJwM9aPZlSwsLGBvb4/U1FRYTJ8OYW6O7P/7Pzg6OiI9PR1ZWVnytl98ARsLC2R99BEePnyoPaaDgwPUajXS0tK06+zs7GBubo6UlBTtOhsbG9jY2CAxMVG7zsrKCnZ2dkhJSUHuoxeHKSkpcHBwQFpaGtIfTVDQrl07hIeH4+HDhxg4cCDs7e0xZ84crFy5EoMGDdLuBwD29vZIS0uD0Pv01dbWFpaWlgZJcM1zkZSUpN3X0tISVapUQWpqKnJycqBWq5GdnQ0ABs9FRkYGnJ2dkZGRgYyMjEKfiypVqmiPr3nsRX0uNL+btLQ07ThUKhWcnJzw8OFDZGZmQq1WIysrC2q1Gjk5OfmeC0Am/9PT0xEVFYXGjRujRo0a2Lhxo3a/evXqoUGDBti4caP2MdasWROtWrXCnj17cP/+fe3jCw8Px7Fjx3Dt2jXteHr37o2LFy/ijF6jnk6dOiElJQUH9a6tat26NapUqYIoTS8qAA0bNkTdunWxevVq7TovLy80a9YM27Zt0z6XLi4uaNOmDQ4cOID4+Hjt77Bbt244ffo0Lum9iejevTtu3ryJ48ePa9e1bdsWarUae/fu1a5r0aIFzp51wwsv5OLuXVuYm6vx9tt38dlnbti0aQMOH5bPubu7O4KCgrB7927k5uZi9erV2udi/vwzePVVX5w8aYOgoFTs22eP9PQLOKt3LUznzp2RlJSEQ4cOadcFBwfDxsYGO3bs0K5r1KgRfHx8sHbtWu06Hx8fNGnSBFu3btX+bqtXr47Q0FDs378fCQkJAGRMde3aFadOncLly5e1t+/Rowdu3Lhh8Fy0a9cOOTk5iI6O1q5r2bIlXFxcsHnzZu06f39/1K9fH+vXr0fOo092PTw8EBgYiF27dmnj18nJCe3bt8eRI0dw41FvMXNzc/Ts2RPnz5/HOb2Pm7t06YIHDx7g8OHD2nUhISGwtrY2eC4aN24MLy8vrFu3TrvO19cXjRs3xpYtW7TnIFdXV4SEhGDfvn24c+cOAPn33qVLF5w8eRKxsbHa2/fs2RPXrl3DSb0pWjt06IDMzEzs27dPuy4wMBBVq1bFli1btOvq168Pf39/rFu3Tvv3WatWLbRs2RI7d+7UnmednZ3Rrl07HD58GDdv3gQg/4579OiBc+fO4fz589pj6p/LNUJDQ2FhYYFdu3Zp1zVt2hS1atXC+vXrtevq1KmDRo0aYfPmzdpzkJubG4KDg7UxCshzcefOnXHixAlcuXJFe/tevXrhypUrOKU3C0KHDh2QkZGB/fv3a9cFBQXByckJW/Ua3gUEBMDPzw9r167V/h/x9PRE8+bNsX37du15v2rVqmjbti0OHTqEW48u37K0tET37t1x9uxZXNB7ddutWzfcuXMHR48e1a5r06YNzMzMsHv3boPnwsPDAxs2bNCuq1u3Lho2bIhNmzZpP/SsUaMGWrdujb179+Leo0t2q1Spgk6dOhmcvwCgT58+uHTpEk6fPq1d17FjR6SlpeGA3jTcrVq1goODA7bpvSNt0KAB6tWrhzVr1mjP85rzl/5zUa1aNYSFheHgwYO4ffs2AHnOj4iIwJkzZ3Dx4kXtMSMiIhAfH48YTY8WAGGPeo7t0UzGAqB58+Ylci4/duw2/u//2iI+vgqaNQO+/voyNm/WxUVpnMuFECV+Lnd1dcUmvaoqPz8/BAQEYMOGDdr/n/rn8gcPHhg8FzExMYiLiwMAmJmZoVevXrhwgefyynou15zbTHkuj46Oxt27dwGUzLm82u7duLR2LRzi4mB//Tocb92C+aNz1P2AAOz5/HPtuTy9Zk2Yp6YitVYtZNeti5rh4bhgbo5rdnZId3WF5YYNunM5oJ2BnOfysjuXq9VqbN++vUxfl1+4sA0ZGWnw8QECA3Wvyy9duocbN+wRH18V5uaNcfBgMs6dM8OtW3ZITTXTzjGmz9xcwNdXDReXO6hdOwW1a6eic+daCA52wv79T3EuP3MGcbduAbVqwczTE71+/BEXT57ExePHkf3oMXV1coK1mRlUt28Da9fK5ZGH1arh0oABiO3Th+fypzyXa16PVqTX5UIA5uZB2LmzBn79NR23bunaYlpbA4GBCQgNvY5WreLh41Ot0HP57cOHUW/ZMlQ9dw5OV65AleeDsqydO5HYsyf2798PVU4ObH78EY169oSTs7N8XZ6YCGzdytflT3Eu13/PpJTX5aVxLtfPDxVKKIi1tbWwtrYWEyZMEEeOHBE//PCDsLGxEYsWLRJCCLFnzx4BQNy8edPgdoMGDRLPPfecEEKITz75RPj7++c7tqurq5g7d64QQoiuXbuKUaNGGWw/deqUACBOnz5tdGwZGRkiKSlJu8TFxQkAIikpyej+Dx8+FKdPnxYPHz58siehIFOnCgHIr0VZX8IePHhg8PPChQsFAHHw4EGD9WvWrBEAxCeffCKGDRsmqlSpIi5evCh69Ogh7O3tRd++fYUQQuTm5opvvvlGNGzYUFhbWws3NzcxatQocf/+fYPjqdVqMW3aNFGrVi1ha2srwsPDxcmTJ4W3t7cYNmyYdr+oqCgBQERFRRncft++faJHjx7C2dlZ2NnZiSZNmohZs2YJIYQYNmyYAJBv0SjpMRpT4nFSAWRlCfHxx0KYmcnQ9vMTIk+YGfXvv//mW3fhghCenvI4deoIceVKKQyYqIiMxSiRMUlJQrRoIc9dvr5C3LpVNvfLGCWlK5cxmpgoxP79QixaJMSHH8oXOfq8veUfu/5iZiZE3bpCDBliuG9qapkNm4qnPMRoZqYQp08LsXy5EJ98IsTQoUIEBQlhb58/FPUXd3chOnYU4o03hPj2WyE2bRIiLk4ItboEB5eWJsTevUJ8950Qw4YJ0aiR7k3BnDm6/WJi5Iv8fv2EmD5diA0bhLhzpwQHUnGVhxgtCrVaiEOHhPi//5Pv8/Rj1cZGiP79hfj9dyGSkws4QEqKEFFRQsyYIcTSpbr1CQmGB/PwEGLAACG+/FKI3buFSE8vi4dXqVWUGH2cpKSkQnOKGoqqtFWr1QgKCsKMGTMAyAqNkydPYv78+Rg2bJhJx2ZtbQ1ra+uSO6BexWc+5uaAfg/ZtDTgnXfkZVGTJsmvH34oS/OnT5ezME2c+PjjmpkBtrbFGm5R2w5oKnFcXFwAADk5OYiIiEDbtm3x5ZdfaquSR48ere2L++abbyI2Nhbff/89jh49ij179sDy0eQHkyZNwvTp09GzZ0/07NkTR44cQbdu3bSfiBRm8+bN6N27N9zd3fHWW2+hZs2aOHPmDNasWYO33noLo0ePxs2bN7F582b8+uuv+W5fFmMkQ7GxwIsvyitPAGDECODbb+UlXI/j5eWVb129esDOnUCnTnICh/bt5eVhdeuW8MCJisBYjBLllZEB9Osn27u4ucnWfzVrls19M0ZJ6RQbo0IYXhI+cSKwZ4/uGnV9NWoA06bpfn7mGdkPSnONekCAfAFjbBJgTlqjeIqNUT1WVrIVQt65foQAbtzI32rhzBkZxppFr2gMgHydXr9+/lYL9eoVo9WCnZ28vDw0VLcuLU3ORKzXNhGHDmkrybFqlW69t7dsqfDOO0CbNk9455VDeYjRggghf/WaHrV6BcKwtQV69pStD3r1yvP+UQjg4kXDNgfHj8v+tIDsq/fCC/J7V1eZX6lfX8ahp2eZPT6SynOMlooySiIXiZeXlxg5cqTBurlz5woPDw8hhBCXLl0SAMTRo0cN9mnfvr148803hRBC/PTTT8LZ2dlge3Z2tjA3NxcrVqwQQggxdOhQbcWnxrZt2wSAfFWUBXlcVvyxFZSFfYzZs6fhvnZ2Be/r42O4b/XqBe8bFFSkx1YUmkrbLVu2iDt37oi4uDjxxx9/CBcXF2FrayuuX7+urWT98MMPDW67a9cuAUAsWbLEYP2GDRsM1ickJAgrKyvRq1cvodb7CPejjz4SAAqttM3JyRG+vr7C29s7X5Ww/rHGjBkjjP0ZlMYYjWGlrc6SJUI4OspQdXIS4o8/Su7YcXFC+PvrPiw9e7bkjk1EVFJycoQYOFCeqxwchDh82NQjIiIDDx8KceKEEH/9Ja9ye/FFIVq2FCIgwHC/jh0LL1HMzTXN+ImKKW/BeL9+QtSvL4S5ecFvPc3N5evvZ54R4oMPhFi4UIjoaCHyvDUrnpQUIXbsEOKrr4R44QXdC33NsmGDbt+NG4V47jkhPvtMiK1bS2gAVFbUahl7770nUx/6v2Y7OyEGDZKnZIMLEZKThTh1Svdzbq58g5k3SGvXlgeYP7+sHxZR+ay0DQsLM+jlAgDnz5+Ht7c3ANmfpWbNmti6dSuaN28OQPYE3b9/P15//XUAsr9JYmIiDh8+jMBHM6Nu27YNarUawcHB2n3++9//Ijs7W1stuXnzZtSvX99oP1tFe/TclDZNP9u89PsLy+F4Y8mSJahVq5Z2neZ3o7Fs2TI4OTmha9eu2j4ygOyLY29vj6ioKLz44ovYsmULsrKyMG7cOKj0qhfGjx+vrcYuyNGjRxEbG4tvvvkm3wRqqiLMRloWYyQpJQUYO1Y34XGbNnKyHR+fJzuOpn+YMbVrAzt2AJ07A6dPAx06yMnJGjd+qqETPZHCYpRICGDcOFk5YmUlC4datizbMTBGSenKLEbv3ZOX6LRqpVs3eLAs79JUZuWVkgJoXiu/9ZacqCYgQFZrFWlacqoIKup51MkJaN1aLvqysuSfin5VrqZSNyUFOH9eLv/+a3i7mjWNT4RWu7Zh0XqB7O3lJXTt2+vWJSUBR47IUkz9v92oKOCvv+Si4eenm+xs6FB5aUslUR5iVAhg/35dRa1ea1XY2clJxAYNkpO1VrETMsiWPaqgjY6Wk9z5+OgmaDQzk28A797VTRYWEiIDjhSnPMRoWVJU0vbtt99GmzZtMGPGDDz33HM4cOAAFixYgAULFgCQybbx48dj+vTp8PPzg6+vLyZOnAgPDw/069cPgGxy3L17d7z66quYP38+srOzMXbsWAwePBgej6acf/HFFzFlyhSMHDkS//d//4eTJ09i9uzZ+Oabb8ruwepNTJZP3qmhHzVOB6BriWBlJf9L6v+jAgC9SRDyMTN74mFq5BYwU+2cOXPg7+8PCwsL1KhRA/Xr14eZ3v1YWFigdp6T4YULF5CUlAS3Av45ahrFX716FYBsdK/P1dX1scl1TZuGxsXMypXFGAk4cEC2Q7h0SYbnxInAxx8DFsU4M+lPrmdMzZrA9u1At27yCqvwcHnZcVknRajyelyMUuU2dSowb558s/rbb7KtS1ljjJLSlXiMxsXJGe31M01nz8o39iqVvCxb01rMwUEmbJ2c8mebAgIMZwrv27dkx0nlRmU7j1pZ6f4E9AkB3LxpvNXCzZvA7dty2b7d8HZVqhj+WWn+zOrVkxNKFcrJCejYUS76Bg0CnJ1lMvfwYXlN/YULcvnjD9mTSPOeb80auT4oCGjRomg92soZpcaoWm2YqH00BykAGRd9+shfZffueqfbt94Cfv0VeDTxnYGcHJlz0fwOV60q4icCZGpKjVFTUVTStlWrVli5ciUmTJiAqVOnwtfXF7NmzcKQIUO0+3zwwQdIS0vDqFGjkJiYiLZt22LDhg2w0ev7tGTJEowdOxadO3eGmZkZBgwYgG+//Va73cnJCZs2bcKYMWMQGBiI6tWrY9KkSRg1alTZPdgn6Uml2XfaNMMettOmyR63lpa6nrZl3OuqdevWCAoKKnC7tbW1QRIXkL2L3dzcsGTJEqO3cXV1LdExFkd5GGN5plYDn38uwzYnB/DyktW1bduW7v26ugJbt8p/9gcPysrbDRuAR0X4REQmMX8+MHmy/P777+WbEiKC/MMwN9e9ztU3bRqQm6v74ylIWhpw7pwue/Txx7pGmxMnAosXG7+dp6fMKmn6aEZGyvusUYNv/IkeQ6UCatWSS+fOhtuSk+WfpP5nJWfOyJajaWkyr3r4sOFtzM2BOnXyJ3MDAoDH1sm0bGlYpXHvnu5OTp6UB9b45ReZNdQ8iIAAmcDVVOUGBxevuoSMUqtlYeyyZcDy5cD167pt9vbAM73VGNHmHNpbRsPqyD7gk8NAr70AHmXws7JkwtbGRv5+9KtoHxXsafG8TeWU4s44vXv3Ru/evQvcrlKpMHXqVEydOrXAfapVq4alS5cWej9NmzbFrl27ij3OMqdJ0OpPOqb5OmmS4c+lwKIE/znVrVsXW7ZsQVhYGGwLmRhN0xbjwoULqKP3z/TOnTt4YOzTtDz3AQAnT57M18JBX0GtEspijJXVjRvAf/4jJwQDZHLihx+K8ILrMapVq1bE/YDNm2Wj+r17ga5dgXXrSj9hTFTUGKXKZfly4I035PeTJum+NwXGKCmOubnB61xtjOq/Ls5ryxZg9WpdNkj/ulpATjajmYGpeXN5OXXeLJC/f/5CCF5GS0XA8+jjOTrK7gX6HQwAIDtbXn1nrDo3JUVXHLt6teHtatQouNWC0QtNXVzkpXfduuXf1qmTHMihQzKDeOaMXH79VX7Yk5ysS9pGRclK/GbNij3ZtymYOkbVavkeTJOovXFDt83BARjX9iiGOv0Lv7vRMN+wH/gj0fAAR4/KpCwAvPkm8PLL8nfwxLPekVKZOkaVRnFJWypAbq5hwlZD83MB7QtKin0JXhry3HPPYe7cuZg2bVq+vq85OTlITU2Fs7MzunTpAktLS3z33Xfo1q2bNsE6a9asx95Hy5YttZXaw4cPN+hrK4TQHqvKoxfkiYmJBvuUxRgro3/+AUaOlB9w29kB330HjBhRMh98hoWFFXlfJydg40Z5mc327UBEhHwBaIrLkanyeJIYpcohKkq2iBECGDXq8QWDpY0xSoqTp0Ah7MMP5Zv0776Ts31fuiTfvC9dqquWi44G9K6wAwBUr67L5DyazwIAMH68XIhKCM+jxWdpWXCrhVu38vfMPXNGJvzi4+WyY4fh7ezsjLda8PMrpNXCa6/JBZCV9ocP69oqqNWGN3z3XZlANDcHGjWSlZ6apUkTWf2pQKaI0dxcYM8eXaL21i1ABTUa4Az62ewDevVCt//URLdugM13W4APJutubGsrM/yaClrNh26A4fdUYfA8aohJ2/KisHdypVhhq5GWlqZNcD6tDh06YPTo0Zg5cyZiYmLQrVs3WFpa4sKFC1i2bBlmz56NgQMHwtXVFe+99x5mzpyJ3r17o2fPnjh69CjWr1+P6tWrF3ofZmZmmDdvHvr06YPmzZtjxIgRcHd3x9mzZ3Hq1Cls3LgRALST1b355puIiIiAubk5Bg8eXCZjrEwePpSva+bNkz+3bCnfX9WvX3L3cfDgQbTK+5F9IeztgbVrgWeflb1te/UCVq6UrROISsOTxihVbEePyraXWVlA//7A3Lmmv3KPMUomJQSQmCir2+Li5IxH1avL17nHjwOTJkFMmgTtn8mWLbrbnj6tS9p27Ai8954uU1O/vjwOURngebTkqVTySncPj/wFFikphq0WNF8vXADS02Uh/ZEjhrcxM9O1WshbnWtw5V/NmvINQq9e+QclhOzvduOGnH/m+HG5/Pyz3F6/vhyIxvnzcmIsBVSDllWM5uYCu3frErUZtx8gGPsxGtFoZxGNENV+2GUnAxkA+i8BnnlR3rBTJ2DIEJmkDQ2VCXD9D9uowuN51BCTtlQk2dnZJXq8+fPnIzAwED/88AM++ugjWFhYwMfHBy+99JLBJyvTp0+HjY0N5s+fj6ioKAQHB2PTpk3oZeyfZx4RERGIiorClClT8NVXX0GtVqNu3bp49dVXtfv0798f48aNwx9//IHffvsNQggMHjy4zMZYGZw4ISdcPn1a/vzee8Ann5T8a5bbt28/8W3s7GT173PPyUrbvn3lxLKcP4RKQ3FilCqmS5fkjMcpKXIy4yVL8s9BagqMUSo1QsiZ3W1sdNVnu3bJBEdcnEzUXr8uG1pqrF0rexkB8h/z33/rErYtWxpmW/SntG/blj2PyGR4Hi1bDg664lZ92dnA5cvGWy0kJ8v+uRcvynnH9Lm55U/kBgTIFtcGrRZUKjmxlRAycXvokOHSvLluX7VaVopmZABNm+oGHBgoK3TLOCFZmjGamwvs3An8/Wcu1q3MxJUEOWNYBDZgA3rodsx59NXOTp6/9a/qDQyUM7JSpcXzqCGVEEKYehDlUXJyMpycnJCUlARHR8d82zMyMhAbGwtfX1+DSdLKq7ztA6hkVLQ40ScEMGeOTNJmZsp+U7/8Yrx9VElYvXo1+vTpU6zbZmXJS5SXL5dtqpYu5URAVPKeJkap4oiPB8LCZOK2WTN5OaeTk6lHJTFG6alduiSb1msSsfpf09JkhkTzofaSJcBLL+U/houLzJDMmCE/3QCADz4AvvgCagsLmOXkGG8ZRqQAPI8qmxCy64GxVgv6k2DlZWcni2eNtVrI9xZOCFnmq7lK9cYNWS1qbL4Ta2vZjkG/tV5OTqlOdlbSMZqTA+xdfQ8nftyHzB370DQ9Gq1xAF/gfcypOhH9+gFDOt5E5//UAurV01XQhoYCjRtzYjfKp7KcRx+XU9TgXwgVSUETdhEZc+eO7FW7dq38uVcvWUzj5lZ692n1FKW7VlbAH38Aw4bJhO3gwTLRbOy9JFFxPU2MUsWQnCxzUJcuyQnp169XTsIWYIxSAdLTZcla3iSspjp29mw5qycA7NsnGzQXRL96plUreemNp6ecMcjTU041n3dCn2nTgC++AKZOxebWrRFx4ECZTMJLVBw8jyqbSgW4u8ulY0fDbZpWC3mrczWtFo4elYs+MzP5/9yw1YIKDRpUQTVNZ8FateSEHrGxhj1yDx2SVyDotyBMSAC8vWWlrn6P3ICAErskpyRiNCcH2L36Aaw/fBuul6LRPvc82ufZZ2zoEUzcrrm60gPoeVd+KEf0GDyPGmKlbTFVtkpbKh0VMU42bwb+8x/5vszaWr7PGjvW9L0aiyI3V77X/PlnOd4FC4BXXjH1qIioIsjMlFd6b9sGuLrKmZPr1TP1qKjSS042XhU7ahQQHCz3KagiVmP+fGD0aPn94cNAZKRhIlY/IWtn92TjmzZNJmjzVtYWtJ6IqITl5BTcaiEpqeDbuboab7Xg5fWo1YIQ8lNcGxt5ngTkp7matjD67OyAFi3kxIkDB5bGwyzYnTvAvn1Q792Hi3ed8aXqfaxcCTy4m4NEOMMesq3NLaf6ULcKQc1nQ2HeNlS2flBC7ycihWKlLZWohw8fwjZv5QORnqws4L//Bb78Uv7csCHw+++ydVNZOHPmDBo85Qyi5ubAjz/KZPO8ecCrr8pEy5gxJTRIqtRKIkapfMrNlTmvbdtk27b165WZsGWMVjDJybpq2Lg42edVMwPomjWyL1BKivHbtmqlS9p6egLVquVPwtauLZcmTXS3CwzM3yTyaeTmGiRmtTGqSdTm5pbcfRGVAJ5HKx4LC8DfXy7PPKNbL4RseWSs1UJcnMx13rkje7zqs7XVtFpQoUGDetqkrr8/YBMRIct99fvjHjki28vs2WNYTXLwoOxDFxioq8itVy9P813ICc3NzfOfRwH5AVhuruGk5zEx8pPlffsgoqOhungRAGAGQI36+BHvAwCqV7fA8gaz0TTCHY1HBsO9JqtoqWTwPGqISVsqkszMTCZtqUDnzwMvvKCbnfW114CvvnrygpqncfHixRI5uZuZyV68NjbAN9/IKuGMDODdd0tgkFSplVSMUvkiBPDmm8Dff8tLBFetku+vlIgxWo6kpMhkbPXqspwLADRtAzQVs8nJhreZN0+XtHVy0iVsq1bNn5DVn9irXTt5aa8p6CcSkCdGWWFLCsTzaOWhUgE1a8olPNxwW2qq8VYL588DDx/KvGhMTP7j+fqaISDAHw0a+COg4YtoMAAI8MuFy73zMoGr39Nh3z6ZEdbPCjs6yokag4Jkgrd+fZmw1Wspo41RzRULI0cajEO88CJUZ8/IMT1adxoNEI1QnLQPxegXBQYOUiE8HLCwMLwtUUngedQQk7ZEVGxCAIsWAePGyQ+Aq1UDfvoJ6NfP1CN7OiqVTDrb2sp5UN57TyZu//tfU4+MiMqbadOAuXPleeXXX4HOnU09IlI8IXQ9hS5floGjXzF7/brumty5c4HXX5ffZ2YCGzcaHsvZWZeIrVlTtz4wUGYQatc27KdoTHnob0REpCD29vI0m/dD2pwc2drWWHVuYqI85V++DKxbp38rc1Sv3gANGjRAwC5dq4VGLfqi9s+OMDvyqCI3JkZ+WLd9u1yeeUYmbSdOlAedNAk4cQI+VavKNzUnTsjDL12KrNnzsHWnJZYtA4Jiu6MuPBGNUEQjFLHVW6PzwKoYNAgY1p7zhhGVNf7JlTK2DKbClOf4SEyULez++kv+3LGjfF9Zq5ZJh1ViVCo5P4qNjXyN8/HHMnE7dSrfvxJR0cyfL9t7AsB33wHPPWfa8ZBCJCXJqtiCJvaaMUOXiL1xI1+1qZaTk0zUajRqJJuy67cusLc3flvNVOhERFRmLCwAPz+59OmjWy+EnIMsbyL37Fng2jXg7l1g1y656HjBxmYY6tcfhoAAoFHXbLSyP4NGDw/B/cYhWDRvrttVM+vpsmXQa2gDoVLhhnUddPe4jVPJngCAhfgaNWoA/fsDHw4C2rdna1oiU+JEZMX0uKbBubm5OH/+PNzc3OBSAWZJVKvVMMvbH4ee2r1795CQkAB/f3+Yl6P/hrt3A0OGyBcRFhaykuz99037Dz0rK6vUZpr84gvggw/k9++9B3z+ORO39ORKM0ZJeZYvBwYNkm/EJk6UH/goHWP0KaWlGU/ExsUBw4frsva7d8uWAwX56CP5qSEA3LolPzk01kvWwaHUH5LSMEZJ6RijVNLS0gputZCVZfw2KhXg46Ob/KzOmTUwX78Go7AAZhDIgTl6Yh32IxjJkAndmjWBAQPka5e2bZmoJdOpLOdRTkRmYubm5nB2dkZCQgIAwM7ODqpynOWpLH84ZUUIgfT0dCQkJMDZ2bncJGxzcoDp02WSVq0G6tYFli41bH1XZvI01Y+Pj4enp/yE2GhT/afw/vuy4vbNN+VEaxkZwOzZ+fv8ExXGIEapQtu+Xc7xJAQwahQwZYqpR1Q0jNFCpKcbVsPGxcnEa4cOcvvevUBYWMG3b95cl7T18pJVsQVN7OXlpbudu7ucIZMAMEZJ+RijVNKqVJFtalu2NFyfkwNcuWK81cKDB7INQ2ysptVCb3yMozCDQCasYI0sBGM/oiy6YexrMlEbFsZELSkDz6OGmLQtRTUf9Q7TJG7Ls/T0dNiV5axSlYSzs7M2TpTu6lVZXbtnj/z5P/8Bvv/ehIU+eZrqx8TEyJO7pql+CZe1jRsHWFvLSda+/14mbufP54sbKjptjFKFFhMD9O0rq1+efVbXz7Y8qLQxmp6uS8bWqqVrG3D6tJxlMy5OvgPO68MPdUlbTW8gB4f8iVhPT6BVK93tvLyAkydL9zFVUJU2RqncYIxSWbGwAOrVk0vv3rr1QgB37hgmch1mT8NUMQkTMRXTMREfYxqmYRIsAER+x0kdSVl4HjXEpG0pUqlUcHd3h5ubG7Kzs009nKcSFRWFjvqzVdJTs7S0LDcVtn/9JavFkpLk+9H582UVmUlpZo3WJG6bNzdM2JbCrNKjRsnE7csvA//7n2wl+PPPbMhPRNLly0D37nIekA4d5JUI5eQ0X3E9fAhkZ8sZtQGZmJ0+3bBi9v593f4TJsiesoAsbzp+XLfN3r7gRKynp/wnWcjlbURERKVNpQLc3OTSoQPk+yMxCZMeJWwBYDomQgVgas4kYBpK5X0TEZUMphrKgLm5eblJzhUkJycHNjY2ph4GlbHUVNkSYOFC+XNICLBkCVCnjmnHBUD2Z2jVSrZAmDQJPS0s5HVCpZSw1Rg2TLZKGDJETryWkSGfE0vLUrtLIioH4uOBbt3k12bNgH/+kecKKgNJSfIJN9ZP9t49WRE7c6bcNzcX+OGH/MeoUkUmXjWTtQCyenb9el2iVn9bXmZmTNgSEZHy5Obi9OCpmPbHRKhUshJXpQKmiYkYPBhomJtr6hESUSGYtKUiCSusTxtVSIcPy6tCL1yQ/9j/+19ZxGry5GRmpsySfvmlvO7nr78AKyuYZ2XJkrbatXWvRkrJ888DVlby67Jl8jLoP/+UVbhEBeF5tOJKTgZ69AAuXQJ8fWWer7D8nlIpKkY1zfoKmthr4ED5jwmQSdthwwo+1u3buu89POQHe3lbGDg55f+/YWEhS6dJMRQVo0RGMEZJcSZPRkMAywfJ2pazZwUCAlSIjAQaPssKW1IenkcNMWlLRAbUauDrr+Xk1dnZ8r3sb7/p2vaZTGKirI6aPVvOpg3IqqZffgGysiAsLaHKzpa9C6KiZCNJe/tSG86zzwKrVgH9+8sCr379gBUrAFvbUrtLIlKgzEx5Pjh6FHB1BTZulHNHUSEyMoAbN/JP7BUcLBumA8DNm4CfX8HHaNRI9727O9ClS8ETezk76/a1tCzxnudERERK17+/XO7ff4Bq1aqZejhEVERM2lKR7NmzB3369DH1MKiU3bol3y9v2SJ/7t9fTlpt0v/rWVmyx+CCBbJfAyAvWR0/XiZyP/kEmDoVa5o2RZ/vvgO2bpV9Cw4elFW4TZqU2tB69gTWrAGeeQbYsEFOAvDvv/IqW6K8eB6teHJzgaFDgW3b5GdE69cXnmdUnMmT5RUKj1rKGMTotGnyAU6e/GTHzMw0TMjWqgWEh8ttt28DTZvKGVKMSUzUJW3d3WUTdXd34xN7+fvrbmdpCWze/GTjpHKJ51FSOsYoKR1jlJSOMWqISVsiAiCTjyNGAHfvymrR2bOBV15RwKznlpbA3r0yYdu4MfDee7Jvw2efaRO2mDgRWL1aZptfeQX46Sc5VWrr1sC335bqA+nSRSZse/WSiZvu3YG1a9nakKiiEwJ46y3ZIsXSEli5EggMNPWonpC5uW4yR/1e4PqTOurLzJQVsCoV4OMj1yUlyUSrpmI2IcHwNkOG6JK2Li7ynwwg/9HoV8N6espztoalpTy2yf8JERERERGZBpO2RJVcRgbw/vvA99/Ln5s3B37/HQgIMMFghJCZz+++A37+WZb4qlQyQZuWJjOimjfwubnGJx373//kNcp//w1cvAiMGgUcOmR84pkS0r69LPLq3h3YvRvo2lUmcqtWLbW7JCITmz4dmDNHnpJ++01+gFPuaM6fmsRt8+a6hG3XrjIB26+frn2BJiH74ouytzggLy1Ys0b21tGwsdElZPXbGFhaAidOyOrZqlUfn5BlwpaIiIiIKjGVEEKYehDlUXJyMpycnJCUlATHSlBSFxcXB09PT1MPg0rYqVPA4MHAyZPy5/HjgU8/NcGEWjk5slztiy9kY0hAVtF+9FGRD5EvRtVq4Kuv5DEWLZLVXqXs8GE5e/z9+0CLFsCmTUD16qV+t1RO8DxacfzwA/Daa/L7774Dxo417XieihCyKe8//0BYWUGVlSVbIkydapiI1bCxkYnc33/XrVu0SJ7sNBWzmg/ciEoYz6OkdIxRUjrGKCldZYnRouYUmbQtpsqWtM3KyoKVlZWph0ElRAhg/nzgnXdkpa2bm3zP3aNHGQ8kNVW2MvjmG+DqVbnO1hYYORJ4+22gTp0iH6rAGL14EahXT/fzzZuyyquUEgrHj8uKuzt3ZDeHLVuAGjVK5a6onOF5tGJYsQIYNEjmMz/+WBamllv37gGvvip7O2hYWck2CG++KRv15u0n6+LChCyZDM+jpHSMUVI6xigpXWWJ0aLmFM3KcExUjm3cuNHUQ6AScveuLJJ64w2ZsO3eXSYayzxh+/ChTKaOHy8Ttq6usrIrLk6Wrj1BwhYoJEb1E7Z37gBBQcDzz8teiaWgaVNgxw6ZFz55EujQQc7JQ8TzaPm3Y4fsDKBWy84reVu+litbtsgT1sqVgJl8OZhrYSEnf5w2TfYDnzEDeP11oE8f2TqhenUmbMmkeB4lpWOMktIxRknpGKOGmLQlqkS2bQOaNQP+/VcWU33zjZw0q8wqQfWzl7a2QESETKrOmycTtxMnyiqu0rJ7t0zcLlsGtGwp+xmUggYNgJ07ZWHauXOy562mkJiIyqeYGOCZZ2QR6rPPAnPnltP8ZWamnNCxa1d55YGLi8xCT52KdStWyEz0pEnlvISYiIiIiKj8Y9KWqBLIzgY+/FBetn/zppxkbN8+WeRqVhZngb17ZZbDy0s20tX49lvg7FnZHNLWtvTH8eyzMnHr7Q1cvgy0aSOrekuhS0y9ejJx6+sr76p9e+DSpRK/GyIqA5cvy6sRkpPl3/LSpYC5ualHVQwPHwIhIbLfNwC0aiVbJOhP6jhxIhO3REREREQKwKQtFUk9/UvMqVy5eBEICwM++0zmJkeNAg4dkhNllSq1GvjnH6BtWzmAVavkui1bdPs4OZVY5qPIMRocLCc769dPXgb85pvAgAHAgwclMg59Pj4ycevvD1y7JpM9Z8+W+N1QOcHzaPmUkCAvCrh9W3YT+OcfORdXuWRrK8/J1avLSy569jRI2GpjVJO4zc014WCJ8uN5lJSOMUpKxxglpWOMGuJEZMVU2SYio/JHCODXX4ExY+R8X1WrAj/+KPOTpSorC1i8WFZynTsn11lZAS+9JC/JbdCglAdQRELIKtv33pOlyG++CcyeXSp3dfu2rHI+dUpO+rZ1q5ykjIiULTkZ6NgROHJEfgizd6/sV12uxMcDOTlArVry54cPZU/vmjVNOy4iIiIiokqKE5FRiWIz6PIlKQkYMgQYNkwmbNu3B44dK4OELaCbUv3cOVlJ++GHwJUrwE8/lWrC9oljVKWSidq9e2UZXSleBlyzJrB9u5zHJyEBCA+XSSCqXHgeLV8yM4H+/eXfqqsrsGlTOUzYrl0LNGkiZ0/TVM3a2haYsGWMktIxRknpGKOkdIxRUjrGqCEmbalIsrKyTD0EKqLoaJkc/P132Xlg+nQ5AZmnZynd4dWrMuGpVsufbWyAKVOAr78G4uKAmTPLJNNR7BgNCgI2bAA0n24JAXzxBXD/fskNDvJq5G3bdC0kO3cG9u8v0bsgheN5tPzIzQX+8x9ZFW9vD6xfD/j5mXpUTyA9XV5m0bu3nHwxMVF+fQzGKCkdY5SUjjFKSscYJaVjjBpSVNJ28uTJUKlUBktAQIB2e0ZGBsaMGQMXFxfY29tjwIABiI+PNzjGtWvX0KtXL9jZ2cHNzQ3vv/8+cnJyDPbZvn07WrZsCWtra9SrVw+LFi0qi4dHVKpyc2WCtl07Wdjq4wPs2gX897+lNGFOTIws561bV05Ys3q1bttrrwFvvw04OJTCHZeyOXOADz6Qme+9e0v00FWrypa+YWEyh9K1q5wX7f/Zu+/wKKoujuPfTQ8lAQKhE5Aeeif0HiAgCNhABBRFRRQLdgWxoL6i2BsKiGJBAQVC770aeu/Sa6jp8/5xzcKSACEEdkJ+n+fZh+yd2dmzm5MhOXvnXBGxD8uCp5+G338Hb28YPx5q1HB3VNchKsp8GPXll+b+M8+YT4jUDkFEREREJFOxVdEWoEKFChw8eNB5W3hJReOZZ55h4sSJjB07lnnz5nHgwAE6derk3J6YmEhERARxcXEsXryYUaNGMXLkSN544w3nPrt27SIiIoKmTZsSFRVF//796d27t6ZgX0MB/bFna3v3mr6Lr79uirddu5q/28PCMviJLMtcI9yypVnJbMwY84TNm0P+/Bn8ZNcnw3K0fn0oVcrMEm7UCD744OIs4gwQEGAm9jZtCmfOmM4Ms2dn2OHFxnQezRzeecd8duNwmL7gLVq4O6I0SkqCDz+E2rVh0yZzhcO0aeaqhzSunKYcFbtTjordKUfF7pSjYnfKUVe2Wohs0KBBTJgwgaioqBTboqOjyZcvH2PGjKFLly4AbN68mfLly7NkyRLq1q3LlClTaNeuHQcOHCD/fwWkr7/+mhdffJGjR4/i4+PDiy++yOTJk1m/fr3z2Pfddx+nTp1i6tSpaY5VC5GJXfz5J/TubWZu5shhJlc98IApOGSoY8dM9WLNGnPf0xPuuccs5FW9egY/mZudPg19+sCvv5r7bdrAjz+aHgcZ5MIFuOsuU1Px8zOz+Vq3zrDDi0g6fPut+dEHs07hk0+6N57rEhNj+q+sXw8dO5qVJzPwnCUiIiIiIhkj0y5Etm3bNgoVKsQdd9xBt27d2Lt3LwCrVq0iPj6eFpdMeSlXrhzFihVjyZIlACxZsoRKlSo5C7YA4eHhnD59mg0bNjj3aXHZtJnw8HDnMa4kNjaW06dPu9yykkWLFrk7BLnMuXPw6KPQpYsp2NaubWbXdu+egQXb5IVrAIKCwMsLsmc31w5v325m2tqkYJuhORoQYF7bN9+YiuqUKRneLsHfH/76C9q3N7WWDh3Mfbl96Txqb+PGweOPm69fey0TFWyTP3v38zPnrW+/NS8mHQVb5ajYnXJU7E45KnanHBW7U4668nJ3AJeqU6cOI0eOpGzZshw8eJA333yThg0bsn79eg4dOoSPjw+5cuVyeUz+/Pk5dOgQAIcOHXIp2CZvT952tX1Onz7NhQsX8Pf3TzW2IUOG8Oabb6YYnzJlCtmyZQOgZcuWHD9+nNWXLAsfFhaGl5cXCxYscI5VrlyZwoULM2XKFOfYHXfcQYUKFZgxYwYxMTEABAcHU6dOHZYsWcKxY8cAyJYtG82bN2fdunXs3r3b+fiIiAh2797tLE4DNG7cmJiYGJZdstpRzZo1CQwMZNasWc6xcuXKUbp0aSZPnkzSf5eBFy1alKpVqzJ37lzOnDlDUlISCxcupEGDBqxcuZKDBw8C4O3tTevWrdm8eTPbtm1zHrNVq1YcPXqUf/75xzlWr149PDw8XFpeVK5cmUKFCrnMci5ZsiShoaFMnz6d2NhYwHyPateuzeLFizl+/DgA2bNnp1mzZqxZs8ZZ3Ado3749O3bsYOPGjc6xpk2bcu7cOZYvX+4cq1WrFjlz5mT2Jdemly9fnlKlSjFp0iSSJ6EXK1aMKlWqON8LgDx58lC/fn1WrFjhzC0fHx/Cw8PZtGkT27dvdx4zPDycw4cPu8wgr1+/PuB6QqpatSr58+d3adVRqlQpypcvz7Rp05wNuQsUKICXVy06djzP3r3ZcDgs7r9/LyNHhrBx4xomTjTvhcPhoF27dmzfvp1NmzY5j9msWTPOnDnDihUrnGO1a9cme/bszJkzBwDfEyeotWQJuadMYcr775OQPTsApV9+mXJNmzI7Kopz69bBunUEBQVRr149li9f7uwx7evrS6tWrdi4cSM7duxwPk/r1q05cOAAa9eudY41aNCApKQkFl9SEK1WrRr58uVj+vTpzrHSpUtTrlw5pk6dSnx8PAAFCxakZs2aLFy4kOPHjzNx4kRy5sxJkyZNiIqKYt++fQB4eHgQERHBtm3b2Lx5s/OYzZs3Jzo6mpUrVzrH6tSpg5+fH/PmzYOCBcn5/vvU++QTvPfsYdHChZz8L/+KFy9OpUqVmDVrFufPnwcgb968hIWFsWzZMo4cOQKAn58fLVu2ZMOGDezcudP5PG3atOHQof307LmO48ers3hxIbp0sfj66zMEB89z7le9enWCgoKYMWOGc6xMmTKULVuWKVOmOHt2FypUiBo1arBgwQJOnToFQGBgII0aNWL16tXs378fAE9PT9q2bcvWrVvZsmWL85gtWrTg5MmTrFq1yjlWt25dfH19zXvxn4oVK1KsWDEiIyOdYyVKlKBixYrMnDmTCxcuAJAvXz7q1q3L0qVLOfrfAkj+/v60aNGC9evXs2vXLufj27Zty969e12ugGjcuDGxsbEsXbrUOVajRg1y587NzJkznWNly5alTJkyREZGkvjfhwyFCxemevXqzJ8/n+joaABy5cpFw4YNWbVqFQcOHADAy8uLNm3asGXLFrZu3eo85s06lx87doyJ//V+dte5HCB37tw6l192Lv/mm83061eapCRP2rTZx+DBRW/JubxWrVosWrSIE/8tfJh8/rr0vbjiubx2bRzPPMMeT0+233MP8N+5/P77mTNpknO/0NBQSpYs6cy9S9+L2bNnc+7cOQCCgoI4ceKE28/lJ0+edHkvMuRc/p8KFSpQvHhxJk+e7BzLiHP5/v37Xd6Lhg0bkpCQ4DIhQOfyjDmXJ5/b3Hkut8Pv5aBzuZ1+L7/0XJ6UlMTcuXPTfi5Pw+/lcH3ncjv8Xq5zuX3P5cm/j2b138t1LrfvufzSv5ncdS6H6/y9PB3n8uRz1bWkuz1CYmIiY8eOZc6cORw5coTBgwdTqVIloqOjmTVrFvXr109RHL1ep06dIiQkhI8++gh/f3969erlTLBktWvXpmnTprz//vs8+uij7Nmzx+Ubcv78ebJnz05kZCRt2rShTJky9OrVi5dfftm5T2RkJBEREZw/f/6KRdvY2FiX5z59+jRFixbNMu0RJk6cSPv27d0dRpaXlASffAIvvQRxcVCokOm52KxZBj3B5s2mJ+Lo0eYJwPRbSJ5+ZmM3NUfPnoV58yAi4uJYQoKZeZwBEhKgZ0/4+Wfw8IBRo0yLC7m96DxqT2vWmPbVp0+brgJjx2bYj/bNs2yZWQhyxw7w8TGrTxYseMOHVY6K3SlHxe6Uo2J3ylGxu6ySoze1PcKpU6eoX78+Xbt25ZdffuHvv/92fvqeI0cOnnrqKT755JP0RX6JXLlyUaZMGbZv306BAgWIi4tzflKV7PDhw85GxQUKFHB+onjp9uRtV9snICDgigVbMJ9QBgQEuNyykpw5c7o7hCzv8GFTM3z2WVNP7dAB1q7NgIKtZcHChXDnnVC+PHz/vXmCevVMo9XkBo82d1NzNEcO14Lthg1QrhzMnZshh/fyMoXahx4yhfkHH4ThwzPk0GIjOo/az86dppf06dOmcPvLLzYv2CYkwFtvmQUTd+yAYsVgxowMKdiCclTsTzkqdqccFbtTjordKUddpato+9JLL7FhwwamTZvGzp07uXSyrqenJ126dHGZop9eZ8+eZceOHRQsWJAaNWrg7e3tMuV8y5Yt7N27l7CwMMBMk1+3bp3z8geAGTNmEBAQQGhoqHOfS4+RvE/yMSR1TZo0cXcIWdqUKVC5MkydatoWfvWVqacGBWXAwQ8cgCZNYOJE0wy3Y0dYtMjcOnY0Uz8zgVuaowMHmoJJ8+YweLBr79908vQ06wY9/ripoz/yiFnBXm4fOo/ay5EjEB4Ohw6Z8+tff5nzq23t2mXO1W+8Yc459913cZpwBlGOit0pR8XulKNid8pRsTvlqKt0VWMmTJhAv379aNmyJY5UVjwqU6aMSy+QtHr++eeZN28eu3fvZvHixdx11114enpy//33ExgYyMMPP8yzzz7LnDlzWLVqFb169SIsLIy6desCpsdHaGgo3bt3Z82aNUybNo3XXnuNvn374uvrC8Bjjz3Gzp07eeGFF9i8eTNffvklv//+O88880x63oosY82aNe4OIUuKjYX+/aFtW1NgqFQJVq6Exx67gcXGLlwwVeBkhQub1cseeQQ2bTLV4Hr1MiL8W+qW5uioUdCrl5kWO3AgtGplKj83yMPDFGqffdbcf/JJGDr0hg8rNqHzqH2cOWPOq9u3Q/Hi5gOxy1rm28v581C3rvkwLWdO08JmzJgMD1o5KnanHBW7U46K3SlHxe6Uo67SVbSNjo6mRIkSV9weHx/vbMJ9Pf7991/uv/9+ypYtyz333ENQUBBLly4lX758AHz88ce0a9eOzp0706hRIwoUKMC4ceOcj/f09GTSpEl4enoSFhbGAw88wIMPPsjgwYOd+5QoUYLJkyczY8YMqlSpwtChQxk+fDjh4eHXHW9WcmkTark1Nm2COnVMD1uAfv1g+XKoUCGdBzx+3FxWGxJiLvW/pNk9P/xgVhwvW/aG43aXW5qj2bOb9+zHHyFbNpg9G6pUgUsa8aeXw2HaCr/yirn//PPw9ts3fFixAZ1H7SE2Fu66C1atgnz5YPr0DOsucPNkywavvWbaIqxZY5pep/uTuytTjordKUfF7pSjYnfKUbE75airdHVuK1mypMvqfZebPn26sx3B9fj111+vut3Pz+geM64AAQAASURBVI8vvviCL65yzXBISMg1WzM0adLEZcU9ETuxLHOZfP/+ZlJs3rwwcqRrS9XrsmsXfPSRKTImr1AYEgL//nuxSHsT/vjPErp3h1q14O67Yf16M+N2xgzTNuEGOBzwzjvg7w+vv25uMTGm5q5vlUj6JfeMnjXLtKqOjITSpd0d1RXMn29OArVqmftPPmn6p9i66a6IiIiIiGSUdM207d27Nz/88AO//fabs5+tw+EgNjaWV199lalTp9InkyxeJGmTWhsMyXgnTkCXLmbtrwsXoGVLs9hYugq2Bw+anoelSsHnn5uCbbVq5pLa7dtvuLBoN27L0XLlzBToRx4xvSUbN86wQ7/2Gnzwgfn6nXdgwABT1JfMSedR97IsePpp+P138PY2nWBq1nR3VKmIj4dXXzX9a++/3/RyAPOJzU0u2CpHxe6Uo2J3ylGxO+Wo2J1y1JXDsq6/BGBZFo8++ijff/89uXLl4tSpU+TPn5/jx4+TkJBAnz59+Oqrr25GvLZx+vRpAgMDiY6OJiAgwN3hyG1g7lxzxev+/aagMGQIPPPMDawDdu6cWVn8xAkzA3TAAFOo1Unw5omJubiSUWwsLF2aIUXczz6Dp54yX/ftC59+mmnWhxOxjbffNrPWHQ745Re49153R5SKrVuhWzfTvBxM7+xPPzXTgkVERERE5LaQ1ppiuv7sdzgcfPfdd8yfP58HH3yQNm3aULVqVR599FHmzp172xdss6Lt27e7O4TbVny8mVHZrJkp2JYuDUuWwHPPXUdhLi7O9Fe9556LUzGzZzd9FqKiYNo0aNHiti7Y2iJHL116fsAAM1Pu5ZchHT2+L9WvH3zzjfn2ffGFmYmdmHhjocqtZ4sczaK++84UbMH0CbddwdayYPhwczXEypWQOzeMHWva2tzCgq1yVOxOOSp2pxwVu1OOit0pR13d0HV2DRo0oEGDBhkVi9jYpk2bKFWqlLvDuO3s3Aldu8KyZeb+Qw+ZgkKa/0Y/fdpUIz7+2FR8AXr2NMuiA3TqlNEh25atcjQp6WJV9b33YMECM7WvaNF0H/LRR01NuFcvU9uJjTX1HLW3zDxslaNZyPjx8Nhj5utXXzUfgtjK+fPmMovx4839Zs1g1CgoUuSWh6IcFbtTjordKUfF7pSjYnfKUVe6wFbETX7+GapWNQXbwED47Tf4/vs0FmwPHIAXXzRFwOefNwXbAgVMT4WwsJsdulyLh4eZEvvbb5AzJyxaZL7Zkyff0GEffNC0JPb0hNGjTcE/Pj5jQha5Hc2bZ9rCJiVB795mMT/b8fc3n8J4e8P//mcWM3RDwVZEREREROwlXXO0SpQocc3mwA6Hgx07dqQrKJHb2enTZhHw0aPN/fr1TQE3JCSNB9iwwVxCm1ytK1fOFG4feAB8fW9KzJJO99wDNWqYf1evhnbtzPfq3XdNgSYd7r0XfHzMv2PHms4Yv/2mb73I5dasgTvvNPXQjh3hq69s1CEmNtacw3PkMEH98IP5MK5aNXdHJiIiIiIiNpGuhch69uyZomibmJjInj17WLRoERUrVqRatWqMGDEiwwK1m6y2ENm5c+fInj27u8PI9JYtM7Mjd+40kzHfeMNcrnvVS9wtC/btM4uKJd+vWhUCAuCFFyAiQqtSYfMcjY01PW4/+8xMq1679uL3M50iI033i9hYaN0axo0zE/bEvmydo7eZXbugXj04dAgaNjRtvW3z87Fhg/mPoFo1GDnS3dG4UI6K3SlHxe6Uo2J3ylGxu6ySo2mtKaZrpu3Iq/yRsWbNGsLDw+nWrVt6Di02debMmSzxg3OzJCbCBx+YIm1CgqnXjRljZtle9UHjx5vLZbdtg717L87KmjcPcuW6VeFnCrbOUV9fswJ8kyamt8ENFmzBtC2ePBnat4epU80k3r//NuvPiT3ZOkdvI0eOQKtWpmBbqZL5ubBFwday4PPPzYdtMTFw8KAJskABd0fmpBwVu1OOit0pR8XulKNid8pRVxk+Pa9KlSr06dOHF198MaMPLW60YsUKd4eQae3fDy1bwiuvmILtPfeYy3avWLA9fx6+/BLKloW774bly81Y8mploIJtKjJFjnbqBB06XLw/dSo8+6zpcZAOzZubGYQ5csDs2WbG7enTGRSrZLhMkaOZ3Jkz5gON7duheHHzI2aL0+WhQ+aqiKeeMgXbNm1g3TpbFWxBOSr2pxwVu1OOit0pR8XulKOubso11fnz52fjxo0349AimcqECVC5MsyZY2ZAjhgBv/56hSLCiRPw5pumuW3fvrBjB+TJA6+/bmbZNm9+i6OXm+rMGbOy2Mcfm+u3d+1K12EaNjTrFgUGwsKF5gOCkyczOFaRTCA21nwusmoV5M1rPtAoVMjdUQGTJpn/CKZMMbPuP/vMTJPPn9/dkYmIiIiIiI1leNH2+PHjfP/99xTRyseShZ0/D489BnfdZWqxNWqYdah69rzKQjjJRdtjx6BECfOH/d69MHgwBAffyvDlVsiZE4YPh9y5zWzqatVMY9p0qFvXzLTNk8ccqnlzk0YiWUVSEvToATNnmg/IpkyBMmXcHRVw7hz07g1Hj5rC7apVZiVK26yIJiIiIiIidpWuhciaNWuW6vipU6fYvHkzcXFxjB49mvvvv/+GA7SrrLYQ2eHDh8mvWUFpsnYt3H8/JE82HzAA3n4bfHwu23HFCli0CPr3vzj22mvmD/tOna6xOplcLtPm6J49cN99sHSpuf/kk/Dhh2ZG3nVat84UbI8ehYoVTQErM74lt6tMm6M2Z1mm68Dnn4O3t5nE2rKlu6O6xJQpZjr8kCHp+rm+lZSjYnfKUbE75ajYnXJU7C6r5Ghaa4rpKto2adIEx2WzRBwOB7lz56ZkyZI89NBDlCtX7vqjzkSyWtH27Nmz5MiRw91h2JplmcmxL7xgLtMtUABGj4YWLS7ZKSnJ/AH/v/+ZxcQ8PMwiY3fc4ba4bxeZOkfj403B/oMPzP3q1U1+pOP1bNpkCrcHD5q2yLNmQeHCGRyvpEumzlEbe+cd8+PjcJgFHu+7z43BJCbC0KGmzc2997oxkPRRjordKUfF7pSjYnfKUbG7rJKjaa0ppqs9wty5c5kzZ47Lbfbs2fz555988MEHt33BNiuaM2eOu0OwtSNHoF07ePppU7Bt187MuHUWbGNjTUPbSpXMxnnzzEzaBx4whVu5YZk6R7294f33zRTBoCCoUiVdBVuA8uVh/nwoWhS2bIFGjcxkXnG/TJ2jNvXdd6ZgC/DJJ24u2O7bZ076L74IffrA4cNuDCZ9lKNid8pRsTvlqNidclTsTjnqStdfi9yg6dPNelKHD5srX4cOhSeeuKRl4cqV0KEDHDhg7ufMaf6gf/ppUO9nuVTbthAVZfrcJjt5Evz9wc8vzYcpVcoUbps3h507TeF29mwoWTLjQxZxlwkTTO9wgFdegX793BjM2LHw6KNw6pRpqvvRR+pFLiIiIiIiNyRNRdsff/wxXQd/8MEH0/U4kcwgNhZefdUUaQEqVIBffjGTaUlIuNiTtmxZsxhNoUKmUNunDwQGui1usblLC/lJSdC1q+l18Pvv17WyUvHiZkJ38+awdasp3M6aBboQQm4H8+ebWbVJSWadr7ffdlMgZ86YavGoUeZ+rVrw889QurSbAhIRERERkdtFmoq2PXv2vO4DOxwOFW1vI6Ghoe4OwVa2bDGLjf3zj7n/xBNm7Sj/7eugx4ewebNZWMrhMDNrZ882K0OlWI1MMsptmaO7d5vV5o8ehRo14JtvTBE3jYoUMYXbFi1gwwZo3NgUbitWvHkhy5XdljnqBmvXwp13mg/OOnSAr7665MqGW+nsWahWDXbsMG1uXn4ZBg407U4yKeWo2J1yVOxOOSp2pxwVu1OOukrTQmR70tkQMSQkJF2Pywyy2kJkYlgW/PCDWan8/HnIkwd++N6iQ+Bcs4jU1KkXd162DGrXdluscps4cAC6dYO5c8393r3h009Ny4Q0OnYMWrY0nReCgkxLj+rVb0q0IjfVrl1Qrx4cOgQNG8K0adf1o5Dx+vc3fRpGjzYBiYiIiIiIXEOGLkQWEhKSrpvcPiZOnOjuENzu5EmzGHjv3qZg26JJAtve/o0Ob9eCZs1MwdbDA7p0UcHWDW7bHC1UCGbOhDfeMNMJhw83ubVpU5oPkTevmexdqxYcP25aJixbdhNjllTdtjl6ixw5AuHhpmBbqRL8/bcbCra7dsHevRfvv/ee+TTkNinYKkfF7pSjYnfKUbE75ajYnXLUlZatF0mDBQugalWz1oyXl/k7fdqAmeR54j5z+bq/v+mRsHWr2UkFW8lInp7w5pswYwbkzw/r119s6JlGuXOb2m/9+matpJYtYeHCmxeySEY6c8as07dtG4SEmM/IcuW6hQFYFvz4I1SpYma+JyaacT+/WxyIiIiIiIhkFWnqaZuaQ4cO8f3337N69Wqio6NJuqx44HA4mDVr1g0HKOJOCQnw1ltmkZs8SUfpWmgD/Sc0oVYtIKmVWd2pWTPo29dMZxS5mZo3N7P6Hn4YBg82M7uvQ0CAKXbdeSfMmWNmLU6caFJYxK7i4qBTJ/P5WN68pr1HoUK3MICTJ+Hxx+G33y6OnTpleo2IiIiIiIjcJOkq2q5du5YmTZpw4cIFypYty7p16wgNDeXUqVPs37+fkiVLUrRo0YyOVdyoWLFi7g7hltu920yoOrJ4G5/zEQ97jsQrNgceFfYA2UzBbO5cN62AI5fLMjlaoABMnuw69uuvZnWxNKwwliOHefhdd5l+oBERMH48tG59k+IVpyyToxkoKQl69DCzxLNnh8hIKFPmFgYwdy48+CDs23dxxvtLL5mvb0PKUbE75ajYnXJU7E45KnanHHWVpoXILte2bVvWr1/PwoULyZYtG8HBwcycOZNmzZoxduxYHn/8cSIjI6l9G18iroXIbm+//grfPbyUJ87/j7sYjwf//ZjUrg1jxkDJku4NUCTZP/9A3bqmiPT559CrV5o+SIiNhbvvNjNtfXzg99+hQ4dbEK9IGlkWPP00fPYZeHubDxtatrxFTx4XBwMHwvvvm0BKlYKff1brGxERERERuWEZuhDZ5RYtWkSfPn0oVqwYHv9dnpvcHuHuu++mW7duDBgwID2HFpuaPXu2u0O4Jc6cgUF3rqbw/Q2ZdT6MzowzBdt27WDePFi6VAVbm8oqOZpC4cLQpAlcuGDaJnTvDmfPXvNhvr7wxx9m3by4OPPv2LE3P9ysLMvmaDoNGWIKtgCjRt3Cgi2YKb6RkaZg+/DD5sORLFCwVY6K3SlHxe6Uo2J3ylGxO+Woq3QVbZOSksifPz8AuXLlwtPTkxMnTji3V6pUiVWrVmVMhGIL586dc3cIN93KlVC9Ovw20Z+GLCTBw5ukHr1gwwYzHbFRI7VCsLGskKOpCg6GKVNMhcvT08wGrFED1q695kN9fOCXX0wbkIQEs7bZTz/dgpizqCybo+kwfDi8+qr5+pNP4P77b8GTWpbrAmNjxphPNoYPN31FsgDlqNidclTsTjkqdqccFbtTjrpKV9G2RIkS7Nq1yxzAw4MSJUowc+ZM5/bFixeTS6spS2Zw8iRJ7w5hRcNnCQuD7dvhXNHybHnxB7z27sJj5A8QGuruKEWuzsPD9NmcOxeKFIGtW82swO++u+ZDvbzMLMaHHzaTCx980NSoRNxlwgTo08d8/cor8NRTt+BJjx6Fjh3hnXcujlWoAJ0734InFxERERERSSnNRduTJ086v27VqhVjL7mO9vHHH2f48OG0aNGC5s2bM2rUKLp27ZqxkYpbBd1uq2Tv3QvPPktS0WJ4vPoK1RZ+SqGEPXTuDGvWQNn3epnLziXTuO1yND0aNDCXcUdEmKa1x46l6WGenvDtt/DEE2ay4SOPwBdf3ORYsyDl6LXNn29mfCclmQ8S3n77Fjzp1KlQuTL8/bfpYXv06C14UntSjordKUfF7pSjYnfKUbE75airNC9E5uvrS9u2benWrRv169fnwIEDVK5cGW9vbyzL4p133uHPP//E09OTdu3a8corr+Dj43Oz43cbLUSWSa1ZA//7n1lp7L/LYNdSiU99BlDvk3vp1cdHHRAk80tKMg1q777bzMIFk+/XWPHesuD55+Gjj8z9Dz+E5567ybGK/GftWtOFJjraLIr3xx9mJvhNExNjZqh/8om5HxpqWiJUqXITn1RERERERLK6DF+IrEuXLsycOZN7772X8uXL88UXXzB//nwsy8LhcPDaa6/xzz//sHLlSgYNGnRbF2yzouXLl7s7hBv3669Qtarp+ZmYyCya0Zop9KiyhufXdOehx1SwzcxuixzNKB4ecO+9Fwu2589DnTpm+uxVPqdzOEyhNrmX6PPP36KZjlmEcvTKdu2C1q1NwbZBA9Nr+aYWbNetg1q1LhZsn3zSNDbP4gVb5ajYnXJU7E45KnanHBW7U466SnPR9ueff+bIkSP89NNPNGzYkJ9//plWrVpRuHBhnnvuOVavXn0z4xQ3O3z4sLtDuH4JCbBv38X7rVuTmDMXUwLvpQYracEsKjzbmqXLHJQr574wJWNkyhy9VUaMgFWrTGHqnntMZewKHA5TqH3rLXP/9dfhtdeuWuuVNFKOpu7oUQgPh4MHoWJF06XA3/8mPuGZM9C4MaxfbxbymzwZPvvsJj9p5qAcFbtTjordKUfF7pSjYnfKUVfXtRCZv78/999/PxMnTuTQoUN8+eWXlC5dmmHDhlGrVi3KlSvH22+/zc6dO284sPfeew+Hw0H//v2dYzExMfTt25egoCBy5MhB586dU3xD9+7dS0REBNmyZSM4OJgBAwaQkJDgss/cuXOpXr06vr6+lCpVipEjR95wvGIjZ8+a2VOlSplFZCwLy4Ivfs5Fgdg9tI3+lX+DazBlCgwdCr6+7g5Y5CZ74gn4+GPw9jbXnFerZmYVXsVrr5lOImDWZhowQIVbyXhnzkDbtrBtG4SEwLRpkDv3TX7SnDnNJxMREWbGbdu2N/kJRURERERErt91FW0vlTt3bvr06cO8efPYu3cv7733HtmyZeONN96gdOnS1KtXL91BrVixgm+++YbKlSu7jD/zzDNMnDiRsWPHMm/ePA4cOECnTp2c2xMTE4mIiCAuLo7FixczatQoRo4cyRtvvOHcZ9euXURERNC0aVOioqLo378/vXv3Ztq0aemONyvwzQyVzcOHTaWpWDHo3x/27IHduzmxbj8dOphJhsfiAmjTxvRObN3a3QFLRsoUOeouDof5mVi0CIoXN9ei16tnPty4SiX2+efNBEQwH3D062fa5Ur6KEddxcWZz9VWroS8eWH6dChU6CY92d9/w5IlF+8//jhMnGhm2oqTclTsTjkqdqccFbtTjordKUddpXkhsrRYt24db7zxBn/99RcOh4PE/xZ6uh5nz56levXqfPnll7z99ttUrVqVYcOGER0dTb58+RgzZgxdunQBYPPmzZQvX54lS5ZQt25dpkyZQrt27Thw4AD58+cH4Ouvv+bFF1/k6NGj+Pj48OKLLzJ58mTWr1/vfM777ruPU6dOMXXq1CvGFRsbS2xsrPP+6dOnKVq0qBYis4MdO8yK3z/+CMnfo9Kl4bnnmFP0Qbr19ufgQfDxgQ8+gKeeQr1rJes6dQoefhjGjTP3Bw6EQYOu+pDvvoM+fUx9t3dv+Prra65pJnJVSUnwwAOmd2327DBnjmkxm+HOnTOr6X3zDZQoAVFRoP+zRURERETEjdK6ENkNL/Oxd+9exowZwy+//ML69euxLIt69erRrVu3dB2vb9++RERE0KJFC96+ZAWcVatWER8fT4sWLZxj5cqVo1ixYs6i7ZIlS6hUqZKzYAsQHh7O448/zoYNG6hWrRpLlixxOUbyPpe2YUjNkCFDePPNN1OMT5kyhWzZsgHQsmVLjh8/7tLfNywsDC8vLxYsWOAcq1y5MoULF2bKlCnOsTvuuIMKFSowY8YMYmJiAAgODqZOnTosWbKEY8eOAZAtWzaaN2/OunXr2L17t/PxERER7N69mw0bNjjHGjduTExMDMuWLXOO1axZk8DAQGbNmuXyPpYuXZrJkyeT9N80uqJFi1K1alXmzp3LmTNnsCyLPHny0KBBA1auXMnBgwcB8Pb2pnXr1mzevJlt27Y5j9mqVSuOHj3KP//84xyrV68eHh4eLFy40OW9KFSokEvBvGTJkoSGhjJ9+nRnoTx//vzUrl2bxYsXc/z4cQCyZ89Os2bN2P3XXxT/7jsATpQtS54hQ9hUugKvDfRg/Hg/LAvKlEniq69Ocu7cYiZNMs9Tq1YtcubMyezZs53PXb58eUqVKsWkSZNI/jyjWLFiVKlSxfleAOTJk4f69euzYsUKDh06BICPjw/h4eFs2rSJ7du3O48ZHh7O4cOHiYqKco7Vr18fgEWLFjnHqlatSv78+V1mfZcqVYry5cszbdo04uLiAChQoAC1atVi0aJFnDhxAoCcOXPSpEkT1qxZw969ewFwOBy0a9eO7du3s2nTJucxmzVrxpkzZ1ixYoVzrHbt2mTPnp05c+Y4x0JDQylZsiQTJ050jiW/F7Nnz+bcuXMABAUFUa9ePZYvX+5sV+Lr60urVq3YuHEjO3bscD6+devWHDhwgLVr1zrHGjRoQFJSEosXL3aOVatWjXz58jF9+nTnWOnSpSlXrhxTp04lPj4egIIFC1KzZk0WLlzIiRMncDgczvciKiqKff/1NPbw8CAiIoJt27axefNm5zGbN29OdHQ0Ky9pFVCnTh38/PyYN2+ec6xChQoUL16cyZMnO8eKFy9OpUqVmDVrFufPnwcgb968hIWFsWzZMo4cOQKAn58fLVu2ZMOGDS6tY9q0acP+/ftd3ouGDRuSkJDAkktmBFavXp2goCBmzJjhHCtTpgxly5ZlypQpzvYvhQoVokaNGixYsIBTp04BEBgYSKNGjVi9ejX79+8HwNPTk7Z//MGRgQPJ+eWXLCxenJiJE2nRogUnT55k1apVzuepW7cuvr6+FCgwj6efLsKnn1Zl+HAHMTFJdO4ciaen+RkpUaIEFStWZObMmVy4cAGAfPnyUbduXZYuXcrRo0cB02KnRYsWrF+/nl27djmfp23btuzdu9flw7TGjRsTGxvL0qVLnWM1atQgd+7czJw50zlWtmxZypQpQ2RkpPODwsKFC1O9enXmz59P9H/9e3PlykXDhg1ZtWoVBw4cAMDLy4s2bdqwZcsWtm7d6jzmzTqXXzrmrnM5mCtl3Hkur1WrNvfdd4CxYwvh5ZXEG2+spVatqi7nL4D27duzY8cONm7c6Bxr2rQp586dc1mg4Irn8uhoznboQI7/cv9Iw4YE+/rqXM6Vz+W5cuXi7Nmzbj2Xnzx50uW90Ln8Kufytm3ZunUrW7ZscR7zaufyS9+LihUrUqxYMSIjI51jmeFcnvzz6c5zuR1+Lwf3n8uv9Ht5hp/LM9nv5ZZlERAQkOV/L9e53L7n8iNHjuBwOLL87+U6l9v3XH7pz/Ht/Ht58mu8Jisdjh49an3xxRdW/fr1LQ8PD8vhcFjly5e33n77bWvXrl3pOaRlWZb1yy+/WBUrVrQuXLhgWZZlNW7c2Hr66acty7Ksn3/+2fLx8UnxmFq1alkvvPCCZVmW9cgjj1itWrVy2X7u3DkLsCIjIy3LsqzSpUtb7777rss+kydPtgDr/PnzV4wtJibGio6Odt727dtnAVZ0dHS6X29m8vfff7s7BCMx0bLGj7esn366OJaQYFl9+ljWggWWlZRkbd1qWTVrWpaZF2g2nTvntojlFrFNjmYml5/zZs+2rKSkK+7+66+W5elpfq7uvtuy4uJucny3GeWo8e67F8/PY8bchCdISLCs996zLC8v8ySFC1vWzJk34YluP8pRsTvlqNidclTsTjkqdpdVcjQ6OjpNNcU0z7Q9d+4c48ePZ8yYMcyaNYv4+HgKFixI//796datG9WrV0/roVK1b98+nn76aWbMmIGfn98NHetm8PX1VW8Nd4qJgdGj4cMPYetWyJ/fNEP08zPXaX/9NZZlOiT07WuuiM2dG4YPh0vaHovIpfz9L349frz5YWnXDkaOhKCgFLvfe69ZuO+ee2DsWNOT9LfftJifpN3338Mrr5ivhw2D++/P4Cc4cwbuvBPmzjX3O3eGb7+FPHky+IlERERERERurjQXbYODg4mJiSFHjhx07dqVbt260axZMzw80r2WmYtVq1Zx5MgRl+JvYmIi8+fP5/PPP3dOXT516hS5cuVy7nP48GEKFCgAmCnNl07NTt6evC353+SxS/cJCAjA/9IChtjDiRPw1VdmNaTk71uuXPDQQxAfb4q2mDadjz8Ov/5qdmncGH76CYoUcUvUIplPdLSpvk6aBNWqmR+mVBaU7NgRJkww9d2//jL3x41zrf+KpOavv+DRR83XL78MTz99E54kRw7ImdM0yv3sM+jZU03MRUREREQkU0rzQmQdOnSgW7du3HnnnTdlJuyZM2fYs2ePy1ivXr0oV64cL774IkWLFiVfvnz88ssvdO7cGYAtW7ZQrly5FAuRHTx4kOD/VoT+9ttvGTBgAEeOHMHX15cXX3yRyMhI1q1b53yerl27cuLEiasuRHa5tDYNvl3Ex8fj7e19a590zBjzF/5/PZooWhSeecashJQzp3O3xYuha1fYs8dMuh08GF58UQslZTVuydHbTVSUmUa7bZv5AXrnHRgwAFL5cG7WLDOh8fx5aNYM/v7b1MnkyrJyji5YAK1amYsmHnrIXAWRYbXU06fNv8n/Fx89aj6EKFUqg54g68jKOSqZg3JU7E45KnanHBW7yyo5mtaaYpqnyf7111/cc889N611Qc6cOalYsaLLLXv27AQFBVGxYkUCAwN5+OGHefbZZ5kzZw6rVq2iV69ehIWFUbduXcA0Zg4NDaV79+6sWbOGadOm8dprr9G3b19na4PHHnuMnTt38sILL7B582a+/PJLfv/9d5555pmb8rpuF8kNwm+6/xrZA1CxoinYVq5sps3u2GGKtv8VbBMSTIG2USNTsC1RAhYuNJfeqmCb9dyyHL2dVa0Kq1aZT0ESE+Gll0y7hP8Wn7lU8+YwdaqZ2Dh7NrRufbF2JqnLqjm6bh20b28KtnfeCd98k4EF2yVLTN727XtxLF8+FWzTKavmqGQeylGxO+Wo2J1yVOxOOeoqY3ob3CIff/wx7dq1o3PnzjRq1IgCBQowbtw453ZPT08mTZqEp6cnYWFhPPDAAzz44IMMHjzYuU+JEiWYPHkyM2bMoEqVKgwdOpThw4cTHh7ujpeUaVy6kmaGsyyYPh1atLh47SyYYu2KFWb2X7ducMmnLXv3QtOmMHCgqS1162Z2+69+L1nQTc3RrCRnTvMhyXffmfYjU6bAJStwXqphQ5gxAwIDzQcmLVvCf4sFSyqyYo7u3g3h4Wbia4MGpuuGV5obM11FQgIMGmSScNcuM5X3v1VvJf2yYo5K5qIcFbtTjordKUfF7pSjrjLiT6ebZm7yQiL/8fPz44svvuCLL7644mNCQkKIjIy86nGbNGnCP//8kxEhyo2IjzerGH34IaxZY8b8/c3qNIGB5n7Nmike9scf8Mgjpo9tjhym5e0DD9yyqEVufw6HaUNSpw5ERprGtVdQt66ZaduyJSxfbmbgTp8OefPeunDFno4eNQXbgwfNhRN//51BvY937jQn/SVLzP0HHoDPP7/4/4aIiIiIiMhtIFPNtJXbxJkz8PHHULIkdO9uCrbZs5tVaTZtuuIf3ufOmTrS3Xebgm3t2mZ2rQq2IjdJpUqmQXSyAwfg/vsvLgr4n+rVYe5cCA6Gf/4xs+Av20WymLNnISICtm6FkBDTSiN37hs8qGXBqFFQpYop2AYEwM8/w+jRKtiKiIiIiMhtJ80LkYmrrLYQ2cmTJ8l9w39x/2fIENN4FiB/fnjqKXjsMciT54oPWb3a1Iq2bjWTAF9+2VwZmwX6U0saZWiOSuoiIszM2wIFTLGsWTOXzZs3m6GDB6FsWbNYWeHCborVhrJKjsbFmVbIM2aYGdcLF5p8uGGnT5sDHTpk2iKMHm0qwpJhskqOSualHBW7U46K3SlHxe6ySo5m+EJkkrUlJSWl/8GbNpmqa7JHHzVT8777zjQ8fOWVKxZsk5Jg6FBzCfbWraYANGuWWdReBVu51A3lqKTN//4HoaGmaNaihfnkJDHRublcOZg/H4oVgy1bLi4SKEZWyNGkJOjZ0xRss2eHyZMzqGALZmbtqFHmP4A5c1SwvQmyQo5K5qYcFbtTjordKUfF7pSjrlS0lTRZvHjx9T3AsszCMHfeaYo8Tz11cVtQkFmhvndvs9DRFRw6BG3awPPPm/a3HTuaTgpNm6bvNcjt7bpzVK5faKhZHPChh8zP+Jtvmma2Bw86dylVyhRu77jDtB5t1Ah27HBjzDZyu+eoZcGzz8Ivv5jFxsaNM21s0i0uzrTn+Pnni2OtWpkP+jw9bzheSel2z1HJ/JSjYnfKUbE75ajYnXLUlYq2krESE+HPPyEszFRrJk40/Qzy5YPz59N8mMhIqFzZLGjk7w9ff20KAEFBNzF2Ebm2bNng++/hxx/NVMo5c6Bq1YuLCWImQM6fD2XKwN695lSwebP7QpZb47334JNPzNejRpn6arpt3mz+H/ngA3jiCTh+PENiFBERERERySxUtJWMM2GCuT66SxdYtgx8fU0rhE2bYPx4U+y5hpgYsx5ZRIRZebxyZVi5Evr0MbVfEbGJ7t3ND2elSubTlFKlXDYXLgzz5kGFCmb9ssaNYf16N8UqN933319sVT5sGHTtms4DWZb5lK56ddNWJygIRo7UJ3YiIiIiIpLlqGgraVKtWrVr7xQbC9u3myXCX33VNLP85ps0NzTcuBHq1IFPPzX3n3rK1H5DQ28gcMky0pSjkrHKlTM/pJGRZtYtmKamR44AZr2yuXPNRNwjR6BJE9f21lnN7Zqjf/9tPp8DeOkl88Fbuhw9Ch06wOOPw4ULpvXG2rVw110ZFqtc3e2ao3L7UI6K3SlHxe6Uo2J3ylFXDsuyLHcHkRmldaW3TGvQINMz8PXXAYiNjcXX19dse+stOHbMFGfKlYO+fc14QgL88IOZYpUjR5qfyrLg22/hmWfM3+n58sGIEWa2rUhaueSouM///mcuaR89Glq3BuDkSfPl8uWQKxdMnWo+oMlqbsccXbDAtEGIiTGtjocPT+dVEdHRUL686Y/s4wPvv28+ufPQZ8u30u2Yo3J7UY6K3SlHxe6Uo2J3WSVH01pT1F9DkjpPT3jjDVOgBaZPn27GH3vMjH/2GXz+OQwZYhaLAbPyzKOPXlfB9vhx6NTJHPbCBfPH/9q1KtjK9XPmqLhPQgL88Yf5UKdNGzPtMj6e3LlhxgyoXx9OnTITKBcudHewt97tlqPr1pm1JmNioH17c2FFutvYBAbC/febfhorVkD//irYusHtlqNy+1GOit0pR8XulKNid8pRV/qLSFL3+usweLAp0A4eTPDKlVCihPmrHMz02PBws9qMt3e6nmLOHKhSxbTC9faGoUNhyhRzSbWIZEJeXqaRbfLs+/ffNz0R9u0jIMDMsG3aFM6cMaeP2bPdGq3cgD17zOzpU6dMMf7XX823/7qsXQu7dl28/+67pmBbuXJGhioiIiIiIpIpqWgrV5ZcuB04kDqDB8Pu3Wbm0wMPQFSUqcA0b37dU6vi482CNc2bw/79ZoX5pUvh2Wc1sUok0/PzM7Pwx46FgABYvNg0tZ04kRw5YPJkU+w7f97MqJ861d0By/U6etRcFXHgAFSsCBMnpmmdyYuSkuDjj6FWLejWzczQBrN4pb//TYlZREREREQks1GJTK7u9dcvzqT19DSF29GjzRTZdNixAxo0MF0VLAseftgsTFS9esaFLFlT6dKl3R2CXKpLF/PDXaMGnDhh7u/fj7+/mV2ffFn9nXfCX3+5O9hb43bI0bNnTbF961YoVswU3XPnvo4DHDhgqvbPPmta6wQFwblzNy1euT63Q47K7U05KnanHBW7U46K3SlHXaloK1f31ltmaqyPDyQmwsiR6T7UTz9BtWoXFyP6/XezaE3yovMiN6JcuXLuDkEuV7IkLFoETz9tFicrXBgwEyr/+APuvtucXrp0MeeD211mz9G4OOjc2XQwCAqCadOc39K0mTDBtD6YMcPMqP3qK/j7b9PPVmwhs+eo3P6Uo2J3ylGxO+Wo2J1y1JWKtnJlb73l7Gk79a+/Lva4/W9xsrQ6fdp0VOje3fSybNgQ1qwxBRuRjDJV19nbk68vDBtmCrfJoqLwnjyBMWPMuSEhwaxBNXq026K8JTJzjiYlQc+eMH26+aAtMhLS/PvU+fNmkcq77jKrT1arZmZhP/bYDaxcJjdDZs5RyRqUo2J3ylGxO+Wo2J1y1JWKtpK6Swq2vP468fHxrouTpbFwu3SpaWf588+mu8LgwWYBsmLFbm74kvXEx8e7OwRJizNn4J574K678HruaUZ+E8vDD5uiYI8eZvb97Sqz5qhlmW4Gv/xiFhv780+oXfs6DuDpaabnOhzwwgvmPwZ9gm5LmTVHJetQjordKUfF7pSjYnfKUVfXu9azZBWJic6CrYvk+4mJ13z4e+/BwIHm65AQGDMG6tW7SfGKSObg62sa2Q4dCp9+iueiRXz76+/4+t7Bl1/CI49AbCz07evuQCXZ++/DJ5+Yr0eOhPDwNDwoMdFUe728zPd8zBg4eBCaNbuZoYqIiIiIiNw2VLSV1A0a5HK3YMGCF+9cXsi9zL//mlYIc+ea+/fdZ1oX5sqVoRGKuHDJUbEvHx/48ENo3Nhcb79qFR41qvH58O/x8+vCRx/Bk0+aRcqee87dwWaszJijP/wAL79svv74Y+jWLQ0P2rPH/CfQrNnF/0vKlzc3sbXMmKOStShHxe6Uo2J3ylGxO+WoK4dlWZa7g8iMTp8+TWBgINHR0QQEBLg7HNsYNw5694aTJ03fwy++gAcfVNtCEUnF3r2mme3ixQBYjz/BoMCPGfyeD2C6sLz2mjsDzNr+/tu0oU1KgpdegiFD0vCgX36Bxx+H6GjzSd3OnZA7980OVUREREREJNNIa01RPW0lTRYuXHjV7efPQ58+ZmXxkyehZk345x/To1IFW7kVrpWjYkPFipkp+S+8AIBjx3befMfL2TL79ddN0fZ2+WgxM+XowoVw772mYNurF7z77jUeEB1tZtd27Wq+rlsXVq5UwTaTyUw5KlmTclTsTjkqdqccFbtTjrpSewRJk5MnT15x25o1pgXC5s3m/gsvmBlyPj63KDgRrp6jYmPe3qZpatOmUL06eHjw2mvg75PI8y968s47plXC//6X+T8Ayiw5um4dtG9v3vf27eHbb6/x3i9cCA88YNoieHhcrLZ76VeMzCaz5KhkXcpRsTvlqNidclTsTjnqSn9RSbpZFnz6qSnSxsVBwYLw44/QooW7IxORTKd1a5e7z217jPD6HtRaNIyhQ/2JiTHnGw9dH3JT7dljvhWnTkH9+vDrr9eovZ46BW3bwpkzUKIE/PSTVpwUERERERHJACraSprkzJnT5f7hw+aS2SlTzP327c2CNXnzuiE4EVLmqGRi69bB999T0bL4t8hS6v/7O198UZbYWPj6a/D0dHeA6WP3HD12DMLD4cABqFABJk6EbNmu8aBcucw06MWL4bPPQD3eMzW756iIclTsTjkqdqccFbtTjrrSQmTplJUXIps2zfSqPXwYfH1h6FB44onMf+myiNjIjBnQrRscPUq8b3Yejvua0dYDdO9uPiDSlfcZ6+xZaNYMVqwwrYYXL4bChVPZ0bJg5EgoXRoaNLg4pv8ARERERERE0kQLkUmGioqKIjYWnnvOXDp7+DBUrGjWmenbV3+vi/tFRUW5OwTJSC1bmobZTZrgHXuOH63ufO94mD9Gn6drV4iPd3eA18+uORoXZxaRXLECgoLMB3OpFmxPnIC774aHHjI9bE+fNuP6D+C2YdccFUmmHBW7U46K3SlHxe6Uo65UtJWrGjcOqlSBWrUqkSsXfPSRGe/bF5YvN4VbETvYt2+fu0OQjFawIMycCQMHgsPBQ9YPTHG0ZexYi7vvhthYdwd4feyYo0lJptXN9OmmFcLkyVCuXCo7zp4NlSvDn3+aac6PPQbZs9/yeOXmsmOOilxKOSp2pxwVu1OOit0pR12paCtXNG6cmX21bh0kJHgSE2PGX3oJPv8c/P3dG5+IZAGenjBokCneFixI9kEv4Ovr4K+/oGNHuHDB3QFmXpZlrp4YM8bUYceNgzp1LtspNtasNtmiBezfD2XKwNKl5j+CzNpcWEREREREJBNQ0Vau6M03zb+Xdj12OC4uPiZiJx4eOp3d1po1g+3bqflGWyZPNrNCj01dQZc25zh3zt3BpY3dcvSDD2DYMPP1yJFmETIXJ09CWJhZaMyy4NFHYfVqqFHjFkcqt4rdclTkcspRsTvlqNidclTsTjnqSguRpVNWWIjM3x/n7NpL+flpdpuIuNfysXsofU9VDlGAIdXG8vncitymp+KbYsQI05oWTNubZ55JZSfLgk6dYMEC+P576NDhlsYoIiIiIiJyO9JCZHLDypRJub6MwwFly7onHpGr2bZtm7tDkFuodvEjZM+XjfJs5pt/avFZleGcPGHvzyDtkqMTJ8Ijj5ivX3zxsoLtkSNw6pT52uGA4cNNjxwVbLMEu+SoyJUoR8XulKNid8pRsTvlqCtbFW2/+uorKleuTEBAAAEBAYSFhTHlkmvxY2Ji6Nu3L0FBQeTIkYPOnTtz+PBhl2Ps3buXiIgIsmXLRnBwMAMGDCAhIcFln7lz51K9enV8fX0pVaoUI0eOvBUvL9MZONBMtEou3Doc5v7Age6NSyQ1mzdvdncIcivVqoXPhiii67XGnxhe3f0IS0o9wPHdZ9wd2RXZIUcXLYJ77oHERLMA2ZAhl2ycMgUqVYInnrg4FhRkFoSTLMEOOSpyNcpRsTvlqNidclTsTjnqylZF2yJFivDee++xatUqVq5cSbNmzejQoQMbNmwA4JlnnmHixImMHTuWefPmceDAATp16uR8fGJiIhEREcTFxbF48WJGjRrFyJEjeeONN5z77Nq1i4iICJo2bUpUVBT9+/end+/eTJs27Za/Xrvr1MksFF65Mnh7J1K5slmo5q673B2ZiAiQLx+BCyZzsP97JOBJ25NjOF22JsdnRbk7Mltavx7atTNtb9q1g2+//e9DuQsXoF8/aNvWzLRdt+7ibFsRERERERFxC1sVbdu3b0/btm0pXbo0ZcqU4Z133iFHjhwsXbqU6Ohovv/+ez766COaNWtGjRo1GDFiBIsXL2bp0qUATJ8+nY0bN/LTTz9RtWpV2rRpw1tvvcUXX3xBXFwcAF9//TUlSpRg6NChlC9fnieffJIuXbrw8ccfu/Ol21anThAVBX/+GUlUlAq2ImIzHh4U/PhF9v88jwMeRSgRt5XILj+wf7+7A7OXPXvMQmOnTkH9+vDbb+DlBaxZAzVrwuefmx2ffhpWrIBcudwYrYiIiIiIiNiqaHupxMREfv31V86dO0dYWBirVq0iPj6eFi1aOPcpV64cxYoVY8mSJQAsWbKESpUqkT9/fuc+4eHhnD592jlbd8mSJS7HSN4n+RhXEhsby+nTp11uWUnz5s3dHYLIVSlHs7aQrvWJXRbF8JzP8MipD2jUyBQq7cRdOXrsmCnYHjgAFSrA339DNr8kswJZ7dqwcSMUKABTp8KwYWa1ScmSdB4Vu1OOit0pR8XulKNid8pRV17uDuBy69atIywsjJiYGHLkyMH48eMJDQ0lKioKHx8fcl02+yd//vwcOnQIgEOHDrkUbJO3J2+72j6nT5/mwoUL+Pv7pxrXkCFDePPNN1OMT5kyhWzZsgHQsmVLjh8/zurVq53bw8LC8PLyYsGCBc6xypUrU7hwYZd+vXfccQcVKlRgxowZxMTEABAcHEydOnVYsmQJx44dAyBbtmw0b96cdevWsXv3bufjIyIi2L17t7M4DdC4cWNiYmJYtmyZc6xmzZoEBgYya9Ys51i5cuUoXbo0kydPJikpCYCiRYtStWpV5s6dy5kzZ7Asizx58tCgQQNWrlzJwYMHAfD29qZ169Zs3rzZpWF0q1atOHr0KP/8849zrF69enh4eLBw4UKX96JQoUJMnTrVOVayZElCQ0OZPn06sbGxgPke1a5dm8WLF3P8+HEAsmfPTrNmzVizZg179+51Pr59+/bs2LGDjRs3OseaNm3KuXPnWL58uXOsVq1a5MyZk9mzZzvHypcvT6lSpZg0aRKWZRY1KlasGFWqVHG+FwB58uShfv36rFixwplbPj4+hIeHs2nTJrZv3+48Znh4OIcPHyYqKso5Vr9+fQAWLVrkHKtatSr58+d3adVRqlQpypcvz7Rp05yzxQsUKECtWrVYtGgRJ06cACBnzpw0adLE5b1wOBy0a9eO7du3s2nTJucxmzVrxpkzZ1ixYoVzrHbt2mTPnp05c+Y4x0JDQylZsiQTJ050jiW/F7Nnz+bcuXMABAUFUa9ePZYvX+7sMe3r60urVq3YuHEjO3bscD6+devWHDhwgLVr1zrHGjRoQFJSEosXL3aOVatWjXz58jF9+nTnWOnSpSlXrhxTp04lPj4egIIFC1KzZk0WLlzIiRMncDgczvciKiqKffv2AeDh4UFERATbtm1z6ZHTvHlzoqOjWblypXOsTp06+Pn5MW/ePOdYhQoVKF68OJMnT3aOFS9enEqVKjFr1izOnz8PQN68eQkLC2PZsmUcOXIEAD8/P1q2bMmGDRvYuXOn8/Ft2rRh//79Lu9Fw4YNSUhIcPkQqXr16gQFBTFjxgznWJkyZShbtixTpkxx9uwuVKgQNWrUYMGCBZz679L2wMBAGjVqxOrVq9n/39RTT09P2rZty9atW9myZYvzmC1atODkyZOsWrXKOVa3bl18fX1d3ouKFStSrFgxIiMjnWMlSpSgYsWKzJw5kwsXLgCQL18+6taty9KlSzl69CgA/v7+tGjRgvXr17Nr1y7n49u2bcvevXtZv369c6xx48bExsY6r6QAqFGjBrlz52bmzJnOsbJly1KmTBkiIyNJTEzE8XFb8g50sHMnhNU+x+zSXTjSJRxHjRo0bNiQVatWceDAAQC8vLxo06YNW7ZsYevWrc5j3qxz+fLly53nkFt1Lg8KCuGZZyqzZQvkzXuB555byMaN/jSoUIG4997DJy6OQ3XqsKF/f5qHh+tcTtY+l5coUYL169e79Vx+8uRJl/dC5/KseS4HKFy4MNWrV2f+/PlER0cDF8+d7jyX2+H3coDcuXPr93IbnsstyyIgICDL/16uc7l9z+VHjhzB4XC49VyeK1cut/9ernO5fc/lq1atcv7c3M6/lyefq67FYSW/azYRFxfH3r17iY6O5o8//mD48OHMmzePqKgoevXq5UywZLVr16Zp06a8//77PProo+zZs8flG3L+/HmyZ89OZGQkbdq0oUyZMvTq1YuXX37ZuU9kZCQRERGcP3/+ikXb2NhYl+c+ffo0RYsWJTo6moCAgAx+F+xn4sSJtG/f3t1hiFyRclSS7d8PzZpBu61DGcrzJHn74PHRUOjb9+LKim5wq3M0Lg7uvBOmTTPriS1cCOXKXbLDrFmwYwc88ohb3xexD51Hxe6Uo2J3ylGxO+Wo2F1WydHTp08TGBh4zZqi7doj+Pj4UKpUKWrUqMGQIUOoUqUKn3zyCQUKFCAuLs5ZcU92+PBhChQoAJjqePInipduT952tX0CAgKuWLAF8wllQECAy01EROyncGGYNw+WlHuICXTAIz7OLLR1991ZZoGtpCR46CFTsM2WDaaMPUu5D3vDqFEXd2reHB59VAVbERERERERG7Jd0fZySUlJxMbGUqNGDby9vV2mnG/ZsoW9e/cSFhYGmGny69atc17+ADBjxgwCAgIIDQ117nPpMZL3ST6GiIhkfgUKwN8LcvNmlfE8zTDi8IY//4Tq1c1CW7cxy4Lnn4effzaLjc18dzm1Hq0G339vFhr779I0ERERERERsS9btUd4+eWXadOmDcWKFePMmTOMGTOG999/n2nTptGyZUsef/xxIiMjGTlyJAEBAfTr1w/A2XMnMTGRqlWrUqhQIT744AMOHTpE9+7d6d27N++++y4Au3btomLFivTt25eHHnqI2bNn89RTTzF58mTCw8PTHGtapzLfLo4cOUJwcLC7wxC5IuWopObkSWjdGpKWr2Csx70UT9oF3t7www/wwAO3NJZblaPvvw8vvQQeJLLq7veoOm4gJCZC0aLw44/QpMlNj0EyJ51Hxe6Uo2J3ylGxO+Wo2F1WydFM2R7hyJEjPPjgg5QtW5bmzZuzYsUKZ8EW4OOPP6Zdu3Z07tyZRo0aUaBAAcaNG+d8vKenJ5MmTcLT05OwsDAeeOABHnzwQQYPHuzcp0SJEkyePJkZM2ZQpUoVhg4dyvDhw6+rYJsV+Wk1cbE55aikJndumDED/BrUomrSaiZ4dSbR4QlVqtzyWG5Fjo4YYQq2xdjD3hJNqDr2NVOwvfdeWLNGBVu5Kp1Hxe6Uo2J3ylGxO+Wo2J1y1JWtZtpmJlltpm1WaQYtmZdyVK7m3DmzKNfs2RbV/TbxwaRQmjf/b+ORI3ALPs292Tk6cSLcdRcEJh5nn19pssWchJw54YsvzKxi9a6Va9B5VOxOOSp2pxwVu1OOit1llRzNlDNtRUREbobs2WHSJGjd2sHqmFAiImDKFGDpUiheHD780KzelUktWgT33GMm1d7ZMwj/J3tDvXpmdm337irYioiIiIiIZDIq2oqISJbg7w8TJpgZt7Gx0KEDbB8yFi5cgAEDzIbjx90d5nXbsAHebr2QQjE7aNcOvvsOHO+8DfPmQYkS7g5PRERERERE0kFFW0mTChUquDsEkatSjkpa+PrCH3/A3XdDfDyUn/whKx/5xmyYPBmqVjXTVm+Cm5Gje3fEMyPsdSadbczfObrx20/xeHkBPj6YL0TSTudRsTvlqNidclTsTjkqdqccdaWetumU1XraJiUl4eGhGr/Yl3JUrkdCAvTqBT/9BB4eMGHwWtr/eDds3QqenvD22/DCC2ZjBsnoHD2xbBv7mjxAlZjlAMTe1wPf77+EbNky7Dkka9F5VOxOOSp2pxwVu1OOit1llRxVT1vJUJMnT3Z3CCJXpRyV6+HlBSNHQu/eppVth9crM7LfKrNgV2IivPwyjBuXoc+ZYTlqWcR++T1+9apRJWY50Y5cHP/yN3x/GamCrdwQnUfF7pSjYnfKUbE75ajYnXLUla6dFBGRLMnTE775rzPCF19Ar345OPfZj/Rt2hRmzoTOnd0dYkqnT5PUoxe+E0xBeYFXEwpM+5HSzYq6OTARERERERHJSJppKyIiWZaHB3z2GTz3nLn/ZD8HQ08+BGPGgMNhBs+cgU8/NTNw3SzJx48983cThzeveb+Pz7yZKtiKiIiIiIjchlS0lTQpXry4u0MQuSrlqKSXwwH/+x+8+qq5//zzpqUtAJYFjz0GTz8N4eFw+HC6nyfdORobC/HxWBYMeNWH8BO/0NBzCQ3+foE69TzTHY/I5XQeFbtTjordKUfF7pSjYnfKUVdaiCydstpCZCIiWcHbb8Prr5uvX30V3noLHKN/hMcfh/PnIX9+Mwu3WbNbE9CGDdC1K9x5Jx/kfIsXXzTDo0eb9rsiIiIiIiKSuWghMslQs2bNcncIIlelHJWM8Npr8OGH5ut33oEBA8Dq/iCsXAkVK5qZti1awMCB190u4bpy1LLg88+hZk1Yu5YLn37H2y+eBmDoUBVs5ebQeVTsTjkqdqccFbtTjordKUddqWgraXL+/Hl3hyByVcpRySjPPWfqpWAKpP36QVLZ8rBsGfTubQqqgweb4u2hQ2k+bppz9PBhaNfOPHFMDEeqt6bU2SjOEMALL8Czz6bjRYmkgc6jYnfKUbE75ajYnXJU7E456kpFWxERkcv07QvffWf63X7xBfTpA4m+2czgzz9DjhywefPFxcoyyqRJUKkSREaCry87+39K8Y2RHEgqQI8e8N57Gft0IiIiIiIiYk9e7g5AMoe8efO6OwSRq1KOSkbr3Rt8faFnTxg+HGJiYMQI8Ora1bQtOHbM9LhNlpQEHlf+LPSaOXrsGNx3H5w7B5UqsX3wGGo/VJELMRARcbGILHKz6DwqdqccFbtTjordKUfF7pSjrrQQWTppITIRkazh99+hWzdISIC77zYTbb29L9vp11/hyy/NImVFiqT/yb7/HjZsYO9j71KvmR/790NYGMycCdmy3dDLEBERERERERvQQmSSoZYtW+buEESuSjkqN8s998Aff5hC7dixpnAbG3vJDrGx8PzzsGABVK1qWhukIkWOJiWZVc/mzbs49vDDHHvlI8I7mIJtaKjpmKCCrdwKOo+K3SlHxe6Uo2J3ylGxO+WoKxVtJU2OHDni7hBErko5KjdThw7w11/g52f+7dgRLlz4b6OvL8ydC9Wrw/HjppfBCy9AfLzLMVxydP9+aNkSBgyA7t3hzBnAdEZo1860yy1aFKZNgzx5bslLFNF5VGxPOSp2pxwVu1OOit0pR12paCsiIpIGbdpcnPU6daoprp4799/GUqVg8WJ48klz/3//gzvugOeeS3mgP/80+8+ebQ72+uuQIwfx8WYW77JlplA7bdqNdVoQERERERGRzEtFW0kTPz8/d4cgclXKUbkVmjc3BducOU3NtXVrOH36v42+vvDZZ6aXQmAg/PsvfPQRvPwyANktCx5+GLp0MauaFSoE//wDjzxCkuXgoYdgyhRTx508GcqXd9/rlKxJ51GxO+Wo2J1yVOxOOSp2pxx1pYXI0kkLkYmIZF3LlpmC7alTULu2KeTmzn3JDrt2wb33mka4ixfDiy+aYu6OHWZ7w4ZmdTEfH8C0xB06FLy84O+/zaxeERERERERuf1oITLJUBs2bHB3CCJXpRyVW6lOHZg1C4KCYPlyMwP32LFLdihRAhYuNL1uBw+G99/H2rnTbHvoIZg/31mw/d//TMEW4IcfVLAV99F5VOxOOSp2pxwVu1OOit0pR12paCtpsjO52CBiU8pRudWqVzc12eBg0+WgaVM4fPiSHXx8zEzb118HHx8clmXGvv/eucuoUWbNMoAPPzRrkom4i86jYnfKUbE75ajYnXJU7E456kpFWxERkXSqWBHmzTPtadevh8aNYf/+y3Z66y2IiyPRywvi4sx9TN/ahx82uwwYkPqaZSIiIiIiIpI1ebk7ABERkcysXDnT7aBZM9iyBRo1MouUhYRgCrRvvAGDBxNZtSrto6LgjTfYuxfu/vl1EhOhRw94/313vwoRERERERGxEy1Elk5ZbSGyhIQEvLxU4xf7Uo6Ku+3ZYwq3O3dCsWLwT6e3yDPMFGx5/XVnjh7p9xbBn7/B6wzmn4jXGT/edFEQcTedR8XulKNid8pRsTvlqNhdVslRLUQmGWp/iut9RexFOSruFhJiZtyWLQt798KI4Ykc7WcKtmBydN8+qDHhdV5nMMWLJPL77yrYin3oPCp2pxwVu1OOit0pR8XulKOuVLSVNFm7dq27QxC5KuWo2EHhwqbHbcWK8PzZQVT87XXWrTPbFi7cRKtW8O+/8Gf517lrzSCyZXNvvCKX0nlU7E45KnanHBW7U46K3SlHXd3+c45FRERuofz5Yc4caNUK/vkH6tUzYzt3hmNZEBQE06ZBnjzujlRERERERETsSjNtRUREMljevDBrFpQqBWfPwo4dYFkOAI4fhxUr3BygiIiIiIiI2JoWIkunrLYQ2alTp8iVK5e7wxC5IuWo2FHFirBhg+uYwwGVK0NUlFtCErkinUfF7pSjYnfKUbE75ajYXVbJUS1EJhkqISHB3SGIXJVyVOxox46UY5YFW7bc+lhErkXnUbE75ajYnXJU7E45KnanHHVlq6LtkCFDqFWrFjlz5iQ4OJiOHTuy5bK/bGNiYujbty9BQUHkyJGDzp07c/jwYZd99u7dS0REBNmyZSM4OJgBAwak+MbPnTuX6tWr4+vrS6lSpRg5cuTNfnmZ2pIlS9wdgshVKUfFjsqUMTNrL+VwQNmy7olH5Gp0HhW7U46K3SlHxe6Uo2J3ylFXtirazps3j759+7J06VJmzJhBfHw8rVq14ty5c859nnnmGSZOnMjYsWOZN28eBw4coFOnTs7tiYmJREREEBcXx+LFixk1ahQjR47kjTfecO6za9cuIiIiaNq0KVFRUfTv35/evXszbdq0W/p6RUTk9jZwoJlZm1y4dTjM/YED3RuXiIiIiIiI2JuXuwO41NSpU13ujxw5kuDgYFatWkWjRo2Ijo7m+++/Z8yYMTRr1gyAESNGUL58eZYuXUrdunWZPn06GzduZObMmeTPn5+qVavy1ltv8eKLLzJo0CB8fHz4+uuvKVGiBEOHDgWgfPnyLFy4kI8//pjw8PBUY4uNjSU2NtZ5//Tp0zfpXRARkdtFp07w558weDBs3JhIaKgnAwfCXXe5OzIRERERERGxM1sVbS8XHR0NQJ48eQBYtWoV8fHxtGjRwrlPuXLlKFasGEuWLKFu3bosWbKESpUqkT9/fuc+4eHhPP7442zYsIFq1aqxZMkSl2Mk79O/f/8rxjJkyBDefPPNFONTpkwhW7ZsALRs2ZLjx4+zevVq5/awsDC8vLxYsGCBc6xy5coULlyYKVOmOMfuuOMOKlSowIwZM4iJiQEgODiYOnXqsGTJEo4dOwZAtmzZaN68OevWrWP37t3Ox0dERLB79242XLLiTePGjYmJiWHZsmXOsZo1axIYGMisWbNc3sPSpUszefJkkpKSAChatChVq1Zl7ty5nDlzBsuyWLhwIQ0aNGDlypUcPHgQAG9vb1q3bs3mzZvZtm2b85itWrXi6NGj/PPPP86xevXq4eHhwcKFC13ei0KFCrkU7EuWLEloaCjTp093Fsrz589P7dq1Wbx4McePHwcge/bsNGvWjDVr1rB3717n49u3b8+OHTvYuHGjc6xp06acO3eO5cuXO8eSW3HMnj3bOVa+fHlKlSrFpEmTSF6jr1ixYlSpUsX5XoDJyfr167NixQoOHToEgI+PD+Hh4WzatInt27c7jxkeHs7hw4eJumTVofr16wOwaNEi51jVqlXJnz+/y4zvUqVKUb58eaZNm0ZcXBwABQoUoFatWixatIgTJ04AkDNnTpo0aeLyXjgcDtq1a8f27dvZtGmT85jNmjXjzJkzrLhk+fratWuTPXt25syZ4xwLDQ2lZMmSTJw40TmW/F7Mnj3bOQM+KCiIevXqsXz5cmerEl9fX1q1asXGjRvZcUlTz9atW3PgwAHWrl3rHGvQoAFJSUksXrzYOVatWjXy5cvH9OnTnWOlS5emXLlyTJ06lfj4eAAKFixIzZo1WbhwIZZlMXHiROd7ERUVxb59+wDw8PAgIiKCbdu2sXnzZucxmzdvTnR0NCtXrnSO1alTBz8/P+bNm+ccq1ChAsWLF2fy5MnOseLFi1OpUiVmzZrF+fPnAcibNy9hYWEsW7aMI0eOAODn50fLli3ZsGEDO3fudD6+TZs27N+/3+W9aNiwIQkJCS6XhFSvXp2goCBmzJjhHCtTpgxly5ZlypQpztYvhQoVokaNGixYsIBTp04BEBgYSKNGjVi9ejX79+8HwNPTk7Zt27J161aX9jMtWrTg5MmTrFq1yjlWt25dfH19Xd6LihUrUqxYMSIjI51jJUqUoGLFisycOZMLFy4AkC9fPurWrcvSpUs5evQoAP7+/rRo0YL169eza9cu5+Pbtm3L3r17Wb9+vXOscePGxMbGsnTpUudYjRo1yJ07NzNnznSOlS1bljJlyhAZGUliYiIAhQsXpnr16syfP9/5/0iuXLlo2LAhq1at4sCBAwB4eXnRpk0btmzZwtatW53HzOhzeeHCwURF1WHOnPmcPXsWgFmz3HMuB8idO7fO5TqXp3our169utvP5SdPnnR5L3Qu17n80nO5v78/gFvO5Xb6vRx0LrfrudyyLObOnZvlfy/Xudy+5/Lkv5my6u/lOpfb/1weGBjoPNfdzr+XJ5+rrsVhJb9rNpOUlMSdd97JqVOnnAk4ZswYevXq5TLjFcyb0bRpU95//30effRR9uzZ4/JNOX/+PNmzZycyMpI2bdpQpkwZevXqxcsvv+zcJzIykoiICM6fP+/8hfBSqc20LVq06DVXertdxMTE4Ofn5+4wRK5IOSp2pxwVu1OOit0pR8XulKNid8pRsbuskqOnT58mMDDwmjVFW/W0vVTfvn1Zv349v/76q7tDAcwnlAEBAS63rOTSTxNF7Eg5KnanHBW7U46K3SlHxe6Uo2J3ylGxO+WoK1sWbZ988kkmTZrEnDlzKFKkiHO8QIECxMXFOS8xSHb48GEKFCjg3Cf5UpBLtydvu9o+AQEBqc6yFREREREREREREblVbNXT1rIs+vXrx/jx45k7dy4lSpRw2V6jRg28vb2ZNWsWnTt3BmDLli3s3buXsLAwwPQ3eeeddzhy5AjBwcGAqdQHBAQQGhrq3OfSvi/J+yQfI62xQtZZkOz8+fNZ5rVK5qQcFbtTjordKUfF7pSjYnfKUbE75ajYXVbJ0eTXeM2OtZaNPP7441ZgYKA1d+5c6+DBg87b+fPnnfs89thjVrFixazZs2dbK1eutMLCwqywsDDn9oSEBKtixYpWq1atrKioKGvq1KlWvnz5rJdfftm5z86dO61s2bJZAwYMsDZt2mR98cUXlqenpzV16tQ0x7pv3z4L0E033XTTTTfddNNNN91000033XTTTTfddLuu2759+65ae7TVQmQOhyPV8REjRtCzZ0/ANCV+7rnn+OWXX4iNjSU8PJwvv/zS2foAYM+ePTz++OPMnTuX7Nmz06NHD9577z28vC5OLJ47dy7PPPMMGzdupEiRIrz++uvO50iLpKQkDhw4QM6cOa8Y9+0iedG1ffv2ZblevpI5KEfF7pSjYnfKUbE75ajYnXJU7E45KnaXlXLUsizOnDlDoUKF8PC4cudaWxVtxZ7SuqqdiLsoR8XulKNid8pRsTvlqNidclTsTjkqdqccTcmWC5GJiIiIiIiIiIiIZFUq2oqIiIiIiIiIiIjYiIq2ck2+vr4MHDgQX19fd4cikirlqNidclTsTjkqdqccFbtTjordKUfF7pSjKamnrYiIiIiIiIiIiIiNaKatiIiIiIiIiIiIiI2oaCsiIiIiIiIiIiJiIyraioiIiIiIiIiIiNiIirYiIiIiIiIiIiIiNqKirYiIiIiIiIiIiIiNqGgrV/XFF19QvHhx/Pz8qFOnDsuXL3d3SCJO8+fPp3379hQqVAiHw8GECRPcHZKI05AhQ6hVqxY5c+YkODiYjh07smXLFneHJeL01VdfUblyZQICAggICCAsLIwpU6a4OyyRK3rvvfdwOBz079/f3aGIADBo0CAcDofLrVy5cu4OS8TF/v37eeCBBwgKCsLf359KlSqxcuVKd4cl4lS8ePEU51KHw0Hfvn3dHZrbqWgrV/Tbb7/x7LPPMnDgQFavXk2VKlUIDw/nyJEj7g5NBIBz585RpUoVvvjiC3eHIpLCvHnz6Nu3L0uXLmXGjBnEx8fTqlUrzp075+7QRAAoUqQI7733HqtWrWLlypU0a9aMDh06sGHDBneHJpLCihUr+Oabb6hcubK7QxFxUaFCBQ4ePOi8LVy40N0hiTidPHmS+vXr4+3tzZQpU9i4cSNDhw4ld+7c7g5NxGnFihUu59EZM2YAcPfdd7s5MvdzWJZluTsIsac6depQq1YtPv/8cwCSkpIoWrQo/fr146WXXnJzdCKuHA4H48ePp2PHju4ORSRVR48eJTg4mHnz5tGoUSN3hyOSqjx58vC///2Phx9+2N2hiDidPXuW6tWr8+WXX/L2229TtWpVhg0b5u6wRBg0aBATJkwgKirK3aGIpOqll15i0aJFLFiwwN2hiKRZ//79mTRpEtu2bcPhcLg7HLfSTFtJVVxcHKtWraJFixbOMQ8PD1q0aMGSJUvcGJmISOYUHR0NmKKYiN0kJiby66+/cu7cOcLCwtwdjoiLvn37EhER4fJ7qYhdbNu2jUKFCnHHHXfQrVs39u7d6+6QRJz+/vtvatasyd13301wcDDVqlXju+++c3dYIlcUFxfHTz/9xEMPPZTlC7agoq1cwbFjx0hMTCR//vwu4/nz5+fQoUNuikpEJHNKSkqif//+1K9fn4oVK7o7HBGndevWkSNHDnx9fXnssccYP348oaGh7g5LxOnXX39l9erVDBkyxN2hiKRQp04dRo4cydSpU/nqq6/YtWsXDRs25MyZM+4OTQSAnTt38tVXX1G6dGmmTZvG448/zlNPPcWoUaPcHZpIqiZMmMCpU6fo2bOnu0OxBS93ByAiInK769u3L+vXr1efO7GdsmXLEhUVRXR0NH/88Qc9evRg3rx5KtyKLezbt4+nn36aGTNm4Ofn5+5wRFJo06aN8+vKlStTp04dQkJC+P3339VmRmwhKSmJmjVr8u677wJQrVo11q9fz9dff02PHj3cHJ1ISt9//z1t2rShUKFC7g7FFjTTVlKVN29ePD09OXz4sMv44cOHKVCggJuiEhHJfJ588kkmTZrEnDlzKFKkiLvDEXHh4+NDqVKlqFGjBkOGDKFKlSp88skn7g5LBIBVq1Zx5MgRqlevjpeXF15eXsybN49PP/0ULy8vEhMT3R2iiItcuXJRpkwZtm/f7u5QRAAoWLBgig9iy5cvrzYeYkt79uxh5syZ9O7d292h2IaKtpIqHx8fatSowaxZs5xjSUlJzJo1S73uRETSwLIsnnzyScaPH8/s2bMpUaKEu0MSuaakpCRiY2PdHYYIAM2bN2fdunVERUU5bzVr1qRbt25ERUXh6enp7hBFXJw9e5YdO3ZQsGBBd4ciAkD9+vXZsmWLy9jWrVsJCQlxU0QiVzZixAiCg4OJiIhwdyi2ofYIckXPPvssPXr0oGbNmtSuXZthw4Zx7tw5evXq5e7QRADzi/GlMxl27dpFVFQUefLkoVixYm6MTMS0RBgzZgx//fUXOXPmdPYDDwwMxN/f383RicDLL79MmzZtKFasGGfOnGHMmDHMnTuXadOmuTs0EQBy5syZog949uzZCQoKUn9wsYXnn3+e9u3bExISwoEDBxg4cCCenp7cf//97g5NBIBnnnmGevXq8e6773LPPfewfPlyvv32W7799lt3hybiIikpiREjRtCjRw+8vFSqTKZ3Qq7o3nvv5ejRo7zxxhscOnSIqlWrMnXq1BSLk4m4y8qVK2natKnz/rPPPgtAjx49GDlypJuiEjG++uorAJo0aeIyPmLECDXWF1s4cuQIDz74IAcPHiQwMJDKlSszbdo0WrZs6e7QREQyhX///Zf777+f48ePky9fPho0aMDSpUvJly+fu0MTAaBWrVqMHz+el19+mcGDB1OiRAmGDRtGt27d3B2aiIuZM2eyd+9eHnroIXeHYisOy7IsdwchIiIiIiIiIiIiIoZ62oqIiIiIiIiIiIjYiIq2IiIiIiIiIiIiIjaioq2IiIiIiIiIiIiIjahoKyIiIiIiIiIiImIjKtqKiIiIiIiIiIiI2IiKtiIiIiIiIiIiIiI2oqKtiIiIiIiIiIiIiI2oaCsiIiIikg4Oh4NBgwa5O4yr6tmzJ8WLF3d3GCIiIiJynVS0FRERERG3WbduHV26dCEkJAQ/Pz8KFy5My5Yt+eyzz9wd2i1XvHhx2rVr5+4wRERERMQGVLQVEREREbdYvHgxNWvWZM2aNTzyyCN8/vnn9O7dGw8PDz755BN3hyciIiIi4jZe7g5ARERERLKmd955h8DAQFasWEGuXLlcth05csQ9QYmIiIiI2IBm2oqIiIiIW+zYsYMKFSqkKNgCBAcHu9wfMWIEzZo1Izg4GF9fX0JDQ/nqq69SPC65xcDcuXOpWbMm/v7+VKpUiblz5wIwbtw4KlWqhJ+fHzVq1OCff/5xeXzPnj3JkSMHO3fuJDw8nOzZs1OoUCEGDx6MZVnXfE379+/noYceIn/+/Pj6+lKhQgV++OGHtL8pl9i9ezcOh4MPP/yQb7/9lpIlS+Lr60utWrVYsWJFiv0nTJhAxYoV8fPzo2LFiowfPz7V4yYlJTFs2DAqVKiAn58f+fPnp0+fPpw8edK5z8CBA/Hw8GDWrFkuj3300Ufx8fFhzZo16XpNIiIiIpI2mmkrIiIiIm4REhLCkiVLWL9+PRUrVrzqvl999RUVKlTgzjvvxMvLi4kTJ/LEE0+QlJRE3759Xfbdvn07Xbt2pU+fPjzwwAN8+OGHtG/fnq+//ppXXnmFJ554AoAhQ4Zwzz33sGXLFjw8Ls5lSExMpHXr1tStW5cPPviAqVOnMnDgQBISEhg8ePAVYzx8+DB169bF4XDw5JNPki9fPqZMmcLDDz/M6dOn6d+/f7repzFjxnDmzBn69OmDw+Hggw8+oFOnTuzcuRNvb28Apk+fTufOnQkNDWXIkCEcP36cXr16UaRIkRTH69OnDyNHjqRXr1489dRT7Nq1i88//5x//vmHRYsW4e3tzWuvvcbEiRN5+OGHWbduHTlz5mTatGl89913vPXWW1SpUiVdr0VERERE0sgSEREREXGD6dOnW56enpanp6cVFhZmvfDCC9a0adOsuLi4FPueP38+xVh4eLh1xx13uIyFhIRYgLV48WLn2LRp0yzA8vf3t/bs2eMc/+abbyzAmjNnjnOsR48eFmD169fPOZaUlGRFRERYPj4+1tGjR53jgDVw4EDn/YcfftgqWLCgdezYMZeY7rvvPiswMDDV13B57BEREc77u3btsgArKCjIOnHihHP8r7/+sgBr4sSJzrGqVataBQsWtE6dOuUcmz59ugVYISEhzrEFCxZYgPXzzz+7PPfUqVNTjK9bt87y8fGxevfubZ08edIqXLiwVbNmTSs+Pv6qr0NEREREbpzaI4iIiIiIW7Rs2ZIlS5Zw5513smbNGj744APCw8MpXLgwf//9t8u+/v7+zq+jo6M5duwYjRs3ZufOnURHR7vsGxoaSlhYmPN+nTp1AGjWrBnFihVLMb5z584UsT355JPOr5NnzsbFxTFz5sxUX4tlWfz555+0b98ey7I4duyY8xYeHk50dDSrV69O61vj4t577yV37tzO+w0bNnSJ++DBg0RFRdGjRw8CAwOd+7Vs2ZLQ0FCXY40dO5bAwEBatmzpEmONGjXIkSMHc+bMce5bsWJF3nzzTYYPH054eDjHjh1j1KhReHnpYj0RERGRm02/cYmIiIiI29SqVYtx48YRFxfHmjVrGD9+PB9//DFdunQhKirKWXRctGgRAwcOZMmSJZw/f97lGNHR0S7FyksLs4BzW9GiRVMdv7SXK4CHhwd33HGHy1iZMmUA02c2NUePHuXUqVN8++23fPvtt6nuk97F1S5/PckF3OS49+zZA0Dp0qVTPLZs2bIuxeJt27YRHR2domfwlWIcMGAAv/76K8uXL+fdd99NUQQWERERkZtDRVsRERERcTsfHx9q1apFrVq1KFOmDL169WLs2LEMHDiQHTt20Lx5c8qVK8dHH31E0aJF8fHxITIyko8//pikpCSXY3l6eqb6HFcat9KwwNi1JMfwwAMP0KNHj1T3qVy5crqOnZFxJyUlERwczM8//5zq9nz58rnc37lzJ9u2bQNg3bp11/18IiIiIpI+KtqKiIiIiK3UrFkTMJf9A0ycOJHY2Fj+/vtvl1mnl17Kn5GSkpLYuXOnc3YtwNatWwEoXrx4qo/Jly8fOXPmJDExkRYtWtyUuK4kJCQEwFlcvdSWLVtc7pcsWZKZM2dSv359l5YTqUlKSqJnz54EBATQv39/3n33Xbp06UKnTp0yLngRERERSZV62oqIiIiIW8yZMyfV2aKRkZGAubQfLs40vXTf6OhoRowYcdNi+/zzz51fW5bF559/jre3N82bN091f09PTzp37syff/7J+vXrU2w/evToTYu1YMGCVK1alVGjRrn0950xYwYbN2502feee+4hMTGRt956K8VxEhISOHXqlPP+Rx99xOLFi/n222956623qFevHo8//jjHjh27aa9FRERERAzNtBURERERt+jXrx/nz5/nrrvuoly5csTFxbF48WJ+++03ihcvTq9evQBo1aoVPj4+tG/fnj59+nD27Fm+++47goODnbNxM5Kfnx9Tp06lR48e1KlThylTpjB58mReeeWVFO0DLvXee+8xZ84c6tSpwyOPPEJoaCgnTpxg9erVzJw5kxMnTmR4rMmGDBlCREQEDRo04KGHHuLEiRN89tlnVKhQgbNnzzr3a9y4MX369GHIkCFERUXRqlUrvL292bZtG2PHjuWTTz6hS5cubNq0iddff52ePXvSvn17AEaOHEnVqlV54okn+P3332/aaxERERERzbQVERERETf58MMPadq0KZGRkTz77LM8++yzLF++nCeeeIJly5aRK1cuwMy4/eOPP3A4HDz//PN8/fXXPProozz99NM3JS5PT0+mTp3KoUOHGDBgACtWrGDgwIGpzk69VP78+Vm+fDm9evVi3LhxPPnkk3zyySecOHGC999//6bEmqx169aMHTuWxMREXn75ZcaNG8eIESOcrSYu9fXXX/Ptt99y5MgRXnnlFV5++WVmz57NAw88QP369UlMTKRHjx7kzZuXYcOGOR9XunRphgwZwtixY1W0FREREbnJHFZGrLwgIiIiInIb6NmzJ3/88YfL7FQRERERkVtNM21FREREREREREREbERFWxEREREREREREREbUdFWRERERERERERExEbU01ZERERERERERETERjTTVkRERERERERERMRGVLQVERERERERERERsREVbUVERERERERERERsREVbERERERERERERERtR0VZERERERERERETERlS0FREREREREREREbERFW1FREREREREREREbERFWxEREREREREREREbUdFWRERERERERERExEZUtBURERERERERERGxERVtRURERERERERERGxERVsRERERERERERERG1HRVkRERERERERERMRGVLQVERERERERERERsREVbUVERERERERERERsREVbEREREZto0qQJDofD3WGkyuFw0KRJk1v2fHZ+LyRz2r17Nw6Hg549e7qMZ6ZcK168OMWLF3d3GCIiInILqGgrIiIiIpnCyJEjcTgcjBw58pY9Z8+ePXE4HGm+3crY7Cq5OHrpzcfHh6JFi9K1a1fWrl3r7hAzVHKO7N69292hiIiIyG3Ey90BiIiIiIhc7scff+T8+fPuDoOOHTummNk4d+5c5s2bR4cOHahatarLtsvvZ2UlS5bkgQceAODs2bMsXbqUX375hXHjxjFr1izq16/v5ggNu+SaiIiIyKVUtBURERER2ylWrJi7QwBM0bZjx44uY4MGDWLevHl07NgxxaX2clGpUqUYNGiQy9hrr73GO++8w6uvvsrcuXPdEtfl7JJrIiIiIpdSewQRERHJsubPn0/Hjh3Jnz8/vr6+FC1alE6dOrFw4ULnPgcOHGDgwIHUrVuX4OBgfH19KV68OE888QRHjhxJcczkS6V37tzJ0KFDCQ0NxdfX16W4t3DhQho3bkz27NkJCgri3nvvZd++fel+HQ8//DAOh4P58+enuv2jjz7C4XDw3XffuYyvXbuW++67j4IFC+Lj40NISAj9+vXj+PHjaX7uY8eO0b9/f0qUKIGvry/BwcHcc889rF+/PtX94+Li+Pjjj6lVqxY5c+YkR44chIaG8uyzz3Ly5Ennfpf3Ge3Zsye9evUCoFevXi6X3gM0aNAALy8vDh48mOrzPvjggzgcDpYsWZLm13a9kmOOiYnhtddeo2TJknh7ezsLl1frnXq1S+z/+usvmjdvTu7cufHz86NixYp8+OGHJCYmXjOmPXv24OHhQbNmzVLdHh8fT968eSlatChJSUkAREdH88YbbxAaGkqOHDkICAigVKlS9OjRgz179qTtzbiCfv36AbBixQrnWHK/5P379/Pggw9SoEABPDw8XIq68+fPp3379uTNmxdfX19Kly7Na6+9luoM2cTERN5//31KlSqFn58fpUqVYsiQIc7Xd7mrfV/++usvWrVqRVBQEH5+fhQvXpzu3bs787t48eKMGjUKgBIlSjhz8vL+z7t27aJ3794UK1YMX19fChYsSM+ePa/4fv7111/UqlULf39/8ufPzyOPPOLy8yEiIiK3P820FRERkSzpk08+4ZlnnsHf35+77rqLYsWKsX//fhYuXMgff/xBgwYNAFMsGjp0KM2bN6dOnTp4e3vzzz//8NVXXzFt2jRWr15NYGBgiuP369ePpUuXEhERQfv27QkODgZg1qxZtGnTBg8PD+69914KFSrkvFQ8d+7c6Xot3bt354cffuCnn36iUaNGKbaPHj0aX19f7r77bufY33//zT333IOHhwcdOnSgaNGibNy4kc8//5xp06axbNmya8Zz9OhRwsLC2LFjB02aNOG+++5j165d/PHHH0yePJlp06Y530eACxcu0LJlSxYtWkTp0qXp1asXvr6+bNu2jW+++YYHH3zwis/ZsWNHTp06xV9//ZVqW4I+ffqwaNEiRowYwSuvvOKy7dSpU/zxxx9UqFCBsLAwdu/eTYkSJQgJCbkpfUg7d+7MmjVraN26Nbly5aJEiRLpPtbLL7/Me++9R+HChenUqROBgYEsWLCAAQMGsGzZMsaOHXvVx4eEhNCoUSPmzZvHv//+S5EiRVy2R0ZGcvz4cV588UU8PDywLIvw8HCWLVtG/fr1ad26NR4eHuzZs4e///6b7t27ExISku7Xk+zyIunx48cJCwsjT5483HfffcTExBAQEADAV199Rd++fcmVK5fzZ2nlypW88847zJkzhzlz5uDj4+M81qOPPsoPP/xAiRIl6Nu3LzExMXz00UcsXrz4umJ87rnn+Oijj8iTJw8dO3YkODiYffv2MXPmTGrUqEHFihXp378/I0eOZM2aNTz99NPkypULwKWlxrJlywgPD+fcuXO0a9eO0qVLs3v3bn7++WemTJnCkiVLuOOOO5z7//jjj/To0YOAgAC6d+9Orly5mDRpEi1atCAuLs7ltYqIiMhtzBIRERHJYqKioiwPDw+rUKFC1q5du1y2JSUlWfv373feP3z4sHXmzJkUxxg1apQFWG+//bbLeI8ePSzAKlKkiLVnzx6XbYmJidYdd9xhORwOa8GCBS7P2bVrVwuw0vPrWVJSklWsWDErd+7cVkxMjMu2devWWYDVpUsX59ixY8esgIAAq3Dhwtbu3btd9v/ll18swHryySddxgGrcePGLmO9evWyAOvll192GZ88ebIFWKVKlbISExOd488995wFWN27d7cSEhJcHnPq1CmX97lx48Yp3osRI0ZYgDVixIgU78GFCxesPHnyWHfccYeVlJTksu3zzz+3AGvYsGGWZVnWrl27LMAKCQlJcZy0GDhwYKpxJMdctWpV6/jx4ykel9prSpacN5fm4/Tp0y3ACg8Pt86ePescT0pKsh577DELsP74449rxjt8+HALsN5///0U2zp37mwB1vr16y3Lsqy1a9dagNWxY8cU+8bExKT6s3C55Pc3PDw8xbY33njDAqymTZs6x5LzvlevXinyYsOGDZaXl5dVpUoV69ixYy7bhgwZYgHWhx9+6BybM2eOBVhVqlRxec/+/fdfK2/evBZg9ejRw+U4qX1fJk6caAFWpUqVUjxvfHy8dejQIef91L53yeLi4qzixYtbOXPmtFavXu2ybcGCBZanp6fVrl0751h0dLQVEBBgZc+e3dqyZYvLcRo1anRDeSsiIiKZi9ojiIiISJbzzTffkJSUxNtvv51ikSmHw0GhQoWc94ODg8mRI0eKY3Tv3p2AgABmzpyZ6nMMGDAgRa/MhQsXsnPnTtq1a+cyA9XhcPDuu+/i6emZrtfjcDjo1q0bJ0+eZPLkyS7bRo8eDeBcEArMTL7Tp08zZMiQFLMm77vvPqpXr86vv/561eeMi4vjl19+ISgoiNdee81lW9u2bWnZsiXbt29n0aJFACQkJPDtt98SGBjIJ598kuK1BgYGpvo+p5Wfnx89evRg586dzJ4922Xb999/j6+vL927dwegcOHCbNq0iVmzZqX7+a7mzTffJE+ePDd8nM8//xyAb7/9luzZszvHHQ4H7733Hg6Hg19++eWax+nSpQt+fn789NNPLuOnTp1i0qRJVK1alQoVKrhs8/f3T3EcX1/f6/oebd++nUGDBjFo0CAGDBhAo0aNGDx4MH5+frzzzjsu+/r4+PDBBx+kyItvvvmGhIQEPvvsM4KCgly2vfDCC+TLl8/lPfjxxx8BeOONN1zes8KFC/P000+nOfYvv/wSMDPyL39eLy8v8ufPn6bjTJo0id27dzNgwACqVavmsq1BgwZ06NCByMhITp8+DcCECRM4ffo0Dz30EGXKlHHu6+3tneI9ExERkdub2iOIiIhIlrN8+XIAWrVqlab9x40bxzfffMPq1as5efKkSy/RAwcOpPqY2rVrpxhbs2YNAA0bNkyxLSQkhKJFi6b7cv3u3bszZMgQRo8eTadOnQBISkpizJgxBAUF0bZtW+e+S5cuBcxl2zt27EhxrJiYGI4dO8axY8fImzdvqs+3efNmYmJiaNq0KdmyZUuxvWnTpsyYMYOoqCgaNmzI5s2bOXPmDC1atEh3G4hrefTRR/n444/57rvvaN68OQCrVq3in3/+oWvXrs5Cqre3N+XKlbspMUDq3/v0WLp0KdmzZ+eHH35Idbu/vz+bN2++5nECAwO58847+f3331mzZg1VqlQBYOzYscTGxjqL2QDly5encuXK/PLLL/z777907NiRJk2aULVqVTw8rm++x44dO3jzzTcB857nz5+frl278tJLL1GpUiWXfUuUKJFqriXn6rRp01Itsnt7e7u8B1f7GUtt7EqWL1+Or68vjRs3TvNjUpMc/5YtW1IsygZw6NAhkpKS2Lp1KzVr1rxq/GFhYXh56c83ERGRrEL/64uIiEiWEx0djcPhoGDBgtfcd+jQoTz//PPky5ePVq1aUaRIEecsxGHDhhEbG5vq41KbiRcdHQ3g7G+b2mPSW7QtX748NWrUIDIykpMnT5I7d27mzp3Lv//+yxNPPIG3t7dz3xMnTgDwxRdfXPWY586du2LRNnlm4JVmHCa/t8n7Jb/2woULX8eruj7lypWjcePGTJgwgePHjxMUFMTw4cMBeOSRR27a814urbMwr+XEiRMkJCQ4C5+pOXfuXJqO1b17d37//Xd++uknZ9F29OjReHp60rVrV+d+Xl5ezJ49m0GDBvHnn3/y3HPPAZAvXz6efPJJXn311TTPCA8PD2fq1Klp2vdK71lyrqZ1lml0dDQeHh6p5u31fF+io6MpXLjwdReqL5cc/88//3zV/ZK/j1c7R3h6eqaY9SsiIiK3L7VHEBERkSwnV65cWJbFwYMHr7pfQkICb731FgULFmT9+vX8/PPPvP/++wwaNIiBAwcSFxd3xcemthp98oJlR44cSfUxhw8fvo5XkVL37t2Ji4vj999/By62Rrh0JiXgXOBp3bp1WJZ1xdvVFpxKPsaVYj506JDLfskLNO3fvz+dry5tHnvsMWJjY/nxxx85f/48v/zyC6VLl6ZJkyY39Xkvldr3HnAWABMSElJsSy7WXSogIICgoKCrfo927dqVpphat27tbCWQlJTE7t27WbhwIS1atKBAgQIu+wYFBfHZZ5+xf/9+5+J0efLkYeDAgXzwwQdper7rdaX3LDl/Tp8+fdX3IVlgYCBJSUkcO3YsxbGu5+crV65czlmwNyI5/okTJ141/uQZvVc7RyQmJnL8+PEbikdEREQyDxVtRUREJMtJvnx9+vTpV93v2LFjREdHExYWlmLm28qVK7lw4cJ1PW/yDMcFCxak2LZnzx727dt3Xce73P3334+Xlxc//fQTFy5cYNy4cZQqVYq6deu67FenTh0AlixZku7nKleuHH5+fqxYsYLz58+n2D537lwAqlatCkDZsmUJCAhgxYoVnDx5Ml3PmTzD89L2FJfr1KkT+fLlY/jw4YwdO5bo6Gh69+6drufLaMltIS4vXCclJTkvi79UnTp1OH78ONu2bbvh5/by8uK+++5j//79zJkzh59//hnLslx6HV/O4XBQvnx5+vbty4wZMwD4+++/bziW65Gcq8ltBq7laj9jqY1dSe3atYmNjWXevHnX3PdqeXm9P2tXi3/JkiWpFvxFRETk9qSirYiIiGQ5jz32GJ6enrz22mvs2bPHZZtlWc4+tcHBwfj7+7N69WqXwuTJkyfp16/fdT9vgwYNKFGiBJMmTWLhwoUuz/nKK69ctRiZFsHBwbRq1YpFixYxbNgwTp8+nWpRrlevXuTMmZNXX32VDRs2pNh+/vz5axbJfHx8uP/++zl27BhDhgxx2TZ16lSmTZtGqVKlqF+/PmCKhn369CE6Opqnn346xWuNjo7m7NmzV33O5J60Vytu+/j40LNnTzZu3Mgrr7yCt7c3PXv2dNknPj6ezZs3p9rP92aqVasWACNHjnQZ/+ijj1KdMfvUU08B8NBDD6U6w/LQoUNs2rQpzc+fPON69OjRjB49muzZs3PXXXe57LN79+5UW3Qkz1L18/NL8/NlhCeeeAIvLy/69evH3r17U2w/deoU//zzj/N+8mscPHiwS+uI/fv388knn6T5efv27QvA008/7WxxkCwhIcFl1u7V8rJDhw4UK1aMjz76iPnz56fYHh8f73Iu6NChAwEBAfzwww9s3brVZb/LF/wTERGR25t62oqIiEiWU6lSJYYNG8ZTTz1FhQoV6NixIyEhIRw6dIj58+cTERHBsGHD8PDw4IknnmDo0KFUqVKF9u3bc/r0aaZMmUJISAiFChW6ruf18PDg22+/pW3btrRo0YJ7772XQoUKMXv2bA4ePEjlypVZu3btDb227t27ExkZycCBAwFSLdomXyZ/9913U6VKFVq3bk25cuWIjY1l9+7dzJs3j3r16l2zH+n777/PvHnzePvtt1m8eDF16tRh9+7djB07lmzZsjFixAiXnqCDBw9m6dKljB49mqVLl9KmTRt8fX3ZuXMnU6dOZeHChc6ZuakJCwvD39+fYcOGcfLkSfLlyweQopjVp08fPvzwQw4cOEDnzp1TzJLev38/5cuXJyQkJN09hNOjV69efPDBBwwaNIioqChKlizJypUrWb9+PY0bN04xq7N169a8/vrrvPXWW5QqVYrWrVsTEhLC8ePH2b59OwsWLODtt9+mfPnyaXr+WrVqUbZsWcaMGUN8fDzdu3cne/bsLvtERUXRqVMnateuTWhoKAUKFGD//v1MmDABDw8PnnnmmQx7P9KiYsWKfPnllzz++OOULVuWtm3bUrJkSc6cOcPOnTuZN28ePXv25OuvvwbMAni9evVixIgRVKpUibvuuovY2Fh+++036taty6RJk9L0vG3btuX555/nww8/pHTp0tx1110EBwezf/9+Zs2axfPPP0///v0BaNasGR9++CGPPvoonTt3Jnv27ISEhNC9e3d8fX35448/aNOmDY0bN6ZZs2ZUqlQJh8PBnj17WLBgAUFBQc7F1AIDA/n000/p2bMntWrV4r777iMwMJBJkybh7++fpj7cIiIicpuwRERERLKoOXPmWO3atbPy5Mlj+fj4WEWKFLE6d+5sLVq0yLlPXFyc9c4771ilS5e2fH19rWLFilnPPfecdebMGSskJMQKCQlxOWaPHj0swNq1a9cVn3f+/PlWo0aNLH9/fytPnjzW3Xffbe3Zs8dq3LixdaO/np0/f94KCAiwACssLOyq+27evNl6+OGHrZCQEMvHx8fKnTu3ValSJeupp56yli9f7rIvYDVu3DjFMY4ePWo99dRTVkhIiOXt7W3lzZvX6tKli7Vu3bpUnzMmJsb68MMPrapVq1r+/v5Wjhw5rNDQUOu5556zTp486dzvSu/F5MmTrVq1aln+/v4WcMX3q0GDBhZgTZ06NcW2Xbt2WUCK711aDRw40AKsESNGuIyn5fsXFRVlNW/e3MqWLZsVEBBgdejQwdq2bdtV82bGjBlW+/btrXz58lne3t5WgQIFrLCwMOutt96y9u7de12xv/322873bdq0aSm279u3z3rppZesunXrWsHBwZaPj49VrFgxq1OnTtaSJUvS9BzJ7294eHia9r9Sbl1q+fLl1n333WcVKlTImWfVq1e3XnrpJWvTpk0u+yYkJFhDhgyx7rjjDsvHx8e64447rHfffdfavn27BVg9evRw2f9q37c///zTatq0qRUYGGj5+vpaxYsXt7p3726tX7/eZb8PPvjAKl26tOXt7Z3q6/n333+tp59+2nkeCQgIsMqXL2/17t3bmjVrVornHT9+vFWjRg3L19fXCg4Otnr37m2dOHEi1XOOiIiI3J4clnVJ534RERERkUwuJiaGIkWKkCNHDnbu3Oky21dEREREJDPQb7AiIiIiclsZMWIEx48fp0+fPirYioiIiEimpJm2IiIiInJbeO+99zh69CjffPMN2bNnZ+vWrQQGBro7LBERERGR66airYiIiIgNRUVFMWHChGvuV7x4cXr27HnT48kMHA4H3t7eVKlShc8++4y6deu6OyQRERERkXRR0VZERETEhkaOHEmvXr2uuV/jxo2ZO3fuzQ9IRERERERuGRVtRURERERERERERGzEy90BZFZJSUkcOHCAnDlz4nA43B2OiIiIiIiIiIiI2JxlWZw5c4ZChQpdddFcFW3T6cCBAxQtWtTdYYiIiIiIiIiIiEgms2/fPooUKXLF7SraplPOnDkB8wYHBAS4OZqbb8qUKbRp08bdYYhckXJU7E45KnanHBW7U46K3SlHxe6Uo2J3WSVHT58+TdGiRZ21xStRT9t0On36NIGBgURHR2eJou3x48cJCgpydxgiV6QcFbtTjordKUfF7pSjYnfKUbE75ajYXVbJ0bTWFK/cOEHkElfrsSFiB8pRsTvlqNidclTsTjkqdqccFbtTjordKUdd6d2QNFm4cKG7QxC5KuWo2J1yVOxOOSp2pxwVu1OOit0pR8XulKOuVLQVERERERERERERsREVbUVERERERERERERsxMvdAYi9jRsHb74JW7a0o2xZGDgQOnVyd1QiKVWuXNndIYhclXJU7E45KnanHBW7U46K3SlHM1ZiYiLx8fHuDuO2EhoaSkxMjLvDSDdPT0+8vb0z7HgOy7KsDDtaFpLWld4ys3HjoHPni/cdDrAs+PNPFW7FfuLj4zP05CiS0ZSjYnfKUbE75ajYnXJU7E45mjEsy+LQoUNER0ejklrGsiwLh8Ph7jBuiK+vL3nz5r1qrTCtNUXNtJUrevNN1/uWZQq3gweraCv2M3XqVNq3b+/uMESuSDkqdqccFbtTjordKUfF7pSjGSM6OppTp06RL18+smfPnumLjHZy+vTpTDsx0rIs4uPjiY6OZv/+/QA3/FpUtJUr2ro15ZhlwZYttz4WERERERERERF3siyLI0eOEBAQQN68ed0dzm0nJiYGPz8/d4eRbv7+/uTMmZN///2XY8eO3XDRVguRyRWVKWNm1l4uRw5ITLz18YiIiIiIiIiIuEtiYiKJiYmZdjao3HwOh4PAwEBiY2NvuOexirZyRQMHXmyJABf/PXYM7roLzp1zX2wilytZsqS7QxC5KuWo2J1yVOxOOSp2pxwVu1OO3riEhAQAvLx04frN4Ovr6+4QMkRy7+jEG5zxqKKtXFGnTmbRscqVwc/P/Pv88+Dry//Zu++4qK70j+OfoRcRFQF7Q0Sxxoa995Leza6mbEwxZbObTXaTqDHFbLK/XbMxdbOJ2fRNNs3eNfaOsVcssYuKCALCzO+P48wwFEUF5gLf9+s1L2bO3LlzGB+Od5577nOYOhV69oSjR73dSxEjPj7e210QuSTFqFidYlSsTjEqVqcYFatTjBYf1bEtGcHBwd7uQrEorvhQ0lYu6eabITERfvxxDomJ8MYbsGABRETAunWQkABbtni7lyIwZ84cb3dB5JIUo2J1ilGxOsWoWJ1iVKxOMSpWl5KS4u0uWIqStlIkmZmZrvtdusDKlRAbCwcOmMfz5nmxcyJ4xqiIFSlGxeoUo2J1ilGxOsWoWJ1iVKzO4XB4uwuWoqStXJXGjWHFCujWDc6ehcGD4eOPvd0rERERERERERGRsq9CJm3Hjx+PzWbzuDVt2tTb3bK06OjofG0RETB3Ltx1F2Rnw333wQsvmMXLREpbQTEqYiWKUbE6xahYnWJUrE4xKlanGJXC5M2RFXZbtGhRifbDuYCXGBV2ubvmzZszL9c1/Vr579I6duxYYHtQEHz2GTRqBK+8Ai+/DHv3wkcfmQXLREpLYTEqYhWKUbE6xahYnWJUrE4xKlanGJXCfPrppx6P//Of/zB37tx87c2aNSvRfoSGhpbo/suaCpup9PPzo0aNGkXePjMz06P+y9mzZ0uiW5a1fPlyunTpUuBzPj4mWduoEYweDV98AQcPwvffm9m4IqXhUjEqYgWKUbE6xahYnWJUrE4xKlanGJXC3HPPPR6PV65cydy5c/O155Wenk5ISEix9ePcuXNUqlSp2PZX1lXYpO2uXbuoVasWQUFBdO7cmYkTJ1KvXr1Ct584cSIvvvhivvaZM2e6ArR///4kJyezfv161/OdO3fGz8+PJUuWuNpatWpF7dq1mTlzpqutUaNGNG/enLlz55KRkQFAVFQUCQkJrFixgpMnTwIQEhJC37592bRpE/v27XO9fujQoezbt48tW7a42nr27ElGRgarVq1ytbVv357w8HDmz5/vamvatCmxsbFMnz4du90OQN26dWnTpg2LFi0iNTUVu93O0qVL6datG2vXruXIkSOAmbo+aNAgtm/fTmTkLsaOrc5rr7VnyRJ/Ona8wDPP/EzNmukAdOnSBR8fH5YuXerxWdSqVYtZs2a52mJiYoiPj2fOnDmuRHl0dDQdO3Zk+fLlJCcnA+YMTJ8+fdi4cSMHDhxwvX748OHs2bOHrVu3utp69+5NWloaq1evdrV16NCBsLAwFixY4Gpr1qwZjRs3Ztq0aa4C2PXq1aN169auzwKgWrVqdO3alTVr1nD06FEAAgICGDhwINu2bWP37t2ufQ4cOJBjx46RmJjoauvatSsAy5Ytc7W1adOG6OhoZs+e7Wpr3LgxzZo1Y/bs2WRlZQFQo0YNOnTowLJlyzh16hQAYWFh9OrVy+OzsNlsDBs2jN27d7Nt2zbXPvv06UNqaipr1qxxtXXs2JHQ0FAWLlzoaouPjycmJoapU6e62pyfxYIFC0hLSwMgIiKCLl26sHr1ao4dOwZAYGAgAwYMYOvWrezZs8f1+kGDBnH48GF++eUXV1u3bt2w2+0sX77c1XbdddcRGRnpsbppbGwsTZs2ZdasWVy4cAGAmjVr0r59e5YuXUpycjJTp051fRaJiYkcPHgQAB8fH4YOHcquXbvYvn27a599+/YlJSWFtWvXutoSEhIICgpi8eLFrrbmzZvToEEDpk+f7mpr0KABLVu2ZP78+aSnmxivXr06nTt3ZtWqVRw/fhyAoKAg+vfvz5YtW9i7d6/r9YMHD+bQoUMen0X37t3Jzs5mxYoVrra2bdsSERHB3LlzXW1NmjQhLi6OmTNnkp2dDUCtWrVo164dS5Ys4cyZMwCEh4fTo0cP1q9fz6FDhwDw9fVlyJAh7Ny5kx07drj22a9fP06fPs26detcbZ06dSIwMNDjs2jRogX16tVjxowZrraGDRvSokUL5s2bx/nz5wGIjIykU6dOrFy5khMnTgAQHBxMv3792Lx5M0lJSa7XDxkyhAMHDrB582ZXW8+ePcnMzGTlypWutnbt2lG1alWPqyTi4uJo0qQJM2bMICcnB4DatWvTtm1bfv75Z9fqo1WqVKF79+6sW7eOw4cPA+bk3eDBg9mxYwc7d+507bOkxvITJ064/p68NZYDVK1a9ZJj+a5du1z7HDBgACdOnGDDhg2uNo3lia628jaWJycne30sP336tMdnobFcY3nusdw5tnlzLLfCcTloLLfqWG6321m0aFGFPy7XWG7tsXzq1KkV/rj8Wsby1NRU0tPTOXv2LBkZGYSEhODr6+sak8DEWlBQkOvfH8y4FBISQmpqquvz8fX1JSwsjLS0NL77Dv761yB27/YhLs7Gs89mMnjwedfrK1euTHZ2tivGAVdy89y5c6624OBg/P39PSYaBgYGEhwcTEpKims89ff3JzQ0lHPnzrli18fHh8qVK5Oenu4a88+cOUOVKlXIyMigX79+JCcn8+677/LCCy+wbt06Ro4cycSJE6latSrPP/8848eP9/gsWrduTe/evZk0aZKrLT09nddff51vv/2WEydOULt2bUaNGsXzzz9Pdna263Oz2WyEh4dz/vx5j0mURf0sQkJC8PPzu6rPwvlvk56e7hrzAddn4YwpMGOd3W53jcXO19vtdhYuXOjaZ+6xPHffL8XmqIBLs82cOZNz584RFxfHkSNHePHFFzl06BCbN28mLCyswNcUNNO2bt26pKSkULly5dLqutdMnTqV4cOHF2nbzZthyBAz27Z6dfjpJ+jcuYQ7KBXelcSoiDcoRsXqFKNidYpRsTrFqFidYvTaZWRkkJSURMOGDQkKCgLMuj5FzMEV6McfYcQIsNnMvpw/P/8cbrjh6vYZEmL2c7XGjBnD22+/Te6UYa9evdixYwc5OTnceeedtGjRgujoaG644QZsNhvjxo1j/PjxHvtp0KABvXr1YsqUKYBJ2Hbu3JlDhw4xevRo6tWrx/Lly/n00095/PHHGT9+PFWqVLn6jltEQXGS29mzZwkPD79sTrFCzrQdPHiw636rVq1ISEigfv36/Pe//+X+++8v8DWBgYEEVuAirVdSV6RFC1i1CoYNg/XroXdv+PRTuO22EuygVHiqfSNWpxgVq1OMitUpRsXqFKNidYrRkpGeDsVxRb8zP+r8OWLE1e/r3DkoiX/uo0eP8t577zF69Oirev3f//539uzZw4YNG4iNjQVg9OjR1KpVizfeeIMHH3ywXCRti4uPtztgBVWqVKFJkyYel86Ipz59+lzR9jVrwuLFMHw4ZGbC7bfD66+7Bx+R4nalMSpS2hSjYnWKUbE6xahYnWJUrE4xKtcqMDCQe++996pf/80339C9e3eqVq3KyZMnXbd+/fqRk5PjUcpHlLQFTM2LPXv2ULNmTW93xbI2btx4xa+pVMksRvbYY+bxM8/AI4/AxXIeIsXqamJUpDQpRsXqFKNidYpRsTrFqFidYrRkhISYma1Xe2vRIn8pA5sNWra8+n0W49pgHmrXrk1AQMBVv37Xrl3MmjWLyMhIj1u/fv0A+PXXX4urq+VChSyP8Mc//pHhw4dTv359Dh8+zLhx4/D19eWuu+7ydtcs68CBA7Ru3fqKX+frC//8JzRqBE89Be+9B/v3w9dfQyHlg0WuytXGqEhpUYyK1SlGxeoUo2J1ilGxOsVoybDZrq0UwYsvwi235K9p++KLJVPi4FoEBwdf0fbORdec7HY7/fv3509/+lOB20dHR19138qjCpm0/fXXX7nrrrtITk4mMjKSbt26sXLlSiIjI73dtXLrySehfn1Tk2XmTOjeHaZPh9q1vd0zERERERERERHvuPlm+N//YMIE2LED4uJg3Di46SZv96zoqlatypkzZzzasrKyOHLkiEdbTEwM586dc82szSvvPiq6Cpm0/eqrr7zdhQrppptg0SJT53bjRkhIMIlbnegTERERERERkYrq5pvNrayKiYnh559/9mj74IMP8s20vf322xk/fjyzZ89m4MCBHs+dOXOGbNXT9FAhk7Zy5YYPH14s++nYEVauhKFDYds26NYN/vtfGDy4WHYvFVhxxahISVGMitUpRsXqFKNidYpRsTrFqJSUBx54gIceeohbbrmF/v37s3HjRmbPnk316tU9tnv66af56aefGDZsGKNGjaJdu3akpaWxadMmvv32W/bt2+edX8CitBCZFMmePXuKbV8NG8KyZdC7tymQPXw4vP9+se1eKqjijFGRkqAYFatTjIrVKUbF6hSjYnWKUSkpv/vd73jmmWf4+eef+cMf/kBSUhJz584lNE9R3pCQEBYvXszTTz/NokWLeOKJJ3jttdfYtWsXL774IoGBgV76DaxJSVspkq1btxbr/qpWhVmz4Le/hZwceOgheOYZsNuL9W2kAinuGBUpbopRsTrFqFidYlSsTjEqVqcYlaKaPHkyDofDo23RokVs3ry5wO19fHx47bXXOHHiBGlpacyaNYuYmBj27dvHlClTPLatVKkSr776Krt27SIzM5MTJ06wbNky/vCHP+Qrp1DRKWkrXhMQAFOmmBURAV5/He68E86f92q3REREREREREREvEpJW/Eqmw3GjoX//Af8/eGbb6BvXzhxwts9ExERERERERER8Q6bI+98ZymSs2fPEh4eTkpKCpUrV/Z2d0rcuXPnqFSpUom+x6JFcNNNcOYMNGoEM2ZAXFyJvqWUI6URoyLXQjEqVqcYFatTjIrVKUbF6hSj1y4jI4OkpCQaNmxIUFCQt7tT7uTk5ODr6+vtblyzy8VJUXOKmmkrRZKWllbi79GrFyxfbhYq27sXOneGn38u8beVcqI0YlTkWihGxeoUo2J1ilGxOsWoWJ1iVKzOroWOPChpK0WyevXqUnmfZs1g5UpISIDTp6F/f/jii1J5aynjSitGRa6WYlSsTjEqVqcYFatTjIrVKUbF6nRiwZOStmI5UVGwYAHcfDNkZcGIEfDKK6BCHiIiIiIiIiIiUhEoaSuWFBJiFiX7wx/M4+efhwcegAsXvNsvERERERERERGRkqakrRRJhw4dSv09fXzgb3+DyZPN/Y8+giFDICWl1LsiZYA3YlTkSihGxeoUo2J1ilGxOsWoWJ1iVKwuNDTU212wFCVtpUjCwsK89t6PPgo//gihoTBvHnTtCvv3e607YlHejFGRolCMitUpRsXqFKNidYpRsTrFqFidj4/SlLnp05AiWbBggVfff9gw+PlnqFkTtmyBTp1g3TqvdkksxtsxKnI5ilGxOsWoWJ1iVKxOMSpWpxgVq0tNTfV2FyxFSVspM9q2hVWroGVLOHoUevSAqVO93SsREREREREREZHipaStlCl168LSpTBgAKSnw403wltvebtXIiIiIiIiIiJyLVq1asWoUaNcjxctWoTNZmPRokVe61NeDRo08OhjSVLSVoqkWbNm3u6CS+XKMG0aPPAA2O3w+OPw+99DTo63eybeZKUYFSmIYlSsTjEqVqcYFatTjIrVKUblcqZMmYLNZnPdgoKCaNKkCWPGjOHYsWMl/v42m61Y9jNjxgzGjx9fLPvyJiVtpUgaN27s7S548PeHDz6AiRPN40mT4JZbIC3Nq90SL7JajIrkpRgVq1OMitUpRsXqFKNidYpRKaoJEybw6aefMnnyZLp06cK7775L586dSU9PL9H3zZu07dGjB+fPn6dHjx5XtJ8ZM2bw4osvFmfXvEJJWymSadOmebsL+dhs8Oyz8NVXEBgIP/4IvXqZerdS8VgxRkVyU4yK1SlGxeoUo2J1ilGxOsWoBY0fDy+9VPBzL71knveCwYMHc8899/DAAw8wZcoUnnzySZKSkvjxxx8L3D6tmGbQ2e12j8c+Pj4EBQXh41Mx05cV87eWK+ZwOLzdhULdcQfMnw8REbB2LXTqBFu3ertXUtqsHKMioBgV61OMitUpRsXqFKNidYpRC/L1hbFj8yduX3rJtPv6eqdfefTp0weApKQkRo0aRaVKldizZw9DhgwhLCyMESNGACbpOmnSJJo3b05QUBDR0dGMHj2a06dPe+zP4XDw8ssvU6dOHUJCQujduzdbtmzJ976F1bRdtWoVQ4YMoWrVqoSGhtKqVSvefPNNAEaNGsXbb78N4FHqwam4+1iS/Er13URKSNeusGIFDBkCu3dDly7w3XdwcVwRERERERERESk5l5pt6usLQUH5t33qKcjKMgnarCxzOfFf/2qSthMmwAsvXHq/Pj4QHOx+nJ4OISHX9nsUYM+ePQBEREQAkJ2dzcCBA+nWrRt/+9vfCLn4nqNHj2bKlCnce++9PP744yQlJTF58mQ2bNjAsmXL8Pf3B2Ds2LG8/PLLDBkyhCFDhrB+/XoGDBhAZmbmZfsyd+5chg0bRs2aNXniiSeoUaMG27ZtY9q0aTzxxBOMHj2aw4cPM3fuXD799NN8r7/WPmZlZRXLZ1oUStpKkdSrV8/bXbis2FiTuL3xRli2DAYOhA8/hJEjvd0zKQ1lIUalYlOMitUpRsXqFKNidYpRsTrFaAmrVKnw54YMgenT3Y+jokyCNbeXXzY3cCdsARo0gJMnC95v+/awZo37cXw87Nt3pT3PJyUlhZMnT5KRkcGyZcuYMGECwcHBDBs2jBUrVpCZmcltt93GROdCQ8DSpUv58MMP+fzzz7n77rtd7b1792bQoEF888033H333Zw4cYLXX3+doUOHMnXqVNcs2Oeee45XX331kv3Kyclh9OjR1KxZk8TERKpUqeJ6zjmTvHPnzjRp0oS5c+dyzz33eLy+NPpYnFQeQYqkdevW3u5CkVSvDvPmmZIJ2dkwahSMGwe6CqT8KysxKhWXYlSsTjEqVqcYFatTjIrVKUbLCJvNnbD1kn79+hEZGUndunW58847qVSpEt9//z21a9d2bfPwww97vOabb74hPDyc/v37c/LkSdetXbt2VKpUiYULFwIwb948srKyeOyxxzzKFjz55JOX7deGDRtISkriySef9EjYQv5FzApSGn0sTkraSpHkrR9iZUFB8MUX5qoCMCeoRo6EIsyylzKsLMWoVEyKUbE6xahYnWJUrE4xKlanGC1h584Vfvvf/zy3PX7c8/nnnzftAQFm1lnuGrf79hW+359/9txvMS3w8/bbbzN37lwWLlzI1q1b2bt3LwMHDnQ97+fnR506dTxes2vXLlJSUoiKiiIyMtLjdu7cOY4fPw7A/v37AYiNjfV4fWRkZL5EbF7OMg0tWrS4qt+rOPpYtWrVq3rvq6HyCFIkqamp3u7CFfHxgYkToVEjePhh+PRTOHAAvv8eSvHvS0pRWYtRqXgUo2J1ilGxOsWoWJ1iVKxOMVrCQkOvbtuXXjJlEZwlEZyLkIF5fCX7LaZ6th07dqR9+/aFPh8YGIiPj+c8ULvdTlRUFJ9//nmBr4mMjCyWvl2LstDH3JS0BV577TX+/Oc/88QTTzBp0iRvd0eK0e9+B/XqwW23weLF0LkzzJhhkrkiIiIiIiIiIl7jTNDmrmHr/Jk7cVsGxMTEMG/ePLp27Upw7sXR8qhfvz5gZr02ypWcOXHiBGfOnLnsewBs3ryZfv36FbpdYaUSiqOPp0+fvmQfi1OFL4+wZs0a3n//fVq1auXtrlhatWrVvN2FqzZwICxdCnXqwI4d0KkTrFrl7V5JcSvLMSoVg2JUrE4xKlanGBWrU4yK1SlGLSgnxzNh6/TCC6Y9J8c7/boKt99+Ozk5ObyUu7TDRdnZ2a6EbL9+/fD39+ett95yLR4GFGkSZdu2bWnYsCGTJk3Kl+DNva/Qi7OT825TGn0sThV6pu25c+cYMWIE//rXv3jZuUJfITIzM8nMVRT17NmzJd09S+natau3u3BNWrUyidphw2DDBujVCz77DG65xds9k+JS1mNUyj/FqFidYlSsTjEqVqcYFatTjFrQ+PGFP1dGZtg69ezZk9GjRzNx4kQSExMZMGAA/v7+7Nq1i2+++YY333yTW2+9lcjISP74xz8yceJEhg0bxpAhQ9iwYQMzZ86kevXql3wPHx8f3n33XYYPH06bNm249957qVmzJtu3b2fLli3Mnj0bgHbt2gHw+OOPM3DgQHx9fbnzzjtLpY/FqUInbR999FGGDh1Kv379Lpu0nThxIi+++GK+9pkzZxJysWZI//79SU5OZv369a7nO3fujJ+fH0uWLHG1tWrVitq1azNz5kxXW6NGjWjevDlz584lIyMDgKioKBISElixYgUnT54EICQkhL59+7Jp0yb27dvnev3QoUPZt28fW7ZscbX17NmTjIwMVuWaVtq+fXvCw8OZP3++q61p06bExsYyffp07HY7AHXr1qVNmzYsWrSI1NRU7HY7ERERdOvWjbVr13LkyBEA/P39GTRoENu3b2fXrl2ufQ4YMIATJ06wYcMGV1uXLl3w8fFh6dKlHp9FrVq1mDVrlqstJiaG+Ph45syZ40qUR0dH07FjR5YvX05ycjJgzpz06dOHjRs3cuDAAdfrhw8fzp49e9iaqwB379698fVN49ln1/HGG+1Yuzaa225z8MorWTRvPgfnzPlmzZrRuHFjpk2b5jqbUq9ePVq3bu36LMCcoezatStr1qzh6NGjAAQEBDBw4EC2bdvG7t27Xe89cOBAjh07RmJioqvN+Z/lsmXLXG1t2rQhOjraNcgANG7cmGbNmjF79myysrIAqFGjBh06dGDZsmWcOnUKgLCwMHr16uXxWdhsNoYNG8bu3bvZtm2ba599+vQhNTWVNWvWuNo6duxIaGioa6VEgPj4eGJiYpg6daqrzflZLFiwgLS0NAAiIiLo0qULq1ev5tixY4CpbzNgwAC2bt3qKhQOMGjQIA4fPswvv/ziauvWrRt2u53ly5e72q677joiIyOZM2eOqy02NpamTZsya9YsLly4AEDNmjVp3749S5cuJTk5GR8fH9dnkZiYyMGDBwEzsA8dOpRdu3axfft21z779u1LSkoKa9eudbUlJCQQFBTE4sWLXW3NmzenQYMGTJ8+3dXWoEEDWrZsyfz580lPTwegevXqdO7cmVWrVrkKmAcFBdG/f3+2bNnC3r17Xa8fPHgwhw4d8vgsunfvTnZ2NitWrHC1tW3bloiICObOnetqa9KkCXFxccycOZPs7GwAatWqRbt27ViyZInr7GB4eDg9evRg/fr1HDp0CABfX1+GDBnCzp072bFjh2uf/fr14/Tp06xbt87V1qlTJwIDAz0+ixYtWlCvXj1mzJjhamvYsCEtWrRg3rx5nD9/HjC1gDp16sTKlSs5ceIEAMHBwfTr14/NmzeTlJTkev2QIUM4cOAAmzdvdrX17NmTzMxMVq5c6Wpr164dVatWZd68ea62uLg4mjRpwowZM8i5eBa6du3atG3blp9//pmUlBQAqlSpQvfu3Vm3bh2HDx8GTPH8wYMHs2PHDnbu3OnaZ0mN5blj11tjOUDVqlXL9FielpbG6tWrXW0dOnQgLCyMBQsWuNo0ll/dWO7v74/D4fDqWO683ExjucbygsZy5+/tzbHcCsfloLHcqmO53W4nPDy8wh+Xayy37lh+7NgxfHx8Kvxx+bWM5ampqaSnp3P27FkyMjIICQnB19fXo15wUFAQQUFBHrM8AwICCAkJITU11fX5+Pr6EhYWRlpamutvyWazER4ezvnz5z0mDlauXJns7GxXjANUqlQJMBMSnYKDg/H39/eYaBgYGEhwcDApKSmu8dTf35/Q0FDOnTvnit3cNWpTU1Nd/a9SpQoZGRmuz9E5Bl64cME1/oD5v+Dtt9+mWbNmTJkyhb/85S/4+fnRoEEDbr31Vlq0aMGZM2cICAjg5Zdfxmaz8dFHH7Fw4ULat2/PnDlzGDx4MFlZWZw5c8ajxMG5c+dc/enfvz9z5sxhwoQJ/N///R92u51GjRpx//33u7bp06cPjzzyCN988w2fffYZDoeDQYMGERgYyHvvvUd8fDwff/yxRx9vv/12Vx99fX15+eWX8fX15cMPP2ThwoW0a9eOOXPmMGTIEFcfwYx1drvd47Pw9fXFbrezcOFC1+ebeyzP/e94KTZH7nm+FchXX33FK6+8wpo1awgKCqJXr160adOm0KnOBc20rVu3LikpKVSuXLmUeu09U6dOZfjw4d7uRrHIzoYnnoB33jGPH34Y/vlP8KvQpzDKvvIUo1I+KUbF6hSjYnWKUbE6xahYnWL02mVkZJCUlETDhg0JCgrydnfKnTNnzlClShVvd+OaXS5Ozp49S3h4+GVzihUyTXXw4EGeeOIJ5s6dW+Q/ssDAQAIDA0u4Z1Ia/Pxg8mSIiYE//hHefRf274evv4aLJ6pERERERERERES8pkIuRLZu3TqOHz9O27Zt8fPzw8/Pj8WLF/PPf/4TPz8/11R1cQsICPB2F4qVzQZPPQXffgtBQTBjBvToARevzpAyqLzFqJQ/ilGxOsWoWJ1iVKxOMSpWpxgVq8tdEkEqaHmE1NRU9u/f79F277330rRpU5555hlatGhx2X0UdSqzWN+qVTB8OJw4AXXqmARuy5be7pWIiIiIiIiIWInKI0hRFFd5hAo50zYsLIwWLVp43EJDQ4mIiChSwrYiyl0wv7xJSICVK6FpU/j1V+jaFXLV2ZcyojzHqJQPilGxOsWoWJ1iVKxOMSpWpxgVq3MuoCdGhUzaypXLvepqedSoESxfDj17QmoqDBkC//qXt3slV6K8x6iUfYpRsTrFqFidYlSsTjEqVqcYFavLzMz0dhcspUIuRFaQRYsWebsL4mVVq8Ls2fDAA/DZZ/Dgg7B3L7zyCvjo9IaIiIiIiIiIiJQSpaJEcgkMhP/8B8aONY9few3uvhsyMrzbLxERERERERGxhgq4PJRcgeKKjwq5EFlxqGgLkWVlZVW4lSY/+cTMus3ONnVuf/gBqlf3dq+kMBUxRqVsUYyK1SlGxeoUo2J1ilGxOsXotcvJyWHnzp1ERUURERHh7e6UO3a7HZ9ycKnzyZMnOXnyJLGxsfj6+uZ7vqg5RZVHkCI5duwYdevW9XY3StXIkVC3Ltx8MyxbBp07w4wZEBvr7Z5JQSpijErZohgVq1OMitUpRsXqFKNidYrRa+fr60uVKlU4fvw4ACEhIdhsNi/3qvwoyycWHA4H2dnZnD17lrNnz1KlSpUCE7ZXQklbKZLExMQKObj36WMWKBsyBHbvNonbH36Abt283TPJq6LGqJQdilGxOsWoWJ1iVKxOMSpWpxgtHjVq1ABwJW6l+KSnpxMSEuLtblwTX19fatasSXh4+DXvS0lbkcuIj4eVK+H662HNGujb15ROuPNOb/dMREREREREREqTzWajZs2aREVFceHCBW93p1xZuHAhvXv39nY3rpqfnx++vr7FNvtaSVuRIqhRAxYtghEjzEzbu+6CffvgmWdAV0KIiIiIiIiIVCy+vr7XfPm7eMrOziYoKMjb3bAMLUR2lSraQmSnTp2iWrVq3u6G1+XkwB//CJMmmccPPADvvAP+/l7tlqAYFetTjIrVKUbF6hSjYnWKUbE6xahYXUWJ0aLmFMv+kmwipcjXF/7xD3jrLfDxgQ8/hGHD4OxZb/dMRERERERERETKCyVtpUiWLVvm7S5YypgxpkxCSAjMmWMWJjt40Nu9qtgUo2J1ilGxOsWoWJ1iVKxOMSpWpxgVq1OMelLSVuQqDR8OP/9s6t1u2gQJCbB+vbd7JSIiIiIiIiIiZZ2StiLXoF07WLUKmjeHI0egRw+YPt3bvRIRERERERERkbJMSVspkjZt2ni7C5ZVrx4sWwb9+kFaGlx/vVmcTEqXYlSsTjEqVqcYFatTjIrVKUbF6hSjYnWKUU9K2kqRREdHe7sLlhYeDjNmwH33gd0Ojz4Kf/iDuS+lQzEqVqcYFatTjIrVKUbF6hSjYnWKUbE6xagnJW2lSGbPnu3tLlievz98+CG8/LJ5/Pe/w223QXq6d/tVUShGxeoUo2J1ilGxOsWoWJ1iVKxOMSpWpxj1pKStSDGy2eC55+CLLyAgAL77Dnr3hmPHvN0zEREREREREREpK5S0FSkBd90F8+ZBtWqwejV06gTbtnm7VyIiIiIiIiIiUhYoaStF0rhxY293oczp3h1WrICYGNi3D7p0gUWLvN2r8ksxKlanGBWrU4yK1SlGxeoUo2J1ilGxOsWoJ5vD4XB4uxNl0dmzZwkPDyclJYXKlSt7uztiYSdOwA03mASuvz989BHcc4+3eyUiIiIiIiIiIqWtqDlFzbSVIlEx6KsXGQnz55tFyS5cgN/8BiZMAJ0uKV6KUbE6xahYnWJUrE4xKlanGBWrU4yK1SlGPSlpK0WSlZXl7S6UacHB8NVX8Mwz5vG4cXDvvaCPtfgoRsXqFKNidYpRsTrFqFidYlSsTjEqVqcY9aSkrUgp8fGB116D998HX1/45BMYNAjOnPF2z0RERERERERExEqUtJUiqVGjhre7UG48+CBMmwaVKsHChWaBsn37vN2rsk8xKlanGBWrU4yK1SlGxeoUo2J1ilGxOsWoJy1EdpW0EJlcq40bYehQOHQIoqJg6lTo2NHbvRIRERERERERkZKihcikWC1btszbXSh3WreGlSvNz+PHoVcv+OEHb/eq7FKMitUpRsXqFKNidYpRsTrFqFidYlSsTjHqyfJJ25ycHL766itGjx7NTTfdxKZNmwBISUnhu+++49ixY1e8z3fffZdWrVpRuXJlKleuTOfOnZk5c2Zxd71cOXXqlLe7UC7VqQNLlpjatufPw803w6RJoPnvV04xKlanGBWrU4yK1SlGxeoUo2J1ilGxOsWoJ0snbc+cOUPXrl25++67+fLLL/npp584ceIEAJUqVeLxxx/nzTffvOL91qlTh9dee41169axdu1a+vTpww033MCWLVuK+1cQuaywMFMa4aGHTLL297+Hxx+HnBxv90xERERERERERLzB0knbZ599li1btjB79mz27t1L7vK7vr6+3HrrrcyYMeOK9zt8+HCGDBlCbGwsTZo04ZVXXqFSpUqsXLmy0NdkZmZy9uxZj1tFEhYW5u0ulGt+fvDOO/D66+bx5Mlw441w7pxXu1WmKEbF6hSjYnWKUbE6xahYnWJUrE4xKlanGPXk5+0OXMoPP/zAY489Rv/+/UlOTs73fJMmTZgyZco1vUdOTg7ffPMNaWlpdO7cudDtJk6cyIsvvpivfebMmYSEhAC4+rl+/XrX8507d8bPz48lS5a42lq1akXt2rU9SjI0atSI5s2bM3fuXDIyMgCIiooiISGBFStWcPLkSQBCQkLo27cvmzZtYt++fa7XDx06lH379nnMFu7ZsycZGRmsWrXK1da+fXvCw8OZP3++q61p06bExsYyffp07HY7AHXr1qVNmzYsWrSI1NRUAJYuXUq3bt1Yu3YtR44cAcDf359Bgwaxfft2du3a5drngAEDOHHiBBs2bHC1denSBR8fH5YuXerxWdSqVYtZs2a52mJiYoiPj2fOnDlkZmYCEB0dTceOHVm+fLkrFkJDQ+nTpw8bN27kwIEDrtcPHz6cPXv2sHXrVldb7969SUtLY/Xq1a62Dh06EBYWxoIFC1xtzZo1o3HjxkybNs11kqBevXq0bt3a47OoVq0aXbt2Zc2aNRw9ehSAgIAABg4cyLZt29i9e7drnwMHDuTYsWMkJia62rp27Qp41mtp06YNTzwRTXLyL/zjH9cxbZovCQnnmTcvmF9+mU1WVhZgVlPs0KEDy5Ytc106EBYWRq9evTw+C5vNxrBhw9i9ezfbtm1zvU+fPn1ITU1lzZo1rraOHTsSGhrKwoULXW3x8fHExMQwdepUV5vzs1iwYAFpaWkARERE0KVLF1avXu0qVxIYGMiAAQPYunUre/bscb1+0KBBHD58mF9++cXV1q1bN+x2O8uXL3e1XXfddURGRjJnzhxXW2xsLE2bNmXWrFlcuHABgJo1a9K+fXuWLl1KamoqU6dOdX0WiYmJHDx4EAAfHx+GDh3Krl272L59u2ufffv2JSUlhbVr17raEhISCAoKYvHixa625s2b06BBA6ZPn+5qa9CgAS1btmT+/Pmkp6cDUL16dTp37syqVas4fvw4AEFBQfTv358tW7awd+9e1+sHDx7MoUOHPD6L7t27k52dzYoVK1xtbdu2JSIigrlz57ramjRpQlxcHDNnziQ7OxuAWrVq0a5dO5YsWcKZM2cACA8Pp0ePHqxfv55Dhw4B5oTXkCFD2LlzJzt27HDts1+/fpw+fZp169a52jp16kRgYKDHZ9GiRQvq1avnccKsYcOGtGjRgnnz5nH+/HkAIiMj6dSpEytXrnRdIREcHEy/fv3YvHkzSUlJrtcPGTKEAwcOsHnzZldbz549yczM9DiZ1q5dO6pWrcq8efNcbXFxcTRp0oQZM2aQc3F6eu3atWnbti0///wzKSkpAFSpUoXu3buzbt06Dh8+DICfnx+DBw9mx44d7Ny507XPkhrLAwMDXX9P3hzLq1atqrG8hMfy6OhoZs+e7Wpr3LgxzZo1Y/Zsa4/lvXr18vpYfvr0aY/PQmO5xvK8Yzng1bHcKsflGsutO5YvWrSowh+Xayy37lju/M7k7bHc28flGsutO5aHhoa6xrryfFzuHKsux+ZwWLd6ZnBwMP/85z/53e9+R3JyMpGRkcybN48+ffoA8Oabb/Lcc89x7iqmI27atInOnTuTkZFBpUqV+OKLLxgyZEih22dmZrqCG8xKb3Xr1r3sSm/lxcaNG2ndurW3u1FhrFgB118PJ09C3bowYwa0aOHtXlmbYlSsTjEqVqcYFatTjIrVKUbF6hSjYnUVJUbPnj1LeHj4ZXOKli6PEBMT43FGJa85c+YQHx9/VfuOi4sjMTGRVatW8fDDDzNy5EiPswZ5BQYGuhYuc94qktxnWaTkde4MK1dCkyZw8CB07Qq5TmJKARSjYnWKUbE6xahYnWJUrE4xKlanGBWrU4x6snTS9oEHHuCjjz7i66+/dk2jttlsZGZm8txzzzFr1ixGjx59VfsOCAigcePGtGvXjokTJ9K6deurWtRMpKTExJgZt927w9mzMHgwfPSRt3slIiIiIiIiIiIlzdI1bZ944gm2bNnCXXfd5aphdffdd5OcnEx2djajR4/m/vvvL5b3stvtHuUPxJPNZvN2FyqkatVg7ly47z744gu4/37Yuxdeegn0T+JJMSpWpxgVq1OMitUpRsXqFKNidYpRsTrFqCdL17R1Wrp0Kd9++y27du3CbrcTExPD7bffTo8ePa5qf3/+858ZPHgw9erVIzU1lS+++IK//vWvzJ49m/79+xdpH0WtPyFSHBwOGDfOJGsB7roLPv4YAgO92y8RERERERERESm6ouYULT3T1qlbt25069at2PZ3/Phxfvvb33LkyBHCw8Np1arVFSVsK6Ldu3fTuHFjb3ejwrLZYMIEaNgQHnwQvvwSfv0Vvv8eIiK83TtrUIyK1SlGxeoUo2J1ilGxOsWoWJ1iVKxOMerJ0jVtS8q///1v9u3bR2ZmJsePH2fevHlK2F7Gtm3bvN0FAe69F2bNgsqVYckSs2DZ7t3e7pU1KEbF6hSjYnWKUbE6xahYnWJUrE4xKlanGPVk6Zm2DRs2vGw9C5vNxp49e0qpRyLe17cvLFsGQ4fCrl0mcfvjj9Cli7d7JiIiIiIiIiIixcHSSduePXvmS9rm5OSwf/9+li1bRosWLbjuuuu81DsR72nRAlauhOHDYd066NMHPv0UbrvN2z0TEREREREREZFrVSYWIivIxo0bGThwIJ999hn9+vUr9fevaAuRpaWlERoa6u1uSB5paWZRsqlTzeO//hWeftrUwK1oFKNidYpRsTrFqFidYlSsTjEqVqcYFaurKDFa1Jxima1p27p1a0aPHs0zzzzj7a5UCKmpqd7ughQgNNQsRvb44+bxM8/AQw9BdrZ3++UNilGxOsWoWJ1iVKxOMSpWpxgVq1OMitUpRj2V2aQtQHR0NFu3bvV2NyqENWvWeLsLUghfX3jzTZg0ycyw/eADUzahoo11ilGxOsWoWJ1iVKxOMSpWpxgVq1OMitUpRj2V2aRtcnIy//73v6lTp463uyJiCU88YWbdBgfDrFnQvTv8+qu3eyUiIiIiIiIiIlfK0guR9enTp8D2M2fOsH37drKysvj0009LuVci1nXDDbB4sZlpu3EjJCTA9OnQpo23eyYiIiIiIiIiIkVl6Zm2drsdh8PhcQNo2LAhY8aMYfPmzdx1111e7mXF0LFjR293QYqoQwdYuRLi4+HwYTPjduZMb/eq5ClGxeoUo2J1ilGxOsWoWJ1iVKxOMSpWpxj1ZOmZtosWLfJ2F+SiirB6X3nSoAEsWwa33AILFpiZt5Mnm0XKyivFqFidYlSsTjEqVqcYFatTjIrVKUbF6hSjniw901asY+HChd7uglyhKlXMDNtRoyAnBx5+GP70J7Dbvd2zkqEYFatTjIrVKUbF6hSjYnWKUbE6xahYnWLUk6Vm2v7nP/+5qtf99re/LeaeiJQPAQHw0UcQEwMvvABvvAFJSfCf/5gFy0RERERERERExHoslbQdNWrUFb/GZrMpaStyCTYbPP+8KZlw333w7bfw66/w008QGent3omIiIiIiIiISF6WStomJSV5uwtSiPj4eG93Qa7RPfdA3bpw001mobJOnWDGDIiL83bPiodiVKxOMSpWpxgVq1OMitUpRsXqFKNidYpRTzaHw+HwdifKorNnzxIeHk5KSgqVK1f2dndEimz7dhgyxJRJqFoVfvgBevTwdq9ERERERERERMq/ouYUtRCZFMnUqVO93QUpJk2bmpm2CQlw+jT07w+ff+7tXl07xahYnWJUrE4xKlanGBWrU4yK1SlGxeoUo54sVR6hIEePHuXf//4369evJyUlBbvd7vG8zWZj/vz5XuqdSNkUFQULF8JvfgP/+58pnZCUBM89Z2rgioiIiIiIiIiI91g6afvLL7/Qq1cvzp8/T1xcHJs2bSI+Pp4zZ85w6NAhYmJiqFu3rre7KVImBQfDf/8LzzwDf/sbvPAC7N0L778P/v7e7p2IiIiIiIiISMVl6fIIzz77LJUqVWLHjh3MmzcPh8PBm2++ycGDB/n66685ffo0r732mre7WSHUq1fP212QEuDjA2+8Ae+8Y+5//DEMHgxnzni7Z1dOMSpWpxgVq1OMitUpRsXqFKNidYpRsTrFqCdLL0QWHh7On/70J5577jlOnTpF9erVmTNnDv369QPgiSeeIDExkcWLF5d637QQmZQ3M2bA7bdDWho0bw7Tp0P9+t7ulYiIiIiIiIhI+VEuFiKz2+1ER0cDUKVKFXx9fTl16pTr+ZYtW7Ju3Tpvda9CWbBggbe7ICVsyBBYsgRq1YItW6BTJ1i71tu9KjrFqFidYlSsTjEqVqcYFatTjIrVKUbF6hSjniydtG3YsCFJSUkA+Pj40LBhQ+bNm+d6fvny5VSpUsVLvatY0tLSvN0FKQXXXQerVkGrVnD0KPTsCT/95O1eFY1iVKxOMSpWpxgVq1OMitUpRsXqFKNidYpRT5ZL2p4+fdp1f8CAAXzzzTeuxw8//DAffvgh/fr1o2/fvnzyySfcfffd3uimSLlVp46ZcTtwIKSnw403wj//6e1eiYiIiIiIiIhUHJZL2taoUYObbrqJb7/9lj/84Q98+eWXXLhwAYAnn3ySCRMmkJycTEpKCi+88AIvv/yyl3tcMURERHi7C1KKKleGqVPhwQfB4YAnnoAnn4ScHG/3rHCKUbE6xahYnWJUrE4xKlanGBWrU4yKVX33HbRuDbfeOpTWrc1jseBCZCNGjOCnn34iPT2dsLAwbr75ZkaMGEGfPn2w2Wze7p6LFiKTisDhgDfegGeeMY9vuAE+/xxCQ73bLxEREREREREp+777Dm65BWw2k4Nw/vzf/+Dmm73du5JRZhci+/zzzzl+/DifffYZ3bt35/PPP2fAgAHUrl2bP/zhD6xfv/6a32PixIl06NCBsLAwoqKiuPHGG9mxY0cx9L78Wr16tbe7IF5gs8Gf/gRffQWBgfDjj9Crl6l3azWKUbE6xahYnWJUrE4xKlanGBWrU4yK1djt8Mc/mvvOKaXOxO2ECd7rl1VYLmkLEBwczF133cXUqVM5evQo77zzDrGxsUyaNIkOHTrQtGlTXn75Zfbu3XtV+1+8eDGPPvooK1euZO7cuVy4cIEBAwao4PElHDt2zNtdEC+64w6YPx8iImDtWujUCbZs8XavPClGxeoUo2J1ilGxOsWoWJ1iVKxOMSpWcfasWTunWTNISsr/vMMBmltp0aRtblWrVmX06NEsXryYAwcO8NprrxESEsLYsWOJjY2lS5cuV7zPWbNmMWrUKJo3b07r1q2ZMmUKBw4cYN26dYW+JjMzk7Nnz3rcRCqSrl1h5UqIjYX9+83jBQu83SsRERERERERKQu2b4cxY6B2bbN2zs6d4FNAZtJmg7i40u+f1Viupm1RbNq0ibFjx/Ljjz9is9nIucbVkXbv3k1sbCybNm2iRYsWBW4zfvx4XnzxxXztX331FSEhIQD079+f5ORkjxIOnTt3xs/PjyVLlrjaWrVqRe3atZk5c6arrVGjRjRv3py5c+eSkZEBQFRUFAkJCaxYsYKTJ08CEBISQt++fdm0aRP79u1zvX7o0KHs27ePLbmmP/bs2ZOMjAxWrVrlamvfvj3h4eHMnz/f1da0aVNiY2OZPn06drsdgLp169KmTRsWLVpEamoqdrudiIgIunXrxtq1azly5AgA/v7+DBo0iO3bt7Nr1y7XPgcMGMCJEyfYsGGDq61Lly74+PiwdOlSj8+iVq1azJo1y9UWExNDfHw8c+bMITMzE4Do6Gg6duzI8uXLSU5OBiA0NJQ+ffqwceNGDhw44Hr98OHD2bNnD1u3bnW19e7dm7S0NI/LQZwlMhbkyjw2a9aMxo0bM23aNJx/GvXq1aN169auzwKgWrVqdO3alTVr1nD0Yq2AgIAABg4cyLZt29i9e7drnwMHDuTYsWMkJia62rp27QrAsmXLXG1t2rQhOjqa2bNnu9oaN25Ms2bNmD17NllZWYBZrK9Dhw4sW7aMU6dOARAWFkavXr08PgubzcawYcPYvXs327Ztc+2zT58+pKamsmbNGldbx44dCQ0NZeHCha62+Ph4YmJimDp1qqutXr161KnTml69zrB5cxV8fe08++weXn45ltWrV7vO3AYGBjJgwAC2bt3Knj17XK8fNGgQhw8f5pdffnG1devWDbvdzvLly11t1113HZGRkcyZM8fVFhsbS9OmTZk1a5ZrccKaNWvSvn17li5dSnJyMj4+Pq7PIjExkYMHDwLg4+PD0KFD2bVrF9u3b3fts2/fvqSkpLB27VpXW0JCAkFBQSxevNjV1rx5cxo0aMD06dNdbQ0aNKBly5bMnz+f9PR0AKpXr07nzp1ZtWoVx48fByAoKIj+/fuzZcsWj6sDBg8ezKFDhzw+i+7du5Odnc2KFStcbW3btiUiIoK5c+e62po0aUJcXBwzZ84kOzsbgFq1atGuXTuWLFnCmTNnAAgPD6dHjx6sX7+eQ4cOAeDr68uQIUPYuXOnR1mYfv36cfr0aY+TV506dSIwMNDjs2jRogX16tVjxowZrraGDRvSokUL5s2bx/nz5wGIjIykU6dOrFy5khMnTgDmKop+/fqxefNmknKdTh0yZAgHDhxg8+bNrraePXuSmZnJypUrXW3t2rWjatWqzJs3z9UWFxdHkyZNmDFjhuv/gtq1a9O2bVt+/vlnUlJSAKhSpQrdu3dn3bp1HD58GAA/Pz8GDx7Mjh072Llzp2ufJTWW5/5b8tZYDuZkqMZyjeWtW7dmwYIFrquMIiIiOHfuHFWqVPHqWH769GmPz0Jjucby3GM5mLHBm2O5FY7LQWO5Vcdyu91OeHi4V8fyLl26eP24XGO5dcfyY8eO4ePjU+GPyzWWl+5Y3rBhY8aPX8O0aQ1ITIx0PVe/fhqDB+8hJOQCf/97u1w1bR04HDZeeGEDEyZcVy6Py9PT07nzzjsvW9O2zCRtDxw4wBdffMGXX37J5s2bcTgcdOnShREjRvDwww9f9X7tdjvXX389Z86c8Qj0vDIzM13BDaZocN26dbUQmVRIGRlw772m1i3ACy/Aiy+as2EiIiIiIiIiUrGdOgUffQTvvOMugeDjA8OHw2OPQZ8+7hzCd9+ZGrY7dpgZtuPGwU03ea/vJa2oC5FZOml78uRJ/vvf//LFF1+wYsUKHA4HTZs2ZcSIEYwYMYIGDRpc83s8/PDDzJw5k6VLl1KnTp0iv66oH3B5sXXrVuLj473dDbEQu90ka1991Ty+5x748EOzYJk3KEbF6hSjYnWKUbE6xahYnWJUrE4xKqXhl1/grbfg88/h4oRvqlaFBx6ARx6BS6XyKkqMFjWnaLmatmlpaXz22WcMGTKE2rVrM2bMGJKSknjyySdZu3YtW7du5bnnniuWhO2YMWOYNm0aCxcuvKKEbUWU+1IaETBnyF55xSRqfX3hs89gwABzNs0bFKNidYpRsTrFqFidYlSsTjEqVqcYlZKSnQ3ffgs9e0Lr1iZPcP68+/6vv8Lrr186YQuK0bz8vN2BvKKiosjIyKBSpUrcfffdjBgxgj59+uBTUGXiq+RwOHjsscf4/vvvWbRoEQ0bNiy2fYtUNPffD/Xqwa23ws8/Q5cuMGMGNGrk7Z6JiIiIiIiISEk5cQI++ADee88kZsFM6rr5ZlMCoVs3lVG8FpZL2vbr148RI0Zw/fXXExQUVCLv8eijj/LFF1/w448/EhYW5ipYHx4eTnBwcIm8p0h51r8/LF0KQ4eaGjSdOsFPP5mfIiIiIiIiIlJ+rF1rSiB89RVcXM+LyEgYPRoeeghq1/Zu/8oLS9e0LSm2QtL8H3/8MaNGjSrSPipaTdsLFy7g7+/v7W6IxR0+bIqKr18PQUGmZMItt5TOeytGxeoUo2J1ilGxOsWoWJ1iVKxOMSrXIisLvvnGJGtXrXK3d+hgZtXefvu1r3FTUWK0zNa0LQ0Oh6PAW1ETthXR4cOHvd0FKQNq1YLFi2HYMMjIgNtug7/9DUrj1JBiVKxOMSpWpxgVq1OMitUpRsXqFKNyNQ4fhnHjTFnEe+4xCVt/f/f91avhN78pnkXJFaOeKmTSVq7cL7/84u0uSBlRqRL88AM8+qhJ1j79tLmfnV2y76sYFatTjIrVKUbF6hSjYnWKUbE6xagUlcMBy5bBnXdC/fowYQIcO2Ymak2YAAcPwqefQseOxfu+ilFPlqtpKyJln6+vuWQiJgb+8Ad4913Yv9/UuwkL83bvRERERERERCSv8+fN9/a33oING9zt3bqZEgg33WRm2UrpUNJWREqEzQa//z00aAAjRsCMGdCjB0ybpqLkIiIiIiIiIlZx4AC88w58+CEkJ5u2oCC4+24YMwauu867/auoKuRCZMWhoi1Edvr0aapWrertbkgZtXq1WaDs+HGoUwemT4dWrYr3PRSjYnWKUbE6xahYnWJUrE4xKlanGJXcHA5YtMjMqv3xR7DbTXv9+vDII3D//RARUbp9qigxqoXIpFjZnX+9IlehY0dYuRKaNoVffzWXVsyeXbzvoRgVq1OMitUpRsXqFKNidYpRsZzx4+Gll1wPPWL0pZfM81LhpKXBe+9By5bQpw98/71J2Drv79kDf/pT6SdsQeNoXkraSpEsX77c212QMq5hQ1i+HHr1gtRUGDoUPvig+PavGBWrU4yK1SlGxeoUo2J1ilGxHF9fGDvWlbh1xehLL5l2X18vdk5K25498NRTplzhww/Dli0QGuq+P38+3Hijd8NC46gn1bQVkVJTtaqZYfvAA2alydGjYe9eePVV8NEpJBERERERkeLzwgvm59ix5mebNu6E7YQJ7uel3LLbYc4cmDzZrDPjLJDauDE8+iiMGgVVqnizh3IpStqKSKkKCIBPPoGYGHM1zl//CklJpi0oyNu9ExERERERKcMcDkhMhB073LeaNWHsWIY5t1HCttw7examTDHJ2l273O2DB8Njj8HAgZo4VRZoIbKrVNEWIvv111+pU6eOt7sh5cx//mNm3V64AF26mOLn1atf3b4Uo2J1ilGxOsWoWJ1iVKxOMSqlxm43i4U4k7IBAfDgg+Y5h8Nc4piSUvBrbTb3ilMAN98MdetCp06QkGDq2tlsJf87SInYtg3efttMijp3zrRVrgz33mtm1sbGerd/l1NRxtGi5hSVtL1KFS1pm5mZSWBgoLe7IeXQokVw001w5oy5RGPGjKv7j0QxKlanGBWrU4yK1SlGxeoUo1Ki/vpX2LABtm83UyfT093PxcWZdqfBg81Uy7g4c9u4Eb78EoefH7bsbPdM22PHoEYNz/eJjDTJ206doH9/s6q0WFpODkyfDm+9BfPmudubNTOzan/zG6hUyXv9uxIVZRwtak5Rk6GlSObMmePtLkg51auXWaCsQQPYvdscGyxdeuX7UYyK1SlGxeoUo2J1ilGxOsWoXBW7HfbtM4t//POfZjpk374mYZrbf/8LX39tErDp6eDnZxKyN9wAt97que3MmbBsGXz0EWRlwZdfwoQJTPvuO5OwdS5OFhICn38Ojz9ukrP+/nDiBEybBs8/b6ZrOmVkwPvvm/fPzi7xj0Uu79QpeOMNM/nphhtMwtbHx31/yxazyFhZSdiCxtG8VNNWRLyuWTNYuRKuvx5WrzbHKFOmwF13ebtnIiIiIiIixeDsWTh4EJo3d7fddptJkGZk5N8+MNBMofT1NY8feshcnti0qUnWNmxokqyXknfRsalT8y9O9sILcPfd5n5GhqmHu2qV+YI2YIB7X+vXmz6ASfZ26OCekZuQALVqXeknIlfpl1/MrNrPP4fz501btWqm9ODDD5sJUVI+KGkrIpYQHQ0LF8I998D335vjhqQk+POfVVJJRERERETKiAMHYPNmz4XAduyAI0dMsjM11b0ClM1mEqX+/ma6pDMh67zl9rvfXXlfcnIKXnTM+Tgnx7M9KMgkYTt1gieeyL+/fv3MLJuzZ2HxYnNzevtteOQRc9+ZSQwOvvI+S4EuXIAffjDJ2iVL3O2tW5sSCHfdZcJLyhclbaVIYq1erVrKhZAQ+OYbePpp+Mc/4LnnYO9eePfdy59EVoyK1SlGxeoUo2J1ilGxOsVoBXLmjDsZu2cPjB/vnmnyxBMmu1aQsDA4eRKioszjl1+GV181UyP9SiA9M368x0OPGM2byL2cLl1g7lxTzmH7djMT1zkjd/Nmkz10+t//zMpXrVq5Z+J26mQWL9GMnCty/Dj861/mO/GhQ6bN1xduucUka7t2LV8fqcZRT1qI7CpVtIXIRErb22+b0kp2uynn9M03EB7u7V6JiIiIiEiF88MPZsVkZ6L22DHP5w8fhpo1zf1x4+C77zxnzDZtCk2aQJUqpd3z0nHunCnn4Jxp8+yzZuG0vKpWNQncSZPyzyQWD2vWmFm1X39tyhKDyfU/+KCpUlG7tnf7J9emqDlFJW2vUkVL2s6aNYtBgwZ5uxtSwUybBnfcYerst2hhVsSsV6/gbRWjYnWKUbE6xahYnWJUrE4xWkadOuVZxmD7dvNz8WKIjDTb/PGP8H//5/m6mjXdCdnnnoM6dUq/71eo1GLU4TD1e50zcVetgnXr3LV7cye5333XrEztLMvQqtXlL7Msp7KyzGSlt94yH5lTx45mVu1tt5nceHlWUcbRouYUVR5BiuTChQve7oJUQMOGmXo9w4aZK246dTKJ3LZt82+rGBWrU4yK1SlGxeoUo2J1ilELu3DBLJhRr56p2wrw5pumPMHJkwW/ZscOd9J28GBTn9VZc7ZJEyiDk7dKLUZtNvNZ16tnMo3mzc0KWomJ7oQtmMXRZs6Ezz4zj4OCzBc+Z1mFm24q90ncw4fh/ffNzTmJ29/fTGB67DGTtK0oNI56UtJWRCytbVtzcnboUJO47dEDvvrKJHJFRERERERczpwpeBGwPXsgOxtWrDDJQDBZMWfCtnbt/IuAtWzp3m/fvuYmV8/fH9q1M7fcnn7aZCVXrjSLnJ0+bWbeLl8OlSqZ4q1O06aZtvbtzc8yzOEwv+Jbb5kSwNnZpr1WLXj4YbPuXHS0d/so3qekrRRJzdxnwkRKWb16sHSpOUk7dy7ccAP885/w6KPubRSjYnWKUbE6xahYnWJUrE4xWkqyskwS1pmQve02aNTIPPef/5iFwAoSEuJZi/bmm00Ct0mTMp8ALCpLxmjv3uYGJpO5a5e7pILdblbdcvrDH2DnTvDxMfXznAucJSRAs2am3eLOn4cvv4TJk2HDBnd7t25mVm0FmFh8SZaMUS9STdurVNFq2opYwYUL8Mgj8OGH5vHvfw9vvOH5/7iIiIiIiJQjmzbBJ5+4680mJUFOjvv5zz6DESPM/blz4YEH8i8CFhdnZtOWgaSeFCI72/w7r1hh6uXmlZBgkr1OZ85YauG3/ftN+d4PP4TkZNMWFGR+pTFjoE0br3ZPSplq2kqxWrp0Kd26dfN2N6SC8/eHDz4wJ9L/8hf4xz9g2TKzUNnOnXaaNvVh3Dhz0lzEajSOitUpRsXqFKNidYrRq5CZCbt3518I7C9/geuvN9scOJB/EbDQUHdCtnZtd3v//iY7JgUq0zHq5wdff23uHz5sZuI6Fzpbu9bMvHW6cMHUGYiOds/E7dQJrruuVFfycjhg4UIzq/bHH83EYYD69c1kpPvvh4iIUutOmVCmY7QEKGkrRXL69Glvd0EEMDXt//xnaNgQfvMbU/bI8GHTJlPy6H//U+JWrEfjqFidYlSsTjEqVqcYLYTDYcoS+PlB9eqmbcUKuOce2LfPncnKLTHRnbRt3Roef9xz1mytWuaLgVyRchOjtWqZOgI33WQeZ2fDuXPu53fsMHUI9u0zt6++Mu3+/iZx++CDJmNaQs6dMxPAJ0+GLVvc7X37mhIIw4bpatHClJsYLSZK2opImXTnnfD886aclZOz2Mvdd5v/EBs2hAYNPH9WrarjOxERERGRYpeVZWbJ5l0EbMcOOHsWXn3VzL4Ac9n63r3mflhY/kXAOnRw77dOHXjzzVL/daQM8fPzLIXQooUpj7Bmjbs+7qpVcOKEmfVz443ubQ8eNNNenbNxO3SA8PCr6sbu3fD22/Dxx5CSYtpCQ+G3vzUlEOLjr/YXlIqqQiZtf/75Z9544w3WrVvHkSNH+P7777kx9x+t5BMWFubtLojkc+hQwe2ZmTBjRsHPVa7sTuAWlNRVqEtJ0TgqVqcYFcsZP95MRXrhBSBPjL70kqlpOX68V7omUpAKMY46HHDkiDs5GxcHffqY53bsMLNiC+LjAydPuh83bmyuG4+Lgxo1NKuilFSIGHUKD4d+/cwNTOwmJZnkbdu27u1WrIBp08wNTCw2a2aSuAkJMGQI1K1b6NvY7TBnDrz1Fsyc6Z5I1LixSdSOGnXVOeAKqULFaBFUyIXIZs6cybJly2jXrh0333zzVSVttRCZiPe1bm3WJcg9itlsJvn67LPm/+SkJHNFTFKS52KxhYmIyJ/Idd5v0ACCg0vkVxEREZG8XnoJxo6FCRNcidtLtotI8UtJgX/+052k3bkTUlPdz99/v3uV4PPnzazY2Nj8C4E1blyqtURFiiwpCX76yV0fNynJ8/mvvoI77jD3d++GX36BTp1ICa3FlClmZu2uXe7NBw82JRAGDtS6d1I4LUR2CYMHD2bw4MHe7kaZkpiYSBstZygWM26cqWFrs5nErfPn3/7mLm+UW3q6WZcgdyLX+TMpCU6dMit5JifDunUFv2eNGoUndevVg4CAEvt1pYzTOCpWpxgVy3EmZMeOBbudxBtuoM3UqUrYimWVuXHU4TCXruUtaZCQYP7GwFx2Pnas5+t8fc0BcFyc54zF4GAzm1azZi2rzMVoaWjYEJ54wv34+HF3OYVVq0zJBKdvv3WV+Ei11aGWoxPXk8CmkE60vrctDz4ZQuPGpdz/ckYx6qlCJm2vRmZmJpmZma7HZ8+e9WJvSt/Bgwf1hyOWc/PNZtGxCRNg69Yc4uN9GTeu4IQtQEiIudKlWbOCnz97Nn8yN3dSNzUVjh41t5Ur87/eZjOL1xZWeqFOHRWcr8g0jorVKUal1DnPuIL5T/ibb8xl10ePev7084Px42n58stmsZnnnoNJk+CDD0yxwNBQ85+8837v3uaaVDDXrb7+uvv5vD+jo6FRI3efsrPN+4lcBcuOo2lppr5n7drmcWYmdO5sZs2mpeXfPivLfT80FJ580vytOOvOxsQUPlNBCVtLs2yMWklUFAwfbm4X5eSY6gn7poTTi1a0YDN1HL9yG99yG99COvCeLzy8EWhuXnTunPm/RtNtr4hi1FOFLI+Qm81mK1J5hPHjx/Piiy/ma//qq68ICQkBoH///iQnJ7N+/XrX8507d8bPz48lS5a42lq1akXt2rWZOXOmq61Ro0Y0b96cuXPnkpGRAUBUVBQJCQmsWLGCkxfr/4SEhNC3b182bdrEvn37XK8fOnQo+/btY0uupQl79uxJRkYGq1atcrW1b9+e8PBw5s+f72pr2rQpsbGxTJ8+HfvFlTvr1q1LmzZtWLRoEampqdjtdiIiIujWrRtr167lyJEjAPj7+zNo0CC2b9/OrlzXBAwYMIATJ06wYcMGV1uXLl3w8fFh6dKlHp9FrVq1mDVrlqstJiaG+Ph45syZ40qUR0dH07FjR5YvX05ycjIAoaGh9OnTh40bN3LgwAHX64cPH86ePXvYunWrq613796kpaWxevVqV1uHDh0ICwtjwYIFrrZmzZrRuHFjpk2bhvNPo169erRu3dr1WQBUq1aNrl27smbNGo4ePQpAQEAAAwcOZNu2bezevdu1z4EDB3Ls2DESExNdbV27dgVg2bJlrrY2bdoQHR3N7NmzXW2NGzemWbNmzJ49m6yLB081atSgQ4cOLFu2jFOnTgGm7kuvXr08PgubzcawYcPYvXs327Ztc+2zT58+pKamsmbNGldbx44dCQ0NZeHCha62+Ph4YmJimDp1qqvN+VksWLCAtIsHeBEREXTp0oXVq1dz7GL9gcDAQAYMGMDWrVvZk2ulsEGDBnH48GF++eUXV1u3bt2w2+0sX77c1XbdddcRGRnJnDlzXG2xsbE0bdqUWbNmceHCBQBq1qxJ+/btWbp0KcnJyfj4+Lg+i8TERA4ePAiAj48PQ4cOZdeuXWzfvt21z759+5KSksLatWtdbQkJCQQFBbF48WJXW/PmzalfvwFffz2HY8dCOH48hKys2mRk1GTt2pMcORLIsWMhZGVdOiPr62unevXzREen07ZtBBERZ3E49hIVlU50dDrXX98Ruz2bFStWuF7Ttm1bIiIimDt3rqutSZMmxMXFMXPmTLKzswGoVasW7dq1Y8mSJZw5cwaA8PBwevTowfr16zl0sQCwr68vQ4YMYefOnezYscO1z379+nH69GnW5Zpi3KlTJwIDAz0+ixYtWlCvXj1m5Coa3LBhQ1q0aMG8efM4f/48AJGRkXTq1ImVK1dy4sQJAIKDg+nXrx+bN28mKddlR0OGDOHAgQNs3rzZ1dazZ08yMzNZmSs73q5dO6pWrcq8efNcbXFxcTRp0oQZM2aQk5MDQO3atWnbti0///wzKRdXAKhSpQrdu3dn3bp1HD58GAA/Pz8GDx7Mjh072Llzp2ufJTWW//jjj/hcPGjz1lgOULVqVY3lGssLHMuTk5OJjo726ljuXDG4pMbyBg0aMH36dFdbgwYNaNmyJfPnzyc9PR2A6tWr07lzZ1atWsXx48cBCAoKon///mzZsoW9zoVzMFdvHTp0yOOz6N69O9nZGssBerZrB9Onc2D1agJPnybo9Gki7XYCkpO5cOAAv/buzdb77jNjeaVK7oRSARw2GzaHAwIC2PjTT7QeNKjQbQ/26UPk9OkkJyezccUKhtx2W6Hbpg0aRODUqWYsdzgYdtNNOHx98QkNJcPPj+yAAHICA/GpVImwoUNZcf31ruPylp9/ToNGjTiamsrJ8+fJCQwkJyiINl27csRmY32u5G+vuDgygFWbN+Pw8wObTWN5ORzL7XY74eHhXhvLa164QPtKldg/Zw72bduodOgQYYcOEXTyJOe6dGHhs8+6Xj/swQexHT2K3deX9Bo1OFe7NlUSEsiOiWF9Tg4psbGAxvLyNpYfO3YMHx+fCn9cXtQcS2LiAd56K50ZMxpw/LjJ+/j4OOjZbg/3tpxFuwtraHTiOIEbNmA/fZqZX36Jw9/fjOWvv07WV19xJjaW03Fx+HXtSszdd7Pol180ll9iLM/9nak8H5enp6dz5513XrY8gpK2RUzaFjTTtm7duhWmpu306dMZOnSot7shUihvx6jDYa6kyTs713l//364eExbqMBAqF+/4NILDRtC9eqavFCWeTtGRS5HMSpFkp5uFg9yXnqSd2bs7bfDxIlm2yNHoFatwvd1113wxRfmfnY23HCDqUNUs6bnz2+/hUmTyPHzwzc729RHuuMOM0MwLc30Kff92Fj3wjNpaaa4oHObvD+HDjX1OgEyMi5dvP7GG+H7792P/f1NvwvSpw/kSsZSrRpcTGTh6+s52zchAT7/3L3tmDGmNmju2cPO+7VqwfXXu7fdssXM4sq9TVCQDhi8pFTG0dRUM0N2+3Yzk/w3v3E/V726qfNVkOuug1yJL5YtM9s3amRiWSoE/V9fNBs3moXFPv/c/NcAZhh/4AF4+GHz/cyD88tgdLS7rX37gmvuxcaame4ffaTLMAtQUWK0qDVtlbQtYtI2Ly1EJiJXwm6Hw4cLL71w8KDZ5lJCQwuvp9uwIVSpUtK/hYiIlEuZmaZuX95ErPP+jTfC+PFm26NHTTK1MHfeCV9+ae7n5JjkZY0aBSdj69QxK4BeSt5Fx0pyETKHwyRW8yaBnfejoqBbN7Ot3Q7PP19wIjg93XxZf/NN974rVSr4MnSAXr1MItwpMtLUBS1Iu3aQayYijRrlXzTHZjMJ3FatINfsdx54wPz7FZQMjooymQin5cvNJfIFbRscrMt9S9OHH5pkq7Pu7MWZiYD59891JQR9+ph/47yLgMXFmYyTiBTqwgX44QeTrM01iZc2bcy5v7vuusJFqS9cMIuWORc4W7XKnHABk7jNNaOYJ580CdxOncyJvLp1dfKtnNNCZFKsdu3aRezFS2RErMjqMerjY76b1qkD3bvnf/7CBfj118KTuocPm+96W7aYW0HCwwuvp9uggfm+KN5j9RgVUYyWMxcuwObN+ROwzp+DB5vasGBqXfbsWfi+mjZ134+MNInD6GjPBKzzfv367m19fSHXpbxXLE+CdteuXcTmXpwMijdxa7OZxFZRkls+PvDqq0Xf97lz5t+koCRv3izAhAnm36SgxHFMjOe2VapA1apmG+dVgQ6H2dY5Pcxp0SLPBF9uMTGeSdtHH4Vcl516iI42ceQ0cqQ5OCmoZnDVqp6f09y5ZuXXvNs579eoUfB7WtX48SbOL8ahxzj60kvmxIXzhEdBUlI8FwDbscMky3/80b3Nv/4FuS4/BkySPS4Omjf3rA09f74SPXJJ+r8+v+PHTYn0994z6/KB+bO+5RaTrO3a9Sr/rPz9zf+X7drBI4+YtlOnzN/zxTIegBkn/v1v8/+EU40a7gRujx7QpctV/35ljWLUU4VM2p47d86jHkZSUhKJiYlUq1aNevXqebFn1rV9+3b94YillfUY9fd3J1wLkplpSiwUVHohKQlOnDDH/YmJhX/Hql698Fm69eubqyml5JT1GJXyTzFaBuTkmEG/oMW6jh41s+yeftpse/q056rueeWuH1u9ukkARUUVPCM291LYvr6eMz1LUk6Ox4xaV4w6E7UXayaWGf7+Jsl6uUtjcidPLyf35e7Z2aasgjPRm9f//Z+5dL6gxHHeRHWjRubgI3fi+GJ9TC6u5+GyZUvBlwCDia3cSdtXXzXJ44IEBLgTzwD33GOS/gXN9g0NhSlT3JcW//ijOTAqKHEcEgItW7q3tduLb6awr6/HCQRXjOY+4ZCTY86+163rft1DD5k+505+O/n5mQS/s2TBPfdA376es2YLiyElbOUy9H+925o1Zlbt11+7196LioLRo83tEmXWr161apC3JntODrz9tntG7i+/mLHhhx/MbdAgyFWrly++gNatzera5fCqB8WopwqZtF27di29e/d2PX7qqacAGDlyJFOmTPFSr0REChcYCE2amFtB0tLMd5WCkrr79pnv7idPmluu+ugeatYsPKlbt67KnYmIlAi73UzzKagswdGj5nL8xx832546ZS6pLExYmPt+9erm8o7IyPzlCWrUMIkfJ19fc+m11VxqhmJxl0YoD/z8TAzkjoPcbrih6Pv63//yt9ntnjN6nd55x5w9LqhMRN6Dh+uuMz8LKkGR9+zxkSPmMqSC+PnBp5+6H3/8sefs1LzOn3cnbUeNMiU8CprpGxpqfnfnparffmsS4wUlgkND3SdJxo6FjAyqVKli+vL99yah8tVX8PLLJpmalubuw9mz7oRtjRruZKzzlttjjxX+e4nIFcnMhG++gcmTTY7UqWNH86d2223me1epCgiA3/7W3MCMievXu5O4PXq4tz16FEaMMPfDwkzHExLcs3Kjokq581LSKmTStlevXlTwUr4iUs6Ehpor5Jo3L/j5lJTCSy8kJZnvEUeOmFvu8ndOzvIOBZVeaNjQrIuiOvoiIrmkpRU8G/bIEfMl66GHzHanTl26RqzD4U7aRkSYWjjVq+efDVuzpkkSOfn4mILpIsXFx8fUWspbb6ljx6Lv4+9/L/y5vN/P/v3vwmcG513dtUcPk/QtKHF8/rxnFiYtzcxKTkkxt7z8cn1FnjYNPvmk8D4fOeI+gTB2LB4VsHKtLE5QkNm2Th3z+M9/ht//3pyNDw8vfP8iUiwOHzblD95/35wnBZMrveMOs/bjlQxjJS4kxJywddZQz+30aVMHfc0asyjh/Pmei14+95w5UQRmnMvJ8UIWWopThV+I7GpVtIXI0tPTCcl7KZSIhShGr57DYb4TFVZ6Yd++/JNq8vL3h3r1Ck/qRkfrij3FqFjVd9/Biy/Cjh0O4uJsjBsHN9/s7V5ZVE6OuWShoFmxrVvDffeZ7ZKTTWK1MLfcYmbwgZm9GBJiLnfOWx+2Rg1o0cKUPRCNo1I8UlNNsrag2b7p6Wa1Ieclx19+aWa7Fbbg3JIl7iS2r6/5e7bZzEmZ3OUM6tUrl5cxS9lTkcZRhwOWLTOzav/3P5PDBDPZ5OGH4Xe/M99RyqTsbNi61b3A2cqV5kTRJ5/Ab35jtlm+HHr3NiupOWfiJiSY8jcW/mJWUWJUC5FJsUpJSakQfzhSdilGr57NZnIL1aubxa7zstvh2LHCSy/s328mvOzZU/j6JkFBJolbUOmFBg3M5DELHzsUC8WoWNF335n8oc0GDoeNTZvM4//9r4IlbvPOinXeb9bM1JMEM7slMrLwOqq33OJO2latas5m+fub5GveZGzr1u7X+fh4XjYthdI4KsXiUiUk8rrrLnO7nJdeArsdR0AAtqws83f+xBPX1k+RElARxtHz5835lrfe8lzro3t3UwLhxhvLQdk3Pz9o1crcHnzQtKWkeF4psG6dKda7erXnYobVq5vk7fPPm2SuxVSEGL0SStpKkaxdu5bhw4d7uxsihVKMlhwfH3fOoXPn/M/n5JiVVgsqvbBvnylHl5FhyiUWVjKxUqXC6+k2aFA+rhxUjMq1cpaTdE4My7uo/JXcnK/bt8/s23ndlfPn3XebdXucpR7z3nKXgSzKLSDASx/YyZP5yxPExJiidWDqStapY2beFeTmm91J2ypV3DPpIiPzlydo1879Oh8fk+QNDS1aX5WwLRKNo2JJuRYdm9amDcMTEz0WJxOxkvI8ju7fb0psf/ihqTwEZuLIiBGmBEKbNl7tXsnL+4VpzBgYOtQ9E3fVKlMr9+RJmD7dlGlxmj7dnLF31sdt3twzAVyKynOMXg0lbUVE5Jr4+pqr/urV86yT75SVZcoqFpbUPXIEzp2DTZvMrSBVqxZeeqF+/aLnRURK2oULV59AvdzNuXB7acjMhLVri29/fn5Xn/DNmyyu5JNO5fSjhJ47SsiZIwScPopPvbpw/fXmzc6dM5cjHztW8KzYm25yJ23DwtxLRgcH558V26GD+3U2Gxw4YC4NKMoXGQ1MIuVfroQtL7wAU6d61LgFlLgVKUEOByxcaGbV/vSTOa8K5vvBo4/C/fdDtWre7aPX2GymFEKjRu4rBjIzzfTjlSuhbVv3tjNnmkUUP/7YPA4JMcdAziTugAE6rvESJW1FRKREBQSYiW0xMQU/f/68yYMUVHohKcmcDD592tzWry94H1FRBc/SbdjQJJNVf1+cHA4Tc8WRRC3odXnXxikpBS14fjUJ0Pvug927Pdf/cR7jT5p07Z+Ns37cpdb8AbBhJ4JkanKEGhylJkc4Sg3mMBCAYNLZwHXU4CjhnM33+p98b+SBateb3y0klHVHkgl05GDHRmpgdc6G1ORcpRqkh9fk2IUEtv/d+TnYiPzHVvxqVCcoMozQSrZ8n5PHwXKZLX4nIiUiJ8edsM3N+biwcioick3OnYNPPzX1ardudbf37WtKIAwbpotYChQY6K5tm9udd5pZMitXmlIKZ8/C4sXmBmaWjTNpu2KFGdvatTMnvKVEaSGyq1TRFiI7fvw4UVFR3u6GSKEUo+VXaqq53KmwpG5hSSAnm80sOFBY6YW6dUvn6h/FaNFlZ197ArWw16an51+gvCT4+l5dErUo2wUHF9N6NuPHs3WHL82/euFiTVtcP7fc+RLxcTkwfvw1vUVWynnOJx0lc/9Rsg8eIS2wGsea9TIzh0+dp/tfuhN45ijBZ4/ha8/2eO2aWjcwvs0P5t/xnIOf14UQ5MgA4DxBHKEmR6jJUWqwgs78H390vbYlv5BMBMeJIptrK1zn739tM4Mv9XxQUPmv512cNI6K1SlGxerKeozu3g1vv20mhDq/A4SGwsiRZmZtfLx3+1cu2O2mpp2zpMLBgzBjhvv5wYNh1ix3XV3nImedOkFs7DUf2JT1GC2qouYUlbS9ShUtaXv27NkK8XtKGTJ+vMmKXJzJ4BGjL71kzv5dY7JByobTpwsvvZCUZJJ0l+LraxK3hSV1a9UqngRZeRpHHQ5zdVVJlABIS3NfrV7SgoKKr2Zr3tcFBJSBZNzFy3q33jmBu7e9wPbtDpo2tfFFs5eI/2pswbPHwBzMJye768SGhbkLXmdmwsCB7sW88p5Vuf56+PFHc9/hMB9W7roPkZHuOrFdu7ovLwYzs6NaNfNcWBh2h+2ScXWt9X5LY4Kcj0/BsXatJSSc98vbLKPyNI5K+aQYFasrizFqt8Ps2aYEwsyZ7vbGjU3Z1lGjysf6F2XGffeZf4ijR/M/V7+++QLmPAjOyDAH3FegLMbo1ShqTlHlEaRIFi9erGLQYi2+vh61wlwxmru2mFQIVaua23XX5X/O4TDlFfImcp339+0zCULn/UWL8u8jIMAcfxRUT7dBA1Oa4VLJue++gxdfhG3bQmnWDMaNM2sblbScnMKTVsUxe9VZM6wk+fgUbwIrb3t5S2hdsYsJ2fixY0mcANObNWPo8uXwj3/Aww+7E7YXLpigdS7kdeyYu+4BwPDhppAcmD+YNWs8z5YEBrprxTZt6m632czrqlQxz0VFXXo55zwrIfrYzCKGlSpdw2dQCIfDjA0ldWIiM9O8j91uLvE8d674fwcwH31JzPYu7RMT3hpHRYpKMSplRVn6Xp+SAlOmmJm1u3a524cMMSUQBgwopiuP5Mp89JE5UDp40HORs3XrTH2t3AcHrVubbZ0zcRMSzOzc3CvU5pmM5RGjmoylpK2IlFF5F3lo0yb/YhBS4dlsZuJeZCR07Jj/ebvd5KAKK71w4IBJ3Oza5XmwmFtIiEneFpTU3bTJnP03l5z7smkT3HKLWZz1ppvMvov78n/nLSOjpD5VTwEBJZMQCg01CSfLz1Ytq7KyzJSV/fvNVPOxYxma+/mDB933/f3NKh9paZ77qF7dzIqtX9/dZrPBl19C5cruxbzCwwv/h+zXr7h+o2Jls5n4CwwsmQVMcnKKb0ZwQTfndXSZmebmXEW7OOUtAVKcJ1dCQtxfxL/7zoybBY2jSoqJFShGRYrX1q0mUfvJJ+5Dj8qVzQTPRx81M2zFy2w290rUzsVdL1wws2WczpwxX6AcDvPzs89Me1CQWQTt1lvh97/PNxnLRZOxACVtRaQsyM4233Cdq0kdP25mZwUEuC6fHerjYzJwDzxgTr2KFIGPjyl/UKuWCaW8srPh0KHCk7qHDpnEydatnosg5OVMoDh/3nabOdYpjcuvbbaSvfy6NOoBy1XIzISdO01Nsm3bzK1uXXj9dfO8v7+ZtVDQFM8GDcyZjtw+/NBMaXUmYqOjC58Ve/31xfmblEu+vuYLaElc/edwmJM2xV02wvlaZ/mSnByzTsnZ/OvCFYvgYDPGOCts5B1Hf/Mb+NvfSua9Ra7Exo3mZ94YfeIJc6jqPM6IitKsQJHC5OTAtGnmfPL8+e72+HhTAuE3vymZK2ukGPn7myunnKpUMUnc1as9Z+SePg3Ll0Pz5ma7F14wATB2LPz8s8nMazKWi2raXqWKVtN27969NGrUyNvdkPIgJ8cM1CdPmulLziLj+/aZU6onT5paiSdPum+nT5tEw9NPm23XrYP27Qt/jz/8wf1N7vRpeP99iIszt5gYd/JX5BplZpoJiYXV0z12rGj78fMr/sv/nbfgYM1WLdcyMz3HtDvugPXrYe/e/DUs4uNhyxb34z//2bx261b45hsc/v7YLlzQAbJc0oULV5b4vdJtRcorPz9zzqt2bXci13k/d9ulLk4QuVZW+16fnAz//je88465+AfMyY3rrzfzcHr31t9DueKcdbtqlfle3qWLaV+7Fjp0MJsEBGDLyir3x6OqaSvFqkGDBt7ugliRMwGbO8natKlJjoJJBPz5z+7nkpPNNZrOc0V//Sv86U/m/qlTl54yk/tSi1q1YNgwc2nuzp2wfDkOHx9sdruZtpS7ZuLmzaYPTj4+5rr1uDho0sRcllHQFEuRIggMNJdoFXaZVsuWJkeW+/SozWbCb948d2L1UmU8RXA4TD1Z54zZbdvcM2ijo2HDBve227ebpZXBfPNv1syMic2amYDMbeJEM5Phm29gwgQczz2H7ZVXCr5ETeQif38TWiWx6Ivdbtaly53svfFG2LMn/zhavz5MmlT8fRC5Uk88Ycop5Z0KVbmyWUj90CF3KfBffzW3SwkJyZ/IzXu/Zk1zUlbkSlnle/3GjWZW7eefu0t6VasGv/udKaufu/KSlCM2m/kO3qSJZ3vNmiYX8MwzJmEbEKDj0IuUtJUimT59epkpWC5XyW43dWdyJ1id93v2dBcEXbPGXJ9y8qRnAtbptdfgmWfM/cxM9+I0eYWHe84Cq1sXnnrKJGJz3yIizM/cRQVr1oSpU02yYcoUmDCBaW3aMDwx0SQbDh92b1upEowYATt2mFtqqvn2t2cPzJhh/sNwJm3XroWHHnIndJ2zc5s0MZk1kSv04ou569y5f776qvnSJeIhO9tM0T582Iy7TgkJZuwtyJkzZix1XnP7xhsmq9a0qZnSdanpKXkuPZs+dSrD89YL1wGzlCLn4oO5/8v9618LHkf//ne44Qbv9VXEKSen4BidMsXUrwczvB87ZhK4hw+7f+a9f/q0OWGxe7f7/FthqlUrPKnr/BkVpTJG4smb3+svXIDvv4fJk2HJEnd7mzZmVu1dd+lkRIVVu7YZ/HJyyPHzwzcryxyn6jhUSVuRcisjw1y3nbfUgPPx7bdD//5m20WLoG/fwpeDnzjRnbT18zPJz9zCwz0TrE4NG5rSBAUlYPNOLYyMhP/7v6L/fnnr3Eyd6rk4mc1mHl93nbvoucNhVp1yJnB37nRfkgFmVu66deaWV5068M9/uo++U1JM0rpePS1BL4W6+WazEMmECbB1aw7x8b6MG+cOI6nAtm2DxETP2bO7dpmCoWFhZoxxJlzr1DHjUkyMe9as89a0qWeRxAEDit6HnJyCLz1zPi6Nossil6FxVKyuKDHq52dyEpc7YZuebi6sKCipm/tnRoY5DD11yhy+FsbHx1yQUVAZhtxtVavqEnQpOcePwwcfwHvvmfgF8zdxyy0mWduli+Kvwsv13X5G7slYUOETt0raipQlJ0+aAt55E7HOZOzjj5vL/QGWLbv0qtwxMe6kbZUq7oRt5cru5KrzFh/vfl2TJibJ60zCVqtmLl8oSJUq8OCD1/hLF+Jqkg02m5mlW7Mm9OqV//lBg8zpX2dC15ncPXnSXMuWe+rP1KlmxnFgoLn2LffM3Lg4cxmyZucK5svczTfD1KkzdMVCRXPqlLuUwd698PLL7m8lTz8N06fnf01wsBmfU1LMGArm5NeXXxZ/Pe7x4wt/roIfIIu1aBwVqyuuGA0JMf8FxMQUvo3DYS6yKCyp67x/9Kg5HD5yxNwuJTDw0kldZ5sObeVKrF5tSiD897/uRSyjomD0aHPTVWcCXH4yFlTo41IlbaVIrFL7psxzOMwXcX9/91HPvn3w3XcFL8B18qS5jvr++822v/wClzoQHDzYfb96dTNbK+8sV+ct96W38fHmCC8iovAErFNoqOdrvSVPssEjRq92UK9RwxTPy+vUKZO8da5w6WwLCDAlIDZvzj/NYfp0GDLE3F+92iS6nQndRo0u/zlLuaNxtAL48UeYOdOdqD1+3PP5J55wL76YkGC+deeeMdusmSnilnd58cjIUum+YlSsTjEqVlcaMWqzmZmxVat6HprmlZNj/hsqqAxD7kRvcrI5nHUupnop4eGXr7dbo4Zq9VtZScdoZqYplf/WW+YrkFNCAowZA7fdpjWhJY88k7FcMaorvwCwORx5C1JKURR1pTcpxxwOUx/VmVytV88cpYBJ4L31Vv6SBMnJpqjV+++7Z6AuWGBKExTmlVfgL38x97dvh3vuKbjma/XqpiBQbGyJ/tqSS06OWeY078zcHTtg8WL3NIkJE2DcOPfrfH3di6HFxZkZ0qq2L2JtFy6YWth5FwObM8d8cwZ48kl4803P19Wt607MPvOMmekvIiJiERkZZlbupertHjpkFgYsCpvNnJ+81Izd2rXNV5i85yil7Dp0yJQ/+OAD9znrgAC44w5TAqFDB+/2T8RqippTVNL2KlW0pO38+fPpe6nEYlnnTMDmnumanGxOCTqToCtXwp//7Pn8hQvufbz3nrnOA2DhQujTp/D3y71Y19695ixSQUnYiAiTDHYmBKRQlo7R776Db791J3fPnfN8fts2M8sOTN3cTz/1LLUQF2fiMCSk9PsuxcbSMSpu585BUJB75ZYPPoB//MOsCJOdnX/75cuhc2dzf84cc8LGmaSNizOLIZYRilGxOsWoWF15jtGzZy+9iNqhQ6YMQ+6vR5fi7+9O4l6qNENYWMn+XhVNccaow2Eq8r31lvm64zxMql0bHn4Yfvc79wVGIkVVnsfR3IqaU1R5BCmS9PR0b3eh6BwO86W7sAW4brwR2rUz286ZA6NGmfaCjjDefdedtM3IMJe45xUSYhKsuRejatLELBuftySBMxEbFOTetlEj+PzzYvrlKy5Lx6iz0BmY+Dx82HNmbqNG7m3Xr4e1a80tr7p14eefwXnJyP797nZNVbA8S8doRXTihOesWeft4EFYswbatzfbZWaaGbVgysPkLmXgTMw6DRhwZQuBWYxiVKxOMSpWV55jtHJlc3POMyiI3W6+Vl2u3u7x4+ar1/797sPZwlSqdOkZu7VqmYtYdMl90RRHjJ4/D198AZMnmzVVnbp3N7Nqb7xRJTLk6pXncfRqKGkrBRs/3iQhC6oN+tJL5rLwSy1gUtzOnjWrahdU9zU5GR55xF1n9bvv3ItxFaRWLXfSNiDAszJ/cLBngjU62v1cixZmIZjcs2EjIgqe/Vi7trtotkhuNpt7+eDevfM/P3Ys3HCDZ6mFHTtMDd1ff/WMyQkT4KOPzEmA2FiTPMq9IFq7du7ZgiIVkd1uvg1u3w5t27r/ft56y5QlKczu3e6k7fXXm7+nZs2gTh0tbywiIlIIHx8zszIqylRtK0xWFhw7dvmSDGfPmrk4O3ea26VUr375xdQiIz3n2ciV2b8f3nkHPvzQfDUB8/V5xAhTr7Z1a+/2T6Q80rd5KZivr8dKfdWrVzf3c6/sd6UcDnNzzgj89Vcza7CwBbheeQWGDTPbzpsHt9xS+L579XInbZ19DQw0/zPnLTkQH+9+Xbt2ZmbjpRKwTtWrw513XvnvLaXCFaNlXaNGnjNvnZKTTSmN4GB3W2amOY2dkQGbNplbbufOuZO2n31mTlDkXgxNp8BLVbmJUas6ftz8n5J71uyOHWY6CMBXX5nCamDqTdtsZtZ67lmzzlm0ERHu/davX2FqTitGxeoUo2J1itGiCQgwF4rVrXvp7c6dM4evhSV1nW2Zme6vkL/8Uvj+fH3NrNzLLaYWHl5+z9FeaYw6HGYJlsmT4aefzPlwMIdQjzxi1suuVq34+ykVl8ZRT6ppe5UqRE3b3AnaF17I/zg93fzPWLWqu9jQli1muci8JQmctylT3F+av//efcl4Qd5+2/xPAKZYzh13FFxqoHp1M2OxRQuz7YUL5vRtSEj5/d9WxCk7G/bty78QWlqa55KtvXt7lvfw9TWJW2cS9/XXVWJBrO/sWc+k7I03uuvJ/vijeZyXv7+ZgT52LNx+u2nLzDRXjKhOtIiISJnmcJhZn5ert3vsmDvheDnBwZeeseu85Z5LUd6cO2eW2Zg8GbZudbf362dm1Q4bplnLItdCC5GVsAqRtAVXotZhs2FzOKBGDTNzLzm54NlLl0vETp4Mjz5q7q9fD08/nb/uq/Nxy5bmf0ORIli1ahUJCQne7oZ1/eMfsGqVezG03LWCatTwLBNy661w4IDnQmhNmmgxtGukGL0Ke/bApEnuJO3hw57Pv/IK/OUv7m3vvjv/rNlGjVQmpIgUo2J1ilGxOsWodWVnm8Tt5ertnj5d9H1WrXr5ervR0dY6DLlcjO7aZUogfPwxpKSYttBQGDnSJGubNSuljkqFVVHGUS1EJsXjhRdgwgRszqUgjx71fN7f38zoc4qLg4ceyl+SwPm4Rg33tm3bwvz5Jf87SIVw/Phxb3fB2n7/e/d9u90cmTpn5Tr/vp1Wr3YvxpRX27awbp378fr15m9bi6FdlmI0j5wcSErKvxDYb3/rvsri/Hlzsi+3mjXdJQ06dHC3x8SYExNy1RSjYnWKUbE6xah1+fm5l5W4lPPnPUsyFFaa4fx5k+A9fdpcbFoYHx+TuL1ccrdatdK5SLSgGLXbYfZsU/J/5kx3e2ysSdSOHGlKRoiUBo2jnip00vbtt9/mjTfe4OjRo7Ru3Zq33nqLjh07ertb1vLSS5Cdjd3HBx+7He65xyze4kzEVqrk+b9LfDy8+673+isil+fjYxZUqlMH+vbN//zMmWbhpryLoZ05k/86sFtvNYm34GD3YmjOW/PmcN11pfIriYWdP29uzoJn+/aZxb127jRlCvLKXXc8NtZckZF75myVKqXRaxEREamAgoMLX2LCyeEws1AvldQ9fNgkf3NyzM8jRzznPeQVGFh4jd3cP0NDi+93TUkxM2rfftuswQrmq/3gwfDYYzBggOZkiHhbhU3afv311zz11FO89957JCQkMGnSJAYOHMiOHTuIiorydvesIVcN2/mdOtF/5UrzuEkTMwNXxEKCgoK83YXyo3lzc8vN4TB1qZ3XSYE5Cg0ONjPuz583Kz/kXv0hIQFWrnQ/fu45k7hr0sQkdRs2rFCLoZX7GD192nPG7Pbt5mdSEjz4ILz3ntkuMtK9aF5QkIkFZ0K2WTMzm9spMNDUW5ZSUe5jVMo8xahYnWK0YrDZzDnkKlU8zzXnlZMDJ05cviTDyZPmPHZSkrldSuXKl6+3W7Nm/kPs776DF1+EbduG0LChOQxfutR90Wx4ONx3n7nYqXHja/l0RK6NxlFPFbambUJCAh06dGDyxcsu7XY7devW5bHHHuPZZ5+97OvLfU3bvIuOXa5dRCqu7GxzhJl3MbS2beHvfzfbOBcHzMlxv87Pz1zSHhcH/fub66/E2hwO8+1i2zaz9HPPnqY9NdV8iyjMkCEwfbr78bx5ZgpL/fpaxUJEREQqtMxMMxO3sEXUnD/PnSva/mw2c47cmcjNzDSHXgWJjzezau+5x1xEKyKlQwuRXUJWVhYhISF8++233JhrpemRI0dy5swZfvzxx3yvyczMJDPXZZxnz56lbt265TdpO368+SJ9MTG7ZcsWmjtn3r30kkm8jB/vte6J5OURo2I9586ZGZPOhdDyLoZ2993w+efmfk6OKd1Qv757ETRnyYXYWDM7swwqczHqcMCPP7pnzDpnz6ammuf79YO5c93b16ljviXkXgjMeYuMLJ1CbXJNylyMSoWjGBWrU4xKSUpNvfSMXef9CxeKtr+YGLPwmA7RxEoqyjiqhcgu4eTJk+Tk5BAdHe3RHh0dzfbt2wt8zcSJE3nxxRfztc+cOZOQi6up9+/fn+TkZNavX+96vnPnzvj5+bFkyRJXW6tWrahduzYzc1X5btSoEc2bN2fu3LlkZGQAEBUVRUJCAitWrODkyZMAhISE0LdvXzZt2sS+fftcrx86dCj79u1jS64q6D179iQjI4NVuRZmad++PeHh4czPtQBY06ZNiY2NZfr06djtdgDq3ngjbdq0YdGiRaSmpmK32zl9+jTdunVj7eDBHDlyBKZOxd/fn0GDBrF9+3Z27drl2ueAAQM4ceIEGzZscLV16dIFHx8fli5d6vFZ1KpVi1mzZrnaYmJiiI+PZ86cOa5EeXR0NB07dmT58uUkJycDEBoaSp8+fdi4cSMHDhxwvX748OHs2bOHrVu3utp69+5NWloaq1evdrV16NCBsLAwFixY4Gpr1qwZjRs3Ztq0aTjPZ9SrV4/WrVu7PguAatWq0bVrV9asWcPRi4uzBQQEMHDgQLZt28ZuZ1EgYODAgRw7dozExERXW9euXQFYtmyZq61NmzZER0cze/ZsV1vjxo1p1qwZs2fPJisrC4AaNWrQoUMHli1bxqlTpwAICwujV69eHp+FzWZj2LBh7N69m23btrn22adPH1JTU1mTa5Gpjh07EhoaysKFC11t8fHxxMTEMHXqVFeb87NYsGABaRevpYmIiKBLly6sXr2aY8eOARAYGMiAAQPYunUre/bscb1+0KBBHD58mF9yXULfrVs37HY7y5cvd7Vdd911REZGMmfOHFdbbGwsTZs2ZdasWVy4eCRSs2ZN2rdvz9KlS0lOTmbv3r2uzyIxMZGDBw8C4OPjw9ChQ9m1a5fH33jfvn1JSUlh7dq1rraEhASCgoJYvHixq6158+Y0aNCA6blmCjZo0ICWLVsyf/580i8mH6tXr07nzp1ZtWqVq4B6UFAQ/fv3Z8uWLezdu9f1+sGDB3Po0CGPz6J79+5kZ2ezYsUKV1vbtm2JiIhgbq7kWJMmTYiLi2PmzJlkX1xErFatWrRr144lS5Zw5swZAMLDw+nRowfr16/n0KFDAPj6+jJkyBB27tzJjh07XPvs168fp0+fZl2uYludOnUiMDDQ47No0aIF9erVY8aMGa62hg0b0qJFC+bNm8f58+cBiIyMpFOnTqxcuZITJ04AENyjB/0mTGDz5s0k7dlDUHIylQ4dIqFKFY6HhbHmYqyFHDlC36NHzcKHeRaWcths7B80iE0PPwxAXGwsTX79lQWHDpFWtSrYbNSuXZu2bdvy888/k3KxnEOVKlXo3r0769at4/DhwwD4+fkxePBgduzYwc6dO13vUVJj+e7du10xUGpjed26HmM5QNWqVc1YvnYtx5OSqHToEOGHD9M6IIAT586xMled42G/+x22i///uP4N/PywN2zIr76+/HLx36xVq1bU2raNWYsWubbTWF72xvLk5GTS0tK8Opafvrhst8ZyC4/lwcH069fPjOW5ruMdMmQIBw4cYPPmza62nj17kpmZycpcpXLatWtH1apVmZdr2ldcXBxNmjRhxowZ5Fy8IqOgsdxut9O8eXOvjuVeOS6/zFh+5MgRAB2XW2Ast9vtnDhxosIfl2ssL7mxfOfOxRf3B1275h/L69dvSM2aLfjuu5UcPmzj1Kkg3n23FTk5+TOzhw7Bli2lP5Zb4bhcY7l1x/Lc35nK83F5eu4JTJdQIWfaHj58mNq1a7N8+XI6d+7sav/Tn/7E4sWLPf4AnSrcTNs8pk6dyvDhw73dDZFCKUbLkQsXPBdCy1124cwZeP55M+MfYP9+aNDA3A8Jcc/Kdf7s2NHMzrUAy8To2LGwerX5jPfv93yuQQPPYmq/+52pV5x71mxMjCmNIOWOZWJUpBCKUbE6xahYUevWZjmB3Jkfmw1atYJcOS8RS6go46hm2l5C9erV8fX1dZ19dDp27Bg1atQo8DWBgYEEBgaWRvdERCo2f39o2dLccnM4zGoOua/hOn3aJGf37DHlFhITPY8+n30WJk40948dMwlLZ6mFuDiTpPQrJ/8V2u1w8KDnYmDbtplyE7lmzDBnjucM5urV3QnZ+HjzOTs/43/9q3R/BxEREREpVuPGwS23mMM752Gew2HaRcTaKuRMWzCXWnTs2JG33noLMJdb1atXjzFjxmghsgJkZ2fjV14SG1IuKUYruAsXzAzRvLNzx4yB224z2yxYALku/QdMgrhxYzMz98EHzYJZ4Jm4LCbFFqNZWXDggOfSvvfcA99/71kn2MnX17Q7Z8d+9ZUpitasGTRtapK2ImgcFetTjIrVKUbFqr77zqwlvn27g6ZNbYwbBzfd5O1eieRXUcZRzbS9jKeeeoqRI0fSvn17OnbsyKRJk0hLS+Pee+/1dtcs6dChQ9SvX9/b3RAplGK0gvP3N4nXJk2gsMtp6tQxpRVyJ3YzMtwzUocNc2+7dCnceKPnImjOW+PGUJQrL/Is6OgRo0VZ0DE11XMBMOf9PXvMftPSPGcJp6ebzyE21rOcQdOmZnunO++8fN+lQtI4KlanGBWrU4yKVd18s7nt339AMSqWpnHUU4VN2t5xxx2cOHGCsWPHcvToUdq0acOsWbPyLU4mxi+//KI/HLE0xahcVpMm7lq44C4n4Ezg9uzpfm7HDjh1ClauNLfcfHxgyhT4zW/M4yNHTDI1Lg5q1XLP0PX1NeUYAF54wR2jL71k2idMMDN6jx93J2YffNDsH+D+++Gbbwr+XUJCzPvWrWsejx1rksONGpnErchV0DgqVqcYFatTjIrVKUbF6hSjnips0hZgzJgxjBkzxtvdEBERb/Dxgfr1zW3AAM/nRoyADh08F0Fz3s6ehdq13dvOng3OqzRCQz1n5956qztx26YNPPQQvP8+tG0LM2fC3/9uFldzGjzY9AfMLNnoaM9Zs85b7uQwmPcUERERERGRcqNCJ21FREQKFBxsltpt3dqz3eEwC5pVqeJus9lMSYK9e03Jgg0bzM3pt7+FsWMZ4ucH2dmmbf169/M+PtCwoUnGZma628eOhRdfLPZfTURERERERKyvwi5Edq0q2kJkZ86coUruJIWIxShGxeuysjwXQ3PevvjC1MHNyjI1aG++2XPWbJMmEBTk7d6LaBwVy1OMitUpRsXqFKNidRUlRrUQmRSrbOfsMBGLUoyK1wUEuMsi5PbSS5CVhSMgAFtWFrRo4VqcTMRKNI6K1SlGxeoUo2J1ilGxOsWoJx9vd0DKhhUrVni7CyKXpBgVS8q16Ni0b781i4+NHeu5IJqIRWgcFatTjIrVKUbF6hSjYnWKUU+aaSsiIlISciVseeEFmDrVPcPWuTiZZtyKiIiIiIhIAZS0FRERKQk5Oe6EbW7Oxzk5pd8nERERERERKRO0ENlVqmgLkR06dIjatWt7uxsihVKMitUpRsXqFKNidYpRsTrFqFidYlSsrqLEaFFziqppK0USERHh7S6IXJJiVKxOMSpWpxgVq1OMitUpRsXqFKNidYpRT0raSpHMnTvX210QuSTFqFidYlSsTjEqVqcYFatTjIrVKUbF6hSjnpS0FREREREREREREbEQLUR2lZylgM+ePevlnpSO9PT0CvO7StmkGBWrU4yK1SlGxeoUo2J1ilGxOsWoWF1FiVHn73i5ZcaUtL1KqampANStW9fLPREREREREREREZGyJDU1lfDw8EKftzkul9aVAtntdg4fPkxYWBg2m83b3SlRZ8+epW7duhw8ePCSq9qJeItiVKxOMSpWpxgVq1OMitUpRsXqFKNidRUpRh0OB6mpqdSqVQsfn8Ir12qm7VXy8fGhTp063u5GqapcuXK5/8ORsk0xKlanGBWrU4yK1SlGxeoUo2J1ilGxuooSo5eaYeukhchERERERERERERELERJWxERERERERERERELUdJWLiswMJBx48YRGBjo7a6IFEgxKlanGBWrU4yK1SlGxeoUo2J1ilGxOsVoflqITERERERERERERMRCNNNWRERERERERERExEKUtBURERERERERERGxECVtRURERERERERERCxESVsRERERERERERERC1HSVi7p7bffpkGDBgQFBZGQkMDq1au93SURl59//pnhw4dTq1YtbDYbP/zwg7e7JOIyceJEOnToQFhYGFFRUdx4443s2LHD290ScXn33Xdp1aoVlStXpnLlynTu3JmZM2d6u1sihXrttdew2Ww8+eST3u6KCADjx4/HZrN53Jo2bertbol4OHToEPfccw8REREEBwfTsmVL1q5d6+1uibg0aNAg31hqs9l49NFHvd01r1PSVgr19ddf89RTTzFu3DjWr19P69atGThwIMePH/d210QASEtLo3Xr1rz99tve7opIPosXL+bRRx9l5cqVzJ07lwsXLjBgwADS0tK83TURAOrUqcNrr73GunXrWLt2LX369OGGG25gy5Yt3u6aSD5r1qzh/fffp1WrVt7uioiH5s2bc+TIEddt6dKl3u6SiMvp06fp2rUr/v7+zJw5k61bt/J///d/VK1a1dtdE3FZs2aNxzg6d+5cAG677TYv98z7bA6Hw+HtTog1JSQk0KFDByZPngyA3W6nbt26PPbYYzz77LNe7p2IJ5vNxvfff8+NN97o7a6IFOjEiRNERUWxePFievTo4e3uiBSoWrVqvPHGG9x///3e7oqIy7lz52jbti3vvPNRduVWAAEAAElEQVQOL7/8Mm3atGHSpEne7pYI48eP54cffiAxMdHbXREp0LPPPsuyZctYsmSJt7siUmRPPvkk06ZNY9euXdhsNm93x6s001YKlJWVxbp16+jXr5+rzcfHh379+rFixQov9kxEpGxKSUkBTFJMxGpycnL46quvSEtLo3Pnzt7ujoiHRx99lKFDh3ocl4pYxa5du6hVqxaNGjVixIgRHDhwwNtdEnH56aefaN++PbfddhtRUVFcd911/Otf//J2t0QKlZWVxWeffcZ9991X4RO2oKStFOLkyZPk5OQQHR3t0R4dHc3Ro0e91CsRkbLJbrfz5JNP0rVrV1q0aOHt7oi4bNq0iUqVKhEYGMhDDz3E999/T3x8vLe7JeLy1VdfsX79eiZOnOjtrojkk5CQwJQpU5g1axbvvvsuSUlJdO/endTUVG93TQSAvXv38u677xIbG8vs2bN5+OGHefzxx/nkk0+83TWRAv3www+cOXOGUaNGebsrluDn7Q6IiIiUd48++iibN29WnTuxnLi4OBITE0lJSeHbb79l5MiRLF68WIlbsYSDBw/yxBNPMHfuXIKCgrzdHZF8Bg8e7LrfqlUrEhISqF+/Pv/9739VZkYswW630759e1599VUArrvuOjZv3sx7773HyJEjvdw7kfz+/e9/M3jwYGrVquXtrliCZtpKgapXr46vry/Hjh3zaD927Bg1atTwUq9ERMqeMWPGMG3aNBYuXEidOnW83R0RDwEBATRu3Jh27doxceJEWrduzZtvvuntbokAsG7dOo4fP07btm3x8/PDz8+PxYsX889//hM/Pz9ycnK83UURD1WqVKFJkybs3r3b210RAaBmzZr5TsQ2a9ZMZTzEkvbv38+8efN44IEHvN0Vy1DSVgoUEBBAu3btmD9/vqvNbrczf/581boTESkCh8PBmDFj+P7771mwYAENGzb0dpdELstut5OZmentbogA0LdvXzZt2kRiYqLr1r59e0aMGEFiYiK+vr7e7qKIh3PnzrFnzx5q1qzp7a6IANC1a1d27Njh0bZz507q16/vpR6JFO7jjz8mKiqKoUOHersrlqHyCFKop556ipEjR9K+fXs6duzIpEmTSEtL49577/V210QAc2CceyZDUlISiYmJVKtWjXr16nmxZyKmJMIXX3zBjz/+SFhYmKseeHh4OMHBwV7unQj8+c9/ZvDgwdSrV4/U1FS++OILFi1axOzZs73dNREAwsLC8tUBDw0NJSIiQvXBxRL++Mc/Mnz4cOrXr8/hw4cZN24cvr6+3HXXXd7umggAv//97+nSpQuvvvoqt99+O6tXr+aDDz7ggw8+8HbXRDzY7XY+/vhjRo4ciZ+fUpVO+iSkUHfccQcnTpxg7NixHD16lDZt2jBr1qx8i5OJeMvatWvp3bu36/FTTz0FwMiRI5kyZYqXeiVivPvuuwD06tXLo/3jjz9WYX2xhOPHj/Pb3/6WI0eOEB4eTqtWrZg9ezb9+/f3dtdERMqEX3/9lbvuuovk5GQiIyPp1q0bK1euJDIy0ttdEwGgQ4cOfP/99/z5z39mwoQJNGzYkEmTJjFixAhvd03Ew7x58zhw4AD33Xeft7tiKTaHw+HwdidERERERERERERExFBNWxERERERERERERELUdJWRERERERERERExEKUtBURERERERERERGxECVtRURERERERERERCxESVsRERERERERERERC1HSVkRERERERERERMRClLQVERERERERERERsRAlbUVEREREREREREQsRElbEREREZGrYLPZGD9+vLe7cUmjRo2iQYMG3u6GiIiIiFwhJW1FRERExGs2bdrErbfeSv369QkKCqJ27dr079+ft956y9tdK3UNGjRg2LBh3u6GiIiIiFiAkrYiIiIi4hXLly+nffv2bNy4kd/97ndMnjyZBx54AB8fH958801vd09ERERExGv8vN0BEREREamYXnnlFcLDw1mzZg1VqlTxeO748ePe6ZSIiIiIiAVopq2IiIiIeMWePXto3rx5voQtQFRUlMfjjz/+mD59+hAVFUVgYCDx8fG8++67+V7nLDGwaNEi2rdvT3BwMC1btmTRokUAfPfdd7Rs2ZKgoCDatWvHhg0bPF4/atQoKlWqxN69exk4cCChoaHUqlWLCRMm4HA4Lvs7HTp0iPvuu4/o6GgCAwNp3rw5H330UdE/lFz27duHzWbjb3/7Gx988AExMTEEBgbSoUMH1qxZk2/7H374gRYtWhAUFESLFi34/vvvC9yv3W5n0qRJNG/enKCgIKKjoxk9ejSnT592bTNu3Dh8fHyYP3++x2sffPBBAgIC2Lhx41X9TiIiIiJSNJppKyIiIiJeUb9+fVasWMHmzZtp0aLFJbd99913ad68Oddffz1+fn5MnTqVRx55BLvdzqOPPuqx7e7du7n77rsZPXo099xzD3/7298YPnw47733Hn/5y1945JFHAJg4cSK33347O3bswMfHPZchJyeHQYMG0alTJ15//XVmzZrFuHHjyM7OZsKECYX28dixY3Tq1AmbzcaYMWOIjIxk5syZ3H///Zw9e5Ynn3zyqj6nL774gtTUVEaPHo3NZuP111/n5ptvZu/evfj7+wMwZ84cbrnlFuLj45k4cSLJycnce++91KlTJ9/+Ro8ezZQpU7j33nt5/PHHSUpKYvLkyWzYsIFly5bh7+/P888/z9SpU7n//vvZtGkTYWFhzJ49m3/961+89NJLtG7d+qp+FxEREREpIoeIiIiIiBfMmTPH4evr6/D19XV07tzZ8ac//ckxe/ZsR1ZWVr5t09PT87UNHDjQ0ahRI4+2+vXrOwDH8uXLXW2zZ892AI7g4GDH/v37Xe3vv/++A3AsXLjQ1TZy5EgH4HjsscdcbXa73TF06FBHQECA48SJE652wDFu3DjX4/vvv99Rs2ZNx8mTJz36dOeddzrCw8ML/B3y9n3o0KGux0lJSQ7AERER4Th16pSr/ccff3QAjqlTp7ra2rRp46hZs6bjzJkzrrY5c+Y4AEf9+vVdbUuWLHEAjs8//9zjvWfNmpWvfdOmTY6AgADHAw884Dh9+rSjdu3ajvbt2zsuXLhwyd9DRERERK6dyiOIiIiIiFf079+fFStWcP3117Nx40Zef/11Bg4cSO3atfnpp588tg0ODnbdT0lJ4eTJk/Ts2ZO9e/eSkpLisW18fDydO3d2PU5ISACgT58+1KtXL1/73r178/VtzJgxrvvOmbNZWVnMmzevwN/F4XDwv//9j+HDh+NwODh58qTrNnDgQFJSUli/fn1RPxoPd9xxB1WrVnU97t69u0e/jxw5QmJiIiNHjiQ8PNy1Xf/+/YmPj/fY1zfffEN4eDj9+/f36GO7du2oVKkSCxcudG3bokULXnzxRT788EMGDhzIyZMn+eSTT/Dz08V6IiIiIiVNR1wiIiIi4jUdOnTgu+++Iysri40bN/L999/zj3/8g1tvvZXExERX0nHZsmWMGzeOFStWkJ6e7rGPlJQUj2Rl7sQs4Hqubt26BbbnruUK4OPjQ6NGjTzamjRpApg6swU5ceIEZ86c4YMPPuCDDz4ocJurXVwt7+/jTOA6+71//34AYmNj8702Li7OI1m8a9cuUlJS8tUMLqyPTz/9NF999RWrV6/m1VdfzZcEFhEREZGSoaStiIiIiHhdQEAAHTp0oEOHDjRp0oR7772Xb775hnHjxrFnzx769u1L06ZN+fvf/07dunUJCAhgxowZ/OMf/8But3vsy9fXt8D3KKzdUYQFxi7H2Yd77rmHkSNHFrhNq1atrmrfxdlvu91OVFQUn3/+eYHPR0ZGejzeu3cvu3btAmDTpk1X/H4iIiIicnWUtBURERERS2nfvj1gLvsHmDp1KpmZmfz0008es05zX8pfnOx2O3v37nXNrgXYuXMnAA0aNCjwNZGRkYSFhZGTk0O/fv1KpF+FqV+/PoAruZrbjh07PB7HxMQwb948unbt6lFyoiB2u51Ro0ZRuXJlnnzySV599VVuvfVWbr755uLrvIiIiIgUSDVtRURERMQrFi5cWOBs0RkzZgDm0n5wzzTNvW1KSgoff/xxifVt8uTJrvsOh4PJkyfj7+9P3759C9ze19eXW265hf/9739s3rw53/MnTpwosb7WrFmTNm3a8Mknn3jU9507dy5bt2712Pb2228nJyeHl156Kd9+srOzOXPmjOvx3//+d5YvX84HH3zASy+9RJcuXXj44Yc5efJkif0uIiIiImJopq2IiIiIeMVjjz1Geno6N910E03/n737Dovi6sIA/i7dglhQFMSGAqIC9t6wt2g0xdhL/IyJmsQ0o4m9xZhiYk1Ro0ZjYjT23rE37F2xV0RQEQR2vj+Ou8sqKCLszO6+v+fx0R0WuKyXuzNnzj0nMBCPHz/Gjh07sGDBAhQrVgzdu3cHADRu3BguLi5o1aoVevfujQcPHuDXX39FgQIFjNm4mcnNzQ2rV69G165dUbVqVaxatQorVqzAoEGDnikfkNK4ceOwadMmVK1aFb169UJQUBDu3r2LAwcOYP369bh7926mj9Vg7NixaNGiBWrVqoUePXrg7t27+Pnnn1GmTBk8ePDA+Ly6deuid+/eGDt2LCIiItC4cWM4OzvjzJkz+OeffzBx4kS88cYbOHHiBL7++mt069YNrVq1AgDMmjULoaGheP/99/H3339n2c9CRERERMy0JSIiIiKVTJgwAfXr18fKlSsxYMAADBgwAHv27MH777+P3bt3I3fu3AAk43bhwoXQ6XT49NNPMW3aNPzvf//Dhx9+mCXjcnR0xOrVq3Hjxg189tln2Lt3L4YOHZpqdmpKXl5e2LNnD7p3745Fixahb9++mDhxIu7evYtvvvkmS8Zq0LRpU/zzzz9ITk7Gl19+iUWLFmHmzJnGUhMpTZs2Db/88gtu3bqFQYMG4csvv8TGjRvRqVMn1KxZE8nJyejatSs8PT3x448/Gj+vVKlSGDt2LP755x8GbYmIiIiymE7JjM4LREREREQ2oFu3bli4cKFZdioRERERkaUx05aIiIiIiIiIiIhIQxi0JSIiIiIiIiIiItIQBm2JiIiIiIiIiIiINIQ1bYmIiIiIiIiIiIg0hJm2RERERERERERERBrCoC0RERERERERERGRhjBoS0RERERERERERKQhDNoSERERERERERERaQiDtkREREREREREREQawqAtERERERERERERkYYwaEtERERERERERESkIQzaEhEREREREREREWkIg7ZEREREREREREREGsKgLREREREREREREZGGMGhLREREREREREREpCEM2hIRERERERERERFpCIO2RERERERERERERBrCoC0RERERERERERGRhjBoS0RERJTFIiMjodPp0K1bN7Pj9erVg06nU2dQLymtn4Eoq+h0OtSrV8/sWLdu3aDT6RAZGanKmF6GNf1+ExERkfYwaEtEREREAIBixYqhWLFiag8jw4YNGwadTpfuP8OGDVN7yJrw9Ovi5OSEQoUKoU2bNti6davaw8tUhjmyefNmtYdCRERE9FxOag+AiIiIyF7Nnj0bcXFxag8jXXx8fHDixAl4eHioPZQ0PZ2VCQARERFYsmQJ6tat+8zHU3u+vcqXLx/69u0LAIiPjze+bkuXLsWCBQvw5ptvqjxCMXbsWAwcOBA+Pj5qD4WIiIgoSzFoS0RERKSSIkWKqD2EdHN2dkZgYKDaw3iuevXqPROInTVrFpYsWYJ69eoxs/Y5PD09n3l9fvvtN/Tq1Quff/65ZoK2hQoVQqFChdQeBhEREVGWY3kEIiIiokySnJyMb775BiVLloSbmxtKliyJsWPHQq/Xp/r81Gpezpo1CzqdDrNmzcKyZctQs2ZNuLu7m5UtePz4Mb7//ntUqFABOXLkgLu7O2rXro2lS5em+n0eP36MH374AZUrV4a7uzty5syJoKAgDBgwANHR0cZ6tRcvXsTFixdTLSHwvJq2Fy9eRM+ePeHj4wMXFxcULlwYPXv2xKVLl9L8mRMTEzFs2DAUK1YMrq6u8Pf3x5QpU9L3QmcCQ23U8+fP47vvvkNQUBBcXV2NP9/zaqc+b4v91q1b0apVK3h6esLV1RWlSpXCV199la6M6ri4OLi7u8PPzy/N5wQHByNbtmyIjY0FIFmx3333HUJCQuDh4YEcOXKgWLFieOutt3Do0KF0vRZp6dGjB3LkyIHIyEjcvn0bgKmExr1799C3b1/4+vrCyckJs2bNMn7e4cOH0b59exQqVAguLi4oWrQo+vXrh6ioqFS/z2+//YayZcvCzc0Nvr6++PzzzxEfH5/qc5/3/7J161a0adMGXl5ecHV1ha+vL9q2bYvw8HAAMveGDx8OAKhfv75xjj9dEuTWrVv4+OOPUbJkSbi6usLT0xPt2rXD0aNHUx1TeHg46tatixw5ciBfvnx4++23cfny5ee9tEREREQvxExbIiIiokzyv//9DzNmzEDx4sXxwQcfID4+Ht9//z127Njx0l/rn3/+wdq1a9GyZUu8//77xiBdQkICmjZtis2bNyM0NBQ9e/ZEYmIiVqxYgdatW+Pnn382bnMHgEePHqFRo0bYvn07SpUqhe7du8PV1RVnzpzB9OnT0aVLFxQrVgxDhw7Fjz/+CAD46KOPjJ//ohICp0+fRq1atXD79m20atUKZcqUwdGjRzFjxgwsW7YM4eHh8Pf3f+bz3nnnHezZswfNmjWDo6Mj/v77b3zwwQdwdnZGr169zJ5rCGwrivLSr+OL9OvXD7t27UKLFi3QqlUrFChQIMNfa+rUqfjggw+QO3du49fat28fRo8ejU2bNmHTpk1wcXFJ8/OzZ8+Odu3a4Y8//sCOHTtQo0YNs48fOnQIR44cwdtvv41cuXIBALp27Yq///4bwcHBxv/by5cvY9OmTdi7dy9CQkIy/POklPLmQkJCAsLCwvDgwQO89tprcHJygpeXFwBg6dKleOutt+Dg4IDWrVvD19cXx48fx6RJk7BmzRrs3r0befLkMX6tkSNHYsiQIfDy8kKvXr3g7OyMBQsW4MSJEy81vokTJ+Ljjz9GtmzZ8Prrr6NIkSK4evUqwsPDsXDhQtSqVcsYkN+yZQu6du1qDNbmzp3b+HXOnTuHevXq4cqVK2jcuDHatGmDW7du4d9//8WaNWuwYcMGVK1a1fj8DRs2oFmzZnBwcMDbb78Nb29vbNiwATVr1jT7OYmIiIhemkJEREREr2zTpk0KACUkJER58OCB8fiVK1cUT09PBYDStWtXs8+pW7eu8vTp2MyZMxUAioODg7Ju3bpnvs+gQYMUAMrXX3+t6PV64/HY2FilUqVKiouLi3L16lXj8U8++UQBoHTu3FlJSkoy+1r37t1T7t+/b3xctGhRpWjRoqn+fBcuXEj1Z6hfv74CQJk+fbrZ8cmTJysAlLCwsFR/5qpVqyoxMTHG4ydPnlScnJyUgICAZ743gGdep/QyvJ5Dhw41O961a1cFgFK4cGHl4sWLz3ye4eMXLlx45mNDhw5VACibNm0yHjt27Jji5OSkhISEKHfu3DF7/tixYxUAyoQJE1443vXr1ysAlD59+jzzMcP/5fLlyxVFkf8/nU6nVKxY8Zn/26SkJCU6OvqF309R5PVN7XWfMWOGAkApXry48VjRokUVAEqTJk2UuLg4s+ffuXNHyZUrl+Lj46NERkaafWz+/PkKAKVv377GY2fOnFGcnJwUHx8f5ebNm8bjMTExSkBAgAJAqVu3rtnXSe3/JSIiQnFwcFC8vb2f+f/S6/Vmvw+p/d+lVKNGDcXR0VFZvXq12fFTp04p7u7uSrly5YzHkpOTlRIlSig6nU7Ztm2b2ffs0KHDK81bIiIiIpZHICIiIsoEs2fPBgAMGTIEOXLkMB738fHBhx9++NJfr3Xr1mjYsKHZMb1ej6lTp8LPzw/Dhw83y350d3fHkCFD8PjxYyxatAgAkJSUhF9++QUeHh6YOHEiHB0dzb6eh4cHcubM+dJjM7h06RI2bdqEoKCgZ7Jj33vvPQQGBmLjxo2pbhUfO3asMVsUAAICAlCzZk2cOnUK9+/fN3vuiRMnXjrzMr0+++yzTKktPH36dCQlJeHnn39Gvnz5zD72+eefI3/+/Jg/f/4Lv079+vXh4+ODv//+G4mJicbjer0e8+bNQ/78+dGkSRMAkv2qKArc3Nzg4GB+Wu/o6GiWQfoid+7cwbBhwzBs2DAMHDgQzZo1Q48ePeDg4IBvv/32meePHz8e2bJlMzs2e/ZsxMbGYuzYsShatKjZx9q3b48KFSrgr7/+Mh6bN28ekpKSMGDAALMM51y5cuGrr75K99inT58OvV6PUaNGPVPqQKfTwdvbO11f5+DBg9ixYwe6du1qfI0N/P390atXLxw5csRYJiE8PBznz59Hy5YtUatWLbPvOWbMmGd+34iIiIheBssjEBEREWUCQ/3Q2rVrP/Ox1I69SJUqVZ45durUKURHR8Pb29tYmzMlQ93RkydPGv++f/8+GjZsmCVbtSMiIgAAdevWfaY2r4ODA+rUqYOTJ08iIiICvr6+Zh+vWLHiM1+vcOHCAIB79+7B3d3deDwrG6Cl9jpnxK5duwDAuIX+ac7Ozsb/l+dxcHBAx44dMX78eKxcuRKtW7cGINvwr1+/jn79+sHJSU7hc+XKhebNm2PlypWoUKEC3nzzTdSrVw+VK1eGs7PzS40/KirKOKccHR3h6emJ1q1b45NPPnlm/rq5uaFcuXJpvga7d+/GuXPnnvl4fHw87ty5gzt37sDT0zPTfmf27NkDAGjcuHG6Pyc1hvHfvHkz1aZ1KX+vypYt+9zxFy1aFL6+vqnW3iUiIiJKDwZtiYiIiDJBTEwMHBwc4Onp+czHDPU+X0Zqn3P37l0AwLFjx3Ds2LE0P/fhw4fGMQGS7ZsVDHV20/r5ChUqZPa8lFJm2RoYgpHJycmZNcQXysj/TWoM/zejR49+5a/VuXNnjB8/HnPnzjUGbefMmWP8WEr//PMPxowZg3nz5mHw4MEA5LXt3r07xowZg+zZs6frewYEBKQrqAwABQoUeCZID5heg8mTJz/38x8+fAhPT0/j/EytjvDL/L/ExMRAp9MZ51tGGca/YsUKrFixIs3nPf37lVYdZC8vLwZtiYiIKMNYHoGIiIgoE3h4eECv1+POnTvPfOzmzZsv/fVSC4oZAp3t2rWDoihp/pk5cyYAU4Olq1evvvT3Tw/DeNL6+W7cuGH2PC1K7XUGYCw3kJSU9MzHDMG6lAw/Y2xs7HP/b9KjbNmyCA0NxfLlyxETE4O4uDgsXrwYAQEBqFy5stlzs2fPjlGjRuH8+fM4f/48fv/9dwQEBBgbc2WFtF4zw2tw5MiR574GhtIJHh4eAIBbt24987Ve5ncmd+7cUBQF169ff9kfJdXx//zzz88df9euXV84/pf9GYiIiIiexqAtERERUSYICQkBAGzbtu2Zj6V2LCNKly6NXLlyYd++fWb1TtMSEBCAXLlyYe/evYiOjn7h8x0dHV8qyzU0NBQAsHXr1mcCkoqiYOvWrWbPsyaGchKpBbwPHjz4zLGqVasCMG2xf1WdO3dGfHw8Fi5ciMWLF+PBgwfo1KnTcz+nePHi6NGjB7Zs2YKcOXNi6dKlmTKW9DK8Bjt37kzX8zPrd8ZQ4mLt2rUvfK6hzmxq8zwzx3/x4sVUazkTERERpReDtkRERESZwLBtfcSIEcbt04AE/SZOnJgp38PJyQl9+vTBxYsX8emnn6YauD169Kgx88/JyQm9e/dGTEwMPvzww2cCVTExMXjw4IHxcd68eXHnzh3Ex8enazxFihRB/fr1cezYMcyYMcPsY7/88gtOnDiBsLCwZ+rZvqyTJ0+me+t+ZjFktM6aNcvs+MKFC7Fly5Znnv/+++/DyckJ/fr1w6VLl575+L1791IN9qalQ4cOcHR0xJw5czBnzhzodLpngra3b982NsVKKTo6GgkJCXBzc0v398sM3bt3h7u7OwYPHpxq+Y64uDizoLbhZ/z+++/NslVjY2MxatSodH/f9957D46Ojvjqq69w8eJFs48pioJr164ZH+fNmxcAUg2oVqlSBVWrVsX8+fOxYMGCZz6u1+vN/u9r1aqF4sWLY/ny5QgPDzf7noMGDbJomQ8iIiKyPaxpS0RERJQJ6tevj+7du2PmzJkoV64cXn/9dSQkJGDBggWoVq0ali9fninfZ/jw4Thw4AB++uknrFixAnXq1EGBAgVw9epVHDlyBIcOHcLOnTuNdTZHjBiBXbt2Yc6cOdi1axeaNWsGV1dXnD9/HqtXr0Z4eLgxEzYsLAz79u1Ds2bNULt2bbi4uKBOnTqoU6dOmuOZOnUqatWqhV69emHZsmUICgrCsWPHsHTpUuTPnx9Tp0595Z+5dOnSAJDu8gKZoXXr1vDz88OsWbNw+fJllC9fHidOnMDGjRuNzb9SKlu2LKZMmYI+ffogICAAzZs3h5+fH+7fv4/z589jy5Yt6NatG6ZNm5au71+wYEE0bNgQa9euhYODA2rVqoVixYqZPefq1asoX748QkJCEBwcDB8fH0RFRWHJkiVITEzEp59+mlkvR7rkz58f8+fPx5tvvomQkBA0bdoUgYGBSEhIQGRkJLZs2YIaNWpg9erVAICSJUtiyJAhGDp0KIKDg/HWW2/ByckJ//77L4KDg3Hq1Kl0fd9y5crhxx9/RP/+/VGmTBm0adMGRYsWxY0bN7B161a0aNECP/74IwD5PdXpdBg0aBCOHTsGDw8P5M6dG3379gUAzJ8/H/Xr10f79u3x448/okKFCsiWLRsuXbqEnTt34vbt28abGg4ODvjll1/QvHlzNGzYEG+//Ta8vb2xceNGXL9+HcHBwTh8+HDmv9BERERkHxQiIiIiyhRJSUnK2LFjlRIlSiguLi5KiRIllDFjxihnz55VAChdu3Y1e37dunWVp0/HZs6cqQBQZs6c+dzvM336dKVmzZpKrly5FFdXV6VIkSJK06ZNlalTpyoPHjwwe358fLwyYcIEJTQ0VMmWLZuSM2dOJSgoSPnkk0+U6Oho4/Pu37+v9OrVSylUqJDi6OioAFCGDh2qKIqiXLhwIdWfQVEUJTIyUunevbtSqFAhxcnJSSlUqJDSvXt3JTIy8pnnpvYzG3Tt2lUBoFy4cMHsOIA0P+dFDK+n4ed40fdK6cKFC0qbNm0Ud3d3JUeOHEqDBg2UvXv3KkOHDlUAKJs2bXrmc/bs2aO0b99e8fb2VpydnRVPT0+lQoUKysCBA5UTJ0681Njnzp1r/NmnT5/+zMejo6OVYcOGKXXq1FEKFSqkuLi4KN7e3krTpk2VVatWpfv7AFACAgLS9dyiRYsqRYsWfe5zTp48qfTs2VMpWrSo4uLiouTJk0cpV66c0r9/f2XPnj3PPP/XX39VgoKCFBcXF6Vw4cLKp59+qsTFxSkAlLp165o993n/b5s2bVJatmyp5M2b1/i12rVrp2zfvt3sebNmzVLKlSunuLq6KgCe+Xnu3r2rfPXVV0rZsmWNvy+lSpVSOnTooCxatOiZ77t161alTp06SrZs2ZS8efMqb775pnLx4sXnznUiIiKiF9EpigVTFoiIiIiIiIiIiIjouVjTloiIiIiIiIiIiEhDGLQlIiIiIiIiIiIi0hAGbYmIiIiIiIiIiIg0hEFbIiIiIiIiIiIiIg1h0JaIiIiIiIiIiIhIQ5zUHoC10uv1uHbtGtzd3aHT6dQeDhEREREREREREWmcoii4f/8+vL294eCQdj4tg7YZdO3aNfj6+qo9DCIiIiIiIiIiIrIyly9fRuHChdP8OIO2GeTu7g5AXuBcuXKpPJqst2rVKjRr1kztYRCliXOUtI5zlLSOc5S0jnOUtI5zlLSOc5S0zl7maGxsLHx9fY2xxbToFEVRLDQmmxIbGwsPDw/ExMTYRdA2KioK+fLlU3sYRGniHCWt4xwlreMcJa3jHCWt4xwlreMcJa2zlzma3pgiG5FRujyvxgaRFnCOktZxjpLWcY6S1nGOktZxjpLWcY6S1nGOmuOrQekSHh6u9hCInotzlLSOc5S0jnOUtI5zlLSOc5S0jnOUtI5z1ByDtkREREREREREREQawqAtERERERERERERkYYwaEvpEhwcrPYQiJ6Lc5S0jnOUtI5zlLSOc5S0atEiICQEePPNlggJkcdEWsR1lLSOc9ScTlEURe1BWKP0dnqzFYmJiXB2dlZ7GERp4hwlreMcJa3jHCWt4xwlLVq0CGjXDtDpAEUx/f3vv0DbtmqPjsgc11HSOnuZo+mNKTLTltJl9erVag+B6Lk4R0nrOEdJ6zhHSes4R0mLhg83BWoBU+B2xAh1x0WUGq6jpHWco+YYtCUiIiIiIiJ6SQ8fAseOmQK2BooCnDqlzpiIiMh2MGhLRERERERE9BIiIoCKFYHk5NQ/niMH8OiRRYdEREQ2xi6DtlOnTkVwcDBy5cqFXLlyoXr16li1apXaw9I0Pz8/tYdA9Fyco6R1nKOkdZyjpHWco6QFigL89BNQtapk0+bJI8d1OvPnRUUBVapIJi6RVnAdJa3jHDVnl43Ili1bBkdHR5QqVQqKouCPP/7At99+i4MHD6JMmTLp+hr21oiMiIiIiIjInt25A3TvDixfLo9few34/Xdg61apYXvqFBAQALRuDUyfDty8Cbi5AT/+CPzvf88GdomIyD6xEdlztGrVCs2bN0epUqXg7++P0aNHI2fOnNi1a5faQ9OstWvXqj0EoufiHCWt4xwlreMcJa3jHCU1bdwIBAdLwNbVFfj5Z+C//wBPT6BtWymXsGTJWkRESHOyQ4eAJk2A+HjgvfeAN94A7t5V+Ycgu8d1lLSOc9ScXQZtU0pOTsZff/2Fhw8fonr16mk+LyEhAbGxsWZ/7ElCQoLaQyB6Ls5R0jrOUdI6zlHSOs5RUkNiIjB4MNCwIXD9OhAYCOzeDfTt+2zmbMo56uUFrFwJTJgAODsDixYBoaFAeLhlx0+UEtdR0jrOUXN2WR4BAI4cOYLq1asjPj4eOXPmxLx589C8efM0nz9s2DAMHz78meN//fUXsmfPDgBo1KgRoqKicODAAePHq1evDicnJ2zbts14LDg4GD4+PmZ1dEuUKIEyZcpg3bp1iI+PBwAUKFAAVatWxc6dO3Hnzh0AQPbs2dGgQQMcOXIEkZGRxs9v0aIFIiMjcSxF0aS6desiPj4eu3fvNh6rVKkSPDw8sGHDBuOxwMBAlCpVCitWrIBerwcA+Pr6IjQ0FJs3b8b9+/eh1+uRL18+1KpVC/v27cP169cBAM7OzmjatClOnjyJM2fOGL9m48aNcfv2bRw8eNB4rEaNGnBwcEB4ijOV4OBgeHt7Y/Xq1cZjfn5+CAoKwtq1a42/sF5eXqhSpQp27NiBqKgoAECOHDkQFhaGQ4cO4dKlS8bPb9WqFc6dO4fjx48bj9WvXx8PHz7Enj17jMcqV64Md3d3bNy40XisdOnSKFmyJJYvXw7Dr0aRIkUQEhJifC0AIG/evKhZsyb27t2LGzduAABcXFzQpEkTnDhxAmfPnjV+zSZNmuDmzZuIiIgwHqtZsyYAYPv27cZjoaGh8PLywpo1a4zHSpYsidKlS2PNmjV4/PgxAKBgwYKoXLkytm/fjrtPbte7u7ujXr16Zq+FTqdDy5YtcfbsWZw4ccL4NcPCwnD//n3s3bvXeKxKlSrIkSMHNm3aZDwWFBQEPz8/LFu2zHjM8Fps3LgRDx8+BADky5cPNWrUwJ49e3Dz5k0AgKurKxo3bozjx4/j3Llzxs9v2rQprl27hsOHDxuP1apVC3q9Hjt27DAeK1++PPLnz292l61UqVIIDAzE6tWrkZiYCAAoVKgQKlWqhPDwcERFRcHBwcH4WkRERODy5csAAAcHB7Ro0QJnzpzByZMnjV+zQYMGiImJwb59+4zHqlatCjc3N2zZssV4rEyZMihWrBhWrFhhPFasWDGUK1cOGzZsQFxcHADA09MT1atXx+7du3Hr1i0AgJubGxo1aoRjx47h/Pnzxs9v1qwZrl69avZa1K5dG0lJSdi5c6fxWIUKFZAvXz6sW7fOeMzf3x8BAQFYtWoVkpKSAADe3t6oWLEitm3bhnv37gEAPDw8UKdOHRw4cABXr14FADg6OqJ58+Y4ffo0TqVoa9ywYUNER0dj//79xmPVqlWDq6ur2WtRtmxZFClSBCtXrjQeK168OMqWLYv169fj0ZOOG/nz50e1atWwa9cu3L59GwCQLVs2NGzYEEePHsWFCxeMn9+8eXNcunQJR48eNR6rW7cuEhISzHZAVKxYEXny5MH69euNxwICAuDv74+VK1ci+UknEB8fH1SoUAFbt25FTEwMACB37tyoXbs29u/fj2vXrgEAnJyc0KxZM5w6dQqnT582fs2sWsuXLFkCBwe5V6rWWg4AefLk4VrOtTzVtTwqKgpeXl6qruXR0dFmrwXXcq7lKddyvV6P1q1bq7qWa+G8HOBabqm1fPbsrfjuuwo4eTIvAODdd4GWLdfDwUF+R55ey/V6PTw8PJ5Zy8+ezY0pU2rj7FnAwUFB+/an8OabZ9CokW2el3Mt1+5afvPmTTg4ONj9eTnXcu2u5SmvmWz5vDwuLg7t27d/YXkEuw3aPn78GJcuXUJMTAwWLlyI3377DVu2bEFQUFCqz09ISDCL+MfGxsLX19duatru2bMHVapUUXsYRGniHCWt4xwlreMcJa3jHCVL+vtvqUMbEwN4eAC//AK89dbzP+d5c/T+fcnOnT1bHtepA/z5J1C4cCYPnOg5uI6S1tnLHE1vTVu7Ddo+rWHDhvDz88P06dPT9Xw2IiMiIiIiIrItDx8CH30E/PabPK5eHZg3DyhWLHO+/ty5QJ8+wIMHQN680sisTZvM+dpERGQd2IjsJen1etbOeI6UW2SItIhzlLSOc5S0jnOUtI5zlLLaoUNApUoSsNXpgK++ArZuTX/ANj1ztFMn4OBB+T537wKvvw588AHwZCc7UZbiOkpaxzlqzi6Dtl9++SW2bt2KyMhIHDlyBF9++SU2b96Mjh07qj00zTLUOCHSKs5R0jrOUdI6zlHSOs5RyiqKAvz8M1ClCnDyJODtDWzYAIwcCTg5pf/rpHeOliwJbN8OfPaZPJ4yRb53itKZRFmC6yhpHeeoObsM2t66dQtdunRBQEAAGjRogL1792LNmjVo1KiR2kMjIiIiIiIiC7lzB2jdGujfH3j8GGjVSjJu69fP2u/r4gKMHw+sWQMUKAAcPQpUriy1c1nAkIiIAOAl7hvajt9//13tIVidHDlyqD0EoufiHCWt4xwlreMcJa3jHKXMtmmTlCu4dk2CqBMmSLMwnS5jXy8jc7RxY+DwYaBrVwng9u4NrF0L/PorkCdPxsZBlBauo6R1nKPm2Igsg9iIjIiIiIiIyPokJQHDhwOjR0tWa2Ag8NdfQEiIemPS64EffgC+/BJITASKFJEGaDVrqjcmIiLKGmxERpnq0KFDag+B6Lk4R0nrOEdJ6zhHSes4RykzREYCdeoAo0ZJwPbdd4F9+zInYPsqc9TBAfjkE2DHDql5e+mSjHPkSCA5+dXHRgRwHSXt4xw1x6AtpculS5fUHgLRc3GOktZxjpLWcY6S1nGO0qv65x8gNBTYuRPw8AAWLJAyBJm1Gzcz5milSsCBA0DnzpJ9O2QI0KABcOVKJgyQ7B7XUdI6zlFzDNoSERERERGRzXr4EOjVC3jrLSAmBqhWDYiIkMda5O4OzJ4tf3LmBLZskUzgJUvUHhkREVkSg7ZERERERERkkw4dkuzV336TBmODBwNbtwLFiqk9shfr3Bk4eFDGf/cu0KaNNEp79EjtkRERkSWwEVkGsREZERERERGRNikKMHky8OmnQEICUKgQMHcuEBam9she3uPHEmyeMEEelysnjdOCgtQdFxERZQwbkVGmOnfunNpDIHouzlHSOs5R0jrOUdI6zlFKr6goyUrt108Cti1bAocPZ33ANqvmqIsL8O23wOrVQIECwJEjkn37yy8SnCZKL66jpHWco+YYtKV0OX78uNpDIHouzlHSOs5R0jrOUdI6zlFKj82bpf7r0qUS7PzpJ/m3p2fWf++snqNNmki5h8aNpURC795Slzc6Oku/LdkQrqOkdZyj5hi0JSIiIiIiIquWlAR8/bVk0169CgQEALt3S7atTqf26DJPwYLAqlWSeevkBCxcCISGAjt2qD0yIiLKbAzaEhERERERkdW6eBGoWxcYNUrKBfTsCezfL8FMW+TgILV6d+wA/PyAS5eAOnXk509OVnt0RESUWdiILIPsrRHZgwcPkDNnTrWHQZQmzlHSOs5R0jrOUdI6zlFKzT//AL16ATExQK5cUuf17bfVGYsac/T+feD996XJGiDB67lzgcKFLToMshJcR0nr7GWOshEZZaqHDx+qPQSi5+IcJa3jHCWt4xwlreMcpZTi4oD//U9qusbEANWqARER6gVsAXXmqLs7MGcOMHs2kDMnsGWL1PRdssTiQyErwHWUtI5z1ByDtvRcixbJm76vrydCQuQxkRbt2bNH7SEQPRfnKGkd5yhpHecoGRw+DFSqBPz6q9SrHTQI2LoVKF5c3XGpOUc7dwYOHAAqVgTu3gXatJF6vvHxqg2JNIjrKGkd56g5Bm0pTYsWAe3aAUeOAImJjjhyRB4zcEtERERERJamKMDkyUCVKsCJE0ChQsC6dcDo0YCzs9qjU1+pUlLn9pNP5PGkSabXioiIrA+DtpSm4cPlzrWh6rGiyOMRI9QdFxERERER2ZeoKOD114G+fYGEBKBFC+DQIaBBA7VHpi0uLsCECcCqVUCBApKAU7Ei8Ntvpus6IiKyDgzaUppOn372jV1RgFOn1BkP0fNUrlxZ7SEQPRfnKGmVoRTSm2+2ZCkk0jSuo/YrZZ1WFxdg4kRg2TIgf361R2ZOS3O0aVMJajdqBDx6JM3a3n4buHdP7ZGRmrQ0R4lSwzlqjkFbSpO/v2TWPq1YMYsPheiF3N3d1R4C0XNxjpIWpSyFlJCgYykk0jSuo/YnKQkYMgSoXx+4ehUICAB27wb690/9OkVtWpujBQsCq1cD48cDTk7AP/8AoaFSQoHsk9bmKNHTOEfNMWhLaRo61FQSIaVLl4C1a9UZE1FaNm7cqPYQiJ6Lc5TUlpgIHDsGzJsHfPEF0KyZqcs6SyGRNeA6al8uXgTq1gVGjpS1qUcPYP9+CTpqlRbnqIMD8NlnEqj185PXtU4dqQOcnKz26MjStDhHiVLiHDXnpPYASLvatgX+/Vcu3I4fT0apUo5ISpKyCc2aAd9+C3z8sTbvchMREdmzO3dkW+zhw6a/jx0DHj9+8ecqijw3KUkys4iILG3hQtnOf+8ekCsXMH060L692qOybpUrAwcOAO+/D/z5J/DVV8D69cDcuYCPj9qjIyKi1DDTlp6rbVsgIgL499+VOHZMLvq6dwf0eulK2r07EB+v9iiJiIjsU8rs2YED5aaqj4/UeWzYEBgwAPjjD+DgQQnYursDNWsCffoA06ZJ1lVqN1+TkqR+5PLlbFxDRJYTFwf07g28+aYEbKtWlfWLAdvMkSsXMGeOvC/kyAFs3gwEBwNLl6o9MiIiSg3zJyhdSpcuDQBwdQV+/10u5AwXgidPSu07b2+VB0l2zTBHibSKc5Re1Z075pmzhw49P3vWz0/er0NC5KI8JAQoWlS2yhrkzy81bHU6U2kERQFy5gSOHwdatZLtyePHA1WqWObnJEoL11HbduSIlGw5cULWooEDgeHDAWdntUeWftYwR3U6oEsXoFo14J13JPu2dWugb1/ZSenmpvYIKStZwxwl+8Y5ak6nKMyfyIjY2Fh4eHggJiYGuXLlUns4qli/HnjrLSA6WgK2//0n226IiIgo45KSgFOnni1vcO1a6s93d5egrCEwGxwMlCsngdf0WLRISiGdOiVNfoYOlaY/48ZJh3bDjpq33gLGjJFgMBFRZlEUYOpUSQhJSAAKFZJs0AYN1B6Z7UtIAAYNAr7/Xh4HBwN//QUwZkJElLXSG1Nk0DaD7C1ou3z5crRs2fKZ42fPyp3Z48clC/e334BOnVQYINm9tOYokVZwjlJqUsuePX5cLqRTY8ieTRmgLVbMPHs2o1Kbo5cvS+f2P/6QwIqzM/Dee8DXX0uWLpElcR21PVFRQM+ewJIl8rh5c2DWLOtdX6x1jq5aBXTtCty+DWTPDvz0kzR+Y+8S22Otc5Tsh73M0fTGFFkegdIlrdh+yZLAzp0SqF22DOjcWS46x44FHB0tPEiya7z/RFrHOWrfDNmzhsDsi7Jnc+Y0BWYzkj2bEanNUV9fYOZMaTw6cKBc2P/8swRVBg4EPvpILvCJLIHrqG3ZskWuIa5cAVxcpAxL//7WHSi01jnarJm8J3XpAqxbB7z7LrB2rTSAy51b7dFRZrLWOUr2g3PUHIO29Mpy5ZLSCF9/Ldsmv/0WOHpUmqLwTZ6IiOxNVJR5YFbN7NnMEhwMrFwJbNwIfPaZ1EAcPBiYPFlKK3Trxpu1RJQ+SUnAyJHAqFHS3NjfX7bkly+v9sjsW8GCwOrVwHffScmEv/8Gdu+Wa7oaNdQeHRGRfWLQltKlSJEiz/24gwMwerRkAfXoIZk41apJJ1J/fwsNkuzai+Yokdo4R23P09mzhr/Tkz1r+LtsWalJqwXpmaNhYcDevcCCBXJRHxkpGVk//AB8841sbbbmLDnSNq6j1u/iRaBjR2D7dnncvbtsxc/KXQSWZO1z1MFBbszVrStNys6fB+rUkYZwAwfy5pwtsPY5SraPc9Qca9pmkL3VtH0Zhg6kV64AHh5y57xpU7VHRURElHGG7NmUAdpjx56fPft0gFZr2bOvKiEBmDJFsuXu3pVjdevKjhs2JiWip/37r9zkuXdPblZNny6BQdKm2FipYT5/vjyuX18axPn4qDsuIiJbkN6Yog1dOlBW2rx5c7qfW6ECsG8fULMmEBMDtGgBTJggDUyIssrLzFEiNXCOWoekJAnGzp8vWUXNm8sFqqendDL/+GOp53rggAQtc+aUbaPvvSfdz3fskAvds2eBRYuAoUOB118HSpTQfsD2Zeeoq6u8HufOAV98IY+3bAGqVAHat5fjRJmJ66h1iosDevcG3nhDArZVqgAREbYZsLWlOZorF/Dnn/KelyMHsGmT3IBctkztkdFLGTZM6pE8YTZHR46UjxNpiC2to5lB45cPWWPs2LGoXLky3N3dUaBAAbRp0wanTp1Se1iadv/+/Zd6vpcXsGGDdIPV62WbTZcuQHx8Fg2Q7N7LzlEiS+Mc1Z6oKKnR+uOPskW3YkUJwpYtC3ToINv9V60ylTvw85MA7LBhEpA9d05uTm7fLgHb994DqlfXTrmDl5XROZo7NzBuHHD6tHQf1+mkfELp0sCHH0o3cqLMwHXU+hw9KkHaX36RtWHgQCA8XG5k2SJbm6M6nazrBw5IzeGoKOC112Rt53WdlXB0BIYMMQZujXN05Eg5zpoXpDG2to6+KrusabtlyxZ88MEHqFy5MpKSkjBo0CA0btwYx48fR44cOdQens1wdQV+/VXuyH78MTB3rlzQLV4MeHurPToiIrIXSUny/pOyvEF6as+mLG9Qrpz1BmMtpUgRycgaMEAyb1evllqVM2dKoOajj4Ds2dUeJRFZgqIA06bJehAfL02u5swBGjZUe2SUEf7+wM6dUsv8++9lbd+yRcrgBQaqPTp6rq+/lr+HDJG/Q0NNAdsRI0wfJyJNssug7erVq80ez5o1CwUKFMD+/ftRp04dlUalbXnz5s3Q5+l0QL9+QFAQ8NZbwJ49QKVKEritWjWTB0l2LaNzlMhSOEct42Vrz5YoYV53NjgYKF5c+6UMskJmzdHgYMlQ3rAB+PxzydAaPBiYPFmuE7t2ZWIPZQzXUetw967stvvvP3ncvLnc0MmfX81RWYYtz1FXV+C776RUULdu8h5bsaIEcHv0YBNKzdLrpeHMjh3AkCFo6eAgxxiwJY2y5XU0I9iIDMDZs2dRqlQpHDlyBGXLlk31OQkJCUhIccUXGxsLX19fNiJ7CefOyfvFsWPypv/LL1IygYiI6GWllj17+DBw9Wrqz8+ZU7JlQ0KYPWtJer1kYg0eDERGyrEyZaT0RPPmvMgnsjVbtwIdO0pDYmdnYPx42UrP33Xbcv26XMetXy+P335bMqtz51Z1WGSg18vF9saNUoz4zh3zj+t08hwiUk16G5HZfdBWr9fjtddew7179xAeHp7m84YNG4bhw4c/c/yvv/5C9id7/Ro1aoSoqCgcOHDA+PHq1avDyckJ27ZtMx4LDg6Gj48PVq1aZTxWokQJlClTBuvWrUP8kwJBBQoUQNWqVbFz507cebLQZs+eHQ0aNMCRI0cQabj6AdCiRQtERkbi2LFjxmN169ZFfHw8du/ebTxWqVIleHh4YMOGDcZjgYGBKFWqFFasWAH9k8Xb19cXoaGh2Lx5M+7fvw+9Xo98+fKhVq1a2LdvH65fvw4AcHZ2RtOmTXHy5EmcOXPG+DUbN26M27dv4+DBg8ZjNWrUwMOHDnjzzQTs2VMQANCrVwwmTsyO9etN2c9+fn4ICgrC2rVrjYFyLy8vVKlSBTt27EBUVBQAIEeOHAgLC8OhQ4dw6dIl4+e3atUK586dw/Hjx43H6tevj4cPH2LPnj3GY4a6xhs3bjQeK126NEqWLInly5fD8KtRpEgRhISEGF8LQO7+1KxZE3v37sWNGzcAAC4uLmjSpAlOnDiBs2fPGr9mkyZNcPPmTURERBiP1axZEwCwfft247HQ0FB4eXlhzZo1xmMlS5ZE6dKlsWbNGjx+/BgAULBgQVSuXBnbt2/H3Sftut3d3VGvXj2z10Kn06Fly5Y4e/YsTpw4YfyaYWFhuH//Pvbu3Ws8VqVKFeTIkQObNm0yHgsKCoKfnx+Wpeg2YHgtNm7ciIcPHwIA8uXLhxo1amDPnj24efMmAMDV1dVYcuRcik40TZs2xbVr13D48GHjsVq1akGv12PHjh3GY+XLl0f+/Pmxdu1a47FSpUohMDAQq1evRmJiIgCgUKFCqFSpEsLDwxEVFQUHBwfjaxEREYHLly8DABwcHNCiRQucOXMGJ0+eNH7NBg0aICYmBvv27TMeq1q1Ktzc3LBlyxbjsTJlyqBYsWJYsWKF8VixYsVQrlw5bNiwAXFxcQAAT09PVK9eHbt378atW7cAAG5ubmjUqBGOHTuG8+fPGz+/WbNmuHr1qtlrUbt2bSQlJWHnzp3GYxUqVEC+fPmwbt064zF/f38EBARg1apVSEpKAgB4e3ujYsWK2LZtG+7duwcA8PDwQJ06dXDgwAFcfRLJcnR0RPPmzXH69GmzWt4NGzZEdHQ09u/fbzxWrVo1uLq6mr0WZcuWRZEiRbBy5UrjseLFi6Ns2bJYv349Hj16BADInz8/qlWrhl27duH2k4KW2bJlQ8OGDXH06FFcuHDB+PnNmzfHpUuXcPToUeOxunXrIiEhAbt27TIeq1ixIvLkyYP1hisEAAEBAfD398fKlSuRnJwMAPDx8UGFChWwdetWxMTEAABy586N2rVrY//+/bj2ZE+8k5MTmjVrhlOnTuH06dPGr5lVa3nKuavWWg4AefLkeeW13MHBwew9Mzg4GN7e3mY7WTJzLY+NdUZkZC44OVXEwYN67NuXgEuX3JGYmHq6pq9vIipVcoab22kUKxaDYsViUbmyJ8qX51oOpL2WOzs7Q1GULFnLExMdsHJlMSxcGIiYGPl/K1fuDrp1O446dbIb1/Lo6Giz14JrOdfylGu54edWcy3Xwnk5oL213M0tJ8LD62PUKAV6vQ7e3g/w2WcH8NFHdezqvFyv18PDw8Muzsv9/QPx7runMHt2KSQnO8DbOwELF7oiOZlruaXX8k1//IEcV6/iTmiocS2P8/FB9ifrZHK2bHAsXBg4cwaKTgedouBc167wmzULJ8LDUahbN1yrVQvXatdG/W7d7OK8nGu5dmMsKddYWz4vj4uLQ/v27Rm0fZE+ffpg1apVCA8PR+HChdN8nr1n2i5btgytWrXKlK+l10s37VGj5HGTJtKlO0+eTPnyZKcyc44SZQXO0Rd7lexZQ3mDsmWl4zW9PEvM0ehoaVo2caKpZMXbbwOjR0ujN6Ln4TqqTZcuSXatIWbQrRvw88+yRtsbe5yju3cD77wDXLggpW9GjJC65iyDk4Vu3ZIM2o0b5c/Zs3LyExUFOD2pgPnDD8DDh0BYGLB2LTB8ODBiBJaFhqJVRISppm2BAtJJ1aBWLfkPffNN+6hpQppjL+toejNt7bKmrUHfvn2xfPlybN269bkBW0DuULq6ulpoZLbNwUFq2pUrJyd1a9ZIfdulS1nInojIXkRFmQdmDx16ce1ZQ2DW3mvPWrM8eaQ0wgcfyPXi7NnAggXAokXA++8DX30FeHqqPUoiSq9//wXefRe4d0/KzUybBnTooPaoyJKqVgUOHgT69JFEnMGDpWzC3LlsPp3pJk+WX7IUWbAAJEIeFCTBXMOL/vHH8vfIkcaALb7+Gli2zLw52ZdfSvfwefOAzZvl7kt4ONC/P9C4sQR/AwIs9iMSkTm7DNoqioJ+/fph8eLF2Lx5M4oXL672kDTPxcUl07/mW28BpUpJndszZ+QNf/58qXFH9LKyYo4SZSZ7naOG7NmnA7RpZc/myGHeFIzZs5ZjyTlapIg0Jvr4Y8nIWrNGsm9nzgQGDpQamE+qTxEZ2es6qkWPHsnv7/Tp8rhKFTmPL1FC3XGpzV7nqIcH8OefEuPr21eSQIODZZ1v2VLt0VmhuDgJnG7cCHz2GZAvnxyPijIFbENCJIs2LAyoUyftE6XkZLOmY8Y5agjcJifLnZd335WTswULJIC7f79k6KbcDnvxIlCwoDSoIcoi9rqOpsUuyyO8//77mDdvHpYsWYKAFHeNPDw8kC1btnR9jfSmMtOL3boFtGsn70s6nWyb/OwzNiwgIrI2r5I9a/ib2bP2af164PPPJVsLAHx85Bqza1dusSXSmqNHgfbtZX0H5MbLyJHSeIzo1CnZXW9Yz/v3l4Z0jPM9x+PHUmfCUO5g507gSR8ELFwoF8uA6S54vXpZvy3l9Glg1y7zzuF168r3f+MNSamvU4dv0pRpFi2SpPDTpwF/fymp2bat2qPKOmxE9hy6NKKBM2fORLdu3dL1NewtaHvixAmULl06y77+48dyV/bXX+Vxx47y73TG0ImyfI4SvSpbmqMZzZ5NGaAtV47Zs1qj9hzV601bay9elGNly0o5hWbNeDOX1J+j9k5RZGf2gAFAfLwk3M2eDTRqpPbItINzVCQkyK77H36Qx6Ghsr6zFF4q1qyRyNSTBmpGvr5AgwZSb7Zq1Uz7dhmeow8fyn/glSumY97ecgenQwegQgW+UVOGLVok9yZ0OnmvMfz977+2G7hNb0zRLnNZFEVJ9U96A7b2KGWnvqzg4iLbqyZNkpt1f/4pN+7SCgAQPS2r5yjRq7LWOXr3rmxznDgR6NEDqFhRmsuUKSOZNOPGAStXmtbr4sWBNm2kTNq//0pvjNhYYMcOudjv0weoWZMBWy1Se446OMhN21OngO++kx2ZR48CLVrI7s8UDcXJTqk9R+3Z3btyQf3++xKwbdZMbtYxYGuOc1S4ugLffw+sWCG9rCIi5PxhxgwJxNgdRZE3tJ9+kpMkQ6YSIIHQuDhpCNa+PfDLL3LydPGi1AzKxIAt8ApzNEcOIDJSMoHffRfInRu4dk3+oytVkmNEGaAostvK8G/D3zqd7Lqyd3ZZ05a0SaeTxiSlS0uzyn37ZP1fvBioVk3t0RER2bakJKkvfugQs2dJXa6uksnXvbvcFJg4UXqjVK4s17OjR7NuJpElbd0qN1SuXJESCN98I3WnWcqGXqR5czmX6NwZ2LAB6NlTyqROny51cG2WogDnz0uAc8MGuft965bp43o90KuX/LtoUeD4cQneaj1T1dERqF9f/kyaJFnC8+ZJR/G6dU3Pu3oV+OsvedP28VFvvKRpDx9Kst6kScC5c89+XFHkRr69Y9CWNCcsDNi7VxqUHT0q6//06QAToYmIMsfdu+aB2cOHpTZhfHzqzy9e3LzubHCwBM14wU5ZKU8eCQ598IH0S5kzR64B//1Xsv2++irrS/oR2bOkJGDUKKlXq9dLA+G//pJd0ETpVaiQBGrHj5d1e8ECKd86f76NJebExZk6aMbHA0FBUgPQIFs2oHZtudh9OkXdGktquLoCr70mf+7fB5xShJbmz5cmNZ99JhfzHTpIqn7evOqNlzTjzBlgyhRJJI+JkWOGcggp6XRAihZUdssua9pmBnurafv48WOLd/G7f1/qnv/3nzz++GN5s3firQZKhRpzlOhlqDFHU2bPpgzQpixHllKOHJItmzJAy+xZ+6H1dfTQIWl4tGaNPM6VCxg4UDL+DNfJZNu0PkdtyaVLQKdOwLZt8rhrV8mGyplT3XFpHefo8+3aJfG7CxckaXPkSFnXrfIm8J07sg3E0DwsWzZT9zUAaNJEgrdhYfKnShVNdGOzyBz991/gxx+l07iBs7PUVenQQUpEaOC1IMtJTgZWrTIlaBv4+cnN+Xz55H3m6Zq2ixYBr7+u3rizEhuRZTF7C9pevnwZvr6+Fv++er10EDTUMmnUSO7O5slj8aGQxqk1R4nSK6vn6N27psBserNnDYFZZs8SYD3r6Lp1UvssIkIe+/jIhX+XLmxibeusZY5au8WLZRt7dDTg7g5MnSrlEejFOEdfLCZGemv99Zc8btBAGtp5e6s7rnTZtAlYtkyCtIcOmX/M0RGIijLVfTBEnjTGonP04kX5j543T05MAcDNDbh5kxkBdiIqSmpZT5kiJZEB+bVo3lwa0TdubLr2WLRI4j4nTyoIDNRh6FDbDdgC6Y8pMmeR0iUiIkKVExAHBwnalisnd17WrZOblEuXWucuEso6as1RovTKrDnK7FnKKtayjjZqBOzfL7svBw+Wa8IePaQXyjffSCKPBq+TKRNYyxy1Vo8eAZ98IkFaQOpIz58vmVCUPpyjL+bhITG8Jk0kw27DBjk3mTVLGk9qxqNHwM6dQL16pqjSjBnA3Lmm55Qta8qkrVPHvFCvRt+ILDpHixaVVOovvpBMgvnzpYxEypPQxo1lkenQQTrVMnvAJhw4IFm18+ebEkjy5JEbgn36pN6boG1b+bNs2XK0atXKsgPWMAZtySq88QZQsqTUuT17Vppozp+vsTd2IqJMljJ71vB3erNnDX8ze5ZskYODZP61awdMnizNyY4elfOC+vWlnFKlSmqPksh6HD0qPYOOHZPHX3whGU/c6U9ZQaeTfiXVq8u8i4gAWraUcjfffKPSzvnERGmsYih3sGMHkJAgJ1/BwfKctm2lDEJYmLzZeHmpMFArVaaMFMlO6eRJycpatw6YNg3w9QXeeUcCuMHBmg18U+oSEoCFC+W8bOdO0/HQUMmqfecdlrPKCAZtyWqEhsr76BtvSH2tVq2AMWPkpJLrORFp1aJFsmPgxInmKF0aGDpUzvlTMmTPPl3e4EXZsynLG5Qta+OdmIlS4eYmmYE9egBjxwI//SS7VytXlkDA6NGpZ3MQkVAUafj78cdyQ9DLS5r+Pd0niSgrBARInduBA6UE6sSJwJYtsqPeYg2Itm0Dxo0Dtm4FHjww/5i3N3Dtmilo+/rrtr1f29JKlpQCp/PmyQnz5cty13X8eGnkNmoUX28rcOWKvI/88gtw65Ycc3aWuE3fvnJzhvGajGNN2wyyt5q2d+/eRV6NdHt8/Bjo318WBkDu2Pz2G+/a2DstzVEig0WLJBPw6aL6w4dLgDU92bPFipnXnWX2LGUVW1hHL10Cvv5agk6KIhcNH3wgHcvz5VN7dPSqbGGOasndu0CvXvJeBQBNmwJ//AEUKKDuuKwZ52jGrVgh2bd37sh13aRJ8jjTgj2KIpmdGzfKtk3Ddoz16013KfLlkwzaBg0km7ZUKZuLNml2jj56BKxcKQHcFSskbXPxYmlaBgC3b0s3q4IFVR0mCUWRPnyTJ0vj+ORkOe7tLTWre/XK+H+VZudoJmMjsizGoK36pk6V4G1SElCxoiwWhQurPSpSixbnKFFICHDkiJzYvMjT2bPBwfKY2bNkKba0jkZEyE6ctWvlsYeHZHJ9+KHsbCXrZEtzVG3btkmJkcuX5ebGuHHARx/xhuCr4hx9NdeuAZ07S1wVkB0T06a9wrlQZKR8sQ0b5O8bN+T4gAHAd9/Jv+Pi5Js0aCAnXjb+S2AVczQmRgK277xjqpUxZIhsn2nQQMonvP46T5JV8OCB3BifNAk4ftx0vG5dyapt3VreU16FVczRTJDemKJtr0iUabZv3672EJ7Rp4/cGM2XTxqSVKokpYfIPmlxjpJ9UxTgxIm0A7atW0tG4MKFwOnTQGys1H+aPh14/32gVi2ei5Jl2dI6GhoqOy7XrpV/x8QAX34J+PsDM2eaMkLIutjSHFVLUpLs9qhXTwK2JUvKe8+AATYfq7IIztFX4+0t6/bYsYCjo5RJKF8e2L37Jb/Q7duyLal4cel8NG+eBGzd3EzBWYPs2eUXICTELn4JrGKOenhImnXK4sZnzgB6vdS/7d5darm88YZsFUhruxplmlOnJGHOx0euU44fl1+d996TBJXNm+W/41UDtoCVzFELsv1ViWxa3bpS57ZcOeDmTdnNMmOG2qMiInt39qx0RU5MfPZjOp1cF/z3nzR5addOdt/ZwXUCkcU1aiQ3dufMAYoUkbprPXpIIHfVqvRlwRPZisuXZcf3sGES++jaVTp8V6yo9siITBwdZWdEeLiUiLpwQW5kjxsn89bM3buSkdm3L/DZZ6bjnp6yvd7JCahZU+6Sb9oEREdL1k+3bhb8iShTzJ8vJ9ijRgGlS8v/77//yol0YGAqk4NeVXIysGQJ0LixvMQ//yxJJqVKSQ3qq1dl93PZsmqP1LbxEpGsXvHikmHbtq3Uu+3ZU7Z3JSWpPTIisjcJCcDIkXLysm6dXCsApnJohpq2Q4eqN0Yie+PgAHTqJFkiEyYAuXMDR48CzZsDDRtKUJfI1i1eLDcMt20DcuYE5s4FZs0C3N3VHhlR6qpVk1I3b78t13Vffgm8FvYAd/9cJQHaihUlONu2rRTWnDXLFLjT6eTOXHS0RH9HjJD0cjc3FX8iemV+fsDgwdIMIiIC+PxzwNdXsqcN2Q+GE+1du3hnNoPu3JGbJH5+UlJ43Tr5lWrVSnYxnTwp5aZy51Z7pPaBNW0zyN5q2l6+fBm+vr5qD+O59HoJlgwbJo8bNgQWLADsoBwKwTrmKNm2zZtli9CpU/K4USNgyhRpNjZiBHDypILAQB2GDmUjXNIme1lH796Vrbc//yw3WgApmzd6tNwIJu2ylzmamR49Aj75RLKhAKByZUlY8/NTd1y2inM0kyUlQXF0wqxZkky7Nq4mauKpenilS0sKeVgY8NprpjvmlCqbm6N6vRRaNcRk9uyRRnOAlMh45x2pgRsUpN4YrcS+fVKr9q+/TOdHefMC774r1ziWOkeyuTmaBjYiy2L2FrR9/PgxXFxc1B5Guvz7L9Cli9SU9/OTlP4yZdQeFWU1a5qjZFtu3wY+/RSYPVsee3nJlqG33zZvOMw5Slpnb3P04kXZMTt3riTjODsDH3wAfPWV1Msn7bG3Ofqqjh2TRk5Hj8rjzz6TncV8CbMO5+grSkqS7Q8bN8qf3bulrk2uXDh5EthedxAa3JqHDWgAl6ZheGtqGFyLFVJ71FbF5ufosWOSJrp4MfDwoel4SIgEb7t0AQoWVG98GhMfD/zzjwRr9+wxHa9QAejXT65nLN3A1ebn6BNsREaZas2aNWoPId3atZOGCsWKAefOydaaZcvUHhVlNWuao2Qb9Hrg99+lxtPs2RKg7dNHtgy1b28esAU4R0n77G2OFi0qv7sHDki9tsREueHi5wd8841kKJK22NsczShFkaaWlSpJwNbLS7a0jh/PgG1W4xzNgHPngB9+kL3XefPKxdugQVJ79v594ElTosBAoOPZ4fjxw0i8i9/RZXVHVHu9kHGHE6WPzc/RMmWkkP2tW5Iy+tprclf20CHgiy+kg5aBHecvXrokv2a+vhLH3rNH3h86dZJYyr59UvrZ0gFbwA7m6Eti0JZsUnCwNCirW1d2S7RuDYwZY9frMhFlomPHZH15913Zah0SIic4U6awvhORtQkNlYDWmjXyuxwTI01w/P2lRGJystojJEq/u3elg/d770kGVZMmEqto3FjtkRFBLsZOnwaiokzH1q4FBgwAli+XIG3u3FJH6uefJcDWtKnxqW7uzvjxR0nIyZdPyppWqADMnMnrPHpK9uySJrpkCXDjBvDLL1L/uG5d03M+/1wK3M+dK3PPxikKsGGD/HoVLy6lou7cAQoXlhJRly9LvLtatWeTT0g9DNqSzfL0lKLZ778vC9TgwVLSJi5O7ZERkbWKi5NGGKGh0tciRw7gu+/kbrShfBYRWafGjSXrds4coEgR2ZHbvTtQvrz0s2FAgLRu2zZ5f1q0SBLLJkwAVq6UTFsi1Vy+DPzxB9C1qyyuAQGyH9ugQQMJzH77rZRGuHNHJnHfvlKvNpXoUcuW0jOgfn05N+vRA+jYUW66ET0jb16gVy+po+joKMf0euDPP+UNvnNnWSjbtweWLpXu5jYkNlbKHwQFSd+f//6THz8sTF6SCxck67ZAAbVHSqlh0JbSpWTJkmoPIUOcnaWZ6LRpUpN+wQKgdm05dyDbYq1zlKzHqlVA2bJSJispSTL4jx+X5JD09LzgHCWt4xyV5tOdOklDwW+/lYSvI0ckEadhQ4knkHo4R1OXnCwNL+vVk3PckiWBHTukAZkDr/YsinP0ievXgd69gVKlJFDbrZvUo7lyRfZg37hheq6/v5xkffqppM0agmov4O0tCTpjxsinzJ8vN9l2786aH8lWcI4+4eAgXYSHDpV5+uiRBAtat5aat4MHqz3CV3bihNz78PGR+rQnTwI5c0pS27FjknXbtq32evdxjppjI7IMsrdGZLZg61apd3vnjtxFWrQIqFlT7VERkdZduwZ8+CGwcKE89vWVHXutW6s7LiLKenfvyvbBn34yJd506CDNnCzVRZnoea5ckQzDrVvlcZcuklHl7q7uuMiO3LsnE9DREWjRQo7Fxkp2Y3KyHK9cWdL6wsKAGjUyvVDmrl2yozIyUgJQo0ZJ4z3etKB0URS5Kzt/vvy5fh346COptQzIPDbU4tB43YCkJCkfMmmS9PIzCAiQAG6XLgDDV9rARmSUqWyhGHSdOlLnNjhY6pLXrw/89pvao6LMYgtzlLQlOVmCs4GBErB1dJSspePHMxaw5RwlreMcfVbevJJxe+qUZODqdMC8ebIuDBhgXpaRsh7nqLn//pM6zFu3SvbUnDmyC50BW/XYxRyNi5M6tAMHAlWqSHHZ1q0lUmqQK5d0vlu2TBbKnTulaGaDBlnS2ahaNYmpvf22BK0GDpR6ztevZ/q3snp2MUdflk4nnRu/+062K2zcKOmoBps3y8cDA4Hhw6Uus8bcuiVZ5yVKSPbsxo1y06JNG+npZ8i6tYaALeeoOQZtKV0e20hdl2LFZLvYG29Il+hevYD+/eXfZN1sZY6SNuzfLzVq+/eXvgRVq8qxCRPkwjgjOEdJ6zhH01asmATE9u8HGjWSrNsffgD8/IBvvpFdlZT1OEfFo0fABx9IM5m7dyWWcPCg3Fggddn8HG3bVurGNGkii9/evVIc099fJmLKTbwDBkjxWQ8PiwzNw0OSJH//XXpQrV8vyTorV1rk21sNm5+jr8rRUbK7SpUyHTt7Vm42nD4NDBsmaauVKgHffw9cvaraUBVFyoF07iw7AQcPlpizp6f04LhwAVi8WO6VaDxB2AznqDkGbcnu5MgB/P231P4CJJOuaVNmyxCR7Ob78ENJHNm/Xy4ApkwBtm+XbCYism/ly0uC2Zo1sibExEhGl7+/ZDgmJ6s9QrJ1x47Je9SUKfL400/lPYolACnTJCdLh9Xx46X2RspArKOjZLv4+prq1F6+LNsRfv5Z9ciQTidNyfbtkzX6zh2p2DBgAJCQoOrQyJr17g3cvCl3b5s1k9+D/ftlC56vr6SxWtCjR8CsWVJ1pFo1YO5cuZlcpYrpV3LMGCknTdaPQVtKl4IFC6o9hEyl0wFffy11bXPkkO0DVaoAR4+qPTLKKFubo2RZiiLdU0uXltqVer3URjt5EujTJ909MZ6Lc5S0jnM0/Ro3Bg4ckIsjX1+pK9qtmwR1V682j3FQ5rHnOaoowC+/yEX60aPSn2H1ainf4eKi9ujIwCrnqKLIpPrpJ9lLnS+fTLQvvpB6MGfPmp47fDhw5gxw8SIwc6ak+BUurNrQ01K6tNS57d9fHv/wA1C9uiZ3tVucVc5RLXB3l+0MK1dK3Y3Jk6VBTsmSUjbBYPJkaWgWF5fpQ4iMlBvFvr5A9+4SN3Z1Bbp2BfbsMWXdurll+re2KM5Rc2xElkFsRGY7jhyRMkwXLsi257lz2WCIyJ5ERso2U8P2OT8/yWBq3FjVYRGRlYiPl4Yfo0dLPx5AtiKOHy89S4heVXS0lPT691953KSJZHZ7eak7LrJShst/Q1bsoEHScTGlXLmAevWkcViHDkD+/BYdYmZatkwCXFFRkqwzaZIEuaxpuzhp2MOHMrEAOSEoWFC24eTIITVsOnQAGjYEnJ0z9OX1ein1MXmyzGXDr2+RIpJY0rOnVf962jU2IqNMtX37drWHkGXKlZM7U/XrAw8eyA3m0aOZJWNtbHmOUtZITJRybEFBErB1dpYM/CNHsiZgyzlKWsc5mjFubrJF/dw52Snp4gJs2ABUrCg7iy9cUHuEtsMe52h4uGzz/vdfeZ+aMEHesxiw1SbNztGrVyUzpUcPKdK9aZPpY9WrS73ORo2AcePkwigqCliyRGpGWXlEqFUr4NAhudZ7+FACuJ06SUkse6TZOWqtDAFbQGpw9O0LFC8uk23uXKB5c8DbWzJE9u1L95eNiZHk99Kl5Ubd0qUSn2jYUJpQnj8vWbdW/uuZKs5RcwzaUrrcvXtX7SFkKU9PqU/3wQfy+KuvgPbtZa0l62Drc5Qy1/btkgE3cKDUhapbFzh8WGpdZ0FTYwCco6R9nKOvJm9eCaidOmVqCDVvnuya/OQT1s7PDPY0R5OTgZEj5f3p8mXZgbtjh8wlB17BaZZm5uj9+xLp/+ADWYQKF5Z90zNnApcuyZ0lgyZNJJ177VopiVC5MuDkpN7Ys4CPD7BunSTmODrK2ly+vMSn7Y1m5qgt8vAARo2Su7g7dwL9+kktmzt3ZBvfsmWm5ypKqlliR49KBq2Pj9wzOX1aKjP06yelc9etk13BmVG6Tas4R82p8pafnJyMv/76C71798brr7+OI0eOAABiYmKwaNEi3Lx5U41hkZ1zdpbtMtOny3nK338DtWrJeQ0R2Ya7d2WLaa1aclLk6SmF/DdtMi9HRUSUUcWKSa+S/fslI+bxY2kw7ecnJRMePVJ7hKR1V65IiY0hQ2RrbOfOUkO5UiW1R0aaFRtr3sX+3DngjTckUHTqlET6K1WSoOyaNVISwcDFRQpj2jhHR/mxt20DihaVTMWaNWVd1uvVHh3ZFJ1OOoT99JP8Xq5ZIzU5OnQwPee//4CyZYHRo5F46jwWLpSKJOXKAdOmSfJYUJD8Cl+9Kl+K1yr2yeJB23v37qFmzZro0KED5s+fj6VLl+L27dsAgJw5c6J///6YOHGipYdFL+Du7q72ECzmf/+TxmT58wMREXJ+s22b2qOiF7GnOUovT1EkiBIYCPz2mxzr2VMajVmqrhnnKGkd52jmqlBBMmLWrJHt7TExEi8JCJB6pMnJao/Q+tjDHF2yRObLli3Sa2H2bPljBz+6TbDYHH30SLJlBw+W8gZ585oHYoOD5Q51//4SHLpzB9i7V8ofNG5svqXbzlSvLtd4b70FJCXJutykifSWsgf2sI5qipOT/M7NmiUnAAZ//w0cPw589RWcA/3g82Z1BG/5Cd4ON9CunSSUGLJu7e2/jHPUnMUbkb333nv4888/sWjRIpQvXx4FChTA+vXrERYWBgD46KOPsHnzZkRERGTZGLZu3Ypvv/0W+/fvx/Xr17F48WK0adPmpb4GG5HZvkuXZOtBRIRk4U6eLBl6RGRdTp2SEx5D+bagILmDXbu2uuMiIvuRnAz8+aeUX7p8WY4FB0td7SZN2BCHJAb32WdyvglITeT584FSpdQdF2mIogBjxkiwdscOqZ+ZUp06Eu2ndFEUYMYM2Xb+6JEk7PzxB9CsmdojI1umKFI5YcYPMVAWL8bbyfPQABvgCEn3VhwcoGvQQG62ZM+u7mApS2m2Edl///2Hfv36oVGjRtClcobq7++PyMjILB3Dw4cPERISgsmGsyJ6oUOHDqk9BIsrUkSaP7z5pjQs+t//pK54YqLaI6PU2OMcpeeLjweGDpXAyKZN0ixozBjg4EF1Araco6R1nKNZx9ER6NJFatONHy9l7w4fluBAo0ay9Z1ezFbn6PHjQNWqpoDtp59KTI4BW+uTaXNUr5cTlr/+Mh3T6SQ7b9MmCdh6e5vq1EZGMmD7knQ62XW1f7+cK96+LT2jBgx4Nh5uS2x1HdW6R4/kJkHFilKW4/eFHpiR3A1Dq63Ff5OuIum7iUDVqtDp9ZIZnzJgu3u3XNjYCc5RcxYP2sbExKB48eJpfjwxMRFJSUlZOoZmzZph1KhReP3117P0+9iSS3Za2DVHDmDBAqknDsjJdJMmso6SttjrHKXUrV8vJ+AjRkg9yWbNgGPHgC+/lNJtFjFsmHSRecJsjo4cKR8n0hCuo1nPzU2yKc+fl4ZSLi6SNFexojQvy+K8Batna3NUUYBffpFSXEeOSL+a1auBb7+14HsVZaoMz1FFkS5DkycD7dpJ2meFCkC3buaFsAcMkCKXJ09K8ePZs+U5RYtmxvDtUunSEhPr108e//ADUKOG3GSzRba2jmrd+fPyvu/jIzcJDh6Uc4Hu3YF9+yTrtt0HBeE0oD+waxdw9qzpDh4g9arr1QO8vOST1q2Tuh42jHPUnMWDtn5+fjjwnHSCtWvXIigoyIIjSp+EhATExsaa/SH7oNNJuaj//pPaYps2AVWqyMk1EWnLzZsS+GjUCDhzBihUSJJSVqwASpSw8GAcHaWLTIrALQB5PGSIbbd9JaLnypsXmDBByrd07CjH/vxTyt198ok0TSTbFh0tNTV795aYXOPGwKFDkhxAdub77yWiExQk2/oWLZJFIGdO6WYYFWV6bteuUvMpIIB1VTKRm5s0elq6FMiXT3Y/VKggMXHLFpMkW6DXyw24li2BkiXl/T46WhqVjh8v91sMWbfP8POTwssGZ8/KTZzYWKmL27gxULgw8OGHEuTlBLV5Tpb+hu+++y6++OIL1KtXDw0aNAAA6HQ6JCQkYMSIEVi9ejV++eUXSw/rhcaOHYvhw4c/c3zVqlXI/iR1vVGjRoiKijILSlevXh1OTk7YlqKTVXBwMHx8fLBq1SrjsRIlSqBMmTJYt24d4p+kvhcoUABVq1bFzp07cedJamf27NnRoEEDHDlyxKyMRIsWLRAZGYljx44Zj9WtWxfx8fHYvXu38VilSpXg4eGBDRs2GI8FBgaiVKlSWLFiBfRPWmf6+voiNDQUmzdvxv3796HX6xEeHo5atWph3759uP6kUruzszOaNm2KkydP4syZM8av2bhxY9y+fRsHDx40HqtRowYcHBwQHh5u9lp4e3tj9erVxmN+fn4ICgrC2rVrkfBkb4qXlxeqVKmCHTt2IOrJiUuOHDkQFhaGQ4cOmd2NadWqFc6dO4fjx48bj9WvXx8PHz7Enj17jMcqV64Md3d3bNy40XisdOnSKFmyJJYvXw5DueciRYogJCQEHh6bMXYsMHp0ZVy4kAPVqwNDhpxB6dInAQAuLi5o0qQJTpw4gbNnzxq/ZpMmTXDz5k2zOs01a9YEAGzfvt14LDQ0FF5eXlizZo3xWMmSJVG6dGmsWbMGjx8/BgAULFgQlStXxvbt23H3yVWdu7s76tWrZ/Za6HQ6tGzZEmfPnsWJEyeMXzMsLAz379/H3r17jceqVKmCHDlyYJOh6CeAoKAg+Pn5YdmyZcZjhtdi48aNePjwIQAgX758qFGjBvbs2YObN28CAFxdXdG4cWMcP34c586dM35+06ZNce3aNRw+fNh4rFatWtDr9dixY4fxWPny5ZE/f36sXbvWeKxUqVIIDAzE6tWrkfikRkWhQoVQqVIlhIeHQ6/XY9myZcbXIiIiApefFA50cHBAixYtcObMGZw8edL4NRs0aICYmBjs27fPeKxq1apwc3PDlhRbzMqUKYNixYphxYoVxmPFihVDuXLlsGHDBsTFxQEAPD09Ub16dezevRu3bt0CALi5uaFRo0Y4duwYzp8/b/z8Zs2a4erVq2avRe3atZGUlISdO3caj1WoUAH58uXDunXrjMf8/f0REBCAVatWGXcmeHt7o2LFiti2bRvu3bsHAPDw8ECdOnVw4MABXH3SUdjR0RHNmzfH6dOncerUKePXbNiwIaKjo7F//37jsWrVqsHV1dXstShbtiyKFCmClStXGo8VL14cZcuWxfr16/HoSTZI/vz5Ua1aNezatcvYbDJbtmxo2LAhjh49igsXLhg/v3nz5rh06RKOHj1qPFa3bl0kJCRg165dxmMVK1ZEnjx5sH79euOxgIAA+Pv7Y/nylVi1qjD++CMQDx+6QKcDXn/9Kt566zDc3JIQHp4btWvXxv79+3Ht2jUAgJOTE5o1a4ZTp07hdIp0ikxby0NDUapDBwQOGQIA0AcH42THjgicNw/nunWD39dfW3wtB4A8efLY9Vqe8rXImzcvatasib179+LGjRsA7Hst1+l0qq/l0dHRZq+FPazlHTuuQqVKOTBrVmkcOpQf338P/PJLIt544wxatryA/Pnd7WYtX7lyJZKfdGjz8fFBhQoVsHXrVsTExACAcW2z6FqeBeflJ07kwYQJFXD7dnY4OSno3Pk4Wrc+j717uZZb21peYelS+BQpgu1hYbh79y70ej02b96MevXq4foHHyD27l2c7tBB1vJKlXBj/nwkrF6N0+3bI97TE2FhYUiOjUWu69eR7OyMu6VLI1vz5nBo1AgbY2KgODkBBw8iKCHBqs7LrXUtBw5jwgQ3fP99eRw54omuXYEZM66gT58jyJ49ySbOyw3XTGqu5blzq3BeboEYy5IlW7Fhgy9WriyK69dzGj9evvwttGx5Aa1bu6JixZdcy69eBX7+GXlPnEC18+eBhQvhePOm3GX46Sc8GD8eie++a1NruaIoxrXOls/LDWvVi1i8EZmiKPjf//6H33//Hblz58a9e/fg5eWFqKgoJCUloXfv3pg6darFxqPT6dLViCwhIcE4uQEpGuzr68tGZHYoKkoyIwzr0PDh0ljEweJ560QESF3I996T7UWAZEZMny7bTVWn10tb4gkTZK/r48dSs+Hrr9UeGRFpjKIAa9cCn38u6xoA+PpKiaaOHZmcbwuSk4GxY6U6TnKyJFTNnw9Urqz2yCjDDLtnnn5vNxx/5x1J3dy4UYoXG8yaJVmzgKTdnTkj2XVubhYdPqUuORkYN056IyQny26t+fNltyXR0w4dkooGf/4JGOJwHh5SzaBPH8DfPxO/WWKilEiYN09Sw48fl8xbAFi5Ejh6FGjfXhr0kKaltxGZxYO2BuHh4Vi4cCHOnDkDvV4PPz8/vPXWW6hTp45Fx5HeoO3T0vsC24qzZ8+iZMmSag9DM5KSZPviTz/J43btpNtojhzqjsuecY7an4cP5abJ99/LCXXOnBLc+OADwMni+0hSceyYdDC8e1cKWj1+LIHbjz+WKHOxYmqPkMgM11FtSE6WC7+vvgKeJKYhJAT45hvZFWnPO6KteY5euSLlewxJch07SmlSO7iMsG2KIicjw4cDX3+Ns126oOT8+RKwfZpOB5QvD4SFyQQIDbX4cOnl7NgBdOgAXLwo55ajR0ujQGtO1rHmdVRLEhOBxYuBSZOAFAm/KFdOrkU6dpRrkyyVkAC4upoeN20KGDJKa9WSyfvmm4CnZxYPJHPZyxzVfNBWKxi0TZ9ly5ahVatWag9Dc37/Xe6eJSbKBdWSJewDoBbOUfuybJmUfTPs2mnXDpg4UUrCqS4hQc7qx42TxeFJhm2ykxMcDY0DXFzkjG7wYMnAIdIArqPa8ugR8PPPwJgxwJMdpWjYUOrhlS+v7tgsZtgwSTF+ksFoNkdHjpQItxU0dVyyBOjRQ+7h5cgBTJ0KdO6s9qhUYLjsNNx5ePxYCj0mJpr+JCWZ/u3jI8XpAXleeLj5x1P+qVzZlLJ844ZExFN7XmIi0Ly5bJsDgKtXpTtQat8/MVEiL4MGyXOvXwfKlDF/3pMt4AbG9/ovvpBf1sBACdKGhQF16/I93wrduyf34P/5Rx43aiS1bgsWVHVYGcb3+ldz/bo0kJw+Xf4NyNtU27ZybVK7too3V2fMAObMkbuDhvXWyUkmbadOEsS1AvYyR9MbU9RCLpLFPXjwwKwexoULFxAREYG8efOiCNPI6SX07CnnYm3byraISpWAf/8FLJwwTmQ3Ll+WuvuLF8vjokVlO1KLFuqOy2jbNqBXL+kuBEijkFOngBEjsDI0FK1WrZKr9cePpT3xjBnAwIHyQ2XLpu7YiUhTsmWTUgk9e0rgdtIkYP16KQHTsaPsLLD5hH1DQ0cg9a3nI0aoM650io+XruGTJsnjChWAv/4CSpV6iS+SlCQ3A9MKbPr6mrZ6Xbsm7zlpBTYbNDDd3TxyBFi1Ku3AZs+eprsD27fLe1Zagc2hQyUQCgAbNsie4NSel5go74HvvSfP3bZN7kSkZcIE2doGyM/12mtpP3f4cFPQ9vbtZ5uApuTlZQraJiSYMtNS86TeJgBJr3xSqzVVDg4SsHVxkRu3AwYABQqk/XyyCrlzAwsWyE6H/v1lZ3pwsOyybNZM7dGRJSiKLIOTJsm1viEHw8tLmkn+738aSRzp0UP+XLkik3bePOmqt2qV1G1IGbRNTmbdJSth8aBt8eLFoXvBrQedTmdWJD2z7du3D/Xr1zc+HjBgAACga9eumDVrVpZ9X7JNNWsCe/cCbdoABw/K+fCkSbKAE1HmSEqSjLMhQ4AHD+Sm8YAB8lgTZUkSEuRM3tBIs2BByahZsMBU527ZMsn8KVhQLnALFpRsoC+/lEVj+HC50LXmPXdElOny5QO++w7o109KJvz5p/z55x85NmgQkDev2qPMIoZArSFwGxqadg1RRZGL0NQCi97eprX14kXg1q20A5stWpi2m4aHS4HhtAKbX3wB5Mkjz/3nH2DFCuPHYqOTcHB3IlrcT0QbJGLXu7/js8nF4OICeS+YNCntwObmzaa24t9/L98nLZs2AfXqyb8XL5ZUr7QsX26KLOzf//yvW6eOKWh77ZpEKtLypPkXALkpaajrkZonTasAAM7Opr+dneXN3fBvZ2fzN3gPDwnKpvx4yj+Bgabn5s8vu1lSfjzl165a1fTcAgUk+pbWGHx9Tc/Nl0/qR6b2/b/7Dhg1SjJtHz+Wecr69TZDpwPefVeu+9q3l2WheXM5Fx0zxnyHOtmOhw8l7jlpkqnWPCDzoG9fSdxycVFvfGkqXFhueH3yCXDypBRkLlfO9PGbN+VxmzYSyK1dmwFcDbN4eYRu3bo9E7RNTk7GxYsXsX37dpQtWxbly5fHzJkzLTmsl2Zv5REePnyIHJqIjGhXXJzc2FqwQB736SPbtQ3no5S1OEdt1549kpRjaHpdowYwbZr5uYfqFAVo0kTSL3r1kuKTEyeabes1m6MjR8qFesmSEoW5dEnOALdts++ClaQqrqPWYf9+ycA1NETNnVsCt/362WgPI71eLioXLIACQAdIocCYGFMgtkMHuShNS2ws4O4u/+7eXZpApeX6ddO+5379TGmyqTl7VrqJAbJr4ptv0n5uRITU0gJMgee0bN8ub3aABG0N2aaA/Mwpg4WLF8tNQkBOQocPTzuwOWwYUK2a6Xv8+mvagc233jK90Z47J9moaQU2Q0NNwc1796Sp1tPf2/A5Hh6mnSVPl0uwViluJDwcMAA5vv8+9RsLZBMyJYNeRXyvf7GzZ+Xe2syZsqQBsmx17Cj3g6y+HPX06aYdD4Dc2GzfXt5LK1RQfU22lzlqlTVtDx06hCZNmmDu3Llo+LytMhpgb0HbGzduoKC1Fu6xIEWRrsBffSX/rltXEi/y51d7ZLaPc9T2xMRIydcpU+T3KU8euR7u2VMjyahXrkjgIHdueXz+vGQXGS6en5LmHI2Plx+yRg3TxfS9e8Dp02xTTBbFddR6KIrE0L74wpT9U6SIlEzo2FEja+SrUhTJDB0yRAKeT4uPN6W3dewo6VCpcXaWrCJDRuznn0uEJa3A5qJFpi3tM2ZIN+60Aptffml67pYteLR5N/5e7Iy9h5yRBCf4BzmjR29n5M7vLA1iDGO4cAGIjEw7sFm4sCkCn5AgN/kMH7eJ/1wb8lTmt3EdTSsjnGzG0qVyD8hQq3rKFKBLF7VH9WJ8r0+dXi9VBCZPlr8NSpSQQG337qYl3OolJ0vd2/nzgYULTZFpAPD3l/dTw24PFdjLHE13TFHRmCFDhigVKlRQexgvFBMTowBQYmJi1B6KRSxdulTtIViVpUsVxd1dUQBFKVpUUQ4dUntEto9z1Hbo9Yry11+KUrCg/A4BitK5s6LcvKn2yJ5ITlaUSZPkl7x373R/2kvN0S++kB/8jTcU5fTpDAyS6OVxHbU+SUmKMmuWovj6mtbLkBBFWbNG7ZFlgm++Mf1QLi6KAijJjo7yuE8fWYsNoqIU5cYN+TsmRlHi4hQlMVHeUCxk+3Y55wMUxclJUcaPNx8i2aihQxVlxAjjQ7N1dMQI+TjZrCtXFKVePdNS1amTLEFaxvd6c1FRijJhgqKUKGH6f9TpFKV5c0VZscIO1vH4eEX57z9FeestRXFzUxRnZ0W5c8f08YMHFeXqVYsOyV7maHpjipq7Vevl5YXjx4+rPQwaNiztAv4jR1pFp141tWoF7NolO+YuXpQEukWL1B4VkfadOydNHdq3lxJ5/v7S02T2bI308jh2DKhVSwpZ3b8vjVwSEjL/+9y/L1uTFi4EgoLkFv/Nm5n/fYjIqjk6Al27So+mb76RneeHDkm1lkaNTGVlrEZcnOnfnTtLDdFataRO6ogRWLF4sWQuTp0KjB5tem7evNIRJm9eIFcu2cfq5GSRLZ7JyTKUOnXknK9ECWDHDtk+zaRYOzBsWNqZtF9/zWsmG+fjIw0iR46U9XjuXNldvnev2iOjFzl4UOoU+/gAn34qG+Zy55Y6xadPS4ny5s3tYB13dQVat5byOrduSZpxvnymj7//vuz+CAsDfvvt+c0YKUtoagpGRUXh999/R+HChdUeChm69T4duDVs9WGh6hcKCpJanA0bShHzdu3kvE2vV3tkRNrz+LFc9JYtK1t+XVzk9+XQITlHUF18vKx95csDO3dKbcRJk6QGbVZ0n5g8WfY8t2gh22KnTJH6t8OHSyc2IqIUsmWTXf/nzgEffyxr6Pr1Ejzo3FmCiZq2Y4d0cn3zTdOxQoXkYjE83HyL+ddfy+PUzlMt7OpVOc/76isJ3nboIIGAypVVHRYRWZCjo6wBW7ZImZpz5yRh59tved2nNY8fS0WAmjXl/fH33+UUPyRESnxfvSo9BUuWVHukKnF3l/dig/h4iVorijS97NVLbpC2aSNB3pQ3WinLWLymbVgaV9/37t3DyZMn8fjxY8yZMwfvvPOOJYf10uyipm2KWky32rZFgUWLWJspA5KS5O7dxInyuG1baVKbM6e647I1N2/ehJeXl9rDoAzYulVq4Z84IY8bNJAYpb+/uuMyOnoUeOMNSWUDgNdek6DqS95gzPAc3bxZojGGtI3+/U0LClEm4jpqOy5ckCCCocyri4v01Bo0SJJRNWPfPjmnXL1aHjs7SxOrokXl8bBhZg0dzeboyJESKVUpkzG1epadO6vev4VUxnXUvkVHA//7n2yUAmTHw+zZpt6GWmCPc/TqVem99csvpo1rTk5yet+3rwTZuXY/R2Sk1IKfN092GRq0a2ea7JnIXuaoZhuR1atXD7qnfiN0Oh3y5MkDPz8/9OjRA4GBgZYcUobYRdAWMAZujd16v/pK9awGazVjhgSmEhOB4GBgyRKgWDG1R2U7Hjx4gJyMhFuVO3ckFjlzpjwuUECaZHfooLETp9u3gdKlJZgwaZLcecnAAF9pjiqKnBSNHClNcQwBY0NHdE29YGStuI7anv37ZZ3duFEe584tDR779jX1uVLFoUOSCLB0qTx2dAS6dZPgrCFgmwotzNHUOsfPn6+hG42kKi3MUVKXosgu8g8/BB49kvPbP/6QXoRaYC9zVFEkMWTSJGDxYrnHB8gmjvfek6TRQoXUHaNVOnJE3vTmzQPGjZOadoAEdr/9Vi7kqld/pboS9jJHrbYRmbWwq0ZkDg6mqtwFCyrKzJl2UJE7a2zfriheXvJS5sunKJs2qT0i22EvBcttgV6vKDNmyO+AYWnp3VtR7t5Ve2RP6PWKsm2beQObHTsUJTr6lb5spszRp5vqvP66olSrpihbt7761ya7x3XUNun1irJqlaKUK2dac4sUUZTZs1U6nVu50jQQBwfpNHnmTLo+Ve05evy4ogQHm4Y/YID0cCEyUHuOknYcO2a+7n7yiaIkJKg9Ktufo/fvK8rUqYpStqzptQcUpU4dRVmwQFEeP1Z7hDZCr5duqAZjxphe7KJFpanyoUMZaghq63PUwGobkZHGjBwJ6PXQG2rY3rghe8GqVgW2b1d3bFaoRg3Z4VyxIhAVJVtmpk5Ve1RElnPiBFCvHtCjh/wOlCsnpQynTQPy5FF7dAAuX5Y6TbVrm3cPrF5dUtTUljKj9vp1YO1a6XpYp46UbWAjTyJ6ik4nGV4HD8rOhsKFgUuXgC5d5Hxk3ToLDCJlw8awMMmmffttKT8ze7bmCwgqitQ+rFRJyo3nzy+bHr77LmvKmhOR9TP0N+nbVx5/951cC545o+64bNXp08BHH0ljsT595O0le3YpV3HokNQcfust2ThHmUCnM+9zVLeudEZ1d5dC+t98I8WCy5WTxiUxMeqN1co5ZfU3mD17doY+r0uXLpk8EnppKWrarggNRat9+6SerYuL1CCrVUtWxh9+UHukVsXXV3oX9ewpOwvef1/eSH76SV5aIlv06JG8X48fLyVCsmeXMoQffaSRk6fkZLmD8uWX0ujL2VmiGlpWqBBw9qw0J/v1V2DZMml12727HPPxUXuERKQhhgoEb78t5xxjxwIREUDjxnIT+ZtvpNdipoqMlPPJXbvkZMfJSaKcR47IhZ0VuHcP6N0b+PtveazFGpVEpE1ubsDPP0vDwh49pGRNhQqmGtj0apKT5QbapEmSx2BQsiTwwQfynqeFnAu7UKOG/Jk6Vf5T5s0Dli8Hjh0DxoyRiz6DxESNXABaiaxO+dXpdC/9x8HBIauH9cpsvjzCiBGS2j5ihKIoinL27Fnz4xUrKopOpyhz5qg4SOum1yvKuHHyMgKKUru2oty6pfaorJdxjpLmrF6tKCVKmHbMtGypKJGRao8qhSNHpMSAYYDVqyvK0aOZ/m2ydI6ePKkobduafoZs2RRly5as+35kk7iO2pc7dxTl448VxdlZlg2dTlE6dcqk9fnyZUV57z3TFwfkzeAVWXqObt8uuzwBRXFyUpRvvmGFMHo+rqOUlsuXFaVuXdOS2KmTosTGWn4ctjBH79yR9bhYMdPrqdPJNcbq1VynNSM6WmrijRtnfjwkRFEaN1aUWbMUJSZGUYYONcadFOWpOTpihHzcBqU3ppjljcguXryYoc8r+pwmBFpg843InurWa8bQrffNN6U5j6HI9MKF0p2hQ4dXKjxtb5Yvl5fs/n3ZLbhkiewkILJ2168DH38MLFggj318JNugTRsN9c2aNEkGmZQkWV/jxkl3Amtdw3bulK5DkZGyTyxbNrVHREQad+GCNCebP18eu7gA/fsDgwZloGzNjRuyjk6bZiqJ0LCh7NSqXj1Tx52VkpPlxxg6VP5dooS8PlWqqD0yIrJmycmSdDhsGKDXA35+wF9/SekVerH9++XU/a+/JOwAAHnzyg7WPn2A4sXVHR+lw5kz5p07XV3lF+H4cdnlPXy46WMpdn6nGpeycmxElsVsPtP2KS8sBh0bK03KAEWpWlVRdu2yzMBsxPHjilKypLx82bMryj//qD0i62MvBcutQVKSokyapCi5cpn6zHz0kTrZBC+0dq0MsnVrSYHIQhabo3q9oly5YnqclKQorVopyty5TD2g5+I6at/27VOU+vVNWUu5cyvKt98qyqNH6fwC585Jln/Kri+ZnPFviTl65Yr56/DOO5IIRJQeXEcpPcLDpSGkIYv/228td4pmbXM0Pl4291atat5YrHx5SeKMi1N7hPTSzpxRlJEjFSUw0Pw/FVCU116TOfrUzm9bxEZkZFnOzpKWkTMnsHs3UK2aFOq5ckXtkVmF0qWlUH2jRkBcnCQxDx0qd2CJrMnBg1LOqG9fIDZWMgf27pXS15ooXxgdDWzcaHrcqJGsWYsXS3ceW6DTmdeznT9f6t126iT/IRbpOkRE1qZiRWDDBilFV7as1HL97DMgIACYOzeNc5KkJNO/ixeXVNRq1WSd2bxZmiRakWXLZLfTpk1AjhzArFnAn38CtripjojUU7Om1BRv106W0c8+A5o1k80KJC5fBr76SvrBdO4sp+vOzkDHjtLEeP9+aePATWVWqGRJ+c89flwuHj//XP6jAWDpUjRv29amM2xflipB2xs3bmD06NFo164dGjZsiLCwMLM/DRo0UGNY9Crc3KSBz+nTsnrqdHKGHxAgv2xxcWqPUPPy5JELpY8/lscjRgBvvCFlE4i07v59YMAAiQnu2SMXuJMmSe+ZChXUHh3k3u0//8gdktat5UzQoEoVDdVryAJt20oXuFy55MSocWP5c/Cg2iMjIo3R6SRwEBEBzJwp938uXZIL5ooVU9zziY2VE5USJYCoKNMn//efXE03bGhV62p8vOQevPaa/DjlywMHDkgjbCv6MYjIiuTJI6emv/wigce1a+Wm0Zo1ao9MPYoiN83atZP7gKNHA7dvy3vRyJFy+j53rlTb4dpsA3Q6IDRUOqFGRgJbtwIuLnBMSpJaTQzYAlAhaHv48GEEBQVh1KhROHfuHDZt2oTbt2/jzJkz2Lx5My5fvgwla8vsUgYUKVIkfU8sVAiYMUNS62rWlGDt0KHA4cNZO0Ab4eQEfP+9XCi5uEjyX40awPnzao9M+9I9RylTKYrM06AgyabV66Uz+YkT0rXV0VHtEULO8Fq3Bt56C7h5UzJq7961+DBUm6PZs0txynPngA8/lDSFdeskmt6pE/DwoTrjIs3hOkoGjo7SdfvMGWDsWLnnExEBtGn8EL/7f4OkIsXl/O7yZTlpMcidO0uvpLNijp48KcnBP/8sjwcMkPLgKUvuEaUX11F6GTod0KsXsG8fUK4ccOsW0LSpZN4+fpw131OLc/T+fWDKFNnlERYGLFok9X/r1ZO2OZGRkpjp5aX2SCnLODjIDp3Hj6F3dpZfgJEj1R6VNlimWoNJs2bNFF9fX+XixYvK7du3FZ1Op2zYsEFRFEX5+++/lXz58im7d++29LBemr3VtM0QvV5RFixQlE8/NT9+44Y647EyO3eaygTnzasoGzeqPSIic5GRUirVUIKoeHFFWbVK7VGlkJSkKD/9pCg5c8oAnZ0VZcgQKY5lz86dkyKNgKLUqCFrNRHRc9y+FKcsrvO9cgMFjIv+1VyByq2f/7LaWtl6vaL89pv0EgAUJX9+RVmxQu1REZG9iotTlPffN51XV6okpT9t2YkTitK3r6K4u5t+7hw5FKVPH0U5elTt0ZFFPV3DljVtjSyeabt9+3b07t0bRYoUgcOT7tz6J0Wy3nzzTXTs2BGfffaZpYdFL7AxZQ3I9NLpJLPt229Nxy5elL0OXbsC165l3gBtULVqcte1UiVJCmzUCJg8Wd7O6FkZmqOUIYmJ8msdFCT1/5ydJZHz6FHJDtCEpCS5Pd+/P/DggaSsHzwoHUldXVUZkmbmaIkSwLx5ssBMnmzKirt3D5gwgeVs7Jhm5ihpS3w8PGuXRputA+CFW7iR0w+dMRu+sUfh++nb+OwLB0RHW2YomTVH790D3nkHePddWfIaNAAOHQKaN8+UL092jOsoZVS2bHJatnixlE7Yt09Ktcydm7nfR+05mpQklXQaNpSqZZMmSaatvz/w00/A1auSdVumjKrDJEsaOdKshu3GjRulNMKIEXLczjNuLR601ev18HqS1547d244OjriboptquXKlcP+/fstPSx6gYeZtX125Urg0SNg9mxZmUePlseUKh8fKe3SsaNsEenbF+jdO+u2y1izTJuj9Fw7d8qNhM8/lwvd2rVly+zo0bILXzOcnKTglbu7nPlt26b62Z/m5mjFilJHyuCbb2Q/nr+/lLlJTlZtaKQOzc1RUk/KrmNubkCTJkCRIsBvv6Hg3RP4cG9n1K3viIQEudfj5wd8953Uhs1KmTFHd+6UQMiCBfJWMW6c1JIsVCgTBkh2j+sovao2beQmUp06knfQuTPQpUvm9TlRa47evi3rrZ8f8Prr0vjSwUEqmK1dK6XV+vUDPDxUGR6pKTnZrOmYcY4aArd2fk1i8aBt8eLFceHCBfnmDg4oXrw41q9fb/z4jh07kDt3bksPiyylTx9p/Vi9utRR/OorucX2zz9MIU1DtmzAnDkST9HpgF9/lYyQW7fUHhnZk+ho4L33pFT14cNAvnwS19uyRTJuNWHLFuDYMdPjYcPkDLBPHzkrpOcLCZGgzNWrQM+e8nj5cq7NRPYkOVlurAcESNTA4JtvpNlsz56AszMqVZIL7pUrpQZhdDTw6afyaXPnmsd8tSI5GRgzRm42RkbKxq/wcOCLL/gWQUTa4usLbNwo8SoHB7kWrFBBsm+tzZ49ssm2cGHpW37pklxHDBwofVv++092lHIdtmPDhqXddOzrr+XjdswivxrRKfZMNW7cGP/884/xcZ8+ffDbb7+hYcOGaNCgAf744w906NDBEsOil5AvX77M+2JVqgDbtwN//imr98WLUkahaVMGB9Kg00lm4/Ll0gwkPByoXJnN31PK1DlKRooiv6qBgcD06fK4Wzdp3NK9u0Y6t0ZHyx7XevUkoGC4G5s9u6Sra4Tm52j79sCpU5IulyePBMBbtZLXdfdutUdHFqD5OUpZR6+X1NMyZeTq+uxZ6YxqkDv3M6VldDqgWTPZbTFjhiy3ly5JVlilSkCKnIxMk9E5evWqBAUGD5a3iHfekXOoqlUzeYBk97iOUmZxdJR41ZYtEsQ9e1aqfX333avdGLPEHI2Pl/t/VarIOjt7tuwUrVQJmDULuHJFmlwWLZrlQyErxHXUnE5Rsj5K5urqiubNm6Njx46oWbMmrl27huDgYDg7O0NRFIwePRr//vsvHB0d0bJlSwwaNAguLi5ZPaxXEhsbCw8PD8TExCBXrlxqD8d6PXwoxTHHj5cUjREj1B6R5p08KdtITp+WLNxZsyTmTZTZzpwB3n/fdOEdGAhMmwbUravuuIwURbL0+/cHbt6UY717Az/8IL8clHH37sketokT5cy7WzfzDvFEZBsURdKchg4FjhyRY3nzyp3ivn2BHDnS/aXi4qQe4dixQGysHGvcWE7xQkIyf+jptXy5LGFRUfLjTJokcWlN3HQkIkqH6GigVy/g33/lcZMmwB9/AE+qTmrGxYtyrfDbb8CdO3LMxQV4+215S6lSRd3xEWlJumOKluiK1qFDByVnzpyKg4OD4uHhoXTv3l1Zv369orfijtXp7fRmK3bv3p213+DSJUV58MD0ePt2RRk7VlEePcra72uloqMVpUkTU5fNwYOttnlzpsnyOWpH4uMVZfhwRXF1lfnl5qYoo0bJcc24dElRWrY0/RIEBirKtm1qj+q5rHKOXrqkKO++K3+nPHbjhnpjoixjlXOUXk2zZqZ11MNDujS/4rnt7duK8uGHiuLsLF9Wp1OULl0U5eLFVx/uy8zR+HhF6d/f9OOVL68oJ0+++hiInofrKGUVvV5Rpk+X83JAUby8FGXNmpf/Opk9R/V6RVm3TlFat1YUBwfTmuvrqyhjxijKzZuZ+u3IDtjLOpremKJFyiP8+eefuHXrFubOnYvatWvjzz//ROPGjeHj44NPPvkEBw4csMQw6BXcNGSxZRVfX1M2h14PfPihFL0JCgIWLWLZhKfkzg2sWAF88ok8Hj0aaNs28wrUW6Msn6N2YtMmIDhYkq4SEiRL6uhR2VL61M5Y9UREyNqwfDng7CyDjYgAatVSe2TPZZVz1NdXCmn7+pqOffQRULIkMHy4dMggm2GVc5RejuF62qBRIyBnTukxcOGC7MV9xR1knp7Ajz/KzqD27eXbGfrPfv65ZIxlVHrn6MmTQLVqkvkLyLK1c6fU3CXKSlxHKavodMD//id1bcuWlU1mTZrIuvoyTaoza47GxgI//yyn5I0aAUuWyGV8gwbA4sVSr/bLL4ECBTLl25Ed4TpqzmLlnrNly4Z33nkHy5Ytw40bNzBlyhSUKlUKP/74IypXrozAwECMGjUK58+ft9SQSMv69we8veUCol07ICzMvCEGwdFROjb/8YcE05Yskf5u586pPTKyRrduSWfasDApvVGwIPDXX8Dq1dLlVVPKlpUr75o1JVg7bJiGIso2Li4OuHxZgrXDhsnkmDIFSExUe2RE9CJbt0qNasP+WkA6TF64AIwcKbWsM1GJEsD8+cDevfJtExKkIpafn9RkjI/P1G8HQALEM2YAFSvK24Onp9zf++EHvk0QkW0oU0aae73/vjz+9ls5JT571jLf/9gx+d4+PnLJfvKk3Pvr2xc4flzKqrVpAzg5WWY8RLZOlR59efLkQe/evbFlyxZcunQJ48aNQ/bs2TFkyBCUKlUKNWrUUGNY9ByuljzTdXCQLhanTknGh5sbsHkzUL683F68dctyY7ECXbpIgfpCheRNtEoV6ehsbyw6R22IXi91pwIDpTOtTicnYidOSP0pTdT8i4+XM9JHj+Sxk5O0LN+6VW7vWwmbmKPZs0tTsgULJPJy6xbwwQdyBbFwIXdFWDmbmKP0rF27JA2qbl1ZN8eONf2uZssmkc0sVKmSdEFfsUKWiuhoaWMQGCiNLl+moc7z5mhMjDQY69lT7i81aAAcPgy0aJEJPwRROnEdJUvIlg2YPFk2pObJI9m35cvLmvoiGZmjSUlyvy8sTHInpk6V+/elS8s4rl2TrNvSpTPwwxA9heuoOYs0IkuPI0eOYMiQIViyZAl0Oh2SDd2/NYqNyCzo4kXgiy8kSABIammXLuqOSYOuXZO7mnv3ShbuDz/IHU9NBN1Ik44elSSr7dvlcWioNA/QVDftzZvlZs2ZM1KjYdQotUdEBo8fS+mE4cOB27fl2O+/Az16qDsuIhL79wNDhshNLkDKybz7LjBoEFC4sCpDSk6WUglffw1cvSrHypeXZmUNG2b86+7aJQHbyEg5Bxo1SrYMO6iSnkJEZDmXLwMdOwLbtsnjLl2k4aK7+6t/7Vu35FRv2jTgyhU55uAgTbH79gXq1+e1JlFGpTemqOqpjCHLNiQkBKGhoViyZAlq1KiBSZMmqTksSsXx48fV++ZFi8o+7W3bJH2iUyfTx65dY2bXE97ekkDTubNcFPXvL11GExLUHpllqDpHrUxcHDBwoFwob98u5aS//14C/poJ2N69K8GF+vUlYFuokKRrWTGbm6MuLpJle+6cBIYCAiRqYmAvi48Nsbk5as8GD5Y1c+VKiWL27Cm1b6ZMUS1gC8hQuneXoYwZI+VzDx6UROCmTV9cCevpOZqcLInDtWpJwLZ4cSA8XN7jGLAlNXAdJUvz9ZWeFMOHy7o3ezZQoYLct0vNi+aoosiNsE6d5Gt/9ZUEbPPnl3t+Fy5Ihm9YGAO2lDW4jpqz+OnMnTt3MGXKFNSqVQvFixfHoEGDkJiYiBEjRuD8+fMIDw9Hnz59LD0seoFzWiiUWquW7OM2nIU/eABUriydko4cUXdsGuHmJonIEybIy/T77/KGag+1vDUxR62AYXvqN9/IVqc2baQUwscfa6T2lKJIVn3p0jKBAaBPHxlkmzaqDu1V2ewcdXeXK4WjR2W/HiCRlGrVJFBkSM0gzbPZOWqPatWSq+lOnaTg4G+/AcWKqT0qo+zZpUHNuXPSe9bZGVizRm4mdu0KXLqU+uelnKPXrskp4KBBsuS0by8B4GrVLPRDEKWC6yipwdFR7p9v2SKB1rNnpdfJd989W4ImrTn66BEwc6bc76teXUotPH4sCR1z5khG7+jRQJEiFviByK5xHTVnkaDtw4cPMXfuXDRv3hw+Pj7o27cvLly4gI8++gj79u3D8ePHMXjwYBSz8Mnk5MmTUaxYMbi5uaFq1arYs2ePRb8/vaKdO4GoKKl2HhoqhTgNW3TtmE4HfPKJBOc8PIAdO+TN98ABtUdGarp6FXjjDaBlS8lG8vWV5nWLF8u/NWP0aLnyvnVLArfh4ZIZ5uGh9sjoRVJG/bdskS5AM2YApUpJdCYmRrWhEdm0c+dkP+zYsaZjTZvKLoU5c4CSJdUb2wt4egI//miqo64okiXm7y+VsaKjU/+85cuB4GCplZs9uwQa5s3jWwUR2bdateT0q21b6RH76adS1/t5CTwXLkg5mcKFpcLVgQPSuLFbN9mFZ8i6ZZlRInVYJGhboEABdO3aFdu3b0eHDh2wdu1aXL58Gd999x0qVKhgiSE8Y8GCBRgwYACGDh2KAwcOICQkBE2aNMEtNrmyHo0ayVl+u3ZyC3HqVAkO/PCD3Ba0c02bSr+ggABJdKtVy1QWmOxHcjLw008S//z3X7kT/+mn0t31tdfUHl0qOnWSjgrDhknKVM2aao+IMiIsTO4Y1aoljeTGjZPGZT/+yLIJRJnl4kWpgxQQIMHZ8eOl/g0gd3D9/NQd30vw85NKWHv2APXqyTIxfrwc//57OX8JCQHatWuO/PmBVq3kvn1oqAQYunXjNl0iIgDIm1d6w06bJrswV6+W9XPoUNM6GhIimbmvvSbr7LffSmWyokVlN96VK6asWyJSl0UakbVu3RodO3bEa6+9Bjc3t6z+dulStWpVVK5c2Vg/V6/Xw9fXF/369cPAgQNf+Pn21ogsMTERzs7Oag8jbVu2yP46QzG0gAC5NZgZFdit3L17UmZy9Wp5PGgQMHKk7dV60/wcVcG+fdJozFDTqlo1OYELCVF3XGYOH5Y9sZ99Zjp2/75N/u7a5RxVFGDZMikweeKEHCtWTDKofXxUHRo9yy7nqDW6elUKwv76q6RSAUDz5sCIEUDFiuqOLRMoCrBqlWR+HTtmOq7TmbcxaNFCbkYy+4u0hOsoacnRo7KBLeVamprGjaVNQYsWkuBBpCZ7WUc11YhsyZIleOuttzQTsH38+DH279+Phina1Do4OKBhw4bYuXNnqp+TkJCA2NhYsz/25Nq1a2oP4fnq1pXI1K+/AgUKSOqFDQZ9MiJ3btlGaIiJjRkjpUFtbQprfo5aUGysNKKrWlV+LXLnlmDt9u0aCtg+eiRb5itWlCvzTZtMH7PR3127nKM6naRxHD4s67O3tzSV8/ZWe2SUCruco9Zm3jxJi5oyRQK2DRpIVvuKFTYRsAVk2WjeXO7D//67qfJKyoCtTieZYAzYktZwHSUtKVtW8pjy5Uv9456eUvZ8zRo5XWPAlrSA66g5LbSdsbg7d+4gOTkZXl5eZse9vLxw8uTJVD9n7NixGD58+DPHV61ahezZswMAGjVqhKioKBxIUTy0evXqcHJywrZt24zHgoOD4ePjg1WrVhmPlShRAmXKlMG6desQHx8PQMpKVK1aFTt37sSdO3cAANmzZ0eDBg1w5MgRREZGGj+/RYsWiIyMxLEUt9Hq1q2L+Ph47N6923isUqVK8PDwwIYNG4zHAgMDUapUKaxYsQL6J5XKfX19ERoais2bN+P+/fvQ6/W4fPkyatWqhX379uH69esAAGdnZzRt2hQnT57EmTNnjF+zcePGuH37Ng4ePGg8VqNGDTg4OCA8PNzstfD29sZqQxooAD8/PwQFBWHt2rVIeLKN1svLC1WqVMGOHTsQFRUFAMiRIwfCwsJw6NAhXDJ0rPDyQqszZxB58iSOLFsGAMh2+zbq7N+Pe/36YXeKMVauXBnu7u7YuHGj8Vjp0qVRsmRJLF++HIYk9CJFiiAkJMT4WgBA3rx5UbNmTezduxc3btwAALi4uKBJkyY4ceIEzp49a/yaTZo0wc2bNxEREWE8VvPJlu/t27cbj4WGhsLLywtr1qwxHitZsiRKly6NNWvW4PGTkg8FCxZE5cqVsX37dty9excA4O7ujnr16pm9FjqdDi1btsTZs2dx4sQJ1K4NJCX5YMqU8li2TIeyZe9j8OA98PaOQ5UqVZAjRw5sShE4CwoKgp+fH5Y9eR1TvhYbN27Ew4cPAQD58uVDjRo1sGfPHtx8UjDJ1dUVjRs3xvHjx80KiTdt2hTXrl3D4cOHjcdq1aoFvV6PHTt2GI+VL18e+fPnx9q1a43HSpUqhcDAQKxevRqJTzKLChUqhEqVKiE8PBxRUVE4fPiw8bWIiIjA5cuXAchNmRYtWuDMmTNmv+MNGjRATEwM9u3bZzxWtWpVuLm5YcuWLcZjZcqUQbFixbBixQrjsWLFiqFcuXLYsGED4p5sR/X09ET16tWxe/duY6kVNzc3NGrUCMeOHcP58+eNn9+sWTNcvXrV7LWoXbs2kpKSzG4eVahQAfny5cO6deuMx/z9/REQEIBVq1YhKSkJAODt7Y0KFSpi5MgTmDixOO7elZtkHToA3bodRnz8RaxYATg6OqJ58+Y4ffo0Tp06ZfyaDRs2RHR0NPanaDVbrVo1uLq6mr0WZcuWRZEiRbBy5UrjseLFi6Ns2bJYv349Hj16BADInz8/qlWrhl27duH2k1rT2bJlQ8OGDXHh99+R/+uvkfPJOqK8/jouu7nhUIq5VrduXSQkJGDXrl3GYxUrVkSePHmwfv1647GAgAD4+/tj5cqVSE5OBgD4+PigQoUK2Lp1K2Ke1FHNnTs3ateujf379xtPBJycnNCsWTOcOnUKp0+fNn7NrFrLIyIijP/faq3lAJAnTx511nIvLxSaPx+VihTBjp07ERUVBaeHD1Fh2jR4/fADDjk4mNZyAK1atcK5c+fMOsjWr18fDx8+NKtBb29ruUFYWBju37+PvXv3Go+96loeFRWFmzdvqrqWRz8pYmrPa3nFihWxbds23Lt3DwDg4eGBOnXq4MCBA7gXG4v6iYmILlMGeSdPxulChWQtf/L/a8m1/OjRo7hw4YLx85s3b45Lly7h6NGjxmOvupb36FEB772nx9N5JooCHD+ejGXLVlp8LdfCeTmg4lqOlzgvh/2t5Xq9HhcuXFB1LdfCeTnX8uev5VevXgVgufPy+/dbILV8vQcPgMTEo1i2LGvXci2el3Mt1+5anvKayZbPyw1r1YtYpDyC1ly7dg0+Pj7YsWMHqlevbjz++eefY8uWLWa/gAYJCQnGyQ1IKrOvr6/dlEdYtmwZWrVqpfYwMqZDB2D+fKmTOXy47Be3g3T7tOzZA7z+unRdzpMH+PtvIEXSudWy6jmaCS5ckG1NhvOUkiUlEatRI3XHZebuXSmoO3OmPPb2BiZPltRvO2DvczRVX30lzecAoGNHYNQoTXW4tzecoxpz754UdL1zRxZ0g2PHgKAguyniGhICHDnybKZtcLA03CHSEq6jpEVcR8ma2Ms6qqnyCFrj6ekJR0dH491Hg5s3b6JgwYKpfo6rqyty5cpl9oesRM+eQLly0oK4f39510px18neVKkitU6rVpWXpEkTYOJE8zdxsh6JidLjqUwZCdi6uEhjgSNHNBawVRTpLmMI2PbpI93Q7CRgS2no0UOKbgPAn39KPfIBA6TDEJG9un9fbmAULy5F6KdNA1JkHaFMGbsJ2ALSPEdRTD+yobbt0KHqjouIyFpwHSWyXnYZtHVxcUHFihXN0tf1ej02bNhglnlLJrVq1VJ7CBnXoIG0Fp42TQr3nDgBNGsmldbTKIdh6woVAjZvBrp2BfR64KOPJLZtzU3drXqOZlB4OFC+vJSGffRIYqKHDklCuUZKiJvodDLQ0qVl4FOmAB4eao/Kouxxjr5QiRJSo3PfPlmrHz8GfvhBjo8fz7tJFsY5qrK4OGnhXbw48PXXkmlbpoy0AS9ZUu3RqaZtW2k4FhwMuLoqCA4GFi2SXUNEWsN1lLSI6yhZE66j5uwyaAsAAwYMwK+//oo//vgDJ06cQJ8+ffDw4UN0795d7aFpkqEOi9VycgJ69wbOnJEsLicnYOVKYO5ctUemGjc3SXr8/nvAwUH+Xb8+8KQUmNWx+jn6EqKigHffBWrXll2ynp7A7NnAxo1AYKDao3siORn48Uc5QzRo3172YD2pN2Rv7GmOvrSKFYF162QXREiIdNM7ftyusgm1gHNURbt3y82Kzz+XRd7fX25oHDokV9sOdnvKDkBegogI4OrVu4iIYKCBtIvrKGkV11GyFlxHzdntGeDbb7+NCRMmYMiQIQgNDUVERARWr179THMyEimL0Vu13LmB776TSFfXrsDAgaaPXb8OPCkeby90OuDjjyV+nTs3sHMnULkykKLmvdWwmTn6HIoiwdnAQOmoDUjw9tQpoHNnDcW3Dh0CqleXyfX++1KHA5ABurioOzYV2cMcfSU6ndRrOXAAmDMHGDHC9LGzZ4Hly5l5m8U4R1VUurTUuyleHJg1S85T3nmHrbyfwjlKWsc5SlrHOUpaxzlqzm6DtgDQt29fXLx4EQkJCdi9ezeqVq2q9pDIUvz95aIoZ055rNdLbc3y5YEUHTDtRZMmkuQTEABcuQLUqiW920g7Tp2S3eNdu0pPmjJlgG3bgF9/BfLmVXt0Tzx6JCUQKlYE9u4FcuWSwJudlUGgV+TgAHTqBBQpYjr25ZdAq1ZSAySVZqFEViUpCZgxA3jjDdONiFy5gE2bZLHv2lV2BBERERGRXbProC2R0blzksl19Kh0b3rtNSmlYEf8/SUW0rw5EB8PdOggcZLkZLVHZt/i46WxWHCwXM9nyyaNxw4ckOC6ZmzYIA3/xo2TSdOundSP7t3b7rf10ivS66Wep5sbsHUrUK0a8OabdrdGkw1ITpayTKVLSyH5f/+VDHKD4GDA2Vm98RERERGRpvBKmtKlfPnyag8ha5UqJQGADz+U7JZlyySV8ZNPpBGInfDwAJYuBb74Qh6PGwe0bg3ExKg7rvSwxTm6bp3EQUeOlP5MzZvLjtkvvtBYlYGTJ4GGDeXmh48P8N9/0jjH21vtkWmKLc5Ri3BwAMaOBU6fBrp1kzIKCxcCQUHABx8AN2+qPUKbwTmaRfR64J9/ZEHv3FluEufPL+WaGjZUe3RWhXOUtI5zlLSOc5S0jnPUnE5RWCAuI2JjY+Hh4YGYmBjkypVL7eFkuYSEBLi6uqo9DMs4eVKala1aJY89PYHt2yUV1Y7MmyeJQPHxUkN16VKJbWuVLc3RGzdkChpKVHh7AxMnSvKqZurWPu3ddyUTcswY2eZLz7ClOaqqI0ekHvnKlfJ47Fjz+uSUYZyjWeD6daBpU+DwYXmcJ480G+vb11SiidKNc5S0jnOUtI5zlLTOXuZoemOKzLSldFm7dq3aQ7CcwEAJBqxcKf8uWlS25tqZDh2kZqqPj8Sxq1QBtDwNbGGO6vXAtGky7ebPlwTDfv2kysAbb2goYHvxogzo4kXTsV9+ASZNYsD2OWxhjmpCuXLAihVSL6RVK6B/f9PHLl6UZk6UIZyjWcDQ4DZXLmDYMODCBbnJwIBthnCOktZxjpLWcY6S1nGOmmPQligtzZpJZsx//5lqcj58CPzvf8D586oOzVIqVZJ+UtWqSZWIZs2AH35gA/escOgQULMm0KePlKOoWFFqDP/0k4bioMnJMgGCgqQW40cfmT7GurVkafXqyRaA7NnlsV4v9VzKlJHyCVyoSA0bN8o8fPhQHjs4yNaVCxeAoUPZmJGIiIiI0o1X2UTP4+wMFC5sevztt8Cvv0oTkS++AGJj1RubhRQqBGzeLKUk9XrZtt+jB5CQoPbIbMODB8Cnn0qQdtcuwN1dSiHs3i1Bc804dEii9wMGAHFxQO3asi2dSCvOngWuXZP65G++CdSoIdsFiCwhPByoXx9o0EBuJkyebPpYmTJA3rzqjY2IiIiIrJKT2gMg61BKy8VMLenNN4GdO6VOwPjxwB9/AKNHS0TT0VHt0WUZV1dgxgwgJER6s82aJSUTFi2SoK4WWOMcXbpUyhpeviyP33gD+PFHKUmhGY8eAcOHAxMmSKath4fcvOjZk9m1L8ka56hV8feXwO2ECdLgadcuoE4dKaEwbpxkiNNzcY5mwJ49wNdfm+oHubgAvXtLwzHKdJyjpHWco6R1nKOZKzk5GYkszZWp/Pz8EB8fr/YwMszR0RHOzs6Z9vXYiCyD7K0RGaWgKFJPccAAyegCgPLlJdpWp46qQ7OEdeuAt98GoqOlQdZ//wGVK6s9Kuty+bLUql2yRB4XKyblYFu0UHVYqfvmG1OTpzfekHoNWonUE6Xlxg252fDrr3KzwcFBgmsVK6o9MrIViYmyJi5dKo+dnORm1uDBgK+vumMjIiKiLKUoCm7cuIGYmBgwpEZPc3V1haen53NjhemNKTJom0H2FrRdvXo1mjZtqvYwtOXxY9n+OHy4FCF94w3gn3/UHpVFnD0LvPaaNMhydQV+/x3o2FHdMVnDHE1KkpjnkCFS7tDJSTKXhwwxleXUnEePJJr80Ufyn04ZZg1z1OacOgUMGgRcvw5s327q5qfXM1M8FZyjL+nNN2XLSdeukm1bvLjaI7J5nKOkdZyjpHWco5nj3r17uH79OvLnz48cOXJAp5mO0dbv/v37cHd3V3sYGaIoChITExETE4MHDx7Ax8cnzXhhemOKLI9A6cKU/1S4uAAffwx06iQdoT/91PSxO3cANzeb7Q5dsqTsPO7YEVi+XF6Cw4eBMWPUqxKh9Tm6Z4/smI2IkMc1awLTpgFly6o6LHOKAsyfD/z5p2SPOToC2bJJYx16ZVqfozYpIECa5sXFmQK2sbFA1arSVPL99+XOEwHgHH2uU6eAkSPljyE4O368lEjy91d3bHaEc5S0jnOUtI5z9NUpioJbt24hV65c8PT0VHs4Nic+Ph5ubm5qDyPDsmXLBnd3d1y5cgV37tx55SRPppkQvar8+SXjNmWGzUcfyUXcH39IRpcNypVLSiN8+aU8Hj9eEjFjYlQdlubcuydxoWrVJGCbJ4/s2N66VWMB28hIoHlzicSvXClzl8hWpExl/+03Kco9YAAQGCg3KWx0naZMcP681K0PCpK5MnKk6WPFizNgS0REZGeSk5ORnJxsFzuuKWN0Oh08PDyQkJDwyjdKGLSldCnEGpbp9+ABsHu3bMft1k0yurZvV3tUWcLRUbJr582TxOKVK+XHPX3a8mPR2hxVFOCvv4DSpYGpU+Vx584SK3r3XQ3tzE5KAr7/Xrqbr14tGeQjR0r6NGUqrc1Ru9W/vwRuvb3lZkWnTkClSlKw285xjqZw6ZJkYwcEmG7Atmol84dUwzlKWsc5SlrHOfrqkpKSAABOTty4nhUys4mXmgw/R3Jy8it9Hda0zSB7q2lLLykhQYqXjhwJ3L8vx9q3l6ZORYqoO7Yssn8/0KYNcOUK4OEBLFgANGmi9qjUce6cZNcamon7+0sphPr11R3XMyIiJIK8f788rlMH+OUXCVIQ2bq4OGkg+c03UjIBkEVr+XIpOE3268sv5WbW48fyuEkTYMQIoEoVdcdFREREqouPj8eFCxdQvHhxq97GT1nrRfMkvTFFreR6kcaFh4erPQTr4uoKfPYZcOYM0KuX1FL86y8JhtloNlfFisDevUCNGlIioXlz4LvvJMPUErQwRxMSgFGjpOzB2rUyDYYPl3q/mgvYKgrQt68EbHPnlpoNmzYxYJuFtDBHKYXs2aVJ2blzwIcfAs7OgJeXXQdsOUefcHKSgG39+kB4uOxCYMBWEzhHSes4R0nrOEdJ6+4bkt4IAIO2lE7R0dFqD8E6eXlJ5uKBA0DdupKCWq2a2qPKMgULSs+qnj1lJ+mnn0pT7fj4rP/eas/RLVuA0FBpIB4fDzRsCBw5AgwZorE+R4Youk4ndRvatwdOnNBYzQbbpPYcpTR4ekrG7cmTUu/F4MwZ4JNPgKgo1YZmaXY5R+/eleD95s2mY598AmzYIG9oNWuqNjR6ll3OUbIqnKOkdZyjpHWvWk7A1vAKncgSQkMli3HPHsDdXY4pCtCnD7Brl6pDy2yurpK0+dNPUvN2zhyJV1+7pvbIssadO1K6uF49ifkUKCC9atauBUqVUnt0KURFSQR90CDTsXLlgPnzJdpOZO9KlAB8fEyPBw+WLfJ+fsC4ccCjR+qNjTJfTAwwbBhQrBgwdqysjYabWrlzA2FhKg6OiIiIiIhBW0ond0OgkTJOpzOvZzt/vhQ6rV4d6NhRisHaCJ0O6NcPWLMGyJNHYtWVKsnfWcXSc1RRgBkzTD1qAKB3bwncduggr4EmKIpEkQMDgdmzJQh1/brao7JLXEetTM+eQEiIBPe+/FLuwsyYAdjw3X+7mKMPHkhGdfHiUr/m/n35fx44UO2RUTrYxRwlq8Y5SlrHOUpp0el06fqzOeXupCzg6OiYpV/f2rARWQaxERm9suvXJZNr1iwJrGXLBnzxhdTCzZ5d7dFlmnPngNdeA44fN2Xhdu6s9qhezfHjwHvvAdu2yePgYFP8XVMiIyWbe/VqeVymDPDbbzZdooMoU+n1ctPjq6+AS5fkWJkywIQJQNOm6o6NXt7s2VL64M4deVy6tDQYa9uW5WGIiIgoXWy1EdncuXPNHs+ePRvr1q3DnDlzzI43atQIXl5elhyaVWIjMrKoiIgItYdgewoVkqytvXulZt6jR7JVMzBQsnBt5H6Knx+wcyfQqpU06urSReLSmZ2sZok5GhcncfbQUAnYZs8OfPstsG+fxgK2SUmSUVumjARsXV3/z959h0dVbX0c/056AiG00CGB0Lv03iFUCyqgooDKRUUFQa5dqmJBxCuK4H0FbNcuSu+9t9A7oUgPJUAChGTO+8cmA0MCBEiYE/h9nicPZM+ZM2uGlc1kzT5rmx3S1qxRwdaDNI9mQl5e5lOmbdvMzoo5csCmTWYDv7vQXZ+j3t6mYFu8OHz/vWk8/sgjKthmInd9jkqmpxwVu1OOyrV07tzZ7atkyZKpjl9dsI2Pj0/XONL7fJmd3qVKmuzfv9/TIdy9qlY1FcCffzbtE/bvh48+Miu87hLZssGECabgCWaRWtu2cOpU+j1GRufotGlQvry5qvbiRVOE3rzZbLbm65uhD33zjhyB/v1NlblhQ1i/3rz4fn6ejuyepnk0EwsIgD59YPdu8+Fa796Xb1uzBrZv91Rk6equytGEBBg9Gn788fJYp07w009m88UnnjBFXMlU7qoclbuSclTsTjlqX3/8YTo2BQaaP//4w9MRpdSoUSPKly/P6tWradCgAUFBQbx5ac8Uh8PBgAEDUtwnPDycrl27uo2dOnWK3r17U7hwYfz9/SlevDgffvghTqeThISEO/BMMg8fTwcgIpgGqB06mErgJ59AgwaXf5mMj4eTJ903yMmEvLzMYs8KFaBbN1MErVkT/v7b9IW1q0OHTH3ml1/M94UKweefwwMP2KhvLZhKcnL1uGBBGDHCrNZ++mmtIhNJL9mzmw9Ekjmdpvftxo3Qvbu5TZeLeVZiotkBc9Ag0yKmQAF46CHzG5C3N3Ts6OkIRURE5C5jWebX9lv111/m82SHw5xrwwZ4+GHTpeuBB27tnEFBGfP76vHjx2nVqhWdOnVKdeXtjcTHx9OwYUMOHDhAjx49KFKkCEuWLOGNN97g0KFDqRZ+72Uq2kqaeKnoc2cEBpreiVcaNgw+/NBshNO3rzkmE+vYEUqWNP/5bN8ONWqYhU+tWt3eedM7R5OSTJ/aN9+E06dN3bNXL7Nvje3698+caZrsjh4NzZqZsWee8WxMkoLm0btQbKwpCkZFwahRpmfqq6+audp2E8WNZeocTUoy/5kMHAg7dpixvHlNr/jM/LzETabOUbknKEfF7pSjGSM+HrJmvf3zJHdITP7ziSdu/Vxnz0KWLLcf09UOHz7MV199RY8ePW7p/sOHD2fXrl2sXbuWEiVKANCjRw8KFCjAxx9/zLPPPkv27NnTMeLMTT+xkiZt2rTxdAj3JssyrRPi4+Gdd8ymKb/8kun73d533+VWvqdPQ5s2pjfs7Tyt9MzRNWtMj9oXXzTx1ahh+tYOH26zOkxMDHTpAi1amMu233vP0xHJdWgevQvlyAGTJ8PcuVC9OsTFmaJh8eLw5ZdmBXwmkmlzdOFCsyNk586mYJs7t/lPZfduePll09db7gqZNkflnqEcFbtTjsrt8vf3p1u3brd8/19//ZX69euTI0cOYmJiXF/NmjUjKSmJdevWpWO0mZ+KtpImO5JXrcid5XDAjBnmuohChWDvXrNUtUGDTL8RTt68MGcOPPusKdb++99mk7Jz527tfOmRo2fOwCuvmNrLypWmF+8XX8CSJabQbBuWZTbRKVPGrOxzOOCll0yvCbEtzaN3sUaNYPly05s8IgKOHoWePWHqVE9HdlMybY4GBpom49mzmw+vdu82K56DgjwdmaSzTJujcs9QjordKUczRlCQWdl6q1/ly6dsZeBwmNaCt3rOjHobVLBgQfxuY6+UHTt2MG3aNEJDQ92+ml26YvTAgQPpFepdQe0RJE22bt3qWroud5jDAY8/Dg8+aFYOffghLFpkKotffAHPP+/pCG+Znx+MGWMarffubeqQ27bBn3/efAvf28lRyzKP+fLLkPx/RMeO8OmnkD//LZ0y40RHm3/z6dPN9+XLw9dfQ61ano1Lbkjz6F0uuTf5gw+an8np002f8mRHj0KePB4LLy0yRY5alnltt283kzZAtWrmw83WrU3hVu5amSJH5Z6mHBW7U45mDIfj9loRDBxoetgm97RN/nPgwIxpcXA7Am+yXWNSUpLb906nk+bNm/Pvf/871eNvtkfu3U4rbUUyi6Ags8nNtm2miOvnB5GRno7qtjkcpg3BjBmQM6dZ4Vq9ulm0difs3Qv332/+kzxwAIoVM5uk/fSTDQu2YPo0TJ9uLvd97z3Ty0EFWxH78PMzq2z//vvykonTp80HLO3awaZNno0vM5s7F+rVM03Q+/WDK3fAfvxxFWxFREQkU2rfHn7/3XR7Cggwf/7xh9lLNbPIkSMHp06dchtLSEjg0KFDbmMRERGcPXuWZs2apfpVuHDhOxi1/aloK5LZFC5sVhTt2mUqjMneesvM9Jm0322TJqZgW64cHDpkOkCMH59xj3fxolm4XLYsTJoEvr7mJdy40Ya18LNnL//9kUdM8X79erNLmq+v5+ISkbSZNw9OnDCTTcWKZqPAf/7xdFSZx+LF5j+JJk1Mv5qAAFMYz+Qbc4qIiIgka9/e7G177pz5MzMVbMEUYxcsWOA2NmbMmBQrbTt06MDSpUuZnnzl6BVOnTpFYmJihsaZ2ahoK2nStGlTT4cgV7uyf8DKlfD++6ag17ixmeUzoWLFYOlSc3VxQgJ07Wo2YU/LvH0zObpkCVStavroxsebAvG6dTBkiM1qAPHxZjVZiRJm0zEwK/cGDICSJT0amtw8zaP3sPvvNyts27cHpxO++cb8XL/xBsTGejo6F9vl6K5d0LKlWV07d675kKpnTzM+fLjZcEzuKbbLUZGrKEfF7pSjklGeffZZ1q5dy8MPP8xXX33F888/z/Dhw8l91fu1fv36UaVKFdq2bUv37t356quv+OSTT+jatSuFChVKUeS916loK2kSa6NfKiUVZcvCO++Y1Ufz50OVKvCvf5keiplMcLBZMPzOO+b74cOhTRs4efL690tLjp44AT16QN26sGED5MoFY8eaRXBlytx+7Olq5kxzOfWwYXD4MPz6q6cjktukefQeV6qUmdyWLDFFyPPn4YMPTPH2qkvJPMV2OZo1KyxcCD4+0L077NwJI0dCgQKejkw8xHY5KnIV5ajYnXJUMkr37t157bXXWLBgAX379iU6OpqZM2eS5aqmvEFBQcyfP59+/foxb948evXqxQcffMCOHTsYOHAgWbNm9dAzsKd7smj73nvvUadOHYKCgsiu/mdpsmrVKk+HINeTJQsMGgRbt5odtCzLbIRTooQp+l244OkIb4qXl3k6v/xiWvnOmAE1a8KWLde+z/Vy1LLMJmelS5uNzwC6dTMvV9euKXfq9KiYGHjqKWjRwmw6VriwuaQ6E284J4bmUQGgdm1YsAD++st8WhQZaZterB7P0U2bTK/uZHnzwrhxppf7mDFQpIjHQhN78HiOityAclTsTjkqaTVy5Eisq1ovzps3j40bN6Z6vJeXFx988AHHjh0jLi6OadOmERERwZ49exg3bpzbsVmzZuX9999nx44dXLhwgWPHjrF48WL69u3LxYsXM+opZUr3ZNE2ISGBRx99lOdVBJG7TViY2UFr0SJz/f/p06ZxayYr2iZ79FHTyrBIEdixw+y3NWXKzZ1j+3Zo3hyefBKOHTM1kvnzzdXJtruyNrmy/N13ppL88sumiNGmjacjE5H05HCYlgnr18Pnn18e37nTTHQzZ3ouNk/Yvh2eeAIqVIC33zara5M9+qh7/3YRERERkXvEPVm0HThwIK+88goVKlRI830uXLjA6dOn3b5EbKtuXVixwqxQ+uwzyJbNjFuW+eU4E6lc2bTsrV/f1KDbtoUPP7zxfmvnz8PAgaYGMHu26Rzx3num3W+DBnci8luwYAEcP26CXrrU/NsFB3s6KhHJKD4+7qtshwyB5cvNSvsWLWDtWo+FdkdER5vLHsqWhR9/NBN7+/aQJ4+nIxMRERER8TiHdfV653vIuHHj6N27N6fS0EtuwIABDBw4MMX4Tz/9RFBQEADNmzfn+PHjrFmzxnV77dq18fHxYeEVq0YqVqxIwYIFmTp1qmusWLFilCtXjpkzZ3L+/HkA8uTJQ82aNVm6dCkxlzYhCgoKomnTpmzYsIE9e/a47t+mTRv27NnDpk2bXGMNGzbk/PnzLF++3DVWrVo1QkJCmD17tmusdOnSlChRgsmTJ+N0OgEoXLgwlStXZt68eZw5cwbLssiZMyf16tVj1apVHDp0CABfX19atmzJ1q1b2bFjh+ucLVq04NixY6y94hfOOnXq4OXlxaJFi9xeiwIFCjBt2jTXWEREBGXLlmXGjBlcuLRCNG/evNSoUYMlS5Zw/PhxALJkyUKTJk1Yt24d+/btc92/Xbt27Nq1i82bN7vGGjduTFxcHCtWrHCNVa9eneDgYObMmeMaK1OmDMWLF2fSpEmuSwGKFClCpUqVXK8FQM6cOalbty4rV67k8OHDAPj5+REZGcmWLVvYuXOn65yRkZEcOXKEqCs2B6tbty4Aixcvdo1VrlyZvHnzuu2iWLx4ccqUKcP06dNJSEgAIF++fFSvXp3Fixdz4sQJAIKDg2nUqJHba+FwOGjbti07d+5ky6W+AgUWLKDK8OGc69yZhc2bkxASAkCNGjXIkiULc+fOdT122bJliYiIYOLEia6x5Ndizpw5xMXFAZArVy7q1KnDihUrOHLkCAD+/v60aNGCzZs3s2vXLtf9W7ZsycGDB1m/fr1rrF69ejidTpYsWeIau++++wgNDWXGjBmusbCwEnzxRWlXe4OGDf9hyJAj1KtXlUWLFnHixAkcDgfBwcE4nY14+unz7N0bAECVKkf55Zc8OJ072Lp1q+ucTZs2JTY21u0yoZo1axIQEMD8+fNdY+XKlSM8PJzJkye7xsLDw6lQoQKzZ88mPj4egNy5c1O7dm2WL1/O0Uv9hAMCAmjevDmbNm1i9+7drvu3atWKA3v3smXZMi5eKqo3qFgRn/HjmVuhApaPz6XYq5ArVy5mXrHyrmTJkpQqVYqpU6e6dtcsUKAAVatWZeHCha45LSQkhAYNGrBmzRoOHDgAgLe3N61bt2b79u1s27bNdc5mzZpx8uRJVq9e7RqrVasW/v7+bq9F+fLlKVKkCFOuWPJctGhRypcvz6xZszh37hwAoaGh1KpVi2XLlnHs2DEAAgMDadasGRs3biQ6Otp1/9atW7Nv3z63S20aNmzIhQsXWLZsmWusatWq5MiRg1mzZrnGSpUqRcmSJZkyZYqraX3BggWpUqUKCxYscPXtyp49O/Xr12f16tUcPHgQAB8fH1q1asW2bdvYfsWHGRk1l8+fP9/1gZ+n5nKAHDlyaC636Vye0+mk7ty5OL/4Aq9LP9v/NGpEobFj2ZmY6JrLAZo0acKZM2dYuXKla+x25/LixYuzZ8+eDJ3LS5QoQen8+dn3+OMUmj4dr+TNJtq2Ze1DD/FPaChw+f+1qKgo9u/fD5jL7tq0acOOHTabyw8ccHst6tevT2JiIkuXLnWNaS5Pn7k8eb7w5Fxuh/floLncrnO5ZVlky5YtTe/LIWPm8jvxvrxEiRKULl2aadOmuS5lzp8/P9WqVWPRokWcvLQZheZy+83lR48exeFw3PPvy29nLj9z5gyHDx+mcOHC+Pn5ERQUhLe3t2tOApNrAQEBbrWm5GPPnDnjen28vb0JDg4mLi7O9bPkcDgICQnh3LlzrnkXIFu2bCQmJrpyHHD1fz179qxrLDAwEF9fX7eFhv7+/gQGBhIbG+uaT319fcmSJQtnz5515a6XlxfZsmUjPj7eNc8l/5udP3/e9ToCl37vdrrmHzD/F3h5ed3Sa+Hj40PWrFndxm73tQgKCsLHx+eWXovkf5tbfS28vb3Zt28f+/btc53zyrk8Pj6eTp06ERsbS7bkRXapUNE2jUXbCxcuuCXJ6dOnKVy48A1f4LvF6dOn74nnedfr3dus3gQICYH+/c1O3H5+Hg3rZowaZboGJCaaDhA9eph9abZts4iIcJA7t1mwCpAvH4wYAR062KxvLcCaNfDssxAaCtOm2TBASW+aRyXNdu82bQL+9z/zvZ8fvPaaafadge5YjiYkmI3Z9uwx/WsGDTJtIURuQPOo2J1yVOxOOXr7zp8/T3R0NEWLFiUgIMDT4dx1kpKS8Pb29nQYt+1GeXL69GlCQkJuWFO8a9ojvP766zgcjut+XflJ3s3y9/cnW7Zsbl/3kis/0ZNMbMQImDfP9ByIjYU+fcyl+JMm3bjfgE08/7xp95grF6xeDf/6F2zYABcuONi8+XLBtmfPy/uy2aoeGhcHr74K1aubS59XrjSXCMtdT/OopFmxYqZdwKpV0LSpKXLegQ/XMixHjx2DwYMheWMJPz/zCdyCBWanSRVsJY00j4rdKUfF7pSjYndXrtIV8PF0AOmlb9++dO3a9brHFNNGFiLQsKEpBIwbB2++aXrctmtnlq8mr8K1uUaNTK2zbFnTu/bqenOJEmb1re3MmAHPPXe5SNupkymk583r0bBExKaqVjWfUs2caXqVJ5s/32xa1rUr2HklwokT8Mkn5v+WuDhz+UP37ua2li09G5uIiIiIiM3dNUXb0NBQQi/1QRORG/D2hmeeMbtyv/eeKRw++KCno7opRYtee3HwpZZZ9hEbCy++CN9/b74vUgS+/BLatPFsXCJifw6H2ZQsmdMJr7xiVuoPH252ZmzTxl6XFMTGmv9Xhg83O0iCKUAXL+7RsEREREREMpO7pj3Czdi3bx9RUVHs27ePpKQkoqKiiIqKcmtYLO7KlSvn6RAkI2TLZn7h37sXGje+PP7ZZ/Cf/1y+lNWmSpVKWadwOMy4rfj7m6XBDgf06gWbNqlgew/SPCrpwumEzp0hRw7YvNlcKdGoEVyxudGtuu0cdTrhgw/Mp2oDBpiCbYUK8OefZg688v8ZkVugeVTsTjkqdqccFbsLDAz0dAi2ck9uRNa1a1fGjx+fYnzu3Lk0atQoTedIa9Pgu4XT6cTL656s8d97Dh0yq6Hi46FMGbNSyqaXsf7xBzz8sKmFWtblP//4Ax56yMPB7dkDhQqBz6ULGpJ3SK5Rw2MhiWdpHpV0deqUKZB+9pnpEwNmQhw61PSIuQXpkqPNmsHs2VC6NAwcCI88Asp7SSeaR8XulKNid8rR26eNyDKWZVk47HQF2S3SRmS3Ydy4cViWleIrrQXbe9HkyZM9HYLcKXnymEJt7tywZQu0agWtW5tdvWymfXv4/XeoWBF8fZOoWNEGBdvERPjoI9Nwd8SIy+M1aqhge4/TPCrpKnt2U7Tdvt30tnU4zIS4du0tn/Kmc/TCBfjiCzh69PLYBx/At9/Cxo3QoYMKtpKuNI+K3SlHxe6Uo2J3sbGxng7BVvROWkTceXtDjx6wYwf06WNWik6dai5x7d0bTp70dIRu2reHqCj4/fcpREV5uGC7ejVUrw6vvQbnzsG8edduvCsikh4KF4axY2HdOjNnP/ro5dtWrICMaP108SKMGWNW9L74ovmgKlm1avDkk/beIE1EREREJBNQ0VZEUpc9u9n1e9Mm0zMxMdFsnnXihKcjs5+4OOjb16ykjYoyvSa/+QYmTrTX5kAicveqUMHM2clzzpkz0LataXczalT69ChPTITx403j8B49zK6PBQqYVjoiIiIiIrepYsWKdO3a1fX9vHnzcDgczJs3z2MxXS08PNwtxoykoq2kSXh4uKdDEE8pWRL+/htmzDAFgYiIy7dt3uy5uK7isRxdsgTKlzctJZxO6NTJtJXo1k0FW3GjeVTuqD17ICQEjhyBF14w89Tvv1939f91c/TXX6FcOdOKITratNL59FPYuROeeSa9oxdJleZRsTvlqNidclRuZNy4cTgcDtdXQEAAJUuW5MUXX+TIkSMZ/vjp1c92ypQpDBgwIF3O5Ukq2kqaVKhQwdMhiKc1bw4vvXT5+1WrTBHg/vtNT0UP81iOZs8OBw5AkSIweTL873+QN69nYhFb0zwqd1SFCuZKiZEjITTUzNOPPAJ16sDChde4y3VydN48c45cueDDD2H3btMyRzv8yh2keVTsTjkqdqcclbQaNGgQ3333HSNHjqROnTqMGjWK2rVrEx8fn6GPe3XRtkGDBpw7d44GDRrc1HmmTJnCwIED0zM0j1DRVtJk9uzZng5B7GbFCtOzcOJEU7zt29fsZu4hdyxHLcv0rk1WtqxZibxpk9mwTeQaNI/KHefnBz17wq5d8O67kCULLFsGDRuaFbIDBsDgwa7DXTlqWdC5Mzz//OVzvfWWOXb3bvj3v825RO4wzaNid8pRsTvlqA1d9X7MzeDB5nYPaNWqFZ07d+bZZ59l3Lhx9O7dm+joaP76669Uj4+Li0uXx7WuuirMy8uLgIAAvO7RzW3vzWctNy2jP02RTOiFF2DDBmjVyvRKHD7cbErz1VeQlHTHw7kjObprF7RoYXrXXlm4bdkSsmbN+MeXTE3zqHhMcDAMHGgKtc89B089ZXrdenubYu477wAQHxdnWuEUKQI//ABz5lw+R4EC8PbbkC2bh56EiOZRsT/lqNidctSGkt+PXV24HTzYjNtkc9cmTZoAEB0dTdeuXcmaNSu7du2idevWBAcH88QTTwDgdDoZMWIE5cqVIyAggLx589KjRw9OXrWhuWVZDBkyhEKFChEUFETjxo3ZtGlTiqLttXraLl++nNatW5MjRw6yZMlCxYoV+eyzzwDo2rUrX3zxBYBbq4dktxvjneRzRx9NRO4upUvDlCkwdarZtXzrVrMy67ffYNYsT0eXfi5eNL0bBwyAc+cgIMD0861a1dORiYikXb58ZlOy5DfD77xjNpccMgRmz6ZObOzlXuU+PvDgg+ZDOJv8siAiIiJia9dbbertbX6PvPrYPn0gIcEUaBMS4PXXTSuqwYNh0CDzfu165/Xycm9XFR8PQUG39zxSsWvXLgBy5coFQGJiIpGRkdSrV49hw4YRdOkxe/Towbhx4+jWrRsvv/wy0dHRjBw5krVr17J48WJ8fX0BePfddxkyZAitW7emdevWrFmzhhYtWnDhwoUbxjJz5kzatm1L/vz56dWrF/ny5WPLli1MmjSJXr160aNHDw4ePMjMmTP57rvvUtz/dmNMSEhIl9c0LVS0lTTJnTu3p0MQO2vVCpo1M8WAAQPg0UfveAgZlqOrVsGzz8K6deb7Jk1g9GizSk3kJmgeFdu4sldYSIj5c+lSciWP1a4Nf/6p/txiO5pHxe6Uo2J3ytEMdr2rL1u3NnugJMuTxxRYrzRkiPmCywVbgPBwiIlJ/bzVqsHKlZe/L1vWbEh7m2JjY4mJieH8+fMsXryYQYMGERgYSNu2bVm6dCkXLlzg0UcfZejQoa77LFq0iP/+97/88MMPPP74467xxo0b07JlS3799Vcef/xxjh07xkcffUSbNm2YOHGiaxXsW2+9xfvvv3/duJKSkujRowf58+cnKiqK7Nmzu25LXqVbu3ZtSpYsycyZM+ncubPb/e9EjOlJ7REkTWrXru3pEMTufH3h5Zdhxw5T5Ez2xx/w2mtw+nSGPnyG5Gj//lCzpinY5swJY8eaFcQq2Mot0DwqttS/P/z11+VCrp8fLFmigq3YkuZRsTvlqNidcjSTcDguF2w9pFmzZoSGhlK4cGE6depE1qxZ+fPPPylYsKDrmOev3P8A+PXXXwkJCaF58+bExMS4vqpWrUrWrFmZO3cuALNmzSIhIYGXXnrJrW1B7969bxjX2rVriY6Opnfv3m4FW0i5iVlq7kSM6UlFW0mT5cuXezoEySxy5bp8Ke2FC+Zyj48+Mv1u//vfDOt3myE5mi8fOJ3w+OOwZQt07eq+Qk3kJmgeFVtyOMwHU5aF09fXXJZ3rc0wRDxM86jYnXJU7E45msHOnr321++/ux979Kj77W+/bcb9/Ewrqyvfj+3Zc+3zLljgft7kVle36YsvvmDmzJnMnTuXzZs3s3v3biIjI123+/j4UKhQIbf77Nixg9jYWPLkyUNoaKjb19mzZzl69CgAe/fuBaBEiRJu9w8NDSVHjhzXjSu5TUP58uVv6XndiRjTk9ojSJokJ67ITfHzgy++MIXb7duhe3fz/WefQYMG6fpQ6ZKjR4/CP/9AlSrm+x49oHx5qF//9s8t9zzNo2JLyZtcDBrE5MqVaRcVZb4Hj6/wELma5lGxO+Wo2J1yNINlyXJrxw4ebNoiJLdESH5/Bub7mzlvOvWzrVGjBtWqVbvm7f7+/nh5ua8DdTqd5MmThx9++CHV+4SGht7wca/eiCy9pUeMd5KKtiKScRwOaNMGmjeHL780/W6joqBhQ3jkEfj4Y9Ofx9MsC8aPh759zc7oGzea/xi9vFSwFZG71xUFW955ByZOvFyoVeFWREREJONd/X4MMu37sYiICGbNmkXdunUJvHJztKuEhYUBZtVrsWLFXOPHjh3j1KlTN3wMgI0bN9KsWbNrHnetVgnpEePJkyevG2N6UnsESZOAK3c5FLlZfn7Quzfs3AnPP2+Kob/9BpcubUgPt5yjO3eaonK3bmYX9ZAQOHIk3eISSaZ5VGwnKcntFwRXjr7zjhnPoHY2IrdK86jYnXJU7E45akNXvR9zyYTvxzp06EBSUhKDU2m1lZiY6CrINmvWDF9fXz7//HO3lbUjRoy44WNUqVKFokWLMmLEiBQF3ivPleXS6uSrj7kTMaYnrbSVNGnevLmnQ5C7Qe7cZsXt88+bncmbNr1828aNZqdLr1v7LOmmc/TiRRg+3Kz+PX8eAgJg4EB45RWzqZpIOtM8KrYzYIDbt245mklWdMi9RfOo2J1yVOxOOWpDV70fc5PJ3o81bNiQHj16MHToUKKiomjRogW+vr7s2LGDX3/9lc8++4xHHnmE0NBQXn31VYYOHUrbtm1p3bo1a9euZerUqeTOnfu6j+Hl5cWoUaNo164dlStXplu3buTPn5+tW7eyadMmpk+fDkDVqlUBePnll4mMjMTb25tOnTrdkRjTk4q2kiabNm2iXLlyng5D7hYVKpivZIcOQa1aULo0jBgB9erd9ClvKkdjY02LhnXrzPdNm8Lo0XDpUguRjKB5VOxOOSp2pxwVu1OOit0pRyWjffXVV1StWpXRo0fz5ptv4uPjQ3h4OJ07d6Zu3bqu44YMGUJAQABfffUVc+fOpWbNmsyYMYPWrVvf8DEiIyOZO3cuAwcO5JNPPsHpdBIREUH37t1dx7Rv356XXnqJn376ie+//x7LsujUqVO6xNimTZt0fMWuz2FldJffu9Tp06cJCQkhNjaWbNmyeTqcDDdx4kTatWvn6TDkbjVtGnTsCKdPm+87doQPP4RLfWTS4qZztH17mD8fPv0UnnzS9N8VyUCaR8XulKNid8pRsTvlqNidcvT2nT9/nujoaIoWLap2Exng1KlTZM+e3dNh3LYb5Ulaa4rqaSsinteyJezYAd27m+Lpzz+bVbfvvANxcenzGFOnwpW7pY4aBVu2wFNPqWArIiIiIiIiIraioq2I2EOePDBmDKxZA40amT6zQ4ZA+fLm77fq6FF47DFo3dr0q02WN695TBERERERERERm1HRVtKkVatWng5B7hWVK8OcOfD771C0qGljkIbLTlLkqGXB2LFmxe5PP5kNzvLlA6czY+IWuQHNo2J3ylGxO+Wo2J1yVOxOOSp2FxIS4ukQbEVFW0mTAwcOeDoEuZc4HKZYu3kzDBx4eXzNGujcGf75J8Vd3HJ0505o1gyefhpOnoT77oMVK+CTT0zxVsQDNI+K3SlHxe6Uo2J3ylGxO+Wo2F1CQoKnQ7AVVS8kTdavX+/pEOReFBAAWbNe/r5vX/jhByhZ0rRQePdd102uHJ0xA8qUMat1AwPho49MwbZq1Tsbu8hVNI+K3SlHxe6Uo2J3ylGxO+Wo2N25c+c8HYKtqGgrIpnHsGFQrx6cOwfz58PgwfDoo6YVQrL58yExEYoVgw0boF8/8PHxXMwiIiIiIiIiIjdJRVsRyTyqVoUFC+CXXyAszIz99hvkzo0jMdEUcd9/36zI3bkTIiI8G6+IiIiIiIjcdawrFw6JXCW98sNhKdNuyenTpwkJCSE2NpZs2bJ5OpwMd+rUKbJnz+7pMEQuO3cOhg83PW8vXsTy8TGF20GD4J13PB2dSAqaR8XulKNid8pRsTvlqNidcvT2JSUlsX37dvLkyUOuXLk8Hc5dJzExEZ+74ErZmJgYYmJiKFGiBN7e3iluT2tNMfO/EnJHJCYmejoEEXeBgfDWW9CtGxQpYgq2fn4q2IptaR4Vu1OOit0pR8XulKNid8rR2+ft7U327Nk5evQoAEFBQTgcDg9Hdfe4ePEivr6+ng7jlliWRWJiIqdPn+b06dNkz5491YLtzVDRVtJk6dKltGvXztNhiKT0f/8HSUkk+fjgnZBgWiSocCs2pHlU7E45KnanHBW7U46K3SlH00e+fPkAXIVbST/x8fEEBQV5Oozb4u3tTf78+QkJCbntc6loKyKZ1+DB8O67MGgQUypXpl1UlPkeVLgVERERERGRdOdwOMifPz958uTh4sWLng7nrjJ37lwaN27s6TBumY+PD97e3um2+lpFWxHJnK4o2PLOOzBx4uVCrQq3IiIiIiIikoG8vb1v+/J3cZeYmEhAQICnw7ANL08HcKft2bOHZ555hqJFixIYGEhERAT9+/cnISHB06HZWpUqVTwdgoi7pCS3TcdcOfrOO2Y8KcmDwYmkpHlU7E45KnanHBW7U46K3SlHxe6Uo+7uuZW2W7duxel0Mnr0aIoXL87GjRvp3r07cXFxDBs2zNPh2ZZ2RRTbGTDA7Vu3HNUKW7EhzaNid8pRsTvlqNidclTsTjkqdqccdXfPrbRt2bIlY8eOpUWLFhQrVoz777+fV199lT/++OO697tw4YJrB7jkr3vJzJkzPR2CyHUpR8XulKNid8pRsTvlqNidclTsTjkqdqccdXfPrbRNTWxsLDlz5rzuMUOHDmXgwIEpxqdOnera2a558+YcP36cNWvWuG6vXbs2Pj4+LFy40DVWsWJFChYsyNSpU11jxYoVo1y5csycOZPz588DkCdPHmrWrMnSpUuJiYkBICgoiKZNm7Jhwwb27Nnjun+bNm3Ys2cPmzZtco01bNiQ8+fPs3z5ctdYtWrVCAkJYfbs2a6x0qVLU6JECSZPnozT6QSgcOHCVK5cmXnz5nHmzBmcTieLFi2iXr16rFq1ikOHDgHg6+tLy5Yt2bp1Kzt27HCds0WLFhw7doy1a9e6xurUqYOXlxeLFi1yey0KFCjAtGnTXGMRERGULVuWGTNmcOHCBQDy5s1LjRo1WLJkCcePHwcgS5YsNGnShHXr1rFv3z7X/du1a8euXbvYvHmza6xx48bExcWxYsUK11j16tUJDg5mzpw5rrEyZcpQvHhxJk2ahGVZABQpUoRKlSq5XguAnDlzUrduXVauXMnhw4cB8PPzIzIyki1btrBz507XOSMjIzly5AhRUVGusbp16wKwePFi11jlypXJmzcv06dPd40VL16cMmXKMH36dFcLj3z58lG9enUWL17MiRMnAAgODqZRo0Zur4XD4aBt27bs3LmTLVu2uM7ZpEkTzpw5w8qVK11jNWrUIEuWLMydO9c1VrZsWSIiIpg4caJrLPm1mDNnDnFxcYD5JKxOnTqsWLGCI0eOAODv70+LFi3YvHkzu3btct2/ZcuWHDx4kPXr17vG6tWrh9PpZMmSJa6x++67j9DQUGbMmOEaK1GiBKVLl2batGmuZu/58+enWrVqLFq0CKfTycSJE12vRVRUFPv37wfAy8uLNm3asGPHDrZu3eo6Z9OmTYmNjWXVqlWusZo1axIQEMD8+fNdY+XKlSM8PJzJkye7xsLDw6lQoQKzZ88mPj4egNy5c1O7dm2WL1/u2kk0ICCA5s2bs2nTJnbv3u26f6tWrThw4IDba1G/fn0SExNZunSpa6xKlSrkypXL7T+vkiVLUqpUKaZOnUpiYiIABQoUoGrVqixcuJBTp04BEBISQoMGDVizZg0HDhwATN+l1q1bs337drZt2+Y6Z7NmzTh58iSrV692jdWqVQt/f3+316J8+fIUKVKEKVOmuMaKFi1K+fLlmTVrFufOnQMgNDSUWrVqsWzZMo4dOwZAYGAgzZo1Y+PGjURHR7vu37p1a/bt28fGjRtdYw0bNuTChQssW7bMNVa1alVy5MjBrFmzXGOlSpWiZMmSTJkyhaRLLTEKFixIlSpVWLBgAbGxsQBkz56d+vXrs3r1ag4ePAiYJvGtWrVi27ZtbN++3XXOjJrLk3MUPDeXA+TIkUNzuebyVOdywONz+cmTJ91eC83lmsuvnMuT5zZPzuV2eF8OmsvtOpc7nU7mzZt3z78v11xu37k8+f3ovf6+XHO5fefyK39nupvflyfPVTfisJJftXvUzp07qVq1KsOGDaN79+7XPO7ChQuu5AZT6C1SpAj79+8nW7ZsdyJUj5o6dSqtWrXydBgi16QcFbtTjordKUfF7pSjYnfKUbE75ajY3b2So6dPn6Zw4cKcOnWKkJCQax531xRtX3/9dT788MPrHrNlyxZKly7t+v7AgQM0bNiQRo0a8d///vemHu+ff/6hcOHCtxSriIiIiIiIiIiI3Lv2799PoUKFrnn7XVO0PXbsmGtJ97UUK1YMPz8/AA4ePEijRo2oVasW48aNw8vr5tr7Op1ODh48SHBwMA6H45bjzgySPwG4V1YVS+ajHBW7U46K3SlHxe6Uo2J3ylGxO+Wo2N29lKOWZXHmzBkKFChw3XrkXdPTNjQ0lNDQ0DQde+DAARo3bkzVqlUZO3bsTRdswfTiuV41/G6ULVu2u/4HRzI35ajYnXJU7E45KnanHBW7U46K3SlHxe7ulRy9XluEZHdN0TatDhw4QKNGjQgLC2PYsGGuTRXANB8WERERERERERER8aR7rmg7c+ZMdu7cyc6dO1OslL1LOkWIiIiIiIiIiIhIJnbzfQEyua5du2JZVqpfkjp/f3/69++Pv7+/p0MRSZVyVOxOOSp2pxwVu1OOit0pR8XulKNid8rRlO6ajchERERERERERERE7gb33EpbERERERERERERETtT0VZERERERERERETERlS0FREREREREREREbERFW1FREREREREREREbERFWxEREREREREREREbUdFWruuLL74gPDycgIAAatasyYoVKzwdkojLggULaNeuHQUKFMDhcDBhwgRPhyTiMnToUKpXr05wcDB58uThwQcfZNu2bZ4OS8Rl1KhRVKxYkWzZspEtWzZq167N1KlTPR2WyDV98MEHOBwOevfu7elQRAAYMGAADofD7at06dKeDkvEzYEDB+jcuTO5cuUiMDCQChUqsGrVKk+HJeISHh6eYi51OBz07NnT06F5nIq2ck0///wzffr0oX///qxZs4ZKlSoRGRnJ0aNHPR2aCABxcXFUqlSJL774wtOhiKQwf/58evbsybJly5g5cyYXL16kRYsWxMXFeTo0EQAKFSrEBx98wOrVq1m1ahVNmjThgQceYNOmTZ4OTSSFlStXMnr0aCpWrOjpUETclCtXjkOHDrm+Fi1a5OmQRFxOnjxJ3bp18fX1ZerUqWzevJlPPvmEHDlyeDo0EZeVK1e6zaMzZ84E4NFHH/VwZJ7nsCzL8nQQYk81a9akevXqjBw5EgCn00nhwoV56aWXeP311z0cnYg7h8PBn3/+yYMPPujpUERSdezYMfLkycP8+fNp0KCBp8MRSVXOnDn5+OOPeeaZZzwdiojL2bNnqVKlCl9++SVDhgyhcuXKjBgxwtNhiTBgwAAmTJhAVFSUp0MRSdXrr7/O4sWLWbhwoadDEUmz3r17M2nSJHbs2IHD4fB0OB6llbaSqoSEBFavXk2zZs1cY15eXjRr1oylS5d6MDIRkcwpNjYWMEUxEbtJSkrip59+Ii4ujtq1a3s6HBE3PXv2pE2bNm7vS0XsYseOHRQoUIBixYrxxBNPsG/fPk+HJOLy999/U61aNR599FHy5MnDfffdx9dff+3psESuKSEhge+//56nn376ni/Ygoq2cg0xMTEkJSWRN29et/G8efNy+PBhD0UlIpI5OZ1OevfuTd26dSlfvrynwxFx2bBhA1mzZsXf35/nnnuOP//8k7Jly3o6LBGXn376iTVr1jB06FBPhyKSQs2aNRk3bhzTpk1j1KhRREdHU79+fc6cOePp0EQA2L17N6NGjaJEiRJMnz6d559/npdffpnx48d7OjSRVE2YMIFTp07RtWtXT4diCz6eDkBERORu17NnTzZu3Kg+d2I7pUqVIioqitjYWH777Te6dOnC/PnzVbgVW9i/fz+9evVi5syZBAQEeDockRRatWrl+nvFihWpWbMmYWFh/PLLL2ozI7bgdDqpVq0a77//PgD33XcfGzdu5KuvvqJLly4ejk4kpf/7v/+jVatWFChQwNOh2IJW2kqqcufOjbe3N0eOHHEbP3LkCPny5fNQVCIimc+LL77IpEmTmDt3LoUKFfJ0OCJu/Pz8KF68OFWrVmXo0KFUqlSJzz77zNNhiQCwevVqjh49SpUqVfDx8cHHx4f58+fzn//8Bx8fH5KSkjwdooib7NmzU7JkSXbu3OnpUEQAyJ8/f4oPYsuUKaM2HmJLe/fuZdasWTz77LOeDsU2VLSVVPn5+VG1alVmz57tGnM6ncyePVu97kRE0sCyLF588UX+/PNP5syZQ9GiRT0dksgNOZ1OLly44OkwRABo2rQpGzZsICoqyvVVrVo1nnjiCaKiovD29vZ0iCJuzp49y65du8ifP7+nQxEBoG7dumzbts1tbPv27YSFhXkoIpFrGzt2LHny5KFNmzaeDsU21B5BrqlPnz506dKFatWqUaNGDUaMGEFcXBzdunXzdGgigHljfOVKhujoaKKiosiZMydFihTxYGQipiXCjz/+yF9//UVwcLCrH3hISAiBgYEejk4E3njjDVq1akWRIkU4c+YMP/74I/PmzWP69OmeDk0EgODg4BR9wLNkyUKuXLnUH1xs4dVXX6Vdu3aEhYVx8OBB+vfvj7e3N4899pinQxMB4JVXXqFOnTq8//77dOjQgRUrVjBmzBjGjBnj6dBE3DidTsaOHUuXLl3w8VGpMpleCbmmjh07cuzYMd59910OHz5M5cqVmTZtWorNyUQ8ZdWqVTRu3Nj1fZ8+fQDo0qUL48aN81BUIsaoUaMAaNSokdv42LFj1VhfbOHo0aM89dRTHDp0iJCQECpWrMj06dNp3ry5p0MTEckU/vnnHx577DGOHz9OaGgo9erVY9myZYSGhno6NBEAqlevzp9//skbb7zBoEGDKFq0KCNGjOCJJ57wdGgibmbNmsW+fft4+umnPR2KrTgsy7I8HYSIiIiIiIiIiIiIGOppKyIiIiIiIiIiImIjKtqKiIiIiIiIiIiI2IiKtiIiIiIiIiIiIiI2oqKtiIiIiIiIiIiIiI2oaCsiIiIiIiIiIiJiIyraioiIiIiIiIiIiNiIirYiIiIiIiIiIiIiNqKirYiIiIiIiIiIiIiNqGgrIiIiInILHA4HAwYM8HQY19W1a1fCw8M9HYaIiIiI3CQVbUVERETEYzZs2MAjjzxCWFgYAQEBFCxYkObNm/P55597OrQ7Ljw8nLZt23o6DBERERGxARVtRURERMQjlixZQrVq1Vi3bh3du3dn5MiRPPvss3h5efHZZ595OjwREREREY/x8XQAIiIiInJveu+99wgJCWHlypVkz57d7bajR496JigRERERERvQSlsRERER8Yhdu3ZRrly5FAVbgDx58rh9P3bsWJo0aUKePHnw9/enbNmyjBo1KsX9klsMzJs3j2rVqhEYGEiFChWYN28eAH/88QcVKlQgICCAqlWrsnbtWrf7d+3alaxZs7J7924iIyPJkiULBQoUYNCgQViWdcPndODAAZ5++mny5s2Lv78/5cqV45tvvkn7i3KFPXv24HA4GDZsGGPGjCEiIgJ/f3+qV6/OypUrUxw/YcIEypcvT0BAAOXLl+fPP/9M9bxOp5MRI0ZQrlw5AgICyJs3Lz169ODkyZOuY/r374+XlxezZ892u++//vUv/Pz8WLdu3S09JxERERFJG620FRERERGPCAsLY+nSpWzcuJHy5ctf99hRo0ZRrlw57r//fnx8fJg4cSIvvPACTqeTnj17uh27c+dOHn/8cXr06EHnzp0ZNmwY7dq146uvvuLNN9/khRdeAGDo0KF06NCBbdu24eV1eS1DUlISLVu2pFatWnz00UdMmzaN/v37k5iYyKBBg64Z45EjR6hVqxYOh4MXX3yR0NBQpk6dyjPPPMPp06fp3bv3Lb1OP/74I2fOnKFHjx44HA4++ugj2rdvz+7du/H19QVgxowZPPzww5QtW5ahQ4dy/PhxunXrRqFChVKcr0ePHowbN45u3brx8ssvEx0dzciRI1m7di2LFy/G19eXt99+m4kTJ/LMM8+wYcMGgoODmT59Ol9//TWDBw+mUqVKt/RcRERERCSNLBERERERD5gxY4bl7e1teXt7W7Vr17b+/e9/W9OnT7cSEhJSHBsfH59iLDIy0ipWrJjbWFhYmAVYS5YscY1Nnz7dAqzAwEBr7969rvHRo0dbgDV37lzXWJcuXSzAeumll1xjTqfTatOmjeXn52cdO3bMNQ5Y/fv3d33/zDPPWPnz57diYmLcYurUqZMVEhKS6nO4OvY2bdq4vo+OjrYAK1euXNaJEydc43/99ZcFWBMnTnSNVa5c2cqfP7916tQp19iMGTMswAoLC3ONLVy40AKsH374we2xp02blmJ8w4YNlp+fn/Xss89aJ0+etAoWLGhVq1bNunjx4nWfh4iIiIjcPrVHEBERERGPaN68OUuXLuX+++9n3bp1fPTRR0RGRlKwYEH+/vtvt2MDAwNdf4+NjSUmJoaGDRuye/duYmNj3Y4tW7YstWvXdn1fs2ZNAJo0aUKRIkVSjO/evTtFbC+++KLr78krZxMSEpg1a1aqz8WyLH7//XfatWuHZVnExMS4viIjI4mNjWXNmjVpfWncdOzYkRw5cri+r1+/vlvchw4dIioqii5duhASEuI6rnnz5pQtW9btXL/++ishISE0b97cLcaqVauSNWtW5s6d6zq2fPnyDBw4kP/+979ERkYSExPD+PHj8fHRxXoiIiIiGU3vuERERETEY6pXr84ff/xBQkIC69at488//+TTTz/lkUceISoqylV0XLx4Mf3792fp0qXEx8e7nSM2NtatWHllYRZw3Va4cOFUx6/s5Qrg5eVFsWLF3MZKliwJmD6zqTl27BinTp1izJgxjBkzJtVjbnVztaufT3IBNznuvXv3AlCiRIkU9y1VqpRbsXjHjh3Exsam6Bl8rRj79evHTz/9xIoVK3j//fdTFIFFREREJGOoaCsiIiIiHufn50f16tWpXr06JUuWpFu3bvz666/079+fXbt20bRpU0qXLs3w4cMpXLgwfn5+TJkyhU8//RSn0+l2Lm9v71Qf41rjVho2GLuR5Bg6d+5Mly5dUj2mYsWKt3Tu9Izb6XSSJ08efvjhh1RvDw0Ndft+9+7d7NixA4ANGzbc9OOJiIiIyK1R0VZEREREbKVatWqAuewfYOLEiVy4cIG///7bbdXplZfypyen08nu3btdq2sBtm/fDkB4eHiq9wkNDSU4OJikpCSaNWuWIXFdS1hYGICruHqlbdu2uX0fERHBrFmzqFu3rlvLidQ4nU66du1KtmzZ6N27N++//z6PPPII7du3T7/gRURERCRV6mkrIiIiIh4xd+7cVFeLTpkyBTCX9sPllaZXHhsbG8vYsWMzLLaRI0e6/m5ZFiNHjsTX15emTZumery3tzcPP/wwv//+Oxs3bkxx+7FjxzIs1vz581O5cmXGjx/v1t935syZbN682e3YDh06kJSUxODBg1OcJzExkVOnTrm+Hz58OEuWLGHMmDEMHjyYOnXq8PzzzxMTE5Nhz0VEREREDK20FRERERGPeOmll4iPj+ehhx6idOnSJCQksGTJEn7++WfCw8Pp1q0bAC1atMDPz4927drRo0cPzp49y9dff02ePHlcq3HTU0BAANOmTaNLly7UrFmTqVOnMnnyZN58880U7QOu9MEHHzB37lxq1qxJ9+7dKVu2LCdOnGDNmjXMmjWLEydOpHusyYYOHUqbNm2oV68eTz/9NCdOnODzzz+nXLlynD171nVcw4YN6dGjB0OHDiUqKooWLVrg6+vLjh07+PXXX/nss8945JFH2LJlC++88w5du3alXbt2AIwbN47KlSvzwgsv8Msvv2TYcxERERERrbQVEREREQ8ZNmwYjRs3ZsqUKfTp04c+ffqwYsUKXnjhBZYvX0727NkBs+L2t99+w+Fw8Oqrr/LVV1/xr3/9i169emVIXN7e3kybNo3Dhw/Tr18/Vq5cSf/+/VNdnXqlvHnzsmLFCrp168Yff/zBiy++yGeffcaJEyf48MMPMyTWZC1btuTXX38lKSmJN954gz/++IOxY8e6Wk1c6auvvmLMmDEcPXqUN998kzfeeIM5c+bQuXNn6tatS1JSEl26dCF37tyMGDHCdb8SJUowdOhQfv31VxVtRURERDKYw0qPnRdERERERO4CXbt25bfffnNbnSoiIiIicqdppa2IiIiIiIiIiIiIjahoKyIiIiIiIiIiImIjKtqKiIiIiIiIiIiI2Ih62oqIiIiIiIiIiIjYiFbaioiIiIiIiIiIiNiIirYiIiIiIiIiIiIiNqKirYiIiIiIiIiIiIiNqGgrIiIiIiIiIiIiYiMq2oqIiIiIiIiIiIjYiIq2IiIiIiIiIiIiIjaioq2IiIiIiIiIiIiIjahoKyIiIiIiIiIiImIjKtqKiIiIiIiIiIiI2IiKtiIiIiIiIiIiIiI2oqKtiIiIiIiIiIiIiI2oaCsiIiIiIiIiIiJiIyraioiIiIiIiIiIiNiIirYiIiIid5FGjRrhcDg8HUa62LFjBw899BD58+fHy8uL7Nmzezok8aDw8HDCw8PdxgYMGIDD4WDevHkeielmdO3aFYfDwZ49ezwdioiIiGQCKtqKiIiIiO0kJSXx4IMPMmXKFNq0acO7777L66+/flPnGDduHA6HI81fXbt2zZgnk8mEh4e7vS7e3t7kzp2bFi1a8Ndff3k6vHSVnCPjxo3zdCgiIiIibnw8HYCIiIiIyNWio6PZvHkz3bt3Z8yYMbd0jsqVK9O/f3+3sT179jB+/HgqVarEgw8+mOJ4Mby9vXn77bcBSEhIYOvWrfz999/MnDmTYcOG0bdvXw9HaLz44ot06tSJIkWKeDoUERERkXSloq2IiIiI2M7BgwcBKFCgwC2fo3LlyikKsfPmzWP8+PFUrlyZAQMG3EaEdzcfH58Ur8+MGTNo2bIl7777Ls8//zxBQUGeCe4KuXPnJnfu3J4OQ0RERCTdqT2CiIiIyG1YsGABDz74IHnz5sXf35/ChQvTvn17Fi1a5Drm4MGD9O/fn1q1apEnTx78/f0JDw/nhRde4OjRoynOmdz7cvfu3XzyySeULVsWf39/t8v3Fy1aRMOGDcmSJQu5cuWiY8eO7N+//7afT0JCAp9++inVq1cnODiYrFmzUrZsWfr06cPJkyfdjt24cSMdOnRwPaeiRYvSu3dvjh8/nuK8yf1Iz549S69evShQoAD+/v5UrFiR3377LcWxDRs2BGDgwIGuy/Qzssh6ZW/UcePGUaVKFYKCgmjUqFGK2692vUvs169fT6dOncifPz9+fn6EhYXx0ksvpfoapaZ48eIEBwcTHx+f6u33338/DoeD7du3A+B0Ovnvf/9LjRo1yJkzJ4GBgRQqVIh27drddt/XFi1aUKpUKeLj49m0aRNwuYfy+fPnefvtt4mIiMDX19ft3yo6Oppnn32WIkWK4O/vT/78+enatSt79+5N9XH++usvqlevTmBgIHnz5qV79+4pci/Z9f5d1q1bxxNPPEGhQoVcj9uyZUsmTpwImJ+zbt26AdCtWze3lhBXOnPmDP3796dcuXIEBgaSPXt2IiMj3X7Gr7Rp0ybatm1LcHAwISEhtG7dmo0bN173tRURERG5mlbaioiIiNyizz77jFdeeYXAwEAeeughihQpwoEDB1i0aBG//fYb9erVA0xh95NPPqFp06bUrFkTX19f1q5dy6hRo5g+fTpr1qwhJCQkxflfeuklli1bRps2bWjXrh158uQBYPbs2bRq1QovLy86duxIgQIFmD17NnXr1iVHjhy3/HzOnTtH8+bNWbx4MSVKlKBbt274+/uzY8cORo8ezVNPPeU6/6JFi4iMjCQhIYFHHnmE8PBwli5dymeffcakSZNYtmxZihWQFy9epEWLFpw8eZKHH36Y+Ph4fvrpJzp06MC0adNo0aIFAL179yYqKorx48fTsGFDV+E0+c/w8HD27t1LdHR0io2pbtfHH3/M3LlzeeCBB2jRogXe3t63fK6///6bDh064OXlxQMPPEDhwoXZvHkzI0eOZPr06SxfvvyG/16dO3dm4MCBTJgwgccff9zttpiYGKZNm0bNmjUpWbIkAG+88QYfffQRERERPP744wQHB7tyctasWa7X8HZdXdh8+OGHWbduHS1btiR79uwULVoUgOXLlxMZGUlcXBxt27alRIkS7Nmzhx9++IGpU6eydOlSihUr5jrPt99+S5cuXciWLRtPPvkk2bNnZ9KkSTRr1oyEhAT8/PzSFN/vv//O448/jmVZtGvXjlKlSnH06FGWL1/O//3f/9GuXTsefPBBTp06xV9//cUDDzyQanuMEydO0KBBAzZt2kTdunV57rnnOH36NH/99ReNGzfm119/dWuzsXHjRurWrcvZs2dp3749JUqUYMWKFdStW5dKlSrd/AstIiIi9y5LRERERG5aVFSU5eXlZRUoUMCKjo52u83pdFoHDhxwfX/kyBHrzJkzKc4xfvx4C7CGDBniNt6lSxcLsAoVKmTt3bvX7bakpCSrWLFilsPhsBYuXOj2mI8//rgFWLf6Fq9v374WYD355JNWYmKi222nTp1yPYekpCQrIiLCAqxp06a5HdevXz8LsJ5++mm38bCwMAuwHnjgAevChQuu8VmzZlmAFRkZ6Xb83LlzLcDq379/ijiTz3X1654Wyeft0qWL23j//v0twMqSJYu1fv36FPdLvn3u3Lkpbhs7dqwFWGPHjnWNxcTEWNmyZbMKFixo7dmzx+34//3vfxZgvfjiizeMd8eOHRZgtWrVKsVtn3/+uQVYI0eOdI3lzJnTKlCggBUXF5fi+OPHj9/w8SzLvL7+/v4pxmfNmmU5HA4rS5YsVnx8vGVZltWwYUMLsCpXrpzi/AkJCVZ4eLgVHBxsrVmzxu22hQsXWt7e3lbbtm1dY7GxsVa2bNmsLFmyWNu2bXM7T4MGDSzACgsLcztPav8uhw8ftrJkyWJlyZIlxeNalmXt37/f9ffU/u2ulPwz9fXXX7uNHzlyxCpcuLAVGhpqnTt3zjWe/Hp8//33bse/8cYbrp/NW8lbERERufeoPYKIiIjILRg9ejROp5MhQ4akWO3pcDjcerHmyZOHrFmzpjjHk08+SbZs2Zg1a1aqj9GvX78UGywtWrSI3bt307ZtW9dK3uTHfP/99295ZWhiYiJjxowhJCSEzz77LMV5QkJCXM9h8eLF7Nq1i1atWhEZGel23LvvvkvOnDn58ccfSUhISPE4n376qdtqyaZNmxIWFsbKlSvTHOvs2bPZsmULBQsWvJmnmCb/+te/qFChwm2f59tvv+X06dMMHTqUsLAwt9s6depElSpV+Omnn254nuLFi1O7dm1mzpyZopXGd999h6+vLx07dnQb9/PzSzUPcubMmeb4ExMTGTBgAAMGDOCtt97ikUceoWXLlliWxeDBgwkMDHQ7fuDAgSnOP2nSJPbs2UO/fv2477773G6rV68eDzzwAFOmTOH06dMATJgwgdOnT/P000+7Vg4D+Pr68t5776U59vHjxxMXF0ffvn1TPC5AoUKF0nSemJgYfv75Z5o0acKzzz7rdluePHno168fx44dc/387tu3j/nz51OxYkWeeOIJt+PffPNNsmfPnubnICIiIqL2CCIiIiK3YMWKFQCuS/pv5I8//mD06NGsWbOGkydPkpSU5LotedOtq9WoUSPF2Lp16wCoX79+itvCwsIoXLgwe/bsSVNMV9q6dStnzpyhWbNmN7xkf+3atQCpXmqfNWtWqlWrxowZM9i2bZtbAfTKy+avVKhQIZYuXZrmWCMiItJ87M1K7TW/FcuWLQNMe4Bdu3aluP38+fPExMQQExNzw420nnzySZYuXcr//vc/evXqBcCOHTtYsWIF7dq1c7t/p06d+PLLLylfvjydOnWicePG1K5dO0WR9UaSkpIYOHAgAF5eXuTIkYMmTZrQs2dP7r///hTHp/a6Jb8G27ZtS7Uf8eHDh3E6nWzfvp1q1apdN7dr166Nj0/afnW52Z/Na1m5ciVJSUlcuHAh1fh37NgBmJ+dtm3buuK/8sOUZFmzZqVy5cq33VdYRERE7h0q2oqIiIjcgtjYWBwOB/nz57/hsZ988gmvvvoqoaGhtGjRgkKFCrmKaCNGjODChQup3i9v3rypPi7g6m+b2n1upWibfN60rF5NXhmZWnyA6zVJPi5Zan17AXx8fHA6nWmONSNd6zndrBMnTgDwxRdfXPe4uLi4GxZtO3bsSO/evfn+++9dRdvvvvsOMAXdK3322WcULVqUsWPHMmTIEIYMGUJAQAAdOnTgk08+ueFjJfP39+f8+fNpOhZSf92SX4MffvjhuveNi4sDrp/b3t7e5MqVK02x3EwuX09y/IsXL2bx4sXXPC4t8UP65ZaIiIjcG1S0FREREbkF2bNnx7IsDh06dN3iUGJiIoMHDyZ//vxERUW5FXQsy+Kjjz665n2v3uwJLhc+r75UPtmRI0fS+hTcJF+6feDAgRsemy1btus+1uHDh92Oy0xSe83BrDYF8+95teRi3ZWSn/uGDRsoX778bcWUM2dOWrduzYQJE9i2bRulSpXi+++/JyQkhHbt2rkd6+Pjw6uvvsqrr77KwYMHmT9/PmPHjuXbb7/l8OHDTJ8+/bZiuZbUXrfk12DixIm0bdv2hue4Xm4nJSVx/PjxNBVir8zl29moLjn+vn37MmzYsBsen1E/myIiInJvUk9bERERkVuQfDn4jBkzrntcTEwMsbGx1K5dO8UKvFWrVnHu3LmbetzkHegXLlyY4ra9e/eyf//+mzpfslKlSpEtWzZWrlzJyZMnr3tscp/Q1C71jouLY9WqVQQGBlKqVKlbisWOkltGpFbUTm4XcaWaNWsC3FTbh+tJXlH7/fffs3jxYqKjo3nkkUcICAi45n0KFCjAY489xrRp0yhevDizZs266Xy7HTf7Glwvt5cuXZpqwTw1af3ZBFy9f69sV5KsevXqOByOm45/0aJFKW47e/YsUVFRaTqPiIiICKhoKyIiInJLnnvuOby9vXn77bfZu3ev222WZbn61ObJk4fAwEDWrFlDfHy865iTJ0/y0ksv3fTj1qtXj6JFizJp0iS34pBlWbz55pupFp/SwsfHhx49ehAbG0uvXr1SnCc2NpazZ88CULduXSIiIpg6dWqKTdSGDBnC8ePHeeyxx9w2HEtPu3btYuvWrVy8eDFDzp+a6tWrA2aDsStbOSxdujTVy/+7detGcHAwb731Fps2bUpxe3x8vKvna1q0adOGHDly8MMPP/Dtt98CKVsjXLhwgSVLlqS4b1xcHGfPnsXX19e1YvhOeOCBByhSpAjDhw9nwYIFKW6/ePGiWw4/8MADZMuWjW+++Ybt27e7Hff222+n+XG7dOlC1qxZ+eSTT1ItlF5ZeE/ePC21Dzvy5ctHhw4dWLJkCR9//DGWZaU4Zvny5a6f6yJFitCgQQPWr1+fIifef/99Tp06lebnICIiIqL2CCIiIiK3oEKFCowYMYKXX36ZcuXK8eCDDxIWFsbhw4dZsGABbdq0YcSIEXh5efHCCy/wySefUKlSJdq1a8fp06eZOnUqYWFhFChQ4KYe18vLizFjxtC6dWuaNWtGx44dKVCgAHPmzOHQoUNUrFiR9evX39JzGjRoEMuWLeO7775j2bJltGrVCn9/f3bv3s20adNYtGgRlStXxsvLi3HjxhEZGUnr1q159NFHCQsLY+nSpcybN4+IiAg++OCDW4ohLZo2bcrevXuJjo6+rcvfb0atWrWoW7cuc+bMoXbt2jRo0IC9e/fy119/0a5dO/7880+340NDQ/nf//7Ho48+SqVKlWjZsiWlS5fmwoUL7Nmzh/nz51OnTh2mTZuWpsf39/enQ4cOjB49mrFjxxIWFkaDBg3cjjl37hx169alZMmSVK1alSJFinD27FkmTZrE4cOHefXVV/H390+31yQtMf/222+0atWKhg0b0qRJEypUqIDD4WDv3r0sXLiQXLlysXXrVsC0F/jPf/5D165dqV69Op06dSIkJIRJkyYRGBiYpv7RYD4o+fbbb+nUqRM1atTg/vvvp1SpUsTExLB8+XLCw8OZMGECgGuTthEjRnDy5ElCQ0MBXEXiL7/8km3btvHvf/+b7777jtq1a5M9e3b279/PqlWr2LFjB4cOHSIoKAgwPYzr1q3LU089xYQJEyhRogQrVqxg5cqV1K9fP9VVxCIiIiKpskRERETkls2dO9dq27atlTNnTsvPz88qVKiQ9fDDD1uLFy92HZOQkGC99957VokSJSx/f3+rSJEiVt++fa0zZ85YYWFhVlhYmNs5u3TpYgFWdHT0NR93wYIFVoMGDazAwEArZ86c1qOPPmrt3bvXatiwoXU7b/HOnz9vDRs2zKpcubIVGBhoZc2a1SpbtqzVt29f6+TJk27Hrl+/3nrkkUes3LlzW76+vlZYWJjVq1cv69ixYynOm9rzTJZazHPnzrUAq3///qme60avz7Ukn7dLly5u4/3797cAa+7cude8b0xMjPXUU09ZOXPmtAIDA61atWpZ06dPt8aOHWsB1tixY1PcZ+vWrdYzzzxjhYWFWX5+flaOHDmsChUqWC+//LK1YsWKm4p90aJFFmAB1htvvJHi9oSEBOvDDz+0WrRoYRUqVMjy8/Oz8ubNazVo0MD68ccfLafTmabHCQsLs/z9/dN0bFry7Z9//rF69erlyv9s2bJZZcqUsZ599llr9uzZKY7/888/rapVq1r+/v5Wnjx5rGeffdY6ceJEqjl0vX+3tWvXWh06dLDy5s1r+fr6Wvnz57datWplTZo0ye24yZMnW9WrV7cCAwNdr++V4uPjrY8++siqWrWqlSVLFiswMNAqWrSo9eCDD1rffvutdfHiRbfjN2zYYLVu3drKmjWrFRwcbLVq1crasGFDmn6uRURERJI5LCuV63xERERERERERERExCPU01ZERERERERERETERlS0FREREREREREREbERbUQmIiIicpeKiopybbh0PeHh4XTt2jXD4xERERERkbRRT1sRERGRu9S4cePo1q3bDY9r2LAh8+bNy/iAREREREQkTVS0FREREREREREREbER9bQVERERERERERERsRH1tL1FTqeTgwcPEhwcjMPh8HQ4IiIiIiIiIiIiYnOWZXHmzBkKFCiAl9e119OqaHuLDh48SOHChT0dhoiIiIiIiIiIiGQy+/fvp1ChQte8XUXbWxQcHAyYFzhbtmwejibjTZ06lVatWnk6DJFrUo6K3SlHxe6Uo2J3ylGxO+Wo2J1yVOzuXsnR06dPU7hwYVdt8Vq0EdktOn36NCEhIcTGxt4TRdvjx4+TK1cuT4chck3KUbE75ajYnXJU7E45KnanHBW7U46K3d0rOZrWmqI2IpM0uV6PDRE7UI6K3SlHxe6Uo2J3ylGxO+Wo2J1yVOxOOepOr4akyaJFizwdgsh1KUfF7pSjYnfKUbE75ajYnXJU7E45KnanHHWnoq2IiIiIiIiIiIiIjahoKyIikhEGDIDBg1O/bfBgc7uIiIiIiIhIKnw8HYBkDhUrVvR0CCLXpRwV2/H2hnffNX9/553LOTp4sBkfNMhzsYmkQvOo2J1yVOxOOSp2pxxNX0lJSVy8eNHTYdxVypYty/nz5z0dxi3z9vbG19c33c7nsCzLSrez3UPSutPb3eLixYvpmngi6U05KraUXKBt2ZLE3r3xWb4c+vc3Bdt33vF0dCJuNI+K3SlHxe6Uo2J3ytH0YVkWhw8fJjY2FpXU0pdlWTgcDk+HcVv8/f3JnTv3dWuFaa0paqWtpMm0adNo166dp8MQuSblqNhS6dKQJQtMm4bPtGlm7OmnVbAVW9I8KnanHBW7U46K3SlH00dsbCynTp0iNDSULFmyZPoio52cPn060y6MtCyLixcvEhsby4EDBwBu+7moaCsiIpJRTpyAuDj3sW++gT17zCrcOnU8EpaIiIiIiNw8y7I4evQo2bJlI3fu3J4O565z/vx5AgICPB3GLQsMDCQ4OJh//vmHmJiY2y7aaiMyERGR9HL2LGzYcPn7Z5+FBx4AwOlz6XNSLy+YMwfeessDAYqIiIiIyK1KSkoiKSkp064GlYzncDgICQnhwoULt93zWEVbSZOIiAhPhyByXcpR8SjLgt9+gzJloF07iI834++/D3/9BYMGsXXdOtPL1umEqlXNSttkx4/DmjWeiV3kEs2jYnfKUbE75ajYnXL09iUmJgLg46ML1zOCv7+/p0NIF8m9o5OSkm7rPCraSpqULVvW0yGIXJdyVDxm+3Zo2RIefRT++cespE1uf/Duu65Nx8qWLWt62Q4aBKtXw9y5l8/x0UemkPvQQ7B+vceeitzbNI+K3SlHxe6Uo2J3ytH0oz62GSMwMNDTIaSL9MoPFW0lTWbMmOHpEESuSzkqd1x8PLz9NlSoADNmgL8/9O8PmzZB2bKQlOQq2MIVOZpcuL3yU9eTJ8HhgAkToFIl6NgRNm++889J7mmaR8XulKNid8pRsTvlqNhdbGysp0OwFa3nljS5cOGCp0MQuS7lqNxRx49DtWpmRS2Ylbaffw7Fi18+ZsAAt7u45eilQq7LmDHQu7e5z6+/wi+/mD8ff9wUgkuUyIAnIeJO86jYnXJU7E45KnanHBW7syzL0yHYilbaioiI3KxcueC++6BwYfj9d5gyxb1geyvKljXF2nXr4MEHTZ/cH36ATz5Jl5BFREREREQk81DRVtIkb968ng5B5LqUo5KhLlyAoUPh8OHLY6NHw5Yt0L69aW1wA2nO0YoV4c8/YdUqU7x9663Lt+3eDXv33lzsImmkeVTsTjkqdqccFbtTjsq1OByONH3NmzcvQ+NI3sBLjExRtP3iiy8IDw8nICCAmjVrsmLFiusef+rUKXr27En+/Pnx9/enZMmSTJkyxXV7UlIS77zzDkWLFiUwMJCIiAgGDx6sZdjXUaNGDU+HIHJdylHJMDNmmL61b74J/fpdHg8NhSxZ0nyam87RqlVN8bZw4ctjffqYVgk9e8KBAzd3PpEb0DwqdqccFbtTjordKUflWr777ju3r+bNm6c6XqZMmQyNI8tN/H51L7B9T9uff/6ZPn368NVXX1GzZk1GjBhBZGQk27ZtI0+ePCmOT0hIoHnz5uTJk4fffvuNggULsnfvXrJnz+465sMPP2TUqFGMHz+ecuXKsWrVKrp160ZISAgvv/zyHXx2mceSJUuoU6eOp8MQuSblqKS7f/6BV16B334z3+fPD61b3/LpbjtHz5+HM2fg4kX48kv4v/+D556D11+HfPlu/bwil2geFbtTjordKUfF7pSjci2dO3d2+37ZsmXMnDkzxfjV4uPjCQoKSrc4zp49S9asWdPtfJmd7VfaDh8+nO7du9OtWzfKli3LV199RVBQEN98802qx3/zzTecOHGCCRMmULduXcLDw2nYsCGVKlVyHbNkyRIeeOAB2rRpQ3h4OI88LF70EwAAvRBJREFU8ggtWrS47greCxcucPr0abeve8nx48c9HYLIdSlHJd1cvAgffwylS5uCrbe32SRs61Z47LFbPu1t52hAAMyeDXPnQr16pmXDZ59BsWLw73/DsWO3d36552keFbtTjordKUfF7pSj9vXHH1CpEgQGmj//+MPTEaXUqFEjypcvz+rVq2nQoAFBQUG8+eabgGmvMOCqjZgBwsPD6dq1q9vYqVOn6N27N4ULF8bf35/ixYvz4Ycf4nQ6SUxMvAPPJPOw9UrbhIQEVq9ezRtvvOEa8/LyolmzZixdujTV+/z999/Url2bnj178tdffxEaGsrjjz/Oa6+9hre3NwB16tRhzJgxbN++nZIlS7Ju3ToWLVrE8OHDrxnL0KFDGThwYIrxqVOnuj5VaN68OcePH2fNmjWu22vXro2Pjw8LFy50jVWsWJGCBQsydepU11ixYsUoV64cM2fO5Pz58wDkyZOHmjVrsnTpUmJiYgAICgqiadOmbNiwgT3Ju5YDbdq0Yc+ePWzatMk11rBhQ86fP8/y5ctdY9WqVSMkJITZs2e7xkqXLk2JEiWYPHkyTqcTgMKFC1O5cmXmzZvHmTNncDqdLFq0iHr16rFq1SoOHToEmH4jLVu2ZOvWrezYscN1zhYtWnDs2DHWrl3rGqtTpw5eXl4sWrTI7bUoUKAA06ZNc41FRERQtmxZZsyY4drdMm/evNSoUYMlS5a4/qPJkiULTZo0Yd26dezbt891/3bt2rFr1y42b97sGmvcuDFxcXFuhfnq1asTHBzMnDlzXGNlypShePHiTJo0ydUuo0iRIlSqVMn1WgDkzJmTunXrsnLlSg5f6nHp5+dHZGQkW7ZsYefOna5zRkZGcuTIEaKiolxjdevWBWDx4sWuscqVK5M3b16mT5/uGitevDhlypRh+vTpJCQkAJAvXz6qV6/O4sWLOXHiBADBwcE0atTI7bVwOBy0bduWnTt3smXLFtc5mzRpwpkzZ1i5cqVrrEaNGmTJkoW5c+e6xsqWLUtERAQTJ050jSW/FnPmzCEuLg6AXLlyUadOHVasWMGRI0cA8Pf3p0WLFmzevJldu3a57t+yZUsOHjzI+vXrXWP16tXD6XSyZMkS19h9991HaGgoM2bMcI2VKFGC0qVLM23aNC5evAhA/vz5qVatGosWLcLpdDJx4kTXaxEVFcX+/fsBM2+0adOGHTt2sHXrVtc5mzZtSmxsLKtWrXKN1axZk4CAAObPn+8aK1euHOHh4UyePNk1Fh4eToUKFZg9ezbx8fEA5M6dm9q1a7N8+XKOHj0KQEBAAM2bN2fTpk3s3r3bdf9WrVpx4MABt9eifv36JCYmus1vVapUIVeuXMycOdM1VrJkSUqVKsXUqVNd/6kVKFCAqlWrsnDhQk6dOgVASEgIDRo0YM2aNRy4dCm9t7c3rVu3Zvv27Wzbts11zmbNmnHy5ElWr17tGqtVqxb+/v5ur0X58uUpUqSIW8uZokWLUr58eWbNmsW5c+cACA0NpVatWixbtoxjl4qJgYGBNGvWjI0bNxIdHe26f+vWrdm3bx8bN250jTVs2JALFy6wbNky11jVqlXJkSMHs2bNco2VKlXK1QInKSkJgIIFC1KlShUWLFhAbGwsANmzZ6d+/fqsXr2agwcPAuDj40OrVq3Ytm0b27dvd52z5dq1+PbvD8CJ0qXZ8PzzlHv8cXycThZe8fNws3N5co5COszlP/9MjtWrOffqq+TYvh0+/phjfn6EDhly3bkcIEeOHJrLNZenOpcDHp/LT5486fZaaC7XXH7lXJ48t6VlLr+b35eD5nK7zuVOp5N58+bd8+/LNZfbdy5Pfj+aWd6X23EuP3PmDPHx8Zw+fZrz588TFBSEl5c3R46ccR0XEBBAQECA698fzLwUFBTEmTNnXK+Pt7c3wcHB/PLLeZ5+OgCHw8KyHGzYAA8/DGPGxNG6tfkZy5YtG4mJia4cB1wrUs+ePesaCwwMxNfXl8TE065tN/z9/QkMDCQ2NtY1n/r6+pIlSxbOnj3ryl0vLy+yZctGfHy8a84/deoU2bNn5/z58yQmJhITE0PLli3p1KkTjz32GCEhIa7nmZSURFJSkmt+BlyPl3xMfHw8kZGRHDp0iG7dulGgQAFWrFjBG2+8waFDhxgwYIDrWIfDQUhICOfOnXPFczOvRVBQED4+Pm6LLtP6WiT/28THx7vmfMD1WiTnFJi5zul0uubi5Ps7nU7mzp3rOueVc/mVsV+XZWMHDhywAGvJkiVu4/369bNq1KiR6n1KlSpl+fv7W08//bS1atUq66effrJy5sxpDRgwwHVMUlKS9dprr1kOh8Py8fGxHA6H9f777183lvPnz1uxsbGur/3791uAFRsbe/tPNBOYPXu2p0MQuS7lqKSb2FjLqljRsr75xrKSktLttBmSo06nZU2ebFlt2lhWfPzl8fXrLevkyfR/PLmraR4Vu1OOit0pR8XulKO379y5c9bmzZutc+fOucbOnrUssNfX2bO39zx79uxpXV0ybNiwoQVYX331VYrjAat///4pxsPCwqwuXbq4vh88eLCVJUsWa/v27W7Hvf7665a3t7e1adOm2wvcJlLLkyvFxsamqaZo+/YIN8vpdJInTx7GjBlD1apV6dixI2+99RZfffWV65hffvmFH374gR9//JE1a9Ywfvx4hg0bxvjx4695Xn9/f7Jly+b2dS9p0qSJp0MQuS7lqNySxET4/HN44AHz/gYgWzaIioJu3cAr/f6bzJAcdThMn91Jk8y1VABJSdCxIxQtCkOGmD64ImmgeVTsTjkqdqccFbtTjsrt8vf3p1u3brd8/19//ZX69euTI0cOYmJiXF/NmjUjKSnJ7aoQsXlP29y5c+Pt7e26tCPZkSNHyHeNTVfy589PyZIlXa0QwFxac/jwYdeS5n79+vH666/TqVMnKlSowJNPPskrr7zC0KFDM+7JZHLr1q3zdAgi16UclZu2bBlUrw4vvwx//w1//XX5tuRridJBcn8qf3/nnelPdfCgif/UKXjnHVO8/egjuOJyHZHUaB4Vu1OOit0pR8XulKMZIygIzp699a/y5VP++uFwQIUKt37OdNwbzE3BggXx8/O75fvv2LGDadOmERoa6vbVrFkzAP7555/0CvWuYOuirZ+fH1WrVnXr8+R0Opk9eza1a9dO9T5169Zl586drh5QANu3byd//vyuxIqPj8frqtVTyf0mJHVX9qYSsSPlqKRZTAw8+yzUrm1W1GbPDqNGQbt26f5Qf/xh+lFt2AAJCV6u/lQZWrgtXBjWr4cffoCSJeH4cXjtNbNh2aefwqX+ZiJX0zwqdqccFbtTjordKUczhsMBWbLc+tfAgeaiv+TCrcNhvh848NbPmY5rUNwEJl/dl0bJ/XuTOZ1OmjdvzsyZM1P9at26dXqGm+nZumgL0KdPH77++mvGjx/Pli1beP7554mLi3Mtx37qqafcNip7/vnnOXHiBL169WL79u1MnjyZ999/n549e7qOadeuHe+99x6TJ09mz549/PnnnwwfPpyHHnrojj8/ERG5Q5xO+PprKFUK/u//zFjXrrBtGzz3HFxxhUZ6OH8eevc2f0/uvJD8ZmzQoHR9qJS8veHxx2HTJhg3zhRsjx6FPn1gwYIMfnAREREREUmr9u3h99+hYkUICDB//vEHZKYSVY4cOdw2XgNISEhwbZaZLCIigrNnz9KsWbNUvwoXLnwHo7Y/H08HcCMdO3bk2LFjvPvuuxw+fJjKlSszbdo08ubNC5hPiq5cNVu4cGGmT5/OK6+84tpBsFevXrz22muuYz7//HPeeecdXnjhBY4ePUqBAgXo0aMH77777h1/fiIicoc4naZ/7YkT5p3Ql1/CpR2j09OuXTB6NHzzjVnkejXLMitv//zTLO71ycj/iX18oEsXU8D99luYNQtatLh8++rV5rqr27jESUREREREbk/79uYrs4qIiGDBVYtDxowZk2KlbYcOHRgwYADTp08nMjLS7bZTp06RmJiY4bFmJg7LSl7/Izfj9OnThISEEBsbe89tSiYikmmcOmU26PL3N98vXgwrV8KLL6ZrtTQxESZPNl0Wpk+/PO7rCxcvXvt+BQtC9+6mW0PBgukWTtqcPGn63ebIYXrfPvmkCVhERERERFJ1/vx5oqOjKVq0KAEBAZ4OJ8O8+OKLfPHFF1xZMmzUqBExMTFs3LgxxfGjR4/mueeeo3379jRv3px169Yxffp0zpw5Q5s2bRg3bhxg2pXWr1+f9evX07VrV6pWrUpcXBwbNmzgt99+Y8+ePeTOnftOPc0Mc6M8SWtN0fbtEcQedu3a5ekQRK5LOSpuLMusLC1VCoYNuzxet67pWZBOBdtDh2DwYFP7fPBBU7B1OKBlS7Ov2Q8/mOOu7E8F5lKn0FA4cAAGDICwMNPrdtYssyD4jti61Vx/tWcPPPMMlCkD330HV30aLvcOzaNid8pRsTvlqNidclQySvfu3XnttddYsGABffv2JTo6mpkzZ5IlSxa344KCgpg/fz79+vVj3rx59OrViw8++IAdO3YwcOBA/JMX2wiglba37F5baTtx4kTaZcAmPSLpRTkqLhs3wgsvwMKF5vsqVWDFinTrWWtZMHeuWVU7YYJZZQuQOzc8/TT06GFayCb74w/Tw3bz5iTKlvWmf39TtL1wwdw2atTlUAFKlDAtdrt0gVy50iXka4uPNwF88IHZoA1MoXvAAOjQAbz02e69RPOo2J1yVOxOOSp2pxy9fffKSltPOXXqFNmzZ/d0GLdNK21FRESudOYM9O0LlSubKmhQkClGLl2aLgXbkyfh00+hdGlo2hR++80UbOvWhe+/h3/+gQ8/dC/YgulNFRUFv/8+haioyxsK+PvDY4+ZfcE2bICePSE4GHbsME+jYEFTuF227PJGZukuKMg8WHQ0DB0KOXOajdk6dzYrcEVERERERMQjVLQVEZHMb/58U00dPtxc3v/QQ7BlC7z22m1vsrVyJXTrBgUKQJ8+sH07ZM0Kzz8P69bBokXwxBOX2+beivLlYeRIOHjQbGJWubJZifvtt1C7NlStCl9/DXFxt/VUri1rVnj9dVO8HTQIXn7Zvfq8enUGVo5FRERERETkamqPcIvutfYIZ8+eJWvWrJ4OQ+SalKP3uJ07TeWzYEH4/HNo3fq2ThcXBz/9ZDoHrF59ebxiRVOsfeIJsyr2ZtxMjloWLF9uHv/nn00BFyBbNnjqKdM+oVy5m3v8W7ZpE1SoYCrHgwaZhr3JzXnlrqJ5VOxOOSp2pxwVu1OO3j61R8hYSUlJeKdTWztPUnsEuaPiMmx5l0j6UI7eY+LjTUPZZMWLw7Rppp/tbRRst2yBXr1M7ffZZ03B1s/PdAtYvNi0OXjuuZsv2MLN5ajDAbVqwfjxZrOyYcPMUzx92qzILV8eGjY0heWEhJuP5aasXw+BgbBqlXlt69Y1O6bpM9+7juZRsTvlqNidclTsTjkqdue8Y7syZw4q2kqarFixwtMhiFyXcvQe8vffULasaRa7fPnl8UaNTHHxJiUkwC+/QOPG5rT/+Q/ExpruAB99ZIqm330Hderc3gLTW83RXLlM29lt22DGDNP5wdvb9MJ97DEoXBjefDMDW9A+9phpm9C3LwQEmB7BzZub13vBggx6UPEEzaNid8pRsTvlqNidclTsTh8suFPRVkREMofdu6FdO3jgAdi711Qrb+M/9X374O23oUgR6NgR5s0DLy9z+mnTzIZg/fpB7tzp9xRuh5eXqZX+8Yd5+v37mz67R4+aPcSKFYO2bWHyZNPWN13lyWOW++7ebfrd+vmZgm379mbVs4iIiIiIiKQrFW1FRMTezp83vVTLlYNJk8DX12yatXkzNGlyU6dKSoKpU+H++6FoUXjvPThyBPLlg3feMatVJ0yAyEhTJLWrggVhwAAT7++/Q7NmplvB5MmmcBsRYQq5R46k8wPnzw+ffQa7dpnmvm+/DUFB5jbLMjuziYiIiIiIyG3TRmS36F7biOzw4cPky5fP02GIXJNy9C5lWaaH6tKl5vsmTeCLL6B06Zs6zdGj8M03MHq0exuBJk1M7fGBB0wtOCNldI5u326e39ixcPKkGfP1NYthn38eGjTI4P3DJkwwvRvatjVF9vvuy8AHk4ygeVTsTjkqdqccFbtTjt4+bUSWsS5evIhvRv9idgdoIzK5o4JvZdcdkTtIOXqXcjjMjmD588P//mc2wEpjwdayYNEieOIJ00nhjTdMwTZ7dujdG7Zuhdmz4ZFHMr5gCxmfoyVLwiefmB6848ZBzZpw8SL8/LNpP1u+vNnELDY2gwJYv94sT540CapUgYcfhg0bMujBJCNoHhW7U46K3SlHxe6Uo2J3Xna+3NED9GpImsyZM8fTIYhcl3L0LpGQYHb/mjDh8ljXrmYXrk6d0rRU9PRp+PJLqFgR6teHH380p61e3ay2PXAAPv0USpXKsGeRqjuVo4GB0KULLFsGa9ZA9+6mg8HmzfDSS6YP7r/+BWvXpvMDv/uueZDHHjP/Tn/8AZUqmX+3rVvT+cEkI2geFbtTjordKUfF7pSjYndnzpzxdAi2oqKtiIjYw7x5ULkyvPaaqS4mbzLm5QVpWBWwbh0895wpSvbsCRs3mgLmM8/AqlWwYgV063a5Beu94L77YMwYOHgQPv8cypY1+4Z9/bVZDFurFowfD+fOpdMDliplquQbNpglzJZllvo+8YT5u4iIiIiIiKSJirYiIuJZhw6Zol7jxrBlC4SGwuDBpuJ6A+fPw3ffQZ06pt47erSp9ZYubfbLOngQ/vtfqFo145+GnYWEwIsvmkL2/Plm8auvLyxfbhYyFywIffvCjh3p9IDlysGvv0JUFDz4IPTvf3mVdFwcREen0wOJiIiIiMjdomLFinTt2tX1/bx583A4HMybN89jMV0tPDzcLcaMpKKtpEmZMmU8HYLIdSlHM6HERFNZLV3arM50OMyOWdu2mUridfoZ7dwJ/fpBoULw1FNmnzIfH+jQAebONVfpv/yy6V9rF3bIUYfDbEj2v//B/v3w/vsQFmY2Lhs+3PTFbd7cdDa4eDEdHrBSJfjzT7j//stjI0eaB+rRwwQhtmGHHBVxM2CA+RDvErccHTzY3C5iI5pHxe6Uo3Ij48aNw+FwuL4CAgIoWbIkL774IkeOHMnwx3ek087JU6ZMYcBd8D5BRVtJk+LFi3s6BJHrUo5mQkuXmh3BTp82DWdXrDDNaHPkSPXwxERT/2vRAkqUgGHD4PhxKFIEhgwx9b/kTbfS6f/6dGW3HM2b12zOtmuX2TusTRvzus2aZfYQCw83C2T/+SedH3jdOvOPOWYMFC9ulgAfPJjODyK3wm45KoK3t+mXfalw68rRwYPNuLe3B4MTSUnzqNidclTSatCgQXz33XeMHDmSOnXqMGrUKGrXrk18fHyGPu7VRdsGDRpw7tw5GjRocFPnmTJlCgMHDkzP0DxCRVtJk0mTJnk6BJHrUo5mEomJl/9ev75pQvvVV6aAW61aqnc5eBAGDjRFxPbtYeZMU1xs1Qr+/ht274a33oJ8+e7MU7hVds1Rb29TsJ00ybyWb7wBefKY133QIPO6P/SQed2dznR4wB9/hAULTHU9IQG++AIiIuCVV+AOfHov12bXHJV72DvvmInoUuF20qRJlwu2gwaZ20VsRPOo2J1y1IauuqrEjQevKmnVqhWdO3fm2WefZdy4cfTu3Zvo6Gj++uuvVI+PS96P5DY5r/qFw8vLi4CAALyucxXm3ezefNZy0yxtICM2pxy1OafTNJwtXhwOHLg8PmqUuUz+qtVSlgWzZ5u9rIoUMe9VDhyA3LnNPmU7d8KUKdCuXeZZaJUZcjQ83LRM2L/ftFBo0ACSkmDCBLPCuVQp+OQTs8L5ttSvb/pYzJkDdeua5sQjRpjGuuIxmSFH5R4THQ05c5qWKu++S5v77zcF24EDVbAVW9I8KnanHLWhq64qcbHZVSVNmjQBIDo6mq5du5I1a1Z27dpF69atCQ4O5oknngBM0XXEiBGUK1eOgIAA8ubNS48ePTh58qTb+SzLYsiQIRQqVIigoCAaN27Mpk2bUjzutXraLl++nNatW5MjRw6yZMlCxYoV+eyzzwDo2rUrX3zxBYBbq4dk6R1jRvK5o48mIiL3ntWrTa/alSvN9//5D3z4YaqHnjgB48ebxbfbt18er1fPnOLhh8Hf/w7EfI/z8zOblXXqBJs2mX+Pb781xfJXXzUrmzt2NP8mNWveRjuKxo1h4UKzjHfAAHPiZEeOmN3ScuZMj6ckIplBUpL7L6cPPWRaqlziuFRsOP31T2SLiDCbWIqIiNjF9VabentDQEDKY/v0MVefvfuu+fP1183vSoMHX76q5Hrn9fJy38A5Ph6Cgm7veaRi165dAOTKlQuAxMREIiMjqVevHsOGDSPo0mP26NGDcePG0a1bN15++WWio6MZOXIka9euZfHixfj6+gLw7rvvMmTIEFq3bk3r1q1Zs2YNLVq04MKFCzeMZebMmbRt25b8+fPTq1cv8uXLx5YtW5g0aRK9evWiR48eHDx4kJkzZ/Ldd9+luP/txpiQkJAur2maWHJLYmNjLcCKjY31dCh3RFRUlKdDELku5agNnThhWS+8YFkOh2WBZQUHW9Znn1nWxYtuhzmdlrV8uWV17WpZAQHm0OTDX3jBstav91D86Syz5+iZM5Y1Zoxl3Xff5X8jsKzKlS1r9Ghze7rq2tWysmWzrP79LevUqXQ+uaQms+eoZFL79plJ5IEHLCt3bss6e/bybe+8Yx0t28CaTnPLAusi3q7JZ2+DJzwWssi1aB4Vu1OO3r5z585Zmzdvts6dO5fyxivfJF/91bq1+7FBQdc/ftCgy8fmzn3t46pVcz9vWNhtPb+xY8dagDVr1izr2LFj1v79+62ffvrJypUrlxUYGGj9888/VpcuXSzAev31193uu3DhQguwfvjhB7fxadOmuY0fPXrU8vPzs9q0aWM5nU7XcW+++aYFWF26dHGNzZ071wKsuXPnWpZlWYmJiVbRokWtsLAw6+TJk26Pc+W5evbsaaVW8syIGFNz3Tyx0l5TzBTtEb744gvCw8MJCAigZs2arFix4rrHnzp1ip49e5I/f378/f0pWbIkU6ZMcd0eHh7utkQ6+atnz54Z/VQyrUqVKnk6BJHrUo7azA8/mGvpv/zSvJ14/HHYtg1efhl8zEUecXHw3/+aVrY1a8K4ceYq+UqVzMrOAwdMu9MKFTz7VNJLZs/RrFmhe3ezcHrZMujSxSwWiIoyHS4KFDB7iqXLFUMJCWZ13enTlxsav/cenDmTDieXa8nsOSqZxMWLMH++6XVToYLpgdOjB/z1F8TEmNswLdCXRA7km73NaMFM3mEQviQyBLMif/GmKzat3LbNrEo6fdoTz0jERfOo2J1yNJNwODzeBqhZs2aEhoZSuHBhOnXqRNasWfnzzz8pWLCg65jnn3/e7T6//vorISEhNG/enJiYGNdX1apVyZo1K3PnzgVg1qxZJCQk8NJLL7m1Lejdu/cN41q7di3R0dH07t2b7Nmzu9129SZmqbkTMaYn2xdtf/75Z/r06UP//v1Zs2YNlSpVIjIykqNHj6Z6fEJCAs2bN2fPnj389ttvbNu2ja+//totsVauXMmhQ4dcXzNnzgTg0UcfvSPPKTO6un+IiN0oR21m3To4dgzKlDF9S3/4AfLnB2DzZlO7LVjQFAHXrDEtD558EpYsgbVrze/vwcEefg7p7G7JUYfjcpH9wAHT47ZECVNP/eILKF/e9ML93/8gDVc3pc7PD1atgl9+MTl06hS8/TYUKwYff2wu+5J0d7fkqNjQlT0UR40yGxF+9BFs3Ggu66xTB4YM4Z+/1/DVnpa0b296mE+tN4TX4t7lHQYxBPPL6zsM4R0G8djxkcS/can/3wcfmMtJw8LML7kxMXf+OYqgeVTsTzmawc6evfbX77+7H3v0qPvtb79txv38zP+bV/a43bPn2uddsMD9vJs3p8tT+eKLL5g5cyZz585l8+bN7N69m8jISNftPj4+FCpUyO0+O3bsIDY2ljx58hAaGur2dfbsWVcdb+/evQCUKFHC7f6hoaEpCrFXS27TUL58+Vt6XukRY44cOVKcN6PYvqft8OHD6d69O926dQPgq6++YvLkyXzzzTe8/vrrKY7/5ptvOHHiBEuWLHH1oQgPD3c7JjQ01O37Dz74gIiICBo2bJgxT+IucEarm8TmlKMedvq0aUibPN+++y4UKgTPPQd+fiQkwB9/mN/Vr3xfERFhDuna1fyCfje7G3M0Z07Thqt3b1ObHzXKLJZbuNB8hYbC00+bInzRojd5ci8vePRRaN8efvrJrLjdsQP+/W+zUu/NNzPiKd3T7sYcFQ9JTITly82OkVOmmE/qLr2Xp2VLM+G3akV8o9bM9W3B5KU5mTEWLv0e5pI1IIn3rEG8l/AOXFH3TS7gBgxL4vBZeKdiM/KUXgZbt8KQITB8OPzrX2Zzw6t+oRTJSJpHxe6UoxksS5ZbO3bwYPP/V3IP2+RNyMB8fzPnTad+tjVq1KBatWrXvN3f3x8vL/d1oE6nkzx58vDDDz+kep+ra3GekBlivJKti7YJCQmsXr2aN954wzXm5eVFs2bNWLp0aar3+fvvv6lduzY9e/bkr7/+IjQ0lMcff5zXXnsN71R23UtISOD777+nT58+111KfeHCBbeGyKd1+ZWIiPkU+OefTeUuPBwWLTLFtqxZ4eWX2bsXxowxbRCSL5Dw8oL77zebWDVrZr6XzM3Ly/xbNmtmVt/+97/m3/3gQXPF8kcfQatW5t+8Vaub3ATX29tsNtSxo1mx/fnn8MILl2/fuxfy5dMOdSKedvQoTJtmirQzZsCVOzBPngzdupGYCKuOl2BGzyPMmOXFsh/N3mPJfHzMotsWLcxXlSoD+OsvsB42q/wt6/KfPxR9h+hoYCR86fUEj7R/jPe6TaD4L++bPi4jRpjl/717m0lIRETEjpILtMkFW7j855WF20wgIiKCWbNmUbduXQKv3BztKmFhYYBZ9VqsWDHX+LFjxzh16tQNHwNg48aNNGvW7JrHXau+lx4xnrzyPU4Gs3XRNiYmhqSkJPLmzes2njdvXrZu3ZrqfXbv3s2cOXN44oknmDJlCjt37uSFF17g4sWL9O/fP8XxEyZM4NSpU3Tt2vW6sQwdOpSBAwemGJ86daprl7zmzZtz/Phx1qxZ47q9du3a+Pj4sHDhQtdYxYoVKViwIFOnTnWNFStWjHLlyjFz5kzOnz8PQJ48eahZsyZLly4l5tJlXkFBQTRt2pQNGzawZ88e1/3btGnDnj172HRFM8GGDRty/vx5li9f7hqrVq0aISEhzJ492zVWunRpSpQoweTJk3E6nQAULlyYypUrM2/ePM6cOYPT6WTRokXUq1ePVatWcejQIQB8fX1p2bIlW7duZceOHa5ztmjRgmPHjrF27VrXWJ06dfDy8mLRokVur0WBAgWYNm2aaywiIoKyZcsyY8YMV6E8b9681KhRgyVLlnD8+HEAsmTJQpMmTVi3bh379u1z3b9du3bs2rWLzVdcFtC4cWPi4uLc+iFXr16d4OBg5syZ4xorU6YMxYsXZ9KkSViXLuUrUqQIlSpVcr0WADlz5qRu3bqsXLmSw4cPA+Dn50dkZCRbtmxh586drnNGRkZy5MgRoqKiXGN169YFYPHixa6xypUrkzdvXqZPn+4aK168OGXKlGH69OmuHQrz5ctH9erVWbx4MSdOnAAgODiYRo0aub0WDoeDtm3bsnPnTrZs2eI6Z5MmTThz5gwrV650jdWoUYMsWbK4+rcAlC1bloiICCZOnOgaS34t5syZQ9ylHSxz5cpFnTp1WLFiBUeOHAHMp24tWrRg8+bNrssXAFq2bMnBgwdZv369a6xevXo4nU6WLFniGrvvvvsIDQ1lxowZrrESJUpQunRppk2bxsWLFwHInz8/1apVY9GiRTidTiZOnOh6LaKioti/fz9gPuxp06YNO3bscJs7mjZtSmxsLKtWrXKN1axZk4CAAOZf6qkHUK5cOcLDw5k8ebJrLDw8nAoVKjB79mziL12qnTt3bmrXrs3y5ctdl1UEBATQvHlzNm3axO7du133b9WqFQcOHHB7LerXr09iYqLbh1JVqlQhV65crjYuACVLlqRUqVJMnTqVxMREAAoUKEDVqlVZuHCh6z+6kJAQGjRowJo1azhw4AAA3t7etG7dmu3bt7Nt2zbXOZs1a8bJkydZvXq1a6xWrVr4+/u7vRbly5enSJEiTJkyhaz//EP50aMJvbSzd7zDweLx44nLkZvdu0swd25pJk+2sCzzH2bOnBd48UV/6tffyrlzO7hwwfwe37p1a/bt28fGjRtdj9OwYUMuXLjAsmXLXGNVq1YlR44czJo1yzVWqlQpV9/ypEu/+RcsWJAqVaqwYMECYmNjAciePTv169dn9erVHDx4EDCX9LRq1Ypt27axfft21zkzai739vZ2/Tx5ai4HyJEjR4bP5VWqwNSpEezaVZYhQ2JYsya3a8FdWBhERu6lbt2t5MiRcHNz+cMPExcZyYrkfwfLInLQIHyOHGHD/fezv2lTLF9fzeW3OJfnzJnT43N58ptgzeV3bi5PVrRoUcqXL8+sWbM4d+4cYFab1KpVi2XLlnHs2DEAAgMDadasGRs3biQ6OhoAn7g4WnbujOOKCmxCcDCOyEj+qdiEr6JLs6juQdaty01cnB9w+RepggXP0rjxRTp0yMGFC9Px90+49BwL4u1dhdy5F/D664H8/HNJ/vknK2XLetO58y5KltzM+vW5mTChOKtXh/LLb1788lt7ypVtQL/Hf6Tz/t/wXriQrQcOsONS/t8t78vhzszloPflNzuXO51O5s2bd8+/L9dcbt+5PPl3ptTmcrh33pffzlx+5swZ4uPjOX36NOfPnycoKAhvb2+3VcwBAQEEBAS4FSD9/PwICgrizJkzrtfH29ub4KQkEt5+m/iXXoJTp3A4HISEhHDu1Vfh/HkccXGcP3WKbNmykZiY6MpxgKxZswJw9uxZ11hgYCC+vr5uCw39/f0JDAwkNjbWNZ/6+vqSJUsWzp4968rdK1fOnjlzxhV/9uzZOX/+vOt1TJ4DL1686Jp/ANq3b8+XX37JW2+9xbuXCs7Jr0VMTAxxcXGEhIRQp04dfH19+fTTT6lRowYOhwMfHx9GjBjhOv+pS69FsrNnz3Lq1CmKFStG0aJFGTFiBA899BAhISGu18KyLFc8yYs2T5w44fa8HnjgAb788kvefvtt3rlUDE9+LU6dOkVsbCwhISHUqlULX19fRowY4YoRSBEjmLnO6XS6vRbe3t44nU7mzp3ren2vnMvj09ru7brblHnYgQMHLMBasmSJ23i/fv2sGjVqpHqfEiVKWIULF7YSExNdY5988omVL1++VI9v0aKF1bZt2xvGcv78eSs2Ntb1tX///jTt9CYictc5e9ayXn/dsnx9zY6lAQGWNWiQdWTvOWvoUMsKD3ff0LRpU8v67TfLSkjwdODiKdu3W1bfvpaVM+flvPD1tayOHS1r3jzLumJD1puzf79lFShw+aTh4Zb1zTeWdfFiusYvIpfExFjWDz9Y1hNPWNZDD7nfVru2ZVWpYp3v97a14MMl1ovPJ1olSqTc5Dp7dst6+GHLGj3asnbvTp+w1q+3rKeesiwfn8uPU6aMZU18Y7F1/tCJywdOmmR27160KH0eWERE7jnnzp2zNm/ebJ07d87ToWSIsWPHWoC1cuXKax7TpUsXK0uWLKne1qNHDwuwWrVqZX366afWyJEjrV69elkFChSwfv31V9dxb7zxhgVYrVu3tkaOHGk988wzVoECBazcuXNbXbp0cR03d+5cC7Dmzp3rGps2bZrl6+trhYWFWQMGDLBGjx5tvfLKK1aLFi1cx/zyyy8WYD355JPW999/b/3vf//LsBhTc6M8iY2NTVNN0dZF2wsXLlje3t7Wn3/+6Tb+1FNPWffff3+q92nQoIHVtGlTt7EpU6ZYgHXhwgW38T179lheXl7WhAkTbjq2tL7Ad4sVK1Z4OgSR61KO3iE7d1pWkSKu34qdbdpYK37aZT322OUaLlhWjhyW9corlrVtm6cDtg/lqGXFx1vW+PGWVauWexGnbFnL+s9/LOvUqVs46blzljVihGXlzXv5hMWLW9Z331nWFR/gyo0pRyWFpCTLWrnSsgYNMj+4DsflnzNvb8s6edJKTLSs5cst6/3+56369d0Lp8mH1atnTrF06e19pnKjHN2/37L69bOsbNkuP36+fJb1/vuWdeKEZVn161++oUEDy5o27TY+NRJJSfOo2J1y9PapaHv9oq1lWdaYMWOsqlWrWoGBgVZwcLBVoUIF69///rd18OBB1zFJSUnWwIEDrfz581uBgYFWo0aNrI0bN1pFihS5YdHWsixr0aJFVvPmza3g4GArS5YsVsWKFa3PP//cdXtiYqL10ksvWaGhoZbD4bCuXrN6OzGGhYWpaJusRo0a1osvvuj6PikpySpYsKA1dOjQVI9/4403rLCwMCspKck1NmLECCt//vwpju3fv7+VL18+6+ItvHu814q2f//9t6dDELku5egdkphoWffdZyUVCbMm/2uCVa6s0+2X8xo1LGvsWFOcE3fKUXdr11rWv/5lWVmyXM6foCDLevZZy1q9+hZOGBdnWR9/bFm5c18+4R9/pHfYdzXlqKTQuXPKpbIVKlinnn/NmthvvtXx4YtWjhwpDyle3LJeeMGyJky4xQ9jriGtORoba1nDhllWoUKXY8qSxbIGd9lhnX6su/unjPfdZ1m//qoPeSRdaB4Vu1OO3r67vWjraSdPnvR0COkivYq2tt/+pU+fPnz99deMHz+eLVu28PzzzxMXF0e3SzvQPvXUU24blT3//POcOHGCXr16sX37diZPnsz7779Pz5493c7rdDoZO3YsXbp0wcfH1q19RUQ85/x5swv3pZ5YURu8ebPU7+SN2UybMQ+wabODoCB49lmz78vy5dC1K1ynp7sIAJUrw+jRZuOykSOhXDmIjzebmFWtCjVrwrhxZixNgoLg1VchOhrefx/q1zc73iWLjjYlGhFxZ1kQFQVDh5qfmyt6G1KvHmTNSmLbB1n/4hje7bafMhfXk33UB7T7uAE//+7DyZMQEgLt28NXX8GuXbBjh9kD7IEHzG13WrZs0Lcv7N4N334LFStCXBy8M744OX4ZwwutojnyxCtm3li7Fh591Gx2KCIiImIjtq9WduzYkWPHjvHuu+9y+PBhKleuzLRp01ybk+3bt8+tqXDhwoWZPn06r7zyiqsZda9evXjttdfczjtr1iz27dvH008/fUefT2bl5+fn6RBErks5mgGmToWXXoJdu4hacJrnDg/A7J9SFIAyZeD55+HJJyF7dk8GmjkoR1MXEgI9e8ILL8CiRTBqFPz2G6xYYb5eecV8EPDcc1CqVBpOmDUrvPEGvP662WYezIcOdepA/vwwcCC0bXv5NnFRjt5DTp+GWbPM7oBTp8KljWAAmDoV53MvsGYNzDn8FDPu68aC6X5c2msIAC8v88FKixYQGQnVq8OdWANxsznq62v+j+rcGWbOhI8/Nk971N8FGcVwHqz3Jh8X+ZyIKf/B0aHD5TueO2eK2Zc2GxZJK82jYnfKUbE7h96ju3FYlpad3IrTp08TEhJCbGws2bJl83Q4IiLpZ98+Uyn74w8ADjkK8JL1Gb/zCL6+ZjXV889Dgwaqe0nGOHoUvvnGrMS9YhNfmjY1uXf//aYYk2ZLlpjKUvLOutWrw6BBZkxJLPeaBQvMD9OlnYwBCAriXJ0mrM3Xmu9j2/HLkkIcP+5+t6JFzY9MixbQuHHm/bAuKgqGDYOffoJLm3dTs8xpXuiXhU5PeOPnB3zyCXz0EfTubT5R8sRyYRERsaXz588THR1N0aJFCQgI8HQ4YlM3ypO01hRVtL1F91rRdsuWLZQpU8bTYYhck3I0HSQkkPTJp1gDB+FzIZ5EvPmMXgxgADmLBNOjBzzzDFy60EFuknL05iUlwfTpZvXt5MmXuxvkzw/du5uvQoXSeLKYGFOp+fzzyz0X6tSBwYOhSZMMiT+zUY7eZc6ehTlzzEracuXgxRfN+OnTkCsXzqLF2Fu2FdMcrRm9pQHrtrn/QhEcbGq7LVqYr4gIDzyHq6Rnju7bB599BmPGXP48p0AB6NUL+vxZD59li81gtmzmtevVC/LkSZfHlruX5lGxO+Xo7VPRNmOdO3eOwLug1156FW1t39NW7GHnzp2eDkHkupSjt+fAAVhRvy/eb76Oz4V4FlCfKqxlTutP+N/EYHbvhjffVMH2dihHb563N7RuDRMnmjabb75paiaHDpmFsuHh8NBDMGMGOJ03OFnu3PDBB6bJZZ8+EBBgVuA2bQpbt96Jp2N7ytFMzrJg2zYYMcJUWXPlMk1lv/oKvv0Wp9O0b/1wVDY61NxL4N5tFPtrBC9MaMG6bQF4eUGtWvDuu6ZVyfHj8OefZnW7HQq2kL45WqSIWVC7f7+ZGvLnN10iXnsN8mycyw8tv+NiibKmyP3++2bC6dXL3EHkGjSPit0pR8XuLly44OkQbMX2PW1FRCRjOJ1mEdaoUfDXX1A4qQ9zmMQnwQMJfuFJ/urhoGhRT0cpYoSFwXvvQf/+ppA0ahTMnw8TJpiviAjT97ZbN1Oruqa8eU2lpm9fU6k5dgxKl758+9695sFEMhPLgho1YNUqt+HEIkXZWaI1fye1YVg+k+5GAcCkenLLgyZNIEeOOxu2HWTPbgq1r7wCP/5oFuRv2uRL52md6eb9OB81/Jt/xbxP0KaV8J//wJEjpreCiIiISAZT0VZE5B5z/Dh8+00i8R+NJDhmN3/wHwAK1y/K8n/t4JNHffD393CQItfg52c2ee/YETZvNosIx483O9b36wdvvw0dOpjVgbVqXadlbYECpgBzZZeoffugZEmz+nbgQNP7VsRudu0yLQ9WroRx40ySOxwQEYG1fj3HyzVkUbZW/N/B1kzaURL2Xf4h+P/27ju8yer94/i7u5RRZqGUUXYpZY9Syt5D3JOqiIsvQ0Cc6A+K8FVUHKioiAP1KwiKKHuWTdl77yV7FijQ0ia/Pw5NGygIWJqn7ed1Xb2gJ0+Sk3DnkNw5z33nyWOSs61bQ6tWUKGCyjqn8PY2TQ87d4YZM0zTsnnz3Hl5wf28zH28Vmsub9jeo+Drb+B4yg4cMKVXatVy4cxFRMQVVGlUbiaj4kM1be9QTqtpm5iYqE6TYmmK0Zuz22H5crM78cCvSxh2pTvV2QDAh4+spP2AOoSFuXiS2Zxi9O6Jj4dffzXxvWZN6nj16mb3bVSUqc/5j37+GZ59NrU70b33muRtjRp3Y9qWoxi1qIQE0zxs2jTzs2OH4yLbxs1sSApl1ixYM+lvZq3Iz5kreRyXu7mZ7x5S6tLWr3+bTfwsJrNjdPVqs/P2t99SS7BUrw6vvmq+OPLq2dUUxW3b1tRvadQo0+Ym1qR1VKxOMfrvJScns2PHDgICAih009O75E7YbDbc3bN+JdeTJ09y8uRJKlSogIeHx3WXqxHZXZbTkrYHDx6kZMmSrp6GyA0pRtMXH29O9/z6azi49gQf8jpd+BGAy7kLwntD8O35PGSD/xitTjF699ntZvPh11+bs5cvXzbjefPCU0+Z3bf/+OXErl2mYO7o0alZmocegoEDb+HKWZti1IJGjjTn7ac0zwPsnp4cq9CIeb7tePfg02w+6VxsvGRJ55IH2enzpKtidN8++PRT+P578/8qQIkgO9OCnids1Y+4pawVkZEmeduunbYw51BaR8XqFKMZ48iRI5w9e5aAgAD8/Pxw05qfYbLyFwt2u52kpCTOnTvHuXPnyJ8/P4GBgekeq6TtXZbTkraTJ0+mY8eOrp6GyA0pRp1t3uzoPcOFc8m8wLe8x1sU5AwA9mefw+2D901zJskUitHMdfq0KZswYoTTxkQaNjTJ24ce4uZlQLZtM7tsx40z2eC8eU3Hvlvasps1KUZdKDHRdP+aPh0eecTUpwVznn67dlwuVJz1xdsz7lw7vtvfkvOkvvfMnRuaNUvdTVuxYvbNF7o6Rk+fNmtKSmlbgOp5djOi3FDCt47CLTHx6mB1s37cd5/L5iqu4eoYFfknitGMYbfbOXr0KGfPnnX1VLKdixcv4ufn5+pp/CseHh4EBATg7+9/w4T+reYUVdNWRCSbSEyECRPMLsOFC1PHa5S5wMcnosl94Yw5zfurr3CLiHDZPEUyQ8GCZoNinz6pDff++svkxRYvNuPPPgtdu5J+w72QEFNz4e23zS7bihWdE7Z//w0lSmTKY5Fs6u+/TZJ2+nSYPRsuXADAjhubctVj1iyYN70px73XsfJUNThl3vS7uUHtWqlJ2gYNTD1WufsKFjQbafv2NZvxP/oI1m8rR8T6EZTyHMCI0E9ovXcEHuvXm6ZwStqKiGRLbm5uBAYGEhAQwJUrV1w9nWxl3rx5NGvWzNXTuGOenp54eHhk2O5rJW1FRLK4ffvMGbTffw/Hj5uxAu5xNL03H926u9GihT/uv39uLuzWDTy19EvO4eZm+oq1aAGHD8N335nXy6FD8MEH8OGHphxlt27Qvj1cV3IqLAzGj3duWLZggbnBzp2hf38IDs7MhyRZ3dGjpn7Bhg1Ow5fyBbCqSDu+/L4l4z5KGfUFqhMUZK7SqpUJvSJFMnvSkpavLzz3HHTpAlOnmuTtwoXFab/lIwrSj2HlhxNcszsN7Vd3PS9cCGvXwvPPm63RIiKSLXh4eKRbr1TuXFJSEr6+vq6ehmWoPMIdymnlEU6fPk3BggVdPQ2RG8ppMZqcbM6a/fpr05cmZSUPCrQxvO5PdFz8Oh7DP4cnnnDtRMUhp8WolSUlwZQp5vUza1bqeKlS8OKLJhlTrNhNbuDtt+G998zfPT3NFd5+2xQTzcIUo3fBkSNmsb582XwzAGCzYS9eHI4f50CxcKbY2zPqaDvWUAs7pr64nx80bZq6mzYkJPuWPLgdVo7R5ctN8nbChNRy2LVqmaZlj49oitvCBaYkUZ8+0KMH5M/vyunKXWLlGBUBxahYX06JUdW0vcuUtBWxlpwSo8eOwQ8/wDffwP79qeMtW8Kb7dbTbHx33JfGpg7Onu2aicp1ckqMZjW7dpnX0w8/mHqVYPKwDz5ocmxNmtwgWbZ0KURHp77GvL1Nxvett+AGDQesTjGaAZKTTfZu2jRT9mDNGgDsRYuyZfZhZs1xZ9YsuDR3KZsSK3CK1Lrita4peXDTmss5VFaI0d27TdOyH36AS5cA7LxZ8FvecPuA/Kf2mIPy5jWJ2z59oGjRm9yaZDVZIUYlZ1OMitXllBi91Zyi2oXLLVmyZImrpyByU9k5Ru12czb244+bjXxvvWUStgUKmLp6O1efY3bYy7R4vbZJ2ObODUOHmqSBWEZ2jtGsrHx583I5dMg07ouIMDtxf/vNNHcKDYXPPoPr+kxERJhtugsWmMxuYiIMH27OX8+i34crRv+lt9+GgACIjIR333UkbPcWqsOn8V2pW+0yffuajbcLEiPwDixM584wZoz5Qm71ahgyxMSdErbpywoxWq6cWQoOHIBBg6BIETfeP/0ihU9t5wW/0RwtEgbnz8P775vSKkOHunrKkoGyQoxKzqYYFatTjDpT0lZExKLi4swHv7Awc5rsuHFw5QqEh8OPP5ok08ctplH+nhAYNszs8Hr4YdP1/tVXwcvLxY9AJOvw9YWnnoLYWFi3zjQoy53bvJz69IHixU05ytWrr7li48Ywbx7ExJjtka++mro198oVOHUqkx+J3HU2G6xcaTJyZislAEkJSXD6NJd88jOzwGM8zU8U5ShlT63klQvvQC4/2raFTz6BjRvNGv7jj6aKTUCA6x6O3B2FC5uS1/v3w4gRULaCJ99d7ETxE+t50HMSu4uEm7IZWXRnvoiIiNx96kYjImIxa9eaWpujR8PFi2bMzw+ioszp2jVrpjnYz8/UTKxQAb74wnSqEZF/pXp1k2T58EP45Rfzety0yTT7+/57qFvXvBYfe8y8BHFzg+bNzRbJtLtsR42CV14xWd++fc32eMmaTp82O6unTTNbZU+cAOBA0br8ebkds2bBgbkv4E9HliXUJznBvMWuUQOeuVryIDLSfDkgOUuuXOZLoBdegEmTYOhQd/6M7cifJ+6hMQvJ/2skfUua73/cvv7KfAHUrx/UqePqqYuIiIiLqabtHcppNW0PHjxIySzeYEWyt6weo5cumdOxv/7alENMERpqkkNPPQX+/kB8PKxaZU7HTvHnn6btvc6ntbSsHqM5md0OS5aY1+f48aYSApg+Qs88A//5D1SqlM4V77vPZGnAvID79jUJXIu+b1CMpmP5cpN4X7o0tbsUcMkrL3M9W/Pupb4spYFjvFix1Lq0LVuqXGlGyy4xGhtrmpb99Vfq9zzhdZKJ2V+O3CeuFqxv3drUQ2rcWF3ospDsEqOSfSlGxepySoyqEdldltOStomJiXh7e7t6GiI3lFVjdOdOs6Nv1Cg4c8aMeXnBQw+ZZG2jRlc/q9nt5tNdnz5w8iRs3Wpa3UuWkVVjVJwdP25er998A3v3po43b25es/fdl6Yyic1mXrfR0WarLkDBgqaEwksvQZ48mT39m8rxMRoXZxrLBQaabbFA4voteNeoAsCuXGFMuNSeabRjCZEk4YWvr8mppSRqw8KUX7ubsluM7thhmpb9+KOplBDKZgbn+YD7L47B3ZZsDoqIMMnbDh0UXFlAdotRyX4Uo2J1OSVG1YhMMtTMmTNdPQWRm8pKMXrlCkyYYPoVVaxo6hueOQOlS8N778HBg/Drr2k21+zebT6sPfig6WxSpAgcPuzqhyG3KSvFqNxYQAC88Qbs2mXOlO/YEdzdYe5ceOQR8zoeMMC8jnF3N6/b9etNUeqQEHOa/VtvQZcurn4o18lxMWq3m+KyH3xgCocXLgyPPMK5977giy/Mv23BBpXpzI+U5AAVLm3kDT7gTLWm9HnVi1mzzD/nzJlmM27Vqsqp3W3ZLUYrVjQ7+PfvN+vGsUJVeOjCz5Sz7eQHn25c8fAxu7w7doSXX3b1dOUWZLcYlexHMSpWpxh1pqStiEgm+ftvs+EuONjspJ0zx3zA79ABpkwxudl+/dKcTnvpEgwcCFWqwPTp4O0N//d/sGUL1K/vwkciIu7u0K6dqX6wdy+8/bZ57R45AoMHm9f5ffeZ8qc23OHRR81u2//9D8qXN1m+FOfOmW12kjlsNlPTolQpqFYN3nwTFiyApCR2eYbw8bTK9Opl1uX4i27MCOhM0ydL8vPP5vuy9eth6FDzxVuuXK5+MJIdBATAO++Y72W//BI8ypXhuYSvKJW8l489XuOyVx72R3ZKvcLZs5CQ4LL5ioiISOZQ0lZE5C6y2czZtg88YJI4gwaZD/0BASZBu2ePSQx06AAeHmmueOUK1K5tPsUlJJjswMaNJhvk5+eqhyMi6ShVCv77X5NwGTfObNq02UxCt1070ydw6FA4ecYDnnwStm1z/uJl4ECTyP36ayViMprdbsrJjB3rGLqS7M75BWvg77+57J6LKXSgO19Shj1USNrKBz7RtGxpGtGtW2cS8f/7n6ktHhjouoci2Z+fH3TvDtu3m/rZpcMDeTX5Q4pcOUyZx+px//2mvjb9+0O5cjBsmKl1LyIiItmSatreoZxW03br1q1UrlzZ1dMQuSGrxeipU6ZG3YgR5jTqFI0bm7qXDz5oNs7e1Ftvwc8/m4J3Dz+s826zOKvFqNxdW7ea1/9PP5lSqWB6BT7yiFkDIiKuvqSTksxu+h07zEGlSpmETOfOaYrjZtacs0mMxsfDvHmmfsW0abB/P3ZPT74dcoqpi/Ixdy40vDAdO24soAmXyUVYWGpd2kaN9N2YVWWbGL1FdjssXmyalqX0NPQgib2+lSl5+eqbi0KFoHdv6NkTChRw3WQFyHkxKlmPYlSsLqfEqBqR3WU5LWkrIv/MbjeNxr/+2uy2S9kwly8fPP20ORu3SpUbXDkx0RS3bdkS6tQxYxcvQnIy5M2bKfMXkYwXH282eX79NaxenTperZpJ3kZFQV7vBPjuO3j3XbOtE6BMGVPk8sknwdPTNZPPaiZPhuHDTamDNDuWE/BmPk3pzlfsoRxgSoO3amWStC1bQlCQqyYtcmu2bYOPPzbf5ZKYwFP8j/5e71P6ym5zQJ48Zpvuyy9DsWIunauIiIjcXLZqRPbll18SHByMr68v4eHhrFix4qbHnz17lh49ehAYGIiPjw8VK1Zk2rRpTsccOnSIJ598kkKFCpErVy6qVq3KqlWr7ubDyNJUDFqszpUxeuECjBwJtWqZ3XM//2zyBTVrmvFDh+CLL26SsI2JMRmcfv3MB67kqx2j/fyUsM1GtI7mTLlzw3PPwapVsGKF6T/m6wsbNpikbfHi0P1lHzY27mEKW3/6qamfsnevOfi//820uWapGL10yRQMPnYMMBVlds8/CLNmQUIC+yjNV3TjHiZTkNPc6z2T4ObleP99WLMGjh6F0aPNhmYlbLOOLBWjGSwkBL791jQte+1tHyYUeJ5yV7bxOL+yyaOaeTPy4YemZIK4TE6OUckaFKNidYpRZ5ZP2o4bN46+ffsSHR3NmjVrqF69Om3atOH48ePpHp+YmEirVq3Yt28f48ePZ/v27Xz77bcEpXlHfubMGSIjI/Hy8mL69Ols2bKFjz/+mAI6peiGEhMTXT0FkZtyRYxu3mzORixeHLp2NbUPfX1NEmDZMrOr7oUXzOaXdB0+DI8/brZ5bd9uEjUvvWQ6HEm2o3VU6taFH34wL/1PPzWd4y9cMLtwq1WDhq1yMbpIHxK27jHJl5IlzeKS4vRpUyz3LrF8jO7da7o0dehgTglv144Fff7kgQegcGFo+klHXuEjKrOFMuzly9CvqNDnHsZPy83p0+b7sTfeMF+oaZnNmiwfo5mgWLHUGtqffObJ8uDHqZq8jg5MYb57M9482ie1LNPGjebNimQaxahYnWJUrE4x6szy59t98sknvPDCC3Tp0gWAESNGMHXqVH744QfefPPN647/4YcfOH36NLGxsXhdrQUXHBzsdMwHH3xAyZIlGTVqlGOsTJkyN51HQkICCWlOtTt37tydPiQRycISEmDCBJNkWbQodbxCBVP+4JlnoGDBf7iRK1fM1tvoaJOxcXeHHj1Ml7L8+e/i7EXECgoUgD59TBnKefPMevLnn6bB0JIl0Kdwbp599jW6znmZsoFp3qo99RT8/bdpUHjffTmjzvWxYyaBPW2aOT88jb8JYtxYG39d/d2rUEkOt3qF11ub0gclSmT6bEUyTZ480KuXOUHnjz/cGDq0A81Wd4Cf4MOfTQPU7/9+hfwrZsP995uzeerVc/W0RURE5DZYuqZtYmIifn5+jB8/nvvvv98x3rlzZ86ePcvEiROvu0779u0pWLAgfn5+TJw4kSJFitCpUyfeeOMNPK62Zg8NDaVNmzb8/fffLFiwgKCgILp3784LL7xww7kMHDiQd95557rxsWPH4ne1W0WrVq04deoUa9ascVweERGBp6cni9Jkd6pVq0ZQUBDTp093jJUtW5YqVaowe/ZsLl++DEBAQADh4eEsXbqUkydPAuDn50eLFi3YuHEj+/btc1y/Q4cO7Nu3j81pvk1v0qQJly9fZvny5Y6xOnXq4O/vT0xMjGMsJCSEChUqMHXqVGxXd/CULFmSGjVqMH/+fM6fP4/NZqNQoUI0bNiQVatWceRqzT0vLy/atm3Ltm3b2Llzp+M2W7duzYkTJ1i7dq1jrEGDBri7u7N48WKn56J48eLMmDHDMVauXDlCQ0OZNWuWI1FetGhR6tWrR2xsLKdOnQIgd+7cNG/enPXr13PgwAHH9Tt27Mju3bvZsmWLY6xZs2bEx8c7ldaoW7cuefPmZe7cuY6xypUrU758eaZMmULKS6NUqVJUr17d8VwAFCxYkMjISFauXMnRo0cB8Pb2pk2bNmzdupVdaTpPtWnThmPHjrFu3TrHWGRkJABLlixxjNWoUYOiRYs6nQ5Qvnx5KleuzMyZMx3fOBUrVoy6deuyZMkSTp8+DUDevHlp2rSp03Ph5ubGPffcw65du9i6davjNps3b8758+dZuXKlY6xevXrkzp2befPmOcZCQ0MpV64ckydPdoylPBdz584l/mq34kKFCtGgQQNWrFjBsaunqfr4+NC6dWu2bNnC7t27Hddv27Ythw8fZsOGDY6xhg0bYrPZiI2NdYzVrFmTIkWKMGvWLMdYhQoVCAkJYcaMGVy5cgWAwMBA6tSpw+LFizl16hTu7u6O52LdunUcPHgQAHd3dzp06MDOnTvZluZDf4sWLYiLi3MqjRIeHo6vry8LFixwjFWpUgW7PZg33tjNnDmliIvzAcDDAyIijtO69W6qVTtJQEBhIiIiWL58ueNsAF9fX1q1asXmzZvZs2cPAEELFlDr448BOFOxIhu6deNcuXI0atSIpKQkli5d6rjvWrVqUahQIWbPnu0Yq1ixIpUqVWL69OkkJSUBULx4cWrXrs2iRYs4e/YsAP7+/jRu3Jg1a9Zw6NChq3P2oH379uzYsYPt27c7brNly5acOXOG1WmKbtavXx8fHx+n5yIsLIxSpUo5lZwpU6YMYWFhzJkzh0uXLgFQpEgR6tevz7Jlyzhx4gQAuXLlomXLlmzatIm9e/c6rt++fXsOHDjApk2bHGNNmjQhISGBZcuWOcZq165NgQIFmDNnjmOsUqVKjhI4yVfLSgQFBVGrVi0WLlxI3NUOUPnz56dRo0asXr2aw4cPA+Dp6Um7du3Yvn07O1KaQHH31vK0seuqtRygQIECWsstuJafOuXDwoUVmD27DH//7bgqtWodZ8CAAEILLiW4bUu8Ll4EILlGDc698gqL8+VzJG//7Vru5eWF3W536Vp+accOfM6dw1ajBg0bNuW3kat4rGd9POzJJOHBEiKZRnum0Z5tHqFUDj3DQw/lo379OC5fXubYQXujtTw4OJipU6c6xoKDg6latSoxMTFcvPrcFi58a2s5QLt27Th06JDTc6G1/O6t5SmP25VruRXel8P1a7ndDtu2FWXBgnpMmwbeJDCGTjzEBMdtn6henZ0PP8ypatVoEBmptfyqjFzLbTYb/v7+Of59+ZkzZwDu2vtyreXGnazlx44dw93dPce/L7fqWg56X552jc3OOZaLFy/y+OOPZ+1GZIcPHyYoKIjY2FgiIiIc46+//joLFixweqGkCAkJYd++fURFRdG9e3d27dpF9+7d6dWrF9HR0YBZrAH69u3LI488wsqVK+nduzcjRoygc+fO6c4lvZ22JUuWVCMykWwsORmmTze74KZPN43GwNQ/fOEFeP7526iFaLOlno9rs0HHjmYbzLPP6jxdEXFISoKpU826k7akV8mS0OvJ0/zn4ifk+f4zs0sfzM65QYNMR62suPP2yhWIjTU7aadNg02bOFamPt1rLiUmBuLi4E2GsJMKzKElgSH5ad3aPNwmTW5SfkYkB9u82TQt++UXKHdlK2/wAU/yC55crZkfHg7vvQfNm7t2oiIiIjnUrTYiy3ZJ24oVK3L58mX27t3r2Fn7ySefMHToUMc3F97e3tSpU8fpG8RevXqxcuVKp2/SbuZWn+DsYsmSJY5vLkSsKCNj9Ngx+P5700Rs//7U8VatTOOgjh1vo5l7cjJ88425sSVLTFciyZG0jsrt2r3bLB8//ABXN0Dg6QlPtz/JAL+hlJr4BW5Xd9Ewbhw8+ui/ur9MjdGxY2H8eOyzZ+OWpuRUMu4sIZIWxJCEFwUKmLW39dWSB6VKZc70xJq0jt6ew4fh889hxAjIH7ePV/mI5/kOXxK48Nn35On1rKunmO0oRsXqFKNidTklRm81p5hh27uSk5MZO3YsXbt25YEHHmDjxo0AxMXFMWHCBMfpGbejcOHCeHh4XHfdY8eOUaxYsXSvExgYSMWKFR0JWzDbsY8ePerY+hwYGEhoaKjT9SpXruy0/VucpWwRF7GqfxujdjssWGD6gpUsCW+/bRK2BQvCK6/Ajh2mKfkDD9xGwnbFCrObpUcPWL/etH2WHEvrqNyucuVMOde//4b//Q8aNDA7cX+YVJjgsR/QKGgva5q8THKFSqbGbYqrp6XerrsWo0lJpjuj3U5yMixfDlv++wf88Qdu585xnCL8zFM8zq8Eepygf+OFDPyvFytWwIkTJh/93HNK2IrW0dtVvDi8/z4cPAi9Pwnmw5LDCWYfA3iHEm8+yUsvmf5+/Pab+XI5zVmFcmcUo2I5AwfC4MGOX51idPBgc7mIhWgddZYhSduzZ88SGRlJp06d+PXXX5k0aZKj7lWePHno1asXn3322W3frre3N7Vr13aqDWKz2YiJiXHaeZtWZGQku3btctQNAdixYweBgYF4e3s7jklbMyblmNKlS9/2HEUka4uLMz3BwsKgaVOTHLhyBerXh59+MsmSjz4yjcZu2enTpuN7/fqwejX4+5s7eemlu/UwRCQb8/WFJ580m/XXrTNND/PkgSW7ilJ7wScUOLiR57r7sGoVJkFavz60aWMSpa5y7JhZRB9/nORCRSAigt7tdlC4sJnea5ufIZqB1GUFjSscZWXPn4ma9Di7zxRkwQLzxVnduqZ2uIj8O3nzwssvm937n4wuxuQaA4i75M3w4VCpXBLHnn3TvG8pU8bUVUgpvyIiWZ+HBwwY4JS4BczvAwboP1oRi8uQpO2bb77J5s2bmTlzJnv27CFtxQUPDw8efvhhp+LYt6Nv3758++23/PTTT2zdupVu3boRHx9Ply5dAHj66afp16+f4/hu3bpx+vRpevfuzY4dO5g6dSrvvfcePXr0cBzz8ssvs2zZMt577z127drFmDFjGDlypNMx4ixv3ryunoLITd1ujK5ZY+rSFi9uui9v2WIqF7z4IqxdC0uXwtNPQ65ct3Gjdrs5j7lSJbNjxW433d63b4eePfWmKIfTOioZoXp1U+/20CH46iuoWhXOX/bihx9MkvO5qiuw7d5jTg2IiIAOHcyXR7fgX8forl0QHU1yrbpQrBg88wyMG4fHubOcoiA7Z+7m7FnInx/8Hu5AiZHR/L63Ltt2uPPFF6b0jF4mcjNaR/8dLy/o1Mm8B5o923y3g93Gu/F9OEgJOHIEXn0Ve+nSZvddSl0WuWWKUbGc/v1N7furidu8efOmJmwHDTKXi1iI1tFr2DNA0aJF7f369bPb7Xb7yZMn7W5ubvaYmBjH5V9++aXd39//jm//iy++sJcqVcru7e1tr1evnn3ZsmWOy5o0aWLv3Lmz0/GxsbH28PBwu4+Pj71s2bL2d999156UlOR0zOTJk+1hYWF2Hx8fe0hIiH3kyJG3Nae4uDg7YI+Li7vjxyUimSs+3m7/4Qe7vW5du91kVM1PlSp2+/DhdvvZsxlwJw8+mHqjCxZkwA2KiNyYzWa3L15st3fqZLd7e5vlJ5g99v95dbEnuXmkLnT33We3r1uXsXd+4oTdfvSoPSnJbl+xwm4f++Rkp8V1FbXsg/g/e6R7rL1xZJJ90CC7fdkyu/2at2Qi4kLr19vtTz1lt+fySLB34Xv7dio4XsO23LnNGycRyVoSEsx/zJ9/brdHRdnt58/b7YMGmde2l5f58513XD1LkRztVnOKGdKILFeuXHz++ee88MILnDp1iiJFijBnzhyaX+1I+tlnn/H2229zIRudapPTGpGtX7+e6tWru3oaIjd0sxjdvt004fjxRzh71ox5ecHDD5vGYg0b/oum63Fxpp5C4cLm94MH4fffTSkEL687vFHJjrSOyt124gSMGmXWu717oTw7GcAgohiNO1ff7q1fD9WqpXv9f4xRm81s0Zs2jYS/puO9bjl/VXqT54+/x+nT4Ec83/McM2nD9uC21GwfSOvWpvSMv3/GP17JebSO3j1//w2ffQbfjkim9YU/eIv3qMF6fu66mI5DIilQAJPKveM3TDmDYlRc4uhRWLjQlEVatsz8X522RvX8+dCkCfj4wNU+PzRqZM4QLF/eJVMWuZGcso5maiOycuXKsWbNmhtePmvWrOsaf0nWoiZtYnXXxuiVK/DHH9CyJYSEwLBhJmEbHAxDhpgPJ2PGmPcrd/T5w26H0aPNjffpkzpesiT07auErVxH66jcbUWKwOuvmyoF06dD6L0VeMb9f1RhM2N5jMXezej/W1UOHrx6hTffdKpx5xSjKc1JrlyBceO4EvUMCYUCTQ2G6Gh81i7DzW4ncdtuTp82Sdm2D+YmbsRY+u/uQuzeQL780vRHU8JWMorW0bunRAkYOhT2/+1BvaGPck/xtUSymM7fRFKypKmJG9ftDYiKgqsNp+V6ilG56y5cgHnzTO34FL//Do89Bp9+amq8JSSYbsrt28M775gX+ODBkJiIzf1qCmjRIvMl7rBh5ktZEYvQOursVnug39Tzzz/PG2+8QdOmTWnRogUAbm5uJCQkMGjQIGbMmMHIkSMz4q5ERJxMmGDei2zd2p7KlU3p2L//hm+/NaXZwCRlO3Qwu2rbtMmA0rJbtkCPHuZba4BVq+D8eRVjFBFLcHeHtm3Nz4ED8O23lXn5u7GcOprIlXfdeG8IPNH6FD/O/QzPxMvsXHGahw98atbREDu/l3mdipM+4tB/BvHzhx78552XKHDFNJg9Tx5m04qZbu04VqsdNTuWILa1yeV6Zsi7ShFxJX9/ePVV6NXLjbFjIzn/kcnRfj/sHIP5Cog333rfey/062c6C4rI3WGzwbZtqTtoly+HTZvM+Pffw7PPmuMaNIDatc3rsX59CA83O2hTdqakqWE7tUYNOs6bZxK8ly6Zb2T++MPsur2tzssikhky5O1179692bx5M0888QT58+cHoFOnTpw6dYqkpCS6du3Kc889lxF3JS7iplOhxIImTICHHjLvR+x2DzZsMI3EUgQEwPPPm7HSpTPgDi9cMG96PvnEdGjPlQv+7//glVfM6UYiN6F1VFyhVKnUz2p//eXN11+bDToeM6bgyWUAKkwZxg8sZC01eXTjb+TbeJ7BXu8wYIRpTpJEV3JxibXF2lOgY0NatPPmg2amoZhIZtI6mnm8vU1D1qeeMn0NP/ooH43nLKQfQ3iIP3CfNAkmTcLevDlu/fpBixYqnYBiVP4lm8188womQdu6NZw7d/1xpUqZzyIpatc2m0jSc03TMbcpU8xnmfz5ITravNgXLza7bjduVLkEcTmto84ypKZtisWLFzN+/Hh27tyJzWajXLlyPProozRu3Dij7sIyclpNWxErCgkx9WqvlTu3+fL5gQfM+5AMsXat2VXy99/m93vvNcXfgoMz6A5ERDLHtm2m7u3671byevwA2jHD6fJEvKjEdk7lLUOLFuYzY+vWUK6ciyYsIpawdi189BGsHbudV20f8BT/wwuTOEoaMhTPN1918QxFspDERFi3LnUH7bJl8MQT8N//mstPnjR1j/z8zOksKTtow8OhePFbv5+BA8HDgwlV+vPOO7BjB1SsaPK1D24eDKdOwebNJon7++934YGKSHpuNaeYoUnbnCSnJW137dpFeX3rJhZw9CiMG2fKya5cmf4xvr7mbJ8Mde6cyRL7+MAXX8A992TwHUh2p3VUrObiRXMqdN2kWBbRCA9sJOJFPs5h9/blwgWV5xZr0TpqDfv3m++tp39zgG4XP+Ip/kerYpt4rG8QL74I/pePmXqaOXABUYzKTV28CG+/bRK0a9c6NwsDs2N9zpzU3zdvhkqV/nX9oT/+MA2YzdmJqX/+8Qc8+CDml4sXzc4XMJ1Nf/3VlIP713XlRG5PTllHM7URmWR/W7dudfUUJAc7fx5+/tnUow0KMn2/bpSwdXMz723+tUuXTGHclO+18uUznX22bFHCVu6I1lGxGj8/CA2FlsTggY0EvPHmCq8zlMqVc2S+RSxO66g1lC5tzq6O/bsUF4d8Tp1ih1h9NIjXXzf9WLdGPEtSuYrw9ddw+bKrp5upFKMCmA8v8+aZ7scff5w67usLP/5okrYJCVCokGm8MWiQqUMyfrzz7VSpctsJ29OnYcEC+PJL08+jYUN49FFzWcrHmpQ/+/QxX8Lg5paasAXTJKR3b3Plbdtu6/5F/i2to84ypKZtmTJl/rHuhJubG7t3786IuxORHCAxEWbONDtqJ01y3jkbHm6aF+fJY+rvX/utcXT0v7zzKVOgVy/Yu9e8uXrqKTNevfq/vGEREWv5NXQwoRsGMIBBDKY//RnMIAbweGWA/q6enohYWIEC8Oab8PLLfowZY0onHN5yhoLnV+HJcejenSv938Hr9b7wn/+YL8BFsqMtW2Dp0tRSB5s3m/q0YEqpvfKK+bu7uyl/kD+/+UBTrtwd14KOj4etW00Z2k2bzM/GjamNmG/FwYNmeuXLm02+LVtCs6Z2CrVqZTarLFsGNWqYOb/8snbdirhAhiRtmzRpcl3SNjk5mf3797NkyRLCwsKoWbNmRtyViGRjNhvExppE7W+/mW+KU1SsaBK1nTo518f39zdfTm/ZkkxoqAfR0aaW7R3Zv998qzxxovm9RAnziUREJDsaPJjQsQPY8vggJm3tj9eWZCaF9ufxyhA6dgCEAv2VuBWRm/PxgS5doHNnmDGjAJ3f30v5RT/wOh9S6tRBeOMNrgwegmefl3Dr3QsKF3b1lEXu3IkTJluatm/PU0/BmjXOx5UsaerQ1q/v3GCsR4/bursrV0wd2pTEbEpyds+e1B2z1woOhqpVISzM/LzzDuzcef3xfn5mw++uXebnm2/MZruaNZ/n4ajWvLDqRQqvmgmvvWZqKYwaZcrFiUimues1bdevX0+bNm345ZdfaNmy5d28q0yV02raxsfHkzvtKRMiGWjzZpOoHTPm6ik6VxUrBo8/bpK1tWvf/IvofxWjCQnm1KX//tds6fX0NN8mDxhgtvOKZACto2I5V5uTpCRmnWJ08GBITjbHiFiE1tGsY9Uq+PSDRHz+GMPr9vcJwXSOXdHla2p+859sW35FMZrNpNcsbM8eUz/o3DlzRh6YpObKlXfeLAyT192/3zkxu2mTqU5w5Ur61wkIcE7OVq1qyh7lzet83IQJ8NBD15+dOGGC2WG7cKEppTtnjvlclsrOi56j+Nj+MnmSz2Hz9sE+4S88OrS9rccmcjtyyjpqqUZk0dHRTJkyhdWrV9/tu8o0OS1pe/ToUYoVK+bqaUg28vffpr796NGwfn3qeN68piB+VBQ0b37rZ+H8qxh9+GHz7TFAkyamCFSVKnd2WyI3oHVUrE4xKlanGM169u6FYR8nc+Lbv3gy8XseZAIBJX3p0wf+E7YYv7LFnE+hyuIUo1lYSlokZZfI22+bTR3XNgsDqFwZJk825Q3uwPHjqUnZlD83b4YLF9I/Pk+e1KRsyp9Vqpik7a2aMMGcnbhtm52QELcbnp145AjMnZuaxP37bwjib77lBcLYRGS+TdRu7k/LlibhW6nSHVd4EElXTllHLZW0/eqrr3jllVe4lOHt3F0npyVtJ0+eTMeOHV09Dcnizp419fVHjzYF8lNWHy8vaNfOJGo7doRcuW7/tv9VjC5ZAo88AkOHmvoLeuchd4HWUbE6xahYnWI06zp92vQl+/xzk7ByJ5lt7qGUs+/i8r2P4jeoH1Sr5upp/muK0Szk/HmzJXzZstSfJUtSv0T46COzg7ZQodQdtPXrQ926pibtLTh3ziRj0yZnN20yFRbS4+1t8sFpd86GhUGpUhn38eR2YtRuN2UV5syBmDl2tsYcZuu5oJRLeZyxxBZ/hKYtPR1J3NvcYCxynZyyjt5qTjFDatrezKlTp/j+++8pUaLE3b4ryUjXnDLpRKdMym24fBmmTjWJ2qlTzVlGKRo1MonaRx6BggUzaUJXrsAXX5i/9+1r/oyMNKc6pZziJCIiIiIZpmBBs3HxlVfgl1/gu/fPsH13BSqwA7+JY2HiWM41uYd8Q96CiAhXT1eyq5UrYeTI65uFpVi2LDVp+9RTcP/9t9QsLCHBlDG4NjmbtuxbWm5u5m6uTc6WL4+lSoe4uZm+IhUrQvfubiQnB7FmDcTEgNdP3/PKthdYcfhTuvw8ip9/NmcpVq5sGpq1bGlOYPT3d/GDEMniMiRp27x583THz549y7Zt20hMTOR///tfRtyVZBYPD1PPE5wTt4MHm/FBg1wzL8kSkpPNTtrRo03Vgbi41MvCwkyi9oknoHTpTJ7YwoWm+P+mTSZB+8gjpkkAKGErIiIicpf5+sLzz8OzzxZmypQpPDtwHa3Xvs8j/E6+BVOgwRTOVG9C/m8+xC28nqunK1nV8eOpNWjvv9/sjgVzrv9336UeV7p06g7a8HBI2zy9aFHzk0ZystnncW1ydscOc1l6goKuT85WrmyagGU1Hh7mqaxbFyidG3s3f+rFrWS9Ry2+KTaQPodeY+tWT7ZuNXtkUo5P2YUbEWEaF4rIrcuQ8ghNmzbF7Zpvn9zc3ChQoADlypXj2WefJSSbdRnMEeUR0iRoj734IkVHjkxN2KqbtFzDbjd1+kePNrVqDx9OvaxECVN1ICrq7p35duzYMYpe88YqzYXm9KaUL48KFYIPPjCtjlM6uYrcZTeNURELUIyK1SlGs6fly+F/A3ZSY9aHPM1PeHOFrhXn0uydZjz8sOkPm1UoRl0gMRHWrk1N0i5bZoopp3jnndTNSMeOwbBhqc3CAgPTvUm73XyWuTY5u2WL6Vmcnvz5r28KVqVKJp5NeIsyNEYPHYKuXc3plEBS9drMf+ZHJuwIIybGJLPTypULGjc2CdyWLaF6dX0Uk+vllHXUUjVts6MckbQFR+LW7u6Om80GNWqYr8t8fFJ/0n57eegQzJjhfHnKj7c3lC0LKUWlExPhzBnnY7RqZzl798KYMSZZu3Vr6nj+/GYja1SUKYNwt/9pL1y4QJ48eZwHk5NhxAhzPl5cnDnH58UX4d13TeJWJBOlG6MiFqIYFatTjGZvu3fDD4P+JnnMOD5I6gu4Ubo0/Fj7C+q3zofvs52sde54OhSjd5ndDvv2mff4KWUMNmww2b+03NzMdtb69c0HkrZtb3iTZ85cn5zdtMmMp8fX1yRjr909W7x41miLkeExarebjTG9e5sGJl5e8NVX8PzzHDhgSinExJi6uMeOOV+1UCHTeDqlnELZshk3Lcm6cso6qqTtXZZjkrZgFt6kpBtf/u235jwngJkzb/qfIp9+Cn36mL8vWQINGzpf7umZmsDt3z/12B074MknU5O/1yaE778/tf3lqVPw5ZfpJ459fEyLy6pVzbGJieZ/5Rsd6+OTNf73zWQnT8Jvv5lEbWxs6riPj2kkFhVlGotl5ukv6RYs37vXvGFLSIBatUwHjHo61U5cI6cU1ZesSzEqVqcYzRlOnjQ5ny++gKSTZ9hPafJxnjP5SuHx5uvk6/PsnXWtzQSK0Qx27pypQ5uyi3b5clP64Omn4aefzDHJyVChgsmkpm0Wdk0x1YsXzQaTtMnZjRudzw5My8PD1HK9Njlbtqy5LKu6azF6+HDqrtslS66rTW23mzLCKQnc+fPhwgXnmwgOTk3gNm8ORYpk/DTF+nLKOnpXG5H9/PPPdzSpp59++o6uJy40eDAkJWFzd8fdZoPWrc22yYSE1J+wsNTjCxWCDh2cL0/7k/b8kCtXrr+/pCTzEx/vfPnZs+Y/7BspUyY1aXv0KERH3/jYV14x3UABjhyB2rVvfGzXrmanJpivW8PCrt89nPL3tm3h1VfNsYmJ8NJLN04Eh4RAmzap9zNlSvrJaB8fyJfP+X8su90lieSLF2HiRJOonTkzNY/v5mb+U42KggcfzMRi8zdqlnfpkvn3TWmW9+675o19165Z+x2WiIiISA5QuLA5m/2112D0SG9GDP4/nj71CcXOHYC3enJu0CAud3uZgOhu6nKUXV25AnXqmKzqtXvMPD1Np+MUHh6m0OxVSUmwcydsnOmcnN29+/qbSlG69PXJ2UqV1PLithQvDpMmmVIVtWqlji9bBrVr4+bl5XiOe/c2/8QrV5oE7pw55rB9+0zJ4ZSyw9Wrp9bDbdwYcud2ySMTcak7Sto+88wzt30dNzc3JW2zmjQ1bafWqEHHdevM7w0bmsvSU6eOSUDeiqZNTcfOxMTrk7uJieYdW4oKFWDy5Bsngxs0SD3W39+cAp9yO9cem3IqDZj7L17c+fK0yeK0W0UvXbrxV7Hg3FXr8mXTmfRGHnssNWmbnGy2p95Ihw7Oz6mfn7lOegneyEjn4vpRUWYu6SWZy5aFbt1Sjx092jxfaW4v2dOHVRt9mLggP5/Pr0Z8vDk0gGOEVXXngcd9ePAJH4oHe2d+IvnaZnk2m3nsvXubDHNKs7xXXsnceYmIiIjIv5YrFzzfOzfJPV9nyu8vsfOtUTy890OCL+8n36f9uPDF++wb/AtV3rhHJ8ZlRWmbhS1fbj6nTJtmLvPyMp937HbnZmH165tmYb6+2O1w4MD1O2e3bTMfadJTuHBqUjblzypVzB4ZyQBubs4J223bzGf+0FD48Uen5iZeXuYjfIMG5iPdhQuwaJFJ4MbEwPr1qT8ff2yOj4hIrYdbt67lq6WIZIg7Ko+wf//+O7qz0pneKv7uyfblEdIkbOnfn927d1OuXLnrxrOltIlkDw9IqaeSmGjO6UgvaZyYaHb7ppwGkrLb80ZJ5ogI6NXLHJuQkLp7Ob0kc4cOMHasOdZuN3O60cu2dWuzDTZFvnxw/nz6xzZoYE5dSVG8uNl5nI51VKcm6yhb1jQU6/9zBbwP7HI+KCUhHBICK1akjj/xhClTkN4O5aJFTcmMFN99Z3ZKp5eQzpPHObm9fTt8/rk5f+6557i8ejW+69aZy6pWNfWtRCzEsY6KWJRiVKxOMSpLF15hxcu/0nrNEMqzi/Lsoli90rz6Kjz4gB0PT9dmbxWj/2DUKJg9+/pmYWC2tZ47l5qJW7vW9EIJDOTEieuTs5s33/hjTu7c1++cDQszHz1yukyN0ZkzzYfH06fNv+v//R/063dL2dbjx2HuXJPAnT0brk1B5c0LTZqkllMIDVVVw+wip6yjqml7l2X7pO2NTj0Hk7hNOfVcMpfdDidO3DgZnC+f87ebP/1kdp2md2zp0qaEw1Xn7n+ao5tPcvJQArZLCXiTiA8J+HkkcLFUZS6O/pP69a/+Z1iunNNpSE5CQ827qLS/p+1QllapUs7/A9erd+MyGIUKmSJnKZo1M8WQrtW2rTk1R1+9ioiIiGRL27fa+OP/1jBoah0SEszYlNyPUaZaHoK/egO/GhVdO8GcLKVZ2LJlJrv67rup2bT77jPv08G5WdjVnbTnS4exeau7U3J20yaTwEuPl5fZL3JtcrZ0afW3toyjR83ZnX/9ZX6vUcPsur22edxN2O3mo2dKPdyYGJMHTqtYsdRduC1aQMmSGfUARO6ObJW0/fLLLxk6dChHjx6levXqfPHFF9S7STOhs2fP8vbbbzNhwgROnz5N6dKlGTZsGO3btwdg4MCBvPPOO07XqVSpEtu2bbvlOWX7pO01ckox6Jzm6FGziXf0aFi1KnXcz8/0douKglatbpD/tNnSTwa7uTmXoFi40NQkTu9YPz9TazbF+++b/5HTOzZPHlNUN8VDD5kuaAkJqe1dvb1xvHMXsRito2J1ilGxOsWoXOv4cRg+HKZ8voc1cWZnlg03Noc+QtAX/SjYvEamzidHxuj582bTxbJlzs3CUuzfbzZqAIwfD9u2caV2fbbnq8uG/f5Oydl9+9K/Czc3U9nt2uRsxYrap3G7XBKjdrv50Nmzp8m2enqaM3f79bujm7PZTNmElHq4ixaZE13TqlgxNYHbrBkUKJABj0MyRU5ZR+9qI7L0HD16lO+//541a9YQFxeHzWZzutzNzY2YmJjbvt1x48bRt29fRowYQXh4OMOGDaNNmzZs376dgICA645PTEykVatWBAQEMH78eIKCgti/fz/58+d3Oq5KlSrMmTPH8bunZ4Y9FSKWdu4c/PmnSdTGxJj/9MBsrG7d2iRq77svtSrEDbm7m2Jj/9S9t3HjW5/cm2/e+rF//GH+vFqyI9nTE4/ERPN7di3dISIiIiIOAQEm9/PGG2UZPyCW/COG0PLiZKpu+Q1a/MbGUu3xH9KPUp0aunqq2UNyMmzZYjZopHwGGDAAhg1zPs7LC2rWxF4vnP37YN2alJ2zD7NpE+x4J7Wp8bUCA69PzoaGqglVlubmZkrmNW9udt3++Wfqh9A74O5uShvXrGkaFiYkwNKlqUnclSthxw7z89VX5vjatVN34kZGqsmcZB0ZkqncsGEDTZs25dKlS1SqVImNGzcSGhrK2bNnOXToEOXKlaPkHe5P/+STT3jhhRfo0qULACNGjGDq1Kn88MMPvJlOgueHH37g9OnTxMbG4nX1a7fg4ODrjvP09KRYsWJ3NCeRrCYxEWbMMInaSZOcG67Wr28StY8+at74ZilpaixPS9ssD5S4FREREckhcueGhz+OIPnDScz6dAP2Ie/T8vQ4qh6YBlHT+PjTX6k/7HEiI1090yzm2DHnZmErVpiOUfPmmQZTAPXrYw8O5nK1cPYH1metdzhzz9Rk3TZftvwAF4enf9P+/tcnZ8PCTEU0yaaKFjUbb6ZOTW3KDaajXLFi5qzJO+DjY8KxaVP473/NSZ4LFqSWUti61SRyV640J3b6+prEbUo93Jo1zQYmESvKkKTtm2++SZ48eVi3bh1+fn4EBATw2Wef0bx5c37//Xe6devG6NGjb/t2ExMTWb16Nf3SbJt3d3enZcuWLF26NN3rTJo0iYiICHr06MHEiRMpUqQInTp14o033sAjzStx586dFC9eHF9fXyIiIhgyZAilUk7bSEdCQgIJaU67Pnfu3G0/nqzsZs+NWJPNZvqMjR4Nv//uXPenUiWTqO3UyZSnzZKuaYpXav361EZlStyKBWkdFatTjIrVKUbln3h4QOtXq2F/ZQwrfx3E6X5DqXJgGv1X3culhqYX8IAuB2nVuTge3hmfpck2MTpzJvznP+nWK7Dnzs2OmL+Zt+1qWYONj7Lp3GOcnpT+Tfn4mJ2yaZOzVatCUJAaR7mCy2PUzQ3uuSf195TG2+7uptZtzZr/+i7y5zdnjt53n/n90CGTvE2piXv4cOrv/fqZ45s3Ty2nUKGCYtOVXB6jFpMhSdslS5bw+uuvU6pUKU5fzQyllEd45JFHWLx4Ma+99hoLFiy4rds9efIkycnJFL2mzWPRokVvWH92z549zJ07l6ioKKZNm8auXbvo3r07V65cITo6GoDw8HB+/PFHKlWqxJEjR3jnnXdo1KgRmzZtIm/evOne7pAhQ66rgwswffp0/Pz8AGjVqhWnTp1izZo1jssjIiLw9PRk0aJFjrFq1aoRFBTE9OnTHWNly5alSpUqzJ49m8tXt0EGBAQQHh7O0qVLOXm1AZOfnx8tWrRg48aN7Evzn2iHDh3Yt28fm9M0gGrSpAmXL19m+fLljrE6derg7+/vVKoiJCSEChUqMHXqVMe/W8mSJalRowbz58/n/NW2nOfPn6dhw4asWrWKI0eOAODl5UXbtm3Ztm0bO3fudNxm69atOXHiBGvXrnWMNWjQAHd3dxYvXuz0XBQvXpwZM2Y4xsqVK0doaCizZs1yJMqLFi1KvXr1iI2N5dSpUwDkzp2b5s2bs379eg4cOOC4fseOHdm9ezdbtmxxjDVr1oz4+HhWrFjhGKtbty558+Zl7ty5jrHKlStTvnx5pkyZQkq551KlSlG9enWn56JgwYJERkaycuVKjh49CoC3tzdt2rRh69at7Nq1y3Gbbdq04dixY6xbt84xFnn1a/4lS5Y4xmrUqEHRokWZOXOmY6x8+fJUrlyZmTNnkpiYCECxYsWoW7cuS5Yscbze8ubNS9OmTVm/fj2LFp1h/vwgFi0K4vhxP8dtFSx4mUaNDvHqq8UpVy6OVatWsmWLOcOpXr165M6dm3nz5jmODw0NpVy5ckyePNkxlvJczJ07l/j4eAAKFSpEgwYNWLFiBceOHQPAx8eH1q1bs2XLFnbv3u24ftu2bTl8+DAbNmxwjDVs2BCbzUZsbKxjrGbNmhQpUoRZs2Y5xipUqEBISAgzZszgypUrVNyyhTxduxLUvz+LFy/mzJkzHDhwgLyNGtF00CCOHjrEyqtzd3d3p0OHDuzcudNp7WjRogVxcXGsSlPQNzw8HF9fX6f1qkqVKgQHBzN16lTHWHBwMFWrViUmJoaLFy8CULhwYSIiIli+fDnHr9by8vX1pVWrVmzevJk9aZq3tWvXjkOHDjk9F40aNSIpKcnpS6latWpRqFAhZs+e7RirWLEilSpVYvr06SRdPbesePHi1K5dm0WLFnH27FkA/P39ady4MWvWrOHQoUMAeHh40L59e3bs2MH27dsdt9myZUvOnDnD6tWrHWP169fHx8fH6bkICwujVKlSTJs2zTFWpkwZwsLCmDNnDpeuFpQqUqQI9evXZ9myZZw4cQKAXLly0bJlSzZt2sTeNB2D27dvz4EDB9i0aZNjrEmTJiQkJLBs2TLHWO3atSlQoIBTaZtKlSpRsWJFpk2bRnJyMgBBQUHUqlWLhQsXEhcXB0D+/Plp1KgRq1ev5vDhw4A546Jdu3Zs376dHTt2OG7zbq3lFy9edLyeXLmWFyhQQGt5FljLU54LNzc37rnnHnbt2sXWNE0dmzdvzvnz51mZpnljVlzLAQIDA6lTp45jLU/7XKxbt46DBw8CWsu1luMod+bKtdwq78u1lt/CWt6pDVtr9mHqrAdpOPUE8+aVYNlSN0oubcu+boksafwUuV+oRrM2ppRXRq3lZ86csf5abrfTtlIlzs6cyfk5cyiwfTv7OnQguH9/bDYbmzdvpvG+fdjd3DhVtBK7Ckcw51wVZp1rzJKztbD9N23C22S33N3tVKjgRmDgSQIDT1G69HlCQ5Pp1CmcjRtT13KbzZ0SJbSWg+vW8gMHDrh8LU95X35+yRIiDhzA59w5qFuXk127sqxFC+xXz5rOiLV8y5bZFChwmYcfhm7dAvD3D+e77/ayZEkuNm4sxNmzXkyYABMmmOsVLnyJ6tVP0LlzCSpWPMjx46lxobX87q/liYmJjrUuO78vT1mr/kmGNCLLmzcvn376Kc8//zw2mw0fHx9Gjx7No48+CsB3331Hnz59uHDhwm3d7uHDhwkKCiI2NpaIiAjH+Ouvv86CBQucXigpKlasyOXLl9m7d69jZ+0nn3zC0KFDHS+Ca509e5bSpUvzySef8Nxzz6V7THo7bUuWLJljGpHNnTuX5s2bu3oacgMHD8Kvv5pdtWnea5A3r+nXFRVlCrBn59M+FKNidYpRsTrFqFidYlT+jaNHYczAHTw7Mpz89rMA/O1eko1tXqPuiOcoXMrv5jdwCywdo6dOwYgRqaUOrn4Rk2JPixf4KXIkmzbB9o2JBO5axHJ7Xc5z/WfdkiWvL21QubLqhGYFlozR48ehRw/TqA5MYI0aZQrR3mVJSbB6dWo93NhYU1owrbCw1Hq4TZqYz9hy91gyRu+CTG1EVqZMGce3M+7u7pQpU4Y5c+Y4kraxsbHXNQK7FYULF8bDw8PxLWGKY8eO3bAebWBgIF5eXk6lECpXrszRo0dJTEzEO506Kfnz56dixYpOmftr+fj44OPjc9uPIbtI+fZWrOPMGfP/2ujRsHChacoJpu5/+/YmUXvPPf/cJyy7UIyK1SlGxeoUo2J1ilH5N4oVg74jKnIh+gCL/zOCilM/oUTyQUpM78Xx0oOZGP4yVb/uTtma/nd8H5aI0ZRmYcuWmQKxDz4ImM8Kbv/3f47Dkty92OJbi4UJ4SxJrs+SmEgOOjYKerOZFhQqBE2vqTkbFmbq0UrWZIkYvVZAgKnn9/vvJnm7cSOEh5sm1dHR5gPuXeLpae4qPBzefhsuXoTFi1Pr4a5da5robdoEn31mjq9XL7Uebnj4HZfilRuwZIy60B0nbc+cOUOBAgUAs037999/59133wWgW7duvPLKK+zZswe73c78+fN55ZVXbvs+vL29qV27NjExMdx///2AKbsQExNDz549071OZGQkY8aMwWaz4e7uDsCOHTsIDAxMN2ELcOHCBXbv3s1TTz1123MUyUyXL8OUKSZRO22a87eAjRubRO3DD0PBgq6bo4iIiIiIVeUJzEvDia+RdOElVvb+keK/fEBQ4j7uW/4WbWvVIs9DbXjtNZOMyRLSNgtbtsx0W7p6huvBis3578wHryadCvEOvdlLGZYTzjpbDRIumq2xfn4mGdsqzHkHbdGiqu0pmeiRR0w3sZ494bffTIOWTD5V1M8PWrc2PwAnT5q+eyn1cHfvNrtxY2NNa5Xcuc3n8JR6uFWrmvK8IhnljpO2xYoVo3379kRFRfHKK6/wxBNPcOXKFby8vOjTpw/x8fH88ccfeHh40L9/f9566607up++ffvSuXNn6tSpQ7169Rg2bBjx8fF06dIFgKeffpqgoCCGDBkCmITx8OHD6d27Ny+99BI7d+7kvffeo1evXo7bfPXVV+nYsSOlS5fm8OHDREdH4+HhwRNPPHGnT0e2V0htPF0mORnmzzeJ2j/+gLQ98KpWNYnaJ56AnF6vWzEqVqcYFatTjIrVKUYlI3nm8aXu9//BPuJ5tkSP5diP05l5pDX8Yd5zvxo6jdZ9w2jRpdQtJ2HueowmJJi6aOXLA3DhvB3fipXxPHfG6bDz5GEldYnZ0ZyRqaWeec1zGJUqmc8QHdMkZ4ODlWjKKSy/jhYpAuPGwaOPmqZkKYF58aJJ4Gby2c+FC5tc8iOPmN/37UtN4MbEmCoj06ebn5Tpt2iRWk4hODhTp5stWD5GM9kd17SNiopi0qRJXLx4kbx58/Lggw8SFRVF8+bNccvgr+OGDx/O0KFDOXr0KDVq1ODzzz8n/OpXn02bNiU4OJgff/zRcfzSpUt5+eWXWbduHUFBQTz33HO88cYbjpIJjz/+OAsXLuTUqVMUKVKEhg0b8u6771KuXLlbntOt1p8QuRN2uzkVY/RoGDvWdLhMUbIkdOpkkrVVq7pujiIiIiIi2cmmTfDxxzDpl3PsSipNHi4wOd+TJL3yBve+HpK5NVvtdti7F5YtIzl2OQkLl+GzdR3ncgfyTJN9bNxoLp5CB0qzn2XUZznhLKM+WwildBkPp5qzVatCxYo6lVuyqJ49zZbXH3+EunVdPRsAbDazZqTUw124EK49s79cudQEbrNmJgksAreeU/xXjcguXbrEX3/9xZgxY5g1axZJSUkULVqUJ554gqioKGrVqnWnN215OS1pu2LFCurVq+fqaWR7e/bAmDEmWZummSoFCphv96KioGFDfROeHsWoWJ1iVKxOMSpWpxiVzHJ06V7OP/ECFfabIq823Jjq8xDHn+vHA4Nr3bAU2b+NUZvN7OSz9X2VwDk/kzv+xHXHHKcIFdjJOUxh2cCAZKpU83BKzoaGQp48dzwNycay5Dp69qzpdHf0qPkg/PrrptatxTrfJSaaSiUpu3CXLTNnzaZwc4MaNVLr4TZsaMoxiLMsGaN3IFMakeXKlYsnnniCJ554gjNnzvDbb78xZswYhg0bxrBhw6hQoQJPPvkknTp1omzZsv/mrsTFrm0GJxnnxAlTsmf0aFi6NHXc1xc6djSJ2rZtM/1MkCxHMSpWpxgVq1OMitUpRiWzFIsoQ7F9c4ifu5wjvYZQfvNEOiaMh6/GM3tEG1Y+8QlPDA6lzE8DzSnb/fsD18To4MEmYzNw4HW3b09K5tTCzRyfvBxb7DLy7VpNVJmlrNmai4sX4Qsu05MTJOLFGmqxnHDW56rP+crhFKxdhv9WdaNqVahSBYoUydyan5K1Zcl1NH9+s6W1Vy+zw+n992HSJBg1ynQFswhvb2jUyPy8844pa7hwYWo5hU2bzNm0a9fC0KHm+AYNUnfi1qljGp3ldFkyRu+iDAuJAgUK0LVrV7p27cqhQ4cYM2YMv/76KwMGDCA6Oprw8HBiY2Mz6u5EsrT4eJg40SRqZ82CpCQz7u4OzZubRO2DD0IO2MQtIiIiImJJuZuHU37TX1xZu4m/e75PqdhfaW6bzX9G+9D/V/g11INHNw1gyxZ4Ykt/tm5tT+XK8GvoYELHDoBBg4iLM8maY1NWkmfWBArvWU7FsyspzAXSnimdfHotF2mAtzfMLduDk6WfJE/DGoTW8uWBMOhVUk3BJAcrVMh8eH7kEfjPf2DLFoiIgNdeM1+MWGzXLZjP8vfcY37AbBSeOze1nMLBg6Z3zfz55nuffPlMH7aUnbghIXrNSwYmbdMKCgritddeo23btgwYMICJEyeyfPnyu3FXkkl8tM3zX0tKgtmzzf81f/3lXO+mdm2TqH38cQgMdNkUszTFqFidYlSsTjEqVqcYFVfxqhlGmSW/YN89iC1fzaf8pnLsmQWPbepPAHNoOnYA92NjA9E8uCGa0A2DWJK3LS9/3YWVA8xtvMwiPuF9x22eIy+bc9XlcKn6JNQI5/V2VQgJNz3GPD0ru+iRSnaX5dfR++83W1lTdt2OHAl9+kCxYq6e2T8qVsz0punUyZSs3rUrNYE7bx6cOWM2EE+aZI4vXjx1F26LFhAU5Nr5Z5YsH6MZ7F/VtE3PgQMHHLtsN23ahN1up0GDBkRFRdGtW7eMvCuXymk1beXO2O2mrs3o0aYJ5ok0ZanKljWJ2k6dzLdoIiIiIiKSNaxfD6Ojd/D+xBDcMR+pbbg5/g7wFD/zC09RogTcV2otT53/iuQ64eRvW58y7SuTK49KG4jcsYkTTQmSBx9MHbtyBby8XDenO5ScbMompNTDXbQIEhKcjwkJSd2F27Qp+Pu7ZKqSQTKlEVmKkydPOurZLl26FLvdTkhICFFRUURFRREcHPxv78JyclrSdsuWLYSGhrp6GlnG9u0mUTtmDOzenTpepAg89phJ1oaH63SHjKQYFatTjIrVKUbF6hSjYjlnzjC4yOd0T/6cQpx2DB8jgOVu9Sk7tDtBz7ahQAEXzlEkjWy9jk6cCG++CT/8YEonZGGXLkFsbGo93FWrzIawFO7uULdu6k7cBg2yTw+cbB2jadxqTvGOe9DHx8fzyy+/0L59e4KCgujZsyd79+6lT58+rFq1ii1btvD2229ny4RtTrQ7beZR0nXkCHz6qSkgHhJieg/s3g25c5sk7bRpcOgQfPEF1K+vhG1GU4yK1SlGxeoUo2J1ilGxnAIFGF8lmq/oDsCVq9UHv6QHA6pNJOwVJWzFWrLtOmq3w6BBsG0bREbCq6+azGcWlSuXSci+9x6sWAGnTsGECdC9O1SsCDabOaP3vfdMT5wCBaB1a/jwQ1izxlyeVWXbGL1Dd1zTNiAggMuXL5MnTx46depEVFQUzZs3x939jvPAIlnOuXNm8Rw92hQVT1kcPTygTRuTrL3vPpO4FRERERGR7OXX0MGEbvgvAxjEYPrTn8EMYgCPV3YD+rt6eiI5g5ubaSDz8svw88/w8ccweTKMGmW2oWZxBQrAAw+YHzBNzFJ24cbEmCZns2ebHzB925o1S62HW66cNo1lVXectG3ZsiVRUVHce++9+FqwU5/I3ZKYCDNmwC+/mP8HLl9OvSwiwiRqH33UlEIQEREREZFsavBgQscOYMvjg5i0tT9eW5KZFNqfxytD6NgBEIppCy8id1/BgvDTT/DII9C1K+zYAQ0bmkTu4MHg5+fqGWaYkiXhmWfMj90OW7akJnDnzzc7c8ePNz8ApUun1sNt3hwCAlw4ebktGd6ILKfIaTVtr1y5glcWLOidUWw2WLzY7Kj9/XfT2TFFSEhqQ7GyZV03x5wup8eoWJ9iVKxOMSpWpxgVyxk40JxidzUx6xSjgweb7kIDB7pseiLXyjHr6Jkz0Lcv/Pij+X3mTFM/IAe4cgVWrkzdibt0qRlLq1q11F24jRtDnjyumWt6ckqMZmojspwopyVt9+/fT+nSpV09jUy3caNJ1P76Kxw4kDoeGAhPPGGStTVr6lQDK8ipMSpZh2JUrE4xKlanGBWrU4yK1eW4GJ02DRYsgA8+SB2z23PUB/j4eFi0yCRw58yB9eudL/f0NGcMpzQ1q1cPXJkzzSkxetcbkUnOsmHDBldPIdMcPGjW9GrVzM8HH5iEbb580KWLWegOHjRlcmrVylHrvaXlpBiVrEkxKlanGBWrU4yK1SlGxepyXIy2b++csD10yGQlFy1y3ZwyWe7c0LYtfPQRrFsHx47B2LHw/PMQHAxJSebpGDjQVJMoWBDuuQeGDTOb2DJ7m2eOi9F/cMc1bUWykzNnTNmD0aNh4cLUcW9vs85HRUGHDqaLo4iIiIiIiIhkMf37w6pV0KQJ9OoF776b47qGBwTAY4+ZH4A9e1Lr4cbEmHq4U6eaH4CiRc0u3JSduKVKuW7uOZGStpJjXboEU6aYRO20ac51Xpo0MYnahx82nRpFREREREREJAv79FNzquwPP8Bnn5mEwA8/mMKuOVTZsvDii+bHZjPlE1Lq4S5caHbmjhljfgAqVEhN4DZrZnbmyt2jmrZ3KKfVtD1z5gwFskH2MjnZdFMcPRr++APOnUu9rFo1k6h94gnTjVGyluwSo5J9KUbF6hSjYnWKUbE6xahYnWL0qhkz4IUX4O+/ze8vvQRDhuS4Xbf/JCEBli1LrYe7cqXJqaRwczMlI1u2ND+Rkf/+7OScEqO3mlPUTlu5JTabzdVTuGN2O6xdm9pQ7MiR1MtKlYJOnUyyNizMdXOUfy8rx6jkDIpRsTrFqFidYlSsTjEqVqcYvaptW9i0CV59Fb77Dr74AgoVguhoV8/MUnx8zFnITZrA4MEQF2f6uqWUU9iyBVavNj8ffGCOj4w0CdwWLaB2bfDwuL37VIw6UyMyuSWxsbGunsJt27PHLCyhoWax+OQTk7AtUAC6djVb/ffuNV+oKWGb9WXFGJWcRTEqVqcYFatTjIrVKUbF6hSjafj7w7ffml23zZubBK7clL8/3HsvfP45bN5s+rr9/DN07gxBQWZn7ty58NZbEB4OhQvDgw/Cl1/C9u231tRMMepMO20lWzlxAsaNM7tqly1LHff1NYtLVJT5Us3b23VzFBERERERERELaNPG/KSw2UwW8tlnTdFWuaHixeGpp8yP3W4Ssym7cOfNg7Nn4c8/zQ9AiRKp9XBbtIDAwNTbmjAB3nkHtm5tT+XKZtPzgw+65GFZipK2kuXFx8Nff5lE7axZqTVW3N3NQhAVBQ88ADmg9LCIiIiIiIiI3Klvv4VffjE/3bub8/7z5HH1rCzPzQ1CQsxPz56QlGTKJqQ0NVuyxJQQ/ukn8wPmrOiWLcHPD95/39yG3e7Bxo3w0EOmD1FOT9yqEdkdymmNyP7++29KlCjh6mk4XLkCs2ebRO1ff8HFi6mX1aljErWPPeb8zY1kb1aLUZFrKUbF6hSjYnWKUbE6xahYnWL0Fpw/D6+/DiNGmN+Dg+H7700JBbljFy+axG1KU7O1a29eLsHNzTSLX7cu06aYqW41p6ik7R3KaUnbhIQEfHx8XDoHux2WLzeJ2nHjTCmEFOXKmURtp05QqZLr5iiuY4UYFbkZxahYnWJUrE4xKlanGBWrU4zehpgYeO452L/f/P6f/8CHH0LevK6dVzZx6pQpoTBnDowcmX4C19cXLl3K/LllhlvNKaoRmdySWbNmuey+t2+HAQOgQgWIiIDhw03CtkgReOklU7t2505T/0QJ25zLlTEqcisUo2J1ilGxOsWoWJ1iVKxOMXobWrSAjRuhWzfz+4gRZqeYZIhCheDhh83TWrWq2Vmblpub8juQRZK2X375JcHBwfj6+hIeHs6KFStuevzZs2fp0aMHgYGB+Pj4ULFiRaZNm5buse+//z5ubm706dPnLsxc7tSRI/Dpp6bUQUgIDB4Mu3dD7tzw5JMwfTocPmy6FoaHX/8CFxERERERERG5Y3nzwldfmV23FSrAoEGunlG2FB1tdtqm5HVMbVszntNZvhHZuHHj6Nu3LyNGjCA8PJxhw4bRpk0btm/fTkBAwHXHJyYm0qpVKwICAhg/fjxBQUHs37+f/PnzX3fsypUr+eabb6hWrVomPBL5J3Fxpqvg6NEwd65p2gjg6WmaOUZFwb33msStiIiIiIiIiMhd17w5bN0KHh6pY19+abaCtmzpunllEw8+aJqODRoEW7YkExrqQXS0aSif01k+afvJJ5/wwgsv0KVLFwBGjBjB1KlT+eGHH3jzzTevO/6HH37g9OnTxMbG4uXlBUBwcPB1x124cIGoqCi+/fZb/vvf//7jPBISEkhISHD8fu7cuTt8RFlThQoV7srtJiSYXbOjR8Pkyeb3FA0amETtI4+YUggiN3O3YlQkoyhGxeoUo2J1ilGxOsWoWJ1i9F9Im7DdsAH69IGkJHjxRRg6FHJAr6O76cEHzc+2bTsJCQlx9XQsw9KNyBITE/Hz82P8+PHcf//9jvHOnTtz9uxZJk6ceN112rdvT8GCBfHz82PixIkUKVKETp068cYbb+CR5kXWuXNnChYsyKeffkrTpk2pUaMGw4YNu+FcBg4cyDvvvHPd+NixY/Hz8wOgVatWnDp1ijVr1jguj4iIwNPTk0WLFjnGqlWrRlBQENOnT3eMlS1blipVqjB79mwuX74MQEBAAOHh4SxdupSTJ08C4OfnR4sWLdi4cSP79u1zXL9Dhw7s27ePzZs3O8aaNGnC5cuXWb58uWOsTp06+Pv7ExMT4xgLCQmhQoUKTJ06FdvV7a0lS5akRo0azJ8/n/PnzwNQoEABGjZsyKpVqzhy5AgAXl5etG3blm3btrFz507HbbZu3ZoTJ06wdu1ax1iDBg1wd3dn4cLFbNlSkPnzS7B8eQni4lL/XUqWPM8DD1yiT58Adu6c5UiUFy1alHr16hEbG8upU6cAyJ07N82bN2f9+vUcOHDAcRsdO3Zk9+7dbNmyxTHWrFkz4uPjnUpr1K1bl7x58zJ37lzHWOXKlSlfvjxTpkwh5aVRqlQpqlev7vRcFCxYkMjISFauXMnRo0cB8Pb2pk2bNmzdupVdu3Y5brNNmzYcO3aMdWnaHkZGRgKwZMkSx1iNGjUoWrQoM2fOdIyVL1+eypUrM3PmTBITEwEoVqwYdevWZcmSJZw+fRqAvHnz0rRpU6fnws3NjXvuuYddu3axdetWx202b96c8+fPs3LlSsdYvXr1yJ07N/PmzXOMhYaGUq5cOSZPnuwYS3ku5s6dS3x8PACFChWiQYMGrFixgmPHjgHg4+ND69at2bJlC7t373Zcv23bthw+fJgNGzY4xho2bIjNZiM2NtYxVrNmTYoUKeJUc6lChQqEhIQwY8YMrly5AkBgYCB16tRh8eLFnDlzxum5WLduHQcPHgTA3d2dDh06sHPnTrZt2+a4zRYtWhAXF8eqVascY+Hh4fj6+rJgwQLHWJUqVQgODmbq1KmOseDgYKpWrUpMTAwXL14EoHDhwkRERLB8+XKOHz8OgK+vL61atWLz5s3s2bPHcf127dpx6NAhp+eiUaNGJCUlsXTpUsdYrVq1KFSoELNnz3aMVaxYkUqVKjF9+nSSkpIAKF68OLVr12bRokWcPXsWAH9/fxo3bsyaNWs4dOgQAB4eHrRv354dO3awfft2x222bNmSM2fOsHr1asdY/fr18fHxcXouwsLCKFWqlFPJmTJlyhAWFsacOXO4dLVSfJEiRahfvz7Lli3jxNWugbly5aJly5Zs2rSJvXv3Oq7fvn17Dhw4wKZNmxxjTZo0ISEhgWXLljnGateuTYECBZgzZ45jrFKlSo4SOMnJyQAEBQVRq1YtFi5cSFxcHAD58+enUaNGrF69msOHDwPg6elJu3bt2L59Ozt27HDcptbyW1vLFy9e7PRcFC9enBkzZjjGypUrR2hoKLNmaS3XWq61XGu51nKt5VrLtZZrLddann3W8lXz51P5558pczUObSVKsOKFFzhRsyagtVxr+T+v5RcvXuTxxx//x0Zklk7aHj58mKCgIGJjY4mIiHCMv/766yxYsMDpTU+KkJAQ9u3bR1RUFN27d2fXrl10796dXr16EX21IMbYsWN59913WblyJb6+vreUtE1vp23JkiX/8QnOLmbMmEHbtm3/1W1s3Gh21I4ZA1f/zwageHF44gmzq7ZGDdWnlTuTETEqcjcpRsXqFKNidYpRsTrFqFidYjSDzZ8Pzz0HKV8CPP88fPQR+Pu7dFpZWU6J0XPnzuHv7/+POUXLl0e4XTabjYCAAEaOHImHhwe1a9fm0KFDDB06lOjoaA4ePEjv3r2ZPXs2vr6+t3y7Pj4++Pj43MWZW1vKN6i368AB+PVXk6zduDF1PF8+0ykwKgqaNHE+00DkTtxpjIpkFsWoWJ1iVKxOMSpWpxgVq1OMZrCmTU2phLfeMl3Sv/sOFi6ETZvgarlOuT2KUWeWTtoWLlwYDw8Px6kdKY4dO0axYsXSvU5gYCBeXl5OpRAqV67M0aNHSUxMZPXq1Rw/fpxatWo5Lk9OTmbhwoUMHz6chIQEp+vK7Tt9GsaPN4nahQtTx729oUMHk6jt0AFuI2cuIiIiIiIiImItuXPDZ5/BQw/Bs89Ct25K2EqGsXTS1tvbm9q1axMTE+OoaWuz2YiJiaFnz57pXicyMpIxY8Zgs9lwd3cHYMeOHQQGBuLt7e2oVZJWly5dCAkJua7uraQKDAy86eWXLsGUKSZRO20apHw54uZmdtJGRZk1rECBTJis5Ej/FKMirqYYFatTjIrVKUbF6hSjYnWK0buocWOz6zbtGdpLl8KZM9C+vevmlcUoRp1ZuqYtwLhx4+jcuTPffPMN9erVY9iwYfz2229s27aNokWL8vTTTxMUFMSQIUMAOHjwIFWqVKFz58689NJL7Ny5k2effZZevXrx9ttvp3sft1LT9lq3Wn8iO0tOhnnzTKL2jz/gav1oAKpXN4naxx+HkiVdN0cRERERERERkUx18aJJjOzaBc88A59+Cvnzu3pWYhG3mlN0z8Q53ZHHHnuMjz76iAEDBlCjRg3WrVvHjBkzKFq0KAAHDhxwdNkD05Fv5syZrFy5kmrVqtGrVy969+7Nm2++6aqHkKVNmGDWGR8fG9Wrm+Ts6tXQty+UKAGtWsGPP5qEbenS0K+fKd+ybh289poStpJ50nbMFLEixahYnWJUrE4xKlanGBWrU4xmIjc3uOce8+ePP0KVKua0ZLkpxagzS5dHSNGzZ88blkOYP3/+dWMREREsW7bslm8/vdsQk7B96CGzxtjt7mzYYJqHpVWwIDz6qNlV26ABuFv+awDJrs6cOePqKYjclGJUrE4xKlanGBWrU4yK1SlGM1GuXGZ3bUqt2507TXOfzp3NuGpHpksx6kwpNrmhd95JSdg6j7u5wWOPwaRJcOQIfP01NGyohK2IiIiIiIiIiEPDhuZU5L59TTLlp58gLAz+/tvVM5MsIEvstBXX2LHj+oQtgLc3jB2b+fMRuZm8efO6egoiN6UYFatTjIrVKUbF6hSjYnWKURfx84OPPza7brt0gfLlISjI1bOyJMWoM8s3IrOqnNCIrHp12LjROXHr5gbVqpkvikRERERERERE5BZdugTx8VC4sPn9zBmIjTWlEyTHyDaNyMR1oqNNwtbNzfyeUiohOtq18xJJzzp9kyAWpxgVq1OMitUpRsXqFKNidYpRC8iVKzVhC6Zswj33wFNPwenTrpuXRShGnSlpKzf04IPwxx9mZ62XVzLVqpnmZA884OqZiVzv4MGDrp6CyE0pRsXqFKNidYpRsTrFqFidYtRi7HYICDANgn75BapUgYkTXT0rl1KMOlPSVm7qwQdNKYQ//pjGunVK2IqIiIiIiIiI/GtubvDBB6Y8QkgIHD0K998PUVFw6pSrZycWoKSt3BJ3d4WKWJtiVKxOMSpWpxgVq1OMitUpRsXqFKMWFR4Oa9fCG2+YXbdjxphdt8uXu3pmmU4x6kyNyO5QTmhEJiIiIiIiIiIimWTFCnjmGVPfdvNmKFTI1TOSu0CNyCRD7dy509VTELkpxahYnWJUrE4xKlanGBWrU4yK1SlGs4B69WDNGpg9OzVha7ebEgo5gGLUmZK2cku2bdvm6imI3JRiVKxOMSpWpxgVq1OMitUpRsXqFKNZhK8vVK2a+vvYsRAZCY8/DidPum5emUAx6kxJWxERERERERERESs6cAA8PGDcOAgNhT/+cPWMJJMoaSsiIiIiIiIiImJFb7wBy5ZBWBicOAEPPwyPPWb+LtmaGpHdoZzWiOzixYv4+fm5ehoiN6QYFatTjIrVKUbF6hSjYnWKUbE6xWgWl5AA//0vDBkCyclQpAiMGgUdOrh6Zhkmp8SoGpFJhoqLi3P1FERuSjEqVqcYFatTjIrVKUbF6hSjYnWK0SzOxwcGD4bly03N2xMnIJslOBWjzpS0lVuyatUqV09B5KYUo2J1ilGxOsWoWJ1iVKxOMSpWpxjNJmrXhlWrYNIkaNYsdXzPHsjiJ9MrRp0paSsiIiIiIiIiIpJVeHtDx46pv+/dC9WqwSOPwLFjrpuXZCglbUVERERERERERLKqJUtMzds//oAqVWDs2Cy/61aUtJVbFB4e7uopiNyUYlSsTjEqVqcYFatTjIrVKUbF6hSj2diTT8KKFVC9Opw6BU88AQ8/nOV23SpGnSlpK7fE19fX1VMQuSnFqFidYlSsTjEqVqcYFatTjIrVKUazuZo1TeJ24EDw9IQJEyA0FMaNc/XMbpli1JmStnJLFixY4OopiNyUYlSsTjEqVqcYFatTjIrVKUbF6hSjOYC3N0RHm0ZlNWrA6dOwcaOrZ3XLFKPOPF09AREREREREREREckg1aubXbfffAMvvJA6fvYs+PuDm5vLpia3LkvstP3yyy8JDg7G19eX8PBwVqxYcdPjz549S48ePQgMDMTHx4eKFSsybdo0x+Vff/011apVI1++fOTLl4+IiAimT59+tx+GiIiIiIiIiIjI3eflBT17go+P+T0pCVq2hPvvhyNHXDo1uTWWT9qOGzeOvn37Eh0dzZo1a6hevTpt2rTh+PHj6R6fmJhIq1at2LdvH+PHj2f79u18++23BAUFOY4pUaIE77//PqtXr2bVqlU0b96c++67j82bN2fWw8pyqlSp4uopiNyUYlSsTjEqVqcYFatTjIrVKUbF6hSjOdzy5bBhA0yaBFWqwP/+B3a7q2flRDHqzM1ut9i/0DXCw8OpW7cuw4cPB8Bms1GyZEleeukl3nzzzeuOHzFiBEOHDmXbtm14eXnd8v0ULFiQoUOH8txzz6V7eUJCAgkJCY7fz507R8mSJYmLiyNfvny3+aiyHpvNhru75XP8koMpRsXqFKNidYpRsTrFqFidYlSsTjEqbNwIzzwDa9aY3++5x5RQKF7cpdNKkVNi9Ny5c/j7+/9jTtHSNW0TExNZvXo1/fr1c4y5u7vTsmVLli5dmu51Jk2aREREBD169GDixIkUKVKETp068cYbb+Dh4XHd8cnJyfz+++/Ex8cTERFxw7kMGTKEd95557rx6dOn4+fnB0CrVq04deoUa1KCH4iIiMDT05NFixY5xqpVq0ZQUJBTSYayZctSpUoVZs+ezeXLlwEICAggPDycpUuXcvLkSQD8/Pxo0aIFGzduZN++fY7rd+jQgX379jntFm7SpAmXL19m+fLljrE6derg7+9PTEyMYywkJIQKFSowdepUbDYbACVLlqRGjRrMnz+f8+fPY7PZKFSoEA0bNmTVqlUcubqV3svLi7Zt27Jt2zZ27tzpuM3WrVtz4sQJ1q5d6xhr0KAB7u7uLF682Om5KF68ODNmzHCMlStXjtDQUGbNmuVIlBctWpR69eoRGxvLqVOnAMidOzfNmzdn/fr1HDhwwHH9jh07snv3brZs2eIYa9asGfHx8U6lNerWrUvevHmZO3euY6xy5cqUL1+eKVOmkPJ9RqlSpahevbrjuQCT5I+MjGTlypUcPXoUAG9vb9q0acPWrVvZtWuX4zbbtGnDsWPHWLdunWMsMjISgCVLljjGatSoQdGiRZk5c6ZjrHz58lSuXJmZM2eSmJgIQLFixahbty5Llizh9OnTAOTNm5emTZs6PRdubm7cc8897Nq1i61btzpus3nz5pw/f56VK1c6xurVq0fu3LmZN2+eYyw0NJRy5coxefJkx1jKczF37lzi4+MBKFSoEA0aNGDFihUcO3YMAB8fH1q3bs2WLVvYvXu34/pt27bl8OHDbNiwwTHWsGFDbDYbsbGxjrGaNWtSpEgRZs2a5RirUKECISEhzJgxgytXrgAQGBhInTp1WLx4MadOncLd3d3xXKxbt46DBw8CZt3o0KEDO3fuZNu2bY7bbNGiBXFxcaxatcoxFh4ejq+vr1MB9CpVqhAcHMzUqVMdY8HBwVStWpWYmBguXrwIQOHChYmIiGD58uWOswF8fX1p1aoVmzdvZs+ePY7rt2vXjkOHDjk9F40aNSIpKclpfatVqxaFChVi9uzZjrGKFStSqVIlpk+fTlJSEgDFixendu3aLFq0iLNnzwLg7+9P48aNWbNmDYcOHQLAw8OD9u3bs2PHDrZv3+64zZYtW3LmzBlWr17tGKtfvz4+Pj5Oz0VYWBilSpVyKjlTpkwZwsLCmDNnDpcuXQKgSJEi1K9fn2XLlnHixAkAcuXKRcuWLdm0aRN79+51XL99+/YcOHCATZs2OcaaNGlCQkICy5Ytc4zVrl2bAgUKMGfOHMdYpUqVHCVwkpOTAQgKCqJWrVosXLiQuLg4APLnz0+jRo1YvXo1hw8fBsDT05N27dqxfft2duzY4bjNu7WWT5482fEGxFVrOUCBAgW0lmstT3ctP3XqFEWLFnXpWn7mzBmn50JrudbytGu5zWbjvvvuc+laboX35aC13Kpruc1mw9/fP8e/L9dabt21/NixY7i7u+f49+U5fS13+7//o/rs2ZT87juYMoXEihXZ/MILnLnnHpq3aOHStTztZ6bs/L48Za36J5beaXv48GGCgoKIjY11Sqi+/vrrLFiwwOmFkiIkJIR9+/YRFRVF9+7d2bVrF927d6dXr15ER0c7jtu4cSMRERFcvnyZPHnyMGbMGNq3b3/DueT0nbaTJ0+mY8eOrp6GyA0pRsXqFKNidYpRsTrFqFidYlSsTjEqTjZtMrtuV6+G8HBYsgTS2eyYmXJKjGaLnbZ3wmazERAQwMiRI/Hw8KB27docOnSIoUOHOiVtK1WqxLp164iLi2P8+PF07tyZBQsWEBoamu7t+vj44JNSvFlERERERERERCSrCguDZctg6FB44IHUhG1Skvm7m5tr5yfWTtoWLlwYDw8Px6kdKY4dO0axYsXSvU5gYCBeXl5OpRAqV67M0aNHSUxMxNvbGzDbrMuXLw+Yrf0rV67ks88+45tvvrlLjyZrCw4OdvUURG5KMSpWpxgVq1OMitUpRsXqFKNidYpRuY6nJ6QpSQrAW2/B5s0wciQEBWXqdBSjzixd3dfb25vatWs71Qax2WzExMTcsP5sZGQku3btctQNAdixYweBgYGOhG16bDabU/kDcVa1alVXT0HkphSjYnWKUbE6xahYnWJUrE4xKlanGJV/dPw4DB8O06ZBlSowahRkYlVVxagzSydtAfr27cu3337LTz/9xNatW+nWrRvx8fF06dIFgKefftqpUVm3bt04ffo0vXv3ZseOHUydOpX33nuPHj16OI7p168fCxcuZN++fWzcuJF+/foxf/58oqKiMv3xZRVpE+ciVqQYFatTjIrVKUbF6hSjYnWKUbE6xaj8o4AAWLUK6tWDuDh49llo3x7+/jtT7l4x6szS5REAHnvsMU6cOMGAAQM4evQoNWrUYMaMGRQtWhSAAwcOODrLgenIN3PmTF5++WVHB8HevXvzxhtvOI45fvw4Tz/9NEeOHMHf359q1aoxc+ZMWrVqlemPL6u41c52Iq6iGBWrU4yK1SlGxeoUo2J1ilGxOsWo3JLQUNOU7NNPoX9/mDHD7Lr95BOTxL2LtW4Vo84sn7QF6NmzJz179kz3svnz5183FhERwbJly254e99//31GTU1ERERERERERCT78PSE116De+6BLl1g+XJ4+WXo0AFu0GNKMl6WSNqK6xUuXNjVUxC5KcWoWJ1iVKxOMSpWpxgVq1OMitUpRuW2Va6cuuu2cGHnhK3dnuG7bhWjztzs9kysKJyNnDt3Dn9/f+Li4siXL5+rpyMiIiIiIiIiInL3zZoFH38M334LpUq5ejZZzq3mFC3fiEysYfny5a6egshNKUbF6hSjYnWKUbE6xahYnWJUrE4xKhnCZoOXXjKJ27AwGDnS7LrNAIpRZ0rayi05fvy4q6cgclOKUbE6xahYnWJUrE4xKlanGBWrU4xKhnB3h0mToEEDOH8eunaF1q1h//5/fdOKUWdK2oqIiIiIiIiIiMitqVQJFi6ETz4BX1+YM8fsuv3mmwzbdStK2sot8vX1dfUURG5KMSpWpxgVq1OMitUpRsXqFKNidYpRyVAeHvDyy7BhA0RGwoUL8J//wLx5d3yTilFnakR2h9SITEREREREREREcrzkZBg+HNauhR9/dPVsLE+NyCRDbd682dVTELkpxahYnWJUrE4xKlanGBWrU4yK1SlG5a7x8IDevZ0TtsePwyOPwN69t3wzilFnStrKLdmzZ4+rpyByU4pRsTrFqFidYlSsTjEqVqcYFatTjEqmeuUVGD8eqlaFr74Cm+0fr6IYdaakrYiIiIiIiIiIiGScgQOhcWOIj4cePaBFC1BS9rYoaSsiIiIiIiIiIiIZp1w505Tsiy/Azw/mzze7bocPv6Vdt6JGZHcspzUiS0pKwtPT09XTELkhxahYnWJUrE4xKlanGBWrU4yK1SlGxWX27IHnnjOJW4ChQ+HVV687LKfEqBqRSYY6dOiQq6cgclOKUbE6xahYnWJUrE4xKlanGBWrU4yKy5QtCzEx8OWXULkyvPiiGR84EAYPdhzmFKODB5vLczAlbeWWbNiwwdVTELkpxahYnWJUrE4xKlanGBWrU4yK1SlGxaXc3aF7d9i4EVJ2l7q7w4AB0KcPkCZGBw824x4erpmrRShpKyIiIiIiIiIiIndf2kRs8eLmz88+g/btTa3blITtoEHQv79r5mgR2b9QhIiIiIiIiIiIiFhLixbQrJlpWDZ9Oh1mzYLkZCVsr1IjsjuU0xqRnT17lvz587t6GiI3pBgVq1OMitUpRsXqFKNidYpRsTrFqFiSzQYjR0LPniZh6+0NCQmuntVdpUZkkqGSkpJcPQWRm1KMitUpRsXqFKNidYpRsTrFqFidYlQsyd0dTpyA5GTs3t6QmOjUnCwnU9JWbsnSpUtdPQWRm1KMitUpRsXqFKNidYpRsTrFqFidYlQsKU0N2ynjx5vSCAMGKHGLatqKiIiIiIiIiIhIZru26djkyam1bAcMMH/m4Nq2WWKn7ZdffklwcDC+vr6Eh4ezYsWKmx5/9uxZevToQWBgID4+PlSsWJFp06Y5Lh8yZAh169Ylb968BAQEcP/997N9+/a7/TBEREREREREREQEbtx0rH9/M56c7Jp5WYTld9qOGzeOvn37MmLECMLDwxk2bBht2rRh+/btBAQEXHd8YmIirVq1IiAggPHjxxMUFMT+/fudim0vWLCAHj16ULduXZKSknjrrbdo3bo1W7ZsIXfu3Jn46LKOWrVquXoKIjelGBWrU4yK1SlGxeoUo2J1ilGxOsWoWM7AgU6/OsVoDt5hm8LNbrfbXT2JmwkPD6du3boMHz4cAJvNRsmSJXnppZd48803rzt+xIgRDB06lG3btuHl5XVL93HixAkCAgJYsGABjRs3vqXr3Gqnt+zi8uXL+Pr6unoaIjekGBWrU4yK1SlGxeoUo2J1ilGxOsWoWF1OidFbzSlaujxCYmIiq1evpmXLlo4xd3d3WrZsecMC2pMmTSIiIoIePXpQtGhRwsLCeO+990i+yZbquLg4AAoWLHjDYxISEjh37pzTT04ye/ZsV09B5KYUo2J1ilGxOsWoWJ1iVKxOMSpWpxgVq1OMOrN0eYSTJ0+SnJxM0aJFncaLFi3Ktm3b0r3Onj17mDt3LlFRUUybNo1du3bRvXt3rly5QnR09HXH22w2+vTpQ2RkJGFhYTecy5AhQ3jnnXeuG58+fTp+fn4AtGrVilOnTrFmzRrH5REREXh6erJo0SLHWLVq1QgKCmL69OmOsbJly1KlShVmz57N5cuXAQgICCA8PJylS5dy8uRJAPz8/GjRogUbN25k3759jut36NCBffv2sXnzZsdYkyZNuHz5MsuXL3eM1alTB39/f2JiYhxjISEhVKhQgalTp2Kz2QAoWbIkNWrUYP78+Zw/fx6bzcbixYtp2LAhq1at4siRIwB4eXnRtm1btm3bxs6dOx232bp1a06cOMHatWsdYw0aNMDd3Z3Fixc7PRfFixdnxowZjrFy5coRGhrKrFmzSEhIAMy/eb169YiNjeXUqVMA5M6dm+bNm7N+/XoOHDjguH7Hjh3ZvXs3W7ZscYw1a9aM+Ph4p3rIKXWN586d6xirXLky5cuXZ8qUKaRsQi9VqhTVq1d3PBdgEvyRkZGsXLmSo0ePAuDt7U2bNm3YunUru3btctxmmzZtOHbsGOvWrXOMRUZGArBkyRLHWI0aNShatCgzZ850jJUvX57KlSszc+ZMEhMTAShWrBh169ZlyZIlnD59GoC8efPStGlTp+fCzc2Ne+65h127drF161bHbTZv3pzz58+zcuVKx1i9evXInTs38+bNc4yFhoZSrlw5Jk+e7BhLeS7mzp1LfHw8AIUKFaJBgwasWLGCY8eOAeDj4+MoObJ7927H9du2bcvhw4fZsGGDY6xhw4bYbDZiY2MdYzVr1qRIkSLMmjXLMVahQgVCQkKYMWMGV65cASAwMJA6deqwePFibDYbkydPdjwX69at4+DBg4D5sqdDhw7s3LnTae1o0aIFcXFxrFq1yjEWHh6Or68vCxYscIxVqVKF4OBgpk6d6hgLDg6matWqxMTEcPHiRQAKFy5MREQEy5cv5/jx4wD4+vrSqlUrNm/ezJ49exzXb9euHYcOHXJ6Lho1akRSUpLTl1K1atWiUKFCTv95VaxYkUqVKjF9+nSSkpIAKF68OLVr12bRokWcPXsWAH9/fxo3bsyaNWs4dOgQAB4eHrRv354dO3Y41fJu2bIlZ86cYfXq1Y6x+vXr4+Pj4/RchIWFUapUKac64WXKlCEsLIw5c+Zw6dIlAIoUKUL9+vVZtmwZJ06cACBXrly0bNmSTZs2sXfvXsf127dvz4EDB9i0aZNjrEmTJiQkJLBs2TLHWO3atSlQoABz5sxxjFWqVMlRtzzly7mgoCBq1arFwoULHV/K5c+fn0aNGrF69WoOHz4MgKenJ+3atWP79u3s2LHDcZt3ay1PiVFw3VoOUKBAAa3lWsvTXcsBl6/lZ86ccXoutJZrLU+7lqesba5cy63wvhy0llt1LbfZbMyfPz/Hvy/XWm7dtTzl/WhOf1+utdy6a3naz0zZ+X15ylr1TyxdHuHw4cMEBQURGxtLRESEY/z1119nwYIFTi+UFBUrVuTy5cvs3bsXDw8PAD755BOGDh3qeBGk1a1bN6ZPn87ixYspUaLEDeeSkJDgCG4wu3NLlSrFwYMHc0R5hOnTp9OuXTtXT0PkhhSjYnWKUbE6xahYnWJUrE4xKlanGBWryykxeu7cOUqWLMnZs2fx9/e/4XGW3mlbuHBhPDw8HN8Spjh27BjFihVL9zqBgYF4eXk5ErZgMvtHjx4lMTERb29vx3jPnj2ZMmUKCxcuvGnCFsw3lD4+Po7fU8ojlCxZ8rYfl4iIiIiIiIiIiORc58+fz7pJW29vb2rXrk1MTAz3338/YE6LiomJoWfPnuleJzIykjFjxmCz2XB3NyV7d+zYQWBgoCNha7fbeemll/jzzz+ZP38+ZcqUue25FS9enIMHD5I3b17c3Nzu7AFmESnfAOSUXcWS9ShGxeoUo2J1ilGxOsWoWJ1iVKxOMSpWl5Ni1G63c/78eYoXL37T4yydtAXo27cvnTt3pk6dOtSrV49hw4YRHx9Ply5dAHj66acJCgpiyJAhgCl3MHz4cHr37s1LL73Ezp07ee+99+jVq5fjNnv06MGYMWOYOHEiefPmddQ+8vf3J1euXLc0L3d393/cnZvd5MuXL9u/cCRrU4yK1SlGxeoUo2J1ilGxOsWoWJ1iVKwup8TozXbYprB80vaxxx7jxIkTDBgwgKNHj1KjRg1mzJjhaE524MABx45aMOUKZs6cycsvv+woRt27d2/eeOMNxzFff/01AE2bNnW6r1GjRvHMM8/c9cckIiIiIiIiIiIiciOWT9qCqT17o3II8+fPv24sIiLCqbPhtSzce01ERERERERERERyOPd/PkRyOh8fH6Kjo50asYlYiWJUrE4xKlanGBWrU4yK1SlGxeoUo2J1itHrudm17VRERERERERERETEMrTTVkRERERERERERMRClLQVERERERERERERsRAlbUVEREREREREREQsRElbEREREREREREREQtR0lZu6ssvvyQ4OBhfX1/Cw8NZsWKFq6ck4rBw4UI6duxI8eLFcXNz46+//nL1lEQchgwZQt26dcmbNy8BAQHcf//9bN++3dXTEnH4+uuvqVatGvny5SNfvnxEREQwffp0V09L5Ibef/993Nzc6NOnj6unIgLAwIEDcXNzc/oJCQlx9bREnBw6dIgnn3ySQoUKkStXLqpWrcqqVatcPS0Rh+Dg4OvWUjc3N3r06OHqqbmckrZyQ+PGjaNv375ER0ezZs0aqlevTps2bTh+/LirpyYCQHx8PNWrV+fLL7909VRErrNgwQJ69OjBsmXLmD17NleuXKF169bEx8e7emoiAJQoUYL333+f1atXs2rVKpo3b859993H5s2bXT01keusXLmSb775hmrVqrl6KiJOqlSpwpEjRxw/ixcvdvWURBzOnDlDZGQkXl5eTJ8+nS1btvDxxx9ToEABV09NxGHlypVO6+js2bMBeOSRR1w8M9dzs9vtdldPQqwpPDycunXrMnz4cABsNhslS5bkpZde4s0333Tx7EScubm58eeff3L//fe7eioi6Tpx4gQBAQEsWLCAxo0bu3o6IukqWLAgQ4cO5bnnnnP1VEQcLly4QK1atfjqq6/473//S40aNRg2bJirpyXCwIED+euvv1i3bp2rpyKSrjfffJMlS5awaNEiV09F5Jb16dOHKVOmsHPnTtzc3Fw9HZfSTltJV2JiIqtXr6Zly5aOMXd3d1q2bMnSpUtdODMRkawpLi4OMEkxEatJTk5m7NixxMfHExER4erpiDjp0aMHHTp0cHpfKmIVO3fupHjx4pQtW5aoqCgOHDjg6imJOEyaNIk6derwyCOPEBAQQM2aNfn2229dPS2RG0pMTOSXX37h2WefzfEJW1DSVm7g5MmTJCcnU7RoUafxokWLcvToURfNSkQka7LZbPTp04fIyEjCwsJcPR0Rh40bN5InTx58fHz4z3/+w59//kloaKirpyXiMHbsWNasWcOQIUNcPRWR64SHh/Pjjz8yY8YMvv76a/bu3UujRo04f/68q6cmAsCePXv4+uuvqVChAjNnzqRbt2706tWLn376ydVTE0nXX3/9xdmzZ3nmmWdcPRVL8HT1BERERLK7Hj16sGnTJtW5E8upVKkS69atIy4ujvHjx9O5c2cWLFigxK1YwsGDB+nduzezZ8/G19fX1dMRuU67du0cf69WrRrh4eGULl2a3377TWVmxBJsNht16tThvffeA6BmzZps2rSJESNG0LlzZxfPTuR633//Pe3ataN48eKunoolaKetpKtw4cJ4eHhw7Ngxp/Fjx45RrFgxF81KRCTr6dmzJ1OmTGHevHmUKFHC1dMRceLt7U358uWpXbs2Q4YMoXr16nz22WeunpYIAKtXr+b48ePUqlULT09PPD09WbBgAZ9//jmenp4kJye7eooiTvLnz0/FihXZtWuXq6ciAkBgYOB1X8RWrlxZZTzEkvbv38+cOXN4/vnnXT0Vy1DSVtLl7e1N7dq1iYmJcYzZbDZiYmJU605E5BbY7XZ69uzJn3/+ydy5cylTpoyrpyTyj2w2GwkJCa6ehggALVq0YOPGjaxbt87xU6dOHaKioli3bh0eHh6unqKIkwsXLrB7924CAwNdPRURACIjI9m+fbvT2I4dOyhdurSLZiRyY6NGjSIgIIAOHTq4eiqWofIIckN9+/alc+fO1KlTh3r16jFs2DDi4+Pp0qWLq6cmApg3xml3Muzdu5d169ZRsGBBSpUq5cKZiZiSCGPGjGHixInkzZvXUQ/c39+fXLlyuXh2ItCvXz/atWtHqVKlOH/+PGPGjGH+/PnMnDnT1VMTASBv3rzX1QHPnTs3hQoVUn1wsYRXX32Vjh07Urp0aQ4fPkx0dDQeHh488cQTrp6aCAAvv/wyDRo04L333uPRRx9lxYoVjBw5kpEjR7p6aiJObDYbo0aNonPnznh6KlWZQs+E3NBjjz3GiRMnGDBgAEePHqVGjRrMmDHjuuZkIq6yatUqmjVr5vi9b9++AHTu3Jkff/zRRbMSMb7++msAmjZt6jQ+atQoFdYXSzh+/DhPP/00R44cwd/fn2rVqjFz5kxatWrl6qmJiGQJf//9N0888QSnTp2iSJEiNGzYkGXLllGkSBFXT00EgLp16/Lnn3/Sr18/Bg0aRJkyZRg2bBhRUVGunpqIkzlz5nDgwAGeffZZV0/FUtzsdrvd1ZMQEREREREREREREUM1bUVEREREREREREQsRElbEREREREREREREQtR0lZERERERERERETEQpS0FREREREREREREbEQJW1FRERERERERERELERJWxERERERERERERELUdJWRERERERERERExEKUtBURERERERERERGxECVtRURERETugJubGwMHDnT1NG7qmWeeITg42NXTEBEREZHbpKStiIiIiLjMxo0befjhhyldujS+vr4EBQXRqlUrvvjiC1dPLdMFBwdzzz33uHoaIiIiImIBStqKiIiIiEvExsZSp04d1q9fzwsvvMDw4cN5/vnncXd357PPPnP19EREREREXMbT1RMQERERkZzp3Xffxd/fn5UrV5I/f36ny44fP+6aSYmIiIiIWIB22oqIiIiIS+zevZsqVapcl7AFCAgIcPp91KhRNG/enICAAHx8fAgNDeXrr7++7nopJQbmz59PnTp1yJUrF1WrVmX+/PkATJgwgapVq+Lr60vt2rVZu3at0/WfeeYZ8uTJw549e2jTpg25c+emePHiDBo0CLvd/o+P6dChQzz77LMULVoUHx8fqlSpwg8//HDrT0oa+/btw83NjY8++oiRI0dSrlw5fHx8qFu3LitXrrzu+L/++ouwsDB8fX0JCwvjzz//TPd2bTYbw4YNo0qVKvj6+lK0aFG6du3KmTNnHMdER0fj7u5OTEyM03VffPFFvL29Wb9+/R09JhERERG5NdppKyIiIiIuUbp0aZYuXcqmTZsICwu76bFff/01VapU4d5778XT05PJkyfTvXt3bDYbPXr0cDp2165ddOrUia5du/Lkk0/y0Ucf0bFjR0aMGMFbb71F9+7dARgyZAiPPvoo27dvx909dS9DcnIybdu2pX79+nz44YfMmDGD6OhokpKSGDRo0A3neOzYMerXr4+bmxs9e/akSJEiTJ8+neeee45z587Rp0+fO3qexowZw/nz5+natStubm58+OGHPPjgg+zZswcvLy8AZs2axUMPPURoaChDhgzh1KlTdOnShRIlSlx3e127duXHH3+kS5cu9OrVi7179zJ8+HDWrl3LkiVL8PLy4v/+7/+YPHkyzz33HBs3biRv3rzMnDmTb7/9lsGDB1O9evU7eiwiIiIicovsIiIiIiIuMGvWLLuHh4fdw8PDHhERYX/99dftM2fOtCcmJl537MWLF68ba9Omjb1s2bJOY6VLl7YD9tjYWMfYzJkz7YA9V65c9v379zvGv/nmGztgnzdvnmOsc+fOdsD+0ksvOcZsNpu9Q4cOdm9vb/uJEycc44A9Ojra8ftzzz1nDwwMtJ88edJpTo8//rjd398/3cdw7dw7dOjg+H3v3r12wF6oUCH76dOnHeMTJ060A/bJkyc7xmrUqGEPDAy0nz171jE2a9YsO2AvXbq0Y2zRokV2wD569Gin+54xY8Z14xs3brR7e3vbn3/+efuZM2fsQUFB9jp16tivXLly08chIiIiIv+eyiOIiIiIiEu0atWKpUuXcu+997J+/Xo+/PBD2rRpQ1BQEJMmTXI6NleuXI6/x8XFcfLkSZo0acKePXuIi4tzOjY0NJSIiAjH7+Hh4QA0b96cUqVKXTe+Z8+e6+bWs2dPx99Tds4mJiYyZ86cdB+L3W7njz/+oGPHjtjtdk6ePOn4adOmDXFxcaxZs+ZWnxonjz32GAUKFHD83qhRI6d5HzlyhHXr1tG5c2f8/f0dx7Vq1YrQ0FCn2/r999/x9/enVatWTnOsXbs2efLkYd68eY5jw8LCeOedd/juu+9o06YNJ0+e5KeffsLTUyfriYiIiNxtesclIiIiIi5Tt25dJkyYQGJiIuvXr+fPP//k008/5eGHH2bdunWOpOOSJUuIjo5m6dKlXLx40ek24uLinJKVaROzgOOykiVLpjuetpYrgLu7O2XLlnUaq1ixImDqzKbnxIkTnD17lpEjRzJy5Mh0j7nT5mrXPp6UBG7KvPfv3w9AhQoVrrtupUqVnJLFO3fuJC4u7rqawTea42uvvcbYsWNZsWIF77333nVJYBERERG5O5S0FRERERGX8/b2pm7dutStW5eKFSvSpUsXfv/9d6Kjo9m9ezctWrQgJCSETz75hJIlS+Lt7c20adP49NNPsdlsTrfl4eGR7n3caNx+Cw3G/knKHJ588kk6d+6c7jHVqlW7o9vOyHnbbDYCAgIYPXp0upcXKVLE6fc9e/awc+dOADZu3Hjb9yciIiIid0ZJWxERERGxlDp16gDmtH+AyZMnk5CQwKRJk5x2naY9lT8j2Ww29uzZ49hdC7Bjxw4AgoOD071OkSJFyJs3L8nJybRs2fKuzOtGSpcuDeBIrqa1fft2p9/LlSvHnDlziIyMdCo5kR6bzcYzzzxDvnz56NOnD++99x4PP/wwDz74YMZNXkRERETSpZq2IiIiIuIS8+bNS3e36LRp0wBzaj+k7jRNe2xcXByjRo26a3MbPny44+92u53hw4fj5eVFixYt0j3ew8ODhx56iD/++INNmzZdd/mJEyfu2lwDAwOpUaMGP/30k1N939mzZ7NlyxanYx999FGSk5MZPHjwdbeTlJTE2bNnHb9/8sknxMbGMnLkSAYPHkyDBg3o1q0bJ0+evGuPRUREREQM7bQVEREREZd46aWXuHjxIg888AAhISEkJiYSGxvLuHHjCA4OpkuXLgC0bt0ab29vOnbsSNeuXblw4QLffvstAQEBjt24GcnX15cZM2bQuXNnwsPDmT59OlOnTuWtt966rnxAWu+//z7z5s0jPDycF154gdDQUE6fPs2aNWuYM2cOp0+fzvC5phgyZAgdOnSgYcOGPPvss5w+fZovvviCKlWqcOHCBcdxTZo0oWvXrgwZMoR169bRunVrvLy82LlzJ7///jufffYZDz/8MFu3bqV///4888wzdOzYEYAff/yRGjVq0L17d3777be79lhERERERDttRURERMRFPvroI5o1a8a0adPo27cvffv2ZcWKFXTv3p3ly5eTP39+wOy4HT9+PG5ubrz66quMGDGCF198kd69e9+VeXl4eDBjxgyOHj3Ka6+9xsqVK4mOjk53d2paRYsWZcWKFXTp0oUJEybQs2dPPvvsM06fPs0HH3xwV+aaom3btvz+++8kJyfTr18/JkyYwKhRoxylJtIaMWIEI0eO5Pjx47z11lv069ePuXPn8uSTTxIZGUlycjKdO3emcOHCDBs2zHG9ChUqMGTIEH7//XclbUVERETuMjd7RnReEBERERHJBp555hnGjx/vtDtVRERERCSzaaetiIiIiIiIiIiIiIUoaSsiIiIiIiIiIiJiIUraioiIiIiIiIiIiFiIatqKiIiIiIiIiIiIWIh22oqIiIiIiIiIiIhYiJK2IiIiIiIiIiIiIhaipK2IiIiIiIiIiIiIhShpKyIiIiIiIiIiImIhStqKiIiIiIiIiIiIWIiStiIiIiIiIiIiIiIWoqStiIiIiIiIiIiIiIUoaSsiIiIiIiIiIiJiIf8PanC1y0KERj8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x3000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "# 时间步（样本）索引\n",
    "samples = np.arange(y_test.shape[0])\n",
    "\n",
    "# 特征标签\n",
    "features = ['x_min', 'y_min', 'x_max', 'y_max', 'cx', 'cy', 'card_area', 'card_velocity', 'direction', 'card_conf']\n",
    "\n",
    "# 创建图形和子图\n",
    "fig, axes = plt.subplots(len(features), 1, figsize=(14, 3 * len(features)), tight_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 绘制每个特征的真实值和预测值\n",
    "for i in range(len(features)):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples, y_test[:, i], marker='o', linestyle='-', label='True', color='blue', markersize=4, linewidth=1.5)\n",
    "    ax.plot(samples, predictions[:, i], marker='x', linestyle='--', label='Predicted', color='red', markersize=6, linewidth=1.5)\n",
    "    ax.set_title(f'{features[i]}: True vs Predicted', fontsize=14)\n",
    "    ax.set_xlabel('Sample Index', fontsize=12)\n",
    "    ax.set_ylabel('Value', fontsize=12)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.7)\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 评估指标可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制训练与验证损失曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练与验证准确度曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型评估与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Sample 1 predictions: 9\n",
      "Sample 2 predictions: 9\n",
      "Sample 3 predictions: 9\n",
      "Sample 4 predictions: 4\n",
      "Sample 5 predictions: 9\n",
      "Sample 6 predictions: 9\n",
      "Sample 7 predictions: 9\n",
      "Sample 8 predictions: 9\n",
      "Sample 9 predictions: 1\n",
      "Sample 10 predictions: 9\n"
     ]
    }
   ],
   "source": [
    "# 假设有新的测试数据集\n",
    "test_samples = 10  # 测试样本数\n",
    "time_steps = 3\n",
    "num_features = 10\n",
    "test_data = np.random.rand(test_samples, time_steps, num_features)\n",
    "\n",
    "# 对测试数据进行标准化：我们使用标准化来将数据缩放到均值为0，标准差为1的范围内\n",
    "# (num_samples, time_steps, num_features) -> (num_samples * time_steps, num_features)\n",
    "scaler = StandardScaler()\n",
    "test_data_reshaped = test_data.reshape(-1, num_features)\n",
    "test_data_reshaped = scaler.fit_transform(test_data_reshaped)\n",
    "\n",
    "test_data_reshaped = scaler.transform(test_data_reshaped)\n",
    "# (num_samples * time_steps, num_features) -> (num_samples, time_steps, num_features)\n",
    "test_data = test_data_reshaped.reshape(test_samples, time_steps, num_features)\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = lstm_model.predict(test_data)\n",
    "\n",
    "# 将预测结果转换为类别标签\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# 显示每个测试样本的预测结果\n",
    "for i in range(test_samples):\n",
    "    print(f\"Sample {i+1} predictions: {predicted_classes[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索强化学习识别行为模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "# DQN（Deep Q-Network）\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # 折扣率\n",
    "        self.epsilon = 1.0   # 探索率\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return  # 如果记忆库中的样本数量不足，直接返回\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * \n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# 训练 DQN 模型以识别行为模式\n",
    "state_size = 8  # 包括位置、速度、方向等\n",
    "action_size = 3  # 假设有三种行为模式\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "# 假设有环境交互部分 (类似 gym 环境)\n",
    "for e in range(1000):\n",
    "    state = np.random.rand(1, state_size)  # 随机生成当前状态\n",
    "    action = agent.act(state)  # 选择行为\n",
    "    reward = random.random()  # 通过奖励函数优化策略\n",
    "    next_state = np.random.rand(1, state_size)  # 生成下一个状态\n",
    "    done = e == 999  # 判断是否结束\n",
    "    agent.remember(state, action, reward, next_state, done)  # 记录经验\n",
    "    agent.replay(32)  # 使用随机样本进行经验回放以训练DQN模型\n",
    "\n",
    "### 1. 多模态数据输入, 模拟传感器数据 1000个样本, 4个特征\n",
    "\n",
    "sensor_data = np.random.rand(1000, 4)  # 例如温度、光强度等"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
