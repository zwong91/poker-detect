{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8用于检测牌的位置，而LSTM则学习这些位置的时间序列模式，从而预测未来的行为。\n",
    "- You Only Look Once YOLO 接受整张图片作为输入划分为网格，每个网格预测一组边界框和对应的物体类别，这让 YOLO 很快\n",
    "- YOLO 将物体检测视为回归问题来解决，直接从图片生成边界框坐标和类别概率\n",
    "- LSTM Long Short-Term Memory 长短期记忆网络，适合时间序列预测的行为模式\n",
    "\n",
    "**这是一个相对复杂的深度学习应用，适用于人和动物行为研究中需要分析大量序列数据的场景。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "样本数num_samples: 54 poker, 每个样本time_steps: 20个时间序列, 每个时间序列num_features: 10个特征(待加入更多)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.15 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: filterpy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.4.5)\n",
      "Requirement already satisfied: opencv-python in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: pillow in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (10.4.0)\n",
      "Requirement already satisfied: numpy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: tensorboard in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (2.15.2)\n",
      "Requirement already satisfied: pandas in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tf2onnx in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.16.1)\n",
      "Requirement already satisfied: onnx in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.16.2)\n",
      "Requirement already satisfied: onnxruntime in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (1.19.2)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (1.66.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorflow-macos==2.15.0->tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: scipy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from filterpy) (1.14.1)\n",
      "Requirement already satisfied: matplotlib in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from filterpy) (3.9.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from tensorboard) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: sympy in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from onnxruntime) (1.13.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from matplotlib->filterpy) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow==2.15) (0.43.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.15 filterpy opencv-python pillow numpy scikit-learn tensorboard pandas tf2onnx onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras\n",
    "# print(tensorflow.keras.__version__)\n",
    "\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ultralytics/ultralytics.git@main\n",
      "  Cloning https://github.com/ultralytics/ultralytics.git (to revision main) to /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-req-build-dsp5gm_n\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics.git /private/var/folders/39/wllj512d2dv845j_wdx3vctc0000gn/T/pip-req-build-dsp5gm_n\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the ultralytics package from GitHub\n",
    "%pip install git+https://github.com/ultralytics/ultralytics.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "# 加载YOLOv8 模型\n",
    "def load_yolo_model():\n",
    "    os_type = platform.system()\n",
    "\n",
    "    if os_type == 'Linux':\n",
    "        # 在 Linux 上加载模型\n",
    "        yolo_model = YOLO('poker/n_pretrain/weights/best.pt')\n",
    "    elif os_type == 'Darwin':  # Darwin 是 macOS 的系统名称\n",
    "        # 在 macOS 上加载模型\n",
    "        yolo_model = YOLO(\"poker/n_pretrain/weights/pokerDetect_0821-fp-16-int8-not-nms.mlmodel\")\n",
    "    else:\n",
    "        raise OSError(f\"Unsupported operating system: {os_type}\")\n",
    "    \n",
    "    return yolo_model\n",
    "\n",
    "# 调用函数并获取 yolo_model 对象\n",
    "yolo_model = load_yolo_model()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. YOLOv8 模型检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#from sort import Sort\n",
    "#https://github.com/RizwanMunawar/yolov7-object-tracking/blob/main/sort.py\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, Layer, Masking, BatchNormalization, GRU, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='poker_analysis.log', level=logging.INFO, \n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "\n",
    "# 1. 多目标的位置\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model(frame)  # 进行目标检测\n",
    "    detections = {\n",
    "        'Tc': [], 'Td': [], 'Th': [], 'Ts': [],\n",
    "        '2c': [], '2d': [], '2h': [], '2s': [],\n",
    "        '3c': [], '3d': [], '3h': [], '3s': [],\n",
    "        '4c': [], '4d': [], '4h': [], '4s': [],\n",
    "        '5c': [], '5d': [], '5h': [], '5s': [],\n",
    "        '6c': [], '6d': [], '6h': [], '6s': [],\n",
    "        '7c': [], '7d': [], '7h': [], '7s': [],\n",
    "        '8c': [], '8d': [], '8h': [], '8s': [],\n",
    "        '9c': [], '9d': [], '9h': [], '9s': [],\n",
    "        'Ac': [], 'Ad': [], 'Ah': [], 'As': [],\n",
    "        'Jc': [], 'Jd': [], 'Jh': [], 'Js': [],\n",
    "        'Kc': [], 'Kd': [], 'Kh': [], 'Ks': [],\n",
    "        'Qc': [], 'Qd': [], 'Qh': [], 'Qs': [],\n",
    "        'SJoker': [], 'BJoker': []\n",
    "    }\n",
    "    for result in results:\n",
    "        for obj in result.boxes: # 提取检测结果\n",
    "            if obj.conf.item() > 0.5:\n",
    "                # tensor to numpy\n",
    "                #bbox = obj.xyxy[0].cpu().numpy()\n",
    "                #x_min, y_min, x_max, y_max = obj.xyxy[0]\n",
    "                bbox = obj.xyxy[0].cpu().numpy().astype(int)\n",
    "                x_min, y_min, x_max, y_max = bbox\n",
    "                \n",
    "                # roi = frame[y_min:y_max, x_min:x_max]\n",
    "                # roi_resized = cv2.resize(roi, (64, 64))\n",
    "                \n",
    "                # 数据增强: 随机翻转和旋转\n",
    "                # if np.random.rand() > 0.5:\n",
    "                #     roi_resized = cv2.flip(roi_resized, 1)\n",
    "                # angle = np.random.uniform(-10, 10)\n",
    "                # M = cv2.getRotationMatrix2D((32, 32), angle, 1.0)\n",
    "                # roi_resized = cv2.warpAffine(roi_resized, M, (64, 64))\n",
    "                # roi_tensor = torch.tensor(roi_resized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "                #张量的形状变为 (1, 通道, 高度, 宽度)\n",
    "                #print(\"ROI Tensor:\", roi_tensor)\n",
    "                \n",
    "                #x_center = (x_min + x_max) / 2\n",
    "                #y_center = (y_min + y_max) / 2\n",
    "                # Get the boxes center coordinates (x, y), width (w), and height (h) size\n",
    "                x, y, w, h = obj.xywh[0].cpu()\n",
    "                speed = np.sqrt((w ** 2 + h ** 2))\n",
    "                conf = obj.conf.item()\n",
    "                # labels names\n",
    "                class_id = int(obj.cls.item())\n",
    "                class_name = yolo_model.names[class_id]\n",
    "                if class_name in detections:\n",
    "                    detections[class_name].append([x_min, y_min, x_max, y_max, conf])\n",
    "\n",
    "    return detections\n",
    "\n",
    "# 2. 多模态输入包括上面的视频数据和其他传感器数据\n",
    "#TODO: 假设我们有来自不同传感器的数据，Raspberry Pi 控制挂件装置，读取和处理传感器数据\n",
    "sensor_data = np.random.rand(1000, 5)  # 例如溫度、光強度等\n",
    "\n",
    "# 3. 同步处理多模态数据\n",
    "def synchronize_data(detections, sensor_data):\n",
    "    # hstack 将目标的检测数据与传感器数据在特征层面上拼接在一起，形成一个多模态输入矩阵\n",
    "    return np.hstack([detections, sensor_data[:len(detections), :]])\n",
    "\n",
    "# 获取同步后的数据\n",
    "#sync_data = synchronize_data(all_detections, sensor_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 卡尔曼滤波器精确追踪进行位置更新和噪声过滤\n",
    "\n",
    "https://medium.com/@mosesdaudu001/object-detection-tracking-with-yolov8-and-sort-algorithm-363be8bc0806\n",
    "\n",
    "\n",
    "Predicting future positions of moving objects is indeed a complex task that typically involves motion prediction algorithms such as Kalman filters \n",
    "or more advanced techniques like deep learning-based trajectory prediction.\n",
    "预测移动物体的未来位置确实是一项复杂的任务，通常涉及运动预测算法（例如卡尔曼滤波器）或更先进的技术（例如基于深度学习的轨迹预测）。\n",
    "\n",
    "YOLO's tracking algorithm already incorporates Kalman filtering\n",
    "YOLO 的跟踪算法已经包含卡尔曼滤波器， 提取每个跟踪对象的当前状态（位置和速度），然后多次使用卡尔曼滤波器来预测其未来状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 追踪所有目标对象\\ntracked_positions = []\\nfor det_list in all_detections.values():\\n    tracked_position = [track_objects(d) for d in det_list]\\n    tracked_positions.append(tracked_position)\\n    \\ntracked_positions\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from filterpy.kalman import KalmanFilter\n",
    "# DeepSORT\n",
    "\n",
    "def initialize_kalman_filter():\n",
    "    kf = KalmanFilter(dim_x=7, dim_z=4)  # 7 个状态变量，4 个观测变量\n",
    "    kf.F = np.array([[1,0,0,0,1,0,0],\n",
    "                     [0,1,0,0,0,1,0],\n",
    "                     [0,0,1,0,0,0,1],\n",
    "                     [0,0,0,1,0,0,0],\n",
    "                     [0,0,0,0,1,0,0],\n",
    "                     [0,0,0,0,0,1,0],\n",
    "                     [0,0,0,0,0,0,1]])  # 状态转移矩阵\n",
    "    kf.H = np.array([[1,0,0,0,0,0,0],\n",
    "                     [0,1,0,0,0,0,0],\n",
    "                     [0,0,1,0,0,0,0],\n",
    "                     [0,0,0,1,0,0,0]])  # 观测矩阵\n",
    "    return kf\n",
    "\n",
    "# 初始化卡尔曼滤波器\n",
    "kf = initialize_kalman_filter()\n",
    "\n",
    "def track_objects(detection):\n",
    "    z = np.array([detection[0], detection[1], detection[2], detection[3]])  # 观测变量\n",
    "    kf.predict()  # 预测下一步\n",
    "    kf.update(z)  # 更新滤波\n",
    "    return kf.x[:4]  # 返回更新后的位置信息\n",
    "\"\"\"\n",
    "# 追踪所有目标对象\n",
    "tracked_positions = []\n",
    "for det_list in all_detections.values():\n",
    "    tracked_position = [track_objects(d) for d in det_list]\n",
    "    tracked_positions.append(tracked_position)\n",
    "    \n",
    "tracked_positions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 将视频帧或图像序列转换为LSTM模型的输入格式\n",
    "** 每一个时间点的数据都包括前n个时间步长的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 计算欧几里得距离\n",
    "def calculate_distance(box1, box2):\n",
    "    x1_center = (box1[0] + box1[2]) / 2\n",
    "    y1_center = (box1[1] + box1[3]) / 2\n",
    "    x2_center = (box2[0] + box2[2]) / 2\n",
    "    y2_center = (box2[1] + box2[3]) / 2\n",
    "    return np.sqrt((x1_center - x2_center)**2 + (y1_center - y2_center)**2)\n",
    "\n",
    "# 计算检测框的面积\n",
    "def calculate_area(box):\n",
    "    return (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "# 计算两个检测框之间的速度和角度\n",
    "def calculate_velocity_and_angle(previous_box, current_box, time_interval):\n",
    "    # 计算中心点\n",
    "    previous_center = [(previous_box[0] + previous_box[2]) / 2, (previous_box[1] + previous_box[3]) / 2]\n",
    "    current_center = [(current_box[0] + current_box[2]) / 2, (current_box[1] + current_box[3]) / 2]\n",
    "    \n",
    "    # 计算距离\n",
    "    distance = np.sqrt((current_center[0] - previous_center[0])**2 + (current_center[1] - previous_center[1])**2)\n",
    "    \n",
    "    # 计算速度\n",
    "    velocity = distance / time_interval\n",
    "    \n",
    "    # 计算角度(弧度), 表示检测框的运动方向\n",
    "    direction = np.arctan2(current_center[1] - previous_center[1], current_center[0] - previous_center[0])\n",
    "    \n",
    "    return velocity, direction\n",
    "\n",
    "                        \n",
    "def prepare_complex_sequence_data(detected_objects_list, window_size=5, time_interval=1.0):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # TODO: 目前是追踪54个样本的轨迹, 计算同一帧的两个目标的关联关系?\n",
    "    for key in detected_objects_list:\n",
    "        card_detections = detected_objects_list[key]\n",
    "        print(f\"Key: {key}, vector len: {len(card_detections)}, Card Detections: {card_detections}\")\n",
    "        for i in range(len(card_detections) - window_size):\n",
    "            input_seq = []\n",
    "            for j in range(window_size):\n",
    "                card_boxes = card_detections[i + j] \n",
    "                # 距離、面積、速度和置信度特徵\n",
    "                if card_boxes:\n",
    "                    cx = (card_boxes[0] + card_boxes[2]) / 2\n",
    "                    cy = (card_boxes[1] + card_boxes[3]) / 2\n",
    "                \n",
    "                    card_area = calculate_area(card_boxes)\n",
    "                    card_conf = card_boxes[4]  # 假设置信度在检测框的第五个元素\n",
    "                    \n",
    "                    if i > 0:  # 速度計算需要前一個時間點的數據\n",
    "                        prev_card_box = card_detections[i + j - 1]\n",
    "                        card_velocity, direction = calculate_velocity_and_angle(prev_card_box, card_boxes, time_interval)\n",
    "                    else:\n",
    "                        card_velocity = 0\n",
    "                        direction = 0\n",
    "                    \n",
    "                    # 特征序列\n",
    "                    input_seq.append([cx, cy])\n",
    "                else:\n",
    "                    input_seq.append([0, 0])\n",
    "            \n",
    "            # X 作为LSTM 的输入向量\n",
    "            #seq = np.array(input_seq).flatten()\n",
    "            X.append(input_seq)\n",
    "            # y 作为LSTM 目标值, 构建 y 的 7 个特征, 下一frame的真实位置作为训练时的目标值\n",
    "            next_card_boxes = card_detections[i + window_size]\n",
    "            if next_card_boxes:\n",
    "                next_card_area = calculate_area(next_card_boxes)\n",
    "                cx = (next_card_boxes[0] + next_card_boxes[2]) / 2\n",
    "                cy = (next_card_boxes[1] + next_card_boxes[3]) / 2\n",
    "                next_card_conf = next_card_boxes[4]\n",
    "                if i + window_size > 0:\n",
    "                    prev_next_card_box = card_detections[i + window_size - 1]\n",
    "                    next_card_velocity, direction = calculate_velocity_and_angle(prev_next_card_box, next_card_boxes, time_interval)\n",
    "                else:\n",
    "                    next_card_velocity = 0\n",
    "                    direction = 0\n",
    "                y.append([cx, cy])\n",
    "            else:\n",
    "                y.append([0, 0])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, frame_index):\n",
    "    res = detect_objects(frame)\n",
    "    height, width = frame.shape[:2]\n",
    "    if width == 0 or height == 0:\n",
    "        return frame_index, {}  # 返回空结果，避免除以零\n",
    "\n",
    "    return frame_index, res\n",
    "\n",
    "def load_video_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    all_detections = {\n",
    "        'Tc': [], 'Td': [], 'Th': [], 'Ts': [],\n",
    "        '2c': [], '2d': [], '2h': [], '2s': [],\n",
    "        '3c': [], '3d': [], '3h': [], '3s': [],\n",
    "        '4c': [], '4d': [], '4h': [], '4s': [],\n",
    "        '5c': [], '5d': [], '5h': [], '5s': [],\n",
    "        '6c': [], '6d': [], '6h': [], '6s': [],\n",
    "        '7c': [], '7d': [], '7h': [], '7s': [],\n",
    "        '8c': [], '8d': [], '8h': [], '8s': [],\n",
    "        '9c': [], '9d': [], '9h': [], '9s': [],\n",
    "        'Ac': [], 'Ad': [], 'Ah': [], 'As': [],\n",
    "        'Jc': [], 'Jd': [], 'Jh': [], 'Js': [],\n",
    "        'Kc': [], 'Kd': [], 'Kh': [], 'Ks': [],\n",
    "        'Qc': [], 'Qd': [], 'Qh': [], 'Qs': [],\n",
    "        'SJoker': [], 'BJoker': []\n",
    "    }\n",
    "    frames = []\n",
    "    frame_index = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append((frame_index, frame))\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    results = [None] * len(frames)  # 用于存储结果的列表，保持顺序\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future_to_frame = {executor.submit(process_frame, frame, idx): idx for idx, frame in frames}\n",
    "        for future in as_completed(future_to_frame):\n",
    "            idx, res = future.result()\n",
    "            results[idx] = res  # 按照索引存储结果\n",
    "\n",
    "    #FIXME: 合并结果前过滤掉异常值的结果\n",
    "    for idx, res in enumerate(results):\n",
    "        logging.info(f'#: {idx}, result: {res}')\n",
    "        for key in res.keys():\n",
    "            all_detections[key].extend(res[key])\n",
    "    return all_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用 Keras库來构建LSTM 模型与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Custom Attention Layer\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = tf.nn.tanh(tf.matmul(x, self.W) + self.b)  # Energy\n",
    "        a = tf.nn.softmax(e, axis=1)  # Attention weights\n",
    "        output = tf.reduce_sum(x * a, axis=1)  # Weighted sum of input features\n",
    "        return output\n",
    "\n",
    "# 构建一个更复杂的双向LSTM模型，同时引入注意力机制, 使用检测到的数据进行训练。模型包括多层LSTM、Dropout、BatchNormalization等层\n",
    "# input_shape=(time_steps, num_features)\n",
    "def create_bilstm_attention_model(input_shape, dropout_rate=0.3, l1=0.01, l2=0.01):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    masked_inputs = Masking(mask_value=0.0)(inputs)  # Add a Masking layer\n",
    "    lstm_out = Bidirectional(LSTM(256, return_sequences=True, kernel_regularizer=l1_l2(l1=l1, l2=l2)))(masked_inputs)\n",
    "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "\n",
    "    lstm_out = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l1_l2(l1=l1, l2=l2)))(lstm_out)\n",
    "    # 添加 Dropout 和 BatchNormalization 层\n",
    "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "\n",
    "    lstm_out = Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l1_l2(l1=l1, l2=l2)))(lstm_out)\n",
    "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "    \n",
    "    # 添加 GRU 层，units=64\n",
    "    gru_out = GRU(units=64, return_sequences=True, kernel_regularizer=l1_l2(l1=l1, l2=l2))(lstm_out)\n",
    "    gru_out = Dropout(dropout_rate)(gru_out)\n",
    "    gru_out = BatchNormalization()(gru_out)\n",
    "\n",
    "    # Correct usage of Attention layer\n",
    "    attention = Attention()(gru_out)\n",
    "\n",
    "    # 全连接层，将 LSTM 的输出映射到32个神经元，并应用 ReLU 激活函数来引入非线性\n",
    "    dense_out = Dense(32, activation='relu', kernel_regularizer=l1_l2(l1=l1, l2=l2))(attention)\n",
    "    \n",
    "    feature_len = input_shape[1]\n",
    "    # RepeatVector 和 TimeDistributed 层\n",
    "    # \"one-to-many\" 的序列预测。RepeatVector 层将输入重复 5 次，TimeDistributed 层将 Dense 层的计算分布到每个时间步上。\n",
    "    # 最终输出的形状将是 (batch_size, 5, feature_len)\n",
    "    #repeat_out = RepeatVector(5)(dense_out)\n",
    "    #outputs = TimeDistributed(Dense(units=feature_len, activation='relu'))(repeat_out)\n",
    "    \n",
    "    outputs = Dense(feature_len, kernel_regularizer=l1_l2(l1=l1, l2=l2))(dense_out)  # The final Dense layer outputs 5 values 最后的全连接层，输出5个值\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # 使用Adam优化器(梯度下降优化)和均方误差（MSE）作为损失函数，衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    # 显示模型摘要\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # 均方根误差（RMSE）是一种用于衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好。 \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    # 平均绝对误差（MAE）\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # R^2 分数\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, mse, mae, r2\n",
    "\n",
    "def evaluate_inverse_performance(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 反归一化预测结果和真实值\n",
    "    y_pred_inverse = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_inverse = scaler_y.inverse_transform(y_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "    # 均方根误差（RMSE）是一种用于衡量预测值与实际值之间差异的指标，值越小，表示模型的预测效果越好。 \n",
    "    rmse = np.sqrt(mean_squared_error(y_test_inverse, y_pred_inverse))\n",
    "    # 平均绝对误差（MAE）\n",
    "    mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "    # R^2 分数\n",
    "    r2 = r2_score(y_test_inverse, y_pred_inverse)\n",
    "    \n",
    "    return rmse, mse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coremltools==7.2 in /usr/local/lib/python3.10/dist-packages (7.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (1.26.2)\n",
      "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (1.12)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (4.66.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (23.2)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (23.1.0)\n",
      "Requirement already satisfied: cattrs in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (24.1.0)\n",
      "Requirement already satisfied: pyaml in /usr/local/lib/python3.10/dist-packages (from coremltools==7.2) (24.7.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools==7.2) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools==7.2) (4.8.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->coremltools==7.2) (6.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->coremltools==7.2) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# coremltools 7 以上版本不需要安装 onnx-coreml\n",
    "%pip install coremltools==7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coremltools in /usr/local/lib/python3.10/dist-packages (7.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.26.2)\n",
      "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from coremltools) (1.12)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from coremltools) (4.66.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from coremltools) (23.2)\n",
      "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from coremltools) (23.1.0)\n",
      "Requirement already satisfied: cattrs in /usr/local/lib/python3.10/dist-packages (from coremltools) (24.1.0)\n",
      "Requirement already satisfied: pyaml in /usr/local/lib/python3.10/dist-packages (from coremltools) (24.7.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from cattrs->coremltools) (4.8.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml->coremltools) (6.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->coremltools) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U coremltools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 将数据集拆分为训练集和测试集，训练LSTM模型并选择最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = 'videos/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = 'videos/debug/quick'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频文件路径列表: ['videos/debug/quick/annotated_IMG_0036.mp4', 'videos/debug/quick/IMG_0036.MOV']\n",
      "\n",
      "0: 640x640 (no detections), 33.6ms\n",
      "Speed: 4.3ms preprocess, 33.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.6ms\n",
      "Speed: 3.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.2ms\n",
      "Speed: 2.9ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.8ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 3.0ms preprocess, 11.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.6ms preprocess, 10.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 3.2ms preprocess, 14.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 4.9ms preprocess, 11.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 5.5ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 10.5ms\n",
      "Speed: 9.9ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 15.5ms\n",
      "Speed: 3.8ms preprocess, 15.5ms inference, 19.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 14.6ms\n",
      "Speed: 5.6ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.1ms\n",
      "Speed: 12.2ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.3ms\n",
      "Speed: 3.8ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.9ms\n",
      "Speed: 9.6ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 3.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.0ms\n",
      "Speed: 2.6ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 10.2ms\n",
      "Speed: 3.0ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 10.0ms\n",
      "Speed: 13.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 10.5ms\n",
      "Speed: 2.7ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.8ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3s, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 48.5ms\n",
      "Speed: 3.1ms preprocess, 48.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 10.5ms preprocess, 14.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 10.0ms preprocess, 12.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.1ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 SJoker, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 11.4ms\n",
      "Speed: 3.3ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 11.2ms\n",
      "Speed: 2.9ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 13.9ms\n",
      "Speed: 3.1ms preprocess, 13.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 11.8ms\n",
      "Speed: 2.3ms preprocess, 11.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 12.4ms\n",
      "Speed: 2.4ms preprocess, 12.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 13.0ms\n",
      "Speed: 2.4ms preprocess, 13.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.8ms\n",
      "Speed: 5.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 7ds, 1 8h, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 7ds, 1 8h, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 7ds, 1 8h, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 7ds, 1 8h, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 15.3ms\n",
      "Speed: 43.9ms preprocess, 15.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.3ms\n",
      "Speed: 2.7ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 9.9ms\n",
      "Speed: 3.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.4ms\n",
      "Speed: 2.4ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.2ms\n",
      "Speed: 3.2ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.5ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.6ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jh, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qh, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 10.9ms\n",
      "Speed: 2.8ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 8d, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 11.2ms\n",
      "Speed: 7.8ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kd, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kd, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kd, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kd, 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 10.7ms\n",
      "Speed: 3.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 13.5ms\n",
      "Speed: 2.9ms preprocess, 13.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 9.8ms\n",
      "Speed: 3.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 7.7ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 52.1ms\n",
      "Speed: 2.5ms preprocess, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 13.9ms\n",
      "Speed: 3.4ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 15.5ms\n",
      "Speed: 5.9ms preprocess, 15.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ks, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ks, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 5h, 1 Ks, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 18.4ms\n",
      "Speed: 2.4ms preprocess, 18.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7h, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 4d, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 10.1ms\n",
      "Speed: 4.7ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kh, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kh, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kh, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kh, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kh, 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 9c, 1 Kh, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kh, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Khs, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Khs, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Khs, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 Khs, 9.7ms\n",
      "Speed: 5.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 2 8ds, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 8ds, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 2 8hs, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 8hs, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 8h, 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 8hs, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 8hs, 15.0ms\n",
      "Speed: 2.4ms preprocess, 15.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 8hs, 1 9h, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 8hs, 1 9h, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 8h, 10.3ms\n",
      "Speed: 3.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8h, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8h, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8h, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8h, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8h, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8h, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 8h, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 11.7ms\n",
      "Speed: 8.4ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 8s, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 1 8s, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 1 8s, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 1 8s, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 10.2ms\n",
      "Speed: 7.1ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 1 8s, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 1 8s, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 1 8s, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 1 8s, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.9ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Qc, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 11.9ms\n",
      "Speed: 3.7ms preprocess, 11.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 11.2ms\n",
      "Speed: 5.8ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 11.7ms\n",
      "Speed: 2.8ms preprocess, 11.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 BJoker, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 1 8c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.4ms\n",
      "Speed: 2.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 1 8c, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 8c, 10.6ms\n",
      "Speed: 5.5ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 1 8c, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 1 8c, 14.4ms\n",
      "Speed: 2.3ms preprocess, 14.4ms inference, 9.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 1 8c, 13.5ms\n",
      "Speed: 2.7ms preprocess, 13.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 1 8c, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 1 8c, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.9ms\n",
      "Speed: 2.2ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 1 Kh, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Kh, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Kh, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 1 Kh, 10.4ms\n",
      "Speed: 8.0ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Kh, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 Kh, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Kh, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 10.3ms\n",
      "Speed: 2.8ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 9.5ms\n",
      "Speed: 2.2ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Kh, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 10.3ms\n",
      "Speed: 8.7ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 9.3ms\n",
      "Speed: 2.5ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 9.7ms\n",
      "Speed: 3.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 10.4ms\n",
      "Speed: 8.6ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 2.4ms preprocess, 12.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.9ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.6ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.7ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.7ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 11.1ms\n",
      "Speed: 3.4ms preprocess, 11.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 9.9ms\n",
      "Speed: 3.1ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.8ms\n",
      "Speed: 3.6ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 12.9ms\n",
      "Speed: 2.4ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.7ms\n",
      "Speed: 3.0ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.8ms\n",
      "Speed: 13.2ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 11.0ms\n",
      "Speed: 3.6ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 1 Ks, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 11.9ms\n",
      "Speed: 5.3ms preprocess, 11.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 12.9ms\n",
      "Speed: 5.1ms preprocess, 12.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 12.2ms\n",
      "Speed: 4.5ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 10.4ms\n",
      "Speed: 3.6ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 11.5ms\n",
      "Speed: 6.4ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 10.6ms\n",
      "Speed: 4.1ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 11.6ms\n",
      "Speed: 2.7ms preprocess, 11.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.3ms\n",
      "Speed: 3.9ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 4.5ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.8ms\n",
      "Speed: 3.0ms preprocess, 11.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.5ms\n",
      "Speed: 2.7ms preprocess, 11.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 Kc, 1 Ks, 11.9ms\n",
      "Speed: 2.2ms preprocess, 11.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 11.4ms\n",
      "Speed: 2.5ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.9ms\n",
      "Speed: 2.5ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 11.0ms\n",
      "Speed: 3.4ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.6ms\n",
      "Speed: 8.7ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 7s, 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7c, 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 7c, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.5ms\n",
      "Speed: 3.3ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.6ms\n",
      "Speed: 2.9ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.7ms\n",
      "Speed: 3.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.3ms\n",
      "Speed: 3.2ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.0ms\n",
      "Speed: 2.4ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 18.9ms\n",
      "Speed: 2.8ms preprocess, 18.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.0ms\n",
      "Speed: 3.4ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 12.1ms\n",
      "Speed: 2.6ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.0ms\n",
      "Speed: 2.9ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.6ms\n",
      "Speed: 2.4ms preprocess, 10.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 11.0ms\n",
      "Speed: 2.3ms preprocess, 11.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 6.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 10.9ms\n",
      "Speed: 2.3ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.9ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 3.1ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 4.9ms preprocess, 11.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.7ms\n",
      "Speed: 3.2ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 3.9ms preprocess, 10.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 7.1ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.2ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 10.5ms preprocess, 11.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.9ms preprocess, 11.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 6.1ms preprocess, 11.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.5ms\n",
      "Speed: 25.2ms preprocess, 17.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 3.1ms preprocess, 11.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.7ms preprocess, 11.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 9.6ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.7ms preprocess, 11.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 3.9ms preprocess, 11.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 3.4ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.7ms preprocess, 11.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 11.5ms preprocess, 10.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.1ms\n",
      "Speed: 3.1ms preprocess, 13.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.0ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 3.1ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 3.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 8.3ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 4.9ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 11.6ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.5ms preprocess, 11.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.5ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.9ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 10.6ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.0ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.6ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 7.6ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 39.4ms\n",
      "Speed: 13.6ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.9ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.5ms preprocess, 10.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.6ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 9.7ms preprocess, 13.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.1ms\n",
      "Speed: 2.5ms preprocess, 16.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.3ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 3.9ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.6ms preprocess, 10.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.1ms\n",
      "Speed: 9.4ms preprocess, 14.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.8ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 8.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 33.9ms\n",
      "Speed: 18.4ms preprocess, 33.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.3ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 7.2ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20.9ms\n",
      "Speed: 2.5ms preprocess, 20.9ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 23.7ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 10.4ms preprocess, 10.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.1ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 8.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 5.9ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 2.8ms preprocess, 11.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 47.2ms\n",
      "Speed: 2.7ms preprocess, 47.2ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 10.1ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 6.7ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 9.3ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.8ms\n",
      "Speed: 2.5ms preprocess, 14.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.4ms\n",
      "Speed: 10.0ms preprocess, 14.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 3.3ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 2.0ms preprocess, 11.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 2.3ms preprocess, 11.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.5ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.6ms\n",
      "Speed: 5.4ms preprocess, 11.6ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 11.7ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.0ms\n",
      "Speed: 1.7ms preprocess, 11.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.2ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.7ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kc, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 1.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.2ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 1.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 28.1ms\n",
      "Speed: 15.0ms preprocess, 28.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.7ms\n",
      "Speed: 2.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.2ms\n",
      "Speed: 1.4ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 10.0ms\n",
      "Speed: 3.1ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 1.9ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 1.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.8ms\n",
      "Speed: 1.4ms preprocess, 9.8ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 14.2ms\n",
      "Speed: 1.9ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8c, 1 Kc, 9.9ms\n",
      "Speed: 3.2ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 9.5ms\n",
      "Speed: 2.0ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 8c, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.9ms\n",
      "Speed: 1.4ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.4ms\n",
      "Speed: 2.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.8ms\n",
      "Speed: 1.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 11.2ms\n",
      "Speed: 4.8ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 54.2ms\n",
      "Speed: 2.0ms preprocess, 54.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 14.2ms\n",
      "Speed: 3.0ms preprocess, 14.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 3s, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2s, 1 As, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 As, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.5ms\n",
      "Speed: 2.2ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 Ac, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Td, 1 9s, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.2ms\n",
      "Speed: 1.4ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.2ms\n",
      "Speed: 1.5ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 10.0ms\n",
      "Speed: 1.4ms preprocess, 10.0ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 15.2ms\n",
      "Speed: 34.2ms preprocess, 15.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Tc, 1 9s, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 10.0ms\n",
      "Speed: 1.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.8ms\n",
      "Speed: 1.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.8ms\n",
      "Speed: 1.9ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7d, 1 8h, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 17.7ms\n",
      "Speed: 1.5ms preprocess, 17.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.8ms\n",
      "Speed: 1.6ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Qh, 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2c, 1 Jd, 33.8ms\n",
      "Speed: 13.2ms preprocess, 33.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 9.6ms\n",
      "Speed: 2.1ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 9.4ms\n",
      "Speed: 2.0ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 12.6ms\n",
      "Speed: 5.0ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Jd, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 10.2ms\n",
      "Speed: 2.2ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6d, 1 Kd, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 10.0ms\n",
      "Speed: 1.7ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 Kd, 9.8ms\n",
      "Speed: 1.7ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.5ms\n",
      "Speed: 1.9ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2d, 1 5h, 9.9ms\n",
      "Speed: 9.9ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5h, 1 Ad, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 11.6ms\n",
      "Speed: 34.4ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ad, 1 Jh, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 9.8ms\n",
      "Speed: 4.8ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 Ks, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5c, 1 7h, 9.7ms\n",
      "Speed: 1.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.4ms\n",
      "Speed: 1.9ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 7h, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3h, 1 4d, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 Ad, 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 10.3ms\n",
      "Speed: 2.0ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 14.4ms\n",
      "Speed: 3.2ms preprocess, 14.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4d, 1 As, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9d, 1 9s, 1 As, 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 10.1ms\n",
      "Speed: 4.0ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 9.5ms\n",
      "Speed: 2.1ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 9c, 1 Qd, 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 9.4ms\n",
      "Speed: 2.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Kh, 1 Qd, 9.7ms\n",
      "Speed: 1.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 Kh, 31.3ms\n",
      "Speed: 13.2ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.5ms\n",
      "Speed: 1.9ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8d, 1 9d, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 8d, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 10.3ms\n",
      "Speed: 2.1ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6h, 1 9h, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.7ms\n",
      "Speed: 1.8ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 11.7ms\n",
      "Speed: 2.6ms preprocess, 11.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 15.8ms\n",
      "Speed: 2.3ms preprocess, 15.8ms inference, 8.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 17.4ms\n",
      "Speed: 2.5ms preprocess, 17.4ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 9h, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ts, 1 5d, 11.3ms\n",
      "Speed: 2.4ms preprocess, 11.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5d, 1 6s, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 5d, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 5d, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8d, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 10.9ms\n",
      "Speed: 2.4ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 2h, 1 8s, 9.9ms\n",
      "Speed: 6.1ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 51.9ms\n",
      "Speed: 9.0ms preprocess, 51.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.6ms\n",
      "Speed: 2.7ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 10.0ms\n",
      "Speed: 3.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 8s, 1 Qc, 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 8s, 10.7ms\n",
      "Speed: 2.4ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.9ms\n",
      "Speed: 4.0ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 9.3ms\n",
      "Speed: 2.4ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 12.4ms\n",
      "Speed: 35.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 11.9ms\n",
      "Speed: 2.4ms preprocess, 11.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3d, 1 BJoker, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 10.5ms\n",
      "Speed: 2.5ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 6c, 1 7s, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.5ms\n",
      "Speed: 2.4ms preprocess, 10.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 11.5ms\n",
      "Speed: 2.5ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.8ms\n",
      "Speed: 3.9ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 14.5ms\n",
      "Speed: 31.7ms preprocess, 14.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 6c, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 3c, 1 4h, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.9ms\n",
      "Speed: 6.8ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 41.3ms\n",
      "Speed: 8.3ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4h, 1 Ah, 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 11.0ms\n",
      "Speed: 2.5ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 12.2ms\n",
      "Speed: 2.4ms preprocess, 12.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 5s, 1 Ah, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 29.3ms\n",
      "Speed: 2.3ms preprocess, 29.3ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 11.4ms\n",
      "Speed: 6.5ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Ah, 1 Qs, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 10.0ms\n",
      "Speed: 3.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Qs, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 15.1ms\n",
      "Speed: 6.7ms preprocess, 15.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 11.8ms\n",
      "Speed: 14.6ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 12.9ms\n",
      "Speed: 6.3ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 71.4ms\n",
      "Speed: 2.9ms preprocess, 71.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 14.1ms\n",
      "Speed: 7.2ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 14.8ms\n",
      "Speed: 5.0ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 Js, 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Jc, 1 SJoker, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 47.1ms\n",
      "Speed: 2.3ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 10.1ms\n",
      "Speed: 3.1ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 7c, 1 SJoker, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.5ms\n",
      "Speed: 3.1ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.6ms\n",
      "Speed: 3.5ms preprocess, 10.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 14.2ms\n",
      "Speed: 36.2ms preprocess, 14.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4s, 1 7c, 10.4ms\n",
      "Speed: 3.9ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.7ms\n",
      "Speed: 4.0ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.1ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.3ms\n",
      "Speed: 2.4ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 15.9ms\n",
      "Speed: 6.5ms preprocess, 15.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 11.7ms\n",
      "Speed: 2.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 19.2ms\n",
      "Speed: 25.5ms preprocess, 19.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.2ms\n",
      "Speed: 2.4ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 51.5ms\n",
      "Speed: 4.6ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 1 7c, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 10.3ms\n",
      "Speed: 3.8ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.4ms\n",
      "Speed: 2.5ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 12.7ms\n",
      "Speed: 2.1ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 9.9ms\n",
      "Speed: 3.8ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 51.6ms\n",
      "Speed: 3.2ms preprocess, 51.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 4c, 11.7ms\n",
      "Speed: 2.9ms preprocess, 11.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.8ms\n",
      "Speed: 2.7ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.8ms\n",
      "Speed: 2.3ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 10.0ms\n",
      "Speed: 2.3ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.8ms\n",
      "Speed: 10.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.4ms\n",
      "Speed: 2.3ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 11.2ms\n",
      "Speed: 2.4ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.5ms\n",
      "Speed: 2.1ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Th, 11.0ms\n",
      "Speed: 30.5ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 2.6ms preprocess, 11.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 17.0ms\n",
      "Speed: 2.6ms preprocess, 17.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.8ms\n",
      "Speed: 2.5ms preprocess, 11.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.7ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.7ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.2ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 3.6ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.6ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 3.0ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 7.3ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.8ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.8ms\n",
      "Speed: 27.2ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.2ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 9.0ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.7ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.6ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.8ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 7.1ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.4ms\n",
      "Speed: 37.4ms preprocess, 16.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 9.1ms preprocess, 11.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.2ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 6.6ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.9ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 6.8ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.8ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.4ms\n",
      "Speed: 19.7ms preprocess, 32.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 9.5ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.2ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.7ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 9.2ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.4ms\n",
      "Speed: 2.4ms preprocess, 11.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 16.5ms\n",
      "Speed: 39.0ms preprocess, 16.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 3.9ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.9ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.5ms preprocess, 10.6ms inference, 9.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.3ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.8ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.6ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.7ms\n",
      "Speed: 34.3ms preprocess, 14.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.1ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 3.3ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 7.3ms preprocess, 10.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.5ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.4ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 5.2ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 5.4ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19.6ms\n",
      "Speed: 27.9ms preprocess, 19.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.6ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.3ms\n",
      "Speed: 2.4ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.8ms preprocess, 11.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 40.3ms preprocess, 13.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 9.4ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.6ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 3.2ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.8ms\n",
      "Speed: 9.3ms preprocess, 10.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.1ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.9ms\n",
      "Speed: 2.7ms preprocess, 12.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.7ms\n",
      "Speed: 23.7ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.7ms\n",
      "Speed: 2.7ms preprocess, 10.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 4.9ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.6ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.6ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 9.8ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 2.3ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.4ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 35.6ms\n",
      "Speed: 15.8ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 3.5ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.5ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.7ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.4ms preprocess, 9.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.8ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.6ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.9ms\n",
      "Speed: 2.6ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.8ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 8.3ms preprocess, 10.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.6ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.1ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.3ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 5.2ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 13.6ms\n",
      "Speed: 39.9ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.2ms preprocess, 11.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.9ms preprocess, 10.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 9.1ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.6ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 1.8ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.9ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 41.8ms\n",
      "Speed: 11.9ms preprocess, 41.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.5ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.7ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 12.0ms\n",
      "Speed: 8.2ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.4ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.3ms preprocess, 10.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.5ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.0ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 5.3ms preprocess, 10.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.4ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.9ms\n",
      "Speed: 2.5ms preprocess, 11.9ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 14.5ms\n",
      "Speed: 16.7ms preprocess, 14.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 1.9ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.2ms\n",
      "Speed: 2.6ms preprocess, 11.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.7ms preprocess, 10.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.6ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.6ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 4.1ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 2.5ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 3.1ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 3.3ms preprocess, 10.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.8ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.9ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.3ms\n",
      "Speed: 1.8ms preprocess, 11.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.5ms\n",
      "Speed: 25.6ms preprocess, 11.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.6ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11.1ms\n",
      "Speed: 3.2ms preprocess, 11.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.3ms\n",
      "Speed: 2.5ms preprocess, 10.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.5ms\n",
      "Speed: 10.0ms preprocess, 10.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.4ms\n",
      "Speed: 2.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.4ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.9ms\n",
      "Speed: 2.0ms preprocess, 9.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.8ms\n",
      "Speed: 2.7ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 3.0ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.6ms\n",
      "Speed: 2.5ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 31.1ms\n",
      "Speed: 25.7ms preprocess, 31.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9.7ms\n",
      "Speed: 2.4ms preprocess, 9.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 10.1ms\n",
      "Speed: 2.3ms preprocess, 10.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Key: Tc, vector len: 12, Card Detections: [[99, 1100, 161, 1242, 0.5244140625], [104, 1095, 159, 1240, 0.61767578125], [102, 1086, 161, 1241, 0.63037109375], [102, 1086, 162, 1241, 0.62646484375], [104, 1099, 159, 1240, 0.61669921875], [103, 1084, 162, 1240, 0.63037109375], [103, 1085, 162, 1240, 0.62939453125], [103, 1084, 162, 1240, 0.62744140625], [103, 1085, 162, 1240, 0.6298828125], [104, 1091, 159, 1240, 0.6259765625], [103, 1090, 160, 1240, 0.6279296875], [106, 1089, 162, 1241, 0.64013671875]]\n",
      "Key: Td, vector len: 12, Card Detections: [[100, 1094, 162, 1242, 0.634765625], [100, 1095, 162, 1242, 0.640625], [100, 1096, 162, 1242, 0.64599609375], [100, 1100, 161, 1242, 0.64892578125], [100, 1098, 160, 1242, 0.6494140625], [101, 1099, 161, 1242, 0.6513671875], [100, 1098, 161, 1242, 0.6513671875], [101, 1099, 160, 1242, 0.646484375], [101, 1096, 161, 1243, 0.64599609375], [101, 1092, 162, 1243, 0.650390625], [101, 1092, 162, 1242, 0.6484375], [103, 1092, 160, 1242, 0.58544921875]]\n",
      "Key: Th, vector len: 0, Card Detections: []\n",
      "Key: Ts, vector len: 8, Card Detections: [[98, 1027, 159, 1188, 0.58447265625], [99, 1028, 159, 1187, 0.59765625], [98, 1027, 159, 1188, 0.59375], [98, 1029, 159, 1187, 0.59912109375], [98, 1027, 159, 1188, 0.60546875], [98, 1027, 159, 1188, 0.60400390625], [97, 1027, 159, 1189, 0.60693359375], [99, 1033, 160, 1189, 0.5771484375]]\n",
      "Key: 2c, vector len: 0, Card Detections: []\n",
      "Key: 2d, vector len: 3, Card Detections: [[102, 1047, 165, 1219, 0.5224609375], [101, 1042, 165, 1218, 0.5283203125], [104, 1055, 165, 1217, 0.56494140625]]\n",
      "Key: 2h, vector len: 0, Card Detections: []\n",
      "Key: 2s, vector len: 0, Card Detections: []\n",
      "Key: 3c, vector len: 13, Card Detections: [[77, 1026, 145, 1192, 0.53564453125], [76, 1046, 142, 1192, 0.57568359375], [76, 1041, 143, 1192, 0.56005859375], [77, 1045, 144, 1192, 0.57177734375], [77, 1041, 144, 1193, 0.505859375], [72, 1034, 146, 1195, 0.54736328125], [73, 1032, 145, 1195, 0.5947265625], [73, 1032, 145, 1194, 0.603515625], [73, 1032, 144, 1194, 0.5830078125], [73, 1032, 144, 1195, 0.58740234375], [74, 1033, 145, 1194, 0.6083984375], [75, 1037, 145, 1194, 0.60400390625], [75, 1040, 145, 1194, 0.5830078125]]\n",
      "Key: 3d, vector len: 0, Card Detections: []\n",
      "Key: 3h, vector len: 7, Card Detections: [[482, 1096, 544, 1213, 0.5673828125], [482, 1093, 543, 1213, 0.576171875], [483, 1095, 545, 1214, 0.58935546875], [483, 1095, 544, 1212, 0.58203125], [483, 1097, 544, 1213, 0.57958984375], [483, 1099, 544, 1213, 0.58740234375], [481, 1098, 543, 1214, 0.61962890625]]\n",
      "Key: 3s, vector len: 0, Card Detections: []\n",
      "Key: 4c, vector len: 0, Card Detections: []\n",
      "Key: 4d, vector len: 10, Card Detections: [[100, 1077, 227, 1204, 0.6103515625], [100, 1078, 226, 1205, 0.61376953125], [101, 1076, 226, 1205, 0.60400390625], [100, 1076, 226, 1205, 0.60498046875], [101, 1076, 227, 1205, 0.6083984375], [101, 1076, 227, 1205, 0.60546875], [101, 1077, 227, 1204, 0.60693359375], [101, 1077, 228, 1203, 0.60595703125], [100, 1078, 228, 1204, 0.60107421875], [101, 1075, 229, 1204, 0.60302734375]]\n",
      "Key: 4h, vector len: 8, Card Detections: [[487, 1078, 601, 1211, 0.576171875], [487, 1083, 600, 1211, 0.53955078125], [487, 1078, 600, 1211, 0.5849609375], [487, 1084, 600, 1212, 0.58154296875], [486, 1075, 600, 1212, 0.60009765625], [486, 1079, 599, 1212, 0.58935546875], [486, 1074, 598, 1213, 0.57421875], [485, 1074, 597, 1212, 0.5791015625]]\n",
      "Key: 4s, vector len: 16, Card Detections: [[490, 1102, 607, 1224, 0.58251953125], [489, 1097, 596, 1207, 0.50634765625], [491, 1102, 605, 1213, 0.578125], [490, 1102, 603, 1213, 0.595703125], [490, 1103, 604, 1214, 0.6064453125], [490, 1102, 606, 1215, 0.61376953125], [489, 1101, 605, 1214, 0.6103515625], [489, 1101, 606, 1215, 0.615234375], [489, 1101, 605, 1214, 0.609375], [489, 1100, 610, 1218, 0.583984375], [488, 1100, 609, 1218, 0.57275390625], [489, 1101, 610, 1219, 0.5849609375], [488, 1102, 606, 1222, 0.6083984375], [488, 1102, 605, 1220, 0.5966796875], [488, 1104, 606, 1221, 0.50732421875], [488, 1105, 606, 1222, 0.57666015625]]\n",
      "Key: 5c, vector len: 1, Card Detections: [[483, 1087, 547, 1215, 0.509765625]]\n",
      "Key: 5d, vector len: 12, Card Detections: [[488, 1053, 555, 1218, 0.59765625], [490, 1068, 553, 1220, 0.6044921875], [489, 1065, 552, 1220, 0.60009765625], [491, 1068, 552, 1218, 0.615234375], [492, 1071, 551, 1218, 0.5888671875], [493, 1071, 552, 1218, 0.5830078125], [493, 1068, 553, 1219, 0.546875], [493, 1070, 553, 1218, 0.546875], [493, 1069, 553, 1219, 0.556640625], [490, 1066, 553, 1219, 0.568359375], [489, 1067, 552, 1218, 0.5556640625], [489, 1072, 552, 1218, 0.55419921875]]\n",
      "Key: 5h, vector len: 6, Card Detections: [[479, 1092, 545, 1219, 0.64599609375], [483, 1093, 547, 1219, 0.65234375], [481, 1090, 545, 1219, 0.65185546875], [481, 1092, 544, 1219, 0.65576171875], [481, 1093, 544, 1218, 0.65185546875], [483, 1093, 544, 1218, 0.642578125]]\n",
      "Key: 5s, vector len: 0, Card Detections: []\n",
      "Key: 6c, vector len: 22, Card Detections: [[492, 1071, 551, 1213, 0.67724609375], [494, 1074, 551, 1213, 0.669921875], [494, 1072, 551, 1214, 0.6572265625], [494, 1070, 551, 1213, 0.669921875], [493, 1071, 551, 1213, 0.67626953125], [494, 1071, 551, 1213, 0.666015625], [493, 1071, 551, 1213, 0.6806640625], [494, 1069, 551, 1213, 0.67333984375], [494, 1069, 551, 1213, 0.67724609375], [492, 1068, 551, 1214, 0.66796875], [492, 1071, 550, 1213, 0.6572265625], [492, 1071, 550, 1214, 0.6318359375], [492, 1071, 550, 1213, 0.6279296875], [492, 1072, 550, 1215, 0.61376953125], [491, 1070, 549, 1213, 0.642578125], [492, 1072, 550, 1214, 0.669921875], [491, 1072, 549, 1214, 0.66552734375], [490, 1071, 548, 1214, 0.677734375], [490, 1071, 548, 1214, 0.67529296875], [490, 1071, 549, 1215, 0.6923828125], [489, 1079, 548, 1215, 0.68994140625], [489, 1073, 549, 1215, 0.6787109375]]\n",
      "Key: 6d, vector len: 0, Card Detections: []\n",
      "Key: 6h, vector len: 0, Card Detections: []\n",
      "Key: 6s, vector len: 1, Card Detections: [[87, 1041, 152, 1191, 0.55908203125]]\n",
      "Key: 7c, vector len: 66, Card Detections: [[68, 1034, 135, 1189, 0.5712890625], [67, 1050, 131, 1189, 0.6572265625], [67, 1051, 130, 1189, 0.662109375], [67, 1060, 131, 1191, 0.650390625], [67, 1047, 133, 1191, 0.650390625], [67, 1047, 133, 1193, 0.6416015625], [67, 1053, 133, 1195, 0.64697265625], [66, 1056, 133, 1195, 0.646484375], [66, 1054, 133, 1195, 0.65283203125], [68, 1050, 133, 1192, 0.640625], [66, 1054, 132, 1195, 0.638671875], [67, 1052, 134, 1194, 0.63623046875], [67, 1051, 134, 1195, 0.6357421875], [67, 1051, 133, 1195, 0.6376953125], [66, 1056, 134, 1196, 0.634765625], [67, 1051, 134, 1197, 0.63427734375], [68, 1056, 134, 1194, 0.642578125], [68, 1056, 133, 1195, 0.63037109375], [68, 1056, 134, 1195, 0.64794921875], [68, 1058, 134, 1195, 0.6494140625], [68, 1054, 135, 1195, 0.640625], [68, 1055, 135, 1195, 0.6435546875], [68, 1056, 135, 1196, 0.642578125], [68, 1055, 135, 1195, 0.6396484375], [69, 1055, 135, 1195, 0.64697265625], [69, 1055, 135, 1195, 0.640625], [69, 1056, 136, 1195, 0.6376953125], [69, 1050, 136, 1195, 0.63671875], [69, 1050, 137, 1196, 0.6279296875], [69, 1050, 137, 1196, 0.6494140625], [69, 1042, 138, 1195, 0.6513671875], [69, 1042, 138, 1195, 0.6533203125], [70, 1040, 138, 1193, 0.65673828125], [70, 1039, 138, 1193, 0.658203125], [70, 1040, 138, 1192, 0.65673828125], [70, 1045, 136, 1193, 0.6640625], [70, 1041, 137, 1192, 0.66015625], [71, 1046, 137, 1191, 0.666015625], [71, 1044, 137, 1191, 0.66357421875], [71, 1045, 136, 1191, 0.6611328125], [71, 1045, 136, 1191, 0.66259765625], [71, 1047, 136, 1191, 0.66357421875], [71, 1045, 136, 1190, 0.65673828125], [71, 1047, 137, 1191, 0.66015625], [71, 1045, 138, 1191, 0.65234375], [71, 1045, 137, 1191, 0.6494140625], [71, 1045, 137, 1191, 0.650390625], [71, 1044, 137, 1190, 0.64990234375], [71, 1044, 138, 1190, 0.65185546875], [71, 1044, 138, 1190, 0.6513671875], [72, 1044, 138, 1190, 0.6494140625], [72, 1044, 138, 1190, 0.6474609375], [72, 1045, 138, 1191, 0.6474609375], [72, 1039, 138, 1189, 0.64208984375], [72, 1041, 138, 1191, 0.6416015625], [72, 1043, 138, 1191, 0.640625], [72, 1044, 139, 1191, 0.6435546875], [72, 1041, 139, 1191, 0.642578125], [72, 1041, 139, 1191, 0.64501953125], [73, 1042, 139, 1191, 0.6474609375], [73, 1042, 140, 1191, 0.640625], [73, 1037, 141, 1191, 0.6298828125], [74, 1043, 140, 1191, 0.64306640625], [73, 1038, 141, 1191, 0.64501953125], [73, 1037, 142, 1191, 0.64501953125], [74, 1038, 143, 1191, 0.6474609375]]\n",
      "Key: 7d, vector len: 9, Card Detections: [[101, 1066, 166, 1230, 0.5546875], [106, 1098, 162, 1231, 0.6083984375], [102, 1064, 165, 1231, 0.59814453125], [105, 1095, 162, 1231, 0.60595703125], [104, 1071, 164, 1230, 0.599609375], [106, 1097, 161, 1229, 0.59912109375], [107, 1096, 161, 1229, 0.6025390625], [107, 1095, 161, 1228, 0.60302734375], [107, 1095, 161, 1230, 0.6025390625]]\n",
      "Key: 7h, vector len: 6, Card Detections: [[97, 1047, 165, 1214, 0.57958984375], [96, 1047, 165, 1214, 0.60400390625], [96, 1047, 165, 1214, 0.599609375], [97, 1051, 166, 1214, 0.60791015625], [97, 1059, 166, 1214, 0.59033203125], [97, 1051, 166, 1215, 0.5849609375]]\n",
      "Key: 7s, vector len: 10, Card Detections: [[76, 1020, 145, 1189, 0.5673828125], [78, 1035, 141, 1189, 0.56982421875], [82, 1042, 139, 1189, 0.572265625], [83, 1038, 140, 1189, 0.56591796875], [82, 1037, 140, 1189, 0.5751953125], [79, 1033, 141, 1189, 0.58154296875], [81, 1036, 140, 1189, 0.5791015625], [82, 1037, 141, 1190, 0.5693359375], [81, 1040, 142, 1191, 0.57763671875], [82, 1040, 143, 1193, 0.5732421875]]\n",
      "Key: 8c, vector len: 45, Card Detections: [[470, 1091, 543, 1239, 0.60400390625], [471, 1084, 544, 1238, 0.58056640625], [473, 1083, 544, 1234, 0.658203125], [474, 1080, 545, 1232, 0.66357421875], [474, 1080, 545, 1231, 0.658203125], [474, 1080, 545, 1230, 0.64013671875], [475, 1080, 544, 1231, 0.65966796875], [475, 1080, 544, 1231, 0.65869140625], [475, 1080, 544, 1229, 0.662109375], [474, 1081, 543, 1228, 0.66064453125], [475, 1081, 544, 1228, 0.666015625], [475, 1081, 544, 1228, 0.6708984375], [475, 1081, 544, 1229, 0.6669921875], [475, 1082, 544, 1228, 0.671875], [475, 1081, 543, 1228, 0.66943359375], [475, 1081, 543, 1228, 0.66796875], [475, 1081, 543, 1228, 0.66796875], [475, 1081, 543, 1228, 0.66650390625], [475, 1081, 543, 1228, 0.6640625], [475, 1081, 543, 1228, 0.666015625], [475, 1081, 543, 1228, 0.6494140625], [475, 1081, 543, 1228, 0.6474609375], [475, 1082, 543, 1228, 0.64892578125], [475, 1084, 543, 1228, 0.63623046875], [475, 1083, 543, 1228, 0.6474609375], [475, 1082, 543, 1228, 0.64892578125], [475, 1082, 543, 1228, 0.64599609375], [475, 1082, 543, 1228, 0.64794921875], [475, 1081, 543, 1228, 0.65185546875], [475, 1081, 543, 1229, 0.65283203125], [475, 1083, 543, 1229, 0.642578125], [475, 1083, 543, 1229, 0.6455078125], [475, 1083, 543, 1229, 0.646484375], [475, 1081, 543, 1229, 0.65478515625], [475, 1082, 543, 1229, 0.65234375], [475, 1082, 543, 1229, 0.65283203125], [475, 1081, 543, 1230, 0.64013671875], [474, 1082, 543, 1230, 0.6376953125], [474, 1081, 543, 1231, 0.65234375], [474, 1081, 544, 1231, 0.6572265625], [474, 1081, 543, 1230, 0.65869140625], [473, 1082, 542, 1230, 0.65185546875], [472, 1081, 543, 1231, 0.6494140625], [472, 1081, 541, 1233, 0.61962890625], [490, 1056, 553, 1210, 0.580078125]]\n",
      "Key: 8d, vector len: 5, Card Detections: [[102, 1055, 168, 1223, 0.57763671875], [101, 1052, 169, 1222, 0.59033203125], [102, 1058, 169, 1222, 0.54052734375], [104, 1077, 170, 1225, 0.5966796875], [492, 1093, 549, 1209, 0.60205078125]]\n",
      "Key: 8h, vector len: 18, Card Detections: [[480, 1112, 539, 1223, 0.65185546875], [480, 1108, 540, 1222, 0.66650390625], [480, 1113, 539, 1225, 0.638671875], [480, 1114, 540, 1224, 0.64990234375], [480, 1113, 539, 1223, 0.634765625], [479, 1113, 538, 1223, 0.64697265625], [479, 1113, 538, 1223, 0.654296875], [487, 1068, 550, 1214, 0.5849609375], [487, 1057, 550, 1213, 0.62060546875], [97, 1021, 160, 1189, 0.544921875], [488, 1066, 549, 1212, 0.52783203125], [488, 1060, 549, 1213, 0.564453125], [97, 1024, 161, 1189, 0.5302734375], [488, 1058, 550, 1212, 0.609375], [97, 1024, 161, 1189, 0.5458984375], [487, 1063, 550, 1213, 0.50341796875], [485, 1071, 551, 1214, 0.5546875], [486, 1064, 550, 1215, 0.54296875]]\n",
      "Key: 8s, vector len: 2, Card Detections: [[492, 1083, 551, 1217, 0.50244140625], [489, 1084, 548, 1213, 0.53076171875]]\n",
      "Key: 9c, vector len: 0, Card Detections: []\n",
      "Key: 9d, vector len: 0, Card Detections: []\n",
      "Key: 9h, vector len: 0, Card Detections: []\n",
      "Key: 9s, vector len: 5, Card Detections: [[477, 1100, 538, 1225, 0.5283203125], [476, 1102, 539, 1227, 0.56396484375], [477, 1099, 537, 1227, 0.54736328125], [476, 1098, 538, 1227, 0.5546875], [477, 1093, 537, 1229, 0.52392578125]]\n",
      "Key: Ac, vector len: 0, Card Detections: []\n",
      "Key: Ad, vector len: 0, Card Detections: []\n",
      "Key: Ah, vector len: 0, Card Detections: []\n",
      "Key: As, vector len: 1, Card Detections: [[488, 1058, 552, 1215, 0.5498046875]]\n",
      "Key: Jc, vector len: 27, Card Detections: [[69, 1035, 134, 1184, 0.64794921875], [69, 1038, 134, 1186, 0.65576171875], [70, 1041, 133, 1186, 0.64501953125], [70, 1043, 133, 1186, 0.658203125], [69, 1041, 133, 1186, 0.666015625], [70, 1048, 132, 1188, 0.6494140625], [71, 1054, 131, 1189, 0.64453125], [70, 1053, 132, 1188, 0.64306640625], [69, 1044, 133, 1189, 0.654296875], [70, 1047, 132, 1190, 0.6455078125], [70, 1048, 133, 1191, 0.64892578125], [70, 1048, 132, 1190, 0.654296875], [70, 1048, 132, 1191, 0.65234375], [69, 1048, 132, 1191, 0.65576171875], [69, 1048, 132, 1191, 0.65771484375], [69, 1048, 132, 1191, 0.6572265625], [69, 1047, 133, 1191, 0.65771484375], [69, 1047, 133, 1190, 0.66064453125], [70, 1051, 132, 1191, 0.64990234375], [70, 1047, 133, 1191, 0.6591796875], [70, 1053, 132, 1191, 0.65283203125], [70, 1053, 132, 1191, 0.6474609375], [71, 1045, 132, 1192, 0.62646484375], [71, 1046, 132, 1192, 0.62353515625], [71, 1047, 132, 1192, 0.62548828125], [71, 1063, 134, 1195, 0.57861328125], [72, 1067, 136, 1195, 0.56494140625]]\n",
      "Key: Jd, vector len: 0, Card Detections: []\n",
      "Key: Jh, vector len: 0, Card Detections: []\n",
      "Key: Js, vector len: 9, Card Detections: [[489, 1058, 551, 1213, 0.5478515625], [488, 1057, 551, 1213, 0.54541015625], [487, 1057, 550, 1212, 0.53955078125], [487, 1056, 550, 1213, 0.5478515625], [487, 1056, 550, 1212, 0.576171875], [486, 1057, 549, 1213, 0.599609375], [486, 1057, 550, 1213, 0.58935546875], [486, 1062, 548, 1212, 0.63720703125], [487, 1067, 547, 1212, 0.625]]\n",
      "Key: Kc, vector len: 38, Card Detections: [[90, 1135, 152, 1261, 0.61376953125], [94, 1110, 160, 1253, 0.65380859375], [94, 1114, 158, 1252, 0.6455078125], [93, 1112, 157, 1251, 0.65673828125], [94, 1111, 157, 1251, 0.61474609375], [93, 1100, 159, 1251, 0.6650390625], [94, 1101, 159, 1250, 0.66455078125], [96, 1099, 160, 1249, 0.52490234375], [96, 1099, 161, 1249, 0.65625], [96, 1099, 160, 1249, 0.64599609375], [97, 1099, 160, 1249, 0.58349609375], [98, 1098, 162, 1248, 0.5869140625], [99, 1106, 163, 1248, 0.5849609375], [99, 1099, 164, 1248, 0.57666015625], [99, 1090, 164, 1250, 0.65576171875], [99, 1090, 165, 1250, 0.65234375], [99, 1090, 165, 1250, 0.65234375], [99, 1089, 165, 1250, 0.654296875], [99, 1089, 165, 1250, 0.6513671875], [99, 1090, 165, 1251, 0.65234375], [99, 1090, 165, 1249, 0.65185546875], [99, 1090, 165, 1249, 0.65234375], [99, 1090, 165, 1249, 0.65234375], [99, 1090, 165, 1249, 0.650390625], [99, 1089, 165, 1250, 0.6474609375], [100, 1090, 164, 1250, 0.6474609375], [100, 1091, 165, 1250, 0.64111328125], [100, 1090, 166, 1250, 0.6435546875], [99, 1089, 165, 1250, 0.6484375], [99, 1089, 165, 1250, 0.6455078125], [100, 1089, 165, 1250, 0.6484375], [99, 1089, 165, 1250, 0.6474609375], [99, 1089, 165, 1249, 0.64990234375], [99, 1089, 166, 1250, 0.6484375], [100, 1086, 165, 1250, 0.66064453125], [100, 1087, 166, 1249, 0.66162109375], [101, 1089, 167, 1250, 0.64892578125], [98, 1081, 168, 1249, 0.66552734375]]\n",
      "Key: Kd, vector len: 6, Card Detections: [[481, 1058, 543, 1217, 0.58837890625], [481, 1059, 542, 1217, 0.5830078125], [483, 1063, 541, 1216, 0.58935546875], [480, 1057, 543, 1218, 0.62548828125], [480, 1059, 541, 1218, 0.63037109375], [478, 1057, 541, 1219, 0.61181640625]]\n",
      "Key: Kh, vector len: 13, Card Detections: [[486, 1062, 549, 1217, 0.6123046875], [495, 1050, 554, 1214, 0.51806640625], [94, 1026, 165, 1201, 0.576171875], [95, 1043, 165, 1204, 0.630859375], [489, 1056, 549, 1215, 0.57080078125], [94, 1046, 164, 1199, 0.62939453125], [489, 1059, 551, 1218, 0.5302734375], [93, 1041, 164, 1202, 0.62646484375], [95, 1044, 164, 1199, 0.6298828125], [96, 1046, 164, 1199, 0.6357421875], [94, 1043, 165, 1203, 0.6240234375], [94, 1038, 163, 1205, 0.51123046875], [74, 1009, 138, 1186, 0.51171875]]\n",
      "Key: Ks, vector len: 6, Card Detections: [[93, 1053, 167, 1213, 0.64892578125], [95, 1053, 169, 1213, 0.68310546875], [97, 1054, 168, 1213, 0.66357421875], [98, 1055, 168, 1212, 0.658203125], [100, 1057, 169, 1213, 0.669921875], [98, 1054, 168, 1213, 0.66015625]]\n",
      "Key: Qc, vector len: 6, Card Detections: [[84, 1021, 152, 1189, 0.5009765625], [87, 1020, 149, 1191, 0.52783203125], [86, 1023, 149, 1190, 0.5400390625], [87, 1024, 149, 1192, 0.55419921875], [88, 1036, 146, 1192, 0.5791015625], [88, 1038, 147, 1193, 0.54833984375]]\n",
      "Key: Qd, vector len: 0, Card Detections: []\n",
      "Key: Qh, vector len: 5, Card Detections: [[477, 1106, 539, 1222, 0.5771484375], [479, 1108, 538, 1225, 0.53564453125], [480, 1110, 537, 1222, 0.642578125], [480, 1110, 537, 1221, 0.6220703125], [479, 1110, 537, 1224, 0.5419921875]]\n",
      "Key: Qs, vector len: 0, Card Detections: []\n",
      "Key: SJoker, vector len: 0, Card Detections: []\n",
      "Key: BJoker, vector len: 4, Card Detections: [[483, 1083, 553, 1241, 0.53369140625], [486, 1063, 556, 1221, 0.51806640625], [485, 1078, 555, 1242, 0.517578125], [485, 1081, 555, 1245, 0.5107421875]]\n",
      "Key: Tc, vector len: 12, Card Detections: [[100, 1116, 157, 1242, 0.64794921875], [100, 1115, 157, 1240, 0.64892578125], [101, 1115, 157, 1241, 0.6484375], [101, 1115, 157, 1241, 0.6484375], [102, 1113, 157, 1241, 0.646484375], [102, 1114, 157, 1242, 0.6455078125], [102, 1114, 157, 1242, 0.6416015625], [102, 1114, 157, 1242, 0.6376953125], [102, 1114, 157, 1241, 0.640625], [103, 1114, 157, 1242, 0.6416015625], [103, 1114, 157, 1241, 0.6396484375], [104, 1114, 159, 1242, 0.6435546875]]\n",
      "Key: Td, vector len: 13, Card Detections: [[97, 1119, 161, 1248, 0.658203125], [100, 1119, 159, 1241, 0.66650390625], [100, 1119, 159, 1241, 0.6650390625], [100, 1119, 159, 1241, 0.66455078125], [101, 1119, 159, 1241, 0.66259765625], [101, 1119, 159, 1241, 0.66015625], [101, 1119, 159, 1240, 0.6611328125], [101, 1119, 159, 1240, 0.662109375], [101, 1119, 159, 1241, 0.65966796875], [101, 1119, 159, 1241, 0.65966796875], [102, 1119, 159, 1241, 0.6591796875], [102, 1119, 159, 1241, 0.6591796875], [102, 1120, 160, 1242, 0.65576171875]]\n",
      "Key: Th, vector len: 19, Card Detections: [[476, 1106, 534, 1226, 0.60302734375], [475, 1106, 534, 1217, 0.61669921875], [477, 1107, 532, 1216, 0.6298828125], [477, 1107, 532, 1216, 0.6328125], [477, 1107, 532, 1215, 0.634765625], [477, 1107, 531, 1215, 0.63427734375], [477, 1108, 531, 1216, 0.63134765625], [477, 1108, 532, 1216, 0.63134765625], [477, 1108, 532, 1216, 0.63232421875], [477, 1107, 532, 1217, 0.6318359375], [477, 1107, 532, 1217, 0.6318359375], [477, 1107, 532, 1217, 0.630859375], [477, 1107, 532, 1217, 0.630859375], [477, 1107, 532, 1217, 0.63037109375], [477, 1108, 532, 1218, 0.62939453125], [477, 1108, 532, 1218, 0.62890625], [477, 1110, 531, 1218, 0.62890625], [477, 1110, 530, 1218, 0.62548828125], [475, 1112, 531, 1221, 0.6142578125]]\n",
      "Key: Ts, vector len: 9, Card Detections: [[96, 1054, 158, 1193, 0.56787109375], [96, 1056, 157, 1187, 0.61669921875], [96, 1055, 156, 1187, 0.6181640625], [96, 1055, 157, 1187, 0.6201171875], [96, 1054, 157, 1187, 0.62158203125], [96, 1055, 156, 1187, 0.6181640625], [96, 1055, 156, 1187, 0.615234375], [96, 1056, 156, 1188, 0.615234375], [97, 1057, 157, 1189, 0.60986328125]]\n",
      "Key: 2c, vector len: 12, Card Detections: [[99, 1101, 161, 1229, 0.646484375], [100, 1102, 162, 1230, 0.65185546875], [101, 1101, 162, 1230, 0.63623046875], [101, 1101, 162, 1230, 0.642578125], [102, 1100, 163, 1227, 0.6396484375], [102, 1100, 162, 1228, 0.64501953125], [102, 1100, 163, 1228, 0.64453125], [102, 1100, 163, 1227, 0.64599609375], [102, 1100, 164, 1228, 0.6474609375], [102, 1101, 163, 1228, 0.64306640625], [102, 1100, 163, 1228, 0.6435546875], [103, 1102, 164, 1228, 0.64111328125]]\n",
      "Key: 2d, vector len: 9, Card Detections: [[102, 1089, 164, 1223, 0.630859375], [103, 1090, 163, 1221, 0.63720703125], [104, 1089, 163, 1220, 0.62890625], [105, 1089, 162, 1220, 0.6328125], [105, 1090, 162, 1219, 0.62744140625], [106, 1090, 162, 1219, 0.6171875], [106, 1090, 162, 1219, 0.634765625], [106, 1090, 162, 1220, 0.62548828125], [106, 1091, 163, 1220, 0.62255859375]]\n",
      "Key: 2h, vector len: 7, Card Detections: [[87, 1056, 144, 1186, 0.615234375], [86, 1056, 144, 1186, 0.61376953125], [87, 1055, 144, 1187, 0.61328125], [87, 1055, 143, 1187, 0.61767578125], [87, 1054, 144, 1186, 0.6171875], [87, 1057, 143, 1188, 0.61767578125], [89, 1056, 146, 1190, 0.57470703125]]\n",
      "Key: 2s, vector len: 24, Card Detections: [[102, 1127, 162, 1249, 0.68408203125], [103, 1126, 162, 1248, 0.68359375], [102, 1126, 162, 1249, 0.68115234375], [102, 1126, 162, 1248, 0.6787109375], [101, 1125, 163, 1248, 0.67724609375], [101, 1125, 164, 1249, 0.6640625], [101, 1125, 164, 1249, 0.66845703125], [101, 1125, 163, 1249, 0.67626953125], [101, 1125, 163, 1249, 0.67578125], [101, 1125, 162, 1248, 0.6640625], [101, 1125, 162, 1248, 0.66552734375], [101, 1125, 162, 1248, 0.66064453125], [101, 1125, 162, 1248, 0.65869140625], [101, 1125, 162, 1248, 0.66162109375], [101, 1126, 162, 1248, 0.66162109375], [101, 1125, 162, 1248, 0.66455078125], [101, 1126, 162, 1248, 0.66259765625], [101, 1126, 162, 1248, 0.666015625], [101, 1126, 162, 1248, 0.66357421875], [101, 1125, 162, 1248, 0.6630859375], [101, 1125, 162, 1248, 0.6650390625], [101, 1125, 162, 1248, 0.6611328125], [101, 1125, 162, 1247, 0.6572265625], [100, 1126, 163, 1247, 0.64306640625]]\n",
      "Key: 3c, vector len: 24, Card Detections: [[79, 1054, 141, 1191, 0.6416015625], [81, 1055, 141, 1191, 0.61962890625], [80, 1056, 140, 1191, 0.61572265625], [81, 1056, 140, 1191, 0.61083984375], [81, 1056, 141, 1191, 0.61279296875], [81, 1057, 141, 1192, 0.6142578125], [81, 1059, 141, 1194, 0.61572265625], [82, 1060, 140, 1194, 0.62255859375], [81, 1060, 141, 1194, 0.6162109375], [82, 1060, 140, 1195, 0.61865234375], [81, 1060, 141, 1195, 0.619140625], [81, 1060, 141, 1195, 0.6240234375], [81, 1061, 141, 1195, 0.62646484375], [79, 1060, 142, 1195, 0.634765625], [79, 1060, 142, 1195, 0.625], [79, 1060, 143, 1195, 0.6279296875], [79, 1060, 143, 1194, 0.62548828125], [79, 1060, 143, 1194, 0.625], [79, 1060, 142, 1194, 0.62109375], [79, 1060, 142, 1194, 0.62548828125], [79, 1060, 143, 1194, 0.63037109375], [80, 1060, 143, 1194, 0.62646484375], [80, 1061, 143, 1194, 0.626953125], [80, 1063, 145, 1195, 0.65576171875]]\n",
      "Key: 3d, vector len: 15, Card Detections: [[81, 1050, 143, 1187, 0.6240234375], [81, 1050, 143, 1186, 0.61767578125], [81, 1051, 142, 1188, 0.619140625], [82, 1051, 142, 1188, 0.61279296875], [81, 1050, 143, 1187, 0.62060546875], [81, 1052, 142, 1188, 0.62060546875], [81, 1051, 142, 1188, 0.6220703125], [81, 1052, 142, 1188, 0.623046875], [81, 1052, 142, 1188, 0.62353515625], [81, 1053, 143, 1189, 0.62255859375], [81, 1053, 143, 1189, 0.6259765625], [82, 1054, 143, 1189, 0.623046875], [82, 1054, 143, 1190, 0.626953125], [83, 1055, 143, 1191, 0.6279296875], [83, 1056, 145, 1194, 0.63671875]]\n",
      "Key: 3h, vector len: 7, Card Detections: [[486, 1093, 542, 1213, 0.56005859375], [485, 1092, 542, 1212, 0.55908203125], [486, 1094, 541, 1213, 0.568359375], [485, 1093, 541, 1212, 0.568359375], [485, 1094, 540, 1213, 0.56982421875], [484, 1094, 541, 1212, 0.57373046875], [483, 1095, 540, 1214, 0.611328125]]\n",
      "Key: 3s, vector len: 18, Card Detections: [[478, 1114, 538, 1228, 0.59521484375], [478, 1114, 537, 1228, 0.59765625], [478, 1114, 537, 1228, 0.60986328125], [478, 1114, 536, 1228, 0.6064453125], [478, 1114, 537, 1228, 0.6142578125], [478, 1114, 536, 1229, 0.6142578125], [478, 1114, 536, 1229, 0.6201171875], [478, 1114, 536, 1229, 0.61962890625], [478, 1114, 536, 1229, 0.62451171875], [478, 1114, 537, 1229, 0.6240234375], [478, 1114, 537, 1229, 0.623046875], [478, 1114, 537, 1229, 0.62255859375], [478, 1114, 537, 1229, 0.6259765625], [478, 1114, 537, 1230, 0.625], [478, 1115, 537, 1230, 0.62548828125], [478, 1115, 537, 1230, 0.62158203125], [477, 1116, 536, 1231, 0.62353515625], [475, 1116, 536, 1231, 0.6240234375]]\n",
      "Key: 4c, vector len: 51, Card Detections: [[489, 1096, 609, 1226, 0.64599609375], [488, 1096, 609, 1224, 0.650390625], [488, 1096, 609, 1227, 0.65380859375], [489, 1096, 609, 1227, 0.65185546875], [489, 1097, 610, 1227, 0.65380859375], [489, 1097, 610, 1227, 0.6552734375], [489, 1097, 610, 1227, 0.65771484375], [489, 1097, 609, 1227, 0.65869140625], [489, 1097, 609, 1227, 0.65576171875], [489, 1098, 609, 1228, 0.65576171875], [489, 1097, 609, 1228, 0.65478515625], [489, 1098, 610, 1228, 0.65576171875], [488, 1098, 609, 1228, 0.65478515625], [488, 1098, 609, 1229, 0.654296875], [488, 1098, 609, 1229, 0.65625], [488, 1099, 609, 1230, 0.65576171875], [489, 1098, 609, 1230, 0.65966796875], [488, 1099, 609, 1230, 0.6572265625], [488, 1098, 609, 1230, 0.65478515625], [488, 1098, 609, 1230, 0.6572265625], [488, 1098, 609, 1230, 0.65673828125], [488, 1099, 609, 1231, 0.6591796875], [488, 1099, 609, 1231, 0.66064453125], [488, 1099, 609, 1231, 0.6611328125], [487, 1099, 609, 1231, 0.66064453125], [487, 1100, 609, 1231, 0.6611328125], [487, 1100, 609, 1231, 0.6611328125], [487, 1100, 609, 1232, 0.65673828125], [487, 1100, 609, 1232, 0.6591796875], [487, 1100, 609, 1232, 0.658203125], [487, 1100, 609, 1232, 0.65771484375], [487, 1100, 609, 1232, 0.6572265625], [487, 1101, 609, 1232, 0.6611328125], [487, 1102, 609, 1233, 0.66162109375], [487, 1102, 609, 1233, 0.6630859375], [487, 1101, 609, 1233, 0.66357421875], [487, 1102, 609, 1234, 0.66455078125], [487, 1102, 609, 1234, 0.66455078125], [486, 1103, 609, 1233, 0.66015625], [485, 1103, 609, 1234, 0.66162109375], [485, 1103, 609, 1235, 0.6611328125], [485, 1103, 609, 1235, 0.66259765625], [484, 1104, 610, 1235, 0.662109375], [484, 1104, 610, 1235, 0.66162109375], [484, 1104, 610, 1235, 0.66015625], [484, 1105, 609, 1235, 0.65966796875], [484, 1105, 610, 1235, 0.6572265625], [484, 1106, 609, 1235, 0.6552734375], [484, 1106, 609, 1235, 0.654296875], [483, 1107, 609, 1236, 0.6494140625], [480, 1110, 608, 1237, 0.64599609375]]\n",
      "Key: 4d, vector len: 10, Card Detections: [[102, 1074, 229, 1204, 0.603515625], [101, 1074, 229, 1204, 0.60595703125], [102, 1074, 229, 1204, 0.5986328125], [102, 1074, 229, 1205, 0.5966796875], [102, 1073, 230, 1204, 0.595703125], [102, 1073, 230, 1205, 0.595703125], [102, 1073, 230, 1204, 0.5986328125], [103, 1074, 230, 1204, 0.5966796875], [103, 1074, 230, 1205, 0.60009765625], [103, 1075, 230, 1205, 0.60107421875]]\n",
      "Key: 4h, vector len: 18, Card Detections: [[489, 1089, 605, 1215, 0.591796875], [491, 1090, 600, 1214, 0.626953125], [491, 1090, 600, 1213, 0.62646484375], [491, 1090, 600, 1213, 0.62646484375], [491, 1091, 600, 1213, 0.6279296875], [491, 1090, 600, 1214, 0.626953125], [491, 1091, 600, 1213, 0.6259765625], [491, 1090, 600, 1213, 0.626953125], [491, 1091, 600, 1214, 0.62890625], [491, 1091, 599, 1214, 0.62939453125], [491, 1091, 599, 1214, 0.6298828125], [490, 1091, 599, 1214, 0.62744140625], [490, 1092, 599, 1215, 0.630859375], [490, 1092, 599, 1215, 0.6318359375], [490, 1092, 598, 1215, 0.63330078125], [490, 1092, 598, 1215, 0.63330078125], [489, 1093, 598, 1215, 0.6318359375], [487, 1094, 597, 1216, 0.6201171875]]\n",
      "Key: 4s, vector len: 21, Card Detections: [[489, 1093, 583, 1209, 0.55322265625], [491, 1093, 599, 1222, 0.63623046875], [491, 1092, 598, 1214, 0.64501953125], [491, 1093, 600, 1219, 0.63671875], [491, 1093, 600, 1219, 0.63720703125], [491, 1093, 600, 1220, 0.63916015625], [491, 1093, 600, 1220, 0.6396484375], [491, 1093, 600, 1220, 0.63916015625], [491, 1093, 600, 1221, 0.6376953125], [491, 1093, 600, 1220, 0.63916015625], [491, 1095, 600, 1221, 0.6396484375], [491, 1095, 600, 1221, 0.6396484375], [491, 1095, 600, 1221, 0.638671875], [491, 1095, 599, 1222, 0.64208984375], [491, 1095, 599, 1221, 0.63818359375], [490, 1096, 599, 1222, 0.64013671875], [490, 1096, 599, 1222, 0.64111328125], [489, 1097, 599, 1222, 0.63916015625], [489, 1098, 599, 1224, 0.6396484375], [488, 1099, 598, 1225, 0.63916015625], [486, 1099, 598, 1226, 0.6318359375]]\n",
      "Key: 5c, vector len: 8, Card Detections: [[484, 1094, 544, 1213, 0.60205078125], [486, 1094, 543, 1215, 0.6279296875], [486, 1094, 543, 1215, 0.642578125], [486, 1096, 543, 1216, 0.64453125], [486, 1095, 542, 1216, 0.63525390625], [486, 1097, 542, 1216, 0.640625], [484, 1097, 542, 1217, 0.65087890625], [484, 1095, 543, 1216, 0.5166015625]]\n",
      "Key: 5d, vector len: 14, Card Detections: [[491, 1089, 548, 1217, 0.607421875], [493, 1089, 548, 1212, 0.6376953125], [495, 1089, 547, 1212, 0.6376953125], [495, 1090, 547, 1212, 0.6220703125], [495, 1090, 547, 1212, 0.607421875], [495, 1089, 547, 1211, 0.61669921875], [495, 1089, 547, 1211, 0.60888671875], [495, 1090, 546, 1212, 0.611328125], [495, 1089, 546, 1211, 0.607421875], [495, 1090, 546, 1212, 0.611328125], [494, 1090, 546, 1211, 0.60302734375], [494, 1090, 546, 1212, 0.60595703125], [493, 1091, 546, 1211, 0.64111328125], [491, 1092, 545, 1212, 0.65234375]]\n",
      "Key: 5h, vector len: 6, Card Detections: [[484, 1103, 540, 1218, 0.62890625], [483, 1101, 540, 1218, 0.63525390625], [484, 1102, 540, 1219, 0.63134765625], [484, 1102, 540, 1218, 0.634765625], [484, 1102, 540, 1218, 0.63525390625], [483, 1103, 539, 1218, 0.63134765625]]\n",
      "Key: 5s, vector len: 15, Card Detections: [[492, 1086, 546, 1209, 0.6435546875], [494, 1087, 546, 1210, 0.62548828125], [494, 1086, 546, 1208, 0.62646484375], [494, 1087, 546, 1210, 0.6259765625], [494, 1087, 546, 1210, 0.62353515625], [493, 1087, 547, 1210, 0.61962890625], [493, 1087, 546, 1210, 0.62060546875], [493, 1087, 546, 1210, 0.6181640625], [493, 1088, 546, 1210, 0.62060546875], [493, 1088, 546, 1210, 0.61962890625], [492, 1088, 545, 1211, 0.61474609375], [492, 1088, 545, 1211, 0.62109375], [491, 1090, 544, 1212, 0.61376953125], [491, 1090, 544, 1212, 0.61279296875], [489, 1091, 543, 1212, 0.63427734375]]\n",
      "Key: 6c, vector len: 23, Card Detections: [[493, 1090, 550, 1211, 0.67919921875], [495, 1090, 550, 1214, 0.69091796875], [495, 1089, 549, 1214, 0.681640625], [495, 1091, 549, 1214, 0.6826171875], [495, 1091, 549, 1214, 0.68505859375], [495, 1090, 549, 1214, 0.6875], [495, 1091, 549, 1214, 0.6865234375], [496, 1090, 549, 1214, 0.6865234375], [496, 1091, 549, 1214, 0.685546875], [496, 1091, 549, 1214, 0.68408203125], [494, 1091, 549, 1214, 0.68896484375], [494, 1092, 549, 1215, 0.68701171875], [494, 1092, 549, 1214, 0.69189453125], [493, 1092, 548, 1215, 0.68408203125], [493, 1092, 547, 1214, 0.677734375], [493, 1093, 547, 1215, 0.68017578125], [493, 1092, 547, 1215, 0.68408203125], [493, 1092, 546, 1215, 0.68359375], [493, 1093, 546, 1216, 0.685546875], [493, 1093, 546, 1216, 0.6845703125], [492, 1094, 545, 1216, 0.6806640625], [491, 1095, 545, 1216, 0.68017578125], [490, 1095, 544, 1217, 0.67236328125]]\n",
      "Key: 6d, vector len: 7, Card Detections: [[105, 1094, 162, 1224, 0.63916015625], [105, 1092, 162, 1223, 0.63818359375], [106, 1092, 163, 1223, 0.6416015625], [106, 1093, 163, 1222, 0.64794921875], [107, 1092, 163, 1222, 0.63818359375], [107, 1093, 164, 1222, 0.63623046875], [108, 1093, 165, 1224, 0.64013671875]]\n",
      "Key: 6h, vector len: 8, Card Detections: [[99, 1063, 158, 1202, 0.58154296875], [100, 1062, 158, 1192, 0.67626953125], [100, 1060, 158, 1190, 0.6796875], [100, 1061, 157, 1190, 0.67626953125], [101, 1060, 158, 1189, 0.6787109375], [101, 1060, 158, 1189, 0.6796875], [101, 1060, 158, 1189, 0.6806640625], [102, 1060, 158, 1189, 0.68115234375]]\n",
      "Key: 6s, vector len: 11, Card Detections: [[92, 1054, 152, 1186, 0.666015625], [93, 1054, 150, 1187, 0.712890625], [93, 1055, 150, 1187, 0.7099609375], [93, 1055, 150, 1187, 0.70703125], [93, 1054, 150, 1187, 0.70458984375], [93, 1055, 150, 1187, 0.708984375], [93, 1056, 149, 1188, 0.70849609375], [93, 1056, 149, 1188, 0.7099609375], [93, 1057, 149, 1189, 0.708984375], [93, 1058, 149, 1190, 0.71044921875], [91, 1057, 150, 1194, 0.6845703125]]\n",
      "Key: 7c, vector len: 67, Card Detections: [[66, 1058, 130, 1192, 0.6396484375], [67, 1060, 129, 1193, 0.66259765625], [67, 1062, 129, 1194, 0.66259765625], [66, 1063, 129, 1195, 0.658203125], [67, 1063, 130, 1195, 0.65966796875], [67, 1063, 130, 1195, 0.6630859375], [67, 1064, 130, 1196, 0.65966796875], [67, 1064, 130, 1196, 0.658203125], [67, 1064, 130, 1196, 0.66064453125], [67, 1064, 130, 1195, 0.66259765625], [67, 1064, 130, 1196, 0.65869140625], [67, 1064, 130, 1196, 0.65625], [67, 1064, 130, 1196, 0.6572265625], [67, 1065, 130, 1196, 0.64892578125], [68, 1065, 130, 1196, 0.64697265625], [68, 1066, 130, 1197, 0.6474609375], [68, 1066, 131, 1197, 0.6533203125], [68, 1066, 131, 1197, 0.6552734375], [68, 1066, 131, 1197, 0.6552734375], [68, 1066, 131, 1197, 0.650390625], [68, 1067, 131, 1197, 0.646484375], [69, 1067, 131, 1197, 0.6455078125], [69, 1067, 131, 1197, 0.6435546875], [69, 1067, 131, 1197, 0.642578125], [69, 1067, 131, 1197, 0.64697265625], [69, 1067, 131, 1197, 0.6455078125], [69, 1067, 131, 1196, 0.64453125], [70, 1068, 132, 1196, 0.64697265625], [70, 1068, 132, 1197, 0.64404296875], [70, 1068, 132, 1196, 0.65234375], [71, 1068, 132, 1195, 0.64990234375], [71, 1068, 132, 1195, 0.658203125], [71, 1067, 132, 1194, 0.66259765625], [71, 1067, 132, 1194, 0.658203125], [71, 1067, 132, 1194, 0.65771484375], [71, 1066, 132, 1195, 0.66015625], [71, 1067, 132, 1194, 0.65673828125], [71, 1066, 132, 1194, 0.6611328125], [71, 1066, 132, 1194, 0.66015625], [71, 1066, 132, 1193, 0.65966796875], [71, 1066, 132, 1193, 0.6591796875], [71, 1066, 132, 1193, 0.66015625], [71, 1066, 133, 1193, 0.6572265625], [72, 1066, 132, 1193, 0.66015625], [72, 1066, 132, 1193, 0.6630859375], [72, 1066, 133, 1193, 0.662109375], [72, 1066, 133, 1193, 0.66455078125], [72, 1066, 133, 1192, 0.66259765625], [72, 1066, 133, 1192, 0.66357421875], [72, 1066, 133, 1192, 0.66455078125], [72, 1066, 133, 1192, 0.6630859375], [72, 1066, 133, 1192, 0.66455078125], [72, 1066, 134, 1192, 0.66552734375], [73, 1066, 133, 1192, 0.66357421875], [73, 1065, 133, 1191, 0.6640625], [73, 1065, 134, 1191, 0.66357421875], [72, 1065, 134, 1192, 0.66015625], [73, 1066, 134, 1192, 0.6630859375], [73, 1066, 134, 1192, 0.6669921875], [73, 1066, 134, 1192, 0.66552734375], [73, 1066, 134, 1192, 0.66259765625], [74, 1066, 135, 1192, 0.66357421875], [73, 1066, 135, 1192, 0.6630859375], [74, 1066, 135, 1192, 0.6650390625], [74, 1066, 135, 1192, 0.66162109375], [74, 1066, 136, 1192, 0.66455078125], [78, 1066, 141, 1190, 0.6591796875]]\n",
      "Key: 7d, vector len: 9, Card Detections: [[102, 1105, 160, 1233, 0.64306640625], [102, 1105, 160, 1233, 0.6240234375], [103, 1103, 160, 1233, 0.6279296875], [103, 1104, 161, 1233, 0.6259765625], [103, 1104, 161, 1232, 0.63330078125], [104, 1104, 161, 1232, 0.6279296875], [104, 1104, 161, 1232, 0.6259765625], [105, 1104, 161, 1231, 0.62548828125], [105, 1105, 162, 1233, 0.61328125]]\n",
      "Key: 7h, vector len: 8, Card Detections: [[98, 1075, 162, 1215, 0.63134765625], [102, 1074, 159, 1208, 0.68310546875], [102, 1075, 159, 1207, 0.68017578125], [102, 1075, 159, 1207, 0.68115234375], [102, 1075, 159, 1207, 0.67529296875], [103, 1075, 159, 1207, 0.6787109375], [103, 1077, 159, 1208, 0.673828125], [104, 1077, 161, 1210, 0.68017578125]]\n",
      "Key: 7s, vector len: 10, Card Detections: [[80, 1058, 138, 1188, 0.61376953125], [81, 1058, 138, 1188, 0.6064453125], [82, 1057, 137, 1189, 0.59326171875], [83, 1058, 137, 1190, 0.59228515625], [83, 1059, 137, 1189, 0.599609375], [82, 1059, 137, 1189, 0.60595703125], [82, 1059, 137, 1190, 0.59814453125], [83, 1060, 138, 1191, 0.5966796875], [83, 1060, 138, 1192, 0.599609375], [83, 1060, 139, 1194, 0.60595703125]]\n",
      "Key: 8c, vector len: 49, Card Detections: [[463, 1181, 541, 1269, 0.54833984375], [464, 1161, 538, 1257, 0.59326171875], [468, 1146, 539, 1250, 0.58740234375], [472, 1137, 540, 1243, 0.5908203125], [475, 1131, 538, 1240, 0.59716796875], [477, 1125, 539, 1237, 0.619140625], [478, 1122, 539, 1233, 0.61279296875], [479, 1121, 540, 1232, 0.61669921875], [480, 1120, 541, 1231, 0.6181640625], [480, 1119, 541, 1230, 0.6279296875], [480, 1119, 540, 1231, 0.6279296875], [480, 1119, 540, 1231, 0.6279296875], [480, 1119, 540, 1230, 0.62548828125], [480, 1119, 540, 1230, 0.6240234375], [480, 1119, 539, 1230, 0.6240234375], [479, 1118, 539, 1230, 0.62451171875], [479, 1118, 538, 1230, 0.63037109375], [479, 1118, 538, 1229, 0.62890625], [479, 1118, 538, 1229, 0.6318359375], [479, 1118, 538, 1229, 0.6298828125], [479, 1118, 538, 1229, 0.63037109375], [479, 1118, 538, 1229, 0.62890625], [479, 1118, 538, 1229, 0.6279296875], [479, 1118, 538, 1229, 0.626953125], [479, 1118, 537, 1229, 0.626953125], [479, 1118, 537, 1229, 0.6259765625], [479, 1118, 537, 1229, 0.62353515625], [479, 1119, 537, 1229, 0.62353515625], [479, 1118, 537, 1229, 0.625], [479, 1118, 537, 1229, 0.6259765625], [479, 1118, 537, 1229, 0.6240234375], [479, 1118, 537, 1229, 0.62109375], [479, 1118, 537, 1229, 0.62744140625], [479, 1118, 537, 1229, 0.63037109375], [479, 1119, 537, 1229, 0.6328125], [479, 1119, 537, 1229, 0.63134765625], [479, 1119, 537, 1229, 0.630859375], [478, 1119, 538, 1229, 0.63037109375], [478, 1119, 538, 1230, 0.6337890625], [478, 1119, 538, 1230, 0.6318359375], [478, 1119, 537, 1230, 0.63037109375], [478, 1120, 537, 1230, 0.6298828125], [478, 1120, 537, 1230, 0.62646484375], [478, 1120, 537, 1230, 0.62890625], [478, 1120, 537, 1230, 0.6328125], [477, 1119, 536, 1230, 0.6376953125], [477, 1120, 536, 1230, 0.6337890625], [477, 1120, 535, 1231, 0.626953125], [474, 1117, 535, 1231, 0.64697265625]]\n",
      "Key: 8d, vector len: 13, Card Detections: [[492, 1093, 547, 1211, 0.66162109375], [492, 1094, 545, 1209, 0.6728515625], [493, 1094, 544, 1208, 0.6845703125], [492, 1093, 545, 1209, 0.68994140625], [493, 1093, 544, 1210, 0.69384765625], [493, 1093, 544, 1210, 0.6923828125], [493, 1094, 544, 1210, 0.6904296875], [493, 1093, 544, 1210, 0.69189453125], [492, 1095, 543, 1210, 0.6904296875], [492, 1094, 543, 1209, 0.689453125], [492, 1095, 543, 1211, 0.69140625], [490, 1095, 543, 1211, 0.6748046875], [493, 1092, 546, 1214, 0.59619140625]]\n",
      "Key: 8h, vector len: 9, Card Detections: [[479, 1111, 535, 1224, 0.64794921875], [481, 1112, 534, 1222, 0.66455078125], [480, 1112, 534, 1222, 0.6708984375], [481, 1113, 534, 1224, 0.6669921875], [481, 1113, 534, 1223, 0.6708984375], [481, 1113, 534, 1222, 0.66650390625], [480, 1113, 533, 1223, 0.6689453125], [480, 1113, 533, 1223, 0.68017578125], [478, 1113, 533, 1225, 0.662109375]]\n",
      "Key: 8s, vector len: 14, Card Detections: [[494, 1093, 547, 1213, 0.63720703125], [495, 1092, 547, 1212, 0.6376953125], [495, 1093, 547, 1213, 0.63623046875], [494, 1092, 547, 1212, 0.63671875], [494, 1092, 547, 1212, 0.64208984375], [493, 1093, 547, 1213, 0.64892578125], [494, 1092, 546, 1212, 0.6513671875], [494, 1095, 546, 1214, 0.6552734375], [493, 1093, 546, 1212, 0.650390625], [493, 1094, 546, 1213, 0.65869140625], [493, 1094, 545, 1213, 0.65673828125], [493, 1094, 545, 1213, 0.64990234375], [492, 1095, 545, 1214, 0.654296875], [490, 1096, 544, 1215, 0.63525390625]]\n",
      "Key: 9c, vector len: 8, Card Detections: [[101, 1073, 160, 1203, 0.646484375], [101, 1072, 159, 1202, 0.63818359375], [101, 1073, 159, 1203, 0.63671875], [102, 1072, 160, 1201, 0.64111328125], [103, 1072, 160, 1201, 0.63525390625], [102, 1072, 160, 1202, 0.64111328125], [103, 1072, 160, 1201, 0.6298828125], [104, 1074, 161, 1203, 0.62841796875]]\n",
      "Key: 9d, vector len: 8, Card Detections: [[97, 1066, 157, 1195, 0.65576171875], [99, 1066, 155, 1192, 0.65234375], [99, 1065, 155, 1193, 0.658203125], [99, 1066, 155, 1194, 0.658203125], [100, 1066, 155, 1194, 0.65283203125], [99, 1066, 155, 1194, 0.65869140625], [100, 1066, 155, 1194, 0.65673828125], [100, 1067, 155, 1193, 0.66162109375]]\n",
      "Key: 9h, vector len: 15, Card Detections: [[495, 1095, 547, 1210, 0.58251953125], [495, 1094, 547, 1209, 0.5908203125], [495, 1095, 547, 1209, 0.58935546875], [495, 1096, 546, 1210, 0.5986328125], [495, 1096, 547, 1210, 0.60009765625], [495, 1095, 547, 1211, 0.6015625], [495, 1095, 547, 1210, 0.60546875], [494, 1095, 546, 1211, 0.60791015625], [494, 1096, 546, 1211, 0.60498046875], [494, 1096, 546, 1210, 0.607421875], [494, 1096, 546, 1211, 0.611328125], [494, 1096, 546, 1211, 0.611328125], [493, 1096, 547, 1211, 0.611328125], [493, 1097, 546, 1212, 0.61083984375], [492, 1098, 545, 1212, 0.576171875]]\n",
      "Key: 9s, vector len: 14, Card Detections: [[479, 1112, 535, 1227, 0.61767578125], [481, 1113, 536, 1224, 0.63330078125], [481, 1112, 536, 1224, 0.6357421875], [481, 1112, 536, 1224, 0.6318359375], [481, 1112, 536, 1224, 0.6376953125], [482, 1111, 536, 1225, 0.64501953125], [482, 1112, 534, 1224, 0.63623046875], [482, 1112, 535, 1224, 0.6357421875], [482, 1113, 534, 1225, 0.6337890625], [481, 1113, 535, 1224, 0.63427734375], [481, 1113, 535, 1224, 0.63232421875], [480, 1114, 534, 1225, 0.62939453125], [480, 1116, 534, 1225, 0.61767578125], [99, 1070, 162, 1210, 0.5654296875]]\n",
      "Key: Ac, vector len: 10, Card Detections: [[481, 1116, 538, 1227, 0.51708984375], [481, 1116, 538, 1227, 0.5185546875], [481, 1116, 538, 1227, 0.56591796875], [481, 1116, 539, 1226, 0.54638671875], [481, 1116, 538, 1227, 0.5888671875], [481, 1116, 539, 1227, 0.58642578125], [481, 1116, 538, 1227, 0.57861328125], [481, 1116, 539, 1228, 0.5908203125], [481, 1116, 538, 1227, 0.6044921875], [480, 1117, 538, 1228, 0.501953125]]\n",
      "Key: Ad, vector len: 11, Card Detections: [[105, 1090, 164, 1225, 0.58056640625], [105, 1087, 159, 1217, 0.66259765625], [106, 1087, 159, 1217, 0.64599609375], [106, 1086, 159, 1215, 0.65283203125], [105, 1086, 159, 1215, 0.65576171875], [106, 1086, 159, 1215, 0.6533203125], [106, 1086, 159, 1216, 0.6494140625], [107, 1086, 159, 1216, 0.65234375], [106, 1085, 159, 1215, 0.650390625], [106, 1086, 159, 1215, 0.64599609375], [107, 1083, 161, 1216, 0.64404296875]]\n",
      "Key: Ah, vector len: 32, Card Detections: [[75, 1059, 135, 1188, 0.6484375], [76, 1059, 134, 1188, 0.64208984375], [76, 1059, 134, 1188, 0.63916015625], [76, 1060, 133, 1189, 0.63818359375], [76, 1060, 134, 1189, 0.63916015625], [75, 1060, 134, 1189, 0.6416015625], [76, 1060, 134, 1189, 0.6416015625], [77, 1060, 133, 1190, 0.6337890625], [77, 1060, 133, 1190, 0.6328125], [77, 1060, 133, 1190, 0.63037109375], [77, 1060, 133, 1189, 0.6298828125], [77, 1060, 132, 1189, 0.62939453125], [77, 1060, 132, 1189, 0.6279296875], [76, 1059, 133, 1188, 0.63037109375], [77, 1059, 133, 1188, 0.63134765625], [77, 1059, 133, 1188, 0.62744140625], [76, 1059, 133, 1189, 0.62939453125], [77, 1059, 132, 1189, 0.62939453125], [77, 1059, 132, 1189, 0.62890625], [76, 1059, 132, 1188, 0.6318359375], [76, 1059, 133, 1188, 0.6328125], [76, 1059, 133, 1189, 0.63330078125], [76, 1059, 133, 1189, 0.6328125], [75, 1059, 133, 1188, 0.6328125], [75, 1059, 133, 1188, 0.630859375], [75, 1059, 133, 1188, 0.6337890625], [75, 1059, 133, 1187, 0.630859375], [75, 1058, 133, 1186, 0.62939453125], [75, 1058, 133, 1186, 0.6318359375], [75, 1058, 133, 1186, 0.63134765625], [75, 1060, 133, 1186, 0.6318359375], [75, 1054, 135, 1188, 0.60400390625]]\n",
      "Key: As, vector len: 11, Card Detections: [[481, 1117, 538, 1227, 0.58642578125], [481, 1116, 539, 1228, 0.51220703125], [490, 1093, 546, 1213, 0.60009765625], [491, 1093, 545, 1214, 0.5859375], [491, 1093, 545, 1213, 0.5966796875], [491, 1094, 545, 1214, 0.591796875], [491, 1094, 545, 1213, 0.59765625], [491, 1094, 544, 1213, 0.60009765625], [491, 1095, 544, 1213, 0.6005859375], [491, 1096, 544, 1213, 0.603515625], [488, 1098, 543, 1214, 0.62841796875]]\n",
      "Key: Jc, vector len: 28, Card Detections: [[72, 1054, 133, 1186, 0.66748046875], [72, 1056, 132, 1188, 0.6796875], [72, 1056, 132, 1188, 0.681640625], [72, 1058, 131, 1190, 0.67333984375], [72, 1058, 132, 1189, 0.67236328125], [72, 1060, 131, 1189, 0.6689453125], [72, 1061, 132, 1192, 0.67529296875], [72, 1062, 131, 1193, 0.67578125], [72, 1062, 131, 1192, 0.67724609375], [72, 1063, 130, 1193, 0.67529296875], [72, 1063, 131, 1193, 0.6796875], [72, 1063, 131, 1193, 0.677734375], [72, 1064, 130, 1193, 0.68115234375], [72, 1064, 130, 1194, 0.68017578125], [72, 1064, 130, 1194, 0.6806640625], [72, 1064, 130, 1194, 0.68310546875], [72, 1064, 130, 1194, 0.68017578125], [72, 1064, 130, 1194, 0.68017578125], [72, 1064, 130, 1194, 0.6806640625], [72, 1064, 131, 1194, 0.68310546875], [72, 1065, 130, 1194, 0.68212890625], [72, 1065, 131, 1195, 0.68212890625], [72, 1065, 131, 1194, 0.68115234375], [72, 1066, 131, 1194, 0.6787109375], [72, 1066, 131, 1194, 0.6787109375], [72, 1066, 131, 1194, 0.6787109375], [73, 1068, 132, 1194, 0.6728515625], [72, 1063, 134, 1198, 0.67138671875]]\n",
      "Key: Jd, vector len: 8, Card Detections: [[483, 1107, 534, 1221, 0.6337890625], [484, 1108, 533, 1218, 0.63818359375], [484, 1108, 533, 1218, 0.64013671875], [484, 1107, 533, 1218, 0.638671875], [484, 1107, 533, 1218, 0.6181640625], [484, 1107, 533, 1218, 0.607421875], [484, 1108, 533, 1221, 0.60205078125], [484, 1108, 532, 1219, 0.587890625]]\n",
      "Key: Jh, vector len: 9, Card Detections: [[486, 1099, 538, 1216, 0.62939453125], [486, 1098, 538, 1214, 0.63330078125], [486, 1099, 537, 1214, 0.62548828125], [486, 1099, 537, 1213, 0.6318359375], [486, 1098, 538, 1214, 0.626953125], [486, 1099, 537, 1215, 0.62353515625], [486, 1099, 537, 1214, 0.6279296875], [486, 1101, 536, 1215, 0.62353515625], [485, 1102, 535, 1215, 0.62451171875]]\n",
      "Key: Js, vector len: 14, Card Detections: [[492, 1091, 545, 1211, 0.673828125], [492, 1091, 547, 1212, 0.6806640625], [493, 1092, 546, 1210, 0.67919921875], [493, 1092, 546, 1212, 0.6796875], [493, 1092, 546, 1212, 0.6787109375], [492, 1092, 545, 1212, 0.6806640625], [492, 1093, 545, 1213, 0.6787109375], [492, 1092, 545, 1212, 0.677734375], [492, 1093, 544, 1213, 0.67333984375], [492, 1093, 544, 1213, 0.67236328125], [491, 1093, 543, 1214, 0.67138671875], [491, 1094, 543, 1214, 0.666015625], [490, 1096, 544, 1215, 0.66015625], [488, 1097, 542, 1215, 0.6630859375]]\n",
      "Key: Kc, vector len: 43, Card Detections: [[84, 1170, 147, 1275, 0.6826171875], [87, 1158, 151, 1270, 0.5732421875], [91, 1149, 152, 1264, 0.69091796875], [94, 1141, 155, 1261, 0.67041015625], [95, 1139, 155, 1258, 0.66943359375], [96, 1137, 155, 1256, 0.669921875], [95, 1134, 155, 1254, 0.67626953125], [96, 1134, 155, 1255, 0.67919921875], [97, 1134, 156, 1254, 0.68408203125], [97, 1134, 156, 1253, 0.6865234375], [98, 1133, 157, 1253, 0.689453125], [98, 1133, 156, 1252, 0.693359375], [98, 1132, 156, 1252, 0.69140625], [99, 1132, 158, 1252, 0.68994140625], [99, 1132, 159, 1252, 0.685546875], [100, 1131, 160, 1251, 0.68310546875], [101, 1131, 161, 1252, 0.68603515625], [102, 1130, 162, 1251, 0.68896484375], [103, 1129, 162, 1251, 0.69140625], [103, 1129, 162, 1251, 0.69482421875], [103, 1129, 162, 1251, 0.693359375], [103, 1129, 162, 1251, 0.6923828125], [103, 1129, 162, 1250, 0.689453125], [103, 1129, 162, 1250, 0.68798828125], [103, 1129, 162, 1251, 0.6884765625], [103, 1129, 162, 1251, 0.6865234375], [103, 1129, 162, 1251, 0.6884765625], [103, 1129, 162, 1251, 0.68994140625], [103, 1129, 162, 1251, 0.693359375], [103, 1129, 162, 1251, 0.6904296875], [103, 1128, 162, 1250, 0.69189453125], [103, 1128, 162, 1250, 0.69140625], [103, 1129, 162, 1251, 0.693359375], [103, 1129, 162, 1251, 0.6923828125], [103, 1129, 162, 1251, 0.69091796875], [103, 1129, 162, 1251, 0.6904296875], [103, 1129, 162, 1251, 0.6875], [103, 1129, 162, 1251, 0.68603515625], [103, 1129, 163, 1251, 0.6865234375], [103, 1129, 164, 1251, 0.68505859375], [104, 1130, 164, 1251, 0.693359375], [103, 1130, 164, 1251, 0.6953125], [106, 1130, 163, 1252, 0.646484375]]\n",
      "Key: Kd, vector len: 8, Card Detections: [[484, 1105, 537, 1221, 0.642578125], [484, 1105, 538, 1219, 0.65283203125], [484, 1104, 537, 1220, 0.65087890625], [484, 1104, 537, 1220, 0.654296875], [484, 1104, 537, 1219, 0.6533203125], [484, 1104, 537, 1220, 0.65576171875], [483, 1104, 537, 1221, 0.66064453125], [481, 1104, 535, 1224, 0.591796875]]\n",
      "Key: Kh, vector len: 8, Card Detections: [[102, 1066, 162, 1198, 0.6328125], [103, 1067, 162, 1197, 0.63671875], [104, 1066, 162, 1196, 0.6328125], [105, 1066, 161, 1197, 0.63525390625], [105, 1066, 162, 1195, 0.63037109375], [105, 1066, 162, 1195, 0.630859375], [105, 1066, 162, 1197, 0.6318359375], [106, 1067, 163, 1197, 0.64111328125]]\n",
      "Key: Ks, vector len: 6, Card Detections: [[101, 1081, 163, 1210, 0.66357421875], [102, 1080, 163, 1210, 0.69677734375], [103, 1080, 164, 1210, 0.693359375], [103, 1081, 164, 1210, 0.69287109375], [105, 1079, 165, 1209, 0.6962890625], [105, 1081, 166, 1210, 0.7021484375]]\n",
      "Key: Qc, vector len: 9, Card Detections: [[88, 1055, 146, 1188, 0.66552734375], [89, 1056, 146, 1188, 0.65380859375], [89, 1057, 145, 1188, 0.64892578125], [90, 1058, 144, 1188, 0.6376953125], [90, 1057, 144, 1188, 0.638671875], [90, 1059, 144, 1190, 0.63818359375], [90, 1059, 144, 1191, 0.63525390625], [91, 1059, 144, 1191, 0.640625], [91, 1062, 144, 1193, 0.62744140625]]\n",
      "Key: Qd, vector len: 13, Card Detections: [[494, 1095, 545, 1211, 0.62744140625], [495, 1095, 546, 1211, 0.63427734375], [495, 1096, 546, 1211, 0.63037109375], [495, 1096, 546, 1211, 0.6328125], [495, 1095, 545, 1211, 0.63427734375], [495, 1096, 546, 1212, 0.63330078125], [495, 1095, 545, 1211, 0.6318359375], [495, 1095, 545, 1211, 0.6328125], [495, 1096, 546, 1212, 0.63427734375], [494, 1096, 546, 1212, 0.638671875], [494, 1096, 546, 1213, 0.64111328125], [493, 1098, 544, 1213, 0.64404296875], [492, 1100, 543, 1212, 0.64111328125]]\n",
      "Key: Qh, vector len: 8, Card Detections: [[482, 1111, 535, 1224, 0.6337890625], [482, 1111, 535, 1224, 0.638671875], [482, 1110, 535, 1225, 0.63232421875], [482, 1111, 535, 1225, 0.6318359375], [482, 1110, 534, 1225, 0.63232421875], [482, 1110, 534, 1224, 0.634765625], [481, 1110, 534, 1224, 0.63232421875], [481, 1111, 534, 1224, 0.6240234375]]\n",
      "Key: Qs, vector len: 17, Card Detections: [[493, 1090, 549, 1210, 0.67724609375], [497, 1090, 551, 1213, 0.67333984375], [497, 1090, 550, 1213, 0.669921875], [497, 1090, 550, 1213, 0.67041015625], [497, 1090, 550, 1213, 0.66943359375], [497, 1090, 550, 1214, 0.66748046875], [497, 1090, 550, 1213, 0.66796875], [497, 1090, 550, 1213, 0.669921875], [497, 1090, 550, 1213, 0.66943359375], [496, 1090, 550, 1213, 0.66943359375], [495, 1091, 549, 1213, 0.66748046875], [495, 1091, 549, 1214, 0.671875], [495, 1092, 549, 1213, 0.66796875], [496, 1092, 549, 1213, 0.66455078125], [495, 1093, 548, 1213, 0.66650390625], [494, 1094, 547, 1214, 0.66650390625], [493, 1096, 546, 1215, 0.6806640625]]\n",
      "Key: SJoker, vector len: 15, Card Detections: [[486, 1089, 548, 1216, 0.50927734375], [486, 1090, 552, 1231, 0.59814453125], [488, 1090, 548, 1218, 0.55224609375], [487, 1090, 550, 1228, 0.599609375], [487, 1090, 550, 1228, 0.59521484375], [487, 1090, 550, 1229, 0.572265625], [486, 1091, 549, 1229, 0.57861328125], [486, 1090, 549, 1228, 0.63134765625], [486, 1091, 549, 1233, 0.623046875], [487, 1090, 550, 1232, 0.623046875], [487, 1090, 549, 1229, 0.62939453125], [486, 1090, 549, 1229, 0.63037109375], [486, 1092, 550, 1231, 0.630859375], [486, 1093, 549, 1231, 0.5869140625], [487, 1095, 549, 1231, 0.6044921875]]\n",
      "Key: BJoker, vector len: 15, Card Detections: [[486, 1091, 551, 1233, 0.60107421875], [485, 1090, 555, 1240, 0.60693359375], [487, 1091, 551, 1227, 0.609375], [486, 1092, 552, 1236, 0.61669921875], [487, 1091, 553, 1237, 0.61474609375], [486, 1091, 552, 1238, 0.6201171875], [487, 1091, 553, 1239, 0.62353515625], [487, 1091, 553, 1239, 0.62646484375], [486, 1092, 554, 1240, 0.62744140625], [486, 1091, 554, 1240, 0.626953125], [486, 1091, 554, 1240, 0.6279296875], [487, 1091, 553, 1240, 0.62646484375], [487, 1091, 553, 1241, 0.62890625], [487, 1092, 554, 1242, 0.6318359375], [486, 1096, 551, 1240, 0.63720703125]]\n",
      "X shape: (10, 5, 2)\n",
      "y shape: (10, 2)\n",
      "X_test : [[[      0.125     0.94118]\n",
      "  [       0.25     0.88235]\n",
      "  [       0.25     0.94118]\n",
      "  [       0.25     0.94118]\n",
      "  [       0.25     0.94118]]\n",
      "\n",
      " [[       0.75     0.32352]\n",
      "  [       0.75    0.088234]\n",
      "  [      0.875    0.088234]\n",
      "  [       0.75     0.44118]\n",
      "  [          1           0]]], y_test: [[          0     0.96875]\n",
      " [          1     0.03125]]\n",
      "X_train shape: (8, 5, 2), num_samples: 8, window_size: 5, feature_len: 2\n",
      "y_train shape: (8, 2)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 5, 2)]            0         \n",
      "                                                                 \n",
      " masking_1 (Masking)         (None, 5, 2)              0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 5, 512)            530432    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 5, 512)            0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 5, 512)            2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 5, 256)            656384    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 5, 256)            0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 5, 256)            1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirecti  (None, 5, 128)            164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 5, 128)            0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 5, 64)             37248     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 5, 64)             0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 5, 64)             256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " attention_1 (Attention)     (None, 64)                69        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1393959 (5.32 MB)\n",
      "Trainable params: 1392295 (5.31 MB)\n",
      "Non-trainable params: 1664 (6.50 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 310.8983 - accuracy: 0.6250\n",
      "Epoch 1: val_loss improved from inf to 307.79254, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 21s 21s/step - loss: 310.8983 - accuracy: 0.6250 - val_loss: 307.7925 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 308.0344 - accuracy: 0.8750\n",
      "Epoch 2: val_loss improved from 307.79254 to 304.79852, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 308.0344 - accuracy: 0.8750 - val_loss: 304.7985 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 304.6691 - accuracy: 0.8750\n",
      "Epoch 3: val_loss improved from 304.79852 to 301.81332, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 304.6691 - accuracy: 0.8750 - val_loss: 301.8133 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 301.5668 - accuracy: 0.7500\n",
      "Epoch 4: val_loss improved from 301.81332 to 298.79294, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 301.5668 - accuracy: 0.7500 - val_loss: 298.7929 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 298.5279 - accuracy: 0.8750\n",
      "Epoch 5: val_loss improved from 298.79294 to 295.76080, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 298.5279 - accuracy: 0.8750 - val_loss: 295.7608 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 295.6104 - accuracy: 0.7500\n",
      "Epoch 6: val_loss improved from 295.76080 to 292.74771, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 295.6104 - accuracy: 0.7500 - val_loss: 292.7477 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 292.4483 - accuracy: 0.8750\n",
      "Epoch 7: val_loss improved from 292.74771 to 289.73175, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 292.4483 - accuracy: 0.8750 - val_loss: 289.7318 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 289.3975 - accuracy: 0.8750\n",
      "Epoch 8: val_loss improved from 289.73175 to 286.71082, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 289.3975 - accuracy: 0.8750 - val_loss: 286.7108 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 286.6039 - accuracy: 0.6250\n",
      "Epoch 9: val_loss improved from 286.71082 to 283.70282, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 286.6039 - accuracy: 0.6250 - val_loss: 283.7028 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 283.4103 - accuracy: 1.0000\n",
      "Epoch 10: val_loss improved from 283.70282 to 280.70084, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 283.4103 - accuracy: 1.0000 - val_loss: 280.7008 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 280.3457 - accuracy: 1.0000\n",
      "Epoch 11: val_loss improved from 280.70084 to 277.70114, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 280.3457 - accuracy: 1.0000 - val_loss: 277.7011 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 277.5454 - accuracy: 1.0000\n",
      "Epoch 12: val_loss improved from 277.70114 to 274.71683, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 277.5454 - accuracy: 1.0000 - val_loss: 274.7168 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 274.6766 - accuracy: 0.8750\n",
      "Epoch 13: val_loss improved from 274.71683 to 271.74887, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 274.6766 - accuracy: 0.8750 - val_loss: 271.7489 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 271.4589 - accuracy: 1.0000\n",
      "Epoch 14: val_loss improved from 271.74887 to 268.78995, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 271.4589 - accuracy: 1.0000 - val_loss: 268.7899 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 268.3954 - accuracy: 1.0000\n",
      "Epoch 15: val_loss improved from 268.78995 to 265.83652, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 268.3954 - accuracy: 1.0000 - val_loss: 265.8365 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 265.5508 - accuracy: 0.8750\n",
      "Epoch 16: val_loss improved from 265.83652 to 262.89441, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 265.5508 - accuracy: 0.8750 - val_loss: 262.8944 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 262.5535 - accuracy: 1.0000\n",
      "Epoch 17: val_loss improved from 262.89441 to 259.96164, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 262.5535 - accuracy: 1.0000 - val_loss: 259.9616 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 259.8768 - accuracy: 1.0000\n",
      "Epoch 18: val_loss improved from 259.96164 to 257.04971, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 259.8768 - accuracy: 1.0000 - val_loss: 257.0497 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 256.6364 - accuracy: 1.0000\n",
      "Epoch 19: val_loss improved from 257.04971 to 254.14745, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 256.6364 - accuracy: 1.0000 - val_loss: 254.1474 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 253.8072 - accuracy: 0.7500\n",
      "Epoch 20: val_loss improved from 254.14745 to 251.25735, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 253.8072 - accuracy: 0.7500 - val_loss: 251.2574 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 250.8741 - accuracy: 1.0000\n",
      "Epoch 21: val_loss improved from 251.25735 to 248.37775, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 250.8741 - accuracy: 1.0000 - val_loss: 248.3777 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 248.1068 - accuracy: 0.8750\n",
      "Epoch 22: val_loss improved from 248.37775 to 245.51292, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 248.1068 - accuracy: 0.8750 - val_loss: 245.5129 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 245.1825 - accuracy: 0.8750\n",
      "Epoch 23: val_loss improved from 245.51292 to 242.66258, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 245.1825 - accuracy: 0.8750 - val_loss: 242.6626 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 242.2221 - accuracy: 1.0000\n",
      "Epoch 24: val_loss improved from 242.66258 to 239.82394, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 242.2221 - accuracy: 1.0000 - val_loss: 239.8239 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 239.4769 - accuracy: 0.8750\n",
      "Epoch 25: val_loss improved from 239.82394 to 236.99931, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 239.4769 - accuracy: 0.8750 - val_loss: 236.9993 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 236.6318 - accuracy: 1.0000\n",
      "Epoch 26: val_loss improved from 236.99931 to 234.18796, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 236.6318 - accuracy: 1.0000 - val_loss: 234.1880 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 233.8261 - accuracy: 1.0000\n",
      "Epoch 27: val_loss improved from 234.18796 to 231.39240, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 233.8261 - accuracy: 1.0000 - val_loss: 231.3924 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 231.0144 - accuracy: 0.7500\n",
      "Epoch 28: val_loss improved from 231.39240 to 228.61067, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 231.0144 - accuracy: 0.7500 - val_loss: 228.6107 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 228.2414 - accuracy: 1.0000\n",
      "Epoch 29: val_loss improved from 228.61067 to 225.84387, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 228.2414 - accuracy: 1.0000 - val_loss: 225.8439 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 225.5687 - accuracy: 0.8750\n",
      "Epoch 30: val_loss improved from 225.84387 to 223.09369, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 225.5687 - accuracy: 0.8750 - val_loss: 223.0937 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 222.6617 - accuracy: 1.0000\n",
      "Epoch 31: val_loss improved from 223.09369 to 220.35886, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 222.6617 - accuracy: 1.0000 - val_loss: 220.3589 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 220.0038 - accuracy: 1.0000\n",
      "Epoch 32: val_loss improved from 220.35886 to 217.64056, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 220.0038 - accuracy: 1.0000 - val_loss: 217.6406 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 217.2710 - accuracy: 1.0000\n",
      "Epoch 33: val_loss improved from 217.64056 to 214.93784, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 217.2710 - accuracy: 1.0000 - val_loss: 214.9378 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 214.5728 - accuracy: 1.0000\n",
      "Epoch 34: val_loss improved from 214.93784 to 212.25137, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 214.5728 - accuracy: 1.0000 - val_loss: 212.2514 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 211.9727 - accuracy: 1.0000\n",
      "Epoch 35: val_loss improved from 212.25137 to 209.58408, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 211.9727 - accuracy: 1.0000 - val_loss: 209.5841 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 209.2081 - accuracy: 1.0000\n",
      "Epoch 36: val_loss improved from 209.58408 to 206.93381, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 209.2081 - accuracy: 1.0000 - val_loss: 206.9338 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 206.4971 - accuracy: 1.0000\n",
      "Epoch 37: val_loss improved from 206.93381 to 204.29987, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 206.4971 - accuracy: 1.0000 - val_loss: 204.2999 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 203.9442 - accuracy: 1.0000\n",
      "Epoch 38: val_loss improved from 204.29987 to 201.68265, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 203.9442 - accuracy: 1.0000 - val_loss: 201.6826 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 201.3270 - accuracy: 1.0000\n",
      "Epoch 39: val_loss improved from 201.68265 to 199.08266, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 201.3270 - accuracy: 1.0000 - val_loss: 199.0827 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 198.6901 - accuracy: 1.0000\n",
      "Epoch 40: val_loss improved from 199.08266 to 196.49989, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 198.6901 - accuracy: 1.0000 - val_loss: 196.4999 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 196.1332 - accuracy: 1.0000\n",
      "Epoch 41: val_loss improved from 196.49989 to 193.93459, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 196.1332 - accuracy: 1.0000 - val_loss: 193.9346 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 193.5074 - accuracy: 0.8750\n",
      "Epoch 42: val_loss improved from 193.93459 to 191.38490, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 193.5074 - accuracy: 0.8750 - val_loss: 191.3849 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 190.9812 - accuracy: 1.0000\n",
      "Epoch 43: val_loss improved from 191.38490 to 188.85251, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 190.9812 - accuracy: 1.0000 - val_loss: 188.8525 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 188.4278 - accuracy: 1.0000\n",
      "Epoch 44: val_loss improved from 188.85251 to 186.33664, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 188.4278 - accuracy: 1.0000 - val_loss: 186.3366 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 185.9295 - accuracy: 1.0000\n",
      "Epoch 45: val_loss improved from 186.33664 to 183.83919, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 185.9295 - accuracy: 1.0000 - val_loss: 183.8392 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 183.4219 - accuracy: 1.0000\n",
      "Epoch 46: val_loss improved from 183.83919 to 181.35999, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 183.4219 - accuracy: 1.0000 - val_loss: 181.3600 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 180.9281 - accuracy: 1.0000\n",
      "Epoch 47: val_loss improved from 181.35999 to 178.89847, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 180.9281 - accuracy: 1.0000 - val_loss: 178.8985 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 178.4609 - accuracy: 1.0000\n",
      "Epoch 48: val_loss improved from 178.89847 to 176.45518, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 178.4609 - accuracy: 1.0000 - val_loss: 176.4552 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 176.0425 - accuracy: 1.0000\n",
      "Epoch 49: val_loss improved from 176.45518 to 174.03009, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 176.0425 - accuracy: 1.0000 - val_loss: 174.0301 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 173.6344 - accuracy: 1.0000\n",
      "Epoch 50: val_loss improved from 174.03009 to 171.62297, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 173.6344 - accuracy: 1.0000 - val_loss: 171.6230 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 171.2422 - accuracy: 1.0000\n",
      "Epoch 51: val_loss improved from 171.62297 to 169.23456, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 171.2422 - accuracy: 1.0000 - val_loss: 169.2346 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 168.8621 - accuracy: 1.0000\n",
      "Epoch 52: val_loss improved from 169.23456 to 166.86438, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 168.8621 - accuracy: 1.0000 - val_loss: 166.8644 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 166.5122 - accuracy: 0.8750\n",
      "Epoch 53: val_loss improved from 166.86438 to 164.51332, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 166.5122 - accuracy: 0.8750 - val_loss: 164.5133 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 164.0779 - accuracy: 1.0000\n",
      "Epoch 54: val_loss improved from 164.51332 to 162.18060, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 164.0779 - accuracy: 1.0000 - val_loss: 162.1806 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 161.7433 - accuracy: 1.0000\n",
      "Epoch 55: val_loss improved from 162.18060 to 159.86636, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 161.7433 - accuracy: 1.0000 - val_loss: 159.8664 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 159.4469 - accuracy: 1.0000\n",
      "Epoch 56: val_loss improved from 159.86636 to 157.57086, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 159.4469 - accuracy: 1.0000 - val_loss: 157.5709 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 157.1572 - accuracy: 1.0000\n",
      "Epoch 57: val_loss improved from 157.57086 to 155.29436, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 157.1572 - accuracy: 1.0000 - val_loss: 155.2944 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 154.8824 - accuracy: 1.0000\n",
      "Epoch 58: val_loss improved from 155.29436 to 153.03668, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 154.8824 - accuracy: 1.0000 - val_loss: 153.0367 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 152.5896 - accuracy: 1.0000\n",
      "Epoch 59: val_loss improved from 153.03668 to 150.79674, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 152.5896 - accuracy: 1.0000 - val_loss: 150.7967 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 150.3737 - accuracy: 1.0000\n",
      "Epoch 60: val_loss improved from 150.79674 to 148.57562, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 150.3737 - accuracy: 1.0000 - val_loss: 148.5756 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 148.1414 - accuracy: 1.0000\n",
      "Epoch 61: val_loss improved from 148.57562 to 146.37213, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 148.1414 - accuracy: 1.0000 - val_loss: 146.3721 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 145.9325 - accuracy: 1.0000\n",
      "Epoch 62: val_loss improved from 146.37213 to 144.18752, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 145.9325 - accuracy: 1.0000 - val_loss: 144.1875 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 143.7600 - accuracy: 1.0000\n",
      "Epoch 63: val_loss improved from 144.18752 to 142.02332, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 143.7600 - accuracy: 1.0000 - val_loss: 142.0233 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 141.6197 - accuracy: 1.0000\n",
      "Epoch 64: val_loss improved from 142.02332 to 139.87759, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 141.6197 - accuracy: 1.0000 - val_loss: 139.8776 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 139.4417 - accuracy: 1.0000\n",
      "Epoch 65: val_loss improved from 139.87759 to 137.75000, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 139.4417 - accuracy: 1.0000 - val_loss: 137.7500 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 137.3991 - accuracy: 1.0000\n",
      "Epoch 66: val_loss improved from 137.75000 to 135.64168, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 137.3991 - accuracy: 1.0000 - val_loss: 135.6417 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 135.2108 - accuracy: 1.0000\n",
      "Epoch 67: val_loss improved from 135.64168 to 133.55208, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 135.2108 - accuracy: 1.0000 - val_loss: 133.5521 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 133.1629 - accuracy: 1.0000\n",
      "Epoch 68: val_loss improved from 133.55208 to 131.48201, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 133.1629 - accuracy: 1.0000 - val_loss: 131.4820 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 131.0678 - accuracy: 1.0000\n",
      "Epoch 69: val_loss improved from 131.48201 to 129.43036, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 131.0678 - accuracy: 1.0000 - val_loss: 129.4304 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 129.0718 - accuracy: 1.0000\n",
      "Epoch 70: val_loss improved from 129.43036 to 127.39786, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 129.0718 - accuracy: 1.0000 - val_loss: 127.3979 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 126.9758 - accuracy: 1.0000\n",
      "Epoch 71: val_loss improved from 127.39786 to 125.38548, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 126.9758 - accuracy: 1.0000 - val_loss: 125.3855 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 124.9704 - accuracy: 1.0000\n",
      "Epoch 72: val_loss improved from 125.38548 to 123.39255, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 124.9704 - accuracy: 1.0000 - val_loss: 123.3925 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 123.0177 - accuracy: 1.0000\n",
      "Epoch 73: val_loss improved from 123.39255 to 121.41899, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 123.0177 - accuracy: 1.0000 - val_loss: 121.4190 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 121.0721 - accuracy: 0.8750\n",
      "Epoch 74: val_loss improved from 121.41899 to 119.46526, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 121.0721 - accuracy: 0.8750 - val_loss: 119.4653 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 119.0455 - accuracy: 1.0000\n",
      "Epoch 75: val_loss improved from 119.46526 to 117.53198, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 119.0455 - accuracy: 1.0000 - val_loss: 117.5320 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 117.1516 - accuracy: 1.0000\n",
      "Epoch 76: val_loss improved from 117.53198 to 115.61831, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 117.1516 - accuracy: 1.0000 - val_loss: 115.6183 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 115.1993 - accuracy: 1.0000\n",
      "Epoch 77: val_loss improved from 115.61831 to 113.72375, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 115.1993 - accuracy: 1.0000 - val_loss: 113.7238 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 113.3144 - accuracy: 1.0000\n",
      "Epoch 78: val_loss improved from 113.72375 to 111.84715, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 113.3144 - accuracy: 1.0000 - val_loss: 111.8471 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 111.4517 - accuracy: 1.0000\n",
      "Epoch 79: val_loss improved from 111.84715 to 109.99100, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 111.4517 - accuracy: 1.0000 - val_loss: 109.9910 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 109.6255 - accuracy: 1.0000\n",
      "Epoch 80: val_loss improved from 109.99100 to 108.15297, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 109.6255 - accuracy: 1.0000 - val_loss: 108.1530 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 107.7632 - accuracy: 1.0000\n",
      "Epoch 81: val_loss improved from 108.15297 to 106.33353, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 107.7632 - accuracy: 1.0000 - val_loss: 106.3335 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 105.9258 - accuracy: 1.0000\n",
      "Epoch 82: val_loss improved from 106.33353 to 104.53304, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 105.9258 - accuracy: 1.0000 - val_loss: 104.5330 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 104.1240 - accuracy: 1.0000\n",
      "Epoch 83: val_loss improved from 104.53304 to 102.75121, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 104.1240 - accuracy: 1.0000 - val_loss: 102.7512 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 102.3486 - accuracy: 1.0000\n",
      "Epoch 84: val_loss improved from 102.75121 to 100.98783, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 102.3486 - accuracy: 1.0000 - val_loss: 100.9878 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 100.5490 - accuracy: 1.0000\n",
      "Epoch 85: val_loss improved from 100.98783 to 99.24272, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 100.5490 - accuracy: 1.0000 - val_loss: 99.2427 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 98.8800 - accuracy: 0.8750\n",
      "Epoch 86: val_loss improved from 99.24272 to 97.51730, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 98.8800 - accuracy: 0.8750 - val_loss: 97.5173 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 97.1244 - accuracy: 1.0000\n",
      "Epoch 87: val_loss improved from 97.51730 to 95.81134, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 97.1244 - accuracy: 1.0000 - val_loss: 95.8113 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 95.3940 - accuracy: 1.0000\n",
      "Epoch 88: val_loss improved from 95.81134 to 94.12419, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 95.3940 - accuracy: 1.0000 - val_loss: 94.1242 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 93.7568 - accuracy: 1.0000\n",
      "Epoch 89: val_loss improved from 94.12419 to 92.45661, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 93.7568 - accuracy: 1.0000 - val_loss: 92.4566 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 92.0564 - accuracy: 1.0000\n",
      "Epoch 90: val_loss improved from 92.45661 to 90.80796, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 92.0564 - accuracy: 1.0000 - val_loss: 90.8080 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 90.4067 - accuracy: 1.0000\n",
      "Epoch 91: val_loss improved from 90.80796 to 89.17997, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 90.4067 - accuracy: 1.0000 - val_loss: 89.1800 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 88.7864 - accuracy: 1.0000\n",
      "Epoch 92: val_loss improved from 89.17997 to 87.57116, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 88.7864 - accuracy: 1.0000 - val_loss: 87.5712 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 87.1471 - accuracy: 1.0000\n",
      "Epoch 93: val_loss improved from 87.57116 to 85.98118, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 87.1471 - accuracy: 1.0000 - val_loss: 85.9812 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 85.5504 - accuracy: 1.0000\n",
      "Epoch 94: val_loss improved from 85.98118 to 84.40926, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 85.5504 - accuracy: 1.0000 - val_loss: 84.4093 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 83.9976 - accuracy: 1.0000\n",
      "Epoch 95: val_loss improved from 84.40926 to 82.85393, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 83.9976 - accuracy: 1.0000 - val_loss: 82.8539 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 82.4319 - accuracy: 1.0000\n",
      "Epoch 96: val_loss improved from 82.85393 to 81.31781, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 82.4319 - accuracy: 1.0000 - val_loss: 81.3178 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 80.8999 - accuracy: 1.0000\n",
      "Epoch 97: val_loss improved from 81.31781 to 79.80147, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 80.8999 - accuracy: 1.0000 - val_loss: 79.8015 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 79.3817 - accuracy: 1.0000\n",
      "Epoch 98: val_loss improved from 79.80147 to 78.30461, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 79.3817 - accuracy: 1.0000 - val_loss: 78.3046 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 77.8886 - accuracy: 1.0000\n",
      "Epoch 99: val_loss improved from 78.30461 to 76.82668, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 77.8886 - accuracy: 1.0000 - val_loss: 76.8267 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 76.4312 - accuracy: 1.0000\n",
      "Epoch 100: val_loss improved from 76.82668 to 75.36890, saving model to best_lstm_yolo_model_20240909_1703.tensorflow.keras\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 76.4312 - accuracy: 1.0000 - val_loss: 75.3689 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
      "训练损失: 75.3551, 训练Accuracy: 50.00%, 测试损失: 75.3689, 测试Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es/miniconda3/envs/hello1/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型成功保存为 ONNX 格式，路径为: best_lstm_yolo_model_20240909_1703.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 106, Total Ops 509, % non-converted = 20.83 %\n",
      " * 88 ARITH ops, 18 TF ops\n",
      "\n",
      "- arith.constant:   88 occurrences  (f32: 59, i32: 29)\n",
      "\n",
      "  (i1: 7, i32: 7)\n",
      "\n",
      "\n",
      "- tf.TensorListReserve:    4 occurrences  (: 4)\n",
      "- tf.TensorListSetItem:    7 occurrences  (: 7)\n",
      "- tf.TensorListStack:    7 occurrences  (f32: 7)\n",
      "  (f32: 48, i32: 14)\n",
      "  (f32: 1)\n",
      "  (f32: 3)\n",
      "  (i1: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 31)\n",
      "  (f32: 7, i1: 7)\n",
      "  (i1: 7)\n",
      "  (f32: 40)\n",
      "  (f32: 47)\n",
      "\n",
      "  (i1: 1)\n",
      "  (i32: 4)\n",
      "  (i1: 1)\n",
      "  (i1: 1)\n",
      "  (f32: 6, i1: 1)\n",
      "  (f32: 20)\n",
      "  (i32: 7)\n",
      "  (f32: 1)\n",
      "  (f32: 16)\n",
      "  (f32: 4, i32: 7)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 27)\n",
      "  (f32: 13, i1: 1)\n",
      "  (i32: 7)\n",
      "\n",
      "  (f32: 7)\n",
      "Running TensorFlow Graph Passes:   0%|          | 0/6 [00:00<?, ? passes/s]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "import onnx\n",
    "import tf2onnx\n",
    "import joblib\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# 获取 videos 文件夹中的所有视频文件路径\n",
    "video_extensions = ['.mov', '.mp4', '.avi', '.mkv', '.flv', '.wmv']  # 支持的所有视频格式（小写）\n",
    "video_paths = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if os.path.splitext(f)[1].lower() in video_extensions]\n",
    "\n",
    "print(\"视频文件路径列表:\", video_paths)\n",
    "\n",
    "all_detected_objects_list = []\n",
    "for video_path in video_paths:\n",
    "    detected_objects_list = load_video_frames(video_path)\n",
    "    all_detected_objects_list.append(detected_objects_list)\n",
    "\n",
    "# 时序数据的一般格式 time、x 和 y 列\n",
    "# 使用检测到的数据来训练,  X 是输入序列，y 是对应的目标输出\n",
    "# 定义不同的时间步长度, 每次用前3个时间步的数据来预测下一个时间步的行为\n",
    "time_steps = 5 # window_size 窗口大小\n",
    "feature_len = 2  # 每个时间步的2 values，输出2个值，对应类目标的未来位置cx, cy, card_velocity, direction, card_conf)\n",
    "#predict_times = 1  # 预测的时间步数\n",
    "dropout_rate = 0.2  # dropout比例\n",
    "\n",
    "X_all, y_all = [], []\n",
    "for detected_objects_list in all_detected_objects_list:\n",
    "    X, y = prepare_complex_sequence_data(detected_objects_list, time_steps)\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "\n",
    "# 填充序列，使所有样本具有相同的时间步长\n",
    "X_all = pad_sequences(X_all, maxlen=time_steps, dtype='float32', padding='post', truncating='post')\n",
    "y_all = pad_sequences(y_all, maxlen=time_steps, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# 合并所有视频样本的数据\n",
    "X_all = np.concatenate(X_all, axis=0)\n",
    "y_all = np.concatenate(y_all, axis=0)\n",
    "\n",
    "# 归一化处理特征数据\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_all = scaler_X.fit_transform(X_all.reshape(-1, X_all.shape[-1])).reshape(X_all.shape)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_all = scaler_y.fit_transform(y_all)\n",
    "\n",
    "# 提取缩放器参数\n",
    "scaler_X_params = {'min': scaler_X.data_min_.tolist(), 'max': scaler_X.data_max_.tolist()}\n",
    "scaler_y_params = {'min': scaler_y.data_min_.tolist(), 'max': scaler_y.data_max_.tolist()}\n",
    "\n",
    "\n",
    "print(\"X shape:\", X_all.shape)  # 输出 (num_samples 54, window_size 5, feature_len 5)\n",
    "print(\"y shape:\", y_all.shape)  # 输出 (num_samples, feature_len)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_test : {X_test}, y_test: {y_test}\")\n",
    "\n",
    "# 检查 X_train 的形状\n",
    "print(f\"X_train shape: {X_train.shape}, num_samples: {X_train.shape[0]}, window_size: {X_train.shape[1]}, feature_len: {X_train.shape[2]}\")\n",
    "\n",
    "# 确保目标数据的形状与模型的输出形状一致\n",
    "# 目标数据的形状应该是 (batch_size, x, feature_len)\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "#y_train = np.reshape(y_train, (y_train.shape[0], predict_times, feature_len))\n",
    "#print(f\"y_train shape: {y_train.shape}, num_samples: {y_train.shape[0]}, window_size: {y_train.shape[1]}, feature_len: {y_train.shape[2]}\")\n",
    "\n",
    "# 模型训练\n",
    "# LSTM模型的輸入形狀: X_train.shape[1] 是window_size，X_train.shape[2] num_features是指定目标的7个特征值(x1, y1, x2, y2, card_area, card_velocity, card_conf)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "lstm_model = create_bilstm_attention_model(input_shape, dropout_rate)\n",
    "\n",
    "# 定义回调函数\n",
    "# Add Tensorboard\n",
    "tb_callback = TensorBoard(log_dir='./tb_results', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# EarlyStopping：监控val_loss，如果50个epoch内没有改善，则停止训练，并恢复至最佳模型权重。\n",
    "# ReduceLROnPlateau：当val_loss停止改善时，将学习率降低一半。\n",
    "# ModelCheckpoint：在每个epoch后保存最佳模型\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'best_lstm_yolo_model_{current_time}.tensorflow.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "#model_checkpoint = ModelCheckpoint(f'best_lstm_yolo_model_{current_time}.tensorflow.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "# 拟合nn训练模型: 整个数据集上训练12000次，每次训练32个样本，validation_data 在每个 epoch结束后计算验证集的损失\n",
    "history = lstm_model.fit(X_train, y_train, \n",
    "                epochs=1000,\n",
    "                batch_size=32,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[tb_callback, reduce_lr, model_checkpoint])\n",
    "\n",
    "# # 保存 scaler\n",
    "joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
    "\n",
    "# 保存为 JSON 文件\n",
    "with open('scaler_X.json', 'w') as f:\n",
    "    json.dump(scaler_X_params, f)\n",
    "\n",
    "with open('scaler_y.json', 'w') as f:\n",
    "    json.dump(scaler_y_params, f)\n",
    "\n",
    "# 评估模型\n",
    "train_loss, train_accuracy = lstm_model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss, test_accuracy = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"训练损失: {train_loss:.4f}, 训练Accuracy: {train_accuracy * 100:.2f}%, 测试损失: {test_loss:.4f}, 测试Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "# 选择最佳模型\n",
    "# 训练过程中每个 epoch 的验证损失值\n",
    "val_loss = history.history['val_loss']\n",
    "# 验证损失最小的 epoch 对应就是最佳模型, 保存为lstm_weights_xx.h5文件\n",
    "best_epoch = np.argmin(val_loss)\n",
    "best_model = load_model(f'best_lstm_yolo_model_{current_time}.tensorflow.keras', custom_objects={'Attention': Attention})\n",
    "best_model.save(f'best_lstm_yolo_model_{current_time}.h5')  # 保存整个模型\n",
    "\n",
    "# 将 Keras 模型转换为 ONNX 格式\n",
    "spec = (tf.TensorSpec((None, X_train.shape[1], X_train.shape[2]), tf.float32, name=\"input\"),)\n",
    "output_path = f'best_lstm_yolo_model_{current_time}.onnx'\n",
    "model_proto, _ = tf2onnx.convert.from_keras(best_model, input_signature=spec, opset=13)\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "print(f\"模型成功保存为 ONNX 格式，路径为: {output_path}\")\n",
    "\n",
    "# Convert the model to tflite.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'best_lstm_yolo_model_{current_time}.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "## 转换Core ML 模型\n",
    "# 定义输入\n",
    "sequence_input = ct.TensorType(shape=(1, X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# 进行模型转换\n",
    "coreml_model = ct.convert(\n",
    "    best_model,\n",
    "    convert_to=\"neuralnetwork\",\n",
    "    inputs=[sequence_input]\n",
    ")\n",
    "\n",
    "# 写入元数据\n",
    "#coreml_model.input_description[\"input_1\"] = \"输入序列数据\"\n",
    "#coreml_model.output_description[\"output_1\"] = \"模型输出\"\n",
    "\n",
    "# 模型作者\n",
    "coreml_model.author = \"hello\"\n",
    "\n",
    "# 许可\n",
    "coreml_model.license = \"许可信息\"\n",
    "\n",
    "# 描述\n",
    "coreml_model.short_description = \"双向LSTM模型, 带有注意力机制\"\n",
    "\n",
    "# 版本号\n",
    "coreml_model.version = \"1.0\"\n",
    "\n",
    "# 存储模型\n",
    "coreml_output_path = f'best_lstm_yolo_model_{current_time}.mlmodel'\n",
    "coreml_model.save(coreml_output_path)\n",
    "print(f\"模型成功保存为 CoreML 格式，路径为: {coreml_output_path}\")\n",
    "\n",
    "# 评估模型性能\n",
    "rmse, mse, mae, r2 = evaluate_inverse_performance(lstm_model, X_test, y_test)\n",
    "print(f\"RMSE: {rmse}, MSE: {mse}, MAE: {mae}, R2 Score: {r2}\")\n",
    "\n",
    "# 预测未来行为 如根据最近 3 frame序列, LSTM 模型进行预测下一个时间步的目标位置\n",
    "predictions = best_model.predict(X_test)\n",
    "# inverse 转回去原来的coordinate system\n",
    "predictions = scaler_y.inverse_transform(predictions)\n",
    "print(f\"预测结果：{predictions}\")\n",
    "\n",
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "# 真实数据\n",
    "print(f\"真实数据：{y_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看TensorBoard 实验结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML 打包环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.15 coremltools h5py pillow\n",
    "!python -c \"import coremltools; print(coremltools.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlpackage 新格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 选择最佳模型\n",
    "best_model = load_model(f'best_lstm_yolo_model_{current_time}.h5', custom_objects={'Attention': Attention})\n",
    "\n",
    "# 转换Core ML 模型\n",
    "# 定义输入\n",
    "sequence_input = ct.TensorType(shape=(1, 3, 9))\n",
    "\n",
    "# 进行模型转换\n",
    "coreml_model = ct.convert(\n",
    "    best_model,\n",
    "    inputs=[sequence_input]\n",
    ")\n",
    "\n",
    "# 打印模型的输入和输出特征名称\n",
    "print(\"模型的输入特征名称:\", coreml_model.input_description)\n",
    "print(\"模型的输出特征名称:\", coreml_model.output_description)\n",
    "\n",
    "# 写入元数据\n",
    "#input_feature_name = list(coreml_model.input_description.keys())[0]\n",
    "#output_feature_name = list(coreml_model.output_description.keys())[0]\n",
    "\n",
    "#coreml_model.input_description[input_feature_name] = \"输入序列数据\"\n",
    "#coreml_model.output_description[output_feature_name] = \"模型输出\"\n",
    "\n",
    "# 模型作者\n",
    "coreml_model.author = \"hello\"\n",
    "\n",
    "# 许可\n",
    "coreml_model.license = \"你的许可信息\"\n",
    "\n",
    "# 描述\n",
    "coreml_model.short_description = \"双向LSTM模型，带有注意力机制\"\n",
    "\n",
    "# 版本号\n",
    "coreml_model.version = \"1.0\"\n",
    "\n",
    "# 存储模型\n",
    "coreml_output_path = f'best_lstm_yolo_model.mlpackage'\n",
    "coreml_model.save(coreml_output_path)\n",
    "print(f\"模型成功保存为 Core ML 格式，路径为: {coreml_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlmodel 老格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 选择最佳模型\n",
    "best_model = load_model(f'best_lstm_yolo_model_{current_time}.h5', custom_objects={'Attention': Attention})\n",
    "\n",
    "# 转换Core ML 模型\n",
    "# 定义输入\n",
    "sequence_input = ct.TensorType(shape=(1, 5, 5))\n",
    "\n",
    "# 进行模型转换\n",
    "coreml_model = ct.convert(\n",
    "    best_model, \n",
    "    convert_to=\"neuralnetwork\",\n",
    "    inputs=[sequence_input]\n",
    ")\n",
    "\n",
    "# 打印模型的输入和输出特征名称\n",
    "print(\"模型的输入特征名称:\", coreml_model.input_description)\n",
    "print(\"模型的输出特征名称:\", coreml_model.output_description)\n",
    "\n",
    "# 写入元数据\n",
    "#input_feature_name = list(coreml_model.input_description.keys())[0]\n",
    "#output_feature_name = list(coreml_model.output_description.keys())[0]\n",
    "\n",
    "#coreml_model.input_description[input_feature_name] = \"输入序列数据\"\n",
    "#coreml_model.output_description[output_feature_name] = \"模型输出\"\n",
    "\n",
    "# 模型作者\n",
    "coreml_model.author = \"hello\"\n",
    "\n",
    "# 许可\n",
    "coreml_model.license = \"你的许可信息\"\n",
    "\n",
    "# 描述\n",
    "coreml_model.short_description = \"双向LSTM模型，带有注意力机制\"\n",
    "\n",
    "# 版本号\n",
    "coreml_model.version = \"1.0\"\n",
    "\n",
    "# 存储模型\n",
    "coreml_output_path = f'best_lstm_yolo_model.mlmodel'\n",
    "coreml_model.save(coreml_output_path)\n",
    "print(f\"模型成功保存为 Core ML 格式，路径为: {coreml_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import coremltools as ct\n",
    "\n",
    "# 加载 CoreML 模型\n",
    "coreml_model = ct.models.MLModel(f'best_lstm_yolo_model_20240906_0803.mlmodel')\n",
    "\n",
    "# 加载保存的 MinMaxScaler\n",
    "scaler_X = joblib.load('scaler_X.pkl')\n",
    "scaler_y = joblib.load('scaler_y.pkl')\n",
    "\n",
    "# 假设 X_test 是你的测试数据\n",
    "X_test = np.random.rand(1, 5, 5)  # 示例数据\n",
    "\n",
    "# 数据归一化\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "X_test_scaled = scaler_X.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "\n",
    "# 准备输入数据\n",
    "input_data = {'input_1': X_test_scaled}\n",
    "\n",
    "# 执行预测\n",
    "outputs = coreml_model.predict(input_data)\n",
    "y_pred_scaled = outputs['Identity']\n",
    "\n",
    "# 反归一化预测结果\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "print(f\"预测结果（反归一化）：{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测转换后的ONNX模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 2 Got: 5 Expected: 3\n Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 执行预测\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx预测结果:\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 2 Got: 5 Expected: 3\n Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_model = onnx.load(f'best_lstm_yolo_model_{current_time}.onnx')\n",
    "\n",
    "# 检查模型是否有效\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# 创建 ONNX Runtime 会话\n",
    "ort_session = ort.InferenceSession(f'best_lstm_yolo_model_{current_time}.onnx')\n",
    "\n",
    "# 准备输入数据（根据实际情况调整）\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "input_data = np.random.random((1, 5, 5)).astype(np.float32)\n",
    "\n",
    "# 执行预测\n",
    "outputs = ort_session.run(None, {input_name: input_data})\n",
    "print(\"onnx预测结果:\", outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测结果和真实结果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "# 时间步（样本）索引\n",
    "samples = np.arange(y_test.shape[0])\n",
    "\n",
    "# 特征标签\n",
    "features = ['cx', 'cy', 'card_velocity', 'direction', 'card_conf']\n",
    "\n",
    "# 创建图形和子图\n",
    "fig, axes = plt.subplots(len(features), 1, figsize=(14, 3 * len(features)), tight_layout=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 绘制每个特征的真实值和预测值\n",
    "for i in range(len(features)):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples, y_test[:, i], marker='o', linestyle='-', label='True', color='blue', markersize=4, linewidth=1.5)\n",
    "    ax.plot(samples, predictions[:, i], marker='x', linestyle='--', label='Predicted', color='red', markersize=6, linewidth=1.5)\n",
    "    ax.set_title(f'{features[i]}: True vs Predicted', fontsize=14)\n",
    "    ax.set_xlabel('Sample Index', fontsize=12)\n",
    "    ax.set_ylabel('Value', fontsize=12)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.7)\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 评估指标可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制训练与验证损失曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练与验证准确度曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型评估与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设有新的测试数据集\n",
    "test_samples = 10  # 测试样本数\n",
    "time_steps = 5\n",
    "num_features = 5\n",
    "test_data = np.random.rand(test_samples, time_steps, num_features)\n",
    "\n",
    "# 对测试数据进行标准化：我们使用标准化来将数据缩放到均值为0，标准差为1的范围内\n",
    "# (num_samples, time_steps, num_features) -> (num_samples * time_steps, num_features)\n",
    "scaler = StandardScaler()\n",
    "test_data_reshaped = test_data.reshape(-1, num_features)\n",
    "test_data_reshaped = scaler.fit_transform(test_data_reshaped)\n",
    "\n",
    "test_data_reshaped = scaler.transform(test_data_reshaped)\n",
    "# (num_samples * time_steps, num_features) -> (num_samples, time_steps, num_features)\n",
    "test_data = test_data_reshaped.reshape(test_samples, time_steps, num_features)\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = lstm_model.predict(test_data)\n",
    "\n",
    "# 将预测结果转换为类别标签\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# 显示每个测试样本的预测结果\n",
    "for i in range(test_samples):\n",
    "    print(f\"Sample {i+1} predictions: {predicted_classes[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
